{
    "offset": 0,
    "data": [
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Several works have theoretically studied the success of self-supervised learning (Arora et al., 2019; HaoChen et al., 2021; Lee et al., 2020; Tian et al., 2021; Tosh et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "98fdd001d836f54096efe6121ee0db1400a348ad",
                "externalIds": {
                    "ArXiv": "2310.01583",
                    "CorpusId": 263608898
                },
                "corpusId": 263608898,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/98fdd001d836f54096efe6121ee0db1400a348ad",
                "title": "An Investigation of Representation and Allocation Harms in Contrastive Learning",
                "abstract": "The effect of underrepresentation on the performance of minority groups is known to be a serious problem in supervised learning settings; however, it has been underexplored so far in the context of self-supervised learning (SSL). In this paper, we demonstrate that contrastive learning (CL), a popular variant of SSL, tends to collapse representations of minority groups with certain majority groups. We refer to this phenomenon as representation harm and demonstrate it on image and text datasets using the corresponding popular CL methods. Furthermore, our causal mediation analysis of allocation harm on a downstream classification task reveals that representation harm is partly responsible for it, thus emphasizing the importance of studying and mitigating representation harm. Finally, we provide a theoretical explanation for representation harm using a stochastic block model that leads to a representational neural collapse in a contrastive learning setting.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1471072023",
                        "name": "Subha Maity"
                    },
                    {
                        "authorId": "145625761",
                        "name": "Mayank Agarwal"
                    },
                    {
                        "authorId": "8202372",
                        "name": "Mikhail Yurochkin"
                    },
                    {
                        "authorId": "2247880508",
                        "name": "Yuekai Sun"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Several theoretical investigations have delved into the realm of feature decorrelation based methods within the domain of self-supervised learning, as evidenced by a collection of notable studies [4, 16, 30, 35, 44, 48, 51, 55]."
            ],
            "citingPaper": {
                "paperId": "0964e1b29bd82f1d0f685d44dbdcf6d8c5cce4d8",
                "externalIds": {
                    "ArXiv": "2309.17281",
                    "CorpusId": 263310758
                },
                "corpusId": 263310758,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0964e1b29bd82f1d0f685d44dbdcf6d8c5cce4d8",
                "title": "Information Flow in Self-Supervised Learning",
                "abstract": "In this paper, we provide a comprehensive toolbox for understanding and enhancing self-supervised learning (SSL) methods through the lens of matrix information theory. Specifically, by leveraging the principles of matrix mutual information and joint entropy, we offer a unified analysis for both contrastive and feature decorrelation based methods. Furthermore, we propose the matrix variational masked auto-encoder (M-MAE) method, grounded in matrix information theory, as an enhancement to masked image modeling. The empirical evaluations underscore the effectiveness of M-MAE compared with the state-of-the-art methods, including a 3.9% improvement in linear probing ViT-Base, and a 1% improvement in fine-tuning ViT-Large, both on ImageNet.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "144459366",
                        "name": "Zhiyuan Tan"
                    },
                    {
                        "authorId": "2121269197",
                        "name": "Jingqin Yang"
                    },
                    {
                        "authorId": "8007867",
                        "name": "Weiran Huang"
                    },
                    {
                        "authorId": "2116944866",
                        "name": "Yang Yuan"
                    },
                    {
                        "authorId": "46867228",
                        "name": "Yifan Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "44fee256c12618f02e49169ce9c820e9f8120f88",
                "externalIds": {
                    "ArXiv": "2309.16109",
                    "CorpusId": 263138356
                },
                "corpusId": 263138356,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/44fee256c12618f02e49169ce9c820e9f8120f88",
                "title": "Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics",
                "abstract": "Contrastive learning is a self-supervised representation learning framework, where two positive views generated through data augmentation are made similar by an attraction force in a data representation space, while a repulsive force makes them far from negative examples. Non-contrastive learning, represented by BYOL and SimSiam, further gets rid of negative examples and improves computational efficiency. While learned representations may collapse into a single point due to the lack of the repulsive force at first sight, Tian et al. (2021) revealed through the learning dynamics analysis that the representations can avoid collapse if data augmentation is sufficiently stronger than regularization. However, their analysis does not take into account commonly-used feature normalization, a normalizer before measuring the similarity of representations, and hence excessively strong regularization may collapse the dynamics, which is an unnatural behavior under the presence of feature normalization. Therefore, we extend the previous theory based on the L2 loss by considering the cosine loss, which involves feature normalization. We show that the cosine loss induces sixth-order dynamics (while the L2 loss induces a third-order one), in which a stable equilibrium dynamically emerges even if there are only collapsed solutions with given initial parameters. Thus, we offer a new understanding that feature normalization plays an important role in robustly preventing the dynamics collapse.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2248063366",
                        "name": "Han Bao"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "648d5066c810f95b0b146d13f43780595ca8efe8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-04148",
                    "ArXiv": "2309.04148",
                    "DOI": "10.48550/arXiv.2309.04148",
                    "CorpusId": 261660578
                },
                "corpusId": 261660578,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/648d5066c810f95b0b146d13f43780595ca8efe8",
                "title": "Representation Synthesis by Probabilistic Many-Valued Logic Operation in Self-Supervised Learning",
                "abstract": "Self-supervised learning (SSL) using mixed images has been studied to learn various image representations. Existing methods using mixed images learn a representation by maximizing the similarity between the representation of the mixed image and the synthesized representation of the original images. However, few methods consider the synthesis of representations from the perspective of mathematical logic. In this study, we focused on a synthesis method of representations. We proposed a new SSL with mixed images and a new representation format based on many-valued logic. This format can indicate the feature-possession degree, that is, how much of each image feature is possessed by a representation. This representation format and representation synthesis by logic operation realize that the synthesized representation preserves the remarkable characteristics of the original representations. Our method performed competitively with previous representation synthesis methods for image classification tasks. We also examined the relationship between the feature-possession degree and the number of classes of images in the multilabel image classification dataset to verify that the intended learning was achieved. In addition, we discussed image retrieval, which is an application of our proposed representation format using many-valued logic.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2159561166",
                        "name": "Hiroki Nakamura"
                    },
                    {
                        "authorId": "2114306014",
                        "name": "Masashi Okada"
                    },
                    {
                        "authorId": "1684099",
                        "name": "T. Taniguchi"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "7f732c05c45070cc9e1f25ce8aaedae0c98035e5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-14705",
                    "ArXiv": "2308.14705",
                    "DOI": "10.48550/arXiv.2308.14705",
                    "CorpusId": 261242477
                },
                "corpusId": 261242477,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7f732c05c45070cc9e1f25ce8aaedae0c98035e5",
                "title": "Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning",
                "abstract": "Ensembling a neural network is a widely recognized approach to enhance model performance, estimate uncertainty, and improve robustness in deep supervised learning. However, deep ensembles often come with high computational costs and memory demands. In addition, the efficiency of a deep ensemble is related to diversity among the ensemble members which is challenging for large, over-parameterized deep neural networks. Moreover, ensemble learning has not yet seen such widespread adoption, and it remains a challenging endeavor for self-supervised or unsupervised representation learning. Motivated by these challenges, we present a novel self-supervised training regime that leverages an ensemble of independent sub-networks, complemented by a new loss function designed to encourage diversity. Our method efficiently builds a sub-model ensemble with high diversity, leading to well-calibrated estimates of model uncertainty, all achieved with minimal computational overhead compared to traditional deep self-supervised ensembles. To evaluate the effectiveness of our approach, we conducted extensive experiments across various tasks, including in-distribution generalization, out-of-distribution detection, dataset corruption, and semi-supervised settings. The results demonstrate that our method significantly improves prediction reliability. Our approach not only achieves excellent accuracy but also enhances calibration, surpassing baseline performance across a wide range of self-supervised architectures in computer vision, natural language processing, and genomics data.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2234345330",
                        "name": "Amirhossein Vahidi"
                    },
                    {
                        "authorId": "1447029846",
                        "name": "Lisa Wimmer"
                    },
                    {
                        "authorId": "2183506503",
                        "name": "H. G\u00fcnd\u00fcz"
                    },
                    {
                        "authorId": "2133449619",
                        "name": "Bernd Bischl"
                    },
                    {
                        "authorId": "1691955",
                        "name": "E. H\u00fcllermeier"
                    },
                    {
                        "authorId": "35593430",
                        "name": "Mina Rezaei"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "d88f924ce16a38999937bfb69d807d9da2c4395f",
                "externalIds": {
                    "ArXiv": "2308.14009",
                    "DBLP": "journals/corr/abs-2308-14009",
                    "DOI": "10.1109/TMM.2023.3280734",
                    "CorpusId": 258975906
                },
                "corpusId": 258975906,
                "publicationVenue": {
                    "id": "10e76a35-58d6-443c-9683-fc16f2dd0a92",
                    "name": "IEEE transactions on multimedia",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Transactions on Multimedia",
                        "IEEE Trans Multimedia",
                        "IEEE trans multimedia"
                    ],
                    "issn": "1520-9210",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6046"
                },
                "url": "https://www.semanticscholar.org/paper/d88f924ce16a38999937bfb69d807d9da2c4395f",
                "title": "Towards Fast and Accurate Image-Text Retrieval with Self-Supervised Fine-Grained Alignment",
                "abstract": "Image-text retrieval requires the system to bridge the heterogenous gap between vision and language for accurate retrieval while keeping the network lightweight-enough for efficient retrieval. Existing trade-off solutions mainly study from the view of incorporating cross-modal interactions with the independent-embedding framework or leveraging stronger pretrained encoders, which still demand time-consuming similarity measurement or heavyweight model structure in the retrieval stage. In this work, we propose an image-text alignment module SelfAlign on top of the independent-embedding framework, which improves the retrieval accuracy while maintains the retrieval efficiency without extra supervision. SelfAlign contains two collaborative sub-modules that force image-text alignment at both concept level and context level by self-supervised contrastive learning. It does not require cross-modal embedding interactions during training while maintaining independent image and text encoders during retrieval. With comparable time cost, SelfAlign consistently boosts the accuracy of state-of-the-art non-pretraining independent-embedding models respectively by 9.1%, 4.2% and 6.6% in terms of R@sum score on Flickr30K, MSCOCO 1K and MS-COCO 5K datasets. The retrieval accuracy also outperforms most existing interactive-embedding models with orders of magnitude decrease in retrieval time. The source code is available at: https://github.com/Zjamie813/SelfAlign.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2218597039",
                        "name": "Jiamin Zhuang"
                    },
                    {
                        "authorId": "2151480743",
                        "name": "Jing Yu"
                    },
                    {
                        "authorId": "2193660961",
                        "name": "Yang Ding"
                    },
                    {
                        "authorId": "2233163242",
                        "name": "Xiangyang Qu"
                    },
                    {
                        "authorId": "2112321824",
                        "name": "Yue Hu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Research identifies that combining asymmetrical structures and special tricks [7, 8, 12] enables contrastive learning to",
                "SimSiam [8] subsequently built on BYOL to conduct abundant comparative experiments and demonstrated that the stop-grad [8, 12] is the most vital part in asymmetric method.",
                "3 School of Automation, Southeast University, Nanjing 210096, Jiangsu, China collapses all outputs of the model into constant solutions [11, 12]."
            ],
            "citingPaper": {
                "paperId": "5e2190e164863533a3f6f4f4b6df9d65c4d9c825",
                "externalIds": {
                    "DBLP": "journals/mva/LiuWWZ23",
                    "DOI": "10.1007/s00138-023-01440-z",
                    "CorpusId": 261067492
                },
                "corpusId": 261067492,
                "publicationVenue": {
                    "id": "400d5e36-be35-4097-898f-753f4493156e",
                    "name": "Machine Vision and Applications",
                    "type": "journal",
                    "alternate_names": [
                        "Journal of Machine Vision and Applications",
                        "Mach Vis Appl",
                        "J Mach Vis Appl"
                    ],
                    "issn": "0932-8092",
                    "url": "https://www.springer.com/computer/image+processing/journal/138",
                    "alternate_urls": [
                        "https://link.springer.com/journal/138",
                        "https://www.springer.com/computer/image+processing/journal/138?changeHeader",
                        "http://www.springer.com/computer/image+processing/journal/138"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5e2190e164863533a3f6f4f4b6df9d65c4d9c825",
                "title": "Instance-dimension dual contrastive learning of visual representations",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2186543842",
                        "name": "Qingrui Liu"
                    },
                    {
                        "authorId": "2144692874",
                        "name": "Liantao Wang"
                    },
                    {
                        "authorId": "2233046785",
                        "name": "Qinxu Wang"
                    },
                    {
                        "authorId": "2144165736",
                        "name": "Jinxia Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "079f7bf89ef8e66428926c06938fa896259847a7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-12433",
                    "ArXiv": "2308.12433",
                    "DOI": "10.48550/arXiv.2308.12433",
                    "CorpusId": 261101031
                },
                "corpusId": 261101031,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/079f7bf89ef8e66428926c06938fa896259847a7",
                "title": "A Spatiotemporal Correspondence Approach to Unsupervised LiDAR Segmentation with Traffic Applications",
                "abstract": "We address the problem of unsupervised semantic segmentation of outdoor LiDAR point clouds in diverse traffic scenarios. The key idea is to leverage the spatiotemporal nature of a dynamic point cloud sequence and introduce drastically stronger augmentation by establishing spatiotemporal correspondences across multiple frames. We dovetail clustering and pseudo-label learning in this work. Essentially, we alternate between clustering points into semantic groups and optimizing models using point-wise pseudo-spatiotemporal labels with a simple learning objective. Therefore, our method can learn discriminative features in an unsupervised learning fashion. We show promising segmentation performance on Semantic-KITTI, SemanticPOSS, and FLORIDA benchmark datasets covering scenarios in autonomous vehicle and intersection infrastructure, which is competitive when compared against many existing fully supervised learning methods. This general framework can lead to a unified representation learning approach for LiDAR point clouds incorporating domain knowledge.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108784858",
                        "name": "Xiao Li"
                    },
                    {
                        "authorId": "2118242059",
                        "name": "Pan He"
                    },
                    {
                        "authorId": "1443742098",
                        "name": "A. Wu"
                    },
                    {
                        "authorId": "2155033230",
                        "name": "Sanjay Ranka"
                    },
                    {
                        "authorId": "145257016",
                        "name": "A. Rangarajan"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Compared to contrastive learning, they are generally more efficient and conceptually simple while maintaining state-of-the-art performance [60]."
            ],
            "citingPaper": {
                "paperId": "80fdad6beb0f95157c0b7b9cdd16f2e5da5f2065",
                "externalIds": {
                    "ArXiv": "2308.02346",
                    "DBLP": "journals/corr/abs-2308-02346",
                    "DOI": "10.48550/arXiv.2308.02346",
                    "CorpusId": 260610834
                },
                "corpusId": 260610834,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/80fdad6beb0f95157c0b7b9cdd16f2e5da5f2065",
                "title": "Class Incremental Learning with Self-Supervised Pre-Training and Prototype Learning",
                "abstract": "Deep Neural Network (DNN) has achieved great success on datasets of closed class set. However, new classes, like new categories of social media topics, are continuously added to the real world, making it necessary to incrementally learn. This is hard for DNN because it tends to focus on fitting to new classes while ignoring old classes, a phenomenon known as catastrophic forgetting. State-of-the-art methods rely on knowledge distillation and data replay techniques but still have limitations. In this work, we analyze the causes of catastrophic forgetting in class incremental learning, which owes to three factors: representation drift, representation confusion, and classifier distortion. Based on this view, we propose a two-stage learning framework with a fixed encoder and an incrementally updated prototype classifier. The encoder is trained with self-supervised learning to generate a feature space with high intrinsic dimensionality, thus improving its transferability and generality. The classifier incrementally learns new prototypes while retaining the prototypes of previously learned data, which is crucial in preserving the decision boundary.Our method does not rely on preserved samples of old classes, is thus a non-exemplar based CIL method. Experiments on public datasets show that our method can significantly outperform state-of-the-art exemplar-based methods when they reserved 5 examplers per class, under the incremental setting of 10 phases, by 18.24% on CIFAR-100 and 9.37% on ImageNet100.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2230167644",
                        "name": "Wenzhuo Liu"
                    },
                    {
                        "authorId": "150344922",
                        "name": "Xinjian Wu"
                    },
                    {
                        "authorId": "2075372121",
                        "name": "Fei Zhu"
                    },
                    {
                        "authorId": "2161255193",
                        "name": "Mingming Yu"
                    },
                    {
                        "authorId": "47074942",
                        "name": "Chuan Wang"
                    },
                    {
                        "authorId": "1689269",
                        "name": "Cheng-Lin Liu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "These methods leverage an additional learnable predictor and employ a stop-gradient operation to prevent collapsing, contributing to their successful performance [111]."
            ],
            "citingPaper": {
                "paperId": "916bc9ed62113ad7a5bb8096051593df4ebb2061",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-01578",
                    "ArXiv": "2308.01578",
                    "DOI": "10.48550/arXiv.2308.01578",
                    "CorpusId": 260438737
                },
                "corpusId": 260438737,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/916bc9ed62113ad7a5bb8096051593df4ebb2061",
                "title": "Unsupervised Representation Learning for Time Series: A Review",
                "abstract": "Unsupervised representation learning approaches aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "103236149",
                        "name": "Qianwen Meng"
                    },
                    {
                        "authorId": "1732549",
                        "name": "Hangwei Qian"
                    },
                    {
                        "authorId": "2144384782",
                        "name": "Yong Liu"
                    },
                    {
                        "authorId": "153018970",
                        "name": "Yonghui Xu"
                    },
                    {
                        "authorId": "2111639168",
                        "name": "Zhiqi Shen"
                    },
                    {
                        "authorId": "101457473",
                        "name": "Li-zhen Cui"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "b96a5d6ff0e0c0ad9a1b29029894b2e2342eacb7",
                "externalIds": {
                    "DBLP": "journals/cea/ZhaoZL23",
                    "DOI": "10.1016/j.compag.2023.107967",
                    "CorpusId": 259133897
                },
                "corpusId": 259133897,
                "publicationVenue": {
                    "id": "80fdf70e-8520-4bb7-b387-3abebc9970b7",
                    "name": "Computers and Electronics in Agriculture",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Electron Agric"
                    ],
                    "issn": "0168-1699",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/503304/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/01681699"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b96a5d6ff0e0c0ad9a1b29029894b2e2342eacb7",
                "title": "CLA: A self-supervised contrastive learning method for leaf disease identification with domain adaptation",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2185960148",
                        "name": "Ruzhun Zhao"
                    },
                    {
                        "authorId": "2044551577",
                        "name": "Yuchan Zhu"
                    },
                    {
                        "authorId": "2110413745",
                        "name": "Yuanhong Li"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "e153ecfd36a2a829a9fb989e59940e7cb6b38051",
                "externalIds": {
                    "DBLP": "journals/pr/LiZCBLW23",
                    "DOI": "10.1016/j.patcog.2023.109874",
                    "CorpusId": 260820249
                },
                "corpusId": 260820249,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e153ecfd36a2a829a9fb989e59940e7cb6b38051",
                "title": "BLoG: Bootstrapped graph representation learning with local and global regularization for recommendation",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2150654687",
                        "name": "Ming Li"
                    },
                    {
                        "authorId": "2143836329",
                        "name": "Lin Zhang"
                    },
                    {
                        "authorId": "2290930",
                        "name": "Lixin Cui"
                    },
                    {
                        "authorId": "2075398670",
                        "name": "Lu Bai"
                    },
                    {
                        "authorId": "2193503627",
                        "name": "Zhao Li"
                    },
                    {
                        "authorId": "1748808",
                        "name": "Xindong Wu"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "We will use BYOL (Grill et al. (2020), Definition 2.3)6 for our investigation into scaling as it is wellstudied (Tian et al., 2021; Richemond et al., 2023), relatively simple to implement due to minimal hyper-parameters, and obtains competitive results (Grill et al., 2020; Koppula et al., 2022).",
                "3)6 for our investigation into scaling as it is wellstudied (Tian et al., 2021; Richemond et al., 2023), relatively simple to implement due to minimal hyper-parameters, and obtains competitive results (Grill et al."
            ],
            "citingPaper": {
                "paperId": "3d04f5bb0599ce02d8fa47420f72f500758c4660",
                "externalIds": {
                    "ArXiv": "2307.13813",
                    "DBLP": "journals/corr/abs-2307-13813",
                    "DOI": "10.48550/arXiv.2307.13813",
                    "CorpusId": 260164693
                },
                "corpusId": 260164693,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3d04f5bb0599ce02d8fa47420f72f500758c4660",
                "title": "How to Scale Your EMA",
                "abstract": "Preserving training dynamics across batch sizes is an important tool for practical machine learning as it enables the trade-off between batch size and wall-clock time. This trade-off is typically enabled by a scaling rule, for example, in stochastic gradient descent, one should scale the learning rate linearly with the batch size. Another important tool for practical machine learning is the model Exponential Moving Average (EMA), which is a model copy that does not receive gradient information, but instead follows its target model with some momentum. This model EMA can improve the robustness and generalization properties of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL). Prior works have treated the model EMA separately from optimization, leading to different training dynamics across batch sizes and lower model performance. In this work, we provide a scaling rule for optimization in the presence of model EMAs and demonstrate its validity across a range of architectures, optimizers, and data modalities. We also show the rule's validity where the model EMA contributes to the optimization of the target model, enabling us to train EMA-based pseudo-labeling and SSL methods at small and large batch sizes. For SSL, we enable training of BYOL up to batch size 24,576 without sacrificing performance, optimally a 6$\\times$ wall-clock time reduction.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46254693",
                        "name": "Dan Busbridge"
                    },
                    {
                        "authorId": "16092809",
                        "name": "Jason Ramapuram"
                    },
                    {
                        "authorId": "1763708",
                        "name": "Pierre Ablin"
                    },
                    {
                        "authorId": "145827700",
                        "name": "T. Likhomanenko"
                    },
                    {
                        "authorId": "76954832",
                        "name": "Eeshan Gunesh Dhekane"
                    },
                    {
                        "authorId": "2270464",
                        "name": "Xavier Suau"
                    },
                    {
                        "authorId": "51138986",
                        "name": "Russ Webb"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "50f916a09f4f1cafaf175c18db82f41ec23b685e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-10317",
                    "ArXiv": "2307.10317",
                    "DOI": "10.48550/arXiv.2307.10317",
                    "CorpusId": 259991147
                },
                "corpusId": 259991147,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/50f916a09f4f1cafaf175c18db82f41ec23b685e",
                "title": "FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning",
                "abstract": "Federated Learning (FL) offers a collaborative training framework, allowing multiple clients to contribute to a shared model without compromising data privacy. Due to the heterogeneous nature of local datasets, updated client models may overfit and diverge from one another, commonly known as the problem of client drift. In this paper, we propose FedBug (Federated Learning with Bottom-Up Gradual Unfreezing), a novel FL framework designed to effectively mitigate client drift. FedBug adaptively leverages the client model parameters, distributed by the server at each global round, as the reference points for cross-client alignment. Specifically, on the client side, FedBug begins by freezing the entire model, then gradually unfreezes the layers, from the input layer to the output layer. This bottom-up approach allows models to train the newly thawed layers to project data into a latent space, wherein the separating hyperplanes remain consistent across all clients. We theoretically analyze FedBug in a novel over-parameterization FL setup, revealing its superior convergence rate compared to FedAvg. Through comprehensive experiments, spanning various datasets, training conditions, and network architectures, we validate the efficacy of FedBug. Our contributions encompass a novel FL framework, theoretical analysis, and empirical validation, demonstrating the wide potential and applicability of FedBug.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2115997017",
                        "name": "Chia-Hsiang Kao"
                    },
                    {
                        "authorId": "2218628989",
                        "name": "Yu-Chiang Frank Wang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [
                "Kontrastif \u00f6\u011frenme, ayn\u0131 nesnenin art\u0131r\u0131lm\u0131\u015f g\u00f6r\u00fcnt\u00fclerine ait temsil vekt\u00f6rlerini bir araya getirirken negatif \u00f6rnekleri uzakla\u015ft\u0131rmay\u0131 te\u015fvik etmek olarak tan\u0131mlanabilir [3]."
            ],
            "citingPaper": {
                "paperId": "f4341572ba9805b05c94abde93a1b716df7e8d35",
                "externalIds": {
                    "DBLP": "conf/siu/ErdenCD23",
                    "DOI": "10.1109/SIU59756.2023.10223849",
                    "CorpusId": 261322609
                },
                "corpusId": 261322609,
                "publicationVenue": {
                    "id": "c5f8f5c8-58d0-46aa-bbb5-44ce60315635",
                    "name": "Signal Processing and Communications Applications Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Signal Process Commun Appl Conf",
                        "SIU"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f4341572ba9805b05c94abde93a1b716df7e8d35",
                "title": "Histopathological Classification of Colon Tissue Images with Self-Supervised Models",
                "abstract": "Deep learning techniques have demonstrated their ability to facilitate medical image diagnostics by offering more precise and accurate predictions. Convolutional neural network (CNN) architectures have been employed for a decade as the primary approach to enable automated diagnosis. On the other hand, recently proposed vision transformers (ViTs) based architectures have shown success in various computer vision tasks. However, their efficacy in medical image classification tasks remains largely unexplored due to their requirement for large datasets. Nevertheless, significant performance gains can be achieved by leveraging self-supervised learning techniques through pretraining. This paper analyzes performance of self- supervised pretrained networks in medical image classification tasks. Results on colon histopathology images revealed that CNN based architectures are more effective when trained from scratch, while pretrained models could achieve similar levels of performance with limited data.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2235619054",
                        "name": "Mehmet Bahadir Erden"
                    },
                    {
                        "authorId": "2150349740",
                        "name": "Selahattin Cansiz"
                    },
                    {
                        "authorId": "2776877",
                        "name": "Cigdem Demir"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "0146501975e1b59d32f0f92122ad9f2b26995b45",
                "externalIds": {
                    "DOI": "10.1016/j.knosys.2023.110824",
                    "CorpusId": 260179737
                },
                "corpusId": 260179737,
                "publicationVenue": {
                    "id": "12fff95b-d469-49a0-84a5-4fd4696c3f28",
                    "name": "Knowledge-Based Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Knowl Based Syst",
                        "Knowledge Based Systems",
                        "Knowledge-based Syst"
                    ],
                    "issn": "0950-7051",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525448/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/knowledge-based-systems",
                        "http://www.sciencedirect.com/science/journal/09507051"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0146501975e1b59d32f0f92122ad9f2b26995b45",
                "title": "ADCL: Adversarial Distilled Contrastive Learning on lightweight models for self-supervised image classification",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2116926825",
                        "name": "Ran Wu"
                    },
                    {
                        "authorId": "48447400",
                        "name": "Huanyu Liu"
                    },
                    {
                        "authorId": "1664642236",
                        "name": "Junbao Li"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "These models will not collapse to a trivial solution because they construct subtle asymmetry in the structure of the siamese network and create a dynamic buffer area (Tian, Chen, and Ganguli 2021).",
                "Tian, Chen, and Ganguli (2021) showed that a regularizer is essential for the existence of the non-collapsed solution."
            ],
            "citingPaper": {
                "paperId": "65909b7b029f8214f574f81f4dfbef1fe7289037",
                "externalIds": {
                    "DBLP": "conf/aaai/YangLJ023",
                    "DOI": "10.1609/aaai.v37i9.26282",
                    "CorpusId": 259739325
                },
                "corpusId": 259739325,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/65909b7b029f8214f574f81f4dfbef1fe7289037",
                "title": "Understanding Representation Learnability of Nonlinear Self-Supervised Learning",
                "abstract": "Self-supervised learning (SSL) has empirically shown its data representation learnability in many downstream tasks. There are only a few theoretical works on data representation learnability, and many of those focus on final data representation, treating the nonlinear neural network as a ``black box\". However, the accurate learning results of neural networks are crucial for describing the data distribution features learned by SSL models. Our paper is the first to analyze the learning results of the nonlinear SSL model accurately. We consider a toy data distribution that contains two features: the label-related feature and the hidden feature. Unlike previous linear setting work that depends on closed-form solutions, we use the gradient descent algorithm to train a 1-layer nonlinear SSL model with a certain initialization region and prove that the model converges to a local minimum. Furthermore, different from the complex iterative analysis, we propose a new analysis process which uses the exact version of Inverse Function Theorem to accurately describe the features learned by the local minimum. With this local minimum, we prove that the nonlinear SSL model can capture the label-related feature and hidden feature at the same time. In contrast, the nonlinear supervised learning (SL) model can only learn the label-related feature. We also present the learning processes and results of the nonlinear SSL and SL model via simulation experiments.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2152903728",
                        "name": "Ruofeng Yang"
                    },
                    {
                        "authorId": "2192358872",
                        "name": "Xiangyuan Li"
                    },
                    {
                        "authorId": "2222461981",
                        "name": "Bo Jiang"
                    },
                    {
                        "authorId": "2213842262",
                        "name": "Shuai Li"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "9783eb7bb5503c695827158bc8b3ddb91f40bef2",
                "externalIds": {
                    "ArXiv": "2306.14293",
                    "DBLP": "journals/corr/abs-2306-14293",
                    "DOI": "10.48550/arXiv.2306.14293",
                    "CorpusId": 259251505
                },
                "corpusId": 259251505,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/9783eb7bb5503c695827158bc8b3ddb91f40bef2",
                "title": "Multi-Scale Cross Contrastive Learning for Semi-Supervised Medical Image Segmentation",
                "abstract": "Semi-supervised learning has demonstrated great potential in medical image segmentation by utilizing knowledge from unlabeled data. However, most existing approaches do not explicitly capture high-level semantic relations between distant regions, which limits their performance. In this paper, we focus on representation learning for semi-supervised learning, by developing a novel Multi-Scale Cross Supervised Contrastive Learning (MCSC) framework, to segment structures in medical images. We jointly train CNN and Transformer models, regularising their features to be semantically consistent across different scales. Our approach contrasts multi-scale features based on ground-truth and cross-predicted labels, in order to extract robust feature representations that reflect intra- and inter-slice relationships across the whole dataset. To tackle class imbalance, we take into account the prevalence of each class to guide contrastive learning and ensure that features adequately capture infrequent classes. Extensive experiments on two multi-structure medical segmentation datasets demonstrate the effectiveness of MCSC. It not only outperforms state-of-the-art semi-supervised methods by more than 3.0% in Dice, but also greatly reduces the performance gap with fully supervised methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "4289746",
                        "name": "Qianying Liu"
                    },
                    {
                        "authorId": "19083548",
                        "name": "Xiao Gu"
                    },
                    {
                        "authorId": "2071774114",
                        "name": "Paul Henderson"
                    },
                    {
                        "authorId": "2775904",
                        "name": "F. Deligianni"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "aae9a3807f55bc4b45868c7f43afb8206f2f3baa",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-10684",
                    "ArXiv": "2306.10684",
                    "DOI": "10.1109/TNNLS.2023.3288022",
                    "CorpusId": 259203057,
                    "PubMed": "37436863"
                },
                "corpusId": 259203057,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/aae9a3807f55bc4b45868c7f43afb8206f2f3baa",
                "title": "Visually-Guided Sound Source Separation with Audio-Visual Predictive Coding",
                "abstract": "The framework of visually guided sound source separation generally consists of three parts: visual feature extraction, multimodal feature fusion, and sound signal processing. An ongoing trend in this field has been to tailor involved visual feature extractor for informative visual guidance and separately devise module for feature fusion, while utilizing U-Net by default for sound analysis. However, such a divide-and-conquer paradigm is parameter-inefficient and, meanwhile, may obtain suboptimal performance as jointly optimizing and harmonizing various model components is challengeable. By contrast, this article presents a novel approach, dubbed audio-visual predictive coding (AVPC), to tackle this task in a parameter-efficient and more effective manner. The network of AVPC features a simple ResNet-based video analysis network for deriving semantic visual features, and a predictive coding (PC)-based sound separation network that can extract audio features, fuse multimodal information, and predict sound separation masks in the same architecture. By iteratively minimizing the prediction error between features, AVPC integrates audio and visual information recursively, leading to progressively improved performance. In addition, we develop a valid self-supervised learning strategy for AVPC via copredicting two audio-visual representations of the same sound source. Extensive evaluations demonstrate that AVPC outperforms several baselines in separating musical instrument sounds, while reducing the model size significantly. Code is available at: https://github.com/zjsong/Audio-Visual-Predictive-Coding.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "51139139",
                        "name": "Zengjie Song"
                    },
                    {
                        "authorId": "2175272847",
                        "name": "Zhaoxiang Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "e9ad2c8a4f57ba4296dcd31a6e7d3c4b44725787",
                "externalIds": {
                    "ArXiv": "2306.09466",
                    "DBLP": "journals/corr/abs-2306-09466",
                    "DOI": "10.48550/arXiv.2306.09466",
                    "CorpusId": 259188106
                },
                "corpusId": 259188106,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/e9ad2c8a4f57ba4296dcd31a6e7d3c4b44725787",
                "title": "Simplified Temporal Consistency Reinforcement Learning",
                "abstract": "Reinforcement learning is able to solve complex sequential decision-making tasks but is currently limited by sample efficiency and required computation. To improve sample efficiency, recent work focuses on model-based RL which interleaves model learning with planning. Recent methods further utilize policy learning, value estimation, and, self-supervised learning as auxiliary objectives. In this paper we show that, surprisingly, a simple representation learning approach relying only on a latent dynamics model trained by latent temporal consistency is sufficient for high-performance RL. This applies when using pure planning with a dynamics model conditioned on the representation, but, also when utilizing the representation as policy and value function features in model-free RL. In experiments, our approach learns an accurate dynamics model to solve challenging high-dimensional locomotion tasks with online planners while being 4.1 times faster to train compared to ensemble-based methods. With model-free RL without planning, especially on high-dimensional tasks, such as the DeepMind Control Suite Humanoid and Dog tasks, our approach outperforms model-free methods by a large margin and matches model-based methods' sample efficiency while training 2.4 times faster.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2109917181",
                        "name": "Yi Zhao"
                    },
                    {
                        "authorId": "51044974",
                        "name": "Wenshuai Zhao"
                    },
                    {
                        "authorId": "22169323",
                        "name": "Rinu Boney"
                    },
                    {
                        "authorId": "1776374",
                        "name": "Juho Kannala"
                    },
                    {
                        "authorId": "34906504",
                        "name": "J. Pajarinen"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "The linear representation setting has been widely adopted in transfer learning and self-supervised learning (Jing et al., 2021; Tian et al., 2021; Ji et al., 2021; Wu et al., 2022; Tian, 2022; Nakada et al., 2023)."
            ],
            "citingPaper": {
                "paperId": "b3b726863c8245ebd8ffea7bd859f0bb12f57f02",
                "externalIds": {
                    "ArXiv": "2306.08173",
                    "DBLP": "journals/corr/abs-2306-08173",
                    "DOI": "10.48550/arXiv.2306.08173",
                    "CorpusId": 259165143
                },
                "corpusId": 259165143,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b3b726863c8245ebd8ffea7bd859f0bb12f57f02",
                "title": "Safeguarding Data in Multimodal AI: A Differentially Private Approach to CLIP Training",
                "abstract": "The surge in multimodal AI's success has sparked concerns over data privacy in vision-and-language tasks. While CLIP has revolutionized multimodal learning through joint training on images and text, its potential to unintentionally disclose sensitive information necessitates the integration of privacy-preserving mechanisms. We introduce a differentially private adaptation of the Contrastive Language-Image Pretraining (CLIP) model that effectively addresses privacy concerns while retaining accuracy. Our proposed method, Dp-CLIP, is rigorously evaluated on benchmark datasets encompassing diverse vision-and-language tasks such as image classification and visual question answering. We demonstrate that our approach retains performance on par with the standard non-private CLIP model. Furthermore, we analyze our proposed algorithm under linear representation settings. We derive the convergence rate of our algorithm and show a trade-off between utility and privacy when gradients are clipped per-batch and the loss function does not satisfy smoothness conditions assumed in the literature for the analysis of DP-SGD.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2220099799",
                        "name": "Alyssa Huang"
                    },
                    {
                        "authorId": "14283280",
                        "name": "Peihan Liu"
                    },
                    {
                        "authorId": "150280620",
                        "name": "Ryumei Nakada"
                    },
                    {
                        "authorId": "10537441",
                        "name": "Linjun Zhang"
                    },
                    {
                        "authorId": "2108277232",
                        "name": "Wanrong Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "contexts": [
                "(4)In fact, dimensional collapse is a more salient issue for non-contrastive approaches in SSL (Hua et al., 2021; Tian et al., 2021) due to the lack of negative pairs.",
                "To address dimensional collapse in contrastive learning (and more so in non-contrastive SSL), a line of work proposes to refine loss functions and design structured projectors (Balestriero et al., 2023), but a systematic treatment is still lacking.",
                "Among SSL methods (Chen et al., 2020a; Zbontar et al., 2021; Bardes et al., 2021), contrastive learning (Chen et al., 2020a) is arguably the most popular one, which is also the focus of this paper.",
                "4In fact, dimensional collapse is a more salient issue for non-contrastive approaches in SSL (Hua et al., 2021; Tian et al., 2021) due to the lack of negative pairs.",
                "Self-supervised learning (SSL) (Balestriero et al., 2023) has recently emerged as a novel paradigm to learn meaningful representations from huge unlabeled datasets (Misra and van der Maaten, 2019; Chen et al., 2020a; He et al., 2020; Dwibedi et al., 2021; HaoChen et al., 2021; Jing et al., 2021; Wang and Isola, 2020; Ji et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "1fb0bd938f726b62c0285d6bb2dcff19664bfc5d",
                "externalIds": {
                    "ArXiv": "2306.03335",
                    "DBLP": "journals/corr/abs-2306-03335",
                    "DOI": "10.48550/arXiv.2306.03335",
                    "CorpusId": 259089150
                },
                "corpusId": 259089150,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1fb0bd938f726b62c0285d6bb2dcff19664bfc5d",
                "title": "Unraveling Projection Heads in Contrastive Learning: Insights from Expansion and Shrinkage",
                "abstract": "We investigate the role of projection heads, also known as projectors, within the encoder-projector framework (e.g., SimCLR) used in contrastive learning. We aim to demystify the observed phenomenon where representations learned before projectors outperform those learned after -- measured using the downstream linear classification accuracy, even when the projectors themselves are linear. In this paper, we make two significant contributions towards this aim. Firstly, through empirical and theoretical analysis, we identify two crucial effects -- expansion and shrinkage -- induced by the contrastive loss on the projectors. In essence, contrastive loss either expands or shrinks the signal direction in the representations learned by an encoder, depending on factors such as the augmentation strength, the temperature used in contrastive loss, etc. Secondly, drawing inspiration from the expansion and shrinkage phenomenon, we propose a family of linear transformations to accurately model the projector's behavior. This enables us to precisely characterize the downstream linear classification accuracy in the high-dimensional asymptotic limit. Our findings reveal that linear projectors operating in the shrinkage (or expansion) regime hinder (or improve) the downstream classification accuracy. This provides the first theoretical explanation as to why (linear) projectors impact the downstream performance of learned representations. Our theoretical findings are further corroborated by extensive experiments on both synthetic data and real image data.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "48301009",
                        "name": "Yu Gui"
                    },
                    {
                        "authorId": "1706883847",
                        "name": "Cong Ma"
                    },
                    {
                        "authorId": "2896246",
                        "name": "Yiqiao Zhong"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "54b60b248a8902b30cf216303939c50daaa775e7",
                "externalIds": {
                    "DOI": "10.1109/icassp49357.2023.10094790",
                    "CorpusId": 258529903
                },
                "corpusId": 258529903,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/54b60b248a8902b30cf216303939c50daaa775e7",
                "title": "EMCLR: Expectation Maximization Contrastive Learning Representations",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2216503413",
                        "name": "Meng Liu"
                    },
                    {
                        "authorId": "2073168293",
                        "name": "Ran Yi"
                    },
                    {
                        "authorId": "2149343311",
                        "name": "Lizhuang Ma"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "0aacb6cb82b7a796989c44ab5769e53b96a0532e",
                "externalIds": {
                    "DOI": "10.1109/icassp49357.2023.10096173",
                    "CorpusId": 258543105
                },
                "corpusId": 258543105,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/0aacb6cb82b7a796989c44ab5769e53b96a0532e",
                "title": "Ultimate Negative Sampling for Contrastive Learning",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2110972528",
                        "name": "Huijie Guo"
                    },
                    {
                        "authorId": "145770644",
                        "name": "Lei Shi"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "73ccf31a7e429a61601d2aa6953136d842d73d30",
                "externalIds": {
                    "ArXiv": "2306.00788",
                    "DBLP": "journals/corr/abs-2306-00788",
                    "DOI": "10.48550/arXiv.2306.00788",
                    "CorpusId": 258999873
                },
                "corpusId": 258999873,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/73ccf31a7e429a61601d2aa6953136d842d73d30",
                "title": "Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation",
                "abstract": "Data augmentation is critical to the empirical success of modern self-supervised representation learning, such as contrastive learning and masked language modeling. However, a theoretical understanding of the exact role of the augmentation remains limited. Recent work has built the connection between self-supervised learning and the approximation of the top eigenspace of a graph Laplacian operator, suggesting that learning a linear probe atop such representation can be connected to RKHS regression. Building on this insight, this work delves into a statistical analysis of augmentation-based pretraining. Starting from the isometry property, a geometric characterization of the target function given by the augmentation, we disentangle the effects of the model and the augmentation, and prove two generalization bounds that are free of model complexity. Our first bound works for an arbitrary encoder, and it is the sum of an estimation error bound incurred by fitting a linear probe, and an approximation error bound by RKHS approximation. Our second bound specifically addresses the case where the encoder extracts the top-d eigenspace of a finite-sample-based approximation of the underlying RKHS. A key ingredient in our analysis is the augmentation complexity, which we use to quantitatively compare different augmentations and analyze their impact on downstream performance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3265543",
                        "name": "Runtian Zhai"
                    },
                    {
                        "authorId": "2208142494",
                        "name": "Bing Liu"
                    },
                    {
                        "authorId": "3181040",
                        "name": "Andrej Risteski"
                    },
                    {
                        "authorId": "117539586",
                        "name": "Zico Kolter"
                    },
                    {
                        "authorId": "145969795",
                        "name": "Pradeep Ravikumar"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "While there are many lenses one may take up to study the problem [18, 31, 19, 29, 28, 16], a particularly related to this work concurrent body of literature has adopted the view of the kernel or laplacian-based spectral representation learning [11, 1], which we also share in this work."
            ],
            "citingPaper": {
                "paperId": "4c5d65b02f9f84d572a2cba90d4ac8c68e8e24c1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-19818",
                    "ArXiv": "2305.19818",
                    "DOI": "10.48550/arXiv.2305.19818",
                    "CorpusId": 258987408
                },
                "corpusId": 258987408,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4c5d65b02f9f84d572a2cba90d4ac8c68e8e24c1",
                "title": "Bridging Spectral Embedding and Matrix Completion in Self-Supervised Learning",
                "abstract": "Self-supervised methods received tremendous attention thanks to their seemingly heuristic approach to learning representations that respect the semantics of the data without any apparent supervision in the form of labels. A growing body of literature is already being published in an attempt to build a coherent and theoretically grounded understanding of the workings of a zoo of losses used in modern self-supervised representation learning methods. In this paper, we attempt to provide an understanding from the perspective of a Laplace operator and connect the inductive bias stemming from the augmentation process to a low-rank matrix completion problem. To this end, we leverage the results from low-rank matrix completion to provide theoretical analysis on the convergence of modern SSL methods and a key property that affects their downstream performance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "35783462",
                        "name": "Marina Munkhoeva"
                    },
                    {
                        "authorId": "1738205",
                        "name": "I. Oseledets"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Various theoretical studies have also investigated non-contrastive methods for self-supervised learning [5, 18, 33, 48, 54, 58, 63, 70]."
            ],
            "citingPaper": {
                "paperId": "9265d7801707b9754a5751a990555c3a7edb5f07",
                "externalIds": {
                    "ArXiv": "2305.17326",
                    "CorpusId": 258959512
                },
                "corpusId": 258959512,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/9265d7801707b9754a5751a990555c3a7edb5f07",
                "title": "Matrix Information Theory for Self-Supervised Learning",
                "abstract": "Contrastive learning often relies on comparing positive anchor samples with multiple negative samples to perform Self-Supervised Learning (SSL). However, non-contrastive approaches like BYOL, SimSiam, and Barlow Twins achieve SSL without explicit negative samples. In this paper, we introduce a unified matrix information-theoretic framework that explains many contrastive and non-contrastive learning methods. We then propose a novel method Matrix-SSL based on matrix information theory. Experimental results reveal that Matrix-SSL significantly outperforms state-of-the-art methods on the ImageNet dataset under linear evaluation settings and on MS-COCO for transfer learning tasks. Specifically, when performing 100 epochs pre-training, our method outperforms SimCLR by 4.6%, and when performing transfer learning tasks on MS-COCO, our method outperforms previous SOTA methods such as MoCo v2 and BYOL up to 3.3% with only 400 epochs compared to 800 epochs pre-training. Code available at https://github.com/yifanzhang-pro/Matrix-SSL.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46867228",
                        "name": "Yifan Zhang"
                    },
                    {
                        "authorId": "74125866",
                        "name": "Zhi-Hao Tan"
                    },
                    {
                        "authorId": "2121269197",
                        "name": "Jingqin Yang"
                    },
                    {
                        "authorId": "8007867",
                        "name": "Weiran Huang"
                    },
                    {
                        "authorId": "2116944866",
                        "name": "Yang Yuan"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "attempted to analyze the training dynamics [42] and build a connection between non-contrastive and contrastive methods [40, 16]."
            ],
            "citingPaper": {
                "paperId": "6f3206263bc7682c3abd6a41672c6444db30b78e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-16789",
                    "ArXiv": "2305.16789",
                    "DOI": "10.48550/arXiv.2305.16789",
                    "CorpusId": 258947377
                },
                "corpusId": 258947377,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6f3206263bc7682c3abd6a41672c6444db30b78e",
                "title": "Modulate Your Spectrum in Self-Supervised Learning",
                "abstract": "Whitening loss provides theoretical guarantee in avoiding feature collapse for self-supervised learning (SSL) using joint embedding architectures. One typical implementation of whitening loss is hard whitening that designs whitening transformation over embedding and imposes the loss on the whitened output. In this paper, we propose spectral transformation (ST) framework to map the spectrum of embedding to a desired distribution during forward pass, and to modulate the spectrum of embedding by implicit gradient update during backward pass. We show that whitening transformation is a special instance of ST by definition, and there exist other instances that can avoid collapse by our empirical investigation. Furthermore, we propose a new instance of ST, called IterNorm with trace loss (INTL). We theoretically prove that INTL can avoid collapse and modulate the spectrum of embedding towards an equal-eigenvalue distribution during the course of optimization. Moreover, INTL achieves 76.6% top-1 accuracy in linear evaluation on ImageNet using ResNet-50, which exceeds the performance of the supervised baseline, and this result is obtained by using a batch size of only 256. Comprehensive experiments show that INTL is a promising SSL method in practice. The code is available at https://github.com/winci-ai/intl.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "39163190",
                        "name": "Xi Weng"
                    },
                    {
                        "authorId": "2072724368",
                        "name": "Yu-Li Ni"
                    },
                    {
                        "authorId": "1491630774",
                        "name": "Tengwei Song"
                    },
                    {
                        "authorId": "144009402",
                        "name": "Jie Luo"
                    },
                    {
                        "authorId": "3288214",
                        "name": "R. Anwer"
                    },
                    {
                        "authorId": "2111181927",
                        "name": "Salman Khan"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "48544864",
                        "name": "Lei Huang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Mean squared error \u2013 Defined as MSE(v, v\u0302) = 1n \u2211n\ni=1(vi \u2212 v\u0302i)2, the mean squared error (MSE) is employed in a number of prominent distillation-based SSL frameworks to measure feature alignment (Grill et al., 2020; Tian et al., 2021b; Caron et al., 2021).",
                "\u2026domains such as medical imaging (Ramesh et al., 2022; Chen et al., 2023a) or other tasks such as classification in the wild (Goyal et al., 2021a; Tian et al., 2021a), object detection (Mishra et al., 2021; Li et al., 2022b), pose estimation (Chen et al., 2023c), action detection as well as\u2026"
            ],
            "citingPaper": {
                "paperId": "6209b614db0065de89331196a1ae8aa59404f0db",
                "externalIds": {
                    "ArXiv": "2305.13689",
                    "DBLP": "journals/corr/abs-2305-13689",
                    "DOI": "10.48550/arXiv.2305.13689",
                    "CorpusId": 258841314
                },
                "corpusId": 258841314,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6209b614db0065de89331196a1ae8aa59404f0db",
                "title": "Know Your Self-supervised Learning: A Survey on Image-based Generative and Discriminative Training",
                "abstract": "Although supervised learning has been highly successful in improving the state-of-the-art in the domain of image-based computer vision in the past, the margin of improvement has diminished significantly in recent years, indicating that a plateau is in sight. Meanwhile, the use of self-supervised learning (SSL) for the purpose of natural language processing (NLP) has seen tremendous successes during the past couple of years, with this new learning paradigm yielding powerful language models. Inspired by the excellent results obtained in the field of NLP, self-supervised methods that rely on clustering, contrastive learning, distillation, and information-maximization, which all fall under the banner of discriminative SSL, have experienced a swift uptake in the area of computer vision. Shortly afterwards, generative SSL frameworks that are mostly based on masked image modeling, complemented and surpassed the results obtained with discriminative SSL. Consequently, within a span of three years, over $100$ unique general-purpose frameworks for generative and discriminative SSL, with a focus on imaging, were proposed. In this survey, we review a plethora of research efforts conducted on image-oriented SSL, providing a historic view and paying attention to best practices as well as useful software packages. While doing so, we discuss pretext tasks for image-based SSL, as well as techniques that are commonly used in image-based SSL. Lastly, to aid researchers who aim at contributing to image-focused SSL, we outline a number of promising research directions.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "51963928",
                        "name": "Utku Ozbulak"
                    },
                    {
                        "authorId": "2218133160",
                        "name": "Hyun Jung Lee"
                    },
                    {
                        "authorId": "2218269957",
                        "name": "Beril Boga"
                    },
                    {
                        "authorId": "3014457",
                        "name": "Esla Timothy Anzaku"
                    },
                    {
                        "authorId": "2124858205",
                        "name": "Ho-min Park"
                    },
                    {
                        "authorId": "2579326",
                        "name": "Arnout Van Messem"
                    },
                    {
                        "authorId": "7627712",
                        "name": "W. D. Neve"
                    },
                    {
                        "authorId": "2794885",
                        "name": "J. Vankerschaver"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [
                "These losses are reminiscent of SSL, where they have been theoretically well-studied (Tian et al., 2021; Balestriero & LeCun, 2022), and their translation to VLP has the potential to solve the challenge of the batch size sensitivity and heavily reduce the computational cost."
            ],
            "citingPaper": {
                "paperId": "f6acf07b93347884699d838c91d6a83a9499e31d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-08675",
                    "ArXiv": "2305.08675",
                    "DOI": "10.48550/arXiv.2305.08675",
                    "CorpusId": 258685688
                },
                "corpusId": 258685688,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f6acf07b93347884699d838c91d6a83a9499e31d",
                "title": "Improved baselines for vision-language pre-training",
                "abstract": "Contrastive learning has emerged as an efficient framework to learn multimodal representations. CLIP, a seminal work in this area, achieved impressive results by training on paired image-text data using the contrastive loss. Recent work claims improvements over CLIP using additional non-contrastive losses inspired from self-supervised learning. However, it is sometimes hard to disentangle the contribution of these additional losses from other implementation details, e.g., data augmentation or regularization techniques, used to train the model. To shed light on this matter, in this paper, we first propose, implement and evaluate several baselines obtained by combining contrastive learning with recent advances in self-supervised learning. In particular, we use the loss functions that were proven successful for visual self-supervised learning to align image and text modalities. We find that these baselines outperform a basic implementation of CLIP. However, when a stronger training recipe is employed, the advantage disappears. Indeed, we find that a simple CLIP baseline can also be improved substantially, up to a 25% relative improvement on downstream zero-shot tasks, by using well-known training techniques that are popular in other subfields. Moreover, we discover that it is enough to apply image and text augmentations to make up for most of the improvement attained by prior works. With our improved training recipe for CLIP, we obtain state-of-the-art performance on four standard datasets, and consistently outperform prior work (up to +4% on the largest dataset), while being substantially simpler.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1399225831",
                        "name": "Enrico Fini"
                    },
                    {
                        "authorId": "28898388",
                        "name": "Pietro Astolfi"
                    },
                    {
                        "authorId": "1456285042",
                        "name": "Adriana Romero-Soriano"
                    },
                    {
                        "authorId": "34602236",
                        "name": "Jakob Verbeek"
                    },
                    {
                        "authorId": "3325894",
                        "name": "M. Drozdzal"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Such self-distillation has been explored theoretically and empirically (Chen & He, 2021; Tian et al., 2021) to prevent the collapsing problem, but we do not discuss the distillation scheme in this paper."
            ],
            "citingPaper": {
                "paperId": "5e0f2264b872288afa8c069cda381379897e13e4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-00729",
                    "ArXiv": "2305.00729",
                    "DOI": "10.48550/arXiv.2305.00729",
                    "CorpusId": 258426737
                },
                "corpusId": 258426737,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/5e0f2264b872288afa8c069cda381379897e13e4",
                "title": "What Do Self-Supervised Vision Transformers Learn?",
                "abstract": "We present a comparative study on how and why contrastive learning (CL) and masked image modeling (MIM) differ in their representations and in their performance of downstream tasks. In particular, we demonstrate that self-supervised Vision Transformers (ViTs) have the following properties: (1) CL trains self-attentions to capture longer-range global patterns than MIM, such as the shape of an object, especially in the later layers of the ViT architecture. This CL property helps ViTs linearly separate images in their representation spaces. However, it also makes the self-attentions collapse into homogeneity for all query tokens and heads. Such homogeneity of self-attention reduces the diversity of representations, worsening scalability and dense prediction performance. (2) CL utilizes the low-frequency signals of the representations, but MIM utilizes high-frequencies. Since low- and high-frequency information respectively represent shapes and textures, CL is more shape-oriented and MIM more texture-oriented. (3) CL plays a crucial role in the later layers, while MIM mainly focuses on the early layers. Upon these analyses, we find that CL and MIM can complement each other and observe that even the simplest harmonization can help leverage the advantages of both methods. The code is available at https://github.com/naver-ai/cl-vs-mim.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "150248298",
                        "name": "Namuk Park"
                    },
                    {
                        "authorId": "2382193",
                        "name": "Wonjae Kim"
                    },
                    {
                        "authorId": "3086596",
                        "name": "Byeongho Heo"
                    },
                    {
                        "authorId": "2110993359",
                        "name": "Taekyung Kim"
                    },
                    {
                        "authorId": "2151587",
                        "name": "Sangdoo Yun"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "The predictor acts as a whitening operator preventing collapse [Tian et al., 2021], and momentum network can be applied only to the projector [Pham et al."
            ],
            "citingPaper": {
                "paperId": "6bfafb32b423c3f0456a10984814f89046def489",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-12210",
                    "ArXiv": "2304.12210",
                    "DOI": "10.48550/arXiv.2304.12210",
                    "CorpusId": 258298825
                },
                "corpusId": 258298825,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6bfafb32b423c3f0456a10984814f89046def489",
                "title": "A Cookbook of Self-Supervised Learning",
                "abstract": "Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbook. We hope to empower the curious researcher to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3201463",
                        "name": "Randall Balestriero"
                    },
                    {
                        "authorId": "3407874",
                        "name": "Mark Ibrahim"
                    },
                    {
                        "authorId": "2162736903",
                        "name": "Vlad Sobal"
                    },
                    {
                        "authorId": "4690624",
                        "name": "Ari S. Morcos"
                    },
                    {
                        "authorId": "144675956",
                        "name": "Shashank Shekhar"
                    },
                    {
                        "authorId": "1962083",
                        "name": "T. Goldstein"
                    },
                    {
                        "authorId": "34651419",
                        "name": "Florian Bordes"
                    },
                    {
                        "authorId": "1453740540",
                        "name": "Adrien Bardes"
                    },
                    {
                        "authorId": "51888120",
                        "name": "Gr\u00e9goire Mialon"
                    },
                    {
                        "authorId": "1932187449",
                        "name": "Yuandong Tian"
                    },
                    {
                        "authorId": "102604362",
                        "name": "Avi Schwarzschild"
                    },
                    {
                        "authorId": "145771261",
                        "name": "A. Wilson"
                    },
                    {
                        "authorId": "8284185",
                        "name": "Jonas Geiping"
                    },
                    {
                        "authorId": "2048163343",
                        "name": "Q. Garrido"
                    },
                    {
                        "authorId": "2147013351",
                        "name": "Pierre Fernandez"
                    },
                    {
                        "authorId": "2063958674",
                        "name": "Amir Bar"
                    },
                    {
                        "authorId": "2367683",
                        "name": "H. Pirsiavash"
                    },
                    {
                        "authorId": "1688882",
                        "name": "Yann LeCun"
                    },
                    {
                        "authorId": "121592562",
                        "name": "Micah Goldblum"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Existing Theory of Contrastive Learning Besides the empirical success, theoretical foundations, which explain the efficiency of the methods in contrastive learning, are gradually gathering attention [23, 56, 65, 61, 59]."
            ],
            "citingPaper": {
                "paperId": "6da9e4639b1a9e098c31e01ed716a0f1cf9aee2d",
                "externalIds": {
                    "ArXiv": "2304.09552",
                    "DBLP": "journals/corr/abs-2304-09552",
                    "DOI": "10.48550/arXiv.2304.09552",
                    "CorpusId": 258212921
                },
                "corpusId": 258212921,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6da9e4639b1a9e098c31e01ed716a0f1cf9aee2d",
                "title": "Denoising Cosine Similarity: A Theory-Driven Approach for Efficient Representation Learning",
                "abstract": "Representation learning has been increasing its impact on the research and practice of machine learning, since it enables to learn representations that can apply to various downstream tasks efficiently. However, recent works pay little attention to the fact that real-world datasets used during the stage of representation learning are commonly contaminated by noise, which can degrade the quality of learned representations. This paper tackles the problem to learn robust representations against noise in a raw dataset. To this end, inspired by recent works on denoising and the success of the cosine-similarity-based objective functions in representation learning, we propose the denoising Cosine-Similarity (dCS) loss. The dCS loss is a modified cosine-similarity loss and incorporates a denoising property, which is supported by both our theoretical and empirical findings. To make the dCS loss implementable, we also construct the estimators of the dCS loss with statistical guarantees. Finally, we empirically show the efficiency of the dCS loss over the baseline objective functions in vision and speech domains.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2185326325",
                        "name": "Takumi Nakagawa"
                    },
                    {
                        "authorId": "52446657",
                        "name": "Y. Sanada"
                    },
                    {
                        "authorId": "2210799453",
                        "name": "Hiroki Waida"
                    },
                    {
                        "authorId": "2145061398",
                        "name": "Yuhui Zhang"
                    },
                    {
                        "authorId": "2057979107",
                        "name": "Yuichiro Wada"
                    },
                    {
                        "authorId": "89647940",
                        "name": "K. Takanashi"
                    },
                    {
                        "authorId": "2185321017",
                        "name": "Tomonori Yamada"
                    },
                    {
                        "authorId": "1897617",
                        "name": "T. Kanamori"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "7316e760e22adc7ed7b65e2c647f4a905883e796",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-08014",
                    "ArXiv": "2304.08014",
                    "DOI": "10.48550/arXiv.2304.08014",
                    "CorpusId": 258179084
                },
                "corpusId": 258179084,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7316e760e22adc7ed7b65e2c647f4a905883e796",
                "title": "Self-Supervised Learning from Non-Object Centric Images with a Geometric Transformation Sensitive Architecture",
                "abstract": "Most invariance-based self-supervised methods rely on single object-centric images (e.g., ImageNet images) for pretraining, learning features that invariant to geometric transformation. However, when images are not object-centric, the semantics of the image can be significantly altered due to cropping. Furthermore, as the model becomes insensitive to geometric transformations, it may struggle to capture location information. For this reason, we propose a Geometric Transformation Sensitive Architecture designed to be sensitive to geometric transformations, specifically focusing on four-fold rotation, random crop, and multi-crop. Our method encourages the student to be sensitive by predicting rotation and using targets that vary with those transformations through pooling and rotating the teacher feature map. Additionally, we use patch correspondence loss to encourage correspondence between patches with similar features. This approach allows us to capture long-term dependencies in a more appropriate way than capturing long-term dependencies by encouraging local-to-global correspondence, which occurs when learning to be insensitive to multi-crop. Our approach demonstrates improved performance when using non-object-centric images as pretraining data compared to other methods that train the model to be insensitive to geometric transformation. We surpass DINO[Caron et al.[2021b]] baseline in tasks including image classification, semantic segmentation, detection, and instance segmentation with improvements of 4.9 $Top-1 Acc$, 3.3 $mIoU$, 3.4 $AP^b$, and 2.7 $AP^m$. Code and pretrained models are publicly available at: https://github.com/bok3948/GTSA",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2153269174",
                        "name": "Taeho Kim"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "\u2026learning [Chen et al. (2020); Grill et al. (2020)] yield new types of learning dynamics that can also be well modelled by deep linear networks [Tian et al. (2020, 2021)], even in settings where the learning dynamics do not correspond to gradient descent on any function [Grill et al. (2020)].",
                "\u2026hyperparameter\nNeural networks: from the perceptron to deep nets 21\nchoices that work well for training deep linear models, also work well for their highly nonlinear counterparts [Tian et al. (2021)], thereby opening the door to the use of mathematical analysis to drive practical design decisions."
            ],
            "citingPaper": {
                "paperId": "d3083d2e751601349b3fd884c79994e6ad1cd548",
                "externalIds": {
                    "ArXiv": "2304.06636",
                    "CorpusId": 258107863
                },
                "corpusId": 258107863,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d3083d2e751601349b3fd884c79994e6ad1cd548",
                "title": "Neural networks: from the perceptron to deep nets",
                "abstract": "Artificial networks have been studied through the prism of statistical mechanics as disordered systems since the 80s, starting from the simple models of Hopfield's associative memory and the single-neuron perceptron classifier. Assuming data is generated by a teacher model, asymptotic generalisation predictions were originally derived using the replica method and the online learning dynamics has been described in the large system limit. In this chapter, we review the key original ideas of this literature along with their heritage in the ongoing quest to understand the efficiency of modern deep learning algorithms. One goal of current and future research is to characterize the bias of the learning algorithms toward well-generalising minima in a complex overparametrized loss landscapes with many solutions perfectly interpolating the training data. Works on perceptrons, two-layer committee machines and kernel-like learning machines shed light on these benefits of overparametrization. Another goal is to understand the advantage of depth while models now commonly feature tens or hundreds of layers. If replica computations apparently fall short in describing general deep neural networks learning, studies of simplified linear or untrained models, as well as the derivation of scaling laws provide the first elements of answers.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2214286516",
                        "name": "Marylou Gabri'e"
                    },
                    {
                        "authorId": "25769960",
                        "name": "S. Ganguli"
                    },
                    {
                        "authorId": "1975555",
                        "name": "C. Lucibello"
                    },
                    {
                        "authorId": "1719010",
                        "name": "R. Zecchina"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "The selfsupervised learned features are typically more transferable to new tasks than features from supervised learning (Ericsson et al., 2021), even for non-contrastive objectives (Tian et al., 2021).",
                ", 2021), even for non-contrastive objectives (Tian et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "5de38e8536d03c2b71871fc138cd2b3377a8b44b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-17896",
                    "ArXiv": "2303.17896",
                    "DOI": "10.48550/arXiv.2303.17896",
                    "CorpusId": 257900818
                },
                "corpusId": 257900818,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5de38e8536d03c2b71871fc138cd2b3377a8b44b",
                "title": "Exploring the Limits of Deep Image Clustering using Pretrained Models",
                "abstract": "We present a general methodology that learns to classify images without labels by leveraging pretrained feature extractors. Our approach involves self-distillation training of clustering heads, based on the fact that nearest neighbors in the pretrained feature space are likely to share the same label. We propose a novel objective to learn associations between images by introducing a variant of pointwise mutual information together with instance weighting. We demonstrate that the proposed objective is able to attenuate the effect of false positive pairs while efficiently exploiting the structure in the pretrained feature space. As a result, we improve the clustering accuracy over $k$-means on $17$ different pretrained models by $6.1$\\% and $12.2$\\% on ImageNet and CIFAR100, respectively. Finally, using self-supervised pretrained vision transformers we push the clustering accuracy on ImageNet to $61.6$\\%. The code will be open-sourced.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1832165240",
                        "name": "Nikolas Adaloglou"
                    },
                    {
                        "authorId": "146729868",
                        "name": "F\u00e9lix D. P. Michels"
                    },
                    {
                        "authorId": "2213417369",
                        "name": "Hamza Kalisch"
                    },
                    {
                        "authorId": "2065390431",
                        "name": "M. Kollmann"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Specifically, inspired by (Chen & He, 2021; Grill et al., 2020; Tian et al., 2021), we question the proposed usage of negative pairs for time series forecasting and the idea of augmenting the data to generate positive pairs, which is empirically investigated in several experiments with different\u2026",
                "Specifically, inspired by (Chen & He, 2021; Grill et al., 2020; Tian et al., 2021), we question the proposed usage of negative pairs for time series forecasting and the idea of augmenting the data to generate positive pairs, which is empirically investigated in several experiments with different contrastive methods."
            ],
            "citingPaper": {
                "paperId": "a071d4a95b4f7f2561c0490d51560bfef7667eac",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-18205",
                    "ArXiv": "2303.18205",
                    "DOI": "10.48550/arXiv.2303.18205",
                    "CorpusId": 257901174
                },
                "corpusId": 257901174,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a071d4a95b4f7f2561c0490d51560bfef7667eac",
                "title": "SimTS: Rethinking Contrastive Representation Learning for Time Series Forecasting",
                "abstract": "Contrastive learning methods have shown an impressive ability to learn meaningful representations for image or time series classification. However, these methods are less effective for time series forecasting, as optimization of instance discrimination is not directly applicable to predicting the future state from the history context. Moreover, the construction of positive and negative pairs in current technologies strongly relies on specific time series characteristics, restricting their generalization across diverse types of time series data. To address these limitations, we propose SimTS, a simple representation learning approach for improving time series forecasting by learning to predict the future from the past in the latent space. SimTS does not rely on negative pairs or specific assumptions about the characteristics of the particular time series. Our extensive experiments on several benchmark time series forecasting datasets show that SimTS achieves competitive performance compared to existing contrastive learning methods. Furthermore, we show the shortcomings of the current contrastive learning framework used for time series forecasting through a detailed ablation study. Overall, our work suggests that SimTS is a promising alternative to other contrastive learning approaches for time series forecasting.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2000933950",
                        "name": "Xiaochen Zheng"
                    },
                    {
                        "authorId": "2118654037",
                        "name": "Xing-Yu Chen"
                    },
                    {
                        "authorId": "1811146394",
                        "name": "Manuel Schurch"
                    },
                    {
                        "authorId": "9628283",
                        "name": "Amina Mollaysa"
                    },
                    {
                        "authorId": "153045787",
                        "name": "A. Allam"
                    },
                    {
                        "authorId": "2318427",
                        "name": "M. Krauthammer"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                ", 2021a;b), loss landscapes and training dynamics (Tian et al., 2020; Wang & Isola, 2020; Chen et al., 2021; Tian et al., 2021; Jing et al., 2021; Wen & Li, 2021; Pokle et al., 2022; Ziyin et al., 2022), assran:2022-ssl-hidden-clusterprior, and kernel and spectral methods (Kiani et al.",
                "\u2026(Tsai et al., 2020; 2021; Tosh et al., 2021a;b), loss landscapes and training dynamics (Tian et al., 2020; Wang & Isola, 2020; Chen et al., 2021; Tian et al., 2021; Jing et al., 2021; Wen & Li, 2021; Pokle et al., 2022; Ziyin et al., 2022; Assran et al., 2022a), and kernel and spectral methods\u2026"
            ],
            "citingPaper": {
                "paperId": "0a16511a5a0952f5530b8434a91cdf9df912f28d",
                "externalIds": {
                    "DBLP": "conf/icml/SimonKLGFA23",
                    "ArXiv": "2303.15438",
                    "DOI": "10.48550/arXiv.2303.15438",
                    "CorpusId": 257767106
                },
                "corpusId": 257767106,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0a16511a5a0952f5530b8434a91cdf9df912f28d",
                "title": "On the stepwise nature of self-supervised learning",
                "abstract": "We present a simple picture of the training process of joint embedding self-supervised learning methods. We find that these methods learn their high-dimensional embeddings one dimension at a time in a sequence of discrete, well-separated steps. We arrive at this conclusion via the study of a linearized model of Barlow Twins applicable to the case in which the trained network is infinitely wide. We solve the training dynamics of this model from small initialization, finding that the model learns the top eigenmodes of a certain contrastive kernel in a stepwise fashion, and obtain a closed-form expression for the final learned representations. Remarkably, we then see the same stepwise learning phenomenon when training deep ResNets using the Barlow Twins, SimCLR, and VICReg losses. Our theory suggests that, just as kernel regression can be thought of as a model of supervised learning, kernel PCA may serve as a useful model of self-supervised learning.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2093422698",
                        "name": "James B. Simon"
                    },
                    {
                        "authorId": "1453608917",
                        "name": "Maksis Knutins"
                    },
                    {
                        "authorId": "12907562",
                        "name": "Liu Ziyin"
                    },
                    {
                        "authorId": "2212857568",
                        "name": "Daniel Geisz"
                    },
                    {
                        "authorId": "2196564612",
                        "name": "Abraham J. Fetterman"
                    },
                    {
                        "authorId": "144803472",
                        "name": "Joshua Albrecht"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "shown in [19] that for contrastive learning, the stop-gradient operation is essential and its removal will lead to representation collapse."
            ],
            "citingPaper": {
                "paperId": "071a157fb8b4c83e023f77ea1259d051251ddaeb",
                "externalIds": {
                    "DBLP": "conf/sac/Malaviya0KL23",
                    "DOI": "10.1145/3555776.3577613",
                    "CorpusId": 259099471
                },
                "corpusId": 259099471,
                "publicationVenue": {
                    "id": "d80d58be-58fc-4181-a397-5ac6fd976a47",
                    "name": "ACM Symposium on Applied Computing",
                    "type": "conference",
                    "alternate_names": [
                        "Sel Area Cryptogr",
                        "Int Conf Sel area Cryptogr",
                        "International Conference on Selected areas in Cryptography",
                        "ACM Symp Appl Comput",
                        "Selected Areas in Cryptography",
                        "Symposium on Applied Computing",
                        "SAC",
                        "Symp Appl Comput"
                    ],
                    "url": "https://www.acm.org/publications",
                    "alternate_urls": [
                        "http://sacworkshop.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/071a157fb8b4c83e023f77ea1259d051251ddaeb",
                "title": "FedFAME: A Data Augmentation Free Framework based on Model Contrastive Learning for Federated Semi-Supervised Learning",
                "abstract": "Federated learning has emerged as a privacy-preserving technique to learn a machine learning model without requiring users to share their data. Our paper focuses on Federated Semi-Supervised Learning (FSSL) setting wherein users do not have domain expertise or incentives to label data on their device, and the server has access to some labeled data that is annotated by experts. The existing work in FSSL require data augmentation for model training. However, data augmentation is not well defined for prevalent domains like text and graphs. Moreover, non independent and identically distributed (non-i.i.d.) data across users is a significant challenge in federated learning. We propose a generalized framework based on model contrastive learning called FedFAME which does not require data augmentation, thus making it easy to adapt to different domains. Our experiments on image and text datasets show the robustness of FedFAME towards non-i.i.d. data. We have validated our approach by varying data imbalance across users and the number of labeled instances on the server.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2086069456",
                        "name": "Shubham Malaviya"
                    },
                    {
                        "authorId": "153744298",
                        "name": "Manish Shukla"
                    },
                    {
                        "authorId": "2219558644",
                        "name": "Pratik Korat"
                    },
                    {
                        "authorId": "3086072",
                        "name": "S. Lodha"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "DirectPred [49] provided a theoretical understanding of this non-contrastive SSL setting."
            ],
            "citingPaper": {
                "paperId": "2251905d7e1dfc37f83519008af91b189c099104",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-11098",
                    "ArXiv": "2303.11098",
                    "DOI": "10.48550/arXiv.2303.11098",
                    "CorpusId": 257632008
                },
                "corpusId": 257632008,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2251905d7e1dfc37f83519008af91b189c099104",
                "title": "A closer look at the training dynamics of knowledge distillation",
                "abstract": "In this paper we revisit the efficacy of knowledge distillation as a function matching and metric learning problem. In doing so we verify three important design decisions, namely the normalisation, soft maximum function, and projection layers as key ingredients. We theoretically show that the projector implicitly encodes information on past examples, enabling relational gradients for the student. We then show that the normalisation of representations is tightly coupled with the training dynamics of this projector, which can have a large impact on the students performance. Finally, we show that a simple soft maximum function can be used to address any significant capacity gap problems. Experimental results on various benchmark datasets demonstrate that using these insights can lead to superior or comparable performance to state-of-the-art knowledge distillation techniques, despite being much more computationally efficient. In particular, we obtain these results across image classification (CIFAR100 and ImageNet), object detection (COCO2017), and on more difficult distillation objectives, such as training data efficient transformers, whereby we attain a 77.2% top-1 accuracy with DeiT-Ti on ImageNet.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1481696639",
                        "name": "Roy Miles"
                    },
                    {
                        "authorId": "1712041",
                        "name": "K. Mikolajczyk"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "f38a91afb62b7b4cc4d73c999ba6f911295d6821",
                "externalIds": {
                    "DOI": "10.1101/2022.03.17.484712",
                    "CorpusId": 247600042
                },
                "corpusId": 247600042,
                "publicationVenue": {
                    "id": "027ffd21-ebb0-4af8-baf5-911124292fd0",
                    "name": "bioRxiv",
                    "type": "journal",
                    "url": "http://biorxiv.org/"
                },
                "url": "https://www.semanticscholar.org/paper/f38a91afb62b7b4cc4d73c999ba6f911295d6821",
                "title": "The combination of Hebbian and predictive plasticity learns invariant object representations in deep sensory networks",
                "abstract": "Discriminating distinct objects and concepts from sensory stimuli is essential for survival. Our brains accomplish this feat by forming disentangled internal representations in deep sensory networks shaped through experience-dependent synaptic plasticity. To elucidate the principles that underlie sensory representation learning, we derive a local plasticity model that shapes latent representations to predict future activity. This Latent Predictive Learning (LPL) rule conceptually extends Bienenstock-Cooper-Munro (BCM) theory by unifying Hebbian plasticity with predictive learning. We show that deep neural networks equipped with LPL develop disentangled object representations without supervision. The same rule accurately captures neuronal selectivity changes observed in the primate inferotemporal cortex in response to altered visual experience. Finally, our model generalizes to spiking neural networks and naturally accounts for several experimentally observed properties of synaptic plasticity, including metaplasticity and spike-timing-dependent plasticity (STDP). We thus provide a plausible normative theory of representation learning in the brain while making concrete testable predictions.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "121265709",
                        "name": "Manu Srinath Halvagal"
                    },
                    {
                        "authorId": "2915923",
                        "name": "F T Zenke"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "UniGrad [31] unifies common contrastive learning methods [17, 5, 7, 32, 15, 45, 2] into the same form."
            ],
            "citingPaper": {
                "paperId": "6025534dd4477f5c0f20f685acddbc519239c30f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-06583",
                    "ArXiv": "2303.06583",
                    "DOI": "10.48550/arXiv.2303.06583",
                    "CorpusId": 257496764
                },
                "corpusId": 257496764,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6025534dd4477f5c0f20f685acddbc519239c30f",
                "title": "Improving Masked Autoencoders by Learning Where to Mask",
                "abstract": "Masked image modeling is a promising self-supervised learning method for visual data. It is typically built upon image patches with random masks, which largely ignores the variation of information density between them. The question is: Is there a better masking strategy than random sampling and how can we learn it? We empirically study this problem and initially find that introducing object-centric priors in mask sampling can significantly improve the learned representations. Inspired by this observation, we present AutoMAE, a fully differentiable framework that uses Gumbel-Softmax to interlink an adversarially-trained mask generator and a mask-guided image modeling process. In this way, our approach can adaptively find patches with higher information density for different images, and further strike a balance between the information gain obtained from image reconstruction and its practical training difficulty. In our experiments, AutoMAE is shown to provide effective pretraining models on standard self-supervised benchmarks and downstream tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2177216370",
                        "name": "Haijia Chen"
                    },
                    {
                        "authorId": "2108270774",
                        "name": "Wendong Zhang"
                    },
                    {
                        "authorId": "3530540",
                        "name": "Yunbo Wang"
                    },
                    {
                        "authorId": "2157189845",
                        "name": "Xiaokang Yang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Tian et al. (2021) study the dynamics of non-contrastive learning, but only focus on the predictor parameters."
            ],
            "citingPaper": {
                "paperId": "0ea5511cc66906b0142d8154d9a891c29ed22341",
                "externalIds": {
                    "ArXiv": "2303.04435",
                    "DBLP": "conf/iclr/0001ZDYL023",
                    "DOI": "10.48550/arXiv.2303.04435",
                    "CorpusId": 257404839
                },
                "corpusId": 257404839,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0ea5511cc66906b0142d8154d9a891c29ed22341",
                "title": "A Message Passing Perspective on Learning Dynamics of Contrastive Learning",
                "abstract": "In recent years, contrastive learning achieves impressive results on self-supervised visual representation learning, but there still lacks a rigorous understanding of its learning dynamics. In this paper, we show that if we cast a contrastive objective equivalently into the feature space, then its learning dynamics admits an interpretable form. Specifically, we show that its gradient descent corresponds to a specific message passing scheme on the corresponding augmentation graph. Based on this perspective, we theoretically characterize how contrastive learning gradually learns discriminative features with the alignment update and the uniformity update. Meanwhile, this perspective also establishes an intriguing connection between contrastive learning and Message Passing Graph Neural Networks (MP-GNNs). This connection not only provides a unified understanding of many techniques independently developed in each community, but also enables us to borrow techniques from MP-GNNs to design new contrastive learning variants, such as graph attention, graph rewiring, jumpy knowledge techniques, etc. We believe that our message passing perspective not only provides a new theoretical understanding of contrastive learning dynamics, but also bridges the two seemingly independent areas together, which could inspire more interleaving studies to benefit from each other. The code is available at https://github.com/PKU-ML/Message-Passing-Contrastive-Learning.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2115568564",
                        "name": "Yifei Wang"
                    },
                    {
                        "authorId": "2145907063",
                        "name": "Qi Zhang"
                    },
                    {
                        "authorId": "2210265408",
                        "name": "Tianqi Du"
                    },
                    {
                        "authorId": "2144511379",
                        "name": "Jiansheng Yang"
                    },
                    {
                        "authorId": "33383055",
                        "name": "Zhouchen Lin"
                    },
                    {
                        "authorId": "2115869684",
                        "name": "Yisen Wang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "40ff56355f530bd72010d482ae4f71260136df2d",
                "externalIds": {
                    "DBLP": "conf/iclr/Zhuo0M023",
                    "ArXiv": "2303.02387",
                    "DOI": "10.48550/arXiv.2303.02387",
                    "CorpusId": 257365623
                },
                "corpusId": 257365623,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/40ff56355f530bd72010d482ae4f71260136df2d",
                "title": "Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism",
                "abstract": "Recently, a variety of methods under the name of non-contrastive learning (like BYOL, SimSiam, SwAV, DINO) show that when equipped with some asymmetric architectural designs, aligning positive pairs alone is sufficient to attain good performance in self-supervised visual learning. Despite some understandings of some specific modules (like the predictor in BYOL), there is yet no unified theoretical understanding of how these seemingly different asymmetric designs can all avoid feature collapse, particularly considering methods that also work without the predictor (like DINO). In this work, we propose a unified theoretical understanding for existing variants of non-contrastive learning. Our theory named Rank Differential Mechanism (RDM) shows that all these asymmetric designs create a consistent rank difference in their dual-branch output features. This rank difference will provably lead to an improvement of effective dimensionality and alleviate either complete or dimensional feature collapse. Different from previous theories, our RDM theory is applicable to different asymmetric designs (with and without the predictor), and thus can serve as a unified understanding of existing non-contrastive learning methods. Besides, our RDM theory also provides practical guidelines for designing many new non-contrastive variants. We show that these variants indeed achieve comparable performance to existing methods on benchmark datasets, and some of them even outperform the baselines. Our code is available at \\url{https://github.com/PKU-ML/Rank-Differential-Mechanism}.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2210797120",
                        "name": "Zhijian Zhuo"
                    },
                    {
                        "authorId": "2115568564",
                        "name": "Yifei Wang"
                    },
                    {
                        "authorId": "1685259",
                        "name": "Jinwen Ma"
                    },
                    {
                        "authorId": "2115869684",
                        "name": "Yisen Wang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Tian et al. (2021) investigate the collapse phenomenon in non-contrastive learning and show in a simplified setting how the stop gradient operation can prevent it."
            ],
            "citingPaper": {
                "paperId": "9bbb322400de0f55082e80c4619f5bc4a45b6d9b",
                "externalIds": {
                    "ArXiv": "2302.12091",
                    "DBLP": "journals/corr/abs-2302-12091",
                    "DOI": "10.48550/arXiv.2302.12091",
                    "CorpusId": 257102779
                },
                "corpusId": 257102779,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/9bbb322400de0f55082e80c4619f5bc4a45b6d9b",
                "title": "Random Teachers are Good Teachers",
                "abstract": "In this work, we investigate the implicit regularization induced by teacher-student learning dynamics in self-distillation. To isolate its effect, we describe a simple experiment where we consider teachers at random initialization instead of trained teachers. Surprisingly, when distilling a student into such a random teacher, we observe that the resulting model and its representations already possess very interesting characteristics; (1) we observe a strong improvement of the distilled student over its teacher in terms of probing accuracy. (2) The learned representations are data-dependent and transferable between different tasks but deteriorate strongly if trained on random inputs. (3) The student checkpoint contains sparse subnetworks, so-called lottery tickets, and lies on the border of linear basins in the supervised loss landscape. These observations have interesting consequences for several important areas in machine learning: (1) Self-distillation can work solely based on the implicit regularization present in the gradient dynamics without relying on any dark knowledge, (2) self-supervised learning can learn features even in the absence of data augmentation and (3) training dynamics during the early phase of supervised training do not necessarily require label information. Finally, we shed light on an intriguing local property of the loss landscape: the process of feature learning is strongly amplified if the student is initialized closely to the teacher. These results raise interesting questions about the nature of the landscape that have remained unexplored so far. Code is available at https://github.com/safelix/dinopl.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2209373491",
                        "name": "Felix Sarnthein"
                    },
                    {
                        "authorId": "2090603709",
                        "name": "Gregor Bachmann"
                    },
                    {
                        "authorId": "2051417741",
                        "name": "Sotiris Anagnostidis"
                    },
                    {
                        "authorId": "143936663",
                        "name": "Thomas Hofmann"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                ", 2022), partly explained by the fact that SSL composes the DN of interest f\u03b8 with a projector DN g\u03b3 appended to it during training and thrown away afterward, (ii) too many per-loss and per-projector hyper-parameters whose impact on the DN\u2019s performances are hard to control or predict (Grill et al., 2020; Tian et al., 2021; He & Ozay, 2022), and which are even widely inconsistent across datasets and architectures Zhai et al.",
                "\u2026(ii) too many per-loss and per-projector hyper-parameters whose impact on the DN\u2019s performances are hard to control or predict (Grill et al., 2020; Tian et al., 2021; He & Ozay, 2022), and which are even widely inconsistent across datasets and architectures Zhai et al. (2019); Cosentino et\u2026"
            ],
            "citingPaper": {
                "paperId": "2cc13ffd2574a2ee9473a5ea33fe83300960fdc4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-10260",
                    "ArXiv": "2302.10260",
                    "DOI": "10.48550/arXiv.2302.10260",
                    "CorpusId": 257050859
                },
                "corpusId": 257050859,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2cc13ffd2574a2ee9473a5ea33fe83300960fdc4",
                "title": "Unsupervised Learning on a DIET: Datum IndEx as Target Free of Self-Supervision, Reconstruction, Projector Head",
                "abstract": "Costly, noisy, and over-specialized, labels are to be set aside in favor of unsupervised learning if we hope to learn cheap, reliable, and transferable models. To that end, spectral embedding, self-supervised learning, or generative modeling have offered competitive solutions. Those methods however come with numerous challenges \\textit{e.g.} estimating geodesic distances, specifying projector architectures and anti-collapse losses, or specifying decoder architectures and reconstruction losses. In contrast, we introduce a simple explainable alternative -- coined \\textbf{DIET} -- to learn representations from unlabeled data, free of those challenges. \\textbf{DIET} is blatantly simple: take one's favorite classification setup and use the \\textbf{D}atum \\textbf{I}nd\\textbf{E}x as its \\textbf{T}arget class, \\textit{i.e. each sample is its own class}, no further changes needed. \\textbf{DIET} works without a decoder/projector network, is not based on positive pairs nor reconstruction, introduces no hyper-parameters, and works out-of-the-box across datasets and architectures. Despite \\textbf{DIET}'s simplicity, the learned representations are of high-quality and often on-par with the state-of-the-art \\textit{e.g.} using a linear classifier on top of DIET's learned representation reaches $71.4\\%$ on CIFAR100 with a Resnet101, $52.5\\%$ on TinyImagenet with a Resnext50.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3201463",
                        "name": "Randall Balestriero"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "The linear representation setting has been widely adapted in the machine learning literature (Jing et al., 2021; Tian et al., 2021; Ji et al., 2021; Wu et al., 2022; Tian, 2022)."
            ],
            "citingPaper": {
                "paperId": "48473dde054d100dff272438629e4e8fdf770a8a",
                "externalIds": {
                    "DBLP": "conf/aistats/NakadaGDJ0Z23",
                    "ArXiv": "2302.06232",
                    "DOI": "10.48550/arXiv.2302.06232",
                    "CorpusId": 256827718
                },
                "corpusId": 256827718,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/48473dde054d100dff272438629e4e8fdf770a8a",
                "title": "Understanding Multimodal Contrastive Learning and Incorporating Unpaired Data",
                "abstract": "Language-supervised vision models have recently attracted great attention in computer vision. A common approach to build such models is to use contrastive learning on paired data across the two modalities, as exemplified by Contrastive Language-Image Pre-Training (CLIP). In this paper, under linear representation settings, (i) we initiate the investigation of a general class of nonlinear loss functions for multimodal contrastive learning (MMCL) including CLIP loss and show its connection to singular value decomposition (SVD). Namely, we show that each step of loss minimization by gradient descent can be seen as performing SVD on a contrastive cross-covariance matrix. Based on this insight, (ii) we analyze the performance of MMCL. We quantitatively show that the feature learning ability of MMCL can be better than that of unimodal contrastive learning applied to each modality even under the presence of wrongly matched pairs. This characterizes the robustness of MMCL to noisy data. Furthermore, when we have access to additional unpaired data, (iii) we propose a new MMCL loss that incorporates additional unpaired datasets. We show that the algorithm can detect the ground-truth pairs and improve performance by fully exploiting unpaired datasets. The performance of the proposed algorithm was verified by numerical experiments.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "150280620",
                        "name": "Ryumei Nakada"
                    },
                    {
                        "authorId": "2050160081",
                        "name": "Halil Ibrahim Gulluk"
                    },
                    {
                        "authorId": "10394991",
                        "name": "Zhun Deng"
                    },
                    {
                        "authorId": "2150078690",
                        "name": "Wenlong Ji"
                    },
                    {
                        "authorId": "145085305",
                        "name": "James Y. Zou"
                    },
                    {
                        "authorId": "10537441",
                        "name": "Linjun Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "This reflects the decorrelation of features seen above and was suggested in prior work, either using eigendecomposition (Tian et al., 2021) or Cholesky factorization towards optimal whitening (Ermolov et al., 2021).",
                "Despite the simplicity of the BYOL objective (1), prior work on BYOL theory has involved non-trivial matrix ordinary differential equation analysis under strong assumptions (Tian et al., 2021).",
                ", 2020), or also relied on strong assumptions such as isotropy and multiplicative EMA (Tian et al., 2021) and on differential equation tools for their conclusions.",
                ", 2020) ( Z> \u03b8 Z\u03b8 )\u22121 Z> \u03b8 Z \u2032 \u03be DirectPred (Tian et al., 2021) (Z> \u03b8 Z\u03b8) 1/2 (eigendecomp.",
                "Yet, several works started unveiling the underlying mechanisms behind self-predictive unsupervised learning (Tian et al., 2021; Liu et al., 2022; Halvagal et al., 2022) (see Sec.",
                "This reflects the decorrelation of features seen above and was suggested in prior work, either using eigendecomposition (Tian et al., 2021) or Cholesky factorization towards optimal whitening (Ermolov et al.",
                "This subsumes prior work (Tian et al., 2021; Liu et al., 2022; Halvagal et al., 2022) and enables a more general view informed by optimization on Riemannian manifolds of orthogonal matrices (Edelman et al., 1998; Absil et al., 2007; Bonnabel, 2013).",
                "This fact can be leveraged thanks to the balancing relationship (Tian et al., 2021), valid in the presence of a small weight decay parameter \u03bb:\nA\u03b8,tA > \u03b8,t = P > \u03b8,tP\u03b8,t +M0e \u22122\u03bbt (7)\nwhere A\u03b8,t and P\u03b8,t are now indexed by time t, and M0 is a constant matrix determined at initialization.",
                "This fact can be leveraged thanks to the balancing relationship (Tian et al., 2021), valid in the presence of a small weight decay parameter \u03bb: A\u03b8,tA > \u03b8,t = P > \u03b8,tP\u03b8,t +M0e \u22122\u03bbt (7)",
                "This subsumes prior work (Tian et al., 2021; Liu et al., 2022; Halvagal et al., 2022) and enables a more general view informed by optimization on Riemannian manifolds of orthogonal matrices (Edelman et al.",
                "\u2026at such explanation have involved implicit contrastive properties of normalizations later disproved empirically (Richemond et al., 2020), or also relied on strong assumptions such as isotropy and multiplicative EMA (Tian et al., 2021) and on differential equation tools for their conclusions."
            ],
            "citingPaper": {
                "paperId": "f977308becc05d30cdea92b46f411c0ff89ebd15",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-04817",
                    "ArXiv": "2302.04817",
                    "DOI": "10.48550/arXiv.2302.04817",
                    "CorpusId": 256697279
                },
                "corpusId": 256697279,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/f977308becc05d30cdea92b46f411c0ff89ebd15",
                "title": "The Edge of Orthogonality: A Simple View of What Makes BYOL Tick",
                "abstract": "Self-predictive unsupervised learning methods such as BYOL or SimSiam have shown impressive results, and counter-intuitively, do not collapse to trivial representations. In this work, we aim at exploring the simplest possible mathematical arguments towards explaining the underlying mechanisms behind self-predictive unsupervised learning. We start with the observation that those methods crucially rely on the presence of a predictor network (and stop-gradient). With simple linear algebra, we show that when using a linear predictor, the optimal predictor is close to an orthogonal projection, and propose a general framework based on orthonormalization that enables to interpret and give intuition on why BYOL works. In addition, this framework demonstrates the crucial role of the exponential moving average and stop-gradient operator in BYOL as an efficient orthonormalization mechanism. We use these insights to propose four new \\emph{closed-form predictor} variants of BYOL to support our analysis. Our closed-form predictors outperform standard linear trainable predictor BYOL at $100$ and $300$ epochs (top-$1$ linear accuracy on ImageNet).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "16326904",
                        "name": "Pierre H. Richemond"
                    },
                    {
                        "authorId": "2143234885",
                        "name": "Allison C. Tam"
                    },
                    {
                        "authorId": "11501567",
                        "name": "Yunhao Tang"
                    },
                    {
                        "authorId": "3367628",
                        "name": "Florian Strub"
                    },
                    {
                        "authorId": "1808897",
                        "name": "Bilal Piot"
                    },
                    {
                        "authorId": "145783676",
                        "name": "Felix Hill"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "8ebc684a24d373a3c52435688019ae81c8197286",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-01735",
                    "ArXiv": "2302.01735",
                    "DOI": "10.48550/arXiv.2302.01735",
                    "CorpusId": 256598085
                },
                "corpusId": 256598085,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8ebc684a24d373a3c52435688019ae81c8197286",
                "title": "Rethinking Semi-Supervised Medical Image Segmentation: A Variance-Reduction Perspective",
                "abstract": "For medical image segmentation, contrastive learning is the dominant practice to improve the quality of visual representations by contrasting semantically similar and dissimilar pairs of samples. This is enabled by the observation that without accessing ground truth labels, negative examples with truly dissimilar anatomical features, if sampled, can significantly improve the performance. In reality, however, these samples may come from similar anatomical regions and the models may struggle to distinguish the minority tail-class samples, making the tail classes more prone to misclassification, both of which typically lead to model collapse. In this paper, we propose ARCO, a semi-supervised contrastive learning (CL) framework with stratified group theory for medical image segmentation. In particular, we first propose building ARCO through the concept of variance-reduced estimation and show that certain variance-reduction techniques are particularly beneficial in pixel/voxel-level segmentation tasks with extremely limited labels. Furthermore, we theoretically prove these sampling techniques are universal in variance reduction. Finally, we experimentally validate our approaches on eight benchmarks, i.e., five 2D/3D medical and three semantic segmentation datasets, with different label settings, and our methods consistently outperform state-of-the-art semi-supervised methods. Additionally, we augment the CL frameworks with these sampling techniques and demonstrate significant gains over previous methods. We believe our work is an important step towards semi-supervised medical image segmentation by quantifying the limitation of current self-supervision objectives for accomplishing such challenging safety-critical tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "7694093",
                        "name": "Chenyu You"
                    },
                    {
                        "authorId": "2054962899",
                        "name": "Weicheng Dai"
                    },
                    {
                        "authorId": "51270420",
                        "name": "Yifei Min"
                    },
                    {
                        "authorId": "1927674",
                        "name": "Fenglin Liu"
                    },
                    {
                        "authorId": "1635440219",
                        "name": "Xiaoran Zhang"
                    },
                    {
                        "authorId": null,
                        "name": "Chen Feng"
                    },
                    {
                        "authorId": "31799453",
                        "name": "D. Clifton"
                    },
                    {
                        "authorId": "2107323185",
                        "name": "S. K. Zhou"
                    },
                    {
                        "authorId": "1700330",
                        "name": "L. Staib"
                    },
                    {
                        "authorId": "2140555772",
                        "name": "J. Duncan"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "And it is shown that self-supervised learning can even be performed without contrastive pairs (Grill et al., 2020; Chen & He, 2021; Tian et al., 2021) by establishing a dual pair of Siamese networks to facilitate the training.",
                "Recent Siamese network based self-supervised learning methods (Grill et al., 2020; Chen & He, 2021; Tian et al., 2021; He et al., 2020; Chen et al., 2021) alleviate the huge batch challenge by deploying an momentum copy of the target model to facilitate the training and prevent trivial solutions.",
                "Recent contrastive self-supervised learning methods (Grill et al., 2020; Chen & He, 2021; Tian et al., 2021; He et al., 2020; Chen et al., 2021) alleviate the huge batch challenge at the cost of deploying an momentum copy of the target model to facilitate the training and prevent trivial solutions."
            ],
            "citingPaper": {
                "paperId": "07ba6023e5aed51a68dd178a46e79e74ee009e1a",
                "externalIds": {
                    "DBLP": "conf/iclr/WangW0Q23",
                    "ArXiv": "2302.01384",
                    "DOI": "10.48550/arXiv.2302.01384",
                    "CorpusId": 251732759
                },
                "corpusId": 251732759,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/07ba6023e5aed51a68dd178a46e79e74ee009e1a",
                "title": "Energy-Inspired Self-Supervised Pretraining for Vision Models",
                "abstract": "Motivated by the fact that forward and backward passes of a deep network naturally form symmetric mappings between input and output representations, we introduce a simple yet effective self-supervised vision model pretraining framework inspired by energy-based models (EBMs). In the proposed framework, we model energy estimation and data restoration as the forward and backward passes of a single network without any auxiliary components, e.g., an extra decoder. For the forward pass, we fit a network to an energy function that assigns low energy scores to samples that belong to an unlabeled dataset, and high energy otherwise. For the backward pass, we restore data from corrupted versions iteratively using gradient-based optimization along the direction of energy minimization. In this way, we naturally fold the encoder-decoder architecture widely used in masked image modeling into the forward and backward passes of a single vision model. Thus, our framework now accepts a wide range of pretext tasks with different data corruption methods, and permits models to be pretrained from masked image modeling, patch sorting, and image restoration, including super-resolution, denoising, and colorization. We support our findings with extensive experiments, and show the proposed method delivers comparable and even better performance with remarkably fewer epochs of training compared to the state-of-the-art self-supervised vision model pretraining methods. Our findings shed light on further exploring self-supervised vision model pretraining and pretext tasks beyond masked image modeling.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108725378",
                        "name": "Ze Wang"
                    },
                    {
                        "authorId": "2141735343",
                        "name": "Jiang Wang"
                    },
                    {
                        "authorId": "2145253136",
                        "name": "Zicheng Liu"
                    },
                    {
                        "authorId": "2077648",
                        "name": "Qiang Qiu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Many efforts have been devoted to studying the loss function, and the construction of positive pairs [6, 7, 8, 9, 10, 11], while less are paid on the investigation of the architectures."
            ],
            "citingPaper": {
                "paperId": "602fbd92feb3dc90d670f9823215679f5524c238",
                "externalIds": {
                    "ArXiv": "2301.12189",
                    "DBLP": "journals/corr/abs-2301-12189",
                    "DOI": "10.48550/arXiv.2301.12189",
                    "CorpusId": 256389983
                },
                "corpusId": 256389983,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/602fbd92feb3dc90d670f9823215679f5524c238",
                "title": "Deciphering the Projection Head: Representation Evaluation Self-supervised Learning",
                "abstract": "Self-supervised learning (SSL) aims to learn intrinsic features without labels. Despite the diverse architectures of SSL methods, the projection head always plays an important role in improving the performance of the downstream task. In this work, we systematically investigate the role of the projection head in SSL. Specifically, the projection head targets the uniformity part of SSL, which pushes the dissimilar samples away from each other, thus enabling the encoder to focus on extracting semantic features. Based on this understanding, we propose a Representation Evaluation Design (RED) in SSL models in which a shortcut connection between the representation and the projection vectors is built. Extensive experiments with different architectures, including SimCLR, MoCo-V2, and SimSiam, on various datasets, demonstrate that the representation evaluation design can consistently improve the baseline models in the downstream tasks. The learned representation from the RED-SSL models shows superior robustness to unseen augmentations and out-of-distribution data.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1785376504",
                        "name": "Jiajun Ma"
                    },
                    {
                        "authorId": "2112911801",
                        "name": "Tianyang Hu"
                    },
                    {
                        "authorId": "2155567647",
                        "name": "Wenjia Wang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "ee57e4d7a125f4ca8916284a857c3760d7d378d3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2301-08243",
                    "ArXiv": "2301.08243",
                    "DOI": "10.1109/CVPR52729.2023.01499",
                    "CorpusId": 255999752
                },
                "corpusId": 255999752,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ee57e4d7a125f4ca8916284a857c3760d7d378d3",
                "title": "Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture",
                "abstract": "This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample target blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. Empirically, when combined with Vision Transformers, we find I-JEPA to be highly scalable. For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting and depth prediction.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "38698856",
                        "name": "Mahmoud Assran"
                    },
                    {
                        "authorId": "2101830371",
                        "name": "Quentin Duval"
                    },
                    {
                        "authorId": "1806773",
                        "name": "Ishan Misra"
                    },
                    {
                        "authorId": "2329288",
                        "name": "Piotr Bojanowski"
                    },
                    {
                        "authorId": "2065988715",
                        "name": "Pascal Vincent"
                    },
                    {
                        "authorId": "2066127975",
                        "name": "Michael G. Rabbat"
                    },
                    {
                        "authorId": "1688882",
                        "name": "Yann LeCun"
                    },
                    {
                        "authorId": "2482072",
                        "name": "Nicolas Ballas"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "SimSiam [67] do not collapse [271] have been conducted, but the fundamental reason remains elusive."
            ],
            "citingPaper": {
                "paperId": "0b2134e5ae6f62d66686d5ca9bbbaadc1ddce61e",
                "externalIds": {
                    "ArXiv": "2301.05712",
                    "CorpusId": 261046875
                },
                "corpusId": 261046875,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0b2134e5ae6f62d66686d5ca9bbbaadc1ddce61e",
                "title": "A Survey on Self-supervised Learning: Algorithms, Applications, and Future Trends",
                "abstract": "Deep supervised learning algorithms typically require a large volume of labeled data to achieve satisfactory performance. However, the process of collecting and labeling such data can be expensive and time-consuming. Self-supervised learning (SSL), a subset of unsupervised learning, aims to learn discriminative features from unlabeled data without relying on human-annotated labels. SSL has garnered significant attention recently, leading to the development of numerous related algorithms. However, there is a dearth of comprehensive studies that elucidate the connections and evolution of different SSL variants. This paper presents a review of diverse SSL methods, encompassing algorithmic aspects, application domains, three key trends, and open research questions. Firstly, we provide a detailed introduction to the motivations behind most SSL algorithms and compare their commonalities and differences. Secondly, we explore representative applications of SSL in domains such as image processing, computer vision, and natural language processing. Lastly, we discuss the three primary trends observed in SSL research and highlight the open questions that remain. A curated collection of valuable resources can be accessed at https://github.com/guijiejie/SSL.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2190897431",
                        "name": "Jie Gui"
                    },
                    {
                        "authorId": "2201605955",
                        "name": "Tuo Chen"
                    },
                    {
                        "authorId": null,
                        "name": "Jing Zhang"
                    },
                    {
                        "authorId": "2176189708",
                        "name": "Qiong Cao"
                    },
                    {
                        "authorId": "2165889987",
                        "name": "Zhe Sun"
                    },
                    {
                        "authorId": "2220799935",
                        "name": "Haoran Luo"
                    },
                    {
                        "authorId": "2186146273",
                        "name": "Dacheng Tao"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "BYOL [18] and SimSiam [19] extend similarity loss and remove the dependency on negative instances [20], [21], [22]."
            ],
            "citingPaper": {
                "paperId": "853b326f9696c7e2948f18159162b22ba6d4ccf9",
                "externalIds": {
                    "ArXiv": "2301.03041",
                    "DBLP": "journals/corr/abs-2301-03041",
                    "DOI": "10.1109/TIP.2023.3276708",
                    "CorpusId": 255545826,
                    "PubMed": "37227917"
                },
                "corpusId": 255545826,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/853b326f9696c7e2948f18159162b22ba6d4ccf9",
                "title": "Learning the Relation Between Similarity Loss and Clustering Loss in Self-Supervised Learning",
                "abstract": "Self-supervised learning enables networks to learn discriminative features from massive data itself. Most state-of-the-art methods maximize the similarity between two augmentations of one image based on contrastive learning. By utilizing the consistency of two augmentations, the burden of manual annotations can be freed. Contrastive learning exploits instance-level information to learn robust features. However, the learned information is probably confined to different views of the same instance. In this paper, we attempt to leverage the similarity between two distinct images to boost representation in self-supervised learning. In contrast to instance-level information, the similarity between two distinct images may provide more useful information. Besides, we analyze the relation between similarity loss and feature-level cross-entropy loss. These two losses are essential for most deep learning methods. However, the relation between these two losses is not clear. Similarity loss helps obtain instance-level representation, while feature-level cross-entropy loss helps mine the similarity between two distinct images. We provide theoretical analyses and experiments to show that a suitable combination of these two losses can get state-of-the-art results. Code is available at https://github.com/guijiejie/ICCL.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2669512",
                        "name": "Jidong Ge"
                    },
                    {
                        "authorId": "2144425874",
                        "name": "YuXiang Liu"
                    },
                    {
                        "authorId": "2190897431",
                        "name": "Jie Gui"
                    },
                    {
                        "authorId": "17288955",
                        "name": "Lanting Fang"
                    },
                    {
                        "authorId": "2115912472",
                        "name": "Ming Lin"
                    },
                    {
                        "authorId": "145193332",
                        "name": "J. Kwok"
                    },
                    {
                        "authorId": "2199803951",
                        "name": "Liguo Huang"
                    },
                    {
                        "authorId": "152196691",
                        "name": "B. Luo"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [
                "Several works have theoretically analysed self-supervised approaches, both for contrastive [48], [49], [50], [51], [52] and non-contrastive methods [53], [54], [55], [56], to motivate the reasons for their successes, identify the main underlying principles and subsequently provide more principled/simplified solutions.",
                "In this regard, asymmetries, in the form of stop-gradient and diversified predictors, are sufficient to ensure well-behaved training dynamics [53], [55], [56]."
            ],
            "citingPaper": {
                "paperId": "1c76cf4575f137657b7471addbb27376f82341f3",
                "externalIds": {
                    "ArXiv": "2212.13425",
                    "DBLP": "journals/corr/abs-2212-13425",
                    "DOI": "10.48550/arXiv.2212.13425",
                    "CorpusId": 255186030
                },
                "corpusId": 255186030,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1c76cf4575f137657b7471addbb27376f82341f3",
                "title": "GEDI: GEnerative and DIscriminative Training for Self-Supervised Learning",
                "abstract": "Self-supervised learning is a popular and powerful method for utilizing large amounts of unlabeled data, for which a wide variety of training objectives have been proposed in the literature. In this study, we perform a Bayesian analysis of state-of-the-art self-supervised learning objectives and propose a unified formulation based on likelihood learning. Our analysis suggests a simple method for integrating self-supervised learning with generative models, allowing for the joint training of these two seemingly distinct approaches. We refer to this combined framework as GEDI, which stands for GEnerative and DIscriminative training. Additionally, we demonstrate an instantiation of the GEDI framework by integrating an energy-based model with a cluster-based self-supervised learning model. Through experiments on synthetic and real-world data, including SVHN, CIFAR10, and CIFAR100, we show that GEDI outperforms existing self-supervised learning strategies in terms of clustering performance by a wide margin. We also demonstrate that GEDI can be integrated into a neural-symbolic framework to address tasks in the small data regime, where it can use logical constraints to further improve clustering and classification performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "34592724",
                        "name": "Emanuele Sansone"
                    },
                    {
                        "authorId": "46185682",
                        "name": "Robin Manhaeve"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "In[34], it is mentioned that the potential representation of nodes can be better learned by not using negative samples when performing contrasting learning."
            ],
            "citingPaper": {
                "paperId": "20c1bbc3df38a3ecde7a5ef68c2176cbf043c961",
                "externalIds": {
                    "DOI": "10.1145/3579654.3579771",
                    "CorpusId": 251921382
                },
                "corpusId": 251921382,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/20c1bbc3df38a3ecde7a5ef68c2176cbf043c961",
                "title": "Dynamic Graph Representation Based on Temporal and Contextual Contrasting",
                "abstract": "Dynamic graph representation learning is critical for graph-based downstream tasks such as link prediction, node classification, and graph reconstruction. Many graph-neural-network-based methods have emerged recently, but most are incapable of tracing graph evolution patterns over time. To solve this problem, we propose a continuous-time dynamic graph framework: dynamic graph temporal contextual contrasting (DGTCC) model, which integrates temporal and topology information to capture the latent evolution trend of graph representation. In this model, the node representation is first generated by a self-attention\u2013based temporal encoder, which measures the importance weights of neighbor nodes in temporal sub-graphs and stores them in the contextual memory module. After sampling the node representation from the memory module, the model maximizes the mutual information of the same node that occurred in two nearby temporal views by the contrastive learning mechanism, which helps track the evolutional trend of nodes. In inductive learning settings, the results on four real datasets demonstrate the advantages of the proposed DGTCC model.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2111463049",
                        "name": "Wen-Yuan Zhu"
                    },
                    {
                        "authorId": "2181799689",
                        "name": "Ke Ruan"
                    },
                    {
                        "authorId": "2143649429",
                        "name": "Jin Huang"
                    },
                    {
                        "authorId": "2181929662",
                        "name": "Jing Xiao"
                    },
                    {
                        "authorId": "2118684364",
                        "name": "Weihao Yu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "There are some efforts to theoretically understand the SSL methods [30, 14], the role of data augmentation [28, 26], and some empirical analyses of the contrastive loss [4] and the predictor in the so-called BYOL framework [25]."
            ],
            "citingPaper": {
                "paperId": "4508280a2aaea2d27444fe15e57766ea09d75383",
                "externalIds": {
                    "ArXiv": "2212.11491",
                    "DBLP": "journals/corr/abs-2212-11491",
                    "DOI": "10.48550/arXiv.2212.11491",
                    "CorpusId": 254974097
                },
                "corpusId": 254974097,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4508280a2aaea2d27444fe15e57766ea09d75383",
                "title": "Understanding and Improving the Role of Projection Head in Self-Supervised Learning",
                "abstract": "Self-supervised learning (SSL) aims to produce useful feature representations without access to any human-labeled data annotations. Due to the success of recent SSL methods based on contrastive learning, such as SimCLR, this problem has gained popularity. Most current contrastive learning approaches append a parametrized projection head to the end of some backbone network to optimize the InfoNCE objective and then discard the learned projection head after training. This raises a fundamental question: Why is a learnable projection head required if we are to discard it after training? In this work, we first perform a systematic study on the behavior of SSL training focusing on the role of the projection head layers. By formulating the projection head as a parametric component for the InfoNCE objective rather than a part of the network, we present an alternative optimization scheme for training contrastive learning based SSL frameworks. Our experimental study on multiple image classification datasets demonstrates the effectiveness of the proposed approach over alternatives in the SSL literature.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1491124544",
                        "name": "Kartik Gupta"
                    },
                    {
                        "authorId": "144722114",
                        "name": "Thalaiyasingam Ajanthan"
                    },
                    {
                        "authorId": "5546141",
                        "name": "A. Hengel"
                    },
                    {
                        "authorId": "145273587",
                        "name": "Stephen Gould"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "result"
            ],
            "contexts": [
                "SPIRAL proposed in-utterance contrastive loss& position randomization to avoid model collapse& positional collapse that arise on its own specific SG teacher design but not on the nonlinear learning dynamics of non-contrastive SSL[25].",
                "Hence the fundamental question arises: how do multiple factors, like stop-gradients, EMA, teacher networks, and regularization, all come into play to avoid collapse? This leads to experimental studies like our TriNet and theoretical studies like [25, 26]."
            ],
            "citingPaper": {
                "paperId": "b1c52b79ff3be15cc94119919a5b0f110108d3d4",
                "externalIds": {
                    "ArXiv": "2301.00656",
                    "DBLP": "journals/corr/abs-2301-00656",
                    "DOI": "10.48550/arXiv.2301.00656",
                    "CorpusId": 255372565
                },
                "corpusId": 255372565,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/b1c52b79ff3be15cc94119919a5b0f110108d3d4",
                "title": "TriNet: stabilizing self-supervised learning from complete or slow collapse",
                "abstract": "Self-supervised learning (SSL) models confront challenges of abrupt informational collapse or slow dimensional collapse. We propose TriNet, which introduces a novel triple-branch architecture for preventing collapse and stabilizing the pre-training. TriNet learns the SSL latent embedding space and incorporates it to a higher level space for predicting pseudo target vectors generated by a frozen teacher. Our experimental results show that the proposed method notably stabilizes and accelerates pre-training and achieves a relative word error rate reduction (WERR) of 6.06% compared to the state-of-the-art (SOTA) Data2vec for a downstream benchmark ASR task. We will release our code at https://github.com/tencent-ailab/.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2119909522",
                        "name": "Lixin Cao"
                    },
                    {
                        "authorId": "66063792",
                        "name": "J. Wang"
                    },
                    {
                        "authorId": "2199171011",
                        "name": "Ben Yang"
                    },
                    {
                        "authorId": "144610227",
                        "name": "Dan Su"
                    },
                    {
                        "authorId": "114483585",
                        "name": "Dong Yu"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Building on DirectPred [1], we presented a simple analysis formulated in the eigenspace of representations that illustrates how BYOL/SimSiam\u2019s asymmetric similarity loss avoids representational collapse.",
                "[1] underscored the importance of boosting small eigenvalues and suggested that evolving the weights in the target network using EMA serves as an automatic curriculum for small eigenvalues.",
                "Here, by building on DirectPred [1], we lay out a theoretical framework that reconciles these two views.",
                "[1] for the case of linear feedforward and predictor networks.",
                "Finally, instead of gradient-based optimization, we directly set the predictor network as a simple function of this correlation matrix as suggested in DirectPred [1].",
                "In this work, we consider the linear network setting used previously for studying non-contrastive SSL in [1, 8], and provide a straightforward analysis of how the learning dynamics in DirectPred and DirectCopy prevent representational collapse.",
                "The learning dynamics induced by such asymmetric loss Siamese architectures are surprisingly intricate [1, 8, 9] but not fully understood."
            ],
            "citingPaper": {
                "paperId": "422002b84a0bed310e01d12352147912d35979e8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-04858",
                    "ArXiv": "2212.04858",
                    "DOI": "10.48550/arXiv.2212.04858",
                    "CorpusId": 254535793
                },
                "corpusId": 254535793,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/422002b84a0bed310e01d12352147912d35979e8",
                "title": "Predictor networks and stop-grads provide implicit variance regularization in BYOL/SimSiam",
                "abstract": "Self-supervised learning (SSL) learns useful representations from unlabelled data by training networks to be invariant to pairs of augmented versions of the same input. Non-contrastive methods avoid collapse either by directly regularizing the covariance matrix of network outputs or through asymmetric loss architectures, two seemingly unrelated approaches. Here, by building on DirectPred, we lay out a theoretical framework that reconciles these two views. We derive analytical expressions for the representational learning dynamics in linear networks. By expressing them in the eigenspace of the embedding covariance matrix, where the solutions decouple, we reveal the mechanism and conditions that provide implicit variance regularization. These insights allow us to formulate a new isotropic loss function that equalizes eigenvalue contribution and renders learning more robust. Finally, we show empirically that our findings translate to nonlinear networks trained on CIFAR-10 and STL-10.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "121265709",
                        "name": "Manu Srinath Halvagal"
                    },
                    {
                        "authorId": "1557381641",
                        "name": "Axel Laborieux"
                    },
                    {
                        "authorId": "39979946",
                        "name": "Friedemann Zenke"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "391e3b63c5f265c98b875bb47ae7135fc70fab9e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-03319",
                    "ArXiv": "2212.03319",
                    "DOI": "10.48550/arXiv.2212.03319",
                    "CorpusId": 254366720
                },
                "corpusId": 254366720,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/391e3b63c5f265c98b875bb47ae7135fc70fab9e",
                "title": "Understanding Self-Predictive Learning for Reinforcement Learning",
                "abstract": "We study the learning dynamics of self-predictive learning for reinforcement learning, a family of algorithms that learn representations by minimizing the prediction error of their own future latent representations. Despite its recent empirical success, such algorithms have an apparent defect: trivial representations (such as constants) minimize the prediction error, yet it is obviously undesirable to converge to such solutions. Our central insight is that careful designs of the optimization dynamics are critical to learning meaningful representations. We identify that a faster paced optimization of the predictor and semi-gradient updates on the representation, are crucial to preventing the representation collapse. Then in an idealized setup, we show self-predictive learning dynamics carries out spectral decomposition on the state transition matrix, effectively capturing information of the transition dynamics. Building on the theoretical insights, we propose bidirectional self-predictive learning, a novel self-predictive algorithm that learns two representations simultaneously. We examine the robustness of our theoretical insights with a number of small-scale experiments and showcase the promise of the novel representation learning algorithm with large-scale experiments.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "11501567",
                        "name": "Yunhao Tang"
                    },
                    {
                        "authorId": "3407143",
                        "name": "Z. Guo"
                    },
                    {
                        "authorId": "16326904",
                        "name": "Pierre H. Richemond"
                    },
                    {
                        "authorId": "3429927",
                        "name": "B. '. Pires"
                    },
                    {
                        "authorId": "2232505",
                        "name": "Yash Chandak"
                    },
                    {
                        "authorId": "1708654",
                        "name": "R. Munos"
                    },
                    {
                        "authorId": "144845456",
                        "name": "Mark Rowland"
                    },
                    {
                        "authorId": "37666967",
                        "name": "M. G. Azar"
                    },
                    {
                        "authorId": "153892869",
                        "name": "Charline Le Lan"
                    },
                    {
                        "authorId": "39439114",
                        "name": "Clare Lyle"
                    },
                    {
                        "authorId": "2090601385",
                        "name": "Andr'as Gyorgy"
                    },
                    {
                        "authorId": "41037204",
                        "name": "Shantanu Thakoor"
                    },
                    {
                        "authorId": "2605877",
                        "name": "Will Dabney"
                    },
                    {
                        "authorId": "1808897",
                        "name": "Bilal Piot"
                    },
                    {
                        "authorId": "2439765",
                        "name": "Daniele Calandriello"
                    },
                    {
                        "authorId": "47948270",
                        "name": "M. Va\u013ako"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "841126bb4be9a2d9f98991d87d6b78f7293abcd2",
                "externalIds": {
                    "ArXiv": "2212.03176",
                    "DBLP": "journals/corr/abs-2212-03176",
                    "DOI": "10.48550/arXiv.2212.03176",
                    "CorpusId": 254274982
                },
                "corpusId": 254274982,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/841126bb4be9a2d9f98991d87d6b78f7293abcd2",
                "title": "Domain Adaptation and Generalization on Functional Medical Images: A Systematic Survey",
                "abstract": "Machine learning algorithms have revolutionized different fields, including natural language processing, computer vision, signal processing, and medical data processing. Despite the excellent capabilities of machine learning algorithms in various tasks and areas, the performance of these models mainly deteriorates when there is a shift in the test and training data distributions. This gap occurs due to the violation of the fundamental assumption that the training and test data are independent and identically distributed (i.i.d). In real-world scenarios where collecting data from all possible domains for training is costly and even impossible, the i.i.d assumption can hardly be satisfied. The problem is even more severe in the case of medical images and signals because it requires either expensive equipment or a meticulous experimentation setup to collect data, even for a single domain. Additionally, the decrease in performance may have severe consequences in the analysis of medical records. As a result of such problems, the ability to generalize and adapt under distribution shifts (domain generalization (DG) and domain adaptation (DA)) is essential for the analysis of medical data. This paper provides the first systematic review of DG and DA on functional brain signals to fill the gap of the absence of a comprehensive study in this era. We provide detailed explanations and categorizations of datasets, approaches, and architectures used in DG and DA on functional brain images. We further address the attention-worthy future tracks in this field.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2193625398",
                        "name": "Gita Sarafraz"
                    },
                    {
                        "authorId": "2193625637",
                        "name": "Armin Behnamnia"
                    },
                    {
                        "authorId": "2065651557",
                        "name": "Mehran Hosseinzadeh"
                    },
                    {
                        "authorId": "11026982",
                        "name": "Ali Balapour"
                    },
                    {
                        "authorId": "2193622395",
                        "name": "Amin Meghrazi"
                    },
                    {
                        "authorId": "1688652",
                        "name": "H. Rabiee"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Further, compared to contrastive learning, the non-contrastive learning frameworks require smaller sized batches to train the models (Tian et al., 2021).",
                "Several studies (Jaiswal et al., 2020; Tian et al., 2021; Balestriero and LeCun, 2022) have proposed theoretical analysis to form justifications for the empirical performance of selfsupervised approaches."
            ],
            "citingPaper": {
                "paperId": "09329c36ebb9c68fa3fe9bc975b5a6f3cc176224",
                "externalIds": {
                    "PubMedCentral": "9751328",
                    "DOI": "10.3389/fmicb.2022.996400",
                    "CorpusId": 254129343,
                    "PubMed": "36532463"
                },
                "corpusId": 254129343,
                "publicationVenue": {
                    "id": "25a655e4-17da-4bfc-a246-5cd20202068d",
                    "name": "Frontiers in Microbiology",
                    "type": "journal",
                    "alternate_names": [
                        "Front Microbiol"
                    ],
                    "issn": "1664-302X",
                    "url": "http://www.frontiersin.org/cellular_and_infection_microbiology/about",
                    "alternate_urls": [
                        "https://www.frontiersin.org/journals/microbiology",
                        "http://www.frontiersin.org/microbiology",
                        "http://journal.frontiersin.org/journal/microbiology"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/09329c36ebb9c68fa3fe9bc975b5a6f3cc176224",
                "title": "An AI-based approach for detecting cells and microbial byproducts in low volume scanning electron microscope images of biofilms",
                "abstract": "Microbially induced corrosion (MIC) of metal surfaces caused by biofilms has wide-ranging consequences. Analysis of biofilm images to understand the distribution of morphological components in images such as microbial cells, MIC byproducts, and metal surfaces non-occluded by cells can provide insights into assessing the performance of coatings and developing new strategies for corrosion prevention. We present an automated approach based on self-supervised deep learning methods to analyze Scanning Electron Microscope (SEM) images and detect cells and MIC byproducts. The proposed approach develops models that can successfully detect cells, MIC byproducts, and non-occluded surface areas in SEM images with a high degree of accuracy using a low volume of data while requiring minimal expert manual effort for annotating images. We develop deep learning network pipelines involving both contrastive (Barlow Twins) and non-contrastive (MoCoV2) self-learning methods and generate models to classify image patches containing three labels\u2014cells, MIC byproducts, and non-occluded surface areas. Our experimental results based on a dataset containing seven grayscale SEM images show that both Barlow Twin and MoCoV2 models outperform the state-of-the-art supervised learning models achieving prediction accuracy increases of approximately 8 and 6%, respectively. The self-supervised pipelines achieved this superior performance by requiring experts to annotate only ~10% of the input data. We also conducted a qualitative assessment of the proposed approach using experts and validated the classification outputs generated by the self-supervised models. This is perhaps the first attempt toward the application of self-supervised learning to classify biofilm image components and our results show that self-supervised learning methods are highly effective for this task while minimizing the expert annotation effort.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1471729143",
                        "name": "Dilanga L. B. Abeyrathna"
                    },
                    {
                        "authorId": "2143412491",
                        "name": "M. Ashaduzzaman"
                    },
                    {
                        "authorId": "7568391",
                        "name": "M. Malshe"
                    },
                    {
                        "authorId": "2133192972",
                        "name": "Jawahar Kalimuthu"
                    },
                    {
                        "authorId": "5934248",
                        "name": "V. Gadhamshetty"
                    },
                    {
                        "authorId": "1795814",
                        "name": "P. Chundi"
                    },
                    {
                        "authorId": "39445424",
                        "name": "M. Subramaniam"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "[17] concluded the contrastive learning methods and present a comprehensive theoretical study of SSL without contrastive pairs."
            ],
            "citingPaper": {
                "paperId": "b98949847967ea3170be8525b8d922621fc07094",
                "externalIds": {
                    "DBLP": "conf/trustcom/ChenYWTX22",
                    "DOI": "10.1109/TrustCom56396.2022.00035",
                    "CorpusId": 257646486
                },
                "corpusId": 257646486,
                "publicationVenue": {
                    "id": "ad34e82f-f936-47a5-9c78-c4453dff3f60",
                    "name": "International Conference on Trust, Security and Privacy in Computing and Communications",
                    "type": "conference",
                    "alternate_names": [
                        "TrustCom",
                        "Trust Secur Priv Comput Commun",
                        "Trust, Security And Privacy In Computing And Communications",
                        "Int Conf Trust Secur Priv Comput Commun"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b98949847967ea3170be8525b8d922621fc07094",
                "title": "Towards Adversarial Robustness with Multidimensional Perturbations via Contrastive Learning",
                "abstract": "Recent works have demonstrated that neural networks are vulnerable to adversarial attacks, while adversarial training is promising for improving robustness of deep networks. However, these models still remain vulnerable to new types of attacks not seen due to representative general samples may not be provided during training. Moreover, substantially larger datasets are necessary in adversarial robust models than those required for standard training where labeled data is expensive. In this work, we propose a novel approach to adversarial robustness, which establishes on the insights from min-max optimization that more powerful adversarial perturbations lead to more robust defense. Our algorithm is called Adversarial Training with Multidimensional Perturbations (ATMP), aims at guiding networks learn strong representations through minimizing the distance between differently augmented views via adopting an innovative contrastive learning objective function in the latent space. By perturbing the representations corresponding to key robust features, more powerful adversarial perturbations could be obtained in self-supervised form during adversarial training. Besides, we can avoid label leaking to some extent because no label information is required in generating adversarial examples. Extensive experimental results on common benchmarks show that our method can achieve high robustness against various of representative adversarial attacks. We also compare it with the existing state-of-the-art techniques, and the experiments indicate that our method is superior.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109152191",
                        "name": "Chuanxi Chen"
                    },
                    {
                        "authorId": "40370879",
                        "name": "Dengpan Ye"
                    },
                    {
                        "authorId": "2211921684",
                        "name": "Hao Wang"
                    },
                    {
                        "authorId": "2047455416",
                        "name": "Long Tang"
                    },
                    {
                        "authorId": "2110803925",
                        "name": "Yue Xu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Several theoretical works also study non-contrastive methods for self-supervised representation learning [Wen and Li, 2022, Tian et al., 2021, Garrido et al., 2022, Balestriero and LeCun, 2022]."
            ],
            "citingPaper": {
                "paperId": "88788d73eb81dc0a1134f30a1ff815c727376681",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-14699",
                    "ArXiv": "2211.14699",
                    "DOI": "10.48550/arXiv.2211.14699",
                    "CorpusId": 254044229
                },
                "corpusId": 254044229,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/88788d73eb81dc0a1134f30a1ff815c727376681",
                "title": "A Theoretical Study of Inductive Biases in Contrastive Learning",
                "abstract": "Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of Saunshi et al. argues that the model architecture -- a component largely ignored by previous works -- also has significant influences on the downstream performance of self-supervised learning. In this work, we provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. In particular, we focus on contrastive learning -- a popular self-supervised learning method that is widely used in the vision domain. We show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. As a result, our theory can capture the more realistic setting where contrastive representations have much lower dimensionality than the number of clusters in the data distribution. We instantiate our theory on several synthetic data distributions, and provide empirical evidence to support the theory.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "134168070",
                        "name": "Jeff Z. HaoChen"
                    },
                    {
                        "authorId": "2114186424",
                        "name": "Tengyu Ma"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "contexts": [
                "Ideally, this model should not only perform better than BGRL in the inductive setting, but should also have the same time complexity as BGRL.",
                "As such, we refer to these two methods as BGRL.",
                "This has also been shown to be true for BGRL. Tian et al. (2021) claim that the eigenspace of predictor weights will align with the correlation matrix of the online network under the assumption of a one-layer linear encoder and a one-layer linear predictor.",
                "We can see that T-BGRL pushes apart unseen negative and positive pairs much better than BGRL.\nTable 3: Transductive performance of T-BGRL compared to ML-GCN and BGRL (same numbers as Table 1 above; full figure in Table 5).",
                "BGRL.",
                "We also evaluate the performance of T-BGRL in the transductive setting to ensure that it does not significantly reduce performance when compared to BGRL.",
                "We experiment with several different corruptions methods, but limit ourselves to linear-time corruptions in order to maintain the efficiency of BGRL."
            ],
            "citingPaper": {
                "paperId": "b0e870b0ac63b97f1328ff3eeda14edd99dde109",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-14394",
                    "ArXiv": "2211.14394",
                    "DOI": "10.48550/arXiv.2211.14394",
                    "CorpusId": 254044293
                },
                "corpusId": 254044293,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b0e870b0ac63b97f1328ff3eeda14edd99dde109",
                "title": "Link Prediction with Non-Contrastive Learning",
                "abstract": "A recent focal area in the space of graph neural networks (GNNs) is graph self-supervised learning (SSL), which aims to derive useful node representations without labeled data. Notably, many state-of-the-art graph SSL methods are contrastive methods, which use a combination of positive and negative samples to learn node representations. Owing to challenges in negative sampling (slowness and model sensitivity), recent literature introduced non-contrastive methods, which instead only use positive samples. Though such methods have shown promising performance in node-level tasks, their suitability for link prediction tasks, which are concerned with predicting link existence between pairs of nodes (and have broad applicability to recommendation systems contexts) is yet unexplored. In this work, we extensively evaluate the performance of existing non-contrastive methods for link prediction in both transductive and inductive settings. While most existing non-contrastive methods perform poorly overall, we find that, surprisingly, BGRL generally performs well in transductive settings. However, it performs poorly in the more realistic inductive settings where the model has to generalize to links to/from unseen nodes. We find that non-contrastive models tend to overfit to the training graph and use this analysis to propose T-BGRL, a novel non-contrastive framework that incorporates cheap corruptions to improve the generalization ability of the model. This simple modification strongly improves inductive performance in 5/6 of our datasets, with up to a 120% improvement in Hits@50--all with comparable speed to other non-contrastive baselines and up to 14x faster than the best-performing contrastive baseline. Our work imparts interesting findings about non-contrastive learning for link prediction and paves the way for future researchers to further expand upon this area.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2094369655",
                        "name": "William Shiao"
                    },
                    {
                        "authorId": "2109411071",
                        "name": "Zhichun Guo"
                    },
                    {
                        "authorId": "1742573",
                        "name": "Tong Zhao"
                    },
                    {
                        "authorId": "3000659",
                        "name": "E. Papalexakis"
                    },
                    {
                        "authorId": "152891495",
                        "name": "Yozen Liu"
                    },
                    {
                        "authorId": "145474474",
                        "name": "Neil Shah"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "served that the collapse can be avoidable in carefully designed training frameworks [9, 31, 62], it is still a problem in certain settings depending on model choices and trainingdataset sizes [38]."
            ],
            "citingPaper": {
                "paperId": "baae351142a07d9d0b3d332ba9e983fbde797982",
                "externalIds": {
                    "ArXiv": "2211.13844",
                    "DBLP": "journals/corr/abs-2211-13844",
                    "DOI": "10.48550/arXiv.2211.13844",
                    "CorpusId": 254017503
                },
                "corpusId": 254017503,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/baae351142a07d9d0b3d332ba9e983fbde797982",
                "title": "Ladder Siamese Network: a Method and Insights for Multi-level Self-Supervised Learning",
                "abstract": "Siamese-network-based self-supervised learning (SSL) suffers from slow convergence and instability in training. To alleviate this, we propose a framework to exploit intermediate self-supervisions in each stage of deep nets, called the Ladder Siamese Network. Our self-supervised losses encourage the intermediate layers to be consistent with different data augmentations to single samples, which facilitates training progress and enhances the discriminative ability of the intermediate layers themselves. While some existing work has already utilized multi-level self supervisions in SSL, ours is different in that 1) we reveal its usefulness with non-contrastive Siamese frameworks in both theoretical and empirical viewpoints, and 2) ours improves image-level classification, instance-level detection, and pixel-level segmentation simultaneously. Experiments show that the proposed framework can improve BYOL baselines by 1.0% points in ImageNet linear classification, 1.2% points in COCO detection, and 3.1% points in PASCAL VOC segmentation. In comparison with the state-of-the-art methods, our Ladder-based model achieves competitive and balanced performances in all tested benchmarks without causing large degradation in one.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1890560",
                        "name": "Ryota Yoshihashi"
                    },
                    {
                        "authorId": "2192514324",
                        "name": "Shuhei Nishimura"
                    },
                    {
                        "authorId": "2192514035",
                        "name": "Dai Yonebayashi"
                    },
                    {
                        "authorId": "2192514202",
                        "name": "Yuya Otsuka"
                    },
                    {
                        "authorId": "1500659599",
                        "name": "Tomohiro Tanaka"
                    },
                    {
                        "authorId": "145414551",
                        "name": "Takashi Miyazaki"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Several non-contrastive methods are proposed to learn image-level representations solely based on positive samples [2, 9, 13, 26, 51, 59]."
            ],
            "citingPaper": {
                "paperId": "f1f66410422bf2609c80874f7328e82f1a4766d4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-12817",
                    "ArXiv": "2211.12817",
                    "DOI": "10.48550/arXiv.2211.12817",
                    "CorpusId": 253801956
                },
                "corpusId": 253801956,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f1f66410422bf2609c80874f7328e82f1a4766d4",
                "title": "Reason from Context with Self-supervised Learning",
                "abstract": "Self-supervised learning (SSL) learns to capture discriminative visual features useful for knowledge transfers. To better accommodate the object-centric nature of current downstream tasks such as object recognition and detection, various methods have been proposed to suppress contextual biases or disentangle objects from contexts. Nevertheless, these methods may prove inadequate in situations where object identity needs to be reasoned from associated context, such as recognizing or inferring tiny or obscured objects. As an initial effort in the SSL literature, we investigate whether and how contextual associations can be enhanced for visual reasoning within SSL regimes, by (a) proposing a new Self-supervised method with external memories for Context Reasoning (SeCo), and (b) introducing two new downstream tasks, lift-the-flap and object priming, addressing the problems of\"what\"and\"where\"in context reasoning. In both tasks, SeCo outperformed all state-of-the-art (SOTA) SSL methods by a significant margin. Our network analysis revealed that the proposed external memory in SeCo learns to store prior contextual knowledge, facilitating target identity inference in the lift-the-flap task. Moreover, we conducted psychophysics experiments and introduced a Human benchmark in Object Priming dataset (HOP). Our results demonstrate that SeCo exhibits human-like behaviors.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48032577",
                        "name": "Xinyu Liu"
                    },
                    {
                        "authorId": "2048021896",
                        "name": "Ankur Sikarwar"
                    },
                    {
                        "authorId": "2109781618",
                        "name": "J. Lim"
                    },
                    {
                        "authorId": "2066787605",
                        "name": "Gabriel Kreiman"
                    },
                    {
                        "authorId": "3480262",
                        "name": "Zenglin Shi"
                    },
                    {
                        "authorId": "2418491",
                        "name": "Mengmi Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "6dc692fb1b028105094bb39fb347e777002bde0c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-11335",
                    "ArXiv": "2211.11335",
                    "DOI": "10.1109/CVPR52729.2023.02270",
                    "CorpusId": 253734647
                },
                "corpusId": 253734647,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6dc692fb1b028105094bb39fb347e777002bde0c",
                "title": "Instance-Specific and Model-Adaptive Supervision for Semi-Supervised Semantic Segmentation",
                "abstract": "Recently, semi-supervised semantic segmentation has achieved promising performance with a small fraction of labeled data. However, most existing studies treat all unlabeled data equally and barely consider the differences and training difficulties among unlabeled instances. Differentiating unlabeled instances can promote instance-specific supervision to adapt to the model's evolution dynamically. In this paper, we emphasize the cruciality of instance differences and propose an instance-specific and model-adaptive supervision for semi-supervised semantic segmentation, named iMAS. Relying on the model's performance, iMAS employs a class-weighted symmetric intersection-over-union to evaluate quantitative hardness of each unlabeled instance and supervises the training on unlabeled data in a model-adaptive manner. Specifically, iMAS learns from unlabeled instances progressively by weighing their corresponding consistency losses based on the evaluated hardness. Besides, iMAS dynamically adjusts the augmentation for each instance such that the distortion degree of augmented instances is adapted to the model's generalization capability across the training course. Not integrating additional losses and training procedures, iMAS can obtain remarkable performance gains against current state-of-the-art approaches on segmentation benchmarks under different semi-supervised partition protocols11Code and logs: https://github.com/zhenzhao/iMAS.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145737114",
                        "name": "Zhen Zhao"
                    },
                    {
                        "authorId": "116036819",
                        "name": "Sifan Long"
                    },
                    {
                        "authorId": "19273094",
                        "name": "Jimin Pi"
                    },
                    {
                        "authorId": "2109534192",
                        "name": "Jingdong Wang"
                    },
                    {
                        "authorId": "6578587",
                        "name": "Luping Zhou"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Instance discrimination contains several sub-frameworks, including contrastive learning [13, 31], asymmetric networks [15, 27] and feature decorrelation [6, 89], which are found of similar mechanism [66,70]."
            ],
            "citingPaper": {
                "paperId": "ee96ec926f06ff2f3ce3d131cffcbfe63af39f0c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-09807",
                    "ArXiv": "2211.09807",
                    "DOI": "10.1109/CVPR52729.2023.01525",
                    "CorpusId": 253581779
                },
                "corpusId": 253581779,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ee96ec926f06ff2f3ce3d131cffcbfe63af39f0c",
                "title": "Towards All-in-One Pre-Training via Maximizing Multi-Modal Mutual Information",
                "abstract": "To effectively exploit the potential of large-scale models, various pre-training strategies supported by massive data from different sources are proposed, including supervised pre-training, weakly-supervised pre-training, and self-supervised pre-training. It has been proved that combining multiple pre-training strategies and data from various modalities/sources can greatly boost the training of large-scale models. However, current works adopt a multi-stage pre-training system, where the complex pipeline may increase the uncertainty and instability of the pre-training. It is thus desirable that these strategies can be integrated in a single-stage manner. In this paper, we first propose a general multimodal mutual information formula as a unified optimization target and demonstrate that all mainstream approaches are special cases of our framework. Under this unified perspective, we propose an all-in-one single-stage pre-training approach, named Maximizing Multi-modal Mutual Information Pre-Training (M3I Pre-training). Our approach achieves better performance than previous pre-training methods on various vision benchmarks, including ImageNet classification, COCO object detection, LVIS long-tailed object detection, and ADE20k semantic segmentation. Notably, we successfully pre-train a billion-level parameter image backbone and achieve state-of-the-art performance on various benchmarks under public data setting. Code shall be released at https://github.com/OpenGVLab/M3I-Pre-Training.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145499378",
                        "name": "Weijie Su"
                    },
                    {
                        "authorId": "2578924",
                        "name": "Xizhou Zhu"
                    },
                    {
                        "authorId": "150959424",
                        "name": "Chenxin Tao"
                    },
                    {
                        "authorId": "152309485",
                        "name": "Lewei Lu"
                    },
                    {
                        "authorId": "2185909990",
                        "name": "Bin Li"
                    },
                    {
                        "authorId": "2115218570",
                        "name": "Gao Huang"
                    },
                    {
                        "authorId": "145858545",
                        "name": "Y. Qiao"
                    },
                    {
                        "authorId": "2137313794",
                        "name": "Xiaogang Wang"
                    },
                    {
                        "authorId": "2141009492",
                        "name": "Jie Zhou"
                    },
                    {
                        "authorId": "3304536",
                        "name": "Jifeng Dai"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "collapse resulting from the absence of negative samples [162]."
            ],
            "citingPaper": {
                "paperId": "625c2f8d72cc9ce454c27599f2fdc84f81341b01",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-08129",
                    "ArXiv": "2211.08129",
                    "DOI": "10.1109/TGRS.2023.3276853",
                    "CorpusId": 253523330
                },
                "corpusId": 253523330,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/625c2f8d72cc9ce454c27599f2fdc84f81341b01",
                "title": "Self-Supervised Remote Sensing Feature Learning: Learning Paradigms, Challenges, and Future Works",
                "abstract": "Deep learning has achieved great success in learning features from massive remote sensing images (RSIs). To better understand the connection between three feature learning paradigms, which are unsupervised feature learning (USFL), supervised feature learning (SFL), and self-SFL (SSFL), this article analyzes and compares them from the perspective of feature learning signals and gives a unified feature learning framework. Under this unified framework, we analyze the advantages of SSFL over the other two learning paradigms in RSI understanding tasks and give a comprehensive review of existing SSFL works in RS, including the pretraining dataset, SSFL signals, and evaluation methods. We further analyze the effects of SSFL signals and pretraining data on the learned features to provide insights into RSI feature learning. Finally, we briefly discuss some open problems and possible research directions.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "49409814",
                        "name": "Chao Tao"
                    },
                    {
                        "authorId": "1410210537",
                        "name": "J. Qi"
                    },
                    {
                        "authorId": "2191048702",
                        "name": "Mingning Guo"
                    },
                    {
                        "authorId": "2152206745",
                        "name": "Qing Zhu"
                    },
                    {
                        "authorId": "2144415124",
                        "name": "Haifeng Li"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "[43] investigated the elements of these negative-free approaches relying on architectural update (adding a predictor block) as well as new training protocol (stop-gradient policy), which enables them to substantially outperform contrastive approaches while avoiding the trivial representation."
            ],
            "citingPaper": {
                "paperId": "61b460cfb485615b3ac4d4e65883f32caa733edc",
                "externalIds": {
                    "ArXiv": "2210.15818",
                    "DBLP": "conf/wacv/MohamadiDA23",
                    "DOI": "10.1109/WACV56688.2023.00282",
                    "CorpusId": 253223995
                },
                "corpusId": 253223995,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/61b460cfb485615b3ac4d4e65883f32caa733edc",
                "title": "FUSSL: Fuzzy Uncertain Self Supervised Learning",
                "abstract": "Self supervised learning (SSL) has become a very successful technique to harness the power of unlabeled data, with no annotation effort. A number of developed approaches are evolving with the goal of outperforming supervised alternatives, which have been relatively successful. Similar to some other disciplines in deep representation learning, one main issue in SSL is robustness of the approaches under different settings. In this paper, for the first time, we recognise the fundamental limits of SSL coming from the use of a single-supervisory signal. To address this limitation, we leverage the power of uncertainty representation to devise a robust and general standard hierarchical learning/training protocol for any SSL baseline, regardless of their assumptions and approaches. Essentially, using the information bottleneck principle, we decompose feature learning into a two-stage training procedure, each with a distinct supervision signal. This double supervision approach is captured in two key steps: 1) invariance enforcement to data augmentation, and 2) fuzzy pseudo labeling (both hard and soft annotation). This simple, yet, effective protocol which enables cross-class/cluster feature learning, is instantiated via an initial training of an ensemble of models through invariance enforcement to data augmentation as first training phase, and then assigning fuzzy labels to the original samples for the second training phase. We consider multiple alternative scenarios with double supervision and evaluate the effectiveness of our approach on recent baselines, covering four different SSL paradigms, including geometrical, contrastive, non-contrastive, and hard/soft whitening (redundancy reduction) baselines. We performed extensive experiments under multiple settings to show that the proposed training protocol consistently improves the performance of the former baselines, independent of their respective underlying principles.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "18095349",
                        "name": "S. Mohamadi"
                    },
                    {
                        "authorId": "1736352",
                        "name": "Gianfranco Doretto"
                    },
                    {
                        "authorId": "145358382",
                        "name": "D. Adjeroh"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "3) Contrastive Learning: Most successful self-supervised or unsupervised visual representation methods [38], [39], [40] rely on contrastive learning."
            ],
            "citingPaper": {
                "paperId": "b7a799a9e6f2b98c088093939be6c7156ce4dd7f",
                "externalIds": {
                    "DBLP": "journals/titb/ShiGWL23",
                    "DOI": "10.1109/JBHI.2022.3216293",
                    "CorpusId": 253064152,
                    "PubMed": "36269914"
                },
                "corpusId": 253064152,
                "publicationVenue": {
                    "id": "eac74c9c-a5c0-417d-8088-8164a6a8bfb3",
                    "name": "IEEE journal of biomedical and health informatics",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Journal of Biomedical and Health Informatics",
                        "IEEE j biomed health informatics",
                        "IEEE J Biomed Health Informatics"
                    ],
                    "issn": "2168-2194",
                    "url": "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6221020",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b7a799a9e6f2b98c088093939be6c7156ce4dd7f",
                "title": "Semi-Supervised Pixel Contrastive Learning Framework for Tissue Segmentation in Histopathological Image",
                "abstract": "Accurate tissue segmentation in histopathological images is essential for promoting the development of precision pathology. However, the size of the digital pathological image is great, which needs to be tiled into small patches containing limited semantic information. To imitate the pathologist's diagnosis process and model the semantic relation of the whole slide image, We propose a semi-supervised pixel contrastive learning framework (SSPCL) which mainly includes an uncertainty-guided mutual dual consistency learning module (UMDC) and a cross image pixel-contrastive learning module (CIPC). The UMDC module enables efficient learning from unlabeled data through mutual dual-consistency and consensus-based uncertainty. The CIPC module aims at capturing the cross-patch semantic relationship by optimizing a contrastive loss between pixel embeddings. We also propose several novel domain-related sampling methods by utilizing the continuous spatial structure of adjacent image patches, which can avoid the problem of false sampling and improve the training efficiency. In this way, SSPCL significantly reduces the labeling cost on histopathological images and realizes the accurate quantitation of tissues. Extensive experiments on three tissue segmentation datasets demonstrate the effectiveness of SSPCL, which outperforms state-of-the-art up to 5.0% in mDice.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2117867785",
                        "name": "Jiangbo Shi"
                    },
                    {
                        "authorId": "2134875126",
                        "name": "Tieliang Gong"
                    },
                    {
                        "authorId": "2108725950",
                        "name": "Chunbao Wang"
                    },
                    {
                        "authorId": "2145261743",
                        "name": "Chen Li"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "0e90ab64cb1f5894a4d4a895ed61f578e24cd494",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-11075",
                    "ArXiv": "2210.11075",
                    "DOI": "10.48550/arXiv.2210.11075",
                    "CorpusId": 253018507
                },
                "corpusId": 253018507,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0e90ab64cb1f5894a4d4a895ed61f578e24cd494",
                "title": "Freeze then Train: Towards Provable Representation Learning under Spurious Correlations and Feature Noise",
                "abstract": "The existence of spurious correlations such as image backgrounds in the training environment can make empirical risk minimization (ERM) perform badly in the test environment. To address this problem, Kirichenko et al. (2022) empirically found that the core features that are related to the outcome can still be learned well even with the presence of spurious correlations. This opens a promising strategy to first train a feature learner rather than a classifier, and then perform linear probing (last layer retraining) in the test environment. However, a theoretical understanding of when and why this approach works is lacking. In this paper, we find that core features are only learned well when their associated non-realizable noise is smaller than that of spurious features, which is not necessarily true in practice. We provide both theories and experiments to support this finding and to illustrate the importance of non-realizable noise. Moreover, we propose an algorithm called Freeze then Train (FTT), that first freezes certain salient features and then trains the rest of the features using ERM. We theoretically show that FTT preserves features that are more beneficial to test time probing. Across two commonly used spurious correlation datasets, FTT outperforms ERM, IRM, JTT and CVaR-DRO, with substantial improvement in accuracy (by 4.5%) when the feature noise is large. FTT also performs better on general distribution shift benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "5935398",
                        "name": "Hao-Tong Ye"
                    },
                    {
                        "authorId": "145085305",
                        "name": "James Y. Zou"
                    },
                    {
                        "authorId": "10537441",
                        "name": "Linjun Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Self-supervised learning [7, 30, 31, 35] has achieved remarkable progress in recent years, in representation learning without the need for class label supervision."
            ],
            "citingPaper": {
                "paperId": "18312bd0309c836e0b69fe80c34789e8a9a2ae8d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-10194",
                    "ArXiv": "2210.10194",
                    "DOI": "10.48550/arXiv.2210.10194",
                    "CorpusId": 252992486
                },
                "corpusId": 252992486,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/18312bd0309c836e0b69fe80c34789e8a9a2ae8d",
                "title": "Rethinking Prototypical Contrastive Learning through Alignment, Uniformity and Correlation",
                "abstract": "Contrastive self-supervised learning (CSL) with a prototypical regularization has been introduced in learning meaningful representations for downstream tasks that require strong semantic information. However, to optimize CSL with a loss that performs the prototypical regularization aggressively, e.g., the ProtoNCE loss, might cause the\"coagulation\"of examples in the embedding space. That is, the intra-prototype diversity of samples collapses to trivial solutions for their prototype being well-separated from others. Motivated by previous works, we propose to mitigate this phenomenon by learning Prototypical representation through Alignment, Uniformity and Correlation (PAUC). Specifically, the ordinary ProtoNCE loss is revised with: (1) an alignment loss that pulls embeddings from positive prototypes together; (2) a uniformity loss that distributes the prototypical level features uniformly; (3) a correlation loss that increases the diversity and discriminability between prototypical level features. We conduct extensive experiments on various benchmarks where the results demonstrate the effectiveness of our method in improving the quality of prototypical contrastive representations. Particularly, in the classification down-stream tasks with linear probes, our proposed method outperforms the state-of-the-art instance-wise and prototypical contrastive learning methods on the ImageNet-100 dataset by 2.96% and the ImageNet-1K dataset by 2.46% under the same settings of batch size and epochs.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2066123456",
                        "name": "Shentong Mo"
                    },
                    {
                        "authorId": "3458345",
                        "name": "Zhun Sun"
                    },
                    {
                        "authorId": "2150356887",
                        "name": "Chao Li"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "More recent works [4], [32], [33] have shown that we can learn high-quality representations without negative samples."
            ],
            "citingPaper": {
                "paperId": "8a3d81f1d4ee013c12801b59f5537fbc7af30511",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-08458",
                    "ArXiv": "2210.08458",
                    "DOI": "10.48550/arXiv.2210.08458",
                    "CorpusId": 252918112
                },
                "corpusId": 252918112,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8a3d81f1d4ee013c12801b59f5537fbc7af30511",
                "title": "Learning Self-Regularized Adversarial Views for Self-Supervised Vision Transformers",
                "abstract": "Automatic data augmentation (AutoAugment) strategies are indispensable in supervised data-efficient training protocols of vision transformers, and have led to state-of-the-art results in supervised learning. Despite the success, its development and application on self-supervised vision transformers have been hindered by several barriers, including the high search cost, the lack of supervision, and the unsuitable search space. In this work, we propose AutoView, a self-regularized adversarial AutoAugment method, to learn views for self-supervised vision transformers, by addressing the above barriers. First, we reduce the search cost of AutoView to nearly zero by learning views and network parameters simultaneously in a single forward-backward step, minimizing and maximizing the mutual information among different augmented views, respectively. Then, to avoid information collapse caused by the lack of label supervision, we propose a self-regularized loss term to guarantee the information propagation. Additionally, we present a curated augmentation policy search space for self-supervised learning, by modifying the generally used search space designed for supervised learning. On ImageNet, our AutoView achieves remarkable improvement over RandAug baseline (+10.2% k-NN accuracy), and consistently outperforms sota manually tuned view policy by a clear margin (up to +1.3% k-NN accuracy). Extensive experiments show that AutoView pretraining also benefits downstream tasks (+1.2% mAcc on ADE20K Semantic Segmentation and +2.8% mAP on revisited Oxford Image Retrieval benchmark) and improves model robustness (+2.3% Top-1 Acc on ImageNet-A and +1.0% AUPR on ImageNet-O). Code and models will be available at https://github.com/Trent-tangtao/AutoView.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2069746552",
                        "name": "Tao Tang"
                    },
                    {
                        "authorId": "46651877",
                        "name": "Changlin Li"
                    },
                    {
                        "authorId": "2749191",
                        "name": "Guangrun Wang"
                    },
                    {
                        "authorId": "9945144",
                        "name": "Kaicheng Yu"
                    },
                    {
                        "authorId": "144950946",
                        "name": "Xiaojun Chang"
                    },
                    {
                        "authorId": "13246332",
                        "name": "Xiaodan Liang"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "contexts": [
                "Indeed, it has been shown that pretraining the same joint-embedding methods on long-tailed datasets can lead to significant drops in performance (Tian et al., 2021a).",
                "Recent theoretical work (Tian et al., 2021b) explores why certain joint-embedding methods with architectural constraint avoid representation collapse without explicit use of a volume maximization penalty; the implicit collapse prevention mechanisms here are not mutually exclusive.",
                "\u2026dynamics of joint-embedding methods, they do not directly explain why empirical use of these methods with real-world classimbalanced data has often led to a degradation in downstream task performance (Tian et al., 2021a; Goyal et al., 2022) (see Appendix A for a broader discussion of related work).",
                "There is also theoretical work (Tian et al., 2021b) which aims to understand why certain joint-embedding methods, such as BYOL (Grill et al., 2020), can avoid representation collapse without explicit use of a volume maximization penalty."
            ],
            "citingPaper": {
                "paperId": "8be831a07abe8c5475c2bd91cc41bf4c1c2be771",
                "externalIds": {
                    "DBLP": "conf/iclr/AssranBDBMBVRB23",
                    "ArXiv": "2210.07277",
                    "DOI": "10.48550/arXiv.2210.07277",
                    "CorpusId": 252907682
                },
                "corpusId": 252907682,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/8be831a07abe8c5475c2bd91cc41bf4c1c2be771",
                "title": "The Hidden Uniform Cluster Prior in Self-Supervised Learning",
                "abstract": "A successful paradigm in representation learning is to perform self-supervised pretraining using tasks based on mini-batch statistics (e.g., SimCLR, VICReg, SwAV, MSN). We show that in the formulation of all these methods is an overlooked prior to learn features that enable uniform clustering of the data. While this prior has led to remarkably semantic representations when pretraining on class-balanced data, such as ImageNet, we demonstrate that it can hamper performance when pretraining on class-imbalanced data. By moving away from conventional uniformity priors and instead preferring power-law distributed feature clusters, we show that one can improve the quality of the learned representations on real-world class-imbalanced datasets. To demonstrate this, we develop an extension of the Masked Siamese Networks (MSN) method to support the use of arbitrary features priors.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "38698856",
                        "name": "Mahmoud Assran"
                    },
                    {
                        "authorId": "3201463",
                        "name": "Randall Balestriero"
                    },
                    {
                        "authorId": "2101830371",
                        "name": "Quentin Duval"
                    },
                    {
                        "authorId": "34651419",
                        "name": "Florian Bordes"
                    },
                    {
                        "authorId": "1806773",
                        "name": "Ishan Misra"
                    },
                    {
                        "authorId": "2329288",
                        "name": "Piotr Bojanowski"
                    },
                    {
                        "authorId": "145467703",
                        "name": "Pascal Vincent"
                    },
                    {
                        "authorId": "2066127975",
                        "name": "Michael G. Rabbat"
                    },
                    {
                        "authorId": "2482072",
                        "name": "Nicolas Ballas"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "48bf7949fa0b99de39e0f09439295f7dd07d85a8",
                "externalIds": {
                    "ArXiv": "2210.03595",
                    "DBLP": "journals/corr/abs-2210-03595",
                    "DOI": "10.48550/arXiv.2210.03595",
                    "CorpusId": 252762664
                },
                "corpusId": 252762664,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/48bf7949fa0b99de39e0f09439295f7dd07d85a8",
                "title": "Unsupervised Few-shot Learning via Deep Laplacian Eigenmaps",
                "abstract": "Learning a new task from a handful of examples remains an open challenge in machine learning. Despite the recent progress in few-shot learning, most methods rely on supervised pretraining or meta-learning on labeled meta-training data and cannot be applied to the case where the pretraining data is unlabeled. In this study, we present an unsupervised few-shot learning method via deep Laplacian eigenmaps. Our method learns representation from unlabeled data by grouping similar samples together and can be intuitively interpreted by random walks on augmented training data. We analytically show how deep Laplacian eigenmaps avoid collapsed representation in unsupervised learning without explicit comparison between positive and negative samples. The proposed method significantly closes the performance gap between supervised and unsupervised few-shot learning. Our method also achieves comparable performance to current state-of-the-art self-supervised learning methods under linear evaluation protocol.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3289893",
                        "name": "Kuilin Chen"
                    },
                    {
                        "authorId": "2143724945",
                        "name": "Chi-Guhn Lee"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "8, we find that: 1) BW-based whitening loss ensures a whitened target \u1e902, while SimSiam does not put constraint on the target Z2; 2) SimSiam uses a learnable predictor P\u03b8p(\u00b7), which is shown to empirically avoid collapse by matching the rank of the covariance matrix by back-propagation [40], while BW-based whitening loss has an implicit predictor \u03c6(Z1) depending on the input itself, which is a full-rank matrix by design.",
                "It remains not clear how the asymmetric network avoids collapse without negative pairs, leaving the debates on batch normalization (BN) [14, 41, 36] and stop-gradient [8, 46], even though preliminary works have attempted to analyze the training dynamics theoretical with certain assumptions [40] and build a connection between asymmetric network with contrastive learning methods [39]."
            ],
            "citingPaper": {
                "paperId": "889b77e22d74f8704c5ee4ee73e8dd5a2b15f46c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-03586",
                    "ArXiv": "2210.03586",
                    "DOI": "10.48550/arXiv.2210.03586",
                    "CorpusId": 252762418
                },
                "corpusId": 252762418,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/889b77e22d74f8704c5ee4ee73e8dd5a2b15f46c",
                "title": "An Investigation into Whitening Loss for Self-supervised Learning",
                "abstract": "A desirable objective in self-supervised learning (SSL) is to avoid feature collapse. Whitening loss guarantees collapse avoidance by minimizing the distance between embeddings of positive pairs under the conditioning that the embeddings from different views are whitened. In this paper, we propose a framework with an informative indicator to analyze whitening loss, which provides a clue to demystify several interesting phenomena as well as a pivoting point connecting to other SSL methods. We reveal that batch whitening (BW) based methods do not impose whitening constraints on the embedding, but they only require the embedding to be full-rank. This full-rank constraint is also sufficient to avoid dimensional collapse. Based on our analysis, we propose channel whitening with random group partition (CW-RGP), which exploits the advantages of BW-based methods in preventing collapse and avoids their disadvantages requiring large batch size. Experimental results on ImageNet classification and COCO object detection reveal that the proposed CW-RGP possesses a promising potential for learning good representations. The code is available at https://github.com/winci-ai/CW-RGP.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "39163190",
                        "name": "Xi Weng"
                    },
                    {
                        "authorId": "2109138795",
                        "name": "Lei Huang"
                    },
                    {
                        "authorId": "2111487534",
                        "name": "Lei Zhao"
                    },
                    {
                        "authorId": "3288214",
                        "name": "R. Anwer"
                    },
                    {
                        "authorId": "2111181927",
                        "name": "Salman Khan"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "The success of BYOL (Grill et al., 2020) inspired empirical (Chen & He, 2021) and theoretical (Tian et al., 2021) analyses into what enables BYOL to effectively learn and avoid collapse with the EMA Teacher during pre-training.",
                ", 2020) inspired empirical (Chen & He, 2021) and theoretical (Tian et al., 2021) analyses into what enables BYOL to effectively learn and avoid collapse with the EMA Teacher during pre-training."
            ],
            "citingPaper": {
                "paperId": "429e68167c418d7aea7379083599834d5e36606f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-02077",
                    "ArXiv": "2210.02077",
                    "DOI": "10.48550/arXiv.2210.02077",
                    "CorpusId": 252715443
                },
                "corpusId": 252715443,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/429e68167c418d7aea7379083599834d5e36606f",
                "title": "Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders",
                "abstract": "Masked image modeling (MIM) has become a popular strategy for self-supervised learning~(SSL) of visual representations with Vision Transformers. A representative MIM model, the masked auto-encoder (MAE), randomly masks a subset of image patches and reconstructs the masked patches given the unmasked patches. Concurrently, many recent works in self-supervised learning utilize the student/teacher paradigm which provides the student with an additional target based on the output of a teacher composed of an exponential moving average (EMA) of previous students. Although common, relatively little is known about the dynamics of the interaction between the student and teacher. Through analysis on a simple linear model, we find that the teacher conditionally removes previous gradient directions based on feature similarities which effectively acts as a conditional momentum regularizer. From this analysis, we present a simple SSL method, the Reconstruction-Consistent Masked Auto-Encoder (RC-MAE) by adding an EMA teacher to MAE. We find that RC-MAE converges faster and requires less memory usage than state-of-the-art self-distillation methods during pre-training, which may provide a way to enhance the practicality of prohibitively expensive self-supervised learning of Vision Transformer models. Additionally, we show that RC-MAE achieves more robustness and better performance compared to MAE on downstream tasks such as ImageNet-1K classification, object detection, and instance segmentation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3445691",
                        "name": "Youngwan Lee"
                    },
                    {
                        "authorId": "2051330801",
                        "name": "Jeffrey Willette"
                    },
                    {
                        "authorId": "1804971",
                        "name": "Jonghee Kim"
                    },
                    {
                        "authorId": "2108550899",
                        "name": "Juho Lee"
                    },
                    {
                        "authorId": "35788904",
                        "name": "Sung Ju Hwang"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Preventing such collapsed representations is a frequently discussed topic in literature (Hua et al., 2021; Jing et al., 2021; Pokle et al., 2022; Tian et al., 2021) and has motivated the design of several SSL techniques (Zbontar et al., 2021; Bardes et al., 2021; Ermolov et al., 2021).",
                "In practice, however, SSL training often experiences the phenomenon of dimensional collapse (Jing et al., 2021; Tian et al., 2021; Pokle et al., 2022), where the learned representation spans a low dimensional subspace of the overall available space.",
                "Preventing such collapsed representations is a frequently discussed topic in literature (Hua et al., 2021; Jing et al., 2021; Pokle et al., 2022; Tian et al., 2021) and has motivated the design of several SSL techniques (Zbontar et al.",
                "\u2026causality and data-generating processes (Zimmerman et al., 2021; Kugelgen et al., 2021; Trivedi et al., 2022; Tian et al., 2020; Mitrovic et al., 2020; Wang et al., 2022), dynamics (Wang and Isola, 2020; Tian et al., 2021; Tian, 2022; Wang and Liu, 2021), and loss landscapes (Pokle et al., 2022).",
                ", 2022), dynamics (Wang and Isola, 2020; Tian et al., 2021; Tian, 2022; Wang and Liu, 2021), and loss landscapes (Pokle et al."
            ],
            "citingPaper": {
                "paperId": "197790926475674f5997a7f70d06c6265617282e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-00638",
                    "ArXiv": "2210.00638",
                    "DOI": "10.48550/arXiv.2210.00638",
                    "CorpusId": 252683253
                },
                "corpusId": 252683253,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/197790926475674f5997a7f70d06c6265617282e",
                "title": "What shapes the loss landscape of self-supervised learning?",
                "abstract": "Prevention of complete and dimensional collapse of representations has recently become a design principle for self-supervised learning (SSL). However, questions remain in our theoretical understanding: When do those collapses occur? What are the mechanisms and causes? We answer these questions by deriving and thoroughly analyzing an analytically tractable theory of SSL loss landscapes. In this theory, we identify the causes of the dimensional collapse and study the effect of normalization and bias. Finally, we leverage the interpretability afforded by the analytical theory to understand how dimensional collapse can be beneficial and what affects the robustness of SSL against data imbalance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "12907562",
                        "name": "Liu Ziyin"
                    },
                    {
                        "authorId": "35573359",
                        "name": "E. S. Lubana"
                    },
                    {
                        "authorId": "144365686",
                        "name": "Masakuni Ueda"
                    },
                    {
                        "authorId": "1912151014",
                        "name": "Hidenori Tanaka"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "[107] Yuandong Tian, Xinlei Chen, and Surya Ganguli.",
                "Many investigators have appreciated the importance of improving our understanding of unsupervised representation learning and taken pioneering steps to simplify SOTA methods [18; 19; 114; 22], to establish connections to classical methods [69; 4], to unify different approaches [4; 39; 97; 62; 55], to visualize the representation [9; 116; 15], and to analyze the methods from a theoretical perspective [3; 45; 107; 4]."
            ],
            "citingPaper": {
                "paperId": "537166437212aac4b4297121e0ba4b7e545d4e54",
                "externalIds": {
                    "ArXiv": "2209.15261",
                    "DBLP": "journals/corr/abs-2209-15261",
                    "DOI": "10.48550/arXiv.2209.15261",
                    "CorpusId": 252668658
                },
                "corpusId": 252668658,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/537166437212aac4b4297121e0ba4b7e545d4e54",
                "title": "Minimalistic Unsupervised Learning with the Sparse Manifold Transform",
                "abstract": "We describe a minimalistic and interpretable method for unsupervised learning, without resorting to data augmentation, hyperparameter tuning, or other engineering designs, that achieves performance close to the SOTA SSL methods. Our approach leverages the sparse manifold transform, which unifies sparse coding, manifold learning, and slow feature analysis. With a one-layer deterministic sparse manifold transform, one can achieve 99.3% KNN top-1 accuracy on MNIST, 81.1% KNN top-1 accuracy on CIFAR-10 and 53.2% on CIFAR-100. With a simple gray-scale augmentation, the model gets 83.2% KNN top-1 accuracy on CIFAR-10 and 57% on CIFAR-100. These results significantly close the gap between simplistic\"white-box\"methods and the SOTA methods. Additionally, we provide visualization to explain how an unsupervised representation transform is formed. The proposed method is closely connected to latent-embedding self-supervised methods and can be treated as the simplest form of VICReg. Though there remains a small performance gap between our simple constructive model and SOTA methods, the evidence points to this as a promising direction for achieving a principled and white-box approach to unsupervised learning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109184424",
                        "name": "Yubei Chen"
                    },
                    {
                        "authorId": "2061343349",
                        "name": "Zeyu Yun"
                    },
                    {
                        "authorId": "144987142",
                        "name": "Y. Ma"
                    },
                    {
                        "authorId": "1708655",
                        "name": "B. Olshausen"
                    },
                    {
                        "authorId": "1688882",
                        "name": "Yann LeCun"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Tian et al. (2021) studies the effect of the non-linear predictor and stop-gradient in these methods and observe that both components are essential to prevent collapse."
            ],
            "citingPaper": {
                "paperId": "fd6afc90f46e016e0972066d6c517585bab47836",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-00092",
                    "ArXiv": "2210.00092",
                    "DOI": "10.48550/arXiv.2210.00092",
                    "CorpusId": 252683519
                },
                "corpusId": 252683519,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/fd6afc90f46e016e0972066d6c517585bab47836",
                "title": "Federated Training of Dual Encoding Models on Small Non-IID Client Datasets",
                "abstract": "Dual encoding models that encode a pair of inputs are widely used for representation learning. Many approaches train dual encoding models by maximizing agreement between pairs of encodings on centralized training data. However, in many scenarios, datasets are inherently decentralized across many clients (user devices or organizations) due to privacy concerns, motivating federated learning. In this work, we focus on federated training of dual encoding models on decentralized data composed of many small, non-IID (independent and identically distributed) client datasets. We show that existing approaches that work well in centralized settings perform poorly when naively adapted to this setting using federated averaging. We observe that, we can simulate large-batch loss computation on individual clients for loss functions that are based on encoding statistics. Based on this insight, we propose a novel federated training approach, Distributed Cross Correlation Optimization (DCCO), which trains dual encoding models using encoding statistics aggregated across clients, without sharing individual data samples. Our experimental results on two datasets demonstrate that the proposed DCCO approach outperforms federated variants of existing approaches by a large margin.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "39963722",
                        "name": "Raviteja Vemulapalli"
                    },
                    {
                        "authorId": "50528587",
                        "name": "W. Morningstar"
                    },
                    {
                        "authorId": "40390773",
                        "name": "P. A. Mansfield"
                    },
                    {
                        "authorId": "153086296",
                        "name": "Hubert Eichner"
                    },
                    {
                        "authorId": "122902793",
                        "name": "K. Singhal"
                    },
                    {
                        "authorId": "2469285",
                        "name": "Arash Afkanpour"
                    },
                    {
                        "authorId": "2056722536",
                        "name": "Bradley Green"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "result"
            ],
            "contexts": [
                "Some prior work has analyzed non-contrastive learning dynamics in a simple linear model [34], but analysis of when collapse happens is still ad hoc and largely anecdotal.",
                "Contrary to previous methods that claim that the stop-gradient, prediction head, and high predictor learning rate are enough to prevent the collapse [7,34], we show that collapse additionally depends on the model capacity relative to the data complexity.",
                "Understanding Self-supervised Learning [34] analyzes a surprisingly predictive linear model that represents the BYOL and SimSiam settings."
            ],
            "citingPaper": {
                "paperId": "568e80ac7555266516e24830b0d325daab6fc595",
                "externalIds": {
                    "ArXiv": "2209.15007",
                    "DBLP": "conf/eccv/LiEP22",
                    "DOI": "10.1007/978-3-031-19821-2_28",
                    "CorpusId": 252596511
                },
                "corpusId": 252596511,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/568e80ac7555266516e24830b0d325daab6fc595",
                "title": "Understanding Collapse in Non-contrastive Siamese Representation Learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2112518983",
                        "name": "Alexander C. Li"
                    },
                    {
                        "authorId": "1763086",
                        "name": "Alexei A. Efros"
                    },
                    {
                        "authorId": "38236002",
                        "name": "Deepak Pathak"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [
                "negative pairs, and ii) prevents representational collapse in an intuitive and explainable manner [15], unlike approaches such as BYOL [2] which are theoretically poorly understood (although some attempts have recently been made [16])."
            ],
            "citingPaper": {
                "paperId": "1cb8b22fcb74bf8a385c658478b9846af3f22c4e",
                "externalIds": {
                    "ArXiv": "2209.14345",
                    "DBLP": "journals/corr/abs-2209-14345",
                    "DOI": "10.48550/arXiv.2209.14345",
                    "CorpusId": 252595848
                },
                "corpusId": 252595848,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/1cb8b22fcb74bf8a385c658478b9846af3f22c4e",
                "title": "Audio Barlow Twins: Self-Supervised Audio Representation Learning",
                "abstract": "The Barlow Twins self-supervised learning objective requires neither negative samples or asymmetric learning updates, achieving results on a par with the current state-of-the-art within Computer Vision. As such, we present Audio Barlow Twins, a novel self-supervised audio representation learning approach, adapting Barlow Twins to the audio domain. We pre-train on the large-scale audio dataset AudioSet, and evaluate the quality of the learnt representations on 18 tasks from the HEAR 2021 Challenge, achieving results which outperform, or otherwise are on a par with, the current state-of-the-art for instance discrimination self-supervised learning approaches to audio representation learning. Code at https://github.com/jonahanton/SSL_audio.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2186403934",
                        "name": "Jonah Anton"
                    },
                    {
                        "authorId": "2043233315",
                        "name": "H. Coppock"
                    },
                    {
                        "authorId": "2180239698",
                        "name": "Pancham Shukla"
                    },
                    {
                        "authorId": "145411696",
                        "name": "Bj\u00f6rn Schuller"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "[24] performs a spectral analysis of DNN\u2019s mapping induced by non-contrastive loss and the momentum encoder approach.",
                "The main risk in such an approach is the so-called the feature collapse phenomenon [19, 24, 27], where the learned representations are invariant to input samples that belong to different manifolds."
            ],
            "citingPaper": {
                "paperId": "4255042a4c526fb89d84230c6a548c6d4d3b39f5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-08622",
                    "ArXiv": "2209.08622",
                    "DOI": "10.48550/arXiv.2209.08622",
                    "CorpusId": 252367257
                },
                "corpusId": 252367257,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4255042a4c526fb89d84230c6a548c6d4d3b39f5",
                "title": "The Geometry of Self-supervised Learning Models and its Impact on Transfer Learning",
                "abstract": "Self-supervised learning (SSL) has emerged as a desirable paradigm in computer vision due to the inability of supervised models to learn representations that can generalize in domains with limited labels. The recent popularity of SSL has led to the development of several models that make use of diverse training strategies, architectures, and data augmentation policies with no existing unified framework to study or assess their effectiveness in transfer learning. We propose a data-driven geometric strategy to analyze different SSL models using local neighborhoods in the feature space induced by each. Unlike existing approaches that consider mathematical approximations of the parameters, individual components, or optimization landscape, our work aims to explore the geometric properties of the representation manifolds learned by SSL models. Our proposed manifold graph metrics (MGMs) provide insights into the geometric similarities and differences between available SSL models, their invariances with respect to specific augmentations, and their performances on transfer learning tasks. Our key findings are two fold: (i) contrary to popular belief, the geometry of SSL models is not tied to its training paradigm (contrastive, non-contrastive, and cluster-based); (ii) we can predict the transfer learning capability for a specific model based on the geometric properties of its semantic and augmentation manifolds.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40125997",
                        "name": "R. Cosentino"
                    },
                    {
                        "authorId": "2125343433",
                        "name": "Sarath Shekkizhar"
                    },
                    {
                        "authorId": "2766123",
                        "name": "M. Soltanolkotabi"
                    },
                    {
                        "authorId": "5877233",
                        "name": "A. Avestimehr"
                    },
                    {
                        "authorId": "2079347891",
                        "name": "Antonio Ortega"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "c92464f04e9c2838cd2fdba4667dff402e938012",
                "externalIds": {
                    "ArXiv": "2209.07999",
                    "DBLP": "journals/corr/abs-2209-07999",
                    "DOI": "10.48550/arXiv.2209.07999",
                    "CorpusId": 252355134
                },
                "corpusId": 252355134,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/c92464f04e9c2838cd2fdba4667dff402e938012",
                "title": "Self-Supervised Learning with an Information Maximization Criterion",
                "abstract": "Self-supervised learning allows AI systems to learn effective representations from large amounts of data using tasks that do not require costly labeling. Mode collapse, i.e., the model producing identical representations for all inputs, is a central problem to many self-supervised learning approaches, making self-supervised tasks, such as matching distorted variants of the inputs, ineffective. In this article, we argue that a straightforward application of information maximization among alternative latent representations of the same input naturally solves the collapse problem and achieves competitive empirical results. We propose a self-supervised learning method, CorInfoMax, that uses a second-order statistics-based mutual information measure that reflects the level of correlation among its arguments. Maximizing this correlative information measure between alternative representations of the same input serves two purposes: (1) it avoids the collapse problem by generating feature vectors with non-degenerate covariances; (2) it establishes relevance among alternative representations by increasing the linear dependence among them. An approximation of the proposed information maximization objective simplifies to a Euclidean distance-based objective function regularized by the log-determinant of the feature covariance matrix. The regularization term acts as a natural barrier against feature space degeneracy. Consequently, beyond avoiding complete output collapse to a single point, the proposed approach also prevents dimensional collapse by encouraging the spread of information across the whole feature space. Numerical experiments demonstrate that CorInfoMax achieves better or competitive performance results relative to the state-of-the-art SSL approaches.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2185348472",
                        "name": "Serdar Ozsoy"
                    },
                    {
                        "authorId": "1832987156",
                        "name": "Shadi S. Hamdan"
                    },
                    {
                        "authorId": "2676352",
                        "name": "Sercan \u00d6. Arik"
                    },
                    {
                        "authorId": "2808366",
                        "name": "Deniz Yuret"
                    },
                    {
                        "authorId": "2130838",
                        "name": "A. Erdogan"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Most work [24, 25, 34, 36, 55, 103, 107, 108] in designing and understanding non-contrastive methods concerns how to avoid the \u201ccollapsing\u201d of the teacher to a constant.",
                "Many recent work [55, 103, 107, 108] have studied how distillating SSL methods work and the importance of optimization tricks such as stop-gradients, exponential moving average, and normalizations."
            ],
            "citingPaper": {
                "paperId": "bd1eb081b9e88857bf0f62ac5b51969004e5593f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-06235",
                    "ArXiv": "2209.06235",
                    "DOI": "10.48550/arXiv.2209.06235",
                    "CorpusId": 252222375
                },
                "corpusId": 252222375,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/bd1eb081b9e88857bf0f62ac5b51969004e5593f",
                "title": "Improving Self-Supervised Learning by Characterizing Idealized Representations",
                "abstract": "Despite the empirical successes of self-supervised learning (SSL) methods, it is unclear what characteristics of their representations lead to high downstream accuracies. In this work, we characterize properties that SSL representations should ideally satisfy. Specifically, we prove necessary and sufficient conditions such that for any task invariant to given data augmentations, desired probes (e.g., linear or MLP) trained on that representation attain perfect accuracy. These requirements lead to a unifying conceptual framework for improving existing SSL methods and deriving new ones. For contrastive learning, our framework prescribes simple but significant improvements to previous methods such as using asymmetric projection heads. For non-contrastive learning, we use our framework to derive a simple and novel objective. Our resulting SSL algorithms outperform baselines on standard benchmarks, including SwAV+multicrops on linear probing of ImageNet.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47367640",
                        "name": "Yann Dubois"
                    },
                    {
                        "authorId": "2117567142",
                        "name": "Tatsunori Hashimoto"
                    },
                    {
                        "authorId": "2490652",
                        "name": "Stefano Ermon"
                    },
                    {
                        "authorId": "145419642",
                        "name": "Percy Liang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "This can be indicated using the stop-gradient operation stopgrad(\u00b7) as follows [58,59]: z\u2032t S = stopgrad(E(\u015d \u2032t S )) (6)"
            ],
            "citingPaper": {
                "paperId": "4fb32a4da10bc4659b407367b24d3fd0969ac684",
                "externalIds": {
                    "PubMedCentral": "9502931",
                    "DBLP": "journals/sensors/DucTBTK22",
                    "DOI": "10.3390/s22186959",
                    "CorpusId": 252319411,
                    "PubMed": "36146306"
                },
                "corpusId": 252319411,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4fb32a4da10bc4659b407367b24d3fd0969ac684",
                "title": "Repetition-Based Approach for Task Adaptation in Imitation Learning",
                "abstract": "Transfer learning is an effective approach for adapting an autonomous agent to a new target task by transferring knowledge learned from the previously learned source task. The major problem with traditional transfer learning is that it only focuses on optimizing learning performance on the target task. Thus, the performance on the target task may be improved in exchange for the deterioration of the source task\u2019s performance, resulting in an agent that is not able to revisit the earlier task. Therefore, transfer learning methods are still far from being comparable with the learning capability of humans, as humans can perform well on both source and new target tasks. In order to address this limitation, a task adaptation method for imitation learning is proposed in this paper. Being inspired by the idea of repetition learning in neuroscience, the proposed adaptation method enables the agent to repeatedly review the learned knowledge of the source task, while learning the new knowledge of the target task. This ensures that the learning performance on the target task is high, while the deterioration of the learning performance on the source task is small. A comprehensive evaluation over several simulated tasks with varying difficulty levels shows that the proposed method can provide high and consistent performance on both source and target tasks, outperforming existing transfer learning methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2125663035",
                        "name": "Tho Nguyen Duc"
                    },
                    {
                        "authorId": "145111410",
                        "name": "Chanh Minh Tran"
                    },
                    {
                        "authorId": "144756231",
                        "name": "Nguyen Bach"
                    },
                    {
                        "authorId": "79397918",
                        "name": "Phan Xuan Tan"
                    },
                    {
                        "authorId": "1740935",
                        "name": "E. Kamioka"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Families of Models Model Rationale Representative Strategies and Methods\nPretext tasks Pixel-level reconstruction [124], [125], inpainting [126], MAE [127], denoising [128], colorization [129], [130], [131] Instance-level predict image rotations [123], scaling and tiling [122], patch ordering [11], patch re-ordering [121]\nDiscriminative models Instance discrimination negative sampling large batch size (SimLR [12]), memory bank (InstDis [132]), queue (MoCo [16]) input transformation data augmentation (PIRL [133]), multi-view augmentation (CMC [134]) negative-sample-free simple siamese (SimSiam [135]), Bootstrap (BYOL [136]), DirectPred [137]\nDeep clustering offline clustering DeepCluster [138], JULE [139], SeLa [140] online clustering IIC [141], PICA [142], AssociativeCluster [143], SwAV [144]\nDeep generative models Discriminator-level DCGAN [145], Self-supervised GAN [146], Transformation GAN [147] Generator-level BiGAN [148], BigBiGAN [149]\n\u2713",
                "negative-sample-free simple siamese (SimSiam [135]), Bootstrap (BYOL [136]), DirectPred [137]",
                "(12)), another alternative non-contrastive scheme for instance discrimintation operates in a negativesample-free manner [135], [136], [137], [181], as exemplified by bootstrap (BYOL) [136] and simple siamese networks (SimSiam) [135])."
            ],
            "citingPaper": {
                "paperId": "a2b27aaeb8d1f66b2bfaa438c1f31d5f39552a15",
                "externalIds": {
                    "ArXiv": "2208.11296",
                    "DBLP": "journals/corr/abs-2208-11296",
                    "DOI": "10.1109/TPAMI.2022.3201576",
                    "CorpusId": 251765280,
                    "PubMed": "36006881"
                },
                "corpusId": 251765280,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a2b27aaeb8d1f66b2bfaa438c1f31d5f39552a15",
                "title": "Semi-Supervised and Unsupervised Deep Visual Learning: A Survey",
                "abstract": "State-of-the-art deep learning models are often trained with a large amount of costly labeled training data. However, requiring exhaustive manual annotations may degrade the model's generalizability in the limited-label regime.Semi-supervised learning and unsupervised learning offer promising paradigms to learn from an abundance of unlabeled visual data. Recent progress in these paradigms has indicated the strong benefits of leveraging unlabeled data to improve model generalization and provide better model initialization. In this survey, we review the recent advanced deep learning algorithms on semi-supervised learning (SSL) and unsupervised learning (UL) for visual recognition from a unified perspective. To offer a holistic understanding of the state-of-the-art in these areas, we propose a unified taxonomy. We categorize existing representative SSL and UL with comprehensive and insightful analysis to highlight their design rationales in different learning scenarios and applications in different computer vision tasks. Lastly, we discuss the emerging trends and open challenges in SSL and UL to shed light on future critical research directions.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "6529501",
                        "name": "Yanbei Chen"
                    },
                    {
                        "authorId": "38286801",
                        "name": "Massimiliano Mancini"
                    },
                    {
                        "authorId": "2171228",
                        "name": "Xiatian Zhu"
                    },
                    {
                        "authorId": "2893664",
                        "name": "Zeynep Akata"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "a2bf37d8047735bb6e1f1a59d01aaf1335b5ba75",
                "externalIds": {
                    "DBLP": "conf/nips/TrivediLHKT22",
                    "ArXiv": "2208.02810",
                    "CorpusId": 253224446
                },
                "corpusId": 253224446,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a2bf37d8047735bb6e1f1a59d01aaf1335b5ba75",
                "title": "Analyzing Data-Centric Properties for Graph Contrastive Learning",
                "abstract": "Recent analyses of self-supervised learning (SSL) find the following data-centric properties to be critical for learning good representations: invariance to task-irrelevant semantics, separability of classes in some latent space, and recoverability of labels from augmented samples. However, given their discrete, non-Euclidean nature, graph datasets and graph SSL methods are unlikely to satisfy these properties. This raises the question: how do graph SSL methods, such as contrastive learning (CL), work well? To systematically probe this question, we perform a generalization analysis for CL when using generic graph augmentations (GGAs), with a focus on data-centric properties. Our analysis yields formal insights into the limitations of GGAs and the necessity of task-relevant augmentations. As we empirically show, GGAs do not induce task-relevant invariances on common benchmark datasets, leading to only marginal gains over naive, untrained baselines. Our theory motivates a synthetic data generation process that enables control over task-relevant information and boasts pre-defined optimal augmentations. This flexible benchmark helps us identify yet unrecognized limitations in advanced augmentation techniques (e.g., automated methods). Overall, our work rigorously contextualizes, both empirically and theoretically, the effects of data-centric properties on augmentation strategies and learning paradigms for graph SSL.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "30440868",
                        "name": "Puja Trivedi"
                    },
                    {
                        "authorId": "35573359",
                        "name": "E. S. Lubana"
                    },
                    {
                        "authorId": "35505461",
                        "name": "Mark Heimann"
                    },
                    {
                        "authorId": "2479152",
                        "name": "Danai Koutra"
                    },
                    {
                        "authorId": "2064767378",
                        "name": "J. Thiagarajan"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Without contrasting negative instances, the training process of non-contrastive methods is more efficient and conceptually simple [52, 55].",
                "To solve this problem, some non-contrastive approaches are developed with only using positive pairs but achieving remarkable performance, such as BYOL [53], SwAV [54], SimSiam [55], DirectPred [52], and DINO [19].",
                "constructed and need a large batch size or memory bank for storage [52]."
            ],
            "citingPaper": {
                "paperId": "3ad827c77a20e210c5222e1a7792b7464a817162",
                "externalIds": {
                    "ArXiv": "2208.00979",
                    "DBLP": "journals/corr/abs-2208-00979",
                    "DOI": "10.48550/arXiv.2208.00979",
                    "CorpusId": 251223968
                },
                "corpusId": 251223968,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3ad827c77a20e210c5222e1a7792b7464a817162",
                "title": "Automatically Discovering Novel Visual Categories with Self-supervised Prototype Learning",
                "abstract": "This paper tackles the problem of novel category discovery (NCD), which aims to discriminate unknown categories in large-scale image collections. The NCD task is challenging due to the closeness to the real-world scenarios, where we have only encountered some partial classes and images. Unlike other works on the NCD, we leverage the prototypes to emphasize the importance of category discrimination and alleviate the issue of missing annotations of novel classes. Concretely, we propose a novel adaptive prototype learning method consisting of two main stages: prototypical representation learning and prototypical self-training. In the first stage, we obtain a robust feature extractor, which could serve for all images with base and novel categories. This ability of instance and category discrimination of the feature extractor is boosted by self-supervised learning and adaptive prototypes. In the second stage, we utilize the prototypes again to rectify offline pseudo labels and train a final parametric classifier for category clustering. We conduct extensive experiments on four benchmark datasets and demonstrate the effectiveness and robustness of the proposed method with state-of-the-art performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2156144478",
                        "name": "Lu Zhang"
                    },
                    {
                        "authorId": "2114129710",
                        "name": "Lu Qi"
                    },
                    {
                        "authorId": "144262997",
                        "name": "Xu Yang"
                    },
                    {
                        "authorId": "145158703",
                        "name": "Hong Qiao"
                    },
                    {
                        "authorId": "152790163",
                        "name": "Ming Yang"
                    },
                    {
                        "authorId": "1715181",
                        "name": "Zhiyong Liu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "However, an implicit contrast is applied by the batch normalization layer in the implemented network [75, 79]."
            ],
            "citingPaper": {
                "paperId": "569ba1ef5db91bc5ecb49c8beb2a14633f4e3159",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-00467",
                    "ArXiv": "2208.00467",
                    "DOI": "10.1145/3550316",
                    "CorpusId": 251224140
                },
                "corpusId": 251224140,
                "publicationVenue": {
                    "id": "4c51a870-1809-485b-8c20-3c1326b3fe16",
                    "name": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies",
                    "alternate_names": [
                        "Proc ACM Interact Mob Wearable Ubiquitous Technol"
                    ],
                    "issn": "2474-9567",
                    "url": "https://dl.acm.org/journal/imwut",
                    "alternate_urls": [
                        "http://imwut.acm.org/",
                        "https://dl.acm.org/pub.cfm?id=J1566"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/569ba1ef5db91bc5ecb49c8beb2a14633f4e3159",
                "title": "COCOA",
                "abstract": "Self-Supervised Learning (SSL) is a new paradigm for learning discriminative representations without labeled data, and has reached comparable or even state-of-the-art results in comparison to supervised counterparts. Contrastive Learning (CL) is one of the most well-known approaches in SSL that attempts to learn general, informative representations of data. CL methods have been mostly developed for applications in computer vision and natural language processing where only a single sensor modality is used. A majority of pervasive computing applications, however, exploit data from a range of different sensor modalities. While existing CL methods are limited to learning from one or two data sources, we propose COCOA (Cross mOdality COntrastive leArning), a self-supervised model that employs a novel objective function to learn quality representations from multisensor data by computing the cross-correlation between different data modalities and minimizing the similarity between irrelevant instances. We evaluate the effectiveness of COCOA against eight recently introduced state-of-the-art self-supervised models, and two supervised baselines across five public datasets. We show that COCOA achieves superior classification performance to all other approaches. Also, COCOA is far more label-efficient than the other baselines including the fully supervised model using only one-tenth of available labeled data.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1864633127",
                        "name": "Shohreh Deldari"
                    },
                    {
                        "authorId": "2099127073",
                        "name": "Hao Xue"
                    },
                    {
                        "authorId": "9261711",
                        "name": "Aaqib Saeed"
                    },
                    {
                        "authorId": "2143623845",
                        "name": "Daniel V. Smith"
                    },
                    {
                        "authorId": "144954586",
                        "name": "Flora D. Salim"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Later work [42] concentrates on the theoretical influence of the asymmetric network structures.",
                "There are follow-up studies on the asymmetric structure that are mainly about the theoretical understanding [42,9] and the effectiveness for linear classification [9,10]."
            ],
            "citingPaper": {
                "paperId": "c7c41c55057fc0c5541e5811a3a52a7fce878c59",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-00275",
                    "ArXiv": "2208.00275",
                    "DOI": "10.48550/arXiv.2208.00275",
                    "CorpusId": 251223578
                },
                "corpusId": 251223578,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/c7c41c55057fc0c5541e5811a3a52a7fce878c59",
                "title": "Revisiting the Critical Factors of Augmentation-Invariant Representation Learning",
                "abstract": "We focus on better understanding the critical factors of augmentation-invariant representation learning. We revisit MoCo v2 and BYOL and try to prove the authenticity of the following assumption: different frameworks bring about representations of different characteristics even with the same pretext task. We establish the first benchmark for fair comparisons between MoCo v2 and BYOL, and observe: (i) sophisticated model configurations enable better adaptation to pre-training dataset; (ii) mismatched optimization strategies of pre-training and fine-tuning hinder model from achieving competitive transfer performances. Given the fair benchmark, we make further investigation and find asymmetry of network structure endows contrastive frameworks to work well under the linear evaluation protocol, while may hurt the transfer performances on long-tailed classification tasks. Moreover, negative samples do not make models more sensible to the choice of data augmentations, nor does the asymmetric network structure. We believe our findings provide useful information for future work.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118226548",
                        "name": "Junqiang Huang"
                    },
                    {
                        "authorId": "2069029697",
                        "name": "Xiangwen Kong"
                    },
                    {
                        "authorId": "2180046336",
                        "name": "Xiangyu Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "In such methods, using various architecture tricks (like prediction head, stop-gradient, momentum encoder, batch normalization or centering) is shown empirically to be sufficient to avoid collapse without instance discrimination, even though it is not fully understood how these multiple factors induce a regularization during training (Richemond et al., 2020; Tian et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "cde535c74312f61d71a7649afb474259c600433d",
                "externalIds": {
                    "DBLP": "conf/iclr/ZhengPRPG23",
                    "ArXiv": "2208.00789",
                    "DOI": "10.48550/arXiv.2208.00789",
                    "CorpusId": 251223862
                },
                "corpusId": 251223862,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/cde535c74312f61d71a7649afb474259c600433d",
                "title": "Self-supervised learning with rotation-invariant kernels",
                "abstract": "We introduce a regularization loss based on kernel mean embeddings with rotation-invariant kernels on the hypersphere (also known as dot-product kernels) for self-supervised learning of image representations. Besides being fully competitive with the state of the art, our method significantly reduces time and memory complexity for self-supervised training, making it implementable for very large embedding dimensions on existing devices and more easily adjustable than previous methods to settings with limited resources. Our work follows the major paradigm where the model learns to be invariant to some predefined image transformations (cropping, blurring, color jittering, etc.), while avoiding a degenerate solution by regularizing the embedding distribution. Our particular contribution is to propose a loss family promoting the embedding distribution to be close to the uniform distribution on the hypersphere, with respect to the maximum mean discrepancy pseudometric. We demonstrate that this family encompasses several regularizers of former methods, including uniformity-based and information-maximization methods, which are variants of our flexible regularization loss with different kernels. Beyond its practical consequences for state-of-the-art self-supervised learning with limited resources, the proposed generic regularization approach opens perspectives to leverage more widely the literature on kernel methods in order to improve self-supervised learning methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2143390934",
                        "name": "L\u00e9on Zheng"
                    },
                    {
                        "authorId": "3242930",
                        "name": "Gilles Puy"
                    },
                    {
                        "authorId": "3395846",
                        "name": "E. Riccietti"
                    },
                    {
                        "authorId": "2173636176",
                        "name": "Patrick P'erez"
                    },
                    {
                        "authorId": "1731535",
                        "name": "R. Gribonval"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Relation-based approaches learn features to increase the similarity among a sample [6, 10, 11, 25, 54] and its transformed positive instances while some also treat other training samples as negative instances."
            ],
            "citingPaper": {
                "paperId": "9ce80440a79b6224aae557fab89239afedc74943",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-10023",
                    "ArXiv": "2207.10023",
                    "DOI": "10.48550/arXiv.2207.10023",
                    "CorpusId": 250699285
                },
                "corpusId": 250699285,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/9ce80440a79b6224aae557fab89239afedc74943",
                "title": "Tailoring Self-Supervision for Supervised Learning",
                "abstract": ". Recently, it is shown that deploying a proper self-supervision is a prospective way to enhance the performance of supervised learning. Yet, the benefits of self-supervision are not fully exploited as previous pretext tasks are specialized for unsupervised representation learning. To this end, we begin by presenting three desirable properties for such auxiliary tasks to assist the supervised objective. First, the tasks need to guide the model to learn rich features. Second, the transformations involved in the self-supervision should not significantly alter the training distribution. Third, the tasks are preferred to be light and generic for high applicability to prior arts. Subsequently, to show how existing pretext tasks can fulfill these and be tailored for supervised learning, we propose a simple auxiliary self-supervision task, predicting localizable rotation ( LoRot ). Our exhaustive experiments validate the merits of LoRot as a pretext task tailored for supervised learning in terms of robustness and generalization capability. Our code is available at https://github.com/wjun0830/Localizable-Rotation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2067245729",
                        "name": "WonJun Moon"
                    },
                    {
                        "authorId": "91999133",
                        "name": "Jihwan Kim"
                    },
                    {
                        "authorId": "7212202",
                        "name": "Jae-Pil Heo"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Some recent works [12,27,72] introduce asymmetry in the alignment of the positive pair to learn meaningful representations without explicit uniformity."
            ],
            "citingPaper": {
                "paperId": "32ff43704a04191cf0b90a1dac7cbbc8f5df12a3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-09176",
                    "ArXiv": "2207.09176",
                    "DOI": "10.48550/arXiv.2207.09176",
                    "CorpusId": 250643930
                },
                "corpusId": 250643930,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/32ff43704a04191cf0b90a1dac7cbbc8f5df12a3",
                "title": "Self-Supervision Can Be a Good Few-Shot Learner",
                "abstract": "Existing few-shot learning (FSL) methods rely on training with a large labeled dataset, which prevents them from leveraging abundant unlabeled data. From an information-theoretic perspective, we propose an effective unsupervised FSL method, learning representations with self-supervision. Following the InfoMax principle, our method learns comprehensive representations by capturing the intrinsic structure of the data. Specifically, we maximize the mutual information (MI) of instances and their representations with a low-bias MI estimator to perform self-supervised pre-training. Rather than supervised pre-training focusing on the discriminable features of the seen classes, our self-supervised model has less bias toward the seen classes, resulting in better generalization for unseen classes. We explain that supervised pre-training and self-supervised pre-training are actually maximizing different MI objectives. Extensive experiments are further conducted to analyze their FSL performance with various training settings. Surprisingly, the results show that self-supervised pre-training can outperform supervised pre-training under the appropriate conditions. Compared with state-of-the-art FSL methods, our approach achieves comparable performance on widely used FSL benchmarks without any labels of the base classes.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2159316456",
                        "name": "Yuning Lu"
                    },
                    {
                        "authorId": "147383784",
                        "name": "Liangjiang Wen"
                    },
                    {
                        "authorId": "2144167531",
                        "name": "Jianzhuang Liu"
                    },
                    {
                        "authorId": "2144470300",
                        "name": "Yajing Liu"
                    },
                    {
                        "authorId": "40434674",
                        "name": "Xinmei Tian"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Furthermore, it has been shown that the stop-grad operation is critical to avoid the problem of complete collapse in the representations (Tian et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "632841ebaf485cd55e225ce8fb7e03fae6dedd3a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-04812",
                    "ArXiv": "2207.04812",
                    "DOI": "10.48550/arXiv.2207.04812",
                    "CorpusId": 250426684,
                    "PubMed": "37207397"
                },
                "corpusId": 250426684,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/632841ebaf485cd55e225ce8fb7e03fae6dedd3a",
                "title": "A clinically motivated self-supervised approach for content-based image retrieval of CT liver images",
                "abstract": "Deep learning-based approaches for content-based image retrieval (CBIR) of computed tomography (CT) liver images is an active field of research, but suffer from some critical limitations. First, they are heavily reliant on labeled data, which can be challenging and costly to acquire. Second, they lack transparency and explainability, which limits the trustworthiness of deep CBIR systems. We address these limitations by: (1) Proposing a self-supervised learning framework that incorporates domain-knowledge into the training procedure, and, (2) by providing the first representation learning explainability analysis in the context of CBIR of CT liver images. Results demonstrate improved performance compared to the standard self-supervised approach across several metrics, as well as improved generalization across datasets. Further, we conduct the first representation learning explainability analysis in the context of CBIR, which reveals new insights into the feature extraction process. Lastly, we perform a case study with cross-examination CBIR that demonstrates the usability of our proposed framework. We believe that our proposed framework could play a vital role in creating trustworthy deep CBIR systems that can successfully take advantage of unlabeled data.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1387887318",
                        "name": "Kristoffer Wickstr\u00f8m"
                    },
                    {
                        "authorId": "2175653689",
                        "name": "Eirik Agnalt Ostmo"
                    },
                    {
                        "authorId": "2175653015",
                        "name": "Keyur Radiya"
                    },
                    {
                        "authorId": "1700727",
                        "name": "Karl \u00d8yvind Mikalsen"
                    },
                    {
                        "authorId": "8199702",
                        "name": "Michael C. Kampffmeyer"
                    },
                    {
                        "authorId": "1747567",
                        "name": "R. Jenssen"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Second, we construct a framework to abstract and maximize similarity object-level agreement (foreground and background) across different views beyond augmentations of the same image [13,18,23]."
            ],
            "citingPaper": {
                "paperId": "f754244db26470d21b49843b2b12ae3532fcf278",
                "externalIds": {
                    "PubMedCentral": "9320898",
                    "DBLP": "journals/sensors/TranLLW22",
                    "DOI": "10.3390/s22145169",
                    "CorpusId": 250469741,
                    "PubMed": "35890847"
                },
                "corpusId": 250469741,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f754244db26470d21b49843b2b12ae3532fcf278",
                "title": "Heuristic Attention Representation Learning for Self-Supervised Pretraining",
                "abstract": "Recently, self-supervised learning methods have been shown to be very powerful and efficient for yielding robust representation learning by maximizing the similarity across different augmented views in embedding vector space. However, the main challenge is generating different views with random cropping; the semantic feature might exist differently across different views leading to inappropriately maximizing similarity objective. We tackle this problem by introducing Heuristic Attention Representation Learning (HARL). This self-supervised framework relies on the joint embedding architecture in which the two neural networks are trained to produce similar embedding for different augmented views of the same image. HARL framework adopts prior visual object-level attention by generating a heuristic mask proposal for each training image and maximizes the abstract object-level embedding on vector space instead of whole image representation from previous works. As a result, HARL extracts the quality semantic representation from each training sample and outperforms existing self-supervised baselines on several downstream tasks. In addition, we provide efficient techniques based on conventional computer vision and deep learning methods for generating heuristic mask proposals on natural image datasets. Our HARL achieves +1.3% advancement in the ImageNet semi-supervised learning benchmark and +0.9% improvement in AP50 of the COCO object detection task over the previous state-of-the-art method BYOL. Our code implementation is available for both TensorFlow and PyTorch frameworks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2166134967",
                        "name": "Van-Nhiem Tran"
                    },
                    {
                        "authorId": "122051172",
                        "name": "Shenxiu Liu"
                    },
                    {
                        "authorId": "3036546",
                        "name": "Yung-Hui Li"
                    },
                    {
                        "authorId": "2145277958",
                        "name": "Jia-Ching Wang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Moreover, it pushes the anchor embedding similar to positive emedding and dissimilar to negative embedding [Tian et al., 2021]."
            ],
            "citingPaper": {
                "paperId": "b67d56604c3bd9ea3f9943c844ab450b3fb682d3",
                "externalIds": {
                    "DBLP": "conf/ijcai/GanHZMW022",
                    "DOI": "10.24963/ijcai.2022/414",
                    "CorpusId": 250639485
                },
                "corpusId": 250639485,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/b67d56604c3bd9ea3f9943c844ab450b3fb682d3",
                "title": "Multi-view Unsupervised Graph Representation Learning",
                "abstract": "Both data augmentation and contrastive loss are the key components of contrastive learning. In this paper, we design a new multi-view unsupervised graph representation learning method including adaptive data augmentation and multi-view contrastive learning, to address some issues of contrastive learning ignoring the information from feature space. Specifically, the adaptive data augmentation first builds a feature graph from the feature space, and then designs a deep graph learning model on the original representation and the topology graph to update the feature graph and the new representation. As a result, the adaptive data augmentation outputs multi-view information, which is fed into two GCNs to generate multi-view embedding features. Two kinds of contrastive losses are further designed on multi-view embedding features to explore the complementary information among the topology and feature graphs. Additionally, adaptive data augmentation and contrastive learning are embedded in a unified framework to form an end-to-end model. Experimental results verify the effectiveness of our proposed method, compared to state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51055866",
                        "name": "Jiangzhang Gan"
                    },
                    {
                        "authorId": "4478507",
                        "name": "Rongyao Hu"
                    },
                    {
                        "authorId": "1500650084",
                        "name": "Mengmeng Zhan"
                    },
                    {
                        "authorId": "2161513927",
                        "name": "Yujie Mo"
                    },
                    {
                        "authorId": "2159760916",
                        "name": "Yingying Wan"
                    },
                    {
                        "authorId": "46875503",
                        "name": "Xiao-lan Zhu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Then, DirectPred (Tian et al., 2021) provides theoretical analysis to verify the effectiveness of BYOL."
            ],
            "citingPaper": {
                "paperId": "6d8ab0c920c2cf6aac8bc17bc425dd1553ede667",
                "externalIds": {
                    "ArXiv": "2206.14702",
                    "DBLP": "conf/icml/QiangLZ0X22",
                    "DOI": "10.48550/arXiv.2206.14702",
                    "CorpusId": 250113579
                },
                "corpusId": 250113579,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/6d8ab0c920c2cf6aac8bc17bc425dd1553ede667",
                "title": "Interventional Contrastive Learning with Meta Semantic Regularizer",
                "abstract": "Contrastive learning (CL)-based self-supervised learning models learn visual representations in a pairwise manner. Although the prevailing CL model has achieved great progress, in this paper, we uncover an ever-overlooked phenomenon: When the CL model is trained with full images, the performance tested in full images is better than that in foreground areas; when the CL model is trained with foreground areas, the performance tested in full images is worse than that in foreground areas. This observation reveals that backgrounds in images may interfere with the model learning semantic information and their influence has not been fully eliminated. To tackle this issue, we build a Structural Causal Model (SCM) to model the background as a confounder. We propose a backdoor adjustment-based regularization method, namely Interventional Contrastive Learning with Meta Semantic Regularizer (ICL-MSR), to perform causal intervention towards the proposed SCM. ICL-MSR can be incorporated into any existing CL methods to alleviate background distractions from representation learning. Theoretically, we prove that ICL-MSR achieves a tighter error bound. Empirically, our experiments on multiple benchmark datasets demonstrate that ICL-MSR is able to improve the performances of different state-of-the-art CL methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2059455684",
                        "name": "Wenwen Qiang"
                    },
                    {
                        "authorId": "2118506408",
                        "name": "Jiangmeng Li"
                    },
                    {
                        "authorId": "2153619515",
                        "name": "Changwen Zheng"
                    },
                    {
                        "authorId": "2100573353",
                        "name": "Bing Su"
                    },
                    {
                        "authorId": "2054473562",
                        "name": "Hui Xiong"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "There are already some works like SimSiam [84] and [249] that try to investigate the underline theory, yet they are not enough."
            ],
            "citingPaper": {
                "paperId": "cfd94ae8dd48c695cd0d0d63cd67573bd5310f87",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-13188",
                    "ArXiv": "2206.13188",
                    "DOI": "10.1109/MGRS.2022.3198244",
                    "CorpusId": 250072803
                },
                "corpusId": 250072803,
                "publicationVenue": {
                    "id": "f3b9cfef-ea93-4f7f-a14f-95fbf796875e",
                    "name": "IEEE Geoscience and Remote Sensing Magazine",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Geosci Remote Sens Mag"
                    ],
                    "issn": "2168-6831",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6245518",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6245518",
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6245518"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/cfd94ae8dd48c695cd0d0d63cd67573bd5310f87",
                "title": "Self-Supervised Learning in Remote Sensing: A review",
                "abstract": "In deep learning research, self-supervised learning (SSL) has received great attention, triggering interest within both the computer vision and remote sensing communities. While there has been big success in computer vision, most of the potential of SSL in the domain of Earth observation remains locked. In this article, we provide an introduction to and a review of the concepts and latest developments in SSL for computer vision in the context of remote sensing. Further, we provide a preliminary benchmark of modern SSL algorithms on popular remote sensing datasets, verifying the potential of SSL in remote sensing and providing an extended study on data augmentations. Finally, we identify a list of promising directions of future research in SSL for Earth observation (SSL4EO) to pave the way for the fruitful interaction of both domains.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2154461554",
                        "name": "Yi Wang"
                    },
                    {
                        "authorId": "11969645",
                        "name": "C. Albrecht"
                    },
                    {
                        "authorId": "2151803043",
                        "name": "Nassim Ait Ali Braham"
                    },
                    {
                        "authorId": "35041003",
                        "name": "Lichao Mou"
                    },
                    {
                        "authorId": "2125159330",
                        "name": "Xiao Xiang Zhu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "2fd346e7edf0ec9de793c96acb0a1e3f2f8a2718",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-08332",
                    "ArXiv": "2206.08332",
                    "DOI": "10.48550/arXiv.2206.08332",
                    "CorpusId": 249712461
                },
                "corpusId": 249712461,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2fd346e7edf0ec9de793c96acb0a1e3f2f8a2718",
                "title": "BYOL-Explore: Exploration by Bootstrapped Prediction",
                "abstract": "We present BYOL-Explore, a conceptually simple yet general approach for curiosity-driven exploration in visually-complex environments. BYOL-Explore learns a world representation, the world dynamics, and an exploration policy all-together by optimizing a single prediction loss in the latent space with no additional auxiliary objective. We show that BYOL-Explore is effective in DM-HARD-8, a challenging partially-observable continuous-action hard-exploration benchmark with visually-rich 3-D environments. On this benchmark, we solve the majority of the tasks purely through augmenting the extrinsic reward with BYOL-Explore s intrinsic reward, whereas prior work could only get off the ground with human demonstrations. As further evidence of the generality of BYOL-Explore, we show that it achieves superhuman performance on the ten hardest exploration games in Atari while having a much simpler design than other competitive agents.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3407143",
                        "name": "Z. Guo"
                    },
                    {
                        "authorId": "41037204",
                        "name": "Shantanu Thakoor"
                    },
                    {
                        "authorId": "2007581998",
                        "name": "Miruna Pislar"
                    },
                    {
                        "authorId": "3429927",
                        "name": "B. '. Pires"
                    },
                    {
                        "authorId": "2064347514",
                        "name": "Florent Altch'e"
                    },
                    {
                        "authorId": "31803582",
                        "name": "Corentin Tallec"
                    },
                    {
                        "authorId": "16927419",
                        "name": "Alaa Saade"
                    },
                    {
                        "authorId": "2439765",
                        "name": "Daniele Calandriello"
                    },
                    {
                        "authorId": "145840757",
                        "name": "Jean-Bastien Grill"
                    },
                    {
                        "authorId": "11501567",
                        "name": "Yunhao Tang"
                    },
                    {
                        "authorId": "47948270",
                        "name": "M. Va\u013ako"
                    },
                    {
                        "authorId": "1708654",
                        "name": "R. Munos"
                    },
                    {
                        "authorId": "37666967",
                        "name": "M. G. Azar"
                    },
                    {
                        "authorId": "1808897",
                        "name": "Bilal Piot"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "To measure subspaces dimensionality, we compute the singular value decomposition on the covariance matrix Covx = U\u03a3V T ,\u03a3 = diag(\u03c3), following general practice in SSL theory [39, 73].",
                "[73] Yuandong Tian, Xinlei Chen, and Surya Ganguli."
            ],
            "citingPaper": {
                "paperId": "1eb0828f6bbfb4218c3e8c86d20385339b9ed25d",
                "externalIds": {
                    "ArXiv": "2206.06424",
                    "DBLP": "journals/corr/abs-2206-06424",
                    "DOI": "10.1109/CVPR52729.2023.01672",
                    "CorpusId": 249642189
                },
                "corpusId": 249642189,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1eb0828f6bbfb4218c3e8c86d20385339b9ed25d",
                "title": "Look, Radiate, and Learn: Self-Supervised Localisation via Radio-Visual Correspondence",
                "abstract": "Next generation cellular networks will implement radio sensing functions alongside customary communications, thereby enabling unprecedented worldwide sensing coverage outdoors. Deep learning has revolutionised computer vision but has had limited application to radio perception tasks, in part due to lack of systematic datasets and benchmarks dedicated to the study of the performance and promise of radio sensing. To address this gap, we present MaxRay: a synthetic radio-visual dataset and benchmark that facilitate precise target localisation in radio. We further propose to learn to localise targets in radio without supervision by extracting self-coordinates from radio-visual correspondence. We use such self-supervised coordinates to train a radio localiser network. We characterise our performance against a number of state-of-the-art baselines. Our results indicate that accurate radio target localisation can be automatically learned from paired radio-visual data without labels, which is important for empirical data. This opens the door for vast data scalability and may prove key to realising the promise of robust radio sensing atop a unified communication-perception cellular infrastructure. Dataset will be hosted on IEEE DataPort.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "30613079",
                        "name": "Mohammed Alloulah"
                    },
                    {
                        "authorId": "29253618",
                        "name": "Maximilian Arnold"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [
                "Subsequent theoretical analysis [12, 13, 14, 15] have demonstrated why these techniques can avoid trivial solutions and learn meaningful representations from different aspects."
            ],
            "citingPaper": {
                "paperId": "1da39c66a3a271e9af84e99e1c93c18ce8ef9716",
                "externalIds": {
                    "ArXiv": "2206.06461",
                    "DBLP": "journals/corr/abs-2206-06461",
                    "DOI": "10.48550/arXiv.2206.06461",
                    "CorpusId": 249642285
                },
                "corpusId": 249642285,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1da39c66a3a271e9af84e99e1c93c18ce8ef9716",
                "title": "Self-Supervised Representation Learning With MUlti-Segmental Informational Coding (MUSIC)",
                "abstract": "Self-supervised representation learning maps high-dimensional data into a meaningful embedding space, where samples of similar semantic contents are close to each other. Most of the recent representation learning methods maximize cosine similarity or minimize the distance between the embedding features of different views from the same sample usually on the l 2 normalized unit hypersphere. To prevent the trivial solutions that all samples have the same embedding feature, various techniques have been developed, such as contrastive learning, stop gradient, variance and covariance regularization, etc. In this study, we propose MUlti-Segmental Informational Coding (MUSIC) for self-supervised representation learning. MUSIC divides the embedding feature into multiple segments that discriminatively partition samples into different semantic clusters and different segments focus on different partition principles. Information theory measurements are directly used to optimize MUSIC and theoretically guarantee trivial solutions are avoided. MUSIC does not depend on commonly used techniques, such as memory bank or large batches, asymmetry networks, gradient stopping, momentum weight updating, etc, making the training framework \ufb02exible. Our experiments demonstrate that MUSIC achieves better results than most related Barlow Twins and VICReg methods on ImageNet classi\ufb01cation with linear probing, and requires neither deep projectors nor large feature dimensions. Code will be made available.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51431831",
                        "name": "Chuang Niu"
                    },
                    {
                        "authorId": "2108296864",
                        "name": "Ge Wang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [
                ", contrastive learning [7], [35], [36], [37], [38], [39], [40], self-clustering [41], [42], [43], and representation alignment [5], [6], [44], [45], [46], [47]."
            ],
            "citingPaper": {
                "paperId": "8ba3464273960b4146c5ff6845a3824edbbc7a56",
                "externalIds": {
                    "ArXiv": "2206.05184",
                    "DBLP": "journals/corr/abs-2206-05184",
                    "DOI": "10.48550/arXiv.2206.05184",
                    "CorpusId": 249605720,
                    "PubMed": "37647184"
                },
                "corpusId": 249605720,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8ba3464273960b4146c5ff6845a3824edbbc7a56",
                "title": "Exploring Feature Self-relation for Self-supervised Transformer",
                "abstract": "Learning representations with self-supervision for convolutional networks (CNN) has been validated to be effective for vision tasks. As an alternative to CNN, vision transformers\u00a0(ViT) have strong representation ability with spatial self-attention and channel-level feedforward networks. Recent works reveal that self-supervised learning helps unleash the great potential of ViT. Still, most works follow self-supervised strategies designed for CNN, e.g.,\u00a0instance-level discrimination of samples, but they ignore the properties of ViT. We observe that relational modeling on spatial and channel dimensions distinguishes ViT from other networks. To enforce this property, we explore the feature SElf-RElation\u00a0(SERE) for training self-supervised ViT. Specifically, instead of conducting self-supervised learning solely on feature embeddings from multiple views, we utilize the feature self-relations, i.e.,\u00a0spatial/channel self-relations, for self-supervised learning. Self-relation based learning further enhances the relation modeling ability of ViT, resulting in stronger representations that stably improve performance on multiple downstream tasks. Our source code is publicly available.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2145415334",
                        "name": "Zhong-Yu Li"
                    },
                    {
                        "authorId": "3180489",
                        "name": "Shanghua Gao"
                    },
                    {
                        "authorId": "2149615771",
                        "name": "Ming-Ming Cheng"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "The terms in Equation 1 can be decomposed using a variance-covariance perspective [31]."
            ],
            "citingPaper": {
                "paperId": "8cff0bbd8133d5b67b079cbb4fe23eedaea5e0ad",
                "externalIds": {
                    "DBLP": "journals/ijon/PassosPHA23",
                    "ArXiv": "2206.02671",
                    "DOI": "10.1016/j.neucom.2022.11.081",
                    "CorpusId": 249394878
                },
                "corpusId": 249394878,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8cff0bbd8133d5b67b079cbb4fe23eedaea5e0ad",
                "title": "Canonical cortical graph neural networks and its application for speech enhancement in audio-visual hearing aids",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "39795571",
                        "name": "L. A. Passos"
                    },
                    {
                        "authorId": "1759037",
                        "name": "J. Papa"
                    },
                    {
                        "authorId": "2117797510",
                        "name": "Amir Hussain"
                    },
                    {
                        "authorId": "2064500",
                        "name": "Ahsan Adeel"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "The fact that a method like SimSiam does not collapse is studied in [29].",
                "The fact that a method like SimSiam does not collapse is studied in Tian et al. (2021).",
                "Even though they do not avoid collapse explicitly through their criteria, recent works such as Halvagal et al. (2022) or Theorem 3 from Tian et al. (2021) have shown links between the training dynamics of SimSiam and variance and covariance regularization, akin to what Lnc would lead to."
            ],
            "citingPaper": {
                "paperId": "11c16254f7b61687b5d9b7637de032461a6ebb5f",
                "externalIds": {
                    "DBLP": "conf/iclr/GarridoCBNL23",
                    "ArXiv": "2206.02574",
                    "DOI": "10.48550/arXiv.2206.02574",
                    "CorpusId": 249395677
                },
                "corpusId": 249395677,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/11c16254f7b61687b5d9b7637de032461a6ebb5f",
                "title": "On the duality between contrastive and non-contrastive self-supervised learning",
                "abstract": "Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new approaches, we focus more on the theoretical similarities between them. By designing contrastive and covariance based non-contrastive criteria that can be related algebraically and shown to be equivalent under limited assumptions, we show how close those families can be. We further study popular methods and introduce variations of them, allowing us to relate this theoretical result to current practices and show the influence (or lack thereof) of design choices on downstream performance. Motivated by our equivalence result, we investigate the low performance of SimCLR and show how it can match VICReg's with careful hyperparameter tuning, improving significantly over known baselines. We also challenge the popular assumption that non-contrastive methods need large output dimensions. Our theoretical and quantitative results suggest that the numerical gaps between contrastive and non-contrastive methods in certain regimes can be closed given better network design choices and hyperparameter tuning. The evidence shows that unifying different SOTA methods is an important direction to build a better understanding of self-supervised learning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2048163343",
                        "name": "Q. Garrido"
                    },
                    {
                        "authorId": "2109184424",
                        "name": "Yubei Chen"
                    },
                    {
                        "authorId": "1453740540",
                        "name": "Adrien Bardes"
                    },
                    {
                        "authorId": "1688714",
                        "name": "Laurent Najman"
                    },
                    {
                        "authorId": "1688882",
                        "name": "Yann LeCun"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "f5db3b0a99e9ab7777b2fecf8b5d237715a3464d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-01342",
                    "ArXiv": "2206.01342",
                    "DOI": "10.48550/arXiv.2206.01342",
                    "CorpusId": 249375359
                },
                "corpusId": 249375359,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/f5db3b0a99e9ab7777b2fecf8b5d237715a3464d",
                "title": "Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning",
                "abstract": "While the empirical success of self-supervised learning (SSL) heavily relies on the usage of deep nonlinear models, existing theoretical works on SSL understanding still focus on linear ones. In this paper, we study the role of nonlinearity in the training dynamics of contrastive learning (CL) on one and two-layer nonlinear networks with homogeneous activation $h(x) = h'(x)x$. We have two major theoretical discoveries. First, the presence of nonlinearity can lead to many local optima even in 1-layer setting, each corresponding to certain patterns from the data distribution, while with linear activation, only one major pattern can be learned. This suggests that models with lots of parameters can be regarded as a \\emph{brute-force} way to find these local optima induced by nonlinearity. Second, in the 2-layer case, linear activation is proven not capable of learning specialized weights into diverse patterns, demonstrating the importance of nonlinearity. In addition, for 2-layer setting, we also discover \\emph{global modulation}: those local patterns discriminative from the perspective of global-level patterns are prioritized to learn, further characterizing the learning process. Simulation verifies our theoretical findings.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1932187449",
                        "name": "Yuandong Tian"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "The work [32] replaces the encoder in BYOL with a two-layer model and gives a theoretical analysis of why the two models (online and target) do not collapse.",
                "This is often due to the lack of proper objective functions or architectures [6, 32].",
                "However, they suffer from the lack of explainability [32].",
                "1Note [32] provides an analysis of their learning dynamics with twolayer models, which accounts for the reason why the two models do not fail with trivial solutions."
            ],
            "citingPaper": {
                "paperId": "99588393c3addda9048f1814ecdc77d4ce5e7063",
                "externalIds": {
                    "DBLP": "conf/cvpr/ZhangQZYZZLY22",
                    "DOI": "10.1109/CVPR52688.2022.01610",
                    "CorpusId": 250551981
                },
                "corpusId": 250551981,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/99588393c3addda9048f1814ecdc77d4ce5e7063",
                "title": "Align Representations with Base: A New Approach to Self-Supervised Learning",
                "abstract": "Existing symmetric contrastive learning methods suffer from collapses (complete and dimensional) or quadratic complexity of objectives. Departure from these methods which maximize mutual information of two generated views, along either instance or feature dimension, the proposed paradigm introduces intermediate variables at the feature level, and maximizes the consistency between variables and representations of each view. Specifically, the proposed intermediate variables are the nearest group of base vectors to representations. Hence, we call the proposed method ARB (Align Representations with Base). Compared with other symmetric approaches, ARB 1) does not require negative pairs, which leads the complexity of the overall objective function is in linear order, 2) reduces feature redundancy, increasing the information density of training samples, 3) is more robust to output dimension size, which out-performs previous feature-wise arts over 28% Top-1 accuracy on ImageNet-100under low-dimension settings.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2116576240",
                        "name": "Shaofeng Zhang"
                    },
                    {
                        "authorId": "2176292124",
                        "name": "Lyn Qiu"
                    },
                    {
                        "authorId": "2075369514",
                        "name": "Feng Zhu"
                    },
                    {
                        "authorId": "3063894",
                        "name": "Junchi Yan"
                    },
                    {
                        "authorId": "35466544",
                        "name": "Hengrui Zhang"
                    },
                    {
                        "authorId": "145638781",
                        "name": "Rui Zhao"
                    },
                    {
                        "authorId": "46381640",
                        "name": "Hongyang Li"
                    },
                    {
                        "authorId": "2159107948",
                        "name": "Xiaokang Yang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Recently, some theoretical works have tried to understand how these new methods succeed in avoiding representational collapse [15, 27]."
            ],
            "citingPaper": {
                "paperId": "4cc8e0fb90d857c048953e3a467fd32b92dbc9d8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-00227",
                    "ArXiv": "2206.00227",
                    "DOI": "10.1109/CVPR52688.2022.01615",
                    "CorpusId": 249240132
                },
                "corpusId": 249240132,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4cc8e0fb90d857c048953e3a467fd32b92dbc9d8",
                "title": "Rethinking the Augmentation Module in Contrastive Learning: Learning Hierarchical Augmentation Invariance with Expanded Views",
                "abstract": "A data augmentation module is utilized in contrastive learning to transform the given data example into two views, which is considered essential and irreplaceable. However, the pre-determined composition of multiple data augmentations brings two drawbacks. First, the artificial choice of augmentation types brings specific representational invariances to the model, which have different de-grees of positive and negative effects on different down-stream tasks. Treating each type of augmentation equally during training makes the model learn non-optimal repre-sentations for various downstream tasks and limits the flex-ibility to choose augmentation types beforehand. Second, the strong data augmentations used in classic contrastive learning methods may bring too much invariance in some cases, and fine- grained information that is essential to some downstream tasks may be lost. This paper proposes a gen-eral method to alleviate these two problems by considering \u201cwhere\u201d and \u201cwhat\u201d to contrast in a general contrastive learning framework. We first propose to learn different aug-mentation invariances at different depths of the model ac-cording to the importance of each data augmentation in-stead of learning representational invariances evenly in the backbone. We then propose to expand the contrast content with augmentation embeddings to reduce the misleading ef-fects of strong data augmentations. Experiments based on several baseline methods demonstrate that we learn better representations for various benchmarks on classification, detection, and segmentation downstream tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108792807",
                        "name": "Junbo Zhang"
                    },
                    {
                        "authorId": "2075321204",
                        "name": "Kaisheng Ma"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "163724a8910a9322702a68da9741c6bf56245503",
                "externalIds": {
                    "ArXiv": "2206.00845",
                    "DBLP": "conf/cvpr/0012GWLL22",
                    "DOI": "10.1109/CVPR52688.2022.00710",
                    "CorpusId": 249282276
                },
                "corpusId": 249282276,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/163724a8910a9322702a68da9741c6bf56245503",
                "title": "Hyperspherical Consistency Regularization",
                "abstract": "Recent advances in contrastive learning have enlightened diverse applications across various semi-supervised fields. Jointly training supervised learning and unsupervised learning with a shared feature encoder becomes a common scheme. Though it benefits from taking advantage of both feature-dependent information from self-supervised learning and label-dependent information from supervised learning, this scheme remains suffering from bias of the classifier. In this work, we systematically explore the relationship between self-supervised learning and supervised learning, and study how self-supervised learning helps robust data-efficient deep learning. We propose hyperspherical consistency regularization (HCR), a simple yet effective plug-and-play method, to regularize the classifier using feature-dependent information and thus avoid bias from labels. Specifically, HCR first project logits from the classifier and feature projections from the projection head on the respective hypersphere, then it enforces data points on hyperspheres to have similar structures by minimizing binary cross entropy of pairwise distances' similarity metrics. Extensive experiments on semi-supervised and weakly-supervised learning demonstrate the effectiveness of our method, by showing superior performance with HCR.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2111728470",
                        "name": "Cheng Tan"
                    },
                    {
                        "authorId": "1962824654",
                        "name": "Zhangyang Gao"
                    },
                    {
                        "authorId": "47767812",
                        "name": "Lirong Wu"
                    },
                    {
                        "authorId": "2118155623",
                        "name": "Siyuan Li"
                    },
                    {
                        "authorId": "1390908654",
                        "name": "Stan Z. Li"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "9787d29aa66966629350a5c0806e32a19882a2c9",
                "externalIds": {
                    "DBLP": "conf/cvpr/HuangY022",
                    "DOI": "10.1109/CVPR52688.2022.00990",
                    "CorpusId": 250210682
                },
                "corpusId": 250210682,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9787d29aa66966629350a5c0806e32a19882a2c9",
                "title": "Learn from Others and Be Yourself in Heterogeneous Federated Learning",
                "abstract": "Federated learning has emerged as an important distributed learning paradigm, which normally involves collaborative updating with others and local updating on private data. However, heterogeneity problem and catastrophic forgetting bring distinctive challenges. First, due to non-i.i.d (identically and independently distributed) data and heterogeneous architectures, models suffer performance degradation on other domains and communication barrier with participants models. Second, in local updating, model is separately optimized on private data, which is prone to overfit current data distribution and forgets previously acquired knowledge, resulting in catastrophic forgetting. In this work, we propose FCCL (Federated CrossCorrelation and Continual Learning). For heterogeneity problem, FCCL leverages unlabeled public data for communication and construct cross-correlation matrix to learn a generalizable representation under domain shift. Mean- while, for catastrophic forgetting, FCCL utilizes knowledge distillation in local updating, providing inter and intra domain information without leaking privacy. Empirical results on various image classification tasks demonstrate the effectiveness of our method and the efficiency of modules.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2174575646",
                        "name": "Wenke Huang"
                    },
                    {
                        "authorId": "2676247",
                        "name": "Mang Ye"
                    },
                    {
                        "authorId": "2146898164",
                        "name": "Bo Du"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "To prevent trivial solutions (Tian et al., 2021), a popular trick is to apply additional repulsive force between the embeddings of semantically dissimilar images, known as contrastive learning (Chopra et al.",
                "To prevent trivial solutions (Tian et al., 2021), a popular trick is to apply additional repulsive force between the embeddings of semantically dissimilar images, known as contrastive learning (Chopra et al., 2005; Schroff et al., 2015; Sohn, 2016)."
            ],
            "citingPaper": {
                "paperId": "942c856469a6feee06c6c90c1571d6f4d3ebc65b",
                "externalIds": {
                    "ArXiv": "2206.01206",
                    "CorpusId": 260897632
                },
                "corpusId": 260897632,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/942c856469a6feee06c6c90c1571d6f4d3ebc65b",
                "title": "Positive Unlabeled Contrastive Learning",
                "abstract": "Self-supervised pretraining on unlabeled data followed by supervised fine-tuning on labeled data is a popular paradigm for learning from limited labeled examples. We extend this paradigm to the classical positive unlabeled (PU) setting, where the task is to learn a binary classifier given only a few labeled positive samples, and (often) a large amount of unlabeled samples (which could be positive or negative). We first propose a simple extension of standard infoNCE family of contrastive losses, to the PU setting; and show that this learns superior representations, as compared to existing unsupervised and supervised approaches. We then develop a simple methodology to pseudo-label the unlabeled samples using a new PU-specific clustering scheme; these pseudo-labels can then be used to train the final (positive vs. negative) classifier. Our method handily outperforms state-of-the-art PU methods over several standard PU benchmark datasets, while not requiring a-priori knowledge of any class prior (which is a common assumption in other PU methods). We also provide a simple theoretical analysis that motivates our methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40026200",
                        "name": "Anish Acharya"
                    },
                    {
                        "authorId": "70116942",
                        "name": "Sujay Sanghavi"
                    },
                    {
                        "authorId": "50780902",
                        "name": "Li Jing"
                    },
                    {
                        "authorId": "71887641",
                        "name": "Bhargav Bhushanam"
                    },
                    {
                        "authorId": "2066127975",
                        "name": "Michael G. Rabbat"
                    },
                    {
                        "authorId": "1783667",
                        "name": "I. Dhillon"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "[28, 29] on SimCLR [8], [30] on the projector of contrastive models, [14] on BYOL [31] and SimSIAM [8]."
            ],
            "citingPaper": {
                "paperId": "b845c9d7f3fa05f56e7394f273c0c7536ee0e671",
                "externalIds": {
                    "ArXiv": "2205.11508",
                    "DBLP": "journals/corr/abs-2205-11508",
                    "CorpusId": 248986152
                },
                "corpusId": 248986152,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b845c9d7f3fa05f56e7394f273c0c7536ee0e671",
                "title": "Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods",
                "abstract": "Self-Supervised Learning (SSL) surmises that inputs and pairwise positive relationships are enough to learn meaningful representations. Although SSL has recently reached a milestone: outperforming supervised methods in many modalities\\dots the theoretical foundations are limited, method-specific, and fail to provide principled design guidelines to practitioners. In this paper, we propose a unifying framework under the helm of spectral manifold learning to address those limitations. Through the course of this study, we will rigorously demonstrate that VICReg, SimCLR, BarlowTwins et al. correspond to eponymous spectral methods such as Laplacian Eigenmaps, Multidimensional Scaling et al. This unification will then allow us to obtain (i) the closed-form optimal representation for each method, (ii) the closed-form optimal network parameters in the linear regime for each method, (iii) the impact of the pairwise relations used during training on each of those quantities and on downstream task performances, and most importantly, (iv) the first theoretical bridge between contrastive and non-contrastive methods towards global and local spectral embedding methods respectively, hinting at the benefits and limitations of each. For example, (i) if the pairwise relation is aligned with the downstream task, any SSL method can be employed successfully and will recover the supervised method, but in the low data regime, VICReg's invariance hyper-parameter should be high; (ii) if the pairwise relation is misaligned with the downstream task, VICReg with small invariance hyper-parameter should be preferred over SimCLR or BarlowTwins.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3201463",
                        "name": "Randall Balestriero"
                    },
                    {
                        "authorId": "1688882",
                        "name": "Yann LeCun"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Theory of SSL: Recently, substantial advances have been made towards demystifying SSL methods from the perspectives of learning theory (Arora et al., 2019), information theory (Tsai et al., 2021), causality (Kugelgen et al., 2021), and dynamical systems (Tian et al., 2021a).",
                "Since centralized SSL techniques are known to be sensitive to heavy-tailed gradient distributions (Tian et al., 2021b) and require large batch-sizes (Chen et al., 2020), it is unlikely their direct extensions will function well in the high heterogeneity and resource constrained setting of\u2026"
            ],
            "citingPaper": {
                "paperId": "527abfac71e29321350c0249dbd4fca960c44c48",
                "externalIds": {
                    "ArXiv": "2205.11506",
                    "DBLP": "conf/icml/LubanaTKDM22",
                    "DOI": "10.48550/arXiv.2205.11506",
                    "CorpusId": 248987363
                },
                "corpusId": 248987363,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/527abfac71e29321350c0249dbd4fca960c44c48",
                "title": "Orchestra: Unsupervised Federated Learning via Globally Consistent Clustering",
                "abstract": "Federated learning is generally used in tasks where labels are readily available (e.g., next word prediction). Relaxing this constraint requires design of unsupervised learning techniques that can support desirable properties for federated training: robustness to statistical/systems heterogeneity, scalability with number of participants, and communication efficiency. Prior work on this topic has focused on directly extending centralized self-supervised learning techniques, which are not designed to have the properties listed above. To address this situation, we propose Orchestra, a novel unsupervised federated learning technique that exploits the federation's hierarchy to orchestrate a distributed clustering task and enforce a globally consistent partitioning of clients' data into discriminable clusters. We show the algorithmic pipeline in Orchestra guarantees good generalization performance under a linear probe, allowing it to outperform alternative techniques in a broad range of conditions, including variation in heterogeneity, number of clients, participation ratio, and local epochs.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "35573359",
                        "name": "E. S. Lubana"
                    },
                    {
                        "authorId": "2118761614",
                        "name": "Chi Ian Tang"
                    },
                    {
                        "authorId": "1776175",
                        "name": "F. Kawsar"
                    },
                    {
                        "authorId": "1792688",
                        "name": "R. Dick"
                    },
                    {
                        "authorId": "2005305",
                        "name": "Akhil Mathur"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                ", at least 4 GPUs or 32 TPU cores) for learning better representations from images [10]."
            ],
            "citingPaper": {
                "paperId": "c7c9f7767186f1f3685ffef5303d637ba8af8d98",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-03012",
                    "ArXiv": "2206.03012",
                    "DOI": "10.1109/ICASSP43922.2022.9746967",
                    "CorpusId": 249431799
                },
                "corpusId": 249431799,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/c7c9f7767186f1f3685ffef5303d637ba8af8d98",
                "title": "TriBYOL: Triplet BYOL for Self-Supervised Representation Learning",
                "abstract": "This paper proposes a novel self-supervised learning method for learning better representations with small batch sizes. Many self-supervised learning methods based on certain forms of the siamese network have emerged and received significant attention. However, these methods need to use large batch sizes to learn good representations and require heavy computational resources. We present a new triplet network combined with a triple-view loss to improve the performance of self-supervised representation learning with small batch sizes. Experimental results show that our method can drastically outperform state-of-the-art self-supervised learning methods on several datasets in small-batch cases. Our method provides a feasible solution for self-supervised learning with real-world high-resolution images that uses small batch sizes.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2151296785",
                        "name": "Guang Li"
                    },
                    {
                        "authorId": "3470264",
                        "name": "Ren Togo"
                    },
                    {
                        "authorId": "144392699",
                        "name": "Takahiro Ogawa"
                    },
                    {
                        "authorId": "144029207",
                        "name": "M. Haseyama"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "8db9410f6325975d7f31686b7aeb814725b1e775",
                "externalIds": {
                    "ArXiv": "2205.06926",
                    "DBLP": "journals/corr/abs-2205-06926",
                    "DOI": "10.48550/arXiv.2205.06926",
                    "CorpusId": 248811540
                },
                "corpusId": 248811540,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8db9410f6325975d7f31686b7aeb814725b1e775",
                "title": "Toward a Geometrical Understanding of Self-supervised Contrastive Learning",
                "abstract": "Self-supervised learning (SSL) is currently one of the premier techniques to create data representations that are actionable for transfer learning in the absence of human annotations. Despite their success, the underlying geometry of these representations remains elusive, which obfuscates the quest for more robust, trustworthy, and interpretable models. In particular, mainstream SSL techniques rely on a specific deep neural network architecture with two cascaded neural networks: the encoder and the projector. When used for transfer learning, the projector is discarded since empirical results show that its representation generalizes more poorly than the encoder's. In this paper, we investigate this curious phenomenon and analyze how the strength of the data augmentation policies affects the data embedding. We discover a non-trivial relation between the encoder, the projector, and the data augmentation strength: with increasingly larger augmentation policies, the projector, rather than the encoder, is more strongly driven to become invariant to the augmentations. It does so by eliminating crucial information about the data by learning to project it into a low-dimensional space, a noisy estimate of the data manifold tangent plane in the encoder representation. This analysis is substantiated through a geometrical perspective with theoretical and empirical results.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40125997",
                        "name": "R. Cosentino"
                    },
                    {
                        "authorId": "1760529",
                        "name": "Anirvan M. Sengupta"
                    },
                    {
                        "authorId": "121011351",
                        "name": "S. Avestimehr"
                    },
                    {
                        "authorId": "2766123",
                        "name": "M. Soltanolkotabi"
                    },
                    {
                        "authorId": "2079347891",
                        "name": "Antonio Ortega"
                    },
                    {
                        "authorId": "102992766",
                        "name": "Ted L. Willke"
                    },
                    {
                        "authorId": "1730544",
                        "name": "Mariano Tepper"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "What type of negative sampling scheme to use is an essential question, and the role and necessity of negative sampling in contrastive methods is an open issue [274, 277]."
            ],
            "citingPaper": {
                "paperId": "246bd7b76dfa1b9ee4056b1f9419cb5b580e47ae",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-01423",
                    "ArXiv": "2205.01423",
                    "DOI": "10.48550/arXiv.2205.01423",
                    "CorpusId": 248506073
                },
                "corpusId": 248506073,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/246bd7b76dfa1b9ee4056b1f9419cb5b580e47ae",
                "title": "Autonomy and Intelligence in the Computing Continuum: Challenges, Enablers, and Future Directions for Orchestration",
                "abstract": "Future AI applications require performance, reliability and privacy that the existing, cloud-dependant system architectures cannot provide. In this article, we study orchestration in the device-edge-cloud continuum, and focus on edge AI for resource orchestration. We claim that to support the constantly growing requirements of intelligent applications in the device-edge-cloud computing continuum, resource orchestration needs to embrace edge AI and emphasize local autonomy and intelligence. To justify the claim, we provide a general definition for continuum orchestration, and look at how current and emerging orchestration paradigms are suitable for the computing continuum. We describe certain major emerging research themes that may affect future orchestration, and provide an early vision of an orchestration paradigm that embraces those research themes. Finally, we survey current key edge AI methods and look at how they may contribute into fulfilling the vision of future continuum orchestration.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2085166053",
                        "name": "Henna Kokkonen"
                    },
                    {
                        "authorId": "35531833",
                        "name": "Lauri Lov\u00e9n"
                    },
                    {
                        "authorId": "2972928",
                        "name": "Naser Hossein Motlagh"
                    },
                    {
                        "authorId": "2940586",
                        "name": "Juha Partala"
                    },
                    {
                        "authorId": "2164091879",
                        "name": "Alfonso Gonz'alez-Gil"
                    },
                    {
                        "authorId": "2164091921",
                        "name": "Ester Sola"
                    },
                    {
                        "authorId": "2164092553",
                        "name": "Inigo Angulo"
                    },
                    {
                        "authorId": "145332300",
                        "name": "Madhusanka Liyanage"
                    },
                    {
                        "authorId": "48183548",
                        "name": "T. Leppanen"
                    },
                    {
                        "authorId": "2116109061",
                        "name": "Tri Nguyen"
                    },
                    {
                        "authorId": "35688956",
                        "name": "Panos Kostakos"
                    },
                    {
                        "authorId": "1702172",
                        "name": "M. Bennis"
                    },
                    {
                        "authorId": "1759241",
                        "name": "S. Tarkoma"
                    },
                    {
                        "authorId": "1691109",
                        "name": "S. Dustdar"
                    },
                    {
                        "authorId": "2122250",
                        "name": "S. Pirttikangas"
                    },
                    {
                        "authorId": "1745217",
                        "name": "J. Riekki"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "2010) (also known as Contrastive Learning) has emerged as a highly effective approach for unsupervised representation learning using deep networks (Chen et al., 2020; Chen & Li, 2020; Tian et al., 2021; Grill et al., 2020).",
                "Noise contrastive estimation (NCE) (Gutmann & Hyv\u00e4rinen, 2010) (also known as Contrastive Learning) has emerged as a highly effective approach for unsupervised representation learning using deep networks (Chen et al., 2020; Chen & Li, 2020; Tian et al., 2021; Grill et al., 2020).",
                "Finally, there has also been recent work exploring whether contrastive learning can be performed without the use of negative samples while avoiding the phenomenon of feature collapse (Tian et al., 2021; Grill et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "bdbfba030b0acf263f5f78e7a064cd96097e5de2",
                "externalIds": {
                    "ArXiv": "2205.01789",
                    "DBLP": "journals/corr/abs-2205-01789",
                    "DOI": "10.48550/arXiv.2205.01789",
                    "CorpusId": 248512556
                },
                "corpusId": 248512556,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/bdbfba030b0acf263f5f78e7a064cd96097e5de2",
                "title": "Do More Negative Samples Necessarily Hurt in Contrastive Learning?",
                "abstract": "Recent investigations in noise contrastive estimation suggest, both empirically as well as theoretically, that while having more\"negative samples\"in the contrastive loss improves downstream classification performance initially, beyond a threshold, it hurts downstream performance due to a\"collision-coverage\"trade-off. But is such a phenomenon inherent in contrastive learning? We show in a simple theoretical setting, where positive pairs are generated by sampling from the underlying latent class (introduced by Saunshi et al. (ICML 2019)), that the downstream performance of the representation optimizing the (population) contrastive loss in fact does not degrade with the number of negative samples. Along the way, we give a structural characterization of the optimal representation in our framework, for noise contrastive estimation. We also provide empirical support for our theoretical results on CIFAR-10 and CIFAR-100 datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "144030228",
                        "name": "Pranjal Awasthi"
                    },
                    {
                        "authorId": "2312421",
                        "name": "Nishanth Dikkala"
                    },
                    {
                        "authorId": "48655887",
                        "name": "Pritish Kamath"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "In particular, this technique contrasts positive pairs against negative pairs and minimizes differences between positive pairs to avoid collapsing solutions [47], [50]."
            ],
            "citingPaper": {
                "paperId": "7a8e5172f7e73d54a944c485063c3f97b8e72bba",
                "externalIds": {
                    "DBLP": "conf/cluster/AliSKKTMFCTL22",
                    "ArXiv": "2204.09805",
                    "DOI": "10.1109/CLUSTER51413.2022.00050",
                    "CorpusId": 248299878
                },
                "corpusId": 248299878,
                "publicationVenue": {
                    "id": "0be0e7dd-a7b1-46dc-abb3-5226ed0e2289",
                    "name": "IEEE International Conference on Cluster Computing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Clust Comput",
                        "IEEE Int Conf Clust Comput",
                        "International Conference on Cluster Computing",
                        "CLUSTER"
                    ],
                    "url": "http://www.clustercomp.org/"
                },
                "url": "https://www.semanticscholar.org/paper/7a8e5172f7e73d54a944c485063c3f97b8e72bba",
                "title": "fairDMS: Rapid Model Training by Data and Model Reuse",
                "abstract": "Extracting actionable information rapidly from data produced by instruments such as the Linac Coherent Light Source (LCLS-II) and Advanced Photon Source Upgrade (APS-U) is becoming ever more challenging due to high (up to TB/s) data rates. Conventional physics-based information retrieval methods are hard-pressed to detect interesting events fast enough to enable timely focusing on a rare event or correction of an error. Machine learning (ML) methods that learn cheap surrogate classifiers present a promising alternative, but can fail catastrophically when changes in instrument or sample result in degradation in ML performance. To overcome such difficulties, we present a new data storage and ML model training architecture designed to organize large volumes of data and models so that when model degradation is detected, prior models and/or data can be queried rapidly and a more suitable model retrieved and fine-tuned for new conditions. We show that our approach can achieve up to 100x data labelling speedup compared to the current state-of-the-art, 200x improvement in training speed, and 92x speedup in-terms of end-to-end model updating time.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1653441306",
                        "name": "Ahsan Ali"
                    },
                    {
                        "authorId": "2065486966",
                        "name": "Hemant Sharma"
                    },
                    {
                        "authorId": "9297377",
                        "name": "R. Kettimuthu"
                    },
                    {
                        "authorId": "4250752",
                        "name": "P. Kenesei"
                    },
                    {
                        "authorId": "2106385690",
                        "name": "Dennis Trujillo"
                    },
                    {
                        "authorId": "23405177",
                        "name": "A. Miceli"
                    },
                    {
                        "authorId": "2091477753",
                        "name": "Ian T. Foster"
                    },
                    {
                        "authorId": "2163094097",
                        "name": "Ryan Coffee"
                    },
                    {
                        "authorId": "2059210000",
                        "name": "Jana Thayer"
                    },
                    {
                        "authorId": "119568808",
                        "name": "Zhengchun Liu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "f097fb79d7ab0743d96167d419788d4aad8197d7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-08226",
                    "ArXiv": "2204.08226",
                    "DOI": "10.48550/arXiv.2204.08226",
                    "CorpusId": 248227522
                },
                "corpusId": 248227522,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f097fb79d7ab0743d96167d419788d4aad8197d7",
                "title": "Empirical Evaluation and Theoretical Analysis for Representation Learning: A Survey",
                "abstract": "Representation learning enables us to automatically extract generic feature representations from a dataset to solve another machine learning task. Recently, extracted feature representations by a representation learning algorithm and a simple predictor have exhibited state-of-the-art performance on several machine learning tasks. Despite its remarkable progress, there exist various ways to evaluate representation learning algorithms depending on the application because of the flexibility of representation learning. To understand the current representation learning, we review evaluation methods of representation learning algorithms and theoretical analyses. On the basis of our evaluation survey, we also discuss the future direction of representation learning. Note that this survey is the extended version of Nozawa and Sato (2022).",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "13613520",
                        "name": "Kento Nozawa"
                    },
                    {
                        "authorId": "73355331",
                        "name": "Issei Sato"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "e149a22321343d6755b0c50dc5912c72e948d41d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-07714",
                    "ArXiv": "2204.07714",
                    "DOI": "10.1109/CVPR52688.2022.01372",
                    "CorpusId": 248227386
                },
                "corpusId": 248227386,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e149a22321343d6755b0c50dc5912c72e948d41d",
                "title": "Pushing the Performance Limit of Scene Text Recognizer without Human Annotation",
                "abstract": "Scene text recognition (STR) attracts much attention over the years because of its wide application. Most methods train STR model in a fully supervised manner which requires large amounts of labeled data. Although synthetic data contributes a lot to STR, it suffers from the real-to-synthetic domain gap the restricts model performance. In this work, we aim to boost STR models by leveraging both synthetic data and the numerous real unlabeled images, exempting human annotation cost thoroughly. A robust con-sistency regularization based semi-supervised framework is proposed for STR, which can effectively solve the instability issue due to domain inconsistency between synthetic and real images. A character-level consistency regularization is designed to mitigate the misalignment between characters in sequence recognition. Extensive experiments on standard text recognition benchmarks demonstrate the effectiveness of the proposed method. It can steadily improve existing STR models, and boost an STR model to achieve new state-of-the-art results. To our best knowledge, this is the first consistency regularization based framework that applies successfully to STR.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2162792954",
                        "name": "Caiyuan Zheng"
                    },
                    {
                        "authorId": "2155494310",
                        "name": "Hui Li"
                    },
                    {
                        "authorId": "2059323344",
                        "name": "Seon-Min Rhee"
                    },
                    {
                        "authorId": null,
                        "name": "Seungju Han"
                    },
                    {
                        "authorId": "1764869",
                        "name": "Jae-Joon Han"
                    },
                    {
                        "authorId": "1585288737",
                        "name": "Peng Wang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Tian et al [43] performs several experiments and report that the predictor network at the end of the online network and stop-gradients for the target network are necessary to avoid the representation collapse.",
                "However, the absence of the negative pairs in BYOL stirred a lot of commotion in the community and several works [39, 44, 43, 40] have tried to understand the phenomenon."
            ],
            "citingPaper": {
                "paperId": "db86ddae48c3eff500f914f7bd3e72a1e3f613b3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-04545",
                    "ArXiv": "2204.04545",
                    "DOI": "10.48550/arXiv.2204.04545",
                    "CorpusId": 248085157
                },
                "corpusId": 248085157,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/db86ddae48c3eff500f914f7bd3e72a1e3f613b3",
                "title": "Self-Labeling Refinement for Robust Representation Learning with Bootstrap Your Own Latent",
                "abstract": "In this work, we have worked towards two major goals. Firstly, we have investigated the importance of Batch Normalisation (BN) layers in a non-contrastive representation learning framework called Bootstrap Your Own Latent (BYOL)[18]. We conducted several experiments to conclude that BN layers are not necessary for representation learning in BYOL [39]. Moreover, BYOL only learns from the positive pairs of images but ignore other semantically similar images in same input batch. For the second goal, we have introduced two new loss functions to determine the semantically similar pairs in the same input batch of images and reduce the distance between their representations. These loss functions are Cross-Cosine Similarity Loss (CCSL) and Cross-Sigmoid Similarity Loss (CSSL) . Using the proposed loss functions, we are able to surpass the performance of Vanilla BYOL ( 71.04% ) by training BYOL framework using CCSL loss ( 76.87% ) on STL10 dataset. BYOL trained using CSSL loss performs comparably with Vanilla BYOL.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2295877",
                        "name": "Siddhant Garg"
                    },
                    {
                        "authorId": "1612419368",
                        "name": "Dhruval Jain"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "eb9104bb72f3856751d8c1b9c9573768d5f3df35",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-04385",
                    "ArXiv": "2204.04385",
                    "DOI": "10.48550/arXiv.2204.04385",
                    "CorpusId": 248085789
                },
                "corpusId": 248085789,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/eb9104bb72f3856751d8c1b9c9573768d5f3df35",
                "title": "Divergence-aware Federated Self-Supervised Learning",
                "abstract": "Self-supervised learning (SSL) is capable of learning remarkable representations from centrally available data. Recent works further implement federated learning with SSL to learn from rapidly growing decentralized unlabeled images (e.g., from cameras and phones), often resulted from privacy constraints. Extensive attention has been paid to SSL approaches based on Siamese networks. However, such an effort has not yet revealed deep insights into various fundamental building blocks for the federated self-supervised learning (FedSSL) architecture. We aim to fill in this gap via in-depth empirical study and propose a new method to tackle the non-independently and identically distributed (non-IID) data problem of decentralized data. Firstly, we introduce a generalized FedSSL framework that embraces existing SSL methods based on Siamese networks and presents flexibility catering to future methods. In this framework, a server coordinates multiple clients to conduct SSL training and periodically updates local models of clients with the aggregated global model. Using the framework, our study uncovers unique insights of FedSSL: 1) stop-gradient operation, previously reported to be essential, is not always necessary in FedSSL; 2) retaining local knowledge of clients in FedSSL is particularly beneficial for non-IID data. Inspired by the insights, we then propose a new approach for model update, Federated Divergence-aware Exponential Moving Average update (FedEMA). FedEMA updates local models of clients adaptively using EMA of the global model, where the decay rate is dynamically measured by model divergence. Extensive experiments demonstrate that FedEMA outperforms existing methods by 3-4% on linear evaluation. We hope that this work will provide useful insights for future research.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1900312976",
                        "name": "Weiming Zhuang"
                    },
                    {
                        "authorId": "2114784205",
                        "name": "Yonggang Wen"
                    },
                    {
                        "authorId": "2140178647",
                        "name": "Shuai Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "It has been shown [24, 29] that this training procedure is sufficient to avoid collapsed solutions such as constant representations, since the updates to the target network parameters \u03be are not in general in the direction of \u2207\u03beL BY OL \u03b8,\u03be , due to the stop grad operation in the target network."
            ],
            "citingPaper": {
                "paperId": "7d5b53cd14463d1b006f17871be6f89de974d1d2",
                "externalIds": {
                    "ArXiv": "2204.03421",
                    "DBLP": "journals/corr/abs-2204-03421",
                    "DOI": "10.48550/arXiv.2204.03421",
                    "CorpusId": 248006193
                },
                "corpusId": 248006193,
                "publicationVenue": {
                    "id": "af90489e-312f-4514-bea2-bcb399cb8ece",
                    "name": "Interspeech",
                    "type": "conference",
                    "alternate_names": [
                        "Conf Int Speech Commun Assoc",
                        "INTERSPEECH",
                        "Conference of the International Speech Communication Association"
                    ],
                    "issn": "2308-457X",
                    "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech",
                    "alternate_urls": [
                        "http://www.isca-speech.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7d5b53cd14463d1b006f17871be6f89de974d1d2",
                "title": "Self supervised learning for robust voice cloning",
                "abstract": "Voice cloning is a difficult task which requires robust and informative features incorporated in a high quality TTS system in order to effectively copy an unseen speaker's voice. In our work, we utilize features learned in a self-supervised framework via the Bootstrap Your Own Latent (BYOL) method, which is shown to produce high quality speech representations when specific audio augmentations are applied to the vanilla algorithm. We further extend the augmentations in the training procedure to aid the resulting features to capture the speaker identity and to make them robust to noise and acoustic conditions. The learned features are used as pre-trained utterance-level embeddings and as inputs to a Non-Attentive Tacotron based architecture, aiming to achieve multispeaker speech synthesis without utilizing additional speaker features. This method enables us to train our model in an unlabeled multispeaker dataset as well as use unseen speaker embeddings to copy a speaker's voice. Subjective and objective evaluations are used to validate the proposed model, as well as the robustness to the acoustic conditions of the target utterance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2127779636",
                        "name": "Konstantinos Klapsas"
                    },
                    {
                        "authorId": "41021223",
                        "name": "N. Ellinas"
                    },
                    {
                        "authorId": "2161662066",
                        "name": "Karolos Nikitaras"
                    },
                    {
                        "authorId": "146854118",
                        "name": "G. Vamvoukakis"
                    },
                    {
                        "authorId": "3091142",
                        "name": "Panos Kakoulidis"
                    },
                    {
                        "authorId": "2007579985",
                        "name": "K. Markopoulos"
                    },
                    {
                        "authorId": "11898578",
                        "name": "S. Raptis"
                    },
                    {
                        "authorId": "1712724",
                        "name": "June Sig Sung"
                    },
                    {
                        "authorId": "1751341",
                        "name": "Gunu Jho"
                    },
                    {
                        "authorId": "2049902",
                        "name": "A. Chalamandaris"
                    },
                    {
                        "authorId": "1934588",
                        "name": "P. Tsiakoulis"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "cc9df11e321206664cc1c6a873c615b0bb3260b3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-00613",
                    "ArXiv": "2204.00613",
                    "DOI": "10.1109/CVPR52688.2022.01607",
                    "CorpusId": 247922311
                },
                "corpusId": 247922311,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/cc9df11e321206664cc1c6a873c615b0bb3260b3",
                "title": "On the Importance of Asymmetry for Siamese Representation Learning",
                "abstract": "Many recent self-supervised frameworks for visual representation learning are based on certain forms of Siamese networks. Such networks are conceptually symmetric with two parallel encoders, but often practically asymmetric as numerous mechanisms are devised to break the symmetry. In this work, we conduct a formal study on the importance of asymmetry by explicitly distinguishing the two encoders within the network - one produces source encodings and the other targets. Our key insight is keeping a relatively lower variance in target than source generally benefits learning. This is empirically justified by our results from five case studies covering different variance-oriented designs, and is aligned with our preliminary theoretical analysis on the baseline. Moreover, we find the improvements from asymmetric designs generalize well to longer training schedules, multiple other frameworks and newer backbones. Finally, the combined effect of several asymmetric designs achieves a state-of-the-art accuracy on ImageNet linear probing and competitive results on downstream transfer. We hope our exploration will inspire more research in exploiting asymmetry for Siamese representation learning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118448261",
                        "name": "Xiao Wang"
                    },
                    {
                        "authorId": "146884473",
                        "name": "Haoqi Fan"
                    },
                    {
                        "authorId": "1932187449",
                        "name": "Yuandong Tian"
                    },
                    {
                        "authorId": "2055393",
                        "name": "D. Kihara"
                    },
                    {
                        "authorId": "39717886",
                        "name": "Xinlei Chen"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Instance discrimination compares pairs of images to identify which are most similar; it then moves those together while pushing dissimilar images apart [47]."
            ],
            "citingPaper": {
                "paperId": "0cc7d5f3823689bfda3de8e3719e54f6e9f91122",
                "externalIds": {
                    "PubMedCentral": "9029566",
                    "DBLP": "journals/entropy/Albelwi22",
                    "DOI": "10.3390/e24040551",
                    "CorpusId": 248208362,
                    "PubMed": "35455214"
                },
                "corpusId": 248208362,
                "publicationVenue": {
                    "id": "8270cfe1-3713-4325-a7bd-c6a87eed889e",
                    "name": "Entropy",
                    "type": "journal",
                    "issn": "1099-4300",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-155606",
                    "alternate_urls": [
                        "http://www.mdpi.com/journal/entropy/",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-155606",
                        "https://www.mdpi.com/journal/entropy"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0cc7d5f3823689bfda3de8e3719e54f6e9f91122",
                "title": "Survey on Self-Supervised Learning: Auxiliary Pretext Tasks and Contrastive Learning Methods in Imaging",
                "abstract": "Although deep learning algorithms have achieved significant progress in a variety of domains, they require costly annotations on huge datasets. Self-supervised learning (SSL) using unlabeled data has emerged as an alternative, as it eliminates manual annotation. To do this, SSL constructs feature representations using pretext tasks that operate without manual annotation, which allows models trained in these tasks to extract useful latent representations that later improve downstream tasks such as object classification and detection. The early methods of SSL are based on auxiliary pretext tasks as a way to learn representations using pseudo-labels, or labels that were created automatically based on the dataset\u2019s attributes. Furthermore, contrastive learning has also performed well in learning representations via SSL. To succeed, it pushes positive samples closer together, and negative ones further apart, in the latent space. This paper provides a comprehensive literature review of the top-performing SSL methods using auxiliary pretext and contrastive learning techniques. It details the motivation for this research, a general pipeline of SSL, the terminologies of the field, and provides an examination of pretext tasks and self-supervised methods. It also examines how self-supervised methods compare to supervised ones, and then discusses both further considerations and ongoing challenges faced by SSL.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "8861277",
                        "name": "Saleh Albelwi"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "This interpretation echos well with the finding that the eigenspace of hweight aligns well with that of correlation matrix (Tian et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "2b9455fceb0ff58f28a46aebfb8df6f7003e9e40",
                "externalIds": {
                    "ArXiv": "2203.16262",
                    "DBLP": "journals/corr/abs-2203-16262",
                    "DOI": "10.48550/arXiv.2203.16262",
                    "CorpusId": 247693714
                },
                "corpusId": 247693714,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2b9455fceb0ff58f28a46aebfb8df6f7003e9e40",
                "title": "How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning",
                "abstract": "To avoid collapse in self-supervised learning (SSL), a contrastive loss is widely used but often requires a large number of negative samples. Without negative samples yet achieving competitive performance, a recent work has attracted significant attention for providing a minimalist simple Siamese (SimSiam) method to avoid collapse. However, the reason for how it avoids collapse without negative samples remains not fully clear and our investigation starts by revisiting the explanatory claims in the original SimSiam. After refuting their claims, we introduce vector decomposition for analyzing the collapse based on the gradient analysis of the $l_2$-normalized representation vector. This yields a unified perspective on how negative samples and SimSiam alleviate collapse. Such a unified perspective comes timely for understanding the recent progress in SSL.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "31044159",
                        "name": "Chaoning Zhang"
                    },
                    {
                        "authorId": "2156564038",
                        "name": "Kang Zhang"
                    },
                    {
                        "authorId": "48934876",
                        "name": "Chenshuang Zhang"
                    },
                    {
                        "authorId": "144429629",
                        "name": "T. Pham"
                    },
                    {
                        "authorId": "2154412756",
                        "name": "C. D. Yoo"
                    },
                    {
                        "authorId": "98758720",
                        "name": "I. Kweon"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Subsequent works based on data augmentation also showed promising results for methods based on non-contrastive learning (non-CL), which do not require explicit negative samples (Grill et al., 2020; Richemond et al., 2020; Chen & He, 2021; Zbontar et al., 2021; Tian et al., 2021).",
                "Namely, Tian et al. (2021) adopts a linear network and calculates the optimization dynam-\nics of non-contrastive learning, while Wen & Li (2021) analyzes the feature learning process of contrastive learning on a single-layer linear model with ReLU activation.",
                "For an input x, the augmented views a1,a2 \u2208 Rp\u00d71 are generated as \u2217:\na1 := D1x; a2 := D2x (3)\nNetwork architecture We use a dual network architecture inline with prior work Arora et al. (2015); Tian et al. (2021); Wen & Li (2021).",
                "To understand how non-contrastive learning works, existing works mostly focus on analyzing what elements help it avoid learning collapsed representations (Grill et al., 2020; Richemond et al., 2020; Chen & He, 2021; Zbontar et al., 2021; Tian et al., 2021; Wang et al., 2021).",
                "Our model architecture gets inspirations from Tian et al. (2021) and Wen & Li (2021)."
            ],
            "citingPaper": {
                "paperId": "2da945cdbbbadff1177f709eab21a2e51fa0057a",
                "externalIds": {
                    "ArXiv": "2203.15702",
                    "DBLP": "conf/aistats/PokleTLR22",
                    "DOI": "10.48550/arXiv.2203.15702",
                    "CorpusId": 247779296
                },
                "corpusId": 247779296,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2da945cdbbbadff1177f709eab21a2e51fa0057a",
                "title": "Contrasting the landscape of contrastive and non-contrastive learning",
                "abstract": "A lot of recent advances in unsupervised feature learning are based on designing features which are invariant under semantic data augmentations. A common way to do this is contrastive learning, which uses positive and negative samples. Some recent works however have shown promising results for non-contrastive learning, which does not require negative samples. However, the non-contrastive losses have obvious\"collapsed\"minima, in which the encoders output a constant feature embedding, independent of the input. A folk conjecture is that so long as these collapsed solutions are avoided, the produced feature representations should be good. In our paper, we cast doubt on this story: we show through theoretical results and controlled experiments that even on simple data models, non-contrastive losses have a preponderance of non-collapsed bad minima. Moreover, we show that the training process does not avoid these minima.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51346567",
                        "name": "Ashwini Pokle"
                    },
                    {
                        "authorId": "9509390",
                        "name": "Jinjin Tian"
                    },
                    {
                        "authorId": null,
                        "name": "Yuchen Li"
                    },
                    {
                        "authorId": "3181040",
                        "name": "Andrej Risteski"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "For this proof, we borrow theoretical findings from the DirectPred literature [47].",
                "[47] theoretically analyzed on why the non-contrastive methods work well.",
                "Self-supervised learning (SSL) is a framework for learning representations of data [6, 13, 19, 7, 5, 56, 47, 34, 27, 36]."
            ],
            "citingPaper": {
                "paperId": "fee31d441e798348e1de709a19eae6a524583818",
                "externalIds": {
                    "ArXiv": "2203.11437",
                    "CorpusId": 257663698
                },
                "corpusId": 257663698,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/fee31d441e798348e1de709a19eae6a524583818",
                "title": "Representation Uncertainty in Self-Supervised Learning as Variational Inference",
                "abstract": "In this study, a novel self-supervised learning (SSL) method is proposed, which considers SSL in terms of variational inference to learn not only representation but also representation uncertainties. SSL is a method of learning representations without labels by maximizing the similarity between image representations of different augmented views of an image. Meanwhile, variational autoencoder (VAE) is an unsupervised representation learning method that trains a probabilistic generative model with variational inference. Both VAE and SSL can learn representations without labels, but their relationship has not been investigated in the past. Herein, the theoretical relationship between SSL and variational inference has been clarified. Furthermore, a novel method, namely variational inference SimSiam (VI-SimSiam), has been proposed. VI-SimSiam can predict the representation uncertainty by interpreting SimSiam with variational inference and defining the latent space distribution. The present experiments qualitatively show that VI- SimSiam could learn uncertainty by comparing input images and predicted uncertainties. Additionally, we described a relationship between estimated uncertainty and classification accuracy.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2159561166",
                        "name": "Hiroki Nakamura"
                    },
                    {
                        "authorId": "2114306014",
                        "name": "Masashi Okada"
                    },
                    {
                        "authorId": "1684099",
                        "name": "T. Taniguchi"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "In addition, the theoretical analysis and experimental study in Tian et al.51 has raised two additional suggestions for training non-contrastive SSL models like BYOL and SimSiam.",
                ", the extra learnable predictor and a stop-gradient operation.(51) ll OPEN ACCESS Review",
                "In addition, the theoretical analysis and experimental study in Tian et al.(51) has raised two additional suggestions for training non-contrastive SSL models like BYOL and SimSiam."
            ],
            "citingPaper": {
                "paperId": "904fd897a47e2713257334f17c1ce09114e7973d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-01205",
                    "PubMedCentral": "9768631",
                    "ArXiv": "2203.01205",
                    "DOI": "10.1016/j.patter.2022.100616",
                    "CorpusId": 247218173,
                    "PubMed": "36569546"
                },
                "corpusId": 247218173,
                "publicationVenue": {
                    "id": "17bac89e-3dba-467a-b9d4-71e3baefb08b",
                    "name": "Patterns",
                    "type": "journal",
                    "issn": "2666-3899",
                    "url": "https://www.cell.com/patterns",
                    "alternate_urls": [
                        "https://www.sciencedirect.com/journal/patterns"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/904fd897a47e2713257334f17c1ce09114e7973d",
                "title": "Audio self-supervised learning: A survey",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108062111",
                        "name": "Shuo Liu"
                    },
                    {
                        "authorId": "1404341452",
                        "name": "Adria Mallol-Ragolta"
                    },
                    {
                        "authorId": "2156927991",
                        "name": "Emilia Parada-Cabeleiro"
                    },
                    {
                        "authorId": "143857311",
                        "name": "Kun Qian"
                    },
                    {
                        "authorId": "80018757",
                        "name": "Xingshuo Jing"
                    },
                    {
                        "authorId": "2156927668",
                        "name": "Alexander Kathan"
                    },
                    {
                        "authorId": "2145119105",
                        "name": "Bin Hu"
                    },
                    {
                        "authorId": "145411696",
                        "name": "Bj\u00f6rn Schuller"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Although promising performance has been achieved, we observed that the existing deep graph clustering algorithms [9], [14], [15] suffer from the representation collapse issue [16] and easily embed the nodes from different classes into the same embedding.",
                "Representation collapse is a common problem that the network tends to encode samples from different classes into the same representation in the field of the self-supervised learning [16]."
            ],
            "citingPaper": {
                "paperId": "13f39de00f38909256f64e1be7071096788cae3d",
                "externalIds": {
                    "ArXiv": "2202.12533",
                    "DBLP": "journals/corr/abs-2202-12533",
                    "CorpusId": 247154862
                },
                "corpusId": 247154862,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/13f39de00f38909256f64e1be7071096788cae3d",
                "title": "Improved Dual Correlation Reduction Network",
                "abstract": "Deep graph clustering, which aims to reveal the underlying graph structure and divide the nodes into different clusters without human annotations, is a fundamental yet challenging task. However, we observed that the existing methods suffer from the representation collapse problem and easily tend to encode samples with different classes into the same latent embedding. Consequently, the discriminative capability of nodes is limited, resulting in sub-optimal clustering performance. To address this problem, we propose a novel deep graph clustering algorithm termed Improved Dual Correlation Reduction Network (IDCRN) through improving the discriminative capability of samples. Specifically, by approximating the cross-view feature correlation matrix to an identity matrix, we reduce the redundancy between different dimensions of features, thus improving the discriminative capability of the latent space explicitly. Meanwhile, the cross-view sample correlation matrix is forced to approximate the designed clustering-refined adjacency matrix to guide the learned latent representation to recover the affinity matrix even across views, thus enhancing the discriminative capability of features implicitly. Moreover, we avoid the collapsed representation caused by the over-smoothing issue in Graph Convolutional Networks (GCNs) through an introduced propagation regularization term, enabling IDCRN to capture the long-range information with the shallow network structure. Extensive experimental results on six benchmarks have demonstrated the effectiveness and the efficiency of IDCRN compared to the existing state-of-the-art deep graph clustering algorithms.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2119034129",
                        "name": "Yue Liu"
                    },
                    {
                        "authorId": "2516087",
                        "name": "Sihang Zhou"
                    },
                    {
                        "authorId": "2130021053",
                        "name": "Xinwang Liu"
                    },
                    {
                        "authorId": "1381761887",
                        "name": "Wenxuan Tu"
                    },
                    {
                        "authorId": "2154476091",
                        "name": "Xihong Yang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "The recent focus in research has gradually shifted to only minimizing the distance between the positive pairs without simultaneously maximizing the distance between negative pairs [8, 9, 10].",
                "The paper[10] also highlights the impact of a potential asymmetry with the larger number of negative keys than the number of positive keys skewing the learning."
            ],
            "citingPaper": {
                "paperId": "16b222243bc96f930d0b7759329e044e899f852d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2202-12921",
                    "ArXiv": "2202.12921",
                    "DOI": "10.1109/ICIP46576.2022.9897745",
                    "CorpusId": 247158112
                },
                "corpusId": 247158112,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/16b222243bc96f930d0b7759329e044e899f852d",
                "title": "Refining Self-Supervised Learning in Imaging: Beyond Linear Metric",
                "abstract": "We introduce in this paper a new statistical perspective, exploiting the Jaccard similarity metric, as a measure-based metric to effectively invoke non-linear features in the loss of self-supervised contrastive learning. Specifically, our proposed metric may be interpreted as a dependence measure between two adapted projections learned from the so-called latent representations. This is in contrast to the cosine similarity measure in the conventional contrastive learning model, which accounts for correlation information. To the best of our knowledge, this effectively non-linearly fused information embedded in the Jaccard similarity, is novel to self-supervision learning with promising results. The proposed approach is compared to two state-of-the-art self-supervised contrastive learning methods on three image datasets. We not only demonstrate its amenable applicability in current ML problems, but also its improved performance and training efficiency.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40072386",
                        "name": "Bo-Wei Jiang"
                    },
                    {
                        "authorId": "145087510",
                        "name": "H. Krim"
                    },
                    {
                        "authorId": "47353858",
                        "name": "Tianfu Wu"
                    },
                    {
                        "authorId": "49347259",
                        "name": "D. Cansever"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "MSI dataset is binned between the (m/z) range of [50, 1000] to 1024 bins.",
                "We vary k in the interval of [50, 1000] with a sensible step."
            ],
            "citingPaper": {
                "paperId": "08a8bcde4cd1c022e376fbc25aea3ba6abe07aef",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2202-06914",
                    "ArXiv": "2202.06914",
                    "DOI": "10.1109/TNNLS.2023.3265607",
                    "CorpusId": 246822477,
                    "PubMed": "37126634"
                },
                "corpusId": 246822477,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/08a8bcde4cd1c022e376fbc25aea3ba6abe07aef",
                "title": "A Generic Self-Supervised Framework of Learning Invariant Discriminative Features",
                "abstract": "Self-supervised learning (SSL) has become a popular method for generating invariant representations without the need for human annotations. Nonetheless, the desired invariant representation is achieved by utilizing prior online transformation functions on the input data. As a result, each SSL framework is customized for a particular data type, for example, visual data, and further modifications are required if it is used for other dataset types. On the other hand, autoencoder (AE), which is a generic and widely applicable framework, mainly focuses on dimension reduction and is not suited for learning invariant representation. This article proposes a generic SSL framework based on a constrained self-labeling assignment process that prevents degenerate solutions. Specifically, the prior transformation functions are replaced with a self-transformation mechanism, derived through an unsupervised training process of adversarial training, for imposing invariant representations. Via the self-transformation mechanism, pairs of augmented instances can be generated from the same input data. Finally, a training objective based on contrastive learning is designed by leveraging both the self-labeling assignment and the self-transformation mechanism. Despite the fact that the self-transformation process is very generic, the proposed training strategy outperforms a majority of state-of-the-art representation learning methods based on AE structures. To validate the performance of our method, we conduct experiments on four types of data, namely visual, audio, text, and mass spectrometry data and compare them in terms of four quantitative metrics. Our comparison results demonstrate that the proposed method is effective and robust in identifying patterns within the tested datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2007743892",
                        "name": "Foivos Ntelemis"
                    },
                    {
                        "authorId": "2157835870",
                        "name": "Yaochu Jin"
                    },
                    {
                        "authorId": "145128485",
                        "name": "S. Thomas"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "4df8db87bce83ebdb093f39698a6b661d7960256",
                "externalIds": {
                    "ArXiv": "2202.04528",
                    "DBLP": "journals/inffus/PassosPSHA23",
                    "DOI": "10.1016/j.inffus.2022.09.006",
                    "CorpusId": 250264634
                },
                "corpusId": 250264634,
                "publicationVenue": {
                    "id": "06afdd0b-0d85-413f-af8a-c3045c12c561",
                    "name": "Information Fusion",
                    "type": "journal",
                    "alternate_names": [
                        "Inf Fusion"
                    ],
                    "issn": "1566-2535",
                    "url": "https://www.journals.elsevier.com/information-fusion",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/15662535"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4df8db87bce83ebdb093f39698a6b661d7960256",
                "title": "Multimodal audio-visual information fusion using canonical-correlated Graph Neural Network for energy-efficient speech enhancement",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "39795571",
                        "name": "L. A. Passos"
                    },
                    {
                        "authorId": "1400664382",
                        "name": "J. P. Papa"
                    },
                    {
                        "authorId": "9221552",
                        "name": "J. Ser"
                    },
                    {
                        "authorId": "2117797510",
                        "name": "Amir Hussain"
                    },
                    {
                        "authorId": "2064500",
                        "name": "Ahsan Adeel"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "In addition to framework design, theoretical analyses and empirical studies have also been proposed to better understand the behavior and properties of contrastive learning [1, 3, 6, 9, 24, 31, 35, 39, 39, 41, 44, 52]."
            ],
            "citingPaper": {
                "paperId": "a42d557c963f9737ac40111f3a065d842caaf3fc",
                "externalIds": {
                    "ArXiv": "2202.03278",
                    "DBLP": "journals/corr/abs-2202-03278",
                    "DOI": "10.1109/CVPR52688.2022.01556",
                    "CorpusId": 246634338
                },
                "corpusId": 246634338,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a42d557c963f9737ac40111f3a065d842caaf3fc",
                "title": "Crafting Better Contrastive Views for Siamese Representation Learning",
                "abstract": "Recent self-supervised contrastive learning methods greatly benefit from the Siamese structure that aims at minimizing distances between positive pairs. For high performance Siamese representation learning, one of the keys is to design good contrastive pairs. Most previous works simply apply random sampling to make different crops of the same image, which overlooks the semantic information that may degrade the quality of views. In this work, we propose ContrastiveCrop, which could effectively generate better crops for Siamese representation learning. Firstly, a semantic-aware object localization strategy is proposed within the training process in a fully unsupervised manner. This guides us to generate contrastive views which could avoid most false positives (i.e., object vs. background). Moreover, we empirically find that views with similar appearances are trivial for the Siamese model training. Thus, a center-suppressed sampling is further designed to enlarge the variance of crops. Remarkably, our method takes a careful consideration of positive pairs for contrastive learning with negligible extra training overhead. As a plug-and-play and framework-agnostic module, ContrastiveCrop consistently improves SimCLR, MoCo, BYOL, SimSiam by 0.4% \u223c 2.0% classification accuracy on CIFAR-10, CIFAR-100, Tiny ImageNet and STL-10. Superior results are also achieved on downstream detection and segmentation tasks when pre-trained on ImageNet-1K.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115815502",
                        "name": "Xiang Peng"
                    },
                    {
                        "authorId": "2148896193",
                        "name": "Kai Wang"
                    },
                    {
                        "authorId": "46637795",
                        "name": "Zheng Hua Zhu"
                    },
                    {
                        "authorId": "2054451943",
                        "name": "Yang You"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "fb57a29cce4c6e4d6971ccc2f928289703566145",
                "externalIds": {
                    "DBLP": "conf/iclr/LuoWWZ023",
                    "ArXiv": "2203.03539",
                    "CorpusId": 257233135
                },
                "corpusId": 257233135,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/fb57a29cce4c6e4d6971ccc2f928289703566145",
                "title": "Understanding The Robustness of Self-supervised Learning Through Topic Modeling",
                "abstract": "Self-supervised learning has significantly improved the performance of many NLP tasks. However, how can self-supervised learning discover useful representations, and why is it better than traditional approaches such as probabilistic models are still largely unknown. In this paper, we focus on the context of topic modeling and highlight a key advantage of self-supervised learning - when applied to data generated by topic models, self-supervised learning can be oblivious to the specific model, and hence is less susceptible to model misspecification. In particular, we prove that commonly used self-supervised objectives based on reconstruction or contrastive samples can both recover useful posterior information for general topic models. Empirically, we show that the same objectives can perform on par with posterior inference using the correct model, while outperforming posterior inference using misspecified models.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2157861426",
                        "name": "Zeping Luo"
                    },
                    {
                        "authorId": "2157973803",
                        "name": "Shiyou Wu"
                    },
                    {
                        "authorId": "2157861484",
                        "name": "C. Weng"
                    },
                    {
                        "authorId": "2123358667",
                        "name": "Mo Zhou"
                    },
                    {
                        "authorId": "144804200",
                        "name": "Rong Ge"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "To alleviate such constraint, non-contrastive approaches that do not use negative samples have been proposed [23, 5, 71, 63]."
            ],
            "citingPaper": {
                "paperId": "1bb0c5e1eee7bdd679c2a833ad042e0ce56ea71e",
                "externalIds": {
                    "DBLP": "conf/nips/OhKHKSY22",
                    "ArXiv": "2202.01339",
                    "CorpusId": 252846722
                },
                "corpusId": 252846722,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/1bb0c5e1eee7bdd679c2a833ad042e0ce56ea71e",
                "title": "Understanding Cross-Domain Few-Shot Learning Based on Domain Similarity and Few-Shot Difficulty",
                "abstract": "Cross-domain few-shot learning (CD-FSL) has drawn increasing attention for handling large differences between the source and target domains--an important concern in real-world scenarios. To overcome these large differences, recent works have considered exploiting small-scale unlabeled data from the target domain during the pre-training stage. This data enables self-supervised pre-training on the target domain, in addition to supervised pre-training on the source domain. In this paper, we empirically investigate which pre-training is preferred based on domain similarity and few-shot difficulty of the target domain. We discover that the performance gain of self-supervised pre-training over supervised pre-training becomes large when the target domain is dissimilar to the source domain, or the target domain itself has low few-shot difficulty. We further design two pre-training schemes, mixed-supervised and two-stage learning, that improve performance. In this light, we present six findings for CD-FSL, which are supported by extensive experiments and analyses on three source and eight target benchmark datasets with varying levels of domain similarity and few-shot difficulty. Our code is available at https://github.com/sungnyun/understanding-cdfsl.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "46299565",
                        "name": "Jaehoon Oh"
                    },
                    {
                        "authorId": "2109662037",
                        "name": "Sungnyun Kim"
                    },
                    {
                        "authorId": "2047104015",
                        "name": "Namgyu Ho"
                    },
                    {
                        "authorId": "2116515859",
                        "name": "Jin-Hwa Kim"
                    },
                    {
                        "authorId": "22656934",
                        "name": "Hwanjun Song"
                    },
                    {
                        "authorId": "70509252",
                        "name": "Se-Young Yun"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "The theory behind is under investigation (Chen & He, 2021; Tian et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "0228d04512e04306ed5971117a4e07d11df458b8",
                "externalIds": {
                    "DBLP": "conf/iclr/HuangZY0022",
                    "ArXiv": "2201.10207",
                    "CorpusId": 246276212
                },
                "corpusId": 246276212,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0228d04512e04306ed5971117a4e07d11df458b8",
                "title": "SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training",
                "abstract": "We introduce a new approach for speech pre-training named SPIRAL which works by learning denoising representation of perturbed data in a teacher-student framework. Specifically, given a speech utterance, we first feed the utterance to a teacher network to obtain corresponding representation. Then the same utterance is perturbed and fed to a student network. The student network is trained to output representation resembling that of the teacher. At the same time, the teacher network is updated as moving average of student's weights over training steps. In order to prevent representation collapse, we apply an in-utterance contrastive loss as pre-training objective and impose position randomization on the input to the teacher. SPIRAL achieves competitive or better results compared to state-of-the-art speech pre-training method wav2vec 2.0, with significant reduction of training cost (80% for BASE model, 65% for LARGE model). Furthermore, we address the problem of noise-robustness that is critical to real-world speech applications. We propose multi-condition pre-training by perturbing the student's input with various types of additive noise. We demonstrate that multi-condition pre-trained SPIRAL models are more robust to noisy speech (9.0% - 13.3% relative word error rate reduction on real noisy test data), compared to applying multi-condition training solely in the fine-tuning stage. Source code is available at https://github.com/huawei-noah/Speech-Backbones/tree/main/SPIRAL.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2129867182",
                        "name": "WenYong Huang"
                    },
                    {
                        "authorId": "2154958775",
                        "name": "Zhenhe Zhang"
                    },
                    {
                        "authorId": "1851621",
                        "name": "Y. Yeung"
                    },
                    {
                        "authorId": "2110310493",
                        "name": "Xin Jiang"
                    },
                    {
                        "authorId": "30738758",
                        "name": "Qun Liu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Moreover, Tian et al. (2021) analyzed these non-contrastive siamese frameworks from a theoretical view, justifying some key designs including the stop gradient and asymmetric predictor."
            ],
            "citingPaper": {
                "paperId": "e948f6f74d660d95aed4968faafc6e0b3e46680d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-07344",
                    "ArXiv": "2201.07344",
                    "CorpusId": 246035256
                },
                "corpusId": 246035256,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e948f6f74d660d95aed4968faafc6e0b3e46680d",
                "title": "Lung Swapping Autoencoder: Learning a Disentangled Structure-texture Representation of Chest Radiographs",
                "abstract": "Well-labeled datasets of chest radiographs (CXRs) are difficult to acquire due to the high cost of annotation. Thus, it is desirable to learn a robust and transferable representation in an unsupervised manner to benefit tasks that lack labeled data. Unlike natural images, medical images have their own domain prior;e.g., we observe that many pulmonary diseases, such as the COVID-19, manifest as changes in the lung tissue texture rather than the anatomical structure. Therefore, we hypothesize that studying only the texture without the influence of structure variations would be advantageous for downstream prognostic and predictive modeling tasks. In this paper, we propose a generative framework, the Lung Swapping Autoencoder (LSAE), that learns factorized representations of a CXR to disentangle the texture factor from the structure factor. Specifically, by adversarial training, the LSAE is optimized to generate a hybrid image that preserves the lung shape in one image but inherits the lung texture of another. To demonstrate the effectiveness of the disentangled texture representation, we evaluate the texture encoder $Enc",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2144764847",
                        "name": "Lei Zhou"
                    },
                    {
                        "authorId": "1782405431",
                        "name": "Joseph Bae"
                    },
                    {
                        "authorId": "49957558",
                        "name": "Huidong Liu"
                    },
                    {
                        "authorId": "1452128653",
                        "name": "Gagandeep Singh"
                    },
                    {
                        "authorId": "2107026074",
                        "name": "Jeremy Green"
                    },
                    {
                        "authorId": "2117777046",
                        "name": "Amit Gupta"
                    },
                    {
                        "authorId": "145654220",
                        "name": "D. Samaras"
                    },
                    {
                        "authorId": "39017169",
                        "name": "P. Prasanna"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "to boost downstream performance on image [165] and video tasks [161]."
            ],
            "citingPaper": {
                "paperId": "3e906906d475c73b6d8ce24ac5ebdac9979fd01b",
                "externalIds": {
                    "DBLP": "journals/pami/SelvaJENMC23",
                    "ArXiv": "2201.05991",
                    "DOI": "10.1109/TPAMI.2023.3243465",
                    "CorpusId": 246015436,
                    "PubMed": "37022830"
                },
                "corpusId": 246015436,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3e906906d475c73b6d8ce24ac5ebdac9979fd01b",
                "title": "Video Transformers: A Survey",
                "abstract": "Transformer models have shown great success handling long-range interactions, making them a promising tool for modeling video. However, they lack inductive biases and scale quadratically with input length. These limitations are further exacerbated when dealing with the high dimensionality introduced by the temporal dimension. While there are surveys analyzing the advances of Transformers for vision, none focus on an in-depth analysis of video-specific designs. In this survey, we analyze the main contributions and trends of works leveraging Transformers to model video. Specifically, we delve into how videos are handled at the input level first. Then, we study the architectural changes made to deal with video more efficiently, reduce redundancy, re-introduce useful inductive biases, and capture long-term temporal dynamics. In addition, we provide an overview of different training regimes and explore effective self-supervised learning strategies for video. Finally, we conduct a performance comparison on the most common benchmark for Video Transformers (i.e., action classification), finding them to outperform 3D ConvNets even with less computational complexity.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2073004411",
                        "name": "Javier Selva"
                    },
                    {
                        "authorId": "2075449066",
                        "name": "A. S. Johansen"
                    },
                    {
                        "authorId": "7855312",
                        "name": "Sergio Escalera"
                    },
                    {
                        "authorId": "2143163793",
                        "name": "Kamal Nasrollahi"
                    },
                    {
                        "authorId": "1700569",
                        "name": "T. Moeslund"
                    },
                    {
                        "authorId": "2150345448",
                        "name": "Albert Clap'es"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "In the branch without predictor the gradient is not backpropagated during training, which was found to be crucial in preventing collapse to trivial solutions [55]."
            ],
            "citingPaper": {
                "paperId": "609fc1e7566a900e29324a0741c8f4e54e3cad18",
                "externalIds": {
                    "DBLP": "conf/cvpr/Gomez-VillaTYB022",
                    "ArXiv": "2112.15022",
                    "DOI": "10.1109/CVPRW56347.2022.00432",
                    "CorpusId": 245634408
                },
                "corpusId": 245634408,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/609fc1e7566a900e29324a0741c8f4e54e3cad18",
                "title": "Continually Learning Self-Supervised Representations with Projected Functional Regularization",
                "abstract": "Recent self-supervised learning methods are able to learn high-quality image representations and are closing the gap with supervised approaches. However, these methods are unable to acquire new knowledge incrementally \u2013 they are, in fact, mostly used only as a pre-training phase over IID data. In this work we investigate self-supervised methods in continual learning regimes without any replay mechanism. We show that naive functional regularization, also known as feature distillation, leads to lower plasticity and limits continual learning performance. Instead, we propose Projected Functional Regularization in which a separate temporal projection network ensures that the newly learned feature space preserves information of the previous one, while at the same time allowing for the learning of new features. This prevents forgetting while maintaining the plasticity of the learner. Comparison with other incremental learning approaches applied to self-supervision demonstrates that our method obtains competitive performance in different scenarios and on multiple datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1979961602",
                        "name": "Alex Gomez-Villa"
                    },
                    {
                        "authorId": "2470703",
                        "name": "Bartlomiej Twardowski"
                    },
                    {
                        "authorId": "2112483864",
                        "name": "Lu Yu"
                    },
                    {
                        "authorId": "1749498",
                        "name": "Andrew D. Bagdanov"
                    },
                    {
                        "authorId": "2820687",
                        "name": "Joost van de Weijer"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "The second line of research further simplify the contrastive assumption, which only imposes invariant constraints between paired positive samples [9, 15, 46, 47] in the absence of the negative samples."
            ],
            "citingPaper": {
                "paperId": "5b55a93d1cfb22a76b7bd3c33e0105437cfada58",
                "externalIds": {
                    "DBLP": "conf/nips/WangLZPYM21",
                    "ArXiv": "2112.08132",
                    "CorpusId": 245010767
                },
                "corpusId": 245010767,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/5b55a93d1cfb22a76b7bd3c33e0105437cfada58",
                "title": "Improving Self-supervised Learning with Automated Unsupervised Outlier Arbitration",
                "abstract": "Our work reveals a structured shortcoming of the existing mainstream self-supervised learning methods. Whereas self-supervised learning frameworks usually take the prevailing perfect instance level invariance hypothesis for granted, we carefully investigate the pitfalls behind. Particularly, we argue that the existing augmentation pipeline for generating multiple positive views naturally introduces out-of-distribution (OOD) samples that undermine the learning of the downstream tasks. Generating diverse positive augmentations on the input does not always pay off in benefiting downstream tasks. To overcome this inherent deficiency, we introduce a lightweight latent variable model UOTA, targeting the view sampling issue for self-supervised learning. UOTA adaptively searches for the most important sampling region to produce views, and provides viable choice for outlier-robust self-supervised learning approaches. Our method directly generalizes to many mainstream self-supervised learning approaches, regardless of the loss's nature contrastive or not. We empirically show UOTA's advantage over the state-of-the-art self-supervised paradigms with evident margin, which well justifies the existence of the OOD sample issue embedded in the existing approaches. Especially, we theoretically prove that the merits of the proposal boil down to guaranteed estimator variance and bias reduction. Code is available: at https://github.com/ssl-codelab/uota.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2153605980",
                        "name": "Yu Wang"
                    },
                    {
                        "authorId": "2144383782",
                        "name": "Jingyang Lin"
                    },
                    {
                        "authorId": "2151688205",
                        "name": "Jingjing Zou"
                    },
                    {
                        "authorId": "3202968",
                        "name": "Yingwei Pan"
                    },
                    {
                        "authorId": "145690248",
                        "name": "Ting Yao"
                    },
                    {
                        "authorId": "2070183551",
                        "name": "Tao Mei"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "result"
            ],
            "contexts": [
                "This aligns with what has been shown in self-supervised learning [41, 42].",
                "[42] Yuandong Tian, Xinlei Chen, and Surya Ganguli."
            ],
            "citingPaper": {
                "paperId": "c271b4d25bc184bc94622cef6c9aba80e8e2cce3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-04716",
                    "ArXiv": "2112.04716",
                    "CorpusId": 245005650
                },
                "corpusId": 245005650,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/c271b4d25bc184bc94622cef6c9aba80e8e2cce3",
                "title": "DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization",
                "abstract": "Despite overparameterization, deep networks trained via supervised learning are easy to optimize and exhibit excellent generalization. One hypothesis to explain this is that overparameterized deep networks enjoy the benefits of implicit regularization induced by stochastic gradient descent, which favors parsimonious solutions that generalize well on test inputs. It is reasonable to surmise that deep reinforcement learning (RL) methods could also benefit from this effect. In this paper, we discuss how the implicit regularization effect of SGD seen in supervised learning could in fact be harmful in the offline deep RL setting, leading to poor generalization and degenerate feature representations. Our theoretical analysis shows that when existing models of implicit regularization are applied to temporal difference learning, the resulting derived regularizer favors degenerate solutions with excessive\"aliasing\", in stark contrast to the supervised learning case. We back up these findings empirically, showing that feature representations learned by a deep network value function trained via bootstrapping can indeed become degenerate, aliasing the representations for state-action pairs that appear on either side of the Bellman backup. To address this issue, we derive the form of this implicit regularizer and, inspired by this derivation, propose a simple and effective explicit regularizer, called DR3, that counteracts the undesirable effects of this implicit regularizer. When combined with existing offline RL methods, DR3 substantially improves performance and stability, alleviating unlearning in Atari 2600 games, D4RL domains and robotic manipulation from images.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1488785534",
                        "name": "Aviral Kumar"
                    },
                    {
                        "authorId": "29767024",
                        "name": "Rishabh Agarwal"
                    },
                    {
                        "authorId": "2114186424",
                        "name": "Tengyu Ma"
                    },
                    {
                        "authorId": "1760871",
                        "name": "Aaron C. Courville"
                    },
                    {
                        "authorId": "145499435",
                        "name": "G. Tucker"
                    },
                    {
                        "authorId": "1736651",
                        "name": "S. Levine"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "5fab44b185fa2148a57f299ed1c96b2d7c3af048",
                "externalIds": {
                    "ArXiv": "2112.05141",
                    "DBLP": "journals/corr/abs-2112-05141",
                    "DOI": "10.1109/CVPR52688.2022.01403",
                    "CorpusId": 245006078
                },
                "corpusId": 245006078,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5fab44b185fa2148a57f299ed1c96b2d7c3af048",
                "title": "Exploring the Equivalence of Siamese Self-Supervised Learning via A Unified Gradient Framework",
                "abstract": "Self-supervised learning has shown its great potential to extract powerful visual representations without human annotations. Various works are proposed to deal with self-supervised learning from different perspectives: (1) contrastive learning methods (e.g., MoCo, SimCLR) utilize both positive and negative samples to guide the training direction; (2) asymmetric network methods (e.g., BYOL, SimSiam) get rid of negative samples via the introduction of a predictor network and the stop-gradient operation; (3) feature decorrelation methods (e.g., Barlow Twins, VICReg) instead aim to reduce the redundancy between feature dimensions. These methods appear to be quite different in the designed loss functions from various motivations. The final accuracy numbers also vary, where different networks and tricks are utilized in different works. In this work, we demonstrate that these methods can be unified into the same form. Instead of comparing their loss functions, we derive a unified formula through gradient analysis. Furthermore, we conduct fair and detailed experiments to compare their performances. It turns out that there is little gap between these methods, and the use of momentum encoder is the key factor to boost performance. From this unified framework, we propose UniGrad, a simple but effective gradient form for self-supervised learning. It does not require a memory bank or a predictor network, but can still achieve state-of-the-art performance and easily adopt other training strategies. Extensive experiments on linear evaluation and many downstream tasks also show its effectiveness. Code shall be released.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "150959424",
                        "name": "Chenxin Tao"
                    },
                    {
                        "authorId": "2109566342",
                        "name": "Honghui Wang"
                    },
                    {
                        "authorId": "2578924",
                        "name": "Xizhou Zhu"
                    },
                    {
                        "authorId": "46436215",
                        "name": "Jiahua Dong"
                    },
                    {
                        "authorId": "30619669",
                        "name": "S. Song"
                    },
                    {
                        "authorId": "2115218570",
                        "name": "Gao Huang"
                    },
                    {
                        "authorId": "3304536",
                        "name": "Jifeng Dai"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "c25fea20e5b5c520be2783dbd0524cc6dc1edaf8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-04215",
                    "ArXiv": "2112.04215",
                    "DOI": "10.1109/CVPR52688.2022.00940",
                    "CorpusId": 244954199
                },
                "corpusId": 244954199,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c25fea20e5b5c520be2783dbd0524cc6dc1edaf8",
                "title": "Self-Supervised Models are Continual Learners",
                "abstract": "Self-supervised models have been shown to produce comparable or better visual representations than their su-pervised counterparts when trained offline on unlabeled data at scale. However, their efficacy is catastrophically reduced in a Continual Learning (CL) scenario where data is presented to the model sequentially. In this paper, we show that self-supervised loss functions can be seamlessly converted into distillation mechanisms for CL by adding a predictor network that maps the current state of the repre-sentations to their past state. This enables us to devise a framework for Continual self-supervised visual representation Learning that (i) significantly improves the quality of the learned representations, (ii) is compatible with several state-of-the-art self-supervised objectives, and (iii) needs little to no hyperparameter tuning. We demonstrate the ef-fectiveness of our approach empirically by training six pop-ular self-supervised models in various CL settings. Code: github.com/DonkeyShot21/cassle.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1399225831",
                        "name": "Enrico Fini"
                    },
                    {
                        "authorId": "88885763",
                        "name": "Victor Costa"
                    },
                    {
                        "authorId": "1382657362",
                        "name": "Xavier Alameda-Pineda"
                    },
                    {
                        "authorId": "40811261",
                        "name": "E. Ricci"
                    },
                    {
                        "authorId": "72492981",
                        "name": "Alahari Karteek"
                    },
                    {
                        "authorId": "2599292",
                        "name": "J. Mairal"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "2121c6910b5f187fdaecf65981ed76a6a668a559",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiC0FYFIK22",
                    "ArXiv": "2111.13998",
                    "DOI": "10.1109/CVPR52688.2022.00679",
                    "CorpusId": 244714744
                },
                "corpusId": 244714744,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2121c6910b5f187fdaecf65981ed76a6a668a559",
                "title": "Targeted Supervised Contrastive Learning for Long-Tailed Recognition",
                "abstract": "Real-world data often exhibits long tail distributions with heavy class imbalance, where the majority classes can dominate the training process and alter the decision bound-aries of the minority classes. Recently, researchers have in-vestigated the potential of supervised contrastive learning for long-tailed recognition, and demonstrated that it provides a strong performance gain. In this paper, we show that while supervised contrastive learning can help improve performance, past baselines suffer from poor uniformity brought in by imbalanced data distribution. This poor uni-formity manifests in samples from the minority class having poor separability in the feature space. To address this problem, we propose targeted supervised contrastive learning (TSC), which improves the uniformity of the feature distribution on the hypersphere. TSC first generates a set of targets uniformly distributed on a hypersphere. It then makes the features of different classes converge to these distinct and uniformly distributed targets during training. This forces all classes, including minority classes, to main-tain a uniform distribution in the feature space, improves class boundaries, and provides better generalization even in the presence of long-tail data. Experiments on multi-ple datasets show that TSC achieves state-of-the-art performance on long-tailed recognition tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118909373",
                        "name": "Tianhong Li"
                    },
                    {
                        "authorId": "152550893",
                        "name": "Peng Cao"
                    },
                    {
                        "authorId": "46499812",
                        "name": "Yuan Yuan"
                    },
                    {
                        "authorId": "2548303",
                        "name": "Lijie Fan"
                    },
                    {
                        "authorId": "2125052692",
                        "name": "Yuzhe Yang"
                    },
                    {
                        "authorId": "1723233",
                        "name": "R. Feris"
                    },
                    {
                        "authorId": "1688317",
                        "name": "P. Indyk"
                    },
                    {
                        "authorId": "1785714",
                        "name": "D. Katabi"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "This paper mainly investigates this phenomenon of non-contrastive representation learning for deep clustering, and the theoretical analysis can be found in [14], [54]."
            ],
            "citingPaper": {
                "paperId": "5eb77a47ac3e014a046af2b318b576c11f5487ed",
                "externalIds": {
                    "ArXiv": "2111.11821",
                    "DBLP": "journals/pami/HuangCZS23",
                    "DOI": "10.1109/TPAMI.2022.3216454",
                    "CorpusId": 252992558,
                    "PubMed": "36269906"
                },
                "corpusId": 252992558,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5eb77a47ac3e014a046af2b318b576c11f5487ed",
                "title": "Learning Representation for Clustering Via Prototype Scattering and Positive Sampling",
                "abstract": "Existing deep clustering methods rely on either contrastive or non-contrastive representation learning for downstream clustering task. Contrastive-based methods thanks to negative pairs learn uniform representations for clustering, in which negative pairs, however, may inevitably lead to the class collision issue and consequently compromise the clustering performance. Non-contrastive-based methods, on the other hand, avoid class collision issue, but the resulting non-uniform representations may cause the collapse of clustering. To enjoy the strengths of both worlds, this paper presents a novel end-to-end deep clustering method with prototype scattering and positive sampling, termed ProPos. Specifically, we first maximize the distance between prototypical representations, named prototype scattering loss, which improves the uniformity of representations. Second, we align one augmented view of instance with the sampled neighbors of another view\u2014assumed to be truly positive pair in the embedding space\u2014to improve the within-cluster compactness, termed positive sampling alignment. The strengths of ProPos are avoidable class collision issue, uniform representations, well-separated clusters, and within-cluster compactness. By optimizing ProPos in an end-to-end expectation-maximization framework, extensive experimental results demonstrate that ProPos achieves competing performance on moderate-scale clustering benchmark datasets and establishes new state-of-the-art performance on large-scale datasets. Source code is available at https://github.com/Hzzone/ProPos.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2158554903",
                        "name": "Zhizhong Huang"
                    },
                    {
                        "authorId": "2186735792",
                        "name": "Jie Chen"
                    },
                    {
                        "authorId": "2144127151",
                        "name": "Junping Zhang"
                    },
                    {
                        "authorId": "3449207",
                        "name": "Hongming Shan"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                ", in the settings of transfer learning [8, 10, 44, 45] and self-supervised learning [26, 34, 43]."
            ],
            "citingPaper": {
                "paperId": "10fb39c01176fe4758169ac01a6476101697d080",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-03135",
                    "ArXiv": "2111.03135",
                    "CorpusId": 243832624
                },
                "corpusId": 243832624,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/10fb39c01176fe4758169ac01a6476101697d080",
                "title": "Scaffolding Sets",
                "abstract": "Predictors map individual instances in a population to the interval $[0,1]$. For a collection $\\mathcal C$ of subsets of a population, a predictor is multi-calibrated with respect to $\\mathcal C$ if it is simultaneously calibrated on each set in $\\mathcal C$. We initiate the study of the construction of scaffolding sets, a small collection $\\mathcal S$ of sets with the property that multi-calibration with respect to $\\mathcal S$ ensures correctness, and not just calibration, of the predictor. Our approach is inspired by the folk wisdom that the intermediate layers of a neural net learn a highly structured and useful data representation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "22224047",
                        "name": "M. Burhanpurkar"
                    },
                    {
                        "authorId": "10394991",
                        "name": "Zhun Deng"
                    },
                    {
                        "authorId": "1781565",
                        "name": "C. Dwork"
                    },
                    {
                        "authorId": "10537441",
                        "name": "Linjun Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "2) Using siamese network [8] to avoid representation collapse [36, 20, 85]."
            ],
            "citingPaper": {
                "paperId": "1da867c102a407171e64e2b28cb2f9ce63325ee6",
                "externalIds": {
                    "ArXiv": "2110.15255",
                    "DBLP": "journals/corr/abs-2110-15255",
                    "CorpusId": 240070938
                },
                "corpusId": 240070938,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/1da867c102a407171e64e2b28cb2f9ce63325ee6",
                "title": "Self-Supervised Learning Disentangled Group Representation as Feature",
                "abstract": "A good visual representation is an inference map from observations (images) to features (vectors) that faithfully reflects the hidden modularized generative factors (semantics). In this paper, we formulate the notion of\"good\"representation from a group-theoretic view using Higgins' definition of disentangled representation, and show that existing Self-Supervised Learning (SSL) only disentangles simple augmentation features such as rotation and colorization, thus unable to modularize the remaining semantics. To break the limitation, we propose an iterative SSL algorithm: Iterative Partition-based Invariant Risk Minimization (IP-IRM), which successfully grounds the abstract semantics and the group acting on them into concrete contrastive learning. At each iteration, IP-IRM first partitions the training samples into two subsets that correspond to an entangled group element. Then, it minimizes a subset-invariant contrastive loss, where the invariance guarantees to disentangle the group element. We prove that IP-IRM converges to a fully disentangled representation and show its effectiveness on various benchmarks. Codes are available at https://github.com/Wangt-CN/IP-IRM.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2116132591",
                        "name": "Tan Wang"
                    },
                    {
                        "authorId": "2068671905",
                        "name": "Zhongqi Yue"
                    },
                    {
                        "authorId": "2154936244",
                        "name": "Jianqiang Huang"
                    },
                    {
                        "authorId": "2138109020",
                        "name": "Qianru Sun"
                    },
                    {
                        "authorId": "2119078220",
                        "name": "Hanwang Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "d87e5e717e469c20cdd11f200fb167573985a1a2",
                "externalIds": {
                    "ArXiv": "2110.11402",
                    "DBLP": "journals/corr/abs-2110-11402",
                    "CorpusId": 239616335
                },
                "corpusId": 239616335,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d87e5e717e469c20cdd11f200fb167573985a1a2",
                "title": "On the Regularization of Autoencoders",
                "abstract": "While much work has been devoted to understanding the implicit (and explicit) regularization of deep nonlinear networks in the supervised setting, this paper focuses on unsupervised learning, i.e., autoencoders are trained with the objective of reproducing the output from the input. We extend recent results [Jin et al. 2021] on unconstrained linear models and apply them to (1) nonlinear autoencoders and (2) constrained linear autoencoders, obtaining the following two results: first, we show that the unsupervised setting by itself induces strong additional regularization, i.e., a severe reduction in the model-capacity of the learned autoencoder: we derive that a deep nonlinear autoencoder cannot fit the training data more accurately than a linear autoencoder does if both models have the same dimensionality in their last hidden layer (and under a few additional assumptions). Our second contribution is concerned with the low-rank EDLAE model [Steck 2020], which is a linear autoencoder with a constraint on the diagonal of the learned low-rank parameter-matrix for improved generalization: we derive a closed-form approximation to the optimum of its non-convex training-objective, and empirically demonstrate that it is an accurate approximation across all model-ranks in our experiments on three well-known data sets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2454529",
                        "name": "H. Steck"
                    },
                    {
                        "authorId": "1401736799",
                        "name": "Dario Garc\u00eda-Garc\u00eda"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "This module is present in a number of contrastive self-supervised learning methods (Chen et al., 2020a; Grill et al., 2020; Zbontar et al., 2021; Tian et al., 2021).",
                "\u2026the dynamics of learning without contrasting pairs is far from trivial and beyond the scope of this paper; we refer the reader to the recent work by Tian et al. (2021) that studies this learning paradigm in depth and discusses why trivial solutions are avoided when learning without negatives as in\u2026",
                "As also recently noted in Tian et al. (2021), a crucial part of learning with non-contrastive pairs is the projector."
            ],
            "citingPaper": {
                "paperId": "8d79a919efeebde4349a504bf83d668b1693f70a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-09455",
                    "ArXiv": "2110.09455",
                    "CorpusId": 239016330
                },
                "corpusId": 239016330,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/8d79a919efeebde4349a504bf83d668b1693f70a",
                "title": "TLDR: Twin Learning for Dimensionality Reduction",
                "abstract": "Dimensionality reduction methods are unsupervised approaches which learn low-dimensional spaces where some properties of the initial space, typically the notion of\"neighborhood\", are preserved. Such methods usually require propagation on large k-NN graphs or complicated optimization solvers. On the other hand, self-supervised learning approaches, typically used to learn representations from scratch, rely on simple and more scalable frameworks for learning. In this paper, we propose TLDR, a dimensionality reduction method for generic input spaces that is porting the recent self-supervised learning framework of Zbontar et al. (2021) to the specific task of dimensionality reduction, over arbitrary representations. We propose to use nearest neighbors to build pairs from a training set and a redundancy reduction loss to learn an encoder that produces representations invariant across such pairs. TLDR is a method that is simple, easy to train, and of broad applicability; it consists of an offline nearest neighbor computation step that can be highly approximated, and a straightforward learning process. Aiming for scalability, we focus on improving linear dimensionality reduction, and show consistent gains on image and document retrieval tasks, e.g. gaining +4% mAP over PCA on ROxford for GeM- AP, improving the performance of DINO on ImageNet or retaining it with a 10x compression.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1944225",
                        "name": "Yannis Kalantidis"
                    },
                    {
                        "authorId": "2131640257",
                        "name": "Carlos Lassance"
                    },
                    {
                        "authorId": "145467588",
                        "name": "Jon Almaz\u00e1n"
                    },
                    {
                        "authorId": "2295553",
                        "name": "Diane Larlus"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "28c17db217f2d7af12482a087d197851f0a97db0",
                "externalIds": {
                    "DBLP": "conf/iclr/JingVLT22",
                    "ArXiv": "2110.09348",
                    "CorpusId": 239016966
                },
                "corpusId": 239016966,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/28c17db217f2d7af12482a087d197851f0a97db0",
                "title": "Understanding Dimensional Collapse in Contrastive Self-supervised Learning",
                "abstract": "Self-supervised visual representation learning aims to learn useful representations without relying on human annotations. Joint embedding approach bases on maximizing the agreement between embedding vectors from different views of the same image. Various methods have been proposed to solve the collapsing problem where all embedding vectors collapse to a trivial constant solution. Among these methods, contrastive learning prevents collapse via negative sample pairs. It has been shown that non-contrastive methods suffer from a lesser collapse problem of a different nature: dimensional collapse, whereby the embedding vectors end up spanning a lower-dimensional subspace instead of the entire available embedding space. Here, we show that dimensional collapse also happens in contrastive learning. In this paper, we shed light on the dynamics at play in contrastive learning that leads to dimensional collapse. Inspired by our theory, we propose a novel contrastive learning method, called DirectCLR, which directly optimizes the representation space without relying on an explicit trainable projector. Experiments show that DirectCLR outperforms SimCLR with a trainable linear projector on ImageNet.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "50780902",
                        "name": "Li Jing"
                    },
                    {
                        "authorId": "2065988715",
                        "name": "Pascal Vincent"
                    },
                    {
                        "authorId": "1688882",
                        "name": "Yann LeCun"
                    },
                    {
                        "authorId": "1932187449",
                        "name": "Yuandong Tian"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "b1ffcc3fc04304e9d71643ffbcaead9ecb74bd4a",
                "externalIds": {
                    "ArXiv": "2110.08851",
                    "DBLP": "conf/cvpr/KimC22",
                    "DOI": "10.1109/CVPR52688.2022.00952",
                    "CorpusId": 244773742
                },
                "corpusId": 244773742,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b1ffcc3fc04304e9d71643ffbcaead9ecb74bd4a",
                "title": "Unsupervised Representation Learning for Binary Networks by Joint Classifier Learning",
                "abstract": "Self-supervised learning is a promising unsupervised learning framework that has achieved success with large floating point networks. But such networks are not readily deployable to edge devices. To accelerate deployment of models with the benefit of unsupervised representation learning to such resource limited devices for various downstream tasks, we propose a self-supervised learning method for binary networks that uses a moving target network. In particular, we propose to Jointly train a randomly initialized classifier, attached to a pretrained floating point feature extractor, with a binary network. Additionally, we propose a feature similarity loss, a dynamic loss balancing and modified multi-stage training to further improve the accuracy, and call our method BURN. Our empirical validations over five downstream tasks using seven datasets show that BURN outperforms self-supervised baselines for binary networks and sometimes outperforms supervised pretraining. Code is availabe at https://github.com/naver-ai/burn.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Dahyun Kim"
                    },
                    {
                        "authorId": "2112287145",
                        "name": "Jonghyun Choi"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "To reduce the annotation cost for representation learning, self-supervised representation learning (SSL) methods including (Goyal et al., 2021; Tian et al., 2021a; Zbontar et al., 2021; Tian et al., 2020b;a; Chen et al., 2020a; He et al., 2020; Tian et al., 2020b; Chen et al., 2020b) and many more\u2026",
                "\u2026point (FP) networks (Goyal et al., 2021; Tian et al., 2021a; Zbontar et al., 2021; Li et al., 2021a; Cai et al., 2021; Ericsson et al., 2021; Tian et al., 2021b; Ermolov et al., 2021; Tian et al., 2020b; Chen et al., 2020b; Grill et al., 2020; Caron et al., 2020; He et al., 2020) that\u2026",
                "Recent years have witnessed great successes in self-supervised learning (SSL) for floating point (FP) networks (Goyal et al., 2021; Tian et al., 2021a; Zbontar et al., 2021; Li et al., 2021a; Cai et al., 2021; Ericsson et al., 2021; Tian et al., 2021b; Ermolov et al., 2021; Tian et al., 2020b; Chen\u2026",
                "A.3 DISCUSSION ON COMPARISON TO SUPERVISED PRETRAINING\nFollowing the previous literature (Zbontar et al., 2021; Goyal et al., 2021; Tian et al., 2021a; Grill et al., 2020; Caron et al., 2020; He et al., 2020), we used the same amount of labeled and unlabeled data for supervised pretraining or BSSL."
            ],
            "citingPaper": {
                "paperId": "ae045404941ed76257e759a7432888581a040292",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-08851",
                    "CorpusId": 239016638
                },
                "corpusId": 239016638,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/ae045404941ed76257e759a7432888581a040292",
                "title": "Self-Supervised Learning for Binary Networks by Joint Classifier Training",
                "abstract": "Despite the great success of self-supervised learning with large floating point networks, such networks are not readily deployable to edge devices. To accelerate deployment of models to edge devices for various downstream tasks by unsupervised representation learning, we propose a self-supervised learning method for binary networks. In particular, we propose to use a randomly initialized classifier attached to a pretrained floating point feature extractor as targets and jointly train it with a binary network. For better training of the binary network, we propose a feature similarity loss, a dynamic balancing scheme of loss terms, and modified multi-stage training. We call our method as BSSL. Our empirical validations show that BSSL outperforms self-supervised learning baselines for binary networks in various downstream tasks and outperforms supervised pretraining in certain tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Dahyun Kim"
                    },
                    {
                        "authorId": "2112287145",
                        "name": "Jonghyun Choi"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Several works have also theoretically studied the success of self-supervised learning [Arora et al., 2019, HaoChen et al., 2021, Wei et al., 2021, Lee et al., 2020b, Tian et al., 2021, Tosh et al., 2020, 2021]."
            ],
            "citingPaper": {
                "paperId": "a01ac66f5f66a2b23152f631b920972e4407275c",
                "externalIds": {
                    "ArXiv": "2110.05025",
                    "DBLP": "journals/corr/abs-2110-05025",
                    "CorpusId": 238583191
                },
                "corpusId": 238583191,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a01ac66f5f66a2b23152f631b920972e4407275c",
                "title": "Self-supervised Learning is More Robust to Dataset Imbalance",
                "abstract": "Self-supervised learning (SSL) is a scalable way to learn general visual representations since it learns without labels. However, large-scale unlabeled datasets in the wild often have long-tailed label distributions, where we know little about the behavior of SSL. In this work, we systematically investigate self-supervised learning under dataset imbalance. First, we find out via extensive experiments that off-the-shelf self-supervised representations are already more robust to class imbalance than supervised representations. The performance gap between balanced and imbalanced pre-training with SSL is significantly smaller than the gap with supervised learning, across sample sizes, for both in-domain and, especially, out-of-domain evaluation. Second, towards understanding the robustness of SSL, we hypothesize that SSL learns richer features from frequent data: it may learn label-irrelevant-but-transferable features that help classify the rare classes and downstream tasks. In contrast, supervised learning has no incentive to learn features irrelevant to the labels from frequent examples. We validate this hypothesis with semi-synthetic experiments and theoretical analyses on a simplified setting. Third, inspired by the theoretical insights, we devise a re-weighted regularization technique that consistently improves the SSL representation quality on imbalanced datasets with several evaluation criteria, closing the small gap between balanced and imbalanced datasets with the same number of examples.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118903632",
                        "name": "Hong Liu"
                    },
                    {
                        "authorId": "134168070",
                        "name": "Jeff Z. HaoChen"
                    },
                    {
                        "authorId": "1799820",
                        "name": "Adrien Gaidon"
                    },
                    {
                        "authorId": "2114186424",
                        "name": "Tengyu Ma"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "In this paper, we make a first attempt towards the second question, by studying a family of algorithms named DirectSet(\u03b1), in which the DirectPred algorithm proposed by Tian et al. (2021) is a special case with \u03b1 = 1/2.",
                "The numbers for DirectPred, DirectPred (freq=5) and SGD baseline on STL-10/CIFAR-10 are obtained from Tian et al. (2021).",
                "Comparison with Tian et al. (2021) Tian et al. (2021) only explained why the representation in nc-SSL does not collapse to zero, but did not study what representation is learned and how the representation is related to the data distribution and augmentation process.",
                "Tian et al. (2021) also analyzed nc-SSL on a linear network, but did not analyze their proposed approach DirectPred.",
                "Our code is adapted from (Tian et al., 2021) 5, and we follow the same data augmentation process.",
                "Note in the previous work (Tian et al., 2021), they assumed the covariance of the augmentation distribution to be \u03c32I and did not study what representation is learned.",
                "While Tian et al. (2021) addressed the first question, i.e., why the learned representation does not collapse to zero, they did not address the second question, i.e., how the training dynamics in nc-SSL leads to a meaningful representation that depends on the data augmentations and reduces the\u2026",
                "Dynamics for \u03bbB: We can write down the dynamics for \u03bbB as follows:\n\u03bb\u0307B = \u03bbB [ \u2212(1 + \u03c32) |\u03bbB |4\u03b1 + |\u03bbB |2\u03b1 \u2212 \u03b7 ] Similar as the analysis in (Tian et al., 2021), when \u03b7 > 14(1+\u03c32) , we know \u03bb\u0307B < 0 for any \u03bbB > 0 and \u03bbB = 0 is a critical point.",
                "Motivated by the analysis, we also design a simpler and more efficient algorithm (DirectCopy), which achieves comparable or even better performances than the original DirectPred proposed by Tian et al. (2021).",
                "Note in the previous work (Tian et al., 2021), they assumed the covariance of the augmentation distribution to be \u03c3(2)I and did not study what representation is learned.",
                "As one of the first work towards this direction, Tian et al. (2021) showed that while the global optimum of the non-contrastive loss is indeed a trivial one, following gradient direction in nc-SSL, one can find a local optimum that admits a nontrivial representation.",
                "Tian et al. (2021) proposed DirectPred that directly sets the predictor based on the correlation matrix of the predictor inputs.",
                "Inspired by the analysis, we designed a simpler and more efficient algorithm DirectCopy, which achieved comparable or even better performance than the original DirectPred (Tian et al., 2021) on various datasets.",
                "Similar as the analysis in Tian et al. (2021), when \u03b7 > 1 4(1+\u03c32) , we know \u03bb\u0307B < 0 for any \u03bbB > 0 and \u03bbB = 0 is a stable stationary point, as illustrated in Figure 4 (Left).",
                "Thresholding role of weight decay in feature learning: While Tian et al. (2021) showed why nc-SSL does not collapse, one key question is how nc-SSL learns useful features and how the method determines which feature is learned."
            ],
            "citingPaper": {
                "paperId": "8746e08cd315dcfbed09d62a32b489d3c20fdbe4",
                "externalIds": {
                    "ArXiv": "2110.04947",
                    "DBLP": "journals/corr/abs-2110-04947",
                    "CorpusId": 238583030
                },
                "corpusId": 238583030,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8746e08cd315dcfbed09d62a32b489d3c20fdbe4",
                "title": "Towards Demystifying Representation Learning with Non-contrastive Self-supervision",
                "abstract": "Non-contrastive methods of self-supervised learning (such as BYOL and SimSiam) learn representations by minimizing the distance between two views of the same image. These approaches have achieved remarkable performance in practice, but the theoretical understanding lags behind. Tian et al. 2021 explained why the representation does not collapse to zero, however, how the feature is learned still remains mysterious. In our work, we prove in a linear network, non-contrastive methods learn a desirable projection matrix and also reduce the sample complexity on downstream tasks. Our analysis suggests that weight decay acts as an implicit threshold that discards the features with high variance under data augmentations, and keeps the features with low variance. Inspired by our theory, we design a simpler and more computationally efficient algorithm DirectCopy by removing the eigen-decomposition step in the original DirectPred algorithm in Tian et al. 2021. Our experiments show that DirectCopy rivals or even outperforms DirectPred on STL-10, CIFAR-10, CIFAR-100, and ImageNet.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2144799011",
                        "name": "Xiang Wang"
                    },
                    {
                        "authorId": "1639441927",
                        "name": "Xinlei Chen"
                    },
                    {
                        "authorId": "145697585",
                        "name": "S. Du"
                    },
                    {
                        "authorId": "1932187449",
                        "name": "Yuandong Tian"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Stop-gradient For the optimization on variational representation reconstruction, related work have found that adding the stop-gradient operator (SG) as a regularizer can make the training more stable without collapse both empirically [11, 28] and theoretically [73].",
                "27 [73] Yuandong Tian, Xinlei Chen, and Surya Ganguli."
            ],
            "citingPaper": {
                "paperId": "b8f816e23ff40d6afabccca2ee4770087ef0ef57",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-07728",
                    "ArXiv": "2110.07728",
                    "CorpusId": 239009574
                },
                "corpusId": 239009574,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b8f816e23ff40d6afabccca2ee4770087ef0ef57",
                "title": "Pre-training Molecular Graph Representation with 3D Geometry",
                "abstract": "Molecular graph representation learning is a fundamental problem in modern drug and material discovery. Molecular graphs are typically modeled by their 2D topological structures, but it has been recently discovered that 3D geometric information plays a more vital role in predicting molecular functionalities. However, the lack of 3D information in real-world scenarios has significantly impeded the learning of geometric graph representation. To cope with this challenge, we propose the Graph Multi-View Pre-training (GraphMVP) framework where self-supervised learning (SSL) is performed by leveraging the correspondence and consistency between 2D topological structures and 3D geometric views. GraphMVP effectively learns a 2D molecular graph encoder that is enhanced by richer and more discriminative 3D geometry. We further provide theoretical insights to justify the effectiveness of GraphMVP. Finally, comprehensive experiments show that GraphMVP can consistently outperform existing graph SSL methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1563693999",
                        "name": "Shengchao Liu"
                    },
                    {
                        "authorId": "97699982",
                        "name": "Hanchen Wang"
                    },
                    {
                        "authorId": "36326884",
                        "name": "Weiyang Liu"
                    },
                    {
                        "authorId": "1764249",
                        "name": "Joan Lasenby"
                    },
                    {
                        "authorId": "1694050",
                        "name": "Hongyu Guo"
                    },
                    {
                        "authorId": "152226504",
                        "name": "Jian Tang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Moreover, Wen and Li (2021) considered the representation learning under the sparse coding model and studied the optimization properties on shallow ReLU neural networks, (Tian et al., 2021; Wang et al., 2021) investigated why self-supervised learning can learn features without contrastive pairs in a linear representation setting, and (Jing et al."
            ],
            "citingPaper": {
                "paperId": "d20266067e984e79a1e7b8f444a275ad368cea49",
                "externalIds": {
                    "ArXiv": "2110.02473",
                    "DBLP": "journals/corr/abs-2110-02473",
                    "CorpusId": 238407826
                },
                "corpusId": 238407826,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d20266067e984e79a1e7b8f444a275ad368cea49",
                "title": "The Power of Contrast for Feature Learning: A Theoretical Analysis",
                "abstract": "Contrastive learning has achieved state-of-the-art performance in various self-supervised learning tasks and even outperforms its supervised counterpart. Despite its empirical success, theoretical understanding of why contrastive learning works is still limited. In this paper, (i) we provably show that contrastive learning outperforms autoencoder, a classical unsupervised learning method, for both feature recovery and downstream tasks; (ii) we also illustrate the role of labeled data in supervised contrastive learning. This provides theoretical support for recent findings that contrastive learning with labels improves the performance of learned representations in the in-domain downstream task, but it can harm the performance in transfer learning. We verify our theory with numerical experiments.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2150078690",
                        "name": "Wenlong Ji"
                    },
                    {
                        "authorId": "10394991",
                        "name": "Zhun Deng"
                    },
                    {
                        "authorId": "150280620",
                        "name": "Ryumei Nakada"
                    },
                    {
                        "authorId": "145085305",
                        "name": "James Y. Zou"
                    },
                    {
                        "authorId": "10537441",
                        "name": "Linjun Zhang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Recent theoretical works have also shed light on why the linear predictor and gradient block help prevent collapse (Tian et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "d3e624042310f7de8ccb6e1312686bceba856abe",
                "externalIds": {
                    "DBLP": "journals/ficn/TangYA22",
                    "ArXiv": "2109.15089",
                    "PubMedCentral": "8977509",
                    "DOI": "10.3389/fncom.2022.789253",
                    "CorpusId": 238226713,
                    "PubMed": "35386856"
                },
                "corpusId": 238226713,
                "publicationVenue": {
                    "id": "8c456f98-9892-42ac-9b16-418755f01550",
                    "name": "Frontiers in Computational Neuroscience",
                    "type": "journal",
                    "alternate_names": [
                        "Front Comput Neurosci"
                    ],
                    "issn": "1662-5188",
                    "url": "http://www.frontiersin.org/computational_neuroscience",
                    "alternate_urls": [
                        "http://www.frontiersin.org/computationalneuroscience/",
                        "https://www.frontiersin.org/journals/computational-neuroscience"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d3e624042310f7de8ccb6e1312686bceba856abe",
                "title": "Biologically Plausible Training Mechanisms for Self-Supervised Learning in Deep Networks",
                "abstract": "We develop biologically plausible training mechanisms for self-supervised learning (SSL) in deep networks. Specifically, by biologically plausible training we mean (i) all updates of weights are based on current activities of pre-synaptic units and current, or activity retrieved from short term memory of post synaptic units, including at the top-most error computing layer, (ii) complex computations such as normalization, inner products and division are avoided, (iii) asymmetric connections between units, and (iv) most learning is carried out in an unsupervised manner. SSL with a contrastive loss satisfies the third condition as it does not require labeled data and it introduces robustness to observed perturbations of objects, which occur naturally as objects or observers move in 3D and with variable lighting over time. We propose a contrastive hinge based loss whose error involves simple local computations satisfying (ii), as opposed to the standard contrastive losses employed in the literature, which do not lend themselves easily to implementation in a network architecture due to complex computations involving ratios and inner products. Furthermore, we show that learning can be performed with one of two more plausible alternatives to backpropagation that satisfy conditions (i) and (ii). The first is difference target propagation (DTP), which trains network parameters using target-based local losses and employs a Hebbian learning rule, thus overcoming the biologically implausible symmetric weight problem in backpropagation. The second is layer-wise learning, where each layer is directly connected to a layer computing the loss error. The layers are either updated sequentially in a greedy fashion (GLL) or in random order (RLL), and each training stage involves a single hidden layer network. Backpropagation through one layer needed for each such network can either be altered with fixed random feedback weights (RF) or using updated random feedback weights (URF) as in Amity's study 2019. Both methods represent alternatives to the symmetric weight issue of backpropagation. By training convolutional neural networks (CNNs) with SSL and DTP, GLL or RLL, we find that our proposed framework achieves comparable performance to standard BP learning downstream linear classifier evaluation of the learned embeddings.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152363021",
                        "name": "Mufeng Tang"
                    },
                    {
                        "authorId": "2130306785",
                        "name": "Yibo Yang"
                    },
                    {
                        "authorId": "4801654",
                        "name": "Y. Amit"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "4400f860cabc7ece02294d7b286bd1097a72c2a5",
                "externalIds": {
                    "ArXiv": "2109.01116",
                    "DBLP": "conf/nips/0001XLW21",
                    "CorpusId": 235430960
                },
                "corpusId": 235430960,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/4400f860cabc7ece02294d7b286bd1097a72c2a5",
                "title": "An Empirical Study of Graph Contrastive Learning",
                "abstract": "Graph Contrastive Learning (GCL) establishes a new paradigm for learning graph representations without human annotations. Although remarkable progress has been witnessed recently, the success behind GCL is still left somewhat mysterious. In this work, we first identify several critical design considerations within a general GCL paradigm, including augmentation functions, contrasting modes, contrastive objectives, and negative mining techniques. Then, to understand the interplay of different GCL components, we conduct extensive, controlled experiments over a set of benchmark tasks on datasets across various domains. Our empirical studies suggest a set of general receipts for effective GCL, e.g., simple topology augmentations that produce sparse graph views bring promising performance improvements; contrasting modes should be aligned with the granularities of end tasks. In addition, to foster future research and ease the implementation of GCL algorithms, we develop an easy-to-use library PyGCL, featuring modularized CL components, standardized evaluation, and experiment management. We envision this work to provide useful empirical evidence of effective GCL algorithms and offer several insights for future research.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2653121",
                        "name": "Yanqiao Zhu"
                    },
                    {
                        "authorId": "47103911",
                        "name": "Yichen Xu"
                    },
                    {
                        "authorId": "2146553789",
                        "name": "Qiang Liu"
                    },
                    {
                        "authorId": "50425438",
                        "name": "Shu Wu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "6341ae08b074d1b39eb689e82db29e8abf39b1fa",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-02696",
                    "ArXiv": "2108.02696",
                    "DOI": "10.1109/TPAMI.2022.3180995",
                    "CorpusId": 236924643,
                    "PubMed": "35679387"
                },
                "corpusId": 236924643,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6341ae08b074d1b39eb689e82db29e8abf39b1fa",
                "title": "A Low Rank Promoting Prior for Unsupervised Contrastive Learning",
                "abstract": "Unsupervised learning is just at a tipping point where it could really take off. Among these approaches, contrastive learning has led to state-of-the-art performance. In this paper, we construct a novel probabilistic graphical model that effectively incorporates the low rank promoting prior into the framework of contrastive learning, referred to as LORAC. In contrast to the existing conventional self-supervised approaches that only considers independent learning, our hypothesis explicitly requires that all the samples belonging to the same instance class lie on the same subspace with small dimension. This heuristic poses particular joint learning constraints to reduce the degree of freedom of the problem during the search of the optimal network parameterization. Most importantly, we argue that the low rank prior employed here is not unique, and many different priors can be invoked in a similar probabilistic way, corresponding to different hypotheses about underlying truth behind the contrastive features. Empirical evidences show that the proposed algorithm clearly surpasses the state-of-the-art approaches on multiple benchmarks, including image classification, object detection, instance segmentation and keypoint detection. Code is available: https://github.com/ssl-codelab/lorac.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2153605980",
                        "name": "Yu Wang"
                    },
                    {
                        "authorId": "2144383782",
                        "name": "Jingyang Lin"
                    },
                    {
                        "authorId": "48141156",
                        "name": "Qi Cai"
                    },
                    {
                        "authorId": "3202968",
                        "name": "Yingwei Pan"
                    },
                    {
                        "authorId": "145690248",
                        "name": "Ting Yao"
                    },
                    {
                        "authorId": "47636228",
                        "name": "Hongyang Chao"
                    },
                    {
                        "authorId": "144025741",
                        "name": "Tao Mei"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "The recent advances can be classified into two categories (Tian et al., 2021): contrastive SSL and non-contrastive SSL."
            ],
            "citingPaper": {
                "paperId": "ba80db4354a1edd723e3ea837077ef2da01f079b",
                "externalIds": {
                    "ArXiv": "2107.10419",
                    "CorpusId": 236171245
                },
                "corpusId": 236171245,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ba80db4354a1edd723e3ea837077ef2da01f079b",
                "title": "Trip-ROMA: Self-Supervised Learning with Triplets and Random Mappings",
                "abstract": "Contrastive self-supervised learning (SSL) methods, such as MoCo and SimCLR, have achieved great success in unsupervised visual representation learning. They rely on a large number of negative pairs and thus require either large memory banks or large batches. Some recent non-contrastive SSL methods, such as BYOL and SimSiam, attempt to discard negative pairs and have also shown remarkable performance. To avoid collapsed solutions caused by not using negative pairs, these methods require non-trivial asymmetry designs. However, in small data regimes, we can not obtain a sufficient number of negative pairs or effectively avoid the over-fitting problem when negatives are not used at all. To address this situation, we argue that negative pairs are still important but one is generally sufficient for each positive pair. We show that a simple Triplet-based loss (Trip) can achieve surprisingly good performance without requiring large batches or asymmetry designs. Moreover, to alleviate the over-fitting problem in small data regimes and further enhance the effect of Trip, we propose a simple plug-and-play RandOm MApping (ROMA) strategy by randomly mapping samples into other spaces and requiring these randomly projected samples to satisfy the same relationship indicated by the triplets. Integrating the triplet-based loss with random mapping, we obtain the proposed method Trip-ROMA. Extensive experiments, including unsupervised representation learning and unsupervised few-shot learning, have been conducted on ImageNet-1K and seven small datasets. They successfully demonstrate the effectiveness of Trip-ROMA and consistently show that ROMA can further effectively boost other SSL methods. Code is available at https://github.com/WenbinLee/Trip-ROMA.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2108691450",
                        "name": "Wenbin Li"
                    },
                    {
                        "authorId": "2145180721",
                        "name": "Xuesong Yang"
                    },
                    {
                        "authorId": "2120272947",
                        "name": "Meihao Kong"
                    },
                    {
                        "authorId": null,
                        "name": "Lei Wang"
                    },
                    {
                        "authorId": "2055851838",
                        "name": "Jing Huo"
                    },
                    {
                        "authorId": "145644819",
                        "name": "Yang Gao"
                    },
                    {
                        "authorId": "2116782926",
                        "name": "Jiebo Luo"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "This operation has also been shown to be crucial in siamese, non-contrastive, self-supervised learning, both empirically [21, 12] and theoretically [36]."
            ],
            "citingPaper": {
                "paperId": "ad18ebb679d6eabcd01ed5492916a8abab6a3d75",
                "externalIds": {
                    "DBLP": "conf/nips/CachayBD21",
                    "ArXiv": "2107.02233",
                    "CorpusId": 235742646
                },
                "corpusId": 235742646,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/ad18ebb679d6eabcd01ed5492916a8abab6a3d75",
                "title": "End-to-End Weak Supervision",
                "abstract": "Aggregating multiple sources of weak supervision (WS) can ease the data-labeling bottleneck prevalent in many machine learning applications, by replacing the tedious manual collection of ground truth labels. Current state of the art approaches that do not use any labeled training data, however, require two separate modeling steps: Learning a probabilistic latent variable model based on the WS sources -- making assumptions that rarely hold in practice -- followed by downstream model training. Importantly, the first step of modeling does not consider the performance of the downstream model. To address these caveats we propose an end-to-end approach for directly learning the downstream model by maximizing its agreement with probabilistic labels generated by reparameterizing previous probabilistic posteriors with a neural network. Our results show improved performance over prior work in terms of end model performance on downstream test sets, as well as in terms of improved robustness to dependencies among weak supervision sources.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2030978299",
                        "name": "Salva R\u00fchling Cachay"
                    },
                    {
                        "authorId": "2854169",
                        "name": "Benedikt Boecking"
                    },
                    {
                        "authorId": "144292541",
                        "name": "A. Dubrawski"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "We next provide a variance-covariance perspective to the new objective, following similar lines of reasoning in [41, 42].",
                "However, though BGRL could avoid collapse empirically, it still remains as an open problem concerning its theoretical guarantee for preventing trivial solutions [41]."
            ],
            "citingPaper": {
                "paperId": "e7b666c5ff82321cd35cfe5af3deb026ea0d3059",
                "externalIds": {
                    "DBLP": "conf/nips/ZhangWYWY21",
                    "ArXiv": "2106.12484",
                    "CorpusId": 235606326
                },
                "corpusId": 235606326,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/e7b666c5ff82321cd35cfe5af3deb026ea0d3059",
                "title": "From Canonical Correlation Analysis to Self-supervised Graph Neural Networks",
                "abstract": "We introduce a conceptually simple yet effective model for self-supervised representation learning with graph data. It follows the previous methods that generate two views of an input graph through data augmentation. However, unlike contrastive methods that focus on instance-level discrimination, we optimize an innovative feature-level objective inspired by classical Canonical Correlation Analysis. Compared with other works, our approach requires none of the parameterized mutual information estimator, additional projector, asymmetric structures, and most importantly, negative samples which can be costly. We show that the new objective essentially 1) aims at discarding augmentation-variant information by learning invariant representations, and 2) can prevent degenerated solutions by decorrelating features in different dimensions. Our theoretical analysis further provides an understanding for the new objective which can be equivalently seen as an instantiation of the Information Bottleneck Principle under the self-supervised setting. Despite its simplicity, our method performs competitively on seven public graph datasets. The code is available at: https://github.com/hengruizhang98/CCA-SSG.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2153528046",
                        "name": "Hengrui Zhang"
                    },
                    {
                        "authorId": "51171144",
                        "name": "Qitian Wu"
                    },
                    {
                        "authorId": "3063894",
                        "name": "Junchi Yan"
                    },
                    {
                        "authorId": "2242717",
                        "name": "D. Wipf"
                    },
                    {
                        "authorId": "152297693",
                        "name": "Philip S. Yu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "It is an interesting question to understand the design decisions in these pipelines (Tian et al., 2021), but this is outside the scope of the present paper."
            ],
            "citingPaper": {
                "paperId": "1dc01a5383c6380bae943405f15a0b34f7021400",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-09943",
                    "ArXiv": "2106.09943",
                    "CorpusId": 235485473
                },
                "corpusId": 235485473,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1dc01a5383c6380bae943405f15a0b34f7021400",
                "title": "Investigating the Role of Negatives in Contrastive Representation Learning",
                "abstract": "Noise contrastive learning is a popular technique for unsupervised representation learning. In this approach, a representation is obtained via reduction to supervised learning, where given a notion of semantic similarity, the learner tries to distinguish a similar (positive) example from a collection of random (negative) examples. The success of modern contrastive learning pipelines relies on many parameters such as the choice of data augmentation, the number of negative examples, and the batch size; however, there is limited understanding as to how these parameters interact and affect downstream performance. We focus on disambiguating the role of one of these parameters: the number of negative examples. Theoretically, we show the existence of a collision-coverage trade-off suggesting that the optimal number of negative examples should scale with the number of underlying concepts in the data. Empirically, we scrutinize the role of the number of negatives in both NLP and vision tasks. In the NLP task, we find that the results broadly agree with our theory, while our vision experiments are murkier with performance sometimes even being insensitive to the number of negatives. We discuss plausible explanations for this behavior and suggest future directions to better align theory and practice.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "40401847",
                        "name": "J. Ash"
                    },
                    {
                        "authorId": "9935792",
                        "name": "Surbhi Goel"
                    },
                    {
                        "authorId": "37019006",
                        "name": "A. Krishnamurthy"
                    },
                    {
                        "authorId": "31498163",
                        "name": "Dipendra Kumar Misra"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "\u2026started exploring this direction in both nonlinear CCA and AM-SSL (see, e.g., (Lyu & Fu, 2020; von Ku\u0308gelgen et al., 2021; Zimmermann et al., 2021; Tian et al., 2021; Saunshi et al., 2019; Tosh et al., 2021)), but more insights and theoretical underpinnings remain to be discovered under more\u2026",
                ", (Lyu & Fu, 2020; von K\u00fcgelgen et al., 2021; Zimmermann et al., 2021; Tian et al., 2021; Saunshi et al., 2019; Tosh et al., 2021)), but more insights and theoretical underpinnings remain to be discovered under more realistic and challenging settings."
            ],
            "citingPaper": {
                "paperId": "72311c24962cd27b0f7820ece1895f4d416d26ac",
                "externalIds": {
                    "DBLP": "conf/iclr/Lyu0WL22",
                    "ArXiv": "2106.07115",
                    "CorpusId": 248084993
                },
                "corpusId": 248084993,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/72311c24962cd27b0f7820ece1895f4d416d26ac",
                "title": "Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective",
                "abstract": "Multiple views of data, both naturally acquired (e.g., image and audio) and artificially produced (e.g., via adding different noise to data samples), have proven useful in enhancing representation learning. Natural views are often handled by multiview analysis tools, e.g., (deep) canonical correlation analysis [(D)CCA], while the artificial ones are frequently used in self-supervised learning (SSL) paradigms, e.g., BYOL and Barlow Twins. Both types of approaches often involve learning neural feature extractors such that the embeddings of data exhibit high cross-view correlations. Although intuitive, the effectiveness of correlation-based neural embedding is mostly empirically validated. This work aims to understand latent correlation maximization-based deep multiview learning from a latent component identification viewpoint. An intuitive generative model of multiview data is adopted, where the views are different nonlinear mixtures of shared and private components. Since the shared components are view/distortion-invariant, representing the data using such components is believed to reveal the identity of the samples effectively and robustly. Under this model, latent correlation maximization is shown to guarantee the extraction of the shared components across views (up to certain ambiguities). In addition, it is further shown that the private information in each view can be provably disentangled from the shared using proper regularization design. A finite sample analysis, which has been rare in nonlinear mixture identifiability study, is also presented. The theoretical results and newly designed regularization are tested on a series of tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "20650636",
                        "name": "Qinjie Lyu"
                    },
                    {
                        "authorId": "145089659",
                        "name": "Xiao Fu"
                    },
                    {
                        "authorId": "2117928344",
                        "name": "Weiran Wang"
                    },
                    {
                        "authorId": "1606015788",
                        "name": "Songtao Lu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Interestingly, recent work shows that a variant of simple one-way consistency evades trivial solutions even in the context of self-supervised representation learning [50,51]."
            ],
            "citingPaper": {
                "paperId": "05ba3d10657a0070cdfef3d0427e8507a4d917ec",
                "externalIds": {
                    "DBLP": "journals/sensors/GrubisicOS23",
                    "PubMedCentral": "9865240",
                    "ArXiv": "2106.07075",
                    "DOI": "10.3390/s23020940",
                    "CorpusId": 247058636,
                    "PubMed": "36679735"
                },
                "corpusId": 247058636,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/05ba3d10657a0070cdfef3d0427e8507a4d917ec",
                "title": "Revisiting Consistency for Semi-Supervised Semantic Segmentation",
                "abstract": "Semi-supervised learning is an attractive technique in practical deployments of deep models since it relaxes the dependence on labeled data. It is especially important in the scope of dense prediction because pixel-level annotation requires substantial effort. This paper considers semi-supervised algorithms that enforce consistent predictions over perturbed unlabeled inputs. We study the advantages of perturbing only one of the two model instances and preventing the backward pass through the unperturbed instance. We also propose a competitive perturbation model as a composition of geometric warp and photometric jittering. We experiment with efficient models due to their importance for real-time and low-power applications. Our experiments show clear advantages of (1) one-way consistency, (2) perturbing only the student branch, and (3) strong photometric and geometric perturbations. Our perturbation model outperforms recent work and most of the contribution comes from the photometric component. Experiments with additional data from the large coarsely annotated subset of Cityscapes suggest that semi-supervised training can outperform supervised training with coarse labels. Our source code is available at https://github.com/Ivan1248/semisup-seg-efficient.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "46457820",
                        "name": "I. Grubisic"
                    },
                    {
                        "authorId": "3009751",
                        "name": "Marin Orsic"
                    },
                    {
                        "authorId": "3166278",
                        "name": "Sinisa Segvic"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "[116] Yuandong Tian, Xinlei Chen, and Surya Ganguli."
            ],
            "citingPaper": {
                "paperId": "5b00442bd7e12ac1c614127f1f6429c8df3747bc",
                "externalIds": {
                    "DBLP": "conf/nips/KugelgenSGBSBL21",
                    "ArXiv": "2106.04619",
                    "CorpusId": 235376851
                },
                "corpusId": 235376851,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/5b00442bd7e12ac1c614127f1f6429c8df3747bc",
                "title": "Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style",
                "abstract": "Self-supervised representation learning has shown remarkable success in a number of domains. A common practice is to perform data augmentation via hand-crafted transformations intended to leave the semantics of the data invariant. We seek to understand the empirical success of this approach from a theoretical perspective. We formulate the augmentation process as a latent variable model by postulating a partition of the latent representation into a content component, which is assumed invariant to augmentation, and a style component, which is allowed to change. Unlike prior work on disentanglement and independent component analysis, we allow for both nontrivial statistical and causal dependencies in the latent space. We study the identifiability of the latent representation based on pairs of views of the observations and prove sufficient conditions that allow us to identify the invariant content partition up to an invertible mapping in both generative and discriminative settings. We find numerical simulations with dependent latent variables are consistent with our theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional, visually complex images with rich causal dependencies, which we use to study the effect of data augmentations performed in practice.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51135567",
                        "name": "Julius von K\u00fcgelgen"
                    },
                    {
                        "authorId": "49738125",
                        "name": "Yash Sharma"
                    },
                    {
                        "authorId": "31821560",
                        "name": "Luigi Gresele"
                    },
                    {
                        "authorId": "40634590",
                        "name": "Wieland Brendel"
                    },
                    {
                        "authorId": "1707625",
                        "name": "B. Sch\u00f6lkopf"
                    },
                    {
                        "authorId": "2599082",
                        "name": "M. Besserve"
                    },
                    {
                        "authorId": "9557137",
                        "name": "Francesco Locatello"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Some non-contrastive approaches [36], [90], [91] maximize the similarity of different output versions of the image and avoid negative pairs."
            ],
            "citingPaper": {
                "paperId": "d5db4e9a502799d67bb830b7fb58b4fd97b0a695",
                "externalIds": {
                    "ArXiv": "2106.03149",
                    "DBLP": "journals/corr/abs-2106-03149",
                    "DOI": "10.1109/TPAMI.2022.3218275",
                    "CorpusId": 235358087,
                    "PubMed": "36315550"
                },
                "corpusId": 235358087,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d5db4e9a502799d67bb830b7fb58b4fd97b0a695",
                "title": "Large-Scale Unsupervised Semantic Segmentation",
                "abstract": "Empowered by large datasets, e.g., ImageNet and MS COCO, unsupervised learning on large-scale data has enabled significant advances for classification tasks. However, whether the large-scale unsupervised semantic segmentation can be achieved remains unknown. There are two major challenges: i) we need a large-scale benchmark for assessing algorithms; ii) we need to develop methods to simultaneously learn category and shape representation in an unsupervised manner. In this work, we propose a new problem of large-scale unsupervised semantic segmentation (LUSS) with a newly created benchmark dataset to help the research progress. Building on the ImageNet dataset, we propose the ImageNet-S dataset with 1.2 million training images and 50k high-quality semantic segmentation annotations for evaluation. Our benchmark has a high data diversity and a clear task objective. We also present a simple yet effective method that works surprisingly well for LUSS. In addition, we benchmark related un/weakly/fully supervised methods accordingly, identifying the challenges and possible directions of LUSS. The benchmark and source code is publicly available at https://github.com/LUSSeg.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2112310647",
                        "name": "Shangqi Gao"
                    },
                    {
                        "authorId": "2145415334",
                        "name": "Zhong-Yu Li"
                    },
                    {
                        "authorId": "37144787",
                        "name": "Ming-Hsuan Yang"
                    },
                    {
                        "authorId": "1557350184",
                        "name": "Mingg-Ming Cheng"
                    },
                    {
                        "authorId": "7181955",
                        "name": "Junwei Han"
                    },
                    {
                        "authorId": "143635540",
                        "name": "Philip H. S. Torr"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "[41] provide a theoretical analysis and some insights on how collapse is avoided by asymmetric methods, but the complete dynamics is far from being understood and these methods might not work in other self-supervised learning setups."
            ],
            "citingPaper": {
                "paperId": "0d0cf5f64c052aa7edc5bb638203616a620557f6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2105-04906",
                    "ArXiv": "2105.04906",
                    "CorpusId": 234357520
                },
                "corpusId": 234357520,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0d0cf5f64c052aa7edc5bb638203616a620557f6",
                "title": "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
                "abstract": "Recent self-supervised methods for image representation learning are based on maximizing the agreement between embedding vectors from different views of the same image. A trivial solution is obtained when the encoder outputs constant vectors. This collapse problem is often avoided through implicit biases in the learning architecture, that often lack a clear justification or interpretation. In this paper, we introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitly avoids the collapse problem with a simple regularization term on the variance of the embeddings along each dimension individually. VICReg combines the variance term with a decorrelation mechanism based on redundancy reduction and covariance regularization, and achieves results on par with the state of the art on several downstream tasks. In addition, we show that incorporating our new variance term into other methods helps stabilize the training and leads to performance improvements.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1453740540",
                        "name": "Adrien Bardes"
                    },
                    {
                        "authorId": "144189388",
                        "name": "J. Ponce"
                    },
                    {
                        "authorId": "1688882",
                        "name": "Yann LeCun"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "These properties have been leveraged to better understand the role of over-parameterization [29], implicit regularization [30], network pruning [31], continual learning [58], and self-supervised learning [32].",
                "This formula unifies an array of conservation properties noticed under gradient flow [1, 29, 30, 31, 32] with a formal theoretical connection to Noether\u2019s theorem.",
                "Overall, just like how Noether\u2019s theorem [28] unified an array of conservation laws and provided a theoretical foundation to discover new ones in physics, we have further unified conservation laws previously observed in learning systems [1, 29, 30, 31, 32] and generalized these results for any combination of differentiable symmetries in neural network architectures and learning rules (e."
            ],
            "citingPaper": {
                "paperId": "3fa5d98c33087af2c8481486ebbdb1a3ec3ba3cd",
                "externalIds": {
                    "ArXiv": "2105.02716",
                    "DBLP": "conf/nips/TanakaK21",
                    "CorpusId": 240419590
                },
                "corpusId": 240419590,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/3fa5d98c33087af2c8481486ebbdb1a3ec3ba3cd",
                "title": "Noether's Learning Dynamics: Role of Symmetry Breaking in Neural Networks",
                "abstract": "In nature, symmetry governs regularities, while symmetry breaking brings texture. In artificial neural networks, symmetry has been a central design principle to efficiently capture regularities in the world, but the role of symmetry breaking is not well understood. Here, we develop a theoretical framework to study the\"geometry of learning dynamics\"in neural networks, and reveal a key mechanism of explicit symmetry breaking behind the efficiency and stability of modern neural networks. To build this understanding, we model the discrete learning dynamics of gradient descent using a continuous-time Lagrangian formulation, in which the learning rule corresponds to the kinetic energy and the loss function corresponds to the potential energy. Then, we identify\"kinetic symmetry breaking\"(KSB), the condition when the kinetic energy explicitly breaks the symmetry of the potential function. We generalize Noether's theorem known in physics to take into account KSB and derive the resulting motion of the Noether charge:\"Noether's Learning Dynamics\"(NLD). Finally, we apply NLD to neural networks with normalization layers and reveal how KSB introduces a mechanism of\"implicit adaptive optimization\", establishing an analogy between learning dynamics induced by normalization layers and RMSProp. Overall, through the lens of Lagrangian mechanics, we have established a theoretical foundation to discover geometric design principles for the learning dynamics of neural networks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1912151014",
                        "name": "Hidenori Tanaka"
                    },
                    {
                        "authorId": "145616412",
                        "name": "D. Kunin"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "provide an analysis of how various factors involved in BYOL and SimSiam work together to prevent collapse [42]."
            ],
            "citingPaper": {
                "paperId": "8653cbe908c64c0e4a3591fe652d239ab7cf98c1",
                "externalIds": {
                    "DBLP": "conf/iccv/Hua0XRWZ21",
                    "ArXiv": "2105.00470",
                    "DOI": "10.1109/ICCV48922.2021.00946",
                    "CorpusId": 233481690
                },
                "corpusId": 233481690,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/8653cbe908c64c0e4a3591fe652d239ab7cf98c1",
                "title": "On Feature Decorrelation in Self-Supervised Learning",
                "abstract": "In self-supervised representation learning, a common idea behind most of the state-of-the-art approaches is to enforce the robustness of the representations to predefined augmentations. A potential issue of this idea is the existence of completely collapsed solutions (i.e., constant features), which are typically avoided implicitly by carefully chosen implementation details. In this work, we study a relatively concise framework containing the most common components from recent approaches. We verify the existence of complete collapse and discover another reachable collapse pattern that is usually overlooked, namely dimensional collapse. We connect dimensional collapse with strong correlations between axes and consider such connection as a strong motivation for feature decorrelation (i.e., standardizing the covariance matrix). The gains from feature decorrelation are verified empirically to highlight the importance and the potential of this insight.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1419971650",
                        "name": "Tianyu Hua"
                    },
                    {
                        "authorId": "47825356",
                        "name": "Wenxiao Wang"
                    },
                    {
                        "authorId": "2060445410",
                        "name": "Zihui Xue"
                    },
                    {
                        "authorId": "2118462083",
                        "name": "Yue Wang"
                    },
                    {
                        "authorId": "1823941979",
                        "name": "Sucheng Ren"
                    },
                    {
                        "authorId": "2146231364",
                        "name": "Hang Zhao"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Recently, several self-supervised learning methods have achieved the state-of-the-art performance on the large-scale natural image dataset ImageNet [37] without negative sample pairs [38]."
            ],
            "citingPaper": {
                "paperId": "29d591ebfbbbf86f762af6f866ca8d0d974d47f7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2104-02864",
                    "ArXiv": "2104.02864",
                    "DOI": "10.1007/s11548-023-02891-5",
                    "CorpusId": 233169095,
                    "PubMed": "37040011"
                },
                "corpusId": 233169095,
                "publicationVenue": {
                    "id": "eb4f826e-70fb-420c-980d-d63532cff232",
                    "name": "International Journal of Computer Assisted Radiology and Surgery",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Comput Assist Radiol Surg"
                    ],
                    "issn": "1861-6410",
                    "url": "https://www.springer.com/medicine/radiology/journal/11548",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11548",
                        "http://www.springer.com/medicine/radiology/journal/11548"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/29d591ebfbbbf86f762af6f866ca8d0d974d47f7",
                "title": "Self-supervised learning for gastritis detection with gastric X-ray images",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2151296785",
                        "name": "Guang Li"
                    },
                    {
                        "authorId": "3470264",
                        "name": "Ren Togo"
                    },
                    {
                        "authorId": "144392699",
                        "name": "Takahiro Ogawa"
                    },
                    {
                        "authorId": "144029207",
                        "name": "M. Haseyama"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Other works (Saunshi et al., 2019; Tosh et al., 2020; Tian et al., 2021) study the generalization error of contrastive learning based SSL, whose setting is different from our paper."
            ],
            "citingPaper": {
                "paperId": "1902faede5212e62aa8f15f50c3981c1f0505113",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-03568",
                    "ArXiv": "2103.03568",
                    "CorpusId": 232135276
                },
                "corpusId": 232135276,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1902faede5212e62aa8f15f50c3981c1f0505113",
                "title": "Can Pretext-Based Self-Supervised Learning Be Boosted by Downstream Data? A Theoretical Analysis",
                "abstract": "Pretext-based self-supervised learning learns the semantic representation via a handcrafted pretext task over unlabeled data and then uses the learned representation for downstream tasks, which effectively reduces the sample complexity of downstream tasks under Conditional Independence (CI) condition. However, the downstream sample complexity gets much worse if the CI condition does not hold. One interesting question is whether we can make the CI condition hold by using downstream data to refine the unlabeled data to boost self-supervised learning. At first glance, one might think that seeing downstream data in advance would always boost the downstream performance. However, we show that it is not intuitively true and point out that in some cases, it hurts the final performance instead. In particular, we prove both model-free and model-dependent lower bounds of the number of downstream samples used for data refinement. Moreover, we conduct various experiments on both synthetic and real-world datasets to verify our theoretical results.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1577622084",
                        "name": "Jiaye Teng"
                    },
                    {
                        "authorId": "8007867",
                        "name": "Weiran Huang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "In contrast, our method avoids trivial solutions by construction, making our method conceptually simpler and more principled than these alternatives (until their principle is discovered, see (Tian et al., 2021) for an early attempt)."
            ],
            "citingPaper": {
                "paperId": "8a9d84d86ac0d76e63914802f9738325c3bece9c",
                "externalIds": {
                    "ArXiv": "2103.03230",
                    "DBLP": "conf/icml/ZbontarJMLD21",
                    "CorpusId": 232110471
                },
                "corpusId": 232110471,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/8a9d84d86ac0d76e63914802f9738325c3bece9c",
                "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction",
                "abstract": "Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn embeddings which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant solutions. Most current methods avoid such solutions by careful implementation details. We propose an objective function that naturally avoids collapse by measuring the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of a sample, and making it as close to the identity matrix as possible. This causes the embedding vectors of distorted versions of a sample to be similar, while minimizing the redundancy between the components of these vectors. The method is called Barlow Twins, owing to neuroscientist H. Barlow's redundancy-reduction principle applied to a pair of identical networks. Barlow Twins does not require large batches nor asymmetry between the network twins such as a predictor network, gradient stopping, or a moving average on the weight updates. Intriguingly it benefits from very high-dimensional output vectors. Barlow Twins outperforms previous methods on ImageNet for semi-supervised classification in the low-data regime, and is on par with current state of the art for ImageNet classification with a linear classifier head, and for transfer tasks of classification and object detection.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3105120",
                        "name": "Jure Zbontar"
                    },
                    {
                        "authorId": "50780902",
                        "name": "Li Jing"
                    },
                    {
                        "authorId": "1806773",
                        "name": "Ishan Misra"
                    },
                    {
                        "authorId": "1688882",
                        "name": "Yann LeCun"
                    },
                    {
                        "authorId": "4789914",
                        "name": "St\u00e9phane Deny"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "The theoretical analysis on self-supervised representation algorithms without negative samples [Tian et al., 2021] cannot be applied to the contrastive learning setting."
            ],
            "citingPaper": {
                "paperId": "0d48b3c4209a3a37392904c3d12b901fe72a4333",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-06866",
                    "ArXiv": "2102.06866",
                    "CorpusId": 231924409
                },
                "corpusId": 231924409,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0d48b3c4209a3a37392904c3d12b901fe72a4333",
                "title": "Understanding Negative Samples in Instance Discriminative Self-supervised Representation Learning",
                "abstract": "Instance discriminative self-supervised representation learning has been attracted attention thanks to its unsupervised nature and informative feature representation for downstream tasks. In practice, it commonly uses a larger number of negative samples than the number of supervised classes. However, there is an inconsistency in the existing analysis; theoretically, a large number of negative samples degrade classification performance on a downstream supervised task, while empirically, they improve the performance. We provide a novel framework to analyze this empirical result regarding negative samples using the coupon collector's problem. Our bound can implicitly incorporate the supervised loss of the downstream task in the self-supervised loss by increasing the number of negative samples. We confirm that our proposed analysis holds on real-world benchmark datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "13613520",
                        "name": "Kento Nozawa"
                    },
                    {
                        "authorId": "73355331",
                        "name": "Issei Sato"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "This non-collapsing behavior even without relying on negatives has been studied further (Tian et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "b38fcf2aba8b173ba11ada830b7038f496643893",
                "externalIds": {
                    "DBLP": "conf/iclr/ThakoorTAADMVV22",
                    "ArXiv": "2102.06514",
                    "CorpusId": 243756979
                },
                "corpusId": 243756979,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b38fcf2aba8b173ba11ada830b7038f496643893",
                "title": "Large-Scale Representation Learning on Graphs via Bootstrapping",
                "abstract": "Self-supervised learning provides a promising path towards eliminating the need for costly label information in representation learning on graphs. However, to achieve state-of-the-art performance, methods often need large numbers of negative examples and rely on complex augmentations. This can be prohibitively expensive, especially for large graphs. To address these challenges, we introduce Bootstrapped Graph Latents (BGRL) - a graph representation learning method that learns by predicting alternative augmentations of the input. BGRL uses only simple augmentations and alleviates the need for contrasting with negative examples, and is thus scalable by design. BGRL outperforms or matches prior methods on several established benchmarks, while achieving a 2-10x reduction in memory costs. Furthermore, we show that BGRL can be scaled up to extremely large graphs with hundreds of millions of nodes in the semi-supervised regime - achieving state-of-the-art performance and improving over supervised baselines where representations are shaped only through label information. In particular, our solution centered on BGRL constituted one of the winning entries to the Open Graph Benchmark - Large Scale Challenge at KDD Cup 2021, on a graph orders of magnitudes larger than all previously available benchmarks, thus demonstrating the scalability and effectiveness of our approach.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "41037204",
                        "name": "Shantanu Thakoor"
                    },
                    {
                        "authorId": "31803582",
                        "name": "Corentin Tallec"
                    },
                    {
                        "authorId": "37666967",
                        "name": "M. G. Azar"
                    },
                    {
                        "authorId": "2039962468",
                        "name": "Mehdi Azabou"
                    },
                    {
                        "authorId": "1746363",
                        "name": "Eva L. Dyer"
                    },
                    {
                        "authorId": "1708654",
                        "name": "R. Munos"
                    },
                    {
                        "authorId": "1742197495",
                        "name": "Petar Velivckovi'c"
                    },
                    {
                        "authorId": "1806291",
                        "name": "Michal Valko"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Feature learning has been widely investigated from the theoretical perspective in other domains, such as supervised learning Allen-Zhu & Li (2020); Du et al. (2021); Tripuraneni et al. (2020), constrastive learning Tian et al. (2021) and RL Agarwal et al. (2020a)."
            ],
            "citingPaper": {
                "paperId": "81e78a7bdbd578a838cf0cc5f128b1f168500f03",
                "externalIds": {
                    "DBLP": "journals/tmlr/XuLLDW23",
                    "CorpusId": 253064970
                },
                "corpusId": 253064970,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/81e78a7bdbd578a838cf0cc5f128b1f168500f03",
                "title": "Beyond Information Gain: An Empirical Benchmark for Low-Switching-Cost Reinforcement Learning",
                "abstract": "A ubiquitous requirement in many practical reinforcement learning (RL) applications is that the deployed policy that actually interacts with the environment cannot change fre-quently. Such an RL setting is called low-switching-cost RL, i.e., achieving the highest reward while reducing the number of policy switches during training. It has been a recent trend in theoretical RL research to develop provably efficient RL algorithms with low switching cost. The core idea in these theoretical works is to measure the information gain and switch the policy when the information gain is doubled. Despite of the theoretical advances, none of existing approaches have been validated empirically. We conduct the first empirical evaluation of different policy switching criteria on popular RL testbeds, including a medical treatment environment, the Atari games, and robotic control tasks. Surprisingly, although information-gain-based methods do recover the optimal rewards, they often lead to a substantially higher switching cost. By contrast, we find that a feature-based criterion, which has been largely ignored in the theoretical research, consistently produces the best performances over all the domains. We hope our benchmark could bring insights to the community and inspire future research. Our code and complete results can be found at https://sites.google.com/view/low-switching-cost-rl .",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "50433534",
                        "name": "Shusheng Xu"
                    },
                    {
                        "authorId": "2153217950",
                        "name": "Yancheng Liang"
                    },
                    {
                        "authorId": "2110441798",
                        "name": "Yunfei Li"
                    },
                    {
                        "authorId": "145697585",
                        "name": "S. Du"
                    },
                    {
                        "authorId": "2108054518",
                        "name": "Yi Wu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "[215] showed why algorithms without negative examples such as SimSiam [65] and BYOL [63] work: the dynamics of the eigenspace alignment between the predictor and its input correlation matrix play a vital role in preventing complete collapse.",
                "For example, many studies have been conducted on why BYOL and SimSiam [65] do not collapse [215]."
            ],
            "citingPaper": {
                "paperId": "9b5a11d9bb3790dbbb02725231b290f67579469a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2301-05712",
                    "DOI": "10.48550/arXiv.2301.05712",
                    "CorpusId": 255941551
                },
                "corpusId": 255941551,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/9b5a11d9bb3790dbbb02725231b290f67579469a",
                "title": "A Survey of Self-Supervised Learning from Multiple Perspectives: Algorithms, Theory, Applications and Future Trends",
                "abstract": "\u2014Deep supervised learning algorithms generally require large numbers of labeled examples to attain satisfactory performance. To avoid the expensive cost incurred by collecting and labeling too many examples, as a subset of unsupervised learning, self-supervised learning (SSL) was proposed to learn good features from many unlabeled examples without any human-annotated labels. SSL has recently become a hot research topic, and many related algorithms have been proposed. However, few comprehensive studies have explained the connections among different SSL variants and how they have evolved. In this paper, we attempt to provide a review of the various SSL methods from the perspectives of algorithms, theory, applications, three main trends, and open questions. First, the motivations of most SSL algorithms are introduced in detail, and their commonalities and differences are compared. Second, the theoretical issues associated with SSL are investigated. Third, typical applications of SSL in areas such as image processing and computer vision (CV), as well as natural language processing (NLP), are discussed. Finally, the three main trends of SSL and the open research questions are discussed. A collection of useful materials is available at https://github.com/guijiejie/SSL.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2190897431",
                        "name": "Jie Gui"
                    },
                    {
                        "authorId": "2201605955",
                        "name": "Tuo Chen"
                    },
                    {
                        "authorId": "2176189708",
                        "name": "Qiong Cao"
                    },
                    {
                        "authorId": "2165889987",
                        "name": "Zhe Sun"
                    },
                    {
                        "authorId": "2110564218",
                        "name": "Haowen Luo"
                    },
                    {
                        "authorId": "2140448089",
                        "name": "Dacheng Tao"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Tian et al. (2021) study the dynamics of non-contrastive learning, but only focus on the predictor parameters."
            ],
            "citingPaper": {
                "paperId": "cd70c06fe993a4a0a531487adfbdf8a172928e81",
                "externalIds": {
                    "CorpusId": 259506172
                },
                "corpusId": 259506172,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/cd70c06fe993a4a0a531487adfbdf8a172928e81",
                "title": "A MESSAGE PASSING PERSPECTIVE ON LEARNING DY-",
                "abstract": "In recent years, contrastive learning achieves impressive results on self-supervised visual representation learning, but there still lacks a rigorous understanding of its learning dynamics. In this paper, we show that if we cast a contrastive objective equivalently into the feature space, then its learning dynamics admits an interpretable form. Specifically, we show that its gradient descent corresponds to a specific message passing scheme on the corresponding augmentation graph. Based on this perspective, we theoretically characterize how contrastive learning gradually learns discriminative features with the alignment update and the uniformity update. Meanwhile, this perspective also establishes an intriguing connection between contrastive learning and Message Passing Graph Neural Networks (MP-GNNs). This connection not only provides a unified understanding of many techniques independently developed in each community, but also enables us to borrow techniques from MP-GNNs to design new contrastive learning variants, such as graph attention, graph rewiring, jumpy knowledge techniques, etc. We believe that our message passing perspective not only provides a new theoretical understanding of contrastive learning dynamics, but also bridges the two seemingly independent areas together, which could inspire more interleaving studies to benefit from each other.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2145907063",
                        "name": "Qi Zhang"
                    },
                    {
                        "authorId": "2210265408",
                        "name": "Tianqi Du"
                    },
                    {
                        "authorId": "2144511379",
                        "name": "Jiansheng Yang"
                    },
                    {
                        "authorId": "33383055",
                        "name": "Zhouchen Lin"
                    },
                    {
                        "authorId": "2115869684",
                        "name": "Yisen Wang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "However, directly adding the alignment part will cause degenerate solutions (Tian et al., 2021; Wang & Isola, 2020), which means all the images are encoded to the same and collapsed representation.",
                "Besides, Moco and BYOL use momentum and stop-gradient mechanisms are adopted to prevent degenerate solutions (Tian et al., 2021; Wang & Isola, 2020)."
            ],
            "citingPaper": {
                "paperId": "a4a73926567bf72cfc9af9af04fc0230da15474d",
                "externalIds": {
                    "CorpusId": 259841274
                },
                "corpusId": 259841274,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a4a73926567bf72cfc9af9af04fc0230da15474d",
                "title": "C ONTEXTUAL I MAGE M ASKING M ODELING VIA S YN - ERGIZED C ONTRASTING WITHOUT V IEW A UGMENTA - TION FOR F ASTER AND B ETTER V ISUAL P RETRAINING",
                "abstract": "We propose a new contextual masking image modeling (MIM) approach called contrasting-aided contextual MIM (ccMIM), under the MIM paradigm for visual pretraining. Specifically, we adopt importance sampling to select the masked patches with richer semantic information for reconstruction, instead of random sampling as done in previous MIM works. As such, the resulting patch reconstruction task from the remaining less semantic patches could be more difficult and helps to learn. To speed up the possibly slowed convergence due to our more difficult reconstruction task, we further propose a new contrastive loss that aligns the tokens of the vision transformer extracted from the selected masked patches and the remaining ones, respectively. The hope is that it serves as a regularizer for patch feature learning such that the image-level global information could be captured in both masked and unmasked patches, and notably such a single-view contrasting avoids the tedious image augmentation step required in recent efforts of introducing contrastive learning to MIM (to speedup convergence and discriminative ability). Meanwhile, the attention score from the contrastive global feature can also carry effective semantic clues to in turn guide our above masking patch selection scheme. In consequence, our contextual MIM and contrastive learning are synergetically performed in a loop (semantic patch selection-token alignment contrasting) to boost the best of the two worlds: fast convergence and strong performance on downstream tasks without ad-hoc augmentations, which are verified by empirical results on ImageNet-1K for both classification and dense vision tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2116576240",
                        "name": "Shaofeng Zhang"
                    },
                    {
                        "authorId": "2075369514",
                        "name": "Feng Zhu"
                    },
                    {
                        "authorId": "1395873384",
                        "name": "Rui Zhao"
                    },
                    {
                        "authorId": "3063894",
                        "name": "Junchi Yan"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "0380271e23c5a3348f9f8ad1906b692b22f8b75e",
                "externalIds": {
                    "DBLP": "conf/iclr/ChenY0OL23",
                    "CorpusId": 259861238
                },
                "corpusId": 259861238,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0380271e23c5a3348f9f8ad1906b692b22f8b75e",
                "title": "Minimalistic Unsupervised Representation Learning with the Sparse Manifold Transform",
                "abstract": ".",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2109184424",
                        "name": "Yubei Chen"
                    },
                    {
                        "authorId": "2061343349",
                        "name": "Zeyu Yun"
                    },
                    {
                        "authorId": "2185826523",
                        "name": "Yi Ma"
                    },
                    {
                        "authorId": "1708655",
                        "name": "B. Olshausen"
                    },
                    {
                        "authorId": "1688882",
                        "name": "Yann LeCun"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "b72ebbe2156f8fa6a13b33b5a508b621126bf968",
                "externalIds": {
                    "CorpusId": 259935058
                },
                "corpusId": 259935058,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b72ebbe2156f8fa6a13b33b5a508b621126bf968",
                "title": "ML-GUIDED OPTIMIZATION",
                "abstract": "Jan.2015-present Research Scientist and Senior Manager, Meta AI (FAIR) Research Lead in: Long-form Story Generation (2022-) AI-guided Optimization (2019-) Self-supervised and Representation Learning (2020-) Lead Scientist and Engineer of Facebook Go engine. DarkForestGo (2015): Strong CNN-based Go AI before AlphaGo. ELF OpenGo (2018): Superhuman and best open source Go AI that beats professional Go players with 20-0. Replication of AlphaZero with 2k GPUs. Sep.2013-Dec.2014 Researcher / Software Engineer Vision and Learning Group, Driverless Car Team (Waymo), Google X Real-time object recognition for autonomous driving car.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "39402399",
                        "name": "Yuandong Tian"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Many researchers [47], [48], [49], [50], [51] have endeavored to comprehend and elucidate its characteristics, along with its impacts on downstream tasks."
            ],
            "citingPaper": {
                "paperId": "51173fa0947c45ecd9ad332fe5089bd4e4bf15ac",
                "externalIds": {
                    "DBLP": "journals/tgrs/LiXMFWHD23",
                    "DOI": "10.1109/TGRS.2023.3317301",
                    "CorpusId": 262157183
                },
                "corpusId": 262157183,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/51173fa0947c45ecd9ad332fe5089bd4e4bf15ac",
                "title": "Supervised Contrastive Learning-Based Unsupervised Domain Adaptation for Hyperspectral Image Classification",
                "abstract": "Deep domain adaptation has achieved promising results in cross-domain hyperspectral image (HSI) classification. However, existing methods often focus on aligning data distributions without sufficient consideration of separability of source and target domain data themselves. In addition, current adversarial domain adaptation methods aim to achieve similar distributions between domains by confusing the discriminator, rather than obtaining a more compact distribution. In particular, existing methods are not discriminative enough for the target domain due to the difficulty of obtaining high-confidence labeled samples of the target domain. To address the above challenges, we propose a supervised contrastive learning (SCL)-based unsupervised domain adaptation for HSI classification. An SCL strategy is then performed in both the source and target domains, which allows samples from the same category to be pulled closer together and samples from different categories to be pushed further apart, thus enhancing the separability of the data within the domain. The domain adaptation task is treated as a one-class classification (OCC) task, and a novel domain similarity loss based on OCC is introduced to reduce the discrepancy between domains. Finally, a confidence learning-based sample selection strategy is designed to select high-confidence labeled samples from the target domain to fine-tune the domain adaptation model, which can enhance the discrimination of the model to the target domain. Experimental results on three cross-domain datasets demonstrate that our proposed method outperforms existing domain adaptation methods. Our source code is available at https://github.com/Li-ZK/SCLUDA-2023.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1862641",
                        "name": "Zhaokui Li"
                    },
                    {
                        "authorId": "144239164",
                        "name": "Q. Xu"
                    },
                    {
                        "authorId": "2240164394",
                        "name": "Li Ma"
                    },
                    {
                        "authorId": "1838024089",
                        "name": "Z. Fang"
                    },
                    {
                        "authorId": "2152540396",
                        "name": "Yan Wang"
                    },
                    {
                        "authorId": "2244412692",
                        "name": "Wenqiang He"
                    },
                    {
                        "authorId": "2072520954",
                        "name": "Q. Du"
                    }
                ]
            }
        },
        {
            "isInfluential": true,
            "intents": [
                "background",
                "methodology",
                "result"
            ],
            "contexts": [
                "We note some dimensional collapse is still observed for Barlow Twins projectors, as found for BYOL (Grill et al., 2020; Tian et al., 2021) & SimCLR (Chen et al.",
                "The proof of Proposition 3.3 can be found in Appendix A, & is largely inspired from previous work (Saxe et al., 2013; Ji & Telgarsky, 2018; Tian et al., 2021; Jing et al., 2021).",
                "We note some dimensional collapse is still observed for Barlow Twins projectors, as found for BYOL (Grill et al., 2020; Tian et al., 2021) & SimCLR (Chen et al., 2020a; Jing et al., 2021), as the encoder dimension is 512 with projector width of 1024.",
                "We point out that although we provide empirical evidence from practical settings to corroborate our theoretical results, our theory has some non-standard assumptions to ease analytical exposition, such as linear projector MLPs, much like related theoretical work in SSL (Tian et al., 2021; Wang et al., 2021; Jing et al., 2021).",
                "Existing theoretical analyses into feature collapse & its mechanisms in SSL have focused on explaining why it does not occur in non-contrastive SSL (Tian et al., 2021; Zhang et al., 2022) or how a related notion of dimensional collapse (Hua et al., 2021), where features span a low-dimension\u2026",
                "Existing theoretical analyses into feature collapse & its mechanisms in SSL have focused on explaining why it does not occur in non-contrastive SSL (Tian et al., 2021; Zhang et al., 2022) or how a related notion of dimensional collapse (Hua et al.",
                "3 can be found in Appendix A, & is largely inspired from previous work (Saxe et al., 2013; Ji & Telgarsky, 2018; Tian et al., 2021; Jing et al., 2021).",
                "\u2026provide empirical evidence from practical settings to corroborate our theoretical results, our theory has some non-standard assumptions to ease analytical exposition, such as linear projector MLPs, much like related theoretical work in SSL (Tian et al., 2021; Wang et al., 2021; Jing et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "75b589d3f7199154b77d6680866366a38f0608a6",
                "externalIds": {
                    "DBLP": "conf/icml/HeO22",
                    "CorpusId": 250340753
                },
                "corpusId": 250340753,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/75b589d3f7199154b77d6680866366a38f0608a6",
                "title": "Exploring the Gap between Collapsed & Whitened Features in Self-Supervised Learning",
                "abstract": "Avoiding feature collapse, when a Neural Net-work (NN) encoder maps all inputs to a constant vector, is a shared implicit desideratum of various methodological advances in self-supervised learning (SSL). To that end, whitened features have been proposed as an explicit objective to ensure uncollapsed features (Zbontar et al., 2021; Er-molov et al., 2021; Hua et al., 2021; Bardes et al., 2022). We identify power law behaviour in eigenvalue decay, parameterised by exponent \u03b2 \u2265 0 , as a spectrum that bridges between the collapsed & whitened feature extremes. We provide theoretical & empirical evidence highlighting the factors in SSL, like projection layers & regularisation strength, that in\ufb02uence eigenvalue decay rate, & demonstrate that the degree of feature whitening affects generalisation, particularly in label scarce regimes. We use our insights to motivate a novel method, Post-hoc Manipulation of the Principal Axes & Trace (PostMan-Pat), which ef\ufb01ciently post-processes a pretrained encoder to enforce eigenvalue decay rate with power law exponent \u03b2 , & \ufb01nd that PostMan-Pat delivers improved label ef\ufb01ciency and transferability across a range of SSL methods and encoder architectures.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1810714948",
                        "name": "Bobby He"
                    },
                    {
                        "authorId": "2159942",
                        "name": "M. Ozay"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "8596ddc90ca493537f333883e68d14e4b5264a3a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2202-04528",
                    "CorpusId": 246679949
                },
                "corpusId": 246679949,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8596ddc90ca493537f333883e68d14e4b5264a3a",
                "title": "A Multimodal Canonical-Correlated Graph Neural Network for Energy-Efficient Speech Enhancement",
                "abstract": "This paper proposes a novel multimodal self-supervised architecture for energy-efficient AV speech enhancement by integrating graph neural networks with canonical correlation analysis (CCA-GNN). This builds on a state-ofthe-art CCA-GNN that aims to learn representative embeddings by maximizing the correlation between pairs of augmented views of the same input while decorrelating disconnected features. The key idea of the conventional CCA-GNN involves discarding augmentation-variant information and preserving augmentation-invariant information whilst preventing capturing of redundant information. Our proposed AV CCA-GNN model is designed to deal with the challenging multimodal representation learning context. Specifically, our model improves contextual AV speech processing by maximizing canonical correlation from augmented views of the same channel, as well as canonical correlation from audio and visual embeddings. In addition, we propose a positional encoding of the nodes that considers a prior-frame sequence distance instead of a feature-space representation while computing the node\u2019s nearest neighbors. This serves to introduce temporal information in the embeddings through the neighborhood\u2019s connectivity. Experiments conducted with the benchmark ChiME3 dataset show that our proposed prior frame-based AV CCA-GNN reinforces better feature learning in the temporal context, leading to more energy-efficient Preprint submitted to Information Fusion February 10, 2022 speech reconstruction compared to state-of-the-art CCA-GNN and multi-layer perceptron models. The results demonstrate the potential of our proposed approach for exploitation in future assistive technology and energy-efficient multimodal devices.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "39795571",
                        "name": "L. A. Passos"
                    },
                    {
                        "authorId": "1759037",
                        "name": "J. Papa"
                    },
                    {
                        "authorId": "2117797510",
                        "name": "Amir Hussain"
                    },
                    {
                        "authorId": "2064500",
                        "name": "Ahsan Adeel"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Moreover, Wei et al. (2020) and Tian et al. (2021) studied the theoretical properties of self-training and the contrastive learning without the negative pairs respectively."
            ],
            "citingPaper": {
                "paperId": "234bb756367aa5434eaadc867c3443526aa97403",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-03539",
                    "DOI": "10.48550/arXiv.2203.03539",
                    "CorpusId": 247292176
                },
                "corpusId": 247292176,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/234bb756367aa5434eaadc867c3443526aa97403",
                "title": "One Objective for All Models - Self-supervised Learning for Topic Models",
                "abstract": "Self-supervised learning has significantly improved the performance of many NLP tasks. In this paper, we highlight a key advantage of self-supervised learning when applied to data generated by topic models, self-supervised learning can be oblivious to the specific model, and hence is less susceptible to model misspecification. In particular, we prove that commonly used self-supervised objectives based on reconstruction or contrastive samples can both recover useful posterior information for general topic models. Empirically, we show that the same objectives can perform competitively against posterior inference using the correct model, while outperforming posterior inference using misspecified model.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2157861426",
                        "name": "Zeping Luo"
                    },
                    {
                        "authorId": "2157861484",
                        "name": "C. Weng"
                    },
                    {
                        "authorId": "2157973803",
                        "name": "Shiyou Wu"
                    },
                    {
                        "authorId": "2123358667",
                        "name": "Mo Zhou"
                    },
                    {
                        "authorId": "144804200",
                        "name": "Rong Ge"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "[41] conducted a theoretical analysis on why the non-contrastive methods work well."
            ],
            "citingPaper": {
                "paperId": "e6f537f6a40e86e4d028ccce87691171b78f6a41",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-11437",
                    "DOI": "10.48550/arXiv.2203.11437",
                    "CorpusId": 247596769
                },
                "corpusId": 247596769,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e6f537f6a40e86e4d028ccce87691171b78f6a41",
                "title": "Self-Supervised Representation Learning as Multimodal Variational Inference",
                "abstract": "In this paper, we propose a probabilistic extension of the recent self-supervised learning (SSL) method, SimSiam. The proposed extension makes SimSiam uncertainty-aware by considering SimSiam as a generative model of augmented views and learning it in terms of variational inference. SimSiam trains a model by maximizing the similarity between image representations of different augmented views of the same image. The augmentation process sometimes produces ambiguous images, and their representations potentially have uncertainty. Although the use of uncertainty-aware machine learning becoming common, such as in deep variational inference, SimSiam and other SSL methods are insuf\ufb01ciently uncertainty-aware, leading to limitations in the use of augmented ambiguous images. Our main contributions are twofold: Firstly, we clarify the theoretical relationship between non-contrastive SSL and multimodal variational inference. Secondly, we introduce a novel SSL called variational inference SimSiam (VI-SimSiam), which incorporates uncertainty by involving spherical posterior distributions. The experiment results show that VI-SimSiam outperforms SimSiam in classi\ufb01cation tasks in several datasets, such as ImageNette and ImageWoof by successfully estimating the representation uncertainty.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2159561166",
                        "name": "Hiroki Nakamura"
                    },
                    {
                        "authorId": "2114306014",
                        "name": "Masashi Okada"
                    },
                    {
                        "authorId": "1684099",
                        "name": "T. Taniguchi"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "We further note that the InfoMax interpretation of these objectives may not be consistent with its behavior in practice [45] and many recent studies provide theoretical understanding behind their success [46, 47]."
            ],
            "citingPaper": {
                "paperId": "9a79ae1663c2e5ea163da9d12566e08890e1f757",
                "externalIds": {
                    "CorpusId": 249306541
                },
                "corpusId": 249306541,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/9a79ae1663c2e5ea163da9d12566e08890e1f757",
                "title": "An Empirical Study of Graph Contrastive Learning Supplementary Material",
                "abstract": "Yanqiao Zhu1,2 Yichen Xu3 Qiang Liu1,2 Shu Wu1,2\u2217 1Center for Research on Intelligent Perception and Computing National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences 2School of Artificial Intelligence, University of Chinese Academy of Sciences 3School of Computer Science, Beijing University of Posts and Telecommunications yanqiao.zhu@cripac.ia.ac.cn linyxus@bupt.edu.cn {qiang.liu,shu.wu}@nlpr.ia.ac.cn",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2653121",
                        "name": "Yanqiao Zhu"
                    },
                    {
                        "authorId": "47103911",
                        "name": "Yichen Xu"
                    },
                    {
                        "authorId": "48873756",
                        "name": "Q. Liu"
                    },
                    {
                        "authorId": "50425438",
                        "name": "Shu Wu"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "bfbd224208ffaaa47fbac36c63893dd21214c678",
                "externalIds": {
                    "CorpusId": 250406282
                },
                "corpusId": 250406282,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/bfbd224208ffaaa47fbac36c63893dd21214c678",
                "title": "Spontaneous Decomposition from Grouped Network Pathways",
                "abstract": "There have been many recent breakthroughs in self-supervised learning (SSL), i.e. unsupervised techniques used to obtain general purpose image features for downstream tasks. However, these methods often require large amounts of computational resources, and much is still un-known about how architectural choices affect the quality of self-supervised learned representations. There is still a lack of understanding of why compositional features spontaneously arise in previous self-supervised publications. In this work, we propose a class of models that is reminis-cent of an ensemble. We show how this class of models can greatly reduce the number of parameters needed for learning robust representations in a self-supervised setting. Ad-ditionally, we show that sparsely connected network pathways spontaneously create decomposed representations.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1602203137",
                        "name": "Satchel Grant"
                    },
                    {
                        "authorId": "2175516789",
                        "name": "Matheus Dias"
                    },
                    {
                        "authorId": "9050490",
                        "name": "Sahil Kulkarni"
                    },
                    {
                        "authorId": "2071529845",
                        "name": "Stanford"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Several different perspectives have recently been used to successfully analyze SSL\u2019s behavior, including learning theory [15, 14, 34], causality [18, 17], information theory [27], and dynamical systems [35].",
                "[35] Yuandong Tian, Xinlei Chen, and Surya Ganguli."
            ],
            "citingPaper": {
                "paperId": "199bbb97ae2d0b0874a25fc8057dc3119de5ed1f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-02810",
                    "DOI": "10.48550/arXiv.2208.02810",
                    "CorpusId": 251320547
                },
                "corpusId": 251320547,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/199bbb97ae2d0b0874a25fc8057dc3119de5ed1f",
                "title": "Analyzing Data-Centric Properties for Contrastive Learning on Graphs",
                "abstract": "Recent analyses of self-supervised learning (SSL) \ufb01nd the following data-centric properties to be critical for learning good representations: invariance to task-irrelevant semantics, separability of classes in some latent space, and recoverability of labels from augmented samples. However, given their discrete, non-Euclidean nature, graph datasets and graph SSL methods are unlikely to satisfy these properties. This raises the question: how do graph SSL methods, such as contrastive learning (CL), work well? To systematically probe this question, we perform a generalization analysis for CL when using generic graph augmentations (GGAs), with a focus on data-centric properties. Our analysis yields formal insights into the limitations of GGAs and the necessity of task-relevant augmentations. As we empirically show, GGAs do not induce task-relevant invariances on common benchmark datasets, leading to only marginal gains over naive, untrained baselines. Our theory motivates a synthetic data generation process that enables control over task-relevant information and boasts pre-de\ufb01ned optimal augmentations. This \ufb02exible benchmark helps us identify yet unrecognized limitations in advanced augmentation techniques (e.g., automated methods). Overall, our work rigorously contextualizes, both empirically and theoretically, the effects of data-centric properties on augmentation strategies and learning paradigms for graph SSL.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "30440868",
                        "name": "Puja Trivedi"
                    },
                    {
                        "authorId": "35573359",
                        "name": "E. S. Lubana"
                    },
                    {
                        "authorId": "35505461",
                        "name": "Mark Heimann"
                    },
                    {
                        "authorId": "2479152",
                        "name": "Danai Koutra"
                    },
                    {
                        "authorId": "2064767378",
                        "name": "J. Thiagarajan"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Several different perspectives have recently been used to successfully analyze SSL\u2019s behavior, including learning theory [14, 15, 35], causality [17, 18], information theory [27], and dynamical systems [36]."
            ],
            "citingPaper": {
                "paperId": "7c178bb34ab845573dbc360050647a278a2e55b9",
                "externalIds": {
                    "CorpusId": 251642078
                },
                "corpusId": 251642078,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/7c178bb34ab845573dbc360050647a278a2e55b9",
                "title": "Understanding Self-Supervised Graph Representation Learning from a Data-Centric Perspective",
                "abstract": "Recent analyses of self-supervised representation learning (SSL) find the following data-centric assumptions are critical for learning high-quality representations: invariance to task-irrelevant semantics, separability of classes in some latent space, and recoverability of labels from augmented samples. However, it is unlikely that graph SSL methods support these assumptions given the discrete, non-Euclidean nature of graphs. This raises the question: how do graph SSL methods work well? To systematically probe this ques-tion, we perform a generalization analysis of graph SSL when using random topological or feature perturbations as generic graph augmentations (GGAs). Our analysis shows how GGAs can effect the recoverability and separability assumptions and theoretically motivates the need for task-relevant data augmentations. Indeed, we empirically find that GGAs fail to induce task-relevant invariances on benchmark datasets, leading to only marginal gains over naive, untrained baselines. Finally, our theory motivates a synthetic data generation process that enables control over both augmentation recoverability and dataset separability., enabling a better benchmark for evaluation of graph SSL methods that demonstrates different training paradigms are effective in different regimes. Overall, our work rigorously contextualizes, both empirically and theoretically, the effects of data-centric assumptions on graph SSL paradigms and augmentations.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "30440868",
                        "name": "Puja Trivedi"
                    },
                    {
                        "authorId": "35573359",
                        "name": "E. S. Lubana"
                    },
                    {
                        "authorId": "2479152",
                        "name": "Danai Koutra"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "[254] studied the nonlinear learning dynamics of uncollated SSL in a simple linear network where SSL with only positive pairs avoids expression decay."
            ],
            "citingPaper": {
                "paperId": "34ad27ced445cdb178388159a7a75d252dad66cc",
                "externalIds": {
                    "DBLP": "journals/access/ParkK22",
                    "DOI": "10.1109/ACCESS.2021.3140175",
                    "CorpusId": 245723446
                },
                "corpusId": 245723446,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/34ad27ced445cdb178388159a7a75d252dad66cc",
                "title": "A Metaverse: Taxonomy, Components, Applications, and Open Challenges",
                "abstract": "Unlike previous studies on the Metaverse based on Second Life, the current Metaverse is based on the social value of Generation Z that online and offline selves are not different. With the technological development of deep learning-based high-precision recognition models and natural generation models, Metaverse is being strengthened with various factors, from mobile-based always-on access to connectivity with reality using virtual currency. The integration of enhanced social activities and neural-net methods requires a new definition of Metaverse suitable for the present, different from the previous Metaverse. This paper divides the concepts and essential techniques necessary for realizing the Metaverse into three components (i.e., hardware, software, and contents) and three approaches (i.e., user interaction, implementation, and application) rather than marketing or hardware approach to conduct a comprehensive analysis. Furthermore, we describe essential methods based on three components and techniques to Metaverse\u2019s representative Ready Player One, Roblox, and Facebook research in the domain of films, games, and studies. Finally, we summarize the limitations and directions for implementing the immersive Metaverse as social influences, constraints, and open challenges.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115232998",
                        "name": "Sang-Min Park"
                    },
                    {
                        "authorId": "9433532",
                        "name": "Young-Gab Kim"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Following [44], we assume that \u2202qMi \u2202z is positive definite."
            ],
            "citingPaper": {
                "paperId": "59024e44f246a5920e3541ebe841a7f91d974f7c",
                "externalIds": {
                    "DBLP": "conf/eccv/TangZ00O22",
                    "DOI": "10.1007/978-3-031-19812-0_1",
                    "CorpusId": 253270118
                },
                "corpusId": 253270118,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/59024e44f246a5920e3541ebe841a7f91d974f7c",
                "title": "Relative Contrastive Loss for Unsupervised Representation Learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "9084688",
                        "name": "Shixiang Tang"
                    },
                    {
                        "authorId": "2075369514",
                        "name": "Feng Zhu"
                    },
                    {
                        "authorId": "50010487",
                        "name": "Lei Bai"
                    },
                    {
                        "authorId": "145638781",
                        "name": "Rui Zhao"
                    },
                    {
                        "authorId": "3001348",
                        "name": "Wanli Ouyang"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": "b55fec2c05856e7735a2c03ef79e8f41b341f002",
                "externalIds": {
                    "CorpusId": 259141862
                },
                "corpusId": 259141862,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b55fec2c05856e7735a2c03ef79e8f41b341f002",
                "title": "An eigenspace view reveals how predictor networks and stop-grads provide implicit variance regularization",
                "abstract": "Self-supervised learning (SSL) learns useful representations from unlabelled data by training networks to be invariant to pairs of augmented versions of the same input. Non-contrastive methods avoid collapse either by directly regularizing the covariance matrix of network outputs or through asymmetric loss architectures, two seemingly unrelated approaches. Here, by building on DirectPred [1], we lay out a theoretical framework that reconciles these two views. We derive analytical expressions for the representational learning dynamics in linear networks. By expressing them in the eigenspace of the embedding covariance matrix, where the solutions decouple, we reveal the mechanism and conditions that provide implicit variance regularization. These insights allow us to formulate a new isotropic loss function that equalizes eigenvalue contribution and renders learning more robust. Finally, we show empirically that our findings translate in nonlinear networks trained on CIFAR-10 and STL-10.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "121265709",
                        "name": "Manu Srinath Halvagal"
                    },
                    {
                        "authorId": "1557381641",
                        "name": "Axel Laborieux"
                    },
                    {
                        "authorId": "2915923",
                        "name": "F T Zenke"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "In practice, however, SSL training often experiences the failure mode of dimensional collapse (Jing et al., 2021; Tian et al., 2021; Pokle et al., 2022), where the learned representation spans a low dimensional subspace of the overall available space."
            ],
            "citingPaper": {
                "paperId": "42610d734c216533684600aed8462c4edcc75bf1",
                "externalIds": {
                    "CorpusId": 259143575
                },
                "corpusId": 259143575,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/42610d734c216533684600aed8462c4edcc75bf1",
                "title": "Loss Landscape of Self-Supervised Learning",
                "abstract": "Prevention of complete and dimensional collapse of representations has recently become a design principle for self-supervised learning (SSL). However, questions remain in our theoretical understanding: Under what precise condition do these collapses occur? We provide theoretically grounded answers to this question by analyzing SSL loss landscapes for a linear model. We derive an analytically tractable theory of SSL landscape and show that it accurately captures an array of collapse phenomena and identifies their causes. Self-supervised learning (SSL) methods have achieved remarkable results in learning good representations without labeled data. SSL loss functions are designed to promote representational similarity between pairs of related samples while using explicit penalties (Chen et al., 2020; He et al., 2020; HaoChen et al., 2021; Zbontar et al., 2021; Caron et al., 2020; Jing et al., 2021; Balestriero and LeCun, 2022) or asymmetric dynamics (Caron et al., 2021; Grill et al., 2020; Chen and He, 2021) to ensure that the distance between unrelated samples remains large. In practice, however, SSL training often experiences the failure mode of dimensional collapse (Jing et al., 2021; Tian et al., 2021; Pokle et al., 2022), where the learned representation spans a low dimensional subspace of the overall available space. In the extreme case, this failure mode instantiates as a complete collapse , where the learned representation becomes zero-rank, and no informative features can be extracted. In this work, we analytically solve",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1412541292",
                        "name": "Li Ziyin"
                    },
                    {
                        "authorId": "35573359",
                        "name": "E. S. Lubana"
                    },
                    {
                        "authorId": "144365686",
                        "name": "Masakuni Ueda"
                    },
                    {
                        "authorId": "1912151014",
                        "name": "Hidenori Tanaka"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "In contrast, we interpret the information loss in the context of identifiability for CL [22], learning dynamics [1, 17, 11, 18], and the content-style partitioning of latent factors [19].",
                "1, 2 [18] Yuandong Tian, Xinlei Chen, and Surya Ganguli."
            ],
            "citingPaper": {
                "paperId": "1ceea6e4adf348b100b29997b7d759d268800870",
                "externalIds": {
                    "CorpusId": 259143748
                },
                "corpusId": 259143748,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1ceea6e4adf348b100b29997b7d759d268800870",
                "title": "Content suppresses style: dimensionality collapse in contrastive learning",
                "abstract": ",",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "13466492",
                        "name": "E. Rusak"
                    },
                    {
                        "authorId": "1382657853",
                        "name": "Patrik Reizinger"
                    },
                    {
                        "authorId": "149408648",
                        "name": "Roland S. Zimmermann"
                    },
                    {
                        "authorId": "143756149",
                        "name": "O. Bringmann"
                    },
                    {
                        "authorId": "40634590",
                        "name": "Wieland Brendel"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Currently, most works focus on linear variants of deep models [19; 2; 22; 21; 32; 33].",
                "[32] Yuandong Tian, Xinlei Chen, and Surya Ganguli."
            ],
            "citingPaper": {
                "paperId": "31b2a1aeaa6d3e4832b3545fb08c4b2353356f78",
                "externalIds": {
                    "CorpusId": 259143622
                },
                "corpusId": 259143622,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/31b2a1aeaa6d3e4832b3545fb08c4b2353356f78",
                "title": "On the Role of Nonlinearity in Training Dynamics of Contrastive Learning on One-layer Network",
                "abstract": "While the empirical success of self-supervised learning (SSL) heavily relies on the usage of deep nonlinear models, existing theoretical works on SSL understanding still focus on linear ones. In this paper, we study the role of nonlinearity in the training dynamics of contrastive learning (CL) on 1-layer nonlinear networks with homogeneous activation h ( x ) = h \u2032 ( x ) x , by extending recent \u03b1 -CL framework [29] and linking it to kernels [26]. We find that the presence of nonlinearity can lead to many local optima even in 1-layer setting, each corresponding to certain patterns from the data distribution, while with linear activation, only one major pattern can be learned. This suggests that models with lots of parameters can be regarded as a brute-force way to find these local optima induced by nonlinearity.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "39402399",
                        "name": "Yuandong Tian"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "contexts": [
                "The terms in Equation 1 can be decomposed using a variance-covariance perspective [23]."
            ],
            "citingPaper": {
                "paperId": "7b5e3cbbe659766fa4937966225e02bc5e4eb164",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-02671",
                    "DOI": "10.48550/arXiv.2206.02671",
                    "CorpusId": 261298626
                },
                "corpusId": 261298626,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7b5e3cbbe659766fa4937966225e02bc5e4eb164",
                "title": "Canonical Cortical Graph Neural Networks and its Application for Speech Enhancement in Future Audio-Visual Hearing Aids",
                "abstract": ". Despite the recent success of machine learning algorithms, most of these models still face several drawbacks when considering more complex tasks requiring interaction between di\ufb00erent sources, such as multimodal input data and logical time sequence. On the other hand, the biological brain is highly sharpened in this sense, empowered to au-tomatically manage and integrate such a stream of information through millions of years of evolution. In this context, this paper \ufb01nds inspira-tion from recent discoveries in cortical circuits on the brain to propose a more biologically plausible self-supervised machine learning approach that combines multimodal information using intra-layer modulations to-gether with canonical correlation analysis (CCA), as well as a memory mechanism to keep track of temporal data, the so-called Canonical Cortical Graph Neural networks. The approach outperformed recent state-of-the-art results considering both better clean audio reconstruction and energy e\ufb03ciency, described by a reduced and smother neuron \ufb01ring rate distribution, suggesting the model as a suitable approach for speech enhancement in future audio-visual hearing aid devices.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2210752558",
                        "name": "L. A. Passos"
                    },
                    {
                        "authorId": "1400664382",
                        "name": "J. P. Papa"
                    },
                    {
                        "authorId": "2064500",
                        "name": "Ahsan Adeel"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "contexts": [
                "Note that optimizingLview(\u0398) alone without stopping gradient results in a degenerated solution (Chen & He, 2021; Tian et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "85994a0e35cb194f333270dc26e2cf76a51226f1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-10447",
                    "CorpusId": 244477865
                },
                "corpusId": 244477865,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/85994a0e35cb194f333270dc26e2cf76a51226f1",
                "title": "Dynamic Graph Representation Learning via Graph Transformer Networks",
                "abstract": "Dynamic graph representation learning is an important task with widespread applications. Previous methods on dynamic graph learning are usually sensitive to noisy graph information such as missing or spurious connections, which can yield degenerated performance and generalization. To overcome this challenge, we propose a Transformer-based dynamic graph learning method named Dynamic Graph Transformer (DGT) with spatial-temporal encoding to effectively learn graph topology and capture implicit links. To improve the generalization ability, we introduce two complementary self-supervised pre-training tasks and show that jointly optimizing the two pre-training tasks results in a smaller Bayesian error rate via an information-theoretic analysis. We also propose a temporal-union graph structure and a target-context node sampling strategy for an ef\ufb01cient and scalable training. Extensive experiments on real-world datasets illustrate that DGT presents superior performance compared with several state-of-the-art baselines.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "22244104",
                        "name": "Weilin Cong"
                    },
                    {
                        "authorId": "1684996712",
                        "name": "Yanhong Wu"
                    },
                    {
                        "authorId": "1932187449",
                        "name": "Yuandong Tian"
                    },
                    {
                        "authorId": "39345350",
                        "name": "Mengting Gu"
                    },
                    {
                        "authorId": "35846319",
                        "name": "Yinglong Xia"
                    },
                    {
                        "authorId": "1694826",
                        "name": "M. Mahdavi"
                    },
                    {
                        "authorId": "2143946417",
                        "name": "C. Chen"
                    }
                ]
            }
        },
        {
            "isInfluential": false,
            "intents": [],
            "contexts": [],
            "citingPaper": {
                "paperId": null,
                "externalIds": null,
                "corpusId": "239036392",
                "publicationVenue": null,
                "url": null,
                "title": "OLLAPSE IN C ON-TRASTIVE S ELF-SUPERVISED L EARNING",
                "abstract": null,
                "year": 2021,
                "authors": []
            }
        }
    ]
}