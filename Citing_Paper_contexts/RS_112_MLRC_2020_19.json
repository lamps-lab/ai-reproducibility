{
    "offset": 0,
    "data": [
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "eae4ec5ca2686acbff971fdd509c1241a75b9e2f",
                "externalIds": {
                    "ArXiv": "2309.13363",
                    "DBLP": "journals/corr/abs-2309-13363",
                    "DOI": "10.48550/arXiv.2309.13363",
                    "CorpusId": 262459078
                },
                "corpusId": 262459078,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/eae4ec5ca2686acbff971fdd509c1241a75b9e2f",
                "title": "MLPST: MLP is All You Need for Spatio-Temporal Prediction",
                "abstract": "Traffic prediction is a typical spatio-temporal data mining task and has great significance to the public transportation system. Considering the demand for its grand application, we recognize key factors for an ideal spatio-temporal prediction method: efficient, lightweight, and effective. However, the current deep model-based spatio-temporal prediction solutions generally own intricate architectures with cumbersome optimization, which can hardly meet these expectations. To accomplish the above goals, we propose an intuitive and novel framework, MLPST, a pure multi-layer perceptron architecture for traffic prediction. Specifically, we first capture spatial relationships from both local and global receptive fields. Then, temporal dependencies in different intervals are comprehensively considered. Through compact and swift MLP processing, MLPST can well capture the spatial and temporal dependencies while requiring only linear computational complexity, as well as model parameters that are more than an order of magnitude lower than baselines. Extensive experiments validated the superior effectiveness and efficiency of MLPST against advanced baselines, and among models with optimal accuracy, MLPST achieves the best time and space efficiency.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2187882131",
                        "name": "Zijian Zhang"
                    },
                    {
                        "authorId": "2109582755",
                        "name": "Ze Huang"
                    },
                    {
                        "authorId": "2246043330",
                        "name": "Zhiwei Hu"
                    },
                    {
                        "authorId": "2243037657",
                        "name": "Xiangyu Zhao"
                    },
                    {
                        "authorId": "2211473272",
                        "name": "Wanyu Wang"
                    },
                    {
                        "authorId": "3195628",
                        "name": "Zitao Liu"
                    },
                    {
                        "authorId": "2238390764",
                        "name": "Junbo Zhang"
                    },
                    {
                        "authorId": "48330637",
                        "name": "S. Qin"
                    },
                    {
                        "authorId": "2010138167",
                        "name": "Hongwei Zhao"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "a42c6f8959e4c0fa41f612556a12060d6188eaac",
                "externalIds": {
                    "DOI": "10.1117/12.2681850",
                    "CorpusId": 262194519
                },
                "corpusId": 262194519,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a42c6f8959e4c0fa41f612556a12060d6188eaac",
                "title": "A holistic framework for forestry and rural road detection based on satellite imagery and deep semantic segmentation",
                "abstract": "The role of forest and rural road network is very important and multifaceted for: a) the exploitation of forests/fields and movement of the staff involved in their management and protection, b) access to existing technical facilities, c) tourism and recreation and d) harvesting and transport of products. Hence, it is important to systematically record and monitor the network status, including its road segment status and important Points of Interest. Since in most cases, such detection and monitoring procedures require manual and tedious procedures, the INFOROAD project (https://inforoad.karteco.gr/) (Project code: KMP6-0079153), implemented under the framework of the Action \u201cInvestment Plans of Innovation\u201d of the Operational Program \u201cCentral Macedonia 2014 2020\u201d, that is co-funded by the European Regional Development Fund and Greece\u201d, is developing an innovative methodology and tools for automated extraction, mapping and status monitoring of forest and rural road network, by combining remote sensing data with state-of-the-art deep learning approaches. Specifically, automated procedures will be developed for: a) road extraction, b) road network graph detection and c) road segment condition monitoring, from very high-resolution multispectral satellite images using innovative semantic segmentation and classification based on deep learning. From a research perspective, these problems are very challenging, as forest and agricultural roads \u2013 as opposed to asphalt roads - exhibit more significant surface and texture variations, while only few related datasets exist. For this reason, additional data, which is necessary for the training and evaluation of the deep learning algorithms, will also be collected, e.g., by UAVs equipped with RGB cameras that can also provide accurate DSM information, manual inspection or other free sources. The associated dataset that will be created for the pilot application of the project in Seich-Sou Forest, Thessaloniki, will be made freely available to boost future research on the field. The display and management of this information by relevant stakeholders (forest authorities, public, etc.) will be performed by an online Geographical Information System (WebGIS).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2244492121",
                        "name": "Dimitrios Kelesakis"
                    },
                    {
                        "authorId": "2214329241",
                        "name": "Konstantinos Marthoglou"
                    },
                    {
                        "authorId": "2244058813",
                        "name": "N. Grammalidis"
                    },
                    {
                        "authorId": "1747572",
                        "name": "P. Daras"
                    },
                    {
                        "authorId": "2244484156",
                        "name": "Emmanouel Tsiros"
                    },
                    {
                        "authorId": "12310494",
                        "name": "A. Karteris"
                    },
                    {
                        "authorId": "2244490254",
                        "name": "Anastasia Stergiadou"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "0d4f5769755e299dd17041f3c6c47835cdfed0f8",
                "externalIds": {
                    "DOI": "10.1117/12.2681866",
                    "CorpusId": 262137016
                },
                "corpusId": 262137016,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0d4f5769755e299dd17041f3c6c47835cdfed0f8",
                "title": "A smart beekeeping platform based on remote sensing and artificial intelligence",
                "abstract": "Honey bees play an essential role in the food chain, being responsible for one third of the global food supply due to pollination. Thus, preserving the health of beehives is of paramount environmental and economic importance. Unfortunately, at present a decline in bee populations is reported, attributed to factors such as climate change, environmental disasters, use of pesticides, etc. The SmartBeeKeep (https://smartbeekeep.eu/) research project, co-funded by EU and Greek funds, builds on the latest developments in remote sensing and AI technologies to provide a holistic platform (currently at the integration stage) that offers services addressing different needs of beekeepers and associated researchers, facilitating their work and contributing to the study of biodiversity. Specifically, an automated mapping service was implemented that runs periodically in the back end and uses the freely available multi-temporal and multi spectral Sentinel-2 data to estimate and update information regarding beekeeping flora (including blooming detection), based on state-of-the-art AI models for semantic segmentation. Moreover, a web/mobile mapping app and a mobile (progressive web) app were developed, exploiting modern remote sensing and AI technologies. In particular, the mapping app displays freely available data layers that provide crucial information for beekeepers and enables them to view and edit their own data layers, manually entering information regarding beekeeping flora near their apiaries. On the other hand, the mobile app provides two additional functionalities: a) tools for beehive inspection and management, which allow beekeepers to keep track of honeybee colonies development, applied treatments and/or feeding actions, and b) automated AI-based identification of beekeeping plants from photos captured by the mobile phone. An e-marketplace for beekeeping products as well as additional services towards laboratories performing analyses of beekeeping products as well as the general public are also included. Preliminary results for two variants of the automated mapping procedure based on a new dataset including a beekeeping plant are also presented. The final goal is improve current beekeeping practices, reduce costs, and create a new distribution channel for beekeeping products.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2244058813",
                        "name": "N. Grammalidis"
                    },
                    {
                        "authorId": "2244057119",
                        "name": "Andreas Stergioulas"
                    },
                    {
                        "authorId": "2244056702",
                        "name": "Aggelos Avramidis"
                    },
                    {
                        "authorId": "2097429556",
                        "name": "Konstantinos Karystinakis"
                    },
                    {
                        "authorId": "2191591904",
                        "name": "Athanasios Partozis"
                    },
                    {
                        "authorId": "2244056956",
                        "name": "Athanasios Topaloudis"
                    },
                    {
                        "authorId": "2244060673",
                        "name": "Georgia Kalantzi"
                    },
                    {
                        "authorId": "2244058818",
                        "name": "Chrisoula Tananaki"
                    },
                    {
                        "authorId": "2244066272",
                        "name": "Dimitrios Kanelis"
                    },
                    {
                        "authorId": "47118436",
                        "name": "Vasilis Liolios"
                    },
                    {
                        "authorId": "10722553",
                        "name": "Madesis Panagiotis"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "68814b06f49b3d7a18f52685f896a0518a11eabb",
                "externalIds": {
                    "DOI": "10.1117/12.2681856",
                    "CorpusId": 262180892
                },
                "corpusId": 262180892,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/68814b06f49b3d7a18f52685f896a0518a11eabb",
                "title": "LavenderVision: a dataset and methodology for lavender bloom detection using Sentinel-2 data",
                "abstract": "The accelerated advancements in remote sensing technologies and the deployment of satellites offering freely accessible multispectral satellite imagery have facilitated the application of machine learning, particularly deep learning techniques, to tasks such as crop classification, yield estimation, and bloom detection. Additionally, several countries in the European Union have adopted the Land Parcel Identification System (LPIS), that obliges farmers to declare the exact area and crop type of their parcels each year while also making the LPIS data freely accessible to the public. For the purpose of the SmartBeeKeep research project, co-funded by EU and Greek funds, in this work we utilize the above with the objective to combine multispectral and multitemporal satellite data obtained from the Sentinel-2 satellite with the LPIS parcel maps in order to detect and classify the blooming period of the beekeeping plant lavender, with the use of automated deep machine learning methods. The specific plant type was selected as it is exhibits particular interest to the beekeeping community, which is the main focus group of the SmartbeeKeep project. For this task, a dataset was amassed and thoroughly sorted out, that comprises of approximately 15k individual parcels from the area of Southern France between January 2020 to December 2021. For each parcel, a study of its harmonized EVI index was carried out in order to roughly identify its blooming period temporal boundaries and with the help of experts, characteristic parcels for sub-regions of Marseille were selected to create more accurate temporal annotations. Additionally, freely available data from the EU Copernicus DIAS reference service WEkEO were utilized as an initial temporal estimation for the Start-of-Season (SOS) and End-of-Season (EOS) period. Two temporal deep learning methods were evaluated, namely a convolutional and a recurrent and model, so as to establish benchmark results on the created dataset. The dataset will be released upon publication.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2244057119",
                        "name": "Andreas Stergioulas"
                    },
                    {
                        "authorId": "2244058813",
                        "name": "N. Grammalidis"
                    },
                    {
                        "authorId": "2244066272",
                        "name": "Dimitrios Kanelis"
                    },
                    {
                        "authorId": "47118436",
                        "name": "Vasilis Liolios"
                    },
                    {
                        "authorId": "2244058818",
                        "name": "Chrisoula Tananaki"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "5M tokens arranged into chunks of shape [time,channel] \u2261 [12,19]."
            ],
            "citingPaper": {
                "paperId": "6483a6f2038cd8583ad5b6678602bc904459a7f7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-07207",
                    "ArXiv": "2309.07207",
                    "DOI": "10.48550/arXiv.2309.07207",
                    "CorpusId": 261822778
                },
                "corpusId": 261822778,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6483a6f2038cd8583ad5b6678602bc904459a7f7",
                "title": "EarthPT: a foundation model for Earth Observation",
                "abstract": "We introduce EarthPT -- an Earth Observation (EO) pretrained transformer. EarthPT is a 700 million parameter decoding transformer foundation model trained in an autoregressive self-supervised manner and developed specifically with EO use-cases in mind. We demonstrate that EarthPT is an effective forecaster that can accurately predict future pixel-level surface reflectances across the 400-2300 nm range well into the future. For example, forecasts of the evolution of the Normalised Difference Vegetation Index (NDVI) have a typical error of approximately 0.05 (over a natural range of -1 ->1) at the pixel level over a five month test set horizon, out-performing simple phase-folded models based on historical averaging. We also demonstrate that embeddings learnt by EarthPT hold semantically meaningful information and could be exploited for downstream tasks such as highly granular, dynamic land use classification. Excitingly, we note that the abundance of EO data provides us with -- in theory -- quadrillions of training tokens. Therefore, if we assume that EarthPT follows neural scaling laws akin to those derived for Large Language Models (LLMs), there is currently no data-imposed limit to scaling EarthPT and other similar `Large Observation Models.'",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "145618949",
                        "name": "Michael J. Smith"
                    },
                    {
                        "authorId": "2240522321",
                        "name": "Luke Fleming"
                    },
                    {
                        "authorId": "2308961",
                        "name": "J. Geach"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "ad86b56108d301643124fcab266f5bd78806d5c7",
                "externalIds": {
                    "DOI": "10.1016/j.rse.2023.113679",
                    "CorpusId": 259446498
                },
                "corpusId": 259446498,
                "publicationVenue": {
                    "id": "2544009c-f3cc-45f2-b79b-aff3d09cfc34",
                    "name": "Remote Sensing of Environment",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens Environ"
                    ],
                    "issn": "0034-4257",
                    "url": "https://www.journals.elsevier.com/remote-sensing-of-environment",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/00344257"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ad86b56108d301643124fcab266f5bd78806d5c7",
                "title": "A novel Greenness and Water Content Composite Index (GWCCI) for soybean mapping from single remotely sensed multispectral images",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2155552807",
                        "name": "Hui Chen"
                    },
                    {
                        "authorId": "145495205",
                        "name": "Huapeng Li"
                    },
                    {
                        "authorId": "2118395516",
                        "name": "Zhao Liu"
                    },
                    {
                        "authorId": "2048336450",
                        "name": "Ce Zhang"
                    },
                    {
                        "authorId": "48691736",
                        "name": "Shuqing Zhang"
                    },
                    {
                        "authorId": "2139380",
                        "name": "P. Atkinson"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "04a1994668ef1761a24a4630c6852972754e555b",
                "externalIds": {
                    "DOI": "10.1117/1.JRS.17.038503",
                    "CorpusId": 260722784
                },
                "corpusId": 260722784,
                "publicationVenue": {
                    "id": "e1fe9a1d-d67b-4f64-a192-472091321f8e",
                    "name": "Journal of Applied Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "J Appl Remote Sens"
                    ],
                    "issn": "1931-3195",
                    "url": "https://www.spiedigitallibrary.org/journals/journal-of-applied-remote-sensing",
                    "alternate_urls": [
                        "http://remotesensing.spiedigitallibrary.org/journal.aspx"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/04a1994668ef1761a24a4630c6852972754e555b",
                "title": "Multi-task hybrid spectral\u2013spatial temporal convolution networks for classification of agricultural crop types and growth stages using drone-borne hyperspectral and multispectral images",
                "abstract": "Abstract. Accurate crop type and crop growth stage maps are essential for agricultural monitoring and ensuring food security. A wide variety of airborne and spaceborne sensors now provide high spatial, spectral, and temporal resolution images, which are vital for crop mapping and monitoring. Crop type and its growth stage can be characterized by spectral, spatial, and temporal features. The classification of crop types and growth stages has been explored in previous studies as independent tasks. However, the growth stages of a crop are an important factor in identifying the crop and vice-versa. A multi-task learning (MTL) framework is proposed in this work to classify the crop type and its growth stages simultaneously. A hybrid convolutional neural network and temporal convolutional network (CNN-TCN) architecture is presented to process a multitude of features relevant to the tasks. To learn the spatio\u2013spectral features, we fed the hyperspectral input to 3D convolution blocks and multispectral input was given into 2D convolution blocks. We reformulate these multi-channel features into two dimensions and feed them into the temporal convolutional neural network. Subsequently, we use two fully connected branches for each task. MTL frameworks were developed for multispectral (Mx), hyperspectral (Hx), and the combination of Hx and Mx (Hx-Mx) images to model crop type and crop growth stage classification. Results reveal that the proposed model for Hx-Mx outperformed the best single-task model by 13% and 8% in crop growth stage and crop type classification, respectively. Compared to single-task models, the proposed model can exploit the high spectral information from Hx images and high spatial information from Mx images, making the proposed model more useful for unmanned-aerial-vehicle-based crop mapping.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "48047344",
                        "name": "B. Chaudhury"
                    },
                    {
                        "authorId": "30149414",
                        "name": "Anand S. Sahadevan"
                    },
                    {
                        "authorId": "144240262",
                        "name": "Pabitra Mitra"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "db1409a0bc3a01d88e6ee1675a27b4890c5b6174",
                "externalIds": {
                    "DOI": "10.47392/irjash.2023.s060",
                    "CorpusId": 259568531
                },
                "corpusId": 259568531,
                "publicationVenue": {
                    "id": "2c7f7ade-217c-4c28-8075-8dc443762ff4",
                    "name": "International Research Journal on Advanced Science Hub",
                    "type": "journal",
                    "alternate_names": [
                        "Int Res J Adv Sci Hub"
                    ],
                    "issn": "2582-4376",
                    "url": "http://www.rspsciencehub.com/irjash/"
                },
                "url": "https://www.semanticscholar.org/paper/db1409a0bc3a01d88e6ee1675a27b4890c5b6174",
                "title": "Crop Classification using Semi supervised Learning on Data Fusion of SAR and Optical Sensor",
                "abstract": "Crop maps are essential tools for creating crop inventories, forecasting yields, and guiding the use of ef\ufb01cient farm management techniques. These maps must be created at highly exact scales, necessitating dif\ufb01cult, costly, and time-consuming \ufb01eldwork. Deep learning algorithms have now signi\ufb01cantly enhanced outcomes when using data in the geographical and temporal dimensions, which are essential for agricultural research. The simultaneous availability of Sentinel-1 (synthetic aperture radar) and Sentinel-2 (optical) data provides an excellent chance to combine them. Sentinel 1 and Sentinel 2 data sets were collected for the Cape Town, South Africa, region. With the use of these datasets, we use the fusion technique, particularly the layer-level fusion strategy, one of the three fusion procedures (input level, layer level, and deci-sion level). Also, we will compare the results before and after the fusion and discuss the recommended method for converting from a multilayer perceptron decoder to a semi-supervised decoder architecture.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2124052325",
                        "name": "A. R"
                    },
                    {
                        "authorId": "2222012736",
                        "name": "Gopikrishnan C"
                    },
                    {
                        "authorId": "2221970269",
                        "name": "Varun Raj A"
                    },
                    {
                        "authorId": "2124088967",
                        "name": "V. M"
                    },
                    {
                        "authorId": "2222114823",
                        "name": "Mr. Jayakrishnan"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Besides, self-attention can also be employed to extract temporal features within one time series [91], where it can usually outperform RNNs on a variety of tasks."
            ],
            "citingPaper": {
                "paperId": "14f8e032889b05653bb09628159540cb85756088",
                "externalIds": {
                    "ArXiv": "2305.14582",
                    "DBLP": "journals/corr/abs-2305-14582",
                    "DOI": "10.48550/arXiv.2305.14582",
                    "CorpusId": 258865310
                },
                "corpusId": 258865310,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/14f8e032889b05653bb09628159540cb85756088",
                "title": "Interpretation of Time-Series Deep Models: A Survey",
                "abstract": "Deep learning models developed for time-series associated tasks have become more widely researched nowadays. However, due to the unintuitive nature of time-series data, the interpretability problem -- where we understand what is under the hood of these models -- becomes crucial. The advancement of similar studies in computer vision has given rise to many post-hoc methods, which can also shed light on how to explain time-series models. In this paper, we present a wide range of post-hoc interpretation methods for time-series models based on backpropagation, perturbation, and approximation. We also want to bring focus onto inherently interpretable models, a novel category of interpretation where human-understandable information is designed within the models. Furthermore, we introduce some common evaluation metrics used for the explanations, and propose several directions of future researches on the time-series interpretability problem. As a highlight, our work summarizes not only the well-established interpretation methods, but also a handful of fairly recent and under-developed techniques, which we hope to capture their essence and spark future endeavours to innovate and improvise.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1840069786",
                        "name": "Ziqi Zhao"
                    },
                    {
                        "authorId": "46571755",
                        "name": "Yucheng Shi"
                    },
                    {
                        "authorId": "2152956477",
                        "name": "Shushan Wu"
                    },
                    {
                        "authorId": "47829900",
                        "name": "Fan Yang"
                    },
                    {
                        "authorId": "2219406713",
                        "name": "Wenzhan Song"
                    },
                    {
                        "authorId": "47717322",
                        "name": "Ninghao Liu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "We retain the computational simplifications of [2] and use a channel grouping, where the G attention heads process mutually exclusive subsets of D/G channels of the embedding.",
                "This strategy has proved beneficial for learned time series processing [2], [75], since it preserves information about seasonal patterns (e.",
                "Unlike [2], we employ data-driven queries to preserve the temporal dimension of the input.",
                "In a nutshell, U-TAE combines convolutions for multi-scale spatio-spectral encoding with a lightweight non-local temporal attention mechanism [2].",
                "The temporal encoder is based on the Lightweight Temporal Attention Encoder (L-TAE) of [2], which, in turn, is a simplified version of the multi-head self-attention mechanism of the transformer architecture [72]."
            ],
            "citingPaper": {
                "paperId": "964df96a2b6ae980f43b0d86cce3a60245a2ccc3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-13277",
                    "ArXiv": "2305.13277",
                    "DOI": "10.48550/arXiv.2305.13277",
                    "CorpusId": 258833656
                },
                "corpusId": 258833656,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/964df96a2b6ae980f43b0d86cce3a60245a2ccc3",
                "title": "U-TILISE: A Sequence-to-sequence Model for Cloud Removal in Optical Satellite Time Series",
                "abstract": "Satellite image time series in the optical and infrared spectrum suffer from frequent data gaps due to cloud cover, cloud shadows, and temporary sensor outages. It has been a long-standing problem of remote sensing research how to best reconstruct the missing pixel values and obtain complete, cloud-free image sequences. We approach that problem from the perspective of representation learning and develop U-TILISE, an efficient neural model that is able to implicitly capture spatio-temporal patterns of the spectral intensities, and that can therefore be trained to map a cloud-masked input sequence to a cloud-free output sequence. The model consists of a convolutional spatial encoder that maps each individual frame of the input sequence to a latent encoding; an attention-based temporal encoder that captures dependencies between those per-frame encodings and lets them exchange information along the time dimension; and a convolutional spatial decoder that decodes the latent embeddings back into multi-spectral images. We experimentally evaluate the proposed model on EarthNet2021, a dataset of Sentinel-2 time series acquired all over Europe, and demonstrate its superior ability to reconstruct the missing pixels. Compared to a standard interpolation baseline, it increases the PSNR by 1.8 dB at previously seen locations and by 1.3 dB at unseen locations.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "114970986",
                        "name": "Corinne Stucker"
                    },
                    {
                        "authorId": "67228021",
                        "name": "Vivien Sainte Fare Garnot"
                    },
                    {
                        "authorId": "144810819",
                        "name": "K. Schindler"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "\u2026of RS data and integrating its representation into a neural network, similar to architectures such as CNN-RNN (Pelletier et al., 2019; Sainte Fare Garnot et al., 2019) or more advanced structures like PSE-LTAE (Sainte Fare Garnot et al., 2020; Quinton & Landrieu, 2021; Weilandt et al., 2023).",
                "Quinton & Landrieu (2021) propose to use a Pixel-Set Encoder with a Lightweight Temporal Attention Encoder (PSE-LTAE) (Sainte Fare Garnot et al., 2020) combined with a multi-year classification method.",
                "Studies proved that other methods were more efficient in terms of performances (Sainte Fare Garnot et al., 2020).",
                "In the end, Sainte Fare Garnot et al. (2020) proposed a smart method to tackle parcel-level crop classification, by randomly sampling pixels of the parcels to learn expressive descriptors that are processed by a transformer."
            ],
            "citingPaper": {
                "paperId": "c272a2c6a2e8ac5e978102061a239957de742ceb",
                "externalIds": {
                    "ArXiv": "2305.12011",
                    "DBLP": "journals/corr/abs-2305-12011",
                    "DOI": "10.48550/arXiv.2305.12011",
                    "CorpusId": 258832739
                },
                "corpusId": 258832739,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c272a2c6a2e8ac5e978102061a239957de742ceb",
                "title": "Boosting Crop Classification by Hierarchically Fusing Satellite, Rotational, and Contextual Data",
                "abstract": "Accurate in-season crop type classification is crucial for the crop production estimation and monitoring of agricultural parcels. However, the complexity of the plant growth patterns and their spatio-temporal variability present significant challenges. While current deep learning-based methods show promise in crop type classification from single- and multi-modal time series, most existing methods rely on a single modality, such as satellite optical remote sensing data or crop rotation patterns. We propose a novel approach to fuse multimodal information into a model for improved accuracy and robustness across multiple years and countries. The approach relies on three modalities used: remote sensing time series from Sentinel-2 and Landsat 8 observations, parcel crop rotation and local crop distribution. To evaluate our approach, we release a new annotated dataset of 7.4 million agricultural parcels in France and Netherlands. We associate each parcel with time-series of surface reflectance (Red and NIR) and biophysical variables (LAI, FAPAR). Additionally, we propose a new approach to automatically aggregate crop types into a hierarchical class structure for meaningful model evaluation and a novel data-augmentation technique for early-season classification. Performance of the multimodal approach was assessed at different aggregation level in the semantic domain spanning from 151 to 8 crop types or groups. It resulted in accuracy ranging from 91\\% to 95\\% for NL dataset and from 85\\% to 89\\% for FR dataset. Pre-training on a dataset improves domain adaptation between countries, allowing for cross-domain zero-shot learning, and robustness of the performances in a few-shot setting from France to Netherlands. Our proposed approach outperforms comparable methods by enabling learning methods to use the often overlooked spatio-temporal context of parcels, resulting in increased preci...",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "21498279",
                        "name": "Valentin Barri\u00e8re"
                    },
                    {
                        "authorId": "2640851",
                        "name": "M. Claverie"
                    },
                    {
                        "authorId": "2107764182",
                        "name": "M. Schneider"
                    },
                    {
                        "authorId": "33547943",
                        "name": "G. Lemoine"
                    },
                    {
                        "authorId": "1405158994",
                        "name": "R. d\u2019Andrimont"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "In addition to the spatiotemporal format T \u00d7C\u00d7H\u00d7W with high-quality semantic and panoptic annotations, over 120,000 bounding boxes and pixel-precise masks, it is accompanied with a pixel-set format T \u00d7 C \u00d7 N dataset [9] for parcel-based crop type classification.",
                "Meanwhile, as pointed out by previous work [7, 9], another great challenge for effectively learning representations for SITS is to capture the complex temporal dynamics in crop phenology, i.",
                "The pioneering work PSE+TAE [9] has proposed to use MLPs to summarize spatial statistics given the lack of rich spatial semantics in medium-resolution Sentinel-2 images and self-attention to encode temporal patterns, followed by PSE+L-TAE [7] where a light-weight transformer decoder has been used to extract temporal features.",
                "Pixel-Set Encoder (PSE) is particularly effective for dealing with the irregularity in parcel geometry by simplifying parcel representation from T \u00d7C\u00d7H\u00d7W to T \u00d7C\u00d7N , where T is the length of temporal sequence, C is the number channels, H/W denotes the height/width, and N denotes the number of pixels, and consequently requires significantly less storage memory [9] compared to the patch format.",
                "The pioneering work PSE+TAE [9]/PSE+L-TAE [7] has introduced a promising learning paradigm for SITS, where statistics of spectral values are first summarized across the spatial extent of crop parcels by Multi-Layer Perceptrons (MLPs) that operate independently on unordered sets of pixels.",
                "However, the lack of flexibility to operate on different input formats, i.e., the pixel-set or image sequence format, imposes restrictions on PSE+TAE or TSViT."
            ],
            "citingPaper": {
                "paperId": "9ea71e19ff2d831d14adf56ef6d9d5e416bb4039",
                "externalIds": {
                    "ArXiv": "2305.02086",
                    "CorpusId": 258461391
                },
                "corpusId": 258461391,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/9ea71e19ff2d831d14adf56ef6d9d5e416bb4039",
                "title": "Revisiting the Encoding of Satellite Image Time Series",
                "abstract": "Satellite Image Time Series (SITS) representation learning is complex due to high spatiotemporal resolutions, irregular acquisition times, and intricate spatiotemporal interactions. These challenges result in specialized neural network architectures tailored for SITS analysis. The field has witnessed promising results achieved by pioneering researchers, but transferring the latest advances or established paradigms from Computer Vision (CV) to SITS is still highly challenging due to the existing suboptimal representation learning framework. In this paper, we develop a novel perspective of SITS processing as a direct set prediction problem, inspired by the recent trend in adopting query-based transformer decoders to streamline the object detection or image segmentation pipeline. We further propose to decompose the representation learning process of SITS into three explicit steps: collect-update-distribute, which is computationally efficient and suits for irregularly-sampled and asynchronous temporal satellite observations. Facilitated by the unique reformulation, our proposed temporal learning backbone of SITS, initially pre-trained on the resource efficient pixel-set format and then fine-tuned on the downstream dense prediction tasks, has attained new state-of-the-art (SOTA) results on the PASTIS benchmark dataset. Specifically, the clear separation between temporal and spatial components in the semantic/panoptic segmentation pipeline of SITS makes us leverage the latest advances in CV, such as the universal image segmentation architecture, resulting in a noticeable 2.5 points increase in mIoU and 8.8 points increase in PQ, respectively, compared to the best scores reported so far.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "101374725",
                        "name": "Xin Cai"
                    },
                    {
                        "authorId": "145208564",
                        "name": "Y. Bi"
                    },
                    {
                        "authorId": "153680862",
                        "name": "Peter Nicholl"
                    },
                    {
                        "authorId": "1685801",
                        "name": "Roy Sterritt"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "Thus the computational performance of models is a critical consideration, especially for under-resourced institutions and research [20, 30, 31, 32, 33].",
                "This allows for much smaller models to be trained (Presto has \u223c 1000\u00d7 fewer trainable parameters than ScaleMAE and SatMAE), which is important for their practical deployment [20, 30, 31, 32, 33].",
                "A common approach by remote sensing practitioners is to train single pixel-timeseries models [18, 19, 17, 20, 21, 22, 23, 24].",
                "From a remote sensing perspective, there are several advantages to processing pixel-timeseries instead of entire images: \u2022 Many remote sensing applications are specifically designed for pixel-timeseries, particularly when change over time is critical [18, 19, 17, 20, 21, 22, 23, 24]."
            ],
            "citingPaper": {
                "paperId": "59d5f41c9b067f6cdb308153ab9acd71064870df",
                "externalIds": {
                    "ArXiv": "2304.14065",
                    "DBLP": "journals/corr/abs-2304-14065",
                    "DOI": "10.48550/arXiv.2304.14065",
                    "CorpusId": 258352331
                },
                "corpusId": 258352331,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/59d5f41c9b067f6cdb308153ab9acd71064870df",
                "title": "Lightweight, Pre-trained Transformers for Remote Sensing Timeseries",
                "abstract": "Machine learning models for parsing remote sensing data have a wide range of societally relevant applications, but labels used to train these models can be difficult or impossible to acquire. This challenge has spurred research into self-supervised learning for remote sensing data aiming to unlock the use of machine learning in geographies or application domains where labelled datasets are small. Current self-supervised learning approaches for remote sensing data draw significant inspiration from techniques applied to natural images. However, remote sensing data has important differences from natural images -- for example, the temporal dimension is critical for many tasks and data is collected from many complementary sensors. We show we can create significantly smaller performant models by designing architectures and self-supervised training techniques specifically for remote sensing data. We introduce the Pretrained Remote Sensing Transformer (Presto), a transformer-based model pre-trained on remote sensing pixel-timeseries data. Presto excels at a wide variety of globally distributed remote sensing tasks and performs competitively with much larger models while requiring far less compute. Presto can be used for transfer learning or as a feature extractor for simple models, enabling efficient deployment at scale.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1782337568",
                        "name": "Gabriel Tseng"
                    },
                    {
                        "authorId": "2164196053",
                        "name": "Ivan Zvonkov"
                    },
                    {
                        "authorId": "1576655836",
                        "name": "Mirali Purohit"
                    },
                    {
                        "authorId": "2381187",
                        "name": "D. Rolnick"
                    },
                    {
                        "authorId": "151024247",
                        "name": "H. Kerner"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "The L-TAE\u2019s parameters are kept to their default values nhead = 16, and key dimension dk = 4.",
                "Next, as in [22], the low-resolution features ft are processed pixel-wise with an L-TAE [21, 23]: we obtain attention masks over the T observations for each pixel position of the low resolution feature maps.",
                "We use a dropout rate of 0.1 on the attention masks after upsampling, and the temporal aggregation is done with L-TAE\u2019s channel grouping strategy [21].",
                "Contrary to previous work, we only use the L-TAE\u2019s attention masks, and omit attentionweighting of the sequence of low resolution feature maps.",
                "For mono-temporal considera-\ntions, we use the same architecture and simply discard the unnecessary L-TAE-based aggregation."
            ],
            "citingPaper": {
                "paperId": "01361bfd008b8405f13531f59cdcb7c8776b75d4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-05464",
                    "ArXiv": "2304.05464",
                    "DOI": "10.1109/CVPRW59228.2023.00202",
                    "CorpusId": 258079054
                },
                "corpusId": 258079054,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/01361bfd008b8405f13531f59cdcb7c8776b75d4",
                "title": "UnCRtainTS: Uncertainty Quantification for Cloud Removal in Optical Satellite Time Series",
                "abstract": "Clouds and haze often occlude optical satellite images, hindering continuous, dense monitoring of the Earth\u2019s surface. Although modern deep learning methods can implicitly learn to ignore such occlusions, explicit cloud removal as pre-processing enables manual interpretation and allows training models when only few annotations are available. Cloud removal is challenging due to the wide range of occlusion scenarios\u2014from scenes partially visible through haze, to completely opaque cloud coverage. Furthermore, integrating reconstructed images in downstream applications would greatly benefit from trustworthy quality assessment. In this paper, we introduce UnCRtainTS, a method for multi-temporal cloud removal combining a novel attention-based architecture, and a formulation for multivariate uncertainty prediction. These two components combined set a new state-of-the-art performance in terms of image reconstruction on two public cloud removal datasets. Additionally, we show how the well-calibrated predicted uncertainties enable a precise control of the reconstruction quality.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "144377539",
                        "name": "Patrick Ebel"
                    },
                    {
                        "authorId": "67228021",
                        "name": "Vivien Sainte Fare Garnot"
                    },
                    {
                        "authorId": "145182654",
                        "name": "M. Schmitt"
                    },
                    {
                        "authorId": "1753678",
                        "name": "J. D. Wegner"
                    },
                    {
                        "authorId": "2125159330",
                        "name": "Xiao Xiang Zhu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "24d5531079c75401c4bef6e4849e73f3c6d1115f",
                "externalIds": {
                    "DOI": "10.1016/j.srs.2023.100085",
                    "CorpusId": 258389685
                },
                "corpusId": 258389685,
                "publicationVenue": {
                    "id": "6301827f-bdeb-4b8d-8265-7c0568ece6d9",
                    "name": "Science of Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Sci Remote Sens"
                    ],
                    "issn": "2666-0172",
                    "url": "https://www.journals.elsevier.com/science-of-remote-sensing",
                    "alternate_urls": [
                        "https://www.sciencedirect.com/journal/science-of-remote-sensing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/24d5531079c75401c4bef6e4849e73f3c6d1115f",
                "title": "Utility of daily 3m Planet Fusion Surface Reflectance data for tillage practice mapping with deep learning",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2061548223",
                        "name": "D. Luo"
                    },
                    {
                        "authorId": "39712829",
                        "name": "Hankui K. Zhang"
                    },
                    {
                        "authorId": "1919533",
                        "name": "R. Houborg"
                    },
                    {
                        "authorId": "2215656015",
                        "name": "Lina M.N. Ndekelu"
                    },
                    {
                        "authorId": "2496780",
                        "name": "M. Maimaitijiang"
                    },
                    {
                        "authorId": "2151741065",
                        "name": "Khuong H. Tran"
                    },
                    {
                        "authorId": "12644454",
                        "name": "John McMaine"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "369d0ee688f2a615d0454e9cb07fe9f7bda21faa",
                "externalIds": {
                    "DBLP": "journals/chinaf/SunTLWNYF23",
                    "DOI": "10.1007/s11432-022-3588-0",
                    "CorpusId": 257858131
                },
                "corpusId": 257858131,
                "publicationVenue": {
                    "id": "0534c8a0-1226-4f5b-bcf6-a13a8dd1825e",
                    "name": "Science China Information Sciences",
                    "alternate_names": [
                        "Sci China Inf Sci"
                    ],
                    "issn": "1869-1919",
                    "url": "http://info.scichina.com/"
                },
                "url": "https://www.semanticscholar.org/paper/369d0ee688f2a615d0454e9cb07fe9f7bda21faa",
                "title": "From single- to multi-modal remote sensing imagery interpretation: a survey and taxonomy",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2946890",
                        "name": "Xian Sun"
                    },
                    {
                        "authorId": "2152947347",
                        "name": "Yu Tian"
                    },
                    {
                        "authorId": "3287729",
                        "name": "Wanxuan Lu"
                    },
                    {
                        "authorId": "152702629",
                        "name": "Peijin Wang"
                    },
                    {
                        "authorId": "1481700281",
                        "name": "Ruigang Niu"
                    },
                    {
                        "authorId": "4590999",
                        "name": "Hongfeng Yu"
                    },
                    {
                        "authorId": "2266415",
                        "name": "K. Fu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "ee59aa69a8d113fcfb1a29b601a99139b583b359",
                "externalIds": {
                    "ArXiv": "2304.01236",
                    "DBLP": "journals/corr/abs-2304-01236",
                    "DOI": "10.1051/0004-6361/202244657",
                    "CorpusId": 257751904
                },
                "corpusId": 257751904,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ee59aa69a8d113fcfb1a29b601a99139b583b359",
                "title": "Astronomical image time series classification using CONVolutional attENTION (ConvEntion)",
                "abstract": "Aims. The treatment of astronomical image time series has won increasing attention in recent years. Indeed, numerous surveys following up on transient objects are in progress or under construction, such as the Vera Rubin Observatory Legacy Survey for Space and Time (LSST), which is poised to produce huge amounts of these time series. The associated scientific topics are extensive, ranging from the study of objects in our galaxy to the observation of the most distant supernovae for measuring the expansion of the universe. With such a large amount of data available, the need for robust automatic tools to detect and classify celestial objects is growing steadily. Methods. This study is based on the assumption that astronomical images contain more information than light curves. In this paper, we propose a novel approach based on deep learning for classifying different types of space objects directly using images. We named our approach ConvEntion, which stands for CONVolutional attENTION. It is based on convolutions and transformers, which are new approaches for the treatment of astronomical image time series. Our solution integrates spatio-temporal features and can be applied to various types of image datasets with any number of bands. Results. In this work, we solved various problems the datasets tend to suffer from and we present new results for classifications using astronomical image time series with an increase in accuracy of 13%, compared to state-of-the-art approaches that use image time series, and a 12% increase, compared to approaches that use light curves.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2213345135",
                        "name": "Anass Bairouk"
                    },
                    {
                        "authorId": "145246478",
                        "name": "M. Chaumont"
                    },
                    {
                        "authorId": "3994998",
                        "name": "D. Fouchez"
                    },
                    {
                        "authorId": "145273917",
                        "name": "J. Pasquet"
                    },
                    {
                        "authorId": "2372455",
                        "name": "F. Comby"
                    },
                    {
                        "authorId": "46384369",
                        "name": "J. Bautista"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "4c1ca2e2c3f37040e3d6cc4849eff302f145b42d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-12533",
                    "ArXiv": "2303.12533",
                    "DOI": "10.48550/arXiv.2303.12533",
                    "CorpusId": 257663601
                },
                "corpusId": 257663601,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4c1ca2e2c3f37040e3d6cc4849eff302f145b42d",
                "title": "Pixel-wise Agricultural Image Time Series Classification: Comparisons and a Deformable Prototype-based Approach",
                "abstract": "Improvements in Earth observation by satellites allow for imagery of ever higher temporal and spatial resolution. Leveraging this data for agricultural monitoring is key for addressing environmental and economic challenges. Current methods for crop segmentation using temporal data either rely on annotated data or are heavily engineered to compensate the lack of supervision. In this paper, we present and compare datasets and methods for both supervised and unsupervised pixel-wise segmentation of satellite image time series (SITS). We also introduce an approach to add invariance to spectral deformations and temporal shifts to classical prototype-based methods such as K-means and Nearest Centroid Classifier (NCC). We show this simple and highly interpretable method leads to meaningful results in both the supervised and unsupervised settings and significantly improves the state of the art for unsupervised classification of agricultural time series on four recent SITS datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2086971830",
                        "name": "Elliot Vincent"
                    },
                    {
                        "authorId": "144189388",
                        "name": "J. Ponce"
                    },
                    {
                        "authorId": "48582897",
                        "name": "Mathieu Aubry"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Model Year Embedding Other features Crop type classification TAN [200] 2019 2D-CNN & GRU Attention \u2014 temporal TGA [201] 2020 2D-CNN Attention \u2014 squeeze and excitation 3D-CNN [202] 2018 3D-CNN DCM [203] 2020 LSTM Self-attention HierbiLSTM [204] 2022 LSTM Self-attention L-TAE [205] 2020 MLP Attention \u2014 temporal PSE-TAE [186, 206] 2020 MLP Attention \u2014 temporal optionally Multi-modal SITS-BERT [207] 2021 Pre-trained transformer Land Cover classification 1D-CNN [208] 2017 1D-CNN & MLP Hybrid model 1D & 2D-CNNs [209] 2017 1D-CNN; 2D-CNN Ensemble model TempCNN [210] 2019 1D-CNN TASSEL [185] 2020 1D-CNN Self-attention TSI [211] 2021 1D-CNN; LSTM Ensemble model TWINNS [212] 2019 2D-CNN & GRU Attention \u2014 temporal; Multi-modal DuPLO [213] 2019 2D-CNN & GRU Attention \u2014 temporal Sequential RNN [214] 2018 2D-FCN & LSTM Hybrid model FG-UNET [215] 2019 UNet & 2D-CNN Hybrid model LSTM [216] 2017 LSTM HOb2sRNN [217] 2020 GRU Attention \u2014 temporal OD2RNN [218] 2019 GRU Attention \u2014 temporal; Multi-modal SITS-Former [219] 2022 3D-CNN Pre-trained transformer Other classification tasks Deforestation [191] 2022 U-Net & LSTM Hybrid model Flood detection [189] 2020 Resnet & GRU Hybrid model Forest understory [193] 2022 2D-CNN & LSTM Ensemble model Road detection [190] 2020 U-Net & convLSTM Hybrid model Vegetation quality [192] 2017 LSTM; GRU Extrinsic regression tasks TempCNN-LFMC [195] 2021 1D-CNN Multi-tempCNN [196] 2022 1D-CNN Multi-modal, ensemble model LFMC estimation [194] 2020 LSTM Multi-modal LFMC estimation [197] 2022 1D-CNN & LSTM Multi-modal, hybrid, ensemble MLDL-net [199] 2020 2D-CNN & LSTM Hybrid model SSTNN [220] 2021 3D-CNN & LSTM Hybrid model MMFVE [198] 2022 2D-CNN Hybrid model",
                "PSE-TAE [186] used a modified transformer called a temporal attention encoder (TAE) for crop mapping and found the TAE performed better than either a CNN or an RNN. L-TAE [205] replaced the TAE with a light-weight transformer which is both computationally efficient and more accurate than the full TAE.",
                "However, both clustering (TASSEL, [185]), and neural-network based methods, such as the Pixel-Set Encoder [186] have been used for more complex feature extraction.",
                "PSE-TAE [186] used a modified transformer called a temporal attention encoder (TAE) for crop mapping and found the TAE performed better than either a CNN or an RNN."
            ],
            "citingPaper": {
                "paperId": "283de2b58c8c79c213feec9c39a9d29b673c9634",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-02515",
                    "ArXiv": "2302.02515",
                    "DOI": "10.48550/arXiv.2302.02515",
                    "CorpusId": 256616093
                },
                "corpusId": 256616093,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/283de2b58c8c79c213feec9c39a9d29b673c9634",
                "title": "Deep Learning for Time Series Classification and Extrinsic Regression: A Current Survey",
                "abstract": "Time Series Classification and Extrinsic Regression are important and challenging machine learning tasks. Deep learning has revolutionized natural language processing and computer vision and holds great promise in other fields such as time series analysis where the relevant features must often be abstracted from the raw data but are not known a priori. This paper surveys the current state of the art in the fast-moving field of deep learning for time series classification and extrinsic regression. We review different network architectures and training methods used for these tasks and discuss the challenges and opportunities when applying deep learning to time series data. We also summarize two critical applications of time series classification and extrinsic regression, human activity recognition and satellite earth observation.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "103913641",
                        "name": "Seyed Navid Mohammadi Foumani"
                    },
                    {
                        "authorId": "2113311992",
                        "name": "Lynn Miller"
                    },
                    {
                        "authorId": "32847186",
                        "name": "Chang Wei Tan"
                    },
                    {
                        "authorId": "2098367190",
                        "name": "G. I. Webb"
                    },
                    {
                        "authorId": "2318564",
                        "name": "G. Forestier"
                    },
                    {
                        "authorId": "39044014",
                        "name": "Mahsa Salehi"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "af9aef48b8764ff79b34351dbb3f5fe3fd106447",
                "externalIds": {
                    "DBLP": "journals/remotesensing/WeilandtBGMRSSW23",
                    "DOI": "10.3390/rs15030799",
                    "CorpusId": 256540835
                },
                "corpusId": 256540835,
                "publicationVenue": {
                    "id": "8e1bd4b5-d5b2-4e22-ba0a-01fe5568d472",
                    "name": "Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens"
                    ],
                    "issn": "2315-4675",
                    "alternate_issns": [
                        "2072-4292"
                    ],
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-169233",
                    "alternate_urls": [
                        "https://www.mdpi.com/journal/remotesensing",
                        "http://www.mdpi.com/journal/remotesensing",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-169233"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/af9aef48b8764ff79b34351dbb3f5fe3fd106447",
                "title": "Early Crop Classification via Multi-Modal Satellite Data Fusion and Temporal Attention",
                "abstract": "In this article, we propose a deep learning-based algorithm for the classification of crop types from Sentinel-1 and Sentinel-2 time series data which is based on the celebrated transformer architecture. Crucially, we enable our algorithm to do early classification, i.e., predict crop types at arbitrary time points early in the year with a single trained model (progressive intra-season classification). Such early season predictions are of practical relevance for instance for yield forecasts or the modeling of agricultural water balances, therefore being important for the public as well as the private sector. Furthermore, we improve the mechanism of combining different data sources for the prediction task, allowing for both optical and radar data as inputs (multi-modal data fusion) without the need for temporal interpolation. We can demonstrate the effectiveness of our approach on an extensive data set from three federal states of Germany reaching an average F1 score of 0.92 using data of a complete growing season to predict the eight most important crop types and an F1 score above 0.8 when doing early classification at least one month before harvest time. In carefully chosen experiments, we can show that our model generalizes well in time and space.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2919918",
                        "name": "Frank Weilandt"
                    },
                    {
                        "authorId": "39125023",
                        "name": "R. Behling"
                    },
                    {
                        "authorId": "144121992",
                        "name": "R. Goncalves"
                    },
                    {
                        "authorId": "107970453",
                        "name": "A. Madadi"
                    },
                    {
                        "authorId": "117740823",
                        "name": "Lorenz Richter"
                    },
                    {
                        "authorId": "2204240771",
                        "name": "Tiago Sanona"
                    },
                    {
                        "authorId": "3284186",
                        "name": "D. Spengler"
                    },
                    {
                        "authorId": "2204240860",
                        "name": "Jona Welsch"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Finally, [16] view satellite images as un-ordered sets of pixels and calculate feature statistics at the parcel level, but, in contrast to previously mentioned approaches, their implementation requires knowledge of the object geometry."
            ],
            "citingPaper": {
                "paperId": "94556523a94a17415a4abf096327336043577527",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2301-04944",
                    "ArXiv": "2301.04944",
                    "DOI": "10.1109/CVPR52729.2023.01004",
                    "CorpusId": 255749555
                },
                "corpusId": 255749555,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/94556523a94a17415a4abf096327336043577527",
                "title": "ViTs for SITS: Vision Transformers for Satellite Image Time Series",
                "abstract": "In this paper we introduce the Temporo-Spatial Vision Transformer (TSViT), a fully-attentional model for general Satellite Image Time Series (SITS) processing based on the Vision Transformer (ViT). TSViT splits a SITS record into non-overlapping patches in space and time which are tokenized and subsequently processed by a factorized temporo-spatial encoder. We argue, that in contrast to natural images, a temporal-then-spatial factorization is more intuitive for SITS processing and present experimental evidence for this claim. Additionally, we enhance the model's discriminative power by introducing two novel mechanisms for acquisition-time-specific temporal positional encodings and multiple learnable class tokens. The effect of all novel design choices is evaluated through an extensive ablation study. Our proposed architecture achieves state-of-the-art performance, surpassing previous approaches by a significant margin in three publicly available SITS semantic segmentation and classification datasets. All model, training and evaluation codes can be found at https://github.com/michaeltrs/DeepSatModels.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "102361656",
                        "name": "Michail Tarasiou"
                    },
                    {
                        "authorId": "39859050",
                        "name": "Erik Chavez"
                    },
                    {
                        "authorId": "1776444",
                        "name": "S. Zafeiriou"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "[69] and Garnot and Landrieu [70]), panoptic"
            ],
            "citingPaper": {
                "paperId": "2898571ec05cfacf61e24822e1e6e45a9619d376",
                "externalIds": {
                    "ArXiv": "2212.08208",
                    "DBLP": "journals/tgrs/EddinRG23",
                    "DOI": "10.1109/TGRS.2023.3285401",
                    "CorpusId": 254823233
                },
                "corpusId": 254823233,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2898571ec05cfacf61e24822e1e6e45a9619d376",
                "title": "Location-Aware Adaptive Normalization: A Deep Learning Approach for Wildfire Danger Forecasting",
                "abstract": "Climate change is expected to intensify and increase extreme events in the weather cycle. Since this has a significant impact on various sectors of our life, recent works are concerned with identifying and predicting such extreme events from Earth observations. With respect to wildfire danger forecasting, previous deep learning approaches duplicate static variables along the time dimension and neglect the intrinsic differences between static and dynamic variables. Furthermore, most existing multibranch architectures lose the interconnections between the branches during the feature learning stage. To address these issues, this article proposes a 2-D/3-D two-branch convolutional neural network (CNN) with a location-aware adaptive normalization (LOAN) layer. Using LOAN as a building block, we can modulate the dynamic features conditional on their geographical locations. Thus, our approach considers feature properties as a unified yet compound 2-D/3-D model. Besides, we propose using the sinusoidal-based encoding of the day of the year to provide the model with explicit temporal information about the target day within the year. Our experimental results show a better performance of our approach than other baselines on the challenging FireCube dataset. The results show that location-aware adaptive feature normalization is a promising technique to learn the relation between dynamic variables and their geographic locations, which is highly relevant for areas where remote sensing data build the basis for analysis. The source code is available at https://github.com/HakamShams/LOAN.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2220762557",
                        "name": "Mohamad Hakam Shams Eddin"
                    },
                    {
                        "authorId": "46525320",
                        "name": "R. Roscher"
                    },
                    {
                        "authorId": "145689714",
                        "name": "Juergen Gall"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "0852c7c5cb5583592229401e96de073ae6672d4d",
                "externalIds": {
                    "DBLP": "journals/tip/LinYZ23",
                    "DOI": "10.1109/TIP.2022.3226418",
                    "CorpusId": 254445098,
                    "PubMed": "37015527"
                },
                "corpusId": 254445098,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0852c7c5cb5583592229401e96de073ae6672d4d",
                "title": "Transition Is a Process: Pair-to-Video Change Detection Networks for Very High Resolution Remote Sensing Images",
                "abstract": "As an important yet challenging task in Earth observation, change detection (CD) is undergoing a technological revolution, given the broadening application of deep learning. Nevertheless, existing deep learning-based CD methods still suffer from two salient issues: 1) incomplete temporal modeling, and 2) space-time coupling. In view of these issues, we propose a more explicit and sophisticated modeling of time and accordingly establish a pair-to-video change detection (P2V-CD) framework. First, a pseudo transition video that carries rich temporal information is constructed from the input image pair, interpreting CD as a problem of video understanding. Then, two decoupled encoders are utilized to spatially and temporally recognize the type of transition, and the encoders are laterally connected for mutual promotion. Furthermore, the deep supervision technique is applied to accelerate the model training. We illustrate experimentally that the P2V-CD method compares favorably to other state-of-the-art CD approaches in terms of both the visual effect and the evaluation metrics, with a moderate model size and relatively lower computational overhead. Extensive feature map visualization experiments demonstrate how our method works beyond making contrasts between bi-temporal images. Source code is available at https://github.com/Bobholamovic/CDLab.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "65793518",
                        "name": "Manhui Lin"
                    },
                    {
                        "authorId": "47124961",
                        "name": "Guangyi Yang"
                    },
                    {
                        "authorId": "2108879285",
                        "name": "Hongyan Zhang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[276] shows that standard transformers are not as efficient as RNN-based models for reinforcement learning tasks.",
                "On the other hand, [276] shows that their attentionbased model can outperform the state-of-the-art in terms of precision, time, and memory requirements for satellite image time series."
            ],
            "citingPaper": {
                "paperId": "f1f78bbb3e146874501e3c52b56cff6abf731842",
                "externalIds": {
                    "ArXiv": "2211.14732",
                    "DBLP": "journals/corr/abs-2211-14732",
                    "DOI": "10.48550/arXiv.2211.14732",
                    "CorpusId": 254044711
                },
                "corpusId": 254044711,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f1f78bbb3e146874501e3c52b56cff6abf731842",
                "title": "Deep representation learning: Fundamentals, Perspectives, Applications, and Open Challenges",
                "abstract": "Machine Learning algorithms have had a profound impact on the field of computer science over the past few decades. These algorithms performance is greatly influenced by the representations that are derived from the data in the learning process. The representations learned in a successful learning process should be concise, discrete, meaningful, and able to be applied across a variety of tasks. A recent effort has been directed toward developing Deep Learning models, which have proven to be particularly effective at capturing high-dimensional, non-linear, and multi-modal characteristics. In this work, we discuss the principles and developments that have been made in the process of learning representations, and converting them into desirable applications. In addition, for each framework or model, the key issues and open challenges, as well as the advantages, are examined.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "147190281",
                        "name": "K. T. Baghaei"
                    },
                    {
                        "authorId": "32989932",
                        "name": "A. Payandeh"
                    },
                    {
                        "authorId": "2150401440",
                        "name": "Pooya Fayyazsanavi"
                    },
                    {
                        "authorId": "2066329536",
                        "name": "Shahram Rahimi"
                    },
                    {
                        "authorId": "2211341",
                        "name": "Zhiqian Chen"
                    },
                    {
                        "authorId": "48149589",
                        "name": "Somayeh Bakhtiari Ramezani"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[6] illustrates that the different attention heads focus on different portions of the time series.",
                "Similarly, state-of-the-art approaches for crop-type classification using satellite image sequences were proposed using transformer encoder models [5], [6], [7]."
            ],
            "citingPaper": {
                "paperId": "70e924e07fa678bd0019b670fe39f349809e36c2",
                "externalIds": {
                    "ArXiv": "2210.13167",
                    "DBLP": "journals/corr/abs-2210-13167",
                    "DOI": "10.48550/arXiv.2210.13167",
                    "CorpusId": 253098518
                },
                "corpusId": 253098518,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/70e924e07fa678bd0019b670fe39f349809e36c2",
                "title": "Exploring Self-Attention for Crop-type Classification Explainability",
                "abstract": "Automated crop-type classification using Sentinel-2 satellite time series is essential to support agriculture monitoring. Recently, deep learning models based on transformer encoders became a promising approach for crop-type classification. Using explainable machine learning to reveal the inner workings of these models is an important step towards improving stakeholders' trust and efficient agriculture monitoring. In this paper, we introduce a novel explainability framework that aims to shed a light on the essential crop disambiguation patterns learned by a state-of-the-art transformer encoder model. More specifically, we process the attention weights of a trained transformer encoder to reveal the critical dates for crop disambiguation and use domain knowledge to uncover the phenological events that support the model performance. We also present a sensitivity analysis approach to understand better the attention capability for revealing crop-specific phenological events. We report compelling results showing that attention patterns strongly relate to key dates, and consequently, to the critical phenological events for crop-type classification. These findings might be relevant for improving stakeholder trust and optimizing agriculture monitoring processes. Additionally, our sensitivity analysis demonstrates the limitation of attention weights for identifying the important events in the crop phenology as we empirically show that the unveiled phenological events depend on the other crops in the data considered during training.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "19183479",
                        "name": "Ivica Obadic"
                    },
                    {
                        "authorId": "46525320",
                        "name": "R. Roscher"
                    },
                    {
                        "authorId": "34475405",
                        "name": "Dario Augusto Borges Oliveira"
                    },
                    {
                        "authorId": "2125159330",
                        "name": "Xiao Xiang Zhu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "In the Attn column: T = Transformer, P = PSE-TAE (Garnot et al., 2020) and a tick indicates any other transformer-like attention.",
                "The main other attention method used is a model called Pixel-Set Encoder and Temporal Attention Encoder (PSE-TAE) (Garnot et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "8825ee86500feb8e92a22510d1b53dee283f2b6a",
                "externalIds": {
                    "ArXiv": "2210.01272",
                    "DBLP": "journals/corr/abs-2210-01272",
                    "DOI": "10.48550/arXiv.2210.01272",
                    "CorpusId": 252693403
                },
                "corpusId": 252693403,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8825ee86500feb8e92a22510d1b53dee283f2b6a",
                "title": "A systematic review of the use of Deep Learning in Satellite Imagery for Agriculture",
                "abstract": "Agricultural research is essential for increasing food production to meet the requirements of an increasing population in the coming decades. Recently, satellite technology has been improving rapidly and deep learning has seen much success in generic computer vision tasks and many application areas which presents an important opportunity to improve analysis of agricultural land. Here we present a systematic review of 150 studies to find the current uses of deep learning on satellite imagery for agricultural research. Although we identify 5 categories of agricultural monitoring tasks, the majority of the research interest is in crop segmentation and yield prediction. We found that, when used, modern deep learning methods consistently outperformed traditional machine learning across most tasks; the only exception was that Long Short-Term Memory (LSTM) Recurrent Neural Networks did not consistently outperform Random Forests (RF) for yield prediction. The reviewed studies have largely adopted methodologies from generic computer vision, except for one major omission: benchmark datasets are not utilised to evaluate models across studies, making it difficult to compare results. Additionally, some studies have specifically utilised the extra spectral resolution available in satellite imagery, but other divergent properties of satellite images - such as the hugely different scales of spatial patterns - are not being taken advantage of in the reviewed studies.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "38689120",
                        "name": "Brandon Victor"
                    },
                    {
                        "authorId": "2109504322",
                        "name": "Zhen He"
                    },
                    {
                        "authorId": "2280644",
                        "name": "Aiden Nibali"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "We propose that unlike the previous works that build methods on arbitrary sequence lengths [3,8,14,15,19,23] we need some \u2018standards\u2019 for driving a solution to become more robust, trustworthy and logically correct instead of being data hungry.",
                "[15] Vivien Sainte Fare Garnot, Loic Landrieu, Sebastien Giordano, and Nesrine Chehata.",
                "Tasks [23] [8] [3] [15] [14] [19] SICKLE"
            ],
            "citingPaper": {
                "paperId": "a009bd32a742d12fd59b1d55228183dd3c05fbfa",
                "externalIds": {
                    "ArXiv": "2209.12238",
                    "DBLP": "journals/corr/abs-2209-12238",
                    "DOI": "10.48550/arXiv.2209.12238",
                    "CorpusId": 252531945
                },
                "corpusId": 252531945,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a009bd32a742d12fd59b1d55228183dd3c05fbfa",
                "title": "High-Resolution Satellite Imagery for Modeling the Impact of Aridification on Crop Production",
                "abstract": "The availability of well-curated datasets has driven the success of Machine Learning (ML) models. Despite the increased access to earth observation data for agriculture, there is a scarcity of curated, labelled datasets, which limits the potential of its use in training ML models for remote sensing (RS) in agriculture. To this end, we introduce a first-of-its-kind dataset, SICKLE, having time-series images at different spatial resolutions from 3 different satellites, annotated with multiple key cropping parameters for paddy cultivation for the Cauvery Delta region in Tamil Nadu, India. The dataset comprises of 2,398 season-wise samples from 388 unique plots distributed across 4 districts of the Delta. The dataset covers multi-spectral, thermal and microwave data between the time period January 2018-March 2021. The paddy samples are annotated with 4 key cropping parameters, i.e. sowing date, transplanting date, harvesting date and crop yield. This is one of the first studies to consider the growing season (using sowing and harvesting dates) as part of a dataset. We also propose a yield prediction strategy that uses time-series data generated based on the observed growing season and the standard seasonal information obtained from Tamil Nadu Agricultural University for the region. The consequent performance improvement highlights the impact of ML techniques that leverage domain knowledge that are consistent with standard practices followed by farmers in a specific region. We benchmark the dataset on 3 separate tasks, namely crop type, phenology date (sowing, transplanting, harvesting) and yield prediction, and develop an end-to-end framework for predicting key crop parameters in a real-world setting.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "113950386",
                        "name": "Depanshu Sani"
                    },
                    {
                        "authorId": "2067375696",
                        "name": "S. Mahato"
                    },
                    {
                        "authorId": "2164339336",
                        "name": "Parichya Sirohi"
                    },
                    {
                        "authorId": "2055636486",
                        "name": "S. Anand"
                    },
                    {
                        "authorId": "2064973683",
                        "name": "G. Arora"
                    },
                    {
                        "authorId": "2164340233",
                        "name": "Charu Chandra Devshali"
                    },
                    {
                        "authorId": "144927078",
                        "name": "T. Jayaraman"
                    },
                    {
                        "authorId": "2153342635",
                        "name": "Harshvardhan Agarwal"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "b642938b60fe179abcfffe3439d4927a07224818",
                "externalIds": {
                    "DBLP": "conf/ist/StergioulasDG22",
                    "DOI": "10.1109/ist55454.2022.9827752",
                    "CorpusId": 250937400
                },
                "corpusId": 250937400,
                "publicationVenue": {
                    "id": "cf19dde3-83c7-473f-8665-fa746cdf7ae0",
                    "name": "International Symposium on Telecommunications",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Imaging Syst Tech",
                        "SBT/IEEE International Symposium on Telecommunications",
                        "IST",
                        "SBT/IEEE Int Symp Telecommun",
                        "International Conference on Imaging Systems and Techniques",
                        "IEEE Int Workshop Imaging Syst Tech",
                        "Int Symp Telecommun",
                        "IEEE International Workshop on Imaging Systems and Techniques"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b642938b60fe179abcfffe3439d4927a07224818",
                "title": "Crop classification from satellite image sequences using a two-stream network with temporal self-attention",
                "abstract": "In recent years the availability of satellite image observations of Earth has been increasing, creating opportunities for automated methods to be applied in tasks with significant economic importance, such as agricultural parcel crop classification. Designing and implementing automated methods that can efficiently interpret satellite images and handle their temporal nature poses a significant challenge in remote sensing. Deep learning models have proven to be able to leverage these type of data, taking into consideration both their spatial as well as temporal nature. Building on a state-of-the-art architecture using self-attention to classify crops captured in satellite images time series, we introduce two changes in order to better capture the crop phenology. Specifically, the calculation of the self-attention Query is performed by a Temporal Convolutional Network (TCN), while the TCN output is also taken under consideration for the final classification. Moreover, we utilize the temporal differences between consecutive time steps to create an auxiliary time series that can be employed alongside the original time series, in a two-stream architecture, that proves to be capable of further improving performance. We also conduct a detailed ablation study to assess the impact of these contributions. The proposed model was able to produce results that exceed the state-of-the-art on the publicly available Sentinel2-Agri dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51919460",
                        "name": "Andreas Stergioulas"
                    },
                    {
                        "authorId": "2296506",
                        "name": "K. Dimitropoulos"
                    },
                    {
                        "authorId": "48603481",
                        "name": "N. Grammalidis"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "4eaeae300d84ab6d43e0ea7e28d9c1f76da2cd22",
                "externalIds": {
                    "DBLP": "journals/remotesensing/ZhangTHLZT22",
                    "DOI": "10.3390/rs14122778",
                    "CorpusId": 249654915
                },
                "corpusId": 249654915,
                "publicationVenue": {
                    "id": "8e1bd4b5-d5b2-4e22-ba0a-01fe5568d472",
                    "name": "Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens"
                    ],
                    "issn": "2315-4675",
                    "alternate_issns": [
                        "2072-4292"
                    ],
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-169233",
                    "alternate_urls": [
                        "https://www.mdpi.com/journal/remotesensing",
                        "http://www.mdpi.com/journal/remotesensing",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-169233"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4eaeae300d84ab6d43e0ea7e28d9c1f76da2cd22",
                "title": "Seeded Classification of Satellite Image Time Series with Lower-Bounded Dynamic Time Warping",
                "abstract": "Satellite Image Time Series (SITS) record the continuous temporal behavior of land cover types and thus provide a new perspective for finer-grained land cover classification compared with the usual spectral and spatial information contained in a static image. In addition, SITS data is becoming more accessible in recent years due to newly launched satellites and accumulated historical data. However, the lack of labeled training samples limits the exploration of SITS data, especially with sophisticated methods. Even with a straightforward classifier, such as k-nearest neighbor, the accuracy and efficiency of the SITS similarity measure is also a pending problem. In this paper, we propose SKNN-LB-DTW, a seeded SITS classification method based on lower-bounded Dynamic Time Warping (DTW). The word \u201cseeded\u201d indicates that only a few labeled samples are required, and this is not only because of the lack of labeled samples but also because of our aim to explore the rich information contained in SITS, rather than letting training samples dominate the classification results. We use a combination of cascading lower bounds and early abandoning of DTW as an accurate yet efficient similarity measure for large scale tasks. The experimental results on two real SITS datasets demonstrate the utility of the proposed SKNN-LB-DTW, which could become an effective solution for SITS classification when the amount of unlabeled SITS data far exceeds the labeled data.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2148905158",
                        "name": "Zheng Zhang"
                    },
                    {
                        "authorId": "91436383",
                        "name": "Ping Tang"
                    },
                    {
                        "authorId": "9163487",
                        "name": "Changmiao Hu"
                    },
                    {
                        "authorId": "2109075280",
                        "name": "Zhiqiang Liu"
                    },
                    {
                        "authorId": "2154764512",
                        "name": "Weixiong Zhang"
                    },
                    {
                        "authorId": "2153720629",
                        "name": "L. Tang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "In this work, we decided to follow (PSE + TAE) (Sainte-Fare Garnot et al., 2020) and (PSE+LTAE) (Sainte-Fare Garnot et Landrieu, 2020) approaches since they are well suited to classify satellite image time series and map land cover in agricultural environments while using far fewer parameters and\u2026",
                "In 2020, (Sainte-Fare Garnot et al., 2020) presented a new lightweight network for embedding sequences of observations such as satellite time-series.",
                "The motivation behind this design is that, instead of textural information (that is not relevant on S-2 imagery), the network computes learned statistical descriptors of the spectral distribution of the parcel\u2019s observations (Sainte-Fare Garnot et al., 2020).",
                "However, the scientific publications suggest that convolutions may not be as suitable for analysing high-resolution satellite images of agricultural plots such as Sentinel images (Sainte-Fare Garnot et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "e0a7ba2226c76a672c528b176e8dd07262500119",
                "externalIds": {
                    "DOI": "10.5194/isprs-archives-xliii-b3-2022-899-2022",
                    "CorpusId": 249256235
                },
                "corpusId": 249256235,
                "publicationVenue": {
                    "id": "4ab1e1bf-98e8-4e0c-a53a-7a00e37e44e2",
                    "name": "The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences",
                    "type": "journal",
                    "alternate_names": [
                        "Int Arch Photogramm Remote Sens Spat Inf Sci"
                    ],
                    "issn": "1682-1750",
                    "url": "https://www.isprs.org/publications/archives.aspx"
                },
                "url": "https://www.semanticscholar.org/paper/e0a7ba2226c76a672c528b176e8dd07262500119",
                "title": "FEW SHOT CROP MAPPING USING TRANSFORMERS AND TRANSFER LEARNING WITH SENTINEL-2 TIME SERIES: CASE OF KAIROUAN TUNISIA",
                "abstract": "Abstract. In this paper, we present an approach to land cover mapping from Sentinel-2 (S-2) satellite image time series using deep learning methods in the context of few shots in agricultural areas which aims to learn a classifier to recognize unseen classes during training with limited labelled examples. In many countries, there is a lack of Land Parcel Information Systems (LPIS) and thus of agricultural crop type annotations. Annotations are still based on fastidious digitization of parcels and in-field observations that are available in few numbers. Our idea is to transfer learning from pre-trained models on existing LPIS in France and apply them to a different geographical area in Kairouan in Central Tunisia. We build on work employing multi-headed self-attention mechanisms that have contributed to results that outperform other deep learning algorithms such as convolutional neural networks (CNNs), recurrent neural networks (RNNs) in agricultural context using S-2 Time series. We used two transformer-based deep learning models PSE-TAE (Pixel-Set Encoders + Temporal Self-Attention) and PSE-LTAE (Pixel-Set Encoders + Lightweight Temporal Self-Attention). We first studied their generalisation capacity in a few shot context and on different geographical study site. Then, by transferring the knowledge of these models and adapting them to the Tunisian context with the transfer learning techniques we have demonstrated experimentally that the adaptation of these methods is efficient for land cover mapping in agricultural areas with few in-field observations in terms of accuracy with an overall accuracy for both models reaching almost 93% for a detailed classification level with 17 classes.\n",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2167398749",
                        "name": "M. K. Keraani"
                    },
                    {
                        "authorId": "104846661",
                        "name": "K. Mansour"
                    },
                    {
                        "authorId": "2167400270",
                        "name": "B. Khlaifia"
                    },
                    {
                        "authorId": "2710204",
                        "name": "N. Chehata"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "We adopted the PSE-TAE architecture [Sainte Fare Garnot et al., 2020] to utilize the spatio-temporal resolution of the satellites."
            ],
            "citingPaper": {
                "paperId": "109f6816383a35cb1916f69f112d795237a3a6fa",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-03104",
                    "ArXiv": "2205.03104",
                    "DOI": "10.48550/arXiv.2205.03104",
                    "CorpusId": 248562536
                },
                "corpusId": 248562536,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/109f6816383a35cb1916f69f112d795237a3a6fa",
                "title": "Crop Type Identification for Smallholding Farms: Analyzing Spatial, Temporal and Spectral Resolutions in Satellite Imagery",
                "abstract": "The integration of the modern Machine Learning (ML) models into remote sensing and agriculture has expanded the scope of the application of satellite images in the agriculture domain. In this paper, we present how the accuracy of crop type identification improves as we move from medium-spatiotemporal-resolution (MSTR) to high-spatiotemporal-resolution (HSTR) satellite images. We further demonstrate that high spectral resolution in satellite imagery can improve prediction performance for low spatial and temporal resolutions (LSTR) images. The F1-score is increased by 7% when using multispectral data of MSTR images as compared to the best results obtained from HSTR images. Similarly, when crop season based time series of multispectral data is used we observe an increase of 1.2% in the F1-score. The outcome motivates further advancements in the field of synthetic band generation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "113950386",
                        "name": "Depanshu Sani"
                    },
                    {
                        "authorId": "2067375696",
                        "name": "S. Mahato"
                    },
                    {
                        "authorId": "2164339336",
                        "name": "Parichya Sirohi"
                    },
                    {
                        "authorId": "2055636486",
                        "name": "S. Anand"
                    },
                    {
                        "authorId": "2064973683",
                        "name": "G. Arora"
                    },
                    {
                        "authorId": "2164340233",
                        "name": "Charu Chandra Devshali"
                    },
                    {
                        "authorId": "2164339383",
                        "name": "T. Jayaraman"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "In light of this limitation, a series of alternative methodologies have been proposed, including ensemble methods [51], methods derived from statistical analysis [1], pixel-set encoders with temporal attention encoders [37, 5], self-attention with positional encoding [20], and most notably for this paper, CNNs that incorporate the temporal channel [3, 39].",
                "Two recent papers that introduced Transformer models for SITS classification [5, 37] were shown to outperform the Temporal CNN model of Pelletier et al.",
                "Transformers PSAE+TAE [5], PSE + LTAE [37], Transformer [20], Informer [48], GL-TAE [49] \u2022 Utilise mechanisms such as self-attention combined with positional encoding [20] or pixel set-encoders to encode the spatial context of the data in collaboration with a temporal attention encoder to encode the temporal relations between observations [5, 37].",
                "RNNs, even with contemporary components such as GRUs still have much longer processing times than Temporal CNNs, in general, [5].",
                "Whilst additional features are valuable for land-cover classification tasks, it consequently reduces the interpretability of the data and typically enlarges their volume [5].",
                "Recurrent Neural Networks are regularly used as a comparative baseline within deep learning research for time series classification [5, 57].",
                "Transformers have previously been cited as being faster than convolutional and recurrent-based models [33, 5], but in the case of this dataset, the Transformer was the second slowest model."
            ],
            "citingPaper": {
                "paperId": "0a876a03256a3a804e4dbc0adf4fc95b7fbb177d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-08461",
                    "ArXiv": "2204.08461",
                    "DOI": "10.48550/arXiv.2204.08461",
                    "CorpusId": 248240039
                },
                "corpusId": 248240039,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0a876a03256a3a804e4dbc0adf4fc95b7fbb177d",
                "title": "Investigating Temporal Convolutional Neural Networks for Satellite Image Time Series Classification",
                "abstract": "Satellite Image Time Series (SITS) of the Earth's surface provide detailed land cover maps, with their quality in the spatial and temporal dimensions consistently improving. These image time series are integral for developing systems that aim to produce accurate, up-to-date land cover maps of the Earth's surface. Applications are wide-ranging, with notable examples including ecosystem mapping, vegetation process monitoring and anthropogenic land-use change tracking. Recently proposed methods for SITS classification have demonstrated respectable merit, but these methods tend to lack native mechanisms that exploit the temporal dimension of the data; commonly resulting in extensive data pre-processing contributing to prohibitively long training times. To overcome these shortcomings, Temporal CNNs have recently been employed for SITS classification tasks with encouraging results. This paper seeks to survey this method against a plethora of other contemporary methods for SITS classification to validate the existing findings in recent literature. Comprehensive experiments are carried out on two benchmark SITS datasets with the results demonstrating that Temporal CNNs display a superior performance to the comparative benchmark algorithms across both studied datasets, achieving accuracies of 95.0\\% and 87.3\\% respectively. Investigations into the Temporal CNN architecture also highlighted the non-trivial task of optimising the model for a new dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2059790506",
                        "name": "James Brock"
                    },
                    {
                        "authorId": "3323364",
                        "name": "Z. Abdallah"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "The Transformer was also explored by [29] in a pipeline which includes three Multilayer Perceptrons (MLPs) for feature extraction and final classification.",
                "A method published recently in [54] additionally accounts for the phenology shift observed for a single crop between different geographical regions and with a time shift estimation procedure and a semi-supervised learning scheme it manages to boost the performance of the model proposed in [29]."
            ],
            "citingPaper": {
                "paperId": "07897cf16fac3a4fb3064d6c8b26bbcee1dcd38d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-00951",
                    "ArXiv": "2204.00951",
                    "DOI": "10.48550/arXiv.2204.00951",
                    "CorpusId": 247940132
                },
                "corpusId": 247940132,
                "publicationVenue": {
                    "id": "849b6687-df71-4d12-9c46-59f45d5ce951",
                    "name": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE J Sel Top Appl Earth Obs Remote Sens"
                    ],
                    "issn": "1939-1404",
                    "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=4609443",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4609443"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/07897cf16fac3a4fb3064d6c8b26bbcee1dcd38d",
                "title": "A Sentinel-2 Multiyear, Multicountry Benchmark Dataset for Crop Classification and Segmentation With Deep Learning",
                "abstract": "In this work, we introduce Sen4AgriNet, a Sentinel-2-based time series multicountry benchmark dataset, tailored for agricultural monitoring applications with machine and deep learning. Sen4AgriNet dataset is annotated from farmer declarations collected via the land parcel identification system (LPIS) for harmonizing country-wide labels. These declarations have only recently been made available as open data, allowing for the first time the labeling of satellite imagery from ground truth data. We proceed to propose and standardize a new crop type taxonomy across Europe that addresses common agriculture policy (CAP) needs, based on the Food and Agriculture Organization (FAO) indicative crop classification scheme. Sen4AgriNet is the only multicountry, multiyear dataset that includes all spectral information. It is constructed to cover the period 2016\u20132020 for Catalonia and France, while it can be extended to include additional countries. Currently, it contains 42.5 million parcels, which makes it significantly larger than other available archives. We extract two subdatasets to highlight its value for diverse deep learning applications\u2014the object aggregated dataset (OAD) and the patches assembled dataset (PAD). OAD capitalizes zonal statistics of each parcel, thus creating a powerful label-to-features instance for classification algorithms. On the other hand, PAD structure generalizes the classification problem to parcel extraction and semantic segmentation and labeling. The PAD and OAD are examined under three different scenarios to showcase and model the effects of spatial and temporal variability across different years and different countries.1",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2370934",
                        "name": "Dimitrios Sykas"
                    },
                    {
                        "authorId": "88813534",
                        "name": "Maria Sdraka"
                    },
                    {
                        "authorId": "2132515325",
                        "name": "Dimitrios Zografakis"
                    },
                    {
                        "authorId": "49032213",
                        "name": "I. Papoutsis"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", the Pixel-Set spatial and the self-attention temporal encoders [11,12].",
                "Consequently, the researchers have proposed to use Pixel-Set Encoder [12] to obtain learnable statistical descriptors, which is inspired by advances in 3D point cloud processing [33].",
                "Along this line of research, recent work [12] has pointed out that convolutions are not well-suited for extracting spatial features from satellite data for crop classification due to the highly irregular boundaries of parcel fields and limited texture patterns available."
            ],
            "citingPaper": {
                "paperId": "1b848fd6aa67fb10166ba25814409d95a4b0455e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-16149",
                    "ArXiv": "2203.16149",
                    "DOI": "10.48550/arXiv.2203.16149",
                    "CorpusId": 247793981
                },
                "corpusId": 247793981,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1b848fd6aa67fb10166ba25814409d95a4b0455e",
                "title": "Tampered VAE for Improved Satellite Image Time Series Classification",
                "abstract": "The unprecedented availability of spatial and temporal high-resolution satellite image time series (SITS) for crop type mapping is believed to necessitate deep learning architectures to accommodate challenges arising from both dimensions. Recent state-of-the-art deep learning models have shown promising results by stacking spatial and temporal encoders. However, we present a Pyramid Time-Series Transformer (PTST) that operates solely on the temporal dimension, i.e., neglecting the spatial dimension, can produce superior results with a drastic reduction in GPU memory consumption and easy extensibility. Furthermore, we augment it to perform semi-supervised learning by proposing a classification-friendly VAE framework that introduces clustering mechanisms into latent space and can promote linear separability therein. Consequently, a few principal axes of the latent space can explain the majority of variance in raw data. Meanwhile, the VAE framework with proposed tweaks can maintain competitive classification performance as its purely discriminative counterpart when only $40\\%$ of labelled data is used. We hope the proposed framework can serve as a baseline for crop classification with SITS for its modularity and simplicity.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "101374725",
                        "name": "Xin Cai"
                    },
                    {
                        "authorId": "145208564",
                        "name": "Y. Bi"
                    },
                    {
                        "authorId": "153680862",
                        "name": "Peter Nicholl"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "Notably, state-of-theart methods based on self-attention input calendar time via positional encoding [6, 42].",
                "In particular, for each time step t, we concatenate GDD(t) to the intermediate PSE embedding e\u0302(t) before the final PSE output layer MLP2:\ne(t) = MLP2([e\u0302 (t) || GDD(t)]), (3)\nwhere [\u00b7 || \u00b7] indicates concatenation.",
                "Recently, self-attention [52] has led to significant improvements in pixel [40] and parcel classification [41, 42], as well as semantic and panoptic segmentation [6].",
                "The PSE output layer MLP2 [42] is a multi-layer perceptron (MLP) consisting of a linear layer, batch normalization [14], and ReLU [30] activation function."
            ],
            "citingPaper": {
                "paperId": "2b7b7eb96fc30089d53e92ad97ac2db0035dc3cb",
                "externalIds": {
                    "DBLP": "conf/cvpr/NyborgPA22",
                    "ArXiv": "2203.09175",
                    "DOI": "10.1109/CVPRW56347.2022.00145",
                    "CorpusId": 247519069
                },
                "corpusId": 247519069,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2b7b7eb96fc30089d53e92ad97ac2db0035dc3cb",
                "title": "Generalized Classification of Satellite Image Time Series with Thermal Positional Encoding",
                "abstract": "Large-scale crop type classification is a task at the core of remote sensing efforts with applications of both economic and ecological importance. Current state-of-the-art deep learning methods are based on self-attention and use satellite image time series (SITS) to discriminate crop types based on their unique growth patterns. However, existing methods generalize poorly to regions not seen during training mainly due to not being robust to temporal shifts of the growing season caused by variations in climate. To this end, we propose Thermal Positional Encoding (TPE) for attention-based crop classifiers. Unlike previous positional encoding based on calendar time (e.g. day-of-year), TPE is based on thermal time, which is obtained by accumulating daily average temperatures over the growing season. Since crop growth is directly related to thermal time, but not calendar time, TPE addresses the temporal shifts between different regions to improve generalization. We propose multiple TPE strategies, including learnable methods, to further improve results compared to the common fixed positional encodings. We demonstrate our approach on a crop classification task across four different European regions, where we obtain state-of-the-art generalization results. Our source code is available at https://github.com/jnyborg/tpe.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2122273256",
                        "name": "Joachim Nyborg"
                    },
                    {
                        "authorId": "46354194",
                        "name": "Charlotte Pelletier"
                    },
                    {
                        "authorId": "1713664",
                        "name": "I. Assent"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "436a2dc4ff745f698eaa654262b1b66b51886e30",
                "externalIds": {
                    "ArXiv": "2203.06041",
                    "DBLP": "journals/corr/abs-2203-06041",
                    "DOI": "10.48550/arXiv.2203.06041",
                    "CorpusId": 247411448
                },
                "corpusId": 247411448,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/436a2dc4ff745f698eaa654262b1b66b51886e30",
                "title": "Embedding Earth: Self-supervised contrastive pre-training for dense land cover classification",
                "abstract": "In training machine learning models for land cover semantic segmentation there is a stark contrast between the availability of satellite imagery to be used as inputs and ground truth data to enable supervised learning. While thousands of new satellite images become freely available on a daily basis, getting ground truth data is still very challenging, time consuming and costly. In this paper we present Embedding Earth a self-supervised contrastive pre-training method for leveraging the large availability of satellite imagery to improve performance on downstream dense land cover classification tasks. Performing an extensive experimental evaluation spanning four countries and two continents we use models pre-trained with our proposed method as initialization points for supervised land cover semantic segmentation and observe significant improvements up to 25% absolute mIoU. In every case tested we outperform random initialization, especially so when ground truth data are scarse. Through a series of ablation studies we explore the qualities of the proposed approach and find that learnt features can generalize between disparate regions opening up the possibility of using the proposed pre-training scheme as a replacement to random initialization for Earth observation tasks. Code will be uploaded soon at https://github.com/michaeltrs/DeepSatModels.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "102361656",
                        "name": "Michail Tarasiou"
                    },
                    {
                        "authorId": "1776444",
                        "name": "S. Zafeiriou"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "6da6e2d223d9d69362ae50e4da3f880aaaf2687c",
                "externalIds": {
                    "DBLP": "journals/remotesensing/NeynsC22",
                    "DOI": "10.3390/rs14041031",
                    "CorpusId": 247070048
                },
                "corpusId": 247070048,
                "publicationVenue": {
                    "id": "8e1bd4b5-d5b2-4e22-ba0a-01fe5568d472",
                    "name": "Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens"
                    ],
                    "issn": "2315-4675",
                    "alternate_issns": [
                        "2072-4292"
                    ],
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-169233",
                    "alternate_urls": [
                        "https://www.mdpi.com/journal/remotesensing",
                        "http://www.mdpi.com/journal/remotesensing",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-169233"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6da6e2d223d9d69362ae50e4da3f880aaaf2687c",
                "title": "Mapping of Urban Vegetation with High-Resolution Remote Sensing: A Review",
                "abstract": "Green space is increasingly recognized as an important component of the urban environment. Adequate management and planning of urban green space is crucial to maximize its benefits for urban inhabitants and for the urban ecosystem in general. Inventorying urban vegetation is a costly and time-consuming process. The development of new remote sensing techniques to map and monitor vegetation has therefore become an important topic of interest to many scholars. Based on a comprehensive survey of the literature, this review article provides an overview of the main approaches proposed to map urban vegetation from high-resolution remotely sensed data. Studies are reviewed from three perspectives: (a) the vegetation typology, (b) the remote sensing data used and (c) the mapping approach applied. With regard to vegetation typology, a distinction is made between studies focusing on the mapping of functional vegetation types and studies performing mapping of lower-level taxonomic ranks, with the latter mainly focusing on urban trees. A wide variety of high-resolution imagery has been used by researchers for both types of mapping. The fusion of various types of remote sensing data, as well as the inclusion of phenological information through the use of multi-temporal imagery, prove to be the most promising avenues to improve mapping accuracy. With regard to mapping approaches, the use of deep learning is becoming more established, mostly for the mapping of tree species. Through this survey, several research gaps could be identified. Interest in the mapping of non-tree species in urban environments is still limited. The same holds for the mapping of understory species. Most studies focus on the mapping of public green spaces, while interest in the mapping of private green space is less common. The use of imagery with a high spatial and temporal resolution, enabling the retrieval of phenological information for mapping and monitoring vegetation at the species level, still proves to be limited in urban contexts. Hence, mapping approaches specifically tailored towards time-series analysis and the use of new data sources seem to hold great promise for advancing the field. Finally, unsupervised learning techniques and active learning, so far rarely applied in urban vegetation mapping, are also areas where significant progress can be expected.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2054375371",
                        "name": "Robbe Neyns"
                    },
                    {
                        "authorId": "2532094",
                        "name": "F. Canters"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "The work in [54] combines pixel-set encoder"
            ],
            "citingPaper": {
                "paperId": "e0caf76a6a9258638041314c3bf831157a09ad5b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-11367",
                    "ArXiv": "2112.11367",
                    "CorpusId": 245353876
                },
                "corpusId": 245353876,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e0caf76a6a9258638041314c3bf831157a09ad5b",
                "title": "Deep Learning and Earth Observation to Support the Sustainable Development Goals",
                "abstract": "The synergistic combination of deep learning models and Earth observation promises significant advances to support the sustainable development goals (SDGs). New developments and a plethora of applications are already changing the way humanity will face the living planet challenges. This paper reviews current deep learning approaches for Earth observation data, along with their application towards monitoring and achieving the SDGs most impacted by the rapid development of deep learning in Earth observation. We systematically review case studies to 1) achieve zero hunger, 2) sustainable cities, 3) deliver tenure security, 4) mitigate and adapt to climate change, and 5) preserve biodiversity. Important societal, economic and environmental implications are concerned. Exciting times ahead are coming where algorithms and Earth data can help in our endeavor to address the climate crisis and support more sustainable development.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2530636",
                        "name": "C. Persello"
                    },
                    {
                        "authorId": "1753678",
                        "name": "J. D. Wegner"
                    },
                    {
                        "authorId": "34696928",
                        "name": "R. H\u00e4nsch"
                    },
                    {
                        "authorId": "2977931",
                        "name": "D. Tuia"
                    },
                    {
                        "authorId": "2370080",
                        "name": "Pedram Ghamisi"
                    },
                    {
                        "authorId": "38529222",
                        "name": "M. Koeva"
                    },
                    {
                        "authorId": "1397959153",
                        "name": "Gustau Camps-Valls"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "\u2026Encoder (PSE) and Lightweight Temporal Attention Encoder (L-TAE), whose accuracy and computational efficiency have been solidified in recent studies (Schneider and K\u00f6rner, 2020; Kondmann et al., 2021; Garnot and Landrieu, 2020; Garnot et al., 2020), and whose implementations are available."
            ],
            "citingPaper": {
                "paperId": "97d2e207b098ae309c3e3002253d659b1476b7c7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-07558",
                    "ArXiv": "2112.07558",
                    "DOI": "10.1016/j.isprsjprs.2022.03.012",
                    "CorpusId": 245131590
                },
                "corpusId": 245131590,
                "publicationVenue": {
                    "id": "227fb221-5e57-477c-b756-e39dd8ffd538",
                    "name": "Isprs Journal of Photogrammetry and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Isprs J Photogramm Remote Sens"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/97d2e207b098ae309c3e3002253d659b1476b7c7",
                "title": "Multi-Modal Temporal Attention Models for Crop Mapping from Satellite Time Series",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "67228021",
                        "name": "Vivien Sainte Fare Garnot"
                    },
                    {
                        "authorId": "115987954",
                        "name": "Loic Landrieu"
                    },
                    {
                        "authorId": "2710204",
                        "name": "N. Chehata"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "c15e96abeb12652b641a314a94510d1ced06ebf6",
                "externalIds": {
                    "PubMedCentral": "8708901",
                    "DBLP": "journals/sensors/GarbougeRR21",
                    "DOI": "10.3390/s21248425",
                    "CorpusId": 245375358,
                    "PubMed": "34960519"
                },
                "corpusId": 245375358,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c15e96abeb12652b641a314a94510d1ced06ebf6",
                "title": "Enhancing the Tracking of Seedling Growth Using RGB-Depth Fusion and Deep Learning",
                "abstract": "The use of high-throughput phenotyping with imaging and machine learning to monitor seedling growth is a tough yet intriguing subject in plant research. This has been recently addressed with low-cost RGB imaging sensors and deep learning during day time. RGB-Depth imaging devices are also accessible at low-cost and this opens opportunities to extend the monitoring of seedling during days and nights. In this article, we investigate the added value to fuse RGB imaging with depth imaging for this task of seedling growth stage monitoring. We propose a deep learning architecture along with RGB-Depth fusion to categorize the three first stages of seedling growth. Results show an average performance improvement of 5% correct recognition rate by comparison with the sole use of RGB images during the day. The best performances are obtained with the early fusion of RGB and Depth. Also, Depth is shown to enable the detection of growth stage in the absence of the light.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1478147234",
                        "name": "H. Garbouge"
                    },
                    {
                        "authorId": "2303909",
                        "name": "P. Rasti"
                    },
                    {
                        "authorId": "2138643698",
                        "name": "D. Rousseau"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "As in [43], the number of randomly sampled pixels per parcel in the PSE module is set to 64, and the dropout rate (used in TAE) is set to 0.",
                "In [43], a modified self-attention-based mechanism architecture, namely pixel-set encoder\u2013temporal-attention encoder (PSE-TAE), extracts more expressive features than CNNs and GRUs.",
                "To explore different fusion strategies, we adopted pixel set encoder\u2013temporal attention encoder (PSE\u2013TAE) [43] as the deep learning architecture over existing supervised learning algorithms dedicated to SITS classification.",
                "Recently, attention-based architectures have been proposed for the SITS classification in the context of crop type mapping [22,43].",
                "We adapt and extend the original GitHub implementation of the PSE-TAE [43] to (i) accommodate multi-sensor inputs and (ii) design the different fusion strategies."
            ],
            "citingPaper": {
                "paperId": "38192d2855276defad44c7a766db6ce8accd0e0d",
                "externalIds": {
                    "DBLP": "journals/remotesensing/Ofori-AmpofoPL21",
                    "DOI": "10.3390/rs13224668",
                    "CorpusId": 244431871
                },
                "corpusId": 244431871,
                "publicationVenue": {
                    "id": "8e1bd4b5-d5b2-4e22-ba0a-01fe5568d472",
                    "name": "Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens"
                    ],
                    "issn": "2315-4675",
                    "alternate_issns": [
                        "2072-4292"
                    ],
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-169233",
                    "alternate_urls": [
                        "https://www.mdpi.com/journal/remotesensing",
                        "http://www.mdpi.com/journal/remotesensing",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-169233"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/38192d2855276defad44c7a766db6ce8accd0e0d",
                "title": "Crop Type Mapping from Optical and Radar Time Series Using Attention-Based Deep Learning",
                "abstract": "Crop maps are key inputs for crop inventory production and yield estimation and can inform the implementation of effective farm management practices. Producing these maps at detailed scales requires exhaustive field surveys that can be laborious, time-consuming, and expensive to replicate. With a growing archive of remote sensing data, there are enormous opportunities to exploit dense satellite image time series (SITS), temporal sequences of images over the same area. Generally, crop type mapping relies on single-sensor inputs and is solved with the help of traditional learning algorithms such as random forests or support vector machines. Nowadays, deep learning techniques have brought significant improvements by leveraging information in both spatial and temporal dimensions, which are relevant in crop studies. The concurrent availability of Sentinel-1 (synthetic aperture radar) and Sentinel-2 (optical) data offers a great opportunity to utilize them jointly; however, optimizing their synergy has been understudied with deep learning techniques. In this work, we analyze and compare three fusion strategies (input, layer, and decision levels) to identify the best strategy that optimizes optical-radar classification performance. They are applied to a recent architecture, notably, the pixel-set encoder\u2013temporal attention encoder (PSE-TAE) developed specifically for object-based classification of SITS and based on self-attention mechanisms. Experiments are carried out in Brittany, in the northwest of France, with Sentinel-1 and Sentinel-2 time series. Input and layer-level fusion competitively achieved the best overall F-score surpassing decision-level fusion by 2%. On a per-class basis, decision-level fusion increased the accuracy of dominant classes, whereas layer-level fusion improves up to 13% for minority classes. Against single-sensor baseline, multi-sensor fusion strategies identified crop types more accurately: for example, input-level outperformed Sentinel-2 and Sentinel-1 by 3% and 9% in F-score, respectively. We have also conducted experiments that showed the importance of fusion for early time series classification and under high cloud cover condition.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2023580259",
                        "name": "S. Ofori-Ampofo"
                    },
                    {
                        "authorId": "46354194",
                        "name": "Charlotte Pelletier"
                    },
                    {
                        "authorId": "2149915926",
                        "name": "S. Lang"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "It improves the accuracy and computational efficiency compared to the original TAE (Sainte Fare Garnot et al., 2020) by a channel grouping strategy and a learnable master query.",
                "For domain-invariant methods, we align the LTAE feature vector input to the final classifier ( i.e. , o i in Fig.",
                "The network consists of two modules: the pixel-set encoder (PSE) and the lightweight temporal attention encoder (LTAE).",
                "We reproduce these methods for SITS by replacing the original feature extractor with PSE + LTAE.",
                "Overview of the PSE + LTAE model (Sainte Fare Garnot et al., 2020; Sainte Fare Garnot and Landrieu, 2020).",
                "Our implementation is based on the source code of PSE + LTAE (Sainte Fare Garnot and Land-rieu, 2020).",
                "It improves the accuracy and computational efficiency compared to the original TAE [12] by a channel grouping strategy and a learnable master query.",
                "If this is not available, TimeMatch may instead be applied for pixel-based classification by inputting single pixels ( S = 1) to PSE + LTAE.",
                "We consider the following baseline methods: \u2022 Source-Trained is PSE + LTAE trained on the source domain and applied to the target domain without domain adaptation.",
                "To initialize models on the labeled source domain, we follow the original training approach of PSE+LTAE [12].",
                "To initialize models on the labeled source domain, we follow the original training approach of PSE + LTAE (Sainte Fare Garnot et al., 2020).",
                "As model, we use the existing object-based crop classifier PSE + LTAE introduced by Sainte Fare Garnot et al. (2020), Sainte Fare Garnot and Landrieu (2020).",
                "As an alternative, we include the MMD comparison, which is similar to PAN, except the crop classifier is changed to PSE + LTAE.",
                "The result is temporally processed by LTAE to a single embedding o i which is then passed to the classifier.",
                "Recently, the increasing availability of SITS along with advances in deep learning has led to crop classifiers with temporal neural architectures using convolutions [5, 6], recurrent units [7\u201310], self-attention [11, 12], or combinations thereof [13, 14].",
                "Thus, the only difference between VRADA, CoDATS, and the DANN approach mentioned here is the backbone architecture, which in our case is the temporal model PSE + LTAE.",
                "\u2022 Target-Trained is PSE + LTAE trained with labeled target data using the same classes as the source-trained.",
                "The additional input \u03c4 i is input to LTAE by encoding the days with sinusoidal positional encoding (Vaswani et al., 2017) and adding the result to the output of PSE.",
                "Figure 3: Overview of the PSE+LTAE model [12, 53].",
                "In practice, \u03c4 (j) i is typically represented by the day-of-year [8, 12], and makes it possible to account for the irregular temporal sampling of most satellites.",
                "The LTAE module (Sainte Fare Garnot and Landrieu, 2020) handles the temporal context by applying self-attention (Vaswani et al., 2017) with modifications to output a single embedding.",
                "Given the sequence of PSE-embeddings and the encoded \u03c4 i , LTAE outputs a single embedding o i , which is then classified by a multi-layer perceptron to produce class probabilities p ( y"
            ],
            "citingPaper": {
                "paperId": "39cb2252100108e136301d18ebce7af4e181a207",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-02682",
                    "ArXiv": "2111.02682",
                    "DOI": "10.1016/j.isprsjprs.2022.04.018",
                    "CorpusId": 242757521
                },
                "corpusId": 242757521,
                "publicationVenue": {
                    "id": "227fb221-5e57-477c-b756-e39dd8ffd538",
                    "name": "Isprs Journal of Photogrammetry and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Isprs J Photogramm Remote Sens"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/39cb2252100108e136301d18ebce7af4e181a207",
                "title": "TimeMatch: Unsupervised Cross-Region Adaptation by Temporal Shift Estimation",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2122273256",
                        "name": "Joachim Nyborg"
                    },
                    {
                        "authorId": "46354194",
                        "name": "Charlotte Pelletier"
                    },
                    {
                        "authorId": "47744684",
                        "name": "S. Lef\u00e8vre"
                    },
                    {
                        "authorId": "1713664",
                        "name": "I. Assent"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "8282233bdee1f50cf26276374659c404312c9987",
                "externalIds": {
                    "DOI": "10.1002/rse2.240",
                    "CorpusId": 242121022
                },
                "corpusId": 242121022,
                "publicationVenue": {
                    "id": "1f60eecc-63d4-4b5b-a433-529dc965549c",
                    "name": "Remote Sensing in Ecology and Conservation",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens Ecol Conserv"
                    ],
                    "issn": "2056-3485",
                    "url": "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)2056-3485"
                },
                "url": "https://www.semanticscholar.org/paper/8282233bdee1f50cf26276374659c404312c9987",
                "title": "A convolutional neural network architecture designed for the automated survey of seabird colonies",
                "abstract": "Satellite imagery is now well established as a method of finding and estimating the abundance of Antarctic penguin colonies. However, the delineation and classification of penguin colonies in sub\u2010meter satellite imagery has required the use of expert observers and is highly labor intensive, precluding regular censuses at the pan\u2010Antarctic scale. Here we present the first automated pipeline for the segmentation and classification of seabird colonies in high\u2010resolution satellite imagery. Our method leverages site\u2010fidelity by using images from previous years to improve classification performance but is robust to georegistration artifacts imposed by misalignment between sensors or terrain correction. We use a segmentation network with an additional branch that extracts the useful information from the prior mask of the input image. This prior branch provides the main model information on the location and size of guano in a prior annotation yet automatically learns to compensate for potential misalignment between the prior mask and the input image being classified. Our approach outperforms the previous approach by 44%, improving the average Intersection\u2010over\u2010Union segmentation score from 0.34 to 0.50. While penguin guano remains a challenging target for segmentation due to its indistinct and highly variable appearance, the inclusion of prior information represents a key step toward automated image annotation for population monitoring. Moreover, this method can be adapted for other ecological applications where the dynamics of landscape change are slow relative to the repeat frequency of available imagery and prior information may be available to aid with image annotation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "143631873",
                        "name": "Hieu M. Le"
                    },
                    {
                        "authorId": "145654220",
                        "name": "D. Samaras"
                    },
                    {
                        "authorId": "34517528",
                        "name": "H. Lynch"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Attention layers within deep learning models applied to remote sensing data are proving to be highly effective at classifying time series and more robustly handling noisy data [55,56]."
            ],
            "citingPaper": {
                "paperId": "eb6768f3ddf1e79acffdff193e59654bd3b7d297",
                "externalIds": {
                    "DBLP": "journals/remotesensing/GrayCRKUJ21",
                    "DOI": "10.3390/rs13193953",
                    "CorpusId": 241202116
                },
                "corpusId": 241202116,
                "publicationVenue": {
                    "id": "8e1bd4b5-d5b2-4e22-ba0a-01fe5568d472",
                    "name": "Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens"
                    ],
                    "issn": "2315-4675",
                    "alternate_issns": [
                        "2072-4292"
                    ],
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-169233",
                    "alternate_urls": [
                        "https://www.mdpi.com/journal/remotesensing",
                        "http://www.mdpi.com/journal/remotesensing",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-169233"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/eb6768f3ddf1e79acffdff193e59654bd3b7d297",
                "title": "Temporally Generalizable Land Cover Classification: A Recurrent Convolutional Neural Network Unveils Major Coastal Change through Time",
                "abstract": "The ability to accurately classify land cover in periods before appropriate training and validation data exist is a critical step towards understanding subtle long-term impacts of climate change. These trends cannot be properly understood and distinguished from individual disturbance events or decadal cycles using only a decade or less of data. Understanding these long-term changes in low lying coastal areas, home to a huge proportion of the global population, is of particular importance. Relatively simple deep learning models that extract representative spatiotemporal patterns can lead to major improvements in temporal generalizability. To provide insight into major changes in low lying coastal areas, our study (1) developed a recurrent convolutional neural network that incorporates spectral, spatial, and temporal contexts for predicting land cover class, (2) evaluated this model across time and space and compared this model to conventional Random Forest and Support Vector Machine methods as well as other deep learning approaches, and (3) applied this model to classify land cover across 20 years of Landsat 5 data in the low-lying coastal plain of North Carolina, USA. We observed striking changes related to sea level rise that support evidence on a smaller scale of agricultural land and forests transitioning into wetlands and \u201cghost forests\u201d. This work demonstrates that recurrent convolutional neural networks should be considered when a model is needed that can generalize across time and that they can help uncover important trends necessary for understanding and responding to climate change in vulnerable coastal regions.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "48653575",
                        "name": "P. Gray"
                    },
                    {
                        "authorId": "1636936368",
                        "name": "D. Chamorro"
                    },
                    {
                        "authorId": "6030375",
                        "name": "J. Ridge"
                    },
                    {
                        "authorId": "151024247",
                        "name": "H. Kerner"
                    },
                    {
                        "authorId": "92046763",
                        "name": "Emily A. Ury"
                    },
                    {
                        "authorId": "2121353289",
                        "name": "D. Johnston"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "f528e205fbf08dd6ccec8e9a9d46092bfa333141",
                "externalIds": {
                    "MAG": "3185118158",
                    "DOI": "10.1016/J.RSE.2021.112599",
                    "CorpusId": 237710772
                },
                "corpusId": 237710772,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f528e205fbf08dd6ccec8e9a9d46092bfa333141",
                "title": "Towards interpreting multi-temporal deep learning models in crop mapping",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "7169468",
                        "name": "Jinfan Xu"
                    },
                    {
                        "authorId": "2146104184",
                        "name": "Jie Yang"
                    },
                    {
                        "authorId": "32281394",
                        "name": "Xing-Kui Xiong"
                    },
                    {
                        "authorId": "2108564846",
                        "name": "Haifeng Li"
                    },
                    {
                        "authorId": "1767656",
                        "name": "Jingfeng Huang"
                    },
                    {
                        "authorId": "46446811",
                        "name": "K. Ting"
                    },
                    {
                        "authorId": "2747444",
                        "name": "Y. Ying"
                    },
                    {
                        "authorId": "2109640485",
                        "name": "Tao Lin"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "The Temporal Attention Encoder (TAE) [13] and its parsimonious version Lightweight-TAE (LTAE) [11] are temporal sequence encoders based on the language processing literature [35] and adapted for processing SITS.",
                "The temporal dynamics are modeled with temporal convolutions [25], recurrent neural networks [10], hybrid convolutional-recurrent networks [28], and temporal attention [29, 13, 39].",
                "The Sentinel2Agri dataset [13], composed of parcels from the same area, is composed of 191 703 parcels.",
                "Multiple recent studies [19, 11, 13, 30, 12] have solidified the PSE+LTAE (Pixel Set Encoder + Lightweight Temporal Attention) as the state-of-the-art of crop type classification.",
                "The Pixel Set Encoder (PSE) [13] is an efficient spatio-spectral encoder which learns expressive descriptors of the spectral distribution of the observations by randomly sampling pixels within a parcel.",
                "The state-of-the-art of parcel-based crop type classification from Satellite Image Time Series (SITS) is particularly dynamic, especially since the adoption of deep learning methods [13, 25, 29]."
            ],
            "citingPaper": {
                "paperId": "5316ac8443e8ab5518065cc61acf387721f27e2e",
                "externalIds": {
                    "MAG": "3205526128",
                    "ArXiv": "2110.08187",
                    "DBLP": "journals/corr/abs-2110-08187",
                    "DOI": "10.3390/rs13224599",
                    "CorpusId": 239009753
                },
                "corpusId": 239009753,
                "publicationVenue": {
                    "id": "8e1bd4b5-d5b2-4e22-ba0a-01fe5568d472",
                    "name": "Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens"
                    ],
                    "issn": "2315-4675",
                    "alternate_issns": [
                        "2072-4292"
                    ],
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-169233",
                    "alternate_urls": [
                        "https://www.mdpi.com/journal/remotesensing",
                        "http://www.mdpi.com/journal/remotesensing",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-169233"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5316ac8443e8ab5518065cc61acf387721f27e2e",
                "title": "Crop Rotation Modeling for Deep Learning-Based Parcel Classification from Satellite Time Series",
                "abstract": "While annual crop rotations play a crucial role for agricultural optimization, they have been largely ignored for automated crop type mapping. In this paper, we take advantage of the increasing quantity of annotated satellite data to propose to model simultaneously the inter- and intra-annual agricultural dynamics of yearly parcel classification with a deep learning approach. Along with simple training adjustments, our model provides an improvement of over 6.3% mIoU over the current state-of-the-art of crop classification, and a reduction of over 21% of the error rate. Furthermore, we release the first large-scale multi-year agricultural dataset with over 300,000 annotated parcels.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "52199873",
                        "name": "F. Quinton"
                    },
                    {
                        "authorId": "115987954",
                        "name": "Loic Landrieu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "e6c688a9b3c292d3538f51089a94b40c8c6d12ab",
                "externalIds": {
                    "MAG": "3175044012",
                    "DOI": "10.1016/J.RSE.2021.112419",
                    "CorpusId": 237688330
                },
                "corpusId": 237688330,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e6c688a9b3c292d3538f51089a94b40c8c6d12ab",
                "title": "Recurrent-based regression of Sentinel time series for continuous vegetation monitoring",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1397381817",
                        "name": "A. Garioud"
                    },
                    {
                        "authorId": "152688349",
                        "name": "S. Valero"
                    },
                    {
                        "authorId": "12465445",
                        "name": "S. Giordano"
                    },
                    {
                        "authorId": "34890364",
                        "name": "C. Mallet"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "\u00a9 2021 Informa UK Limited, trading as Taylor & Francis Group\n2018; Sitokonstantinou et al. 2018), especially with the joint exploitation of Synthetic Aperture Radar (SAR) and optical images (Veloso et al. 2017; Neetu and Ray 2020)."
            ],
            "citingPaper": {
                "paperId": "09db92688e1983732c506489b0565460fddca7a9",
                "externalIds": {
                    "MAG": "3187655086",
                    "DOI": "10.1080/2150704X.2021.1950940",
                    "CorpusId": 237538259
                },
                "corpusId": 237538259,
                "publicationVenue": {
                    "id": "ee721dd8-0463-444d-930a-854b57e37985",
                    "name": "Remote Sensing Letters",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens Lett"
                    ],
                    "issn": "2150-704X",
                    "url": "http://www.informaworld.com/openurl?genre=journal&issn=2150-704X",
                    "alternate_urls": [
                        "http://www.tandfonline.com/loi/trsl20"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/09db92688e1983732c506489b0565460fddca7a9",
                "title": "Investigating operational country-level crop monitoring with Sentinel~1 and~2 imagery",
                "abstract": "ABSTRACT In this paper, we propose an operational solution for the yearly classification of crop parcels at national scale (namely France) for Land Parcel Identification System updating, under the Common Agricultural Policy (CAP) umbrella. Our pipeline is based on the open-source framework and fed with both time series of Sentinel-1 radar and Sentinel-2 optical images, with complementary contributions. Three conceivable scenarios are investigated with two sets of nomenclatures (17 and 43 classes): early, on-line, and late classifications. Experiments performed on 2017 show very satisfactory results (82\u201397%), locally almost on-par with state-of-the-art deep-based methods. We can conclude our framework offers a strong basis for country-scale operational deployment for 2020+ CAP.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2074007497",
                        "name": "N. David"
                    },
                    {
                        "authorId": "12465445",
                        "name": "S. Giordano"
                    },
                    {
                        "authorId": "34890364",
                        "name": "C. Mallet"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "which achieved higher classification performance [12], [13].",
                "attention encoder (PSE-TAE) [12], which has achieved the best performance in a spatial\u2013temporal crop dataset.",
                "2) Temporal Attention Encoder: The temporal attention encoder (TAE) is a part of the pixel-set encoder and temporal attention encoder (PSE-TAE) [12], which has achieved the best performance in a spatial\u2013temporal crop dataset.",
                "For TAE, the hyperparameters have been adopted the same as [12].",
                "As [12] finds, in crop mapping tasks, the hybrid model always acquires the best performance."
            ],
            "citingPaper": {
                "paperId": "c91f9189f2bf73864aee37c1c4ba0f3ae7442901",
                "externalIds": {
                    "DBLP": "journals/lgrs/TangDXZZ22",
                    "MAG": "3192834253",
                    "DOI": "10.1109/LGRS.2021.3095505",
                    "CorpusId": 238826125
                },
                "corpusId": 238826125,
                "publicationVenue": {
                    "id": "290335d6-cddc-465d-87f1-807e86d8efee",
                    "name": "IEEE Geoscience and Remote Sensing Letters",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Geosci Remote Sens Lett"
                    ],
                    "issn": "1545-598X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=8859",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8859"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c91f9189f2bf73864aee37c1c4ba0f3ae7442901",
                "title": "Channel Attention-Based Temporal Convolutional Network for Satellite Image Time Series Classification",
                "abstract": "Satellite image time series classification has become a research focus with the launch of new remote sensing sensors capable of capturing images with high spatial, spectral, and temporal resolutions. In particular, in the field of crop classification, time dimension information is particularly important. Although some advanced machine learning algorithms, such as random forests (RFs), can achieve good results, they often ignore the time series information. To make full use of temporal and spectral information in multitemporal remote sensing images, a channel attention-based temporal convolutional network (CA-TCN) is proposed in this letter. Specifically, the proposed method is composed of two main modules: temporal convolutional network and attention block. The temporal convolutional network can capture long-range dependence by using a hierarchy of temporal convolutional filters. To capture relevant information inside the sequence and enhance the important information, the attention block is used to enhance the important features in the channel dimension since not all bands contain equal information in crop type classification. The proposed CA-TCN can excavate deeper phenological characteristics. Compared to the temporal attention-based temporal convolutional network and other deep learning-based models, the proposed CA-TCN has achieved state-of-the-art performance in the Breizhcrops dataset with fewer parameters.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2053106669",
                        "name": "Pengfei Tang"
                    },
                    {
                        "authorId": "1882431",
                        "name": "Peijun Du"
                    },
                    {
                        "authorId": "2061313",
                        "name": "J. Xia"
                    },
                    {
                        "authorId": "2151331396",
                        "name": "Peng Zhang"
                    },
                    {
                        "authorId": "47528107",
                        "name": "Wei Zhang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "Recently, attention-based approaches have been adapted to encode sequences of remote sensing images and have led to significant progress for pixel-wise and parcel-wise classification [38, 35, 53]."
            ],
            "citingPaper": {
                "paperId": "5fda2cdb57ac9d43865ac9d652fea94fdf004aa1",
                "externalIds": {
                    "DBLP": "conf/iccv/GarnotL21",
                    "ArXiv": "2107.07933",
                    "DOI": "10.1109/ICCV48922.2021.00483",
                    "CorpusId": 236034332
                },
                "corpusId": 236034332,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/5fda2cdb57ac9d43865ac9d652fea94fdf004aa1",
                "title": "Panoptic Segmentation of Satellite Image Time Series with Convolutional Temporal Attention Networks",
                "abstract": "Unprecedented access to multi-temporal satellite imagery has opened new perspectives for a variety of Earth observation tasks. Among them, pixel-precise panoptic segmentation of agricultural parcels has major economic and environmental implications. While researchers have explored this problem for single images, we argue that the complex temporal patterns of crop phenology are better addressed with temporal sequences of images. In this paper, we present the first end-to-end, single-stage method for panoptic segmentation of Satellite Image Time Series (SITS). This module can be combined with our novel image sequence encoding network which relies on temporal self-attention to extract rich and adaptive multi-scale spatiotemporal features. We also introduce PASTIS, the first open-access SITS dataset with panoptic annotations. We demonstrate the superiority of our encoder for semantic segmentation against multiple competing architectures, and set up the first state-of-the-art of panoptic segmentation of SITS. Our implementation and PASTIS are publicly available.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "67228021",
                        "name": "Vivien Sainte Fare Garnot"
                    },
                    {
                        "authorId": "115987954",
                        "name": "Loic Landrieu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "79efcd9f15fd41bb0ce6e48500954ac85a78e93c",
                "externalIds": {
                    "DBLP": "conf/igarss/CourteilleBMAI21",
                    "DOI": "10.1109/IGARSS47720.2021.9554205",
                    "CorpusId": 238751411
                },
                "corpusId": 238751411,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/79efcd9f15fd41bb0ce6e48500954ac85a78e93c",
                "title": "Channel-Based Attention for Land Cover Classification using Sentinel-2 Time Series",
                "abstract": "Deep Neural Networks (DNNs) are getting increasing attention to deal with land cover classification relying on Satellite Image Time Series (SITS). Though high performances can be achieved, the rationale of a prediction yielded by a DNN often remains unclear. An architecture expressing predictions with respect to input channels is thus proposed in this paper. It relies on convolutional layers and an attention mechanism weighting the importance of each channel in the final classification decision. The correlation between channels is taken into account to set up shared kernels and lower model complexity. Experiments based on Sentinel-2 SITS show promising results.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2061511561",
                        "name": "Hermann Courteille"
                    },
                    {
                        "authorId": "2059134024",
                        "name": "A. Beno\u00eet"
                    },
                    {
                        "authorId": "1841066",
                        "name": "N. M\u00e9ger"
                    },
                    {
                        "authorId": "3005372",
                        "name": "A. Atto"
                    },
                    {
                        "authorId": "1789397",
                        "name": "D. Ienco"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Therefore, apart from agriculture, this work has presented potentially useful instruments for other application domains including the environment [20], medicine [21], econometrics [22], stock-market data [23], and other."
            ],
            "citingPaper": {
                "paperId": "96c3ac61a7eaf61f6bf82266402c69f09a0031b6",
                "externalIds": {
                    "MAG": "3176076396",
                    "DOI": "10.3390/engproc20210050012",
                    "CorpusId": 237912260
                },
                "corpusId": 237912260,
                "publicationVenue": {
                    "id": "a31f77a7-196f-4c89-8eae-820f04d103dd",
                    "name": "Engineering Proceedings",
                    "alternate_names": [
                        "Eng Proc"
                    ],
                    "issn": "2673-4591",
                    "url": "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-1736914"
                },
                "url": "https://www.semanticscholar.org/paper/96c3ac61a7eaf61f6bf82266402c69f09a0031b6",
                "title": "Time-Series of Distributions Forecasting in Agricultural Applications: An Intervals\u2019 Numbers Approach",
                "abstract": "This work represents any distribution of data by an Intervals\u2019 Number (IN), hence it represents all-order data statistics, using a \u201csmall\u201d number of L intervals. The INs considered are induced from images of grapes that ripen. The objective is the accurate prediction of grape maturity. Based on an established algebra of INs, an optimizable IN-regressor is proposed, implementable on a neural architecture, toward predicting future INs from past INs. A recursive scheme tests the capacity of the IN-regressor to learn the physical \u201claw\u201d that generates the non-stationary time-series of INs. Computational experiments demonstrate comparatively the effectiveness of the proposed techniques.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "52131928",
                        "name": "C. Bazinas"
                    },
                    {
                        "authorId": "2280221",
                        "name": "E. Vrochidou"
                    },
                    {
                        "authorId": "145448073",
                        "name": "C. Lytridis"
                    },
                    {
                        "authorId": "2759375",
                        "name": "V. Kaburlasos"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "Time series classification models for satellite data include 1D convolution neural networks (1D-CNN) [8,18], recurrent neural networks (RNN) [45], and attention-based deep learning [46,47]."
            ],
            "citingPaper": {
                "paperId": "ba060652ffb4777b597d99bec336ddd4f53137c4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-11301",
                    "ArXiv": "2204.11301",
                    "DOI": "10.3390/rs13132428",
                    "CorpusId": 236520893
                },
                "corpusId": 236520893,
                "publicationVenue": {
                    "id": "8e1bd4b5-d5b2-4e22-ba0a-01fe5568d472",
                    "name": "Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens"
                    ],
                    "issn": "2315-4675",
                    "alternate_issns": [
                        "2072-4292"
                    ],
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-169233",
                    "alternate_urls": [
                        "https://www.mdpi.com/journal/remotesensing",
                        "http://www.mdpi.com/journal/remotesensing",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-169233"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ba060652ffb4777b597d99bec336ddd4f53137c4",
                "title": "Satellite Image Time Series Analysis for Big Earth Observation Data",
                "abstract": "The development of analytical software for big Earth observation data faces several challenges. Designers need to balance between conflicting factors. Solutions that are efficient for specific hardware architectures can not be used in other environments. Packages that work on generic hardware and open standards will not have the same performance as dedicated solutions. Software that assumes that its users are computer programmers are flexible but may be difficult to learn for a wide audience. This paper describes sits, an open-source R package for satellite image time series analysis using machine learning. To allow experts to use satellite imagery to the fullest extent, sits adopts a time-first, space-later approach. It supports the complete cycle of data analysis for land classification. Its API provides a simple but powerful set of functions. The software works in different cloud computing environments. Satellite image time series are input to machine learning classifiers, and the results are post-processed using spatial smoothing. Since machine learning methods need accurate training data, sits includes methods for quality assessment of training samples. The software also provides methods for validation and accuracy measurement. The package thus comprises a production environment for big EO data analysis. We show that this approach produces high accuracy for land use and land cover maps through a case study in the Cerrado biome, one of the world\u2019s fast moving agricultural frontiers for the year 2018.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "13245934",
                        "name": "R. Sim\u00f5es"
                    },
                    {
                        "authorId": "82927193",
                        "name": "G. C\u00e2mara"
                    },
                    {
                        "authorId": "35255977",
                        "name": "G. R. Queiroz"
                    },
                    {
                        "authorId": "2130768747",
                        "name": "F. Souza"
                    },
                    {
                        "authorId": "1678222",
                        "name": "Pedro Ribeiro de Andrade Neto"
                    },
                    {
                        "authorId": "25613243",
                        "name": "L. Santos"
                    },
                    {
                        "authorId": "2084556779",
                        "name": "Alexandre Carvalho"
                    },
                    {
                        "authorId": "2355151",
                        "name": "K. Ferreira"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "For crop classification at the parcel level [2] argue that S2 pixel size is coarser than the typical agricultural textural information and show that using spatial modelling",
                "This is the same AOI as [2], however, we extend the time period of interest to three years and provide dense annotations for crop types and parcel identities.",
                "Some works involve temporal modelling of single pixel or parcel level aggregated features [12], [20], [2] while others jointly capture temporal and spatial patterns [13], [21], [18], [1].",
                "As a sanity check we run further tests with the label groupings from [2] who reported overall accuracy 0."
            ],
            "citingPaper": {
                "paperId": "dcd0cb3efe3a21c9b5240a5c4e1f1fdd98200b7c",
                "externalIds": {
                    "ArXiv": "2104.04310",
                    "DBLP": "journals/corr/abs-2104-04310",
                    "DOI": "10.1109/TGRS.2022.3198187",
                    "CorpusId": 233204458
                },
                "corpusId": 233204458,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dcd0cb3efe3a21c9b5240a5c4e1f1fdd98200b7c",
                "title": "Context-Self Contrastive Pretraining for Crop Type Semantic Segmentation",
                "abstract": "In this article, we propose a fully supervised pretraining scheme based on contrastive learning particularly tailored to dense classification tasks. The proposed context-self contrastive loss (CSCL) learns an embedding space that makes semantic boundaries pop-up by use of a similarity metric between every location in a training sample and its local context. For crop type semantic segmentation from satellite image time series (SITS), we find performance at parcel boundaries to be a critical bottleneck and explain how CSCL tackles the underlying cause of that problem, improving the state-of-the-art performance in this task. Additionally, using images from the Sentinel-2 (S2) satellite missions we compile the largest, to our knowledge, SITS dataset densely annotated by crop type and parcel identities, which we make publicly available together with the data generation pipeline. Using that data we find CSCL, even with minimal pretraining, to improve all respective baselines and present a process for semantic segmentation at greater resolution than that of the input images for obtaining crop classes at a more granular level. The code and instructions to download the data can be found in https://github.com/michaeltrs/DeepSatModels.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "102361656",
                        "name": "Michail Tarasiou"
                    },
                    {
                        "authorId": "3616981",
                        "name": "R. G\u00fcler"
                    },
                    {
                        "authorId": "1776444",
                        "name": "S. Zafeiriou"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "48fd65a927ea440bb04f968af5b41691e52f59af",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-16836",
                    "ArXiv": "2103.16836",
                    "CorpusId": 232427879
                },
                "corpusId": 232427879,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/48fd65a927ea440bb04f968af5b41691e52f59af",
                "title": "Channel-Based Attention for LCC Using Sentinel-2 Time Series",
                "abstract": "Deep Neural Networks (DNNs) are getting increasing attention to deal with Land Cover Classification (LCC) relying on Satellite Image Time Series (SITS). Though high performances can be achieved, the rationale of a prediction yielded by a DNN often remains unclear. An architecture expressing predictions with respect to input channels is thus proposed in this paper. It relies on convolutional layers and an attention mechanism weighting the importance of each channel in the final classification decision. The correlation between channels is taken into account to set up shared kernels and lower model complexity. Experiments based on a Sentinel-2 SITS show promising results.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2061511561",
                        "name": "Hermann Courteille"
                    },
                    {
                        "authorId": "2059134024",
                        "name": "A. Beno\u00eet"
                    },
                    {
                        "authorId": "2094439080",
                        "name": "N. M'eger"
                    },
                    {
                        "authorId": "3005372",
                        "name": "A. Atto"
                    },
                    {
                        "authorId": "1789397",
                        "name": "D. Ienco"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "\u2026deep learning (Ru\u00dfwurm and Ko\u0308rner, 2017, 2018b; Rustowicz et al., 2019; Zhong et al., 2019; Pelletier et al., 2019; Ru\u00dfwurm et al., 2019; Sainte Fare Garnot et al., 2019, 2020) has shown good performance as a tool for multi-temporal vegetation mapping, on different datasets (Ru\u00dfwurm and\u2026",
                "Supervised machine learning \u2013 recently in particular deep learning (Ru\u00dfwurm and Ko\u0308rner, 2017, 2018b; Rustowicz et al., 2019; Zhong et al., 2019; Pelletier et al., 2019; Ru\u00dfwurm et al., 2019; Sainte Fare Garnot et al., 2019, 2020) has shown good performance as a tool for multi-temporal vegetation mapping, on different datasets (Ru\u00dfwurm and Ko\u0308rner, 2017, 2018b; Rustowicz et al., 2019; Zhong et al., 2019; Pelletier et al., 2019; Ru\u00dfwurm et al., 2019; Sainte Fare Garnot et al., 2020).",
                "In (Rustowicz et al., 2019; Sainte Fare Garnot et al., 2019), satellite images are first processed individually with a CNN to obtain per-image features; then temporal dependencies between these features are modeled with a separate Recurrent Neural Networks (RNNs).",
                "\u2026Sainte Fare Garnot et al., 2019, 2020) has shown good performance as a tool for multi-temporal vegetation mapping, on different datasets (Ru\u00dfwurm and Ko\u0308rner, 2017, 2018b; Rustowicz et al., 2019; Zhong et al., 2019; Pelletier et al., 2019; Ru\u00dfwurm et al., 2019; Sainte Fare Garnot et al., 2020).",
                "Sainte Fare Garnot et al. (2020) combine pixel-set encoder and transformer (Vaswani et al., 2017) and show improved performance over RNN-based approaches."
            ],
            "citingPaper": {
                "paperId": "0793867ea5b55362f55d63e2b9884e3d54cdddb5",
                "externalIds": {
                    "ArXiv": "2102.08820",
                    "MAG": "3190941789",
                    "DBLP": "journals/corr/abs-2102-08820",
                    "DOI": "10.1016/J.RSE.2021.112603",
                    "CorpusId": 231942321
                },
                "corpusId": 231942321,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0793867ea5b55362f55d63e2b9884e3d54cdddb5",
                "title": "Crop mapping from image time series: deep learning with multi-scale label hierarchies",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "26978093",
                        "name": "Mehmet Ozgur Turkoglu"
                    },
                    {
                        "authorId": "1404069168",
                        "name": "S. D'aronco"
                    },
                    {
                        "authorId": "1503471218",
                        "name": "Gregor Perich"
                    },
                    {
                        "authorId": "2538810",
                        "name": "F. Liebisch"
                    },
                    {
                        "authorId": "2051130236",
                        "name": "Constantin Streit"
                    },
                    {
                        "authorId": "144810819",
                        "name": "K. Schindler"
                    },
                    {
                        "authorId": "1753678",
                        "name": "J. D. Wegner"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Apart from change detection purposes, sequential satellite images have also been exploited for land-cover classification as in [53], where multitemporal Sentinel-2 agricultural parcels are transformed to unordered sets of pixels."
            ],
            "citingPaper": {
                "paperId": "82dfb12d3a119bd07bc45d4fae92539b24323cc1",
                "externalIds": {
                    "DBLP": "journals/tgrs/PapadomanolakiV21",
                    "MAG": "3133438312",
                    "DOI": "10.1109/TGRS.2021.3055584",
                    "CorpusId": 233910177
                },
                "corpusId": 233910177,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/82dfb12d3a119bd07bc45d4fae92539b24323cc1",
                "title": "A Deep Multitask Learning Framework Coupling Semantic Segmentation and Fully Convolutional LSTM Networks for Urban Change Detection",
                "abstract": "In this article, we present a deep multitask learning framework able to couple semantic segmentation and change detection using fully convolutional long short-term memory (LSTM) networks. In particular, we present a UNet-like architecture (L-UNet) that models the temporal relationship of spatial feature representations using integrated fully convolutional LSTM blocks on top of every encoding level. In this way, the network is able to capture the temporal relationship of spatial feature vectors in all encoding levels without the need to downsample or flatten them, forming an end-to-end trainable framework. Moreover, we further enrich the L-UNet architecture with an additional decoding branch that performs semantic segmentation on the available semantic categories that are presented in the different input dates, forming a multitask framework. Different loss quantities are also defined and combined together in a circular way to boost the overall performance. The developed methodology has been evaluated on three different data sets, i.e., the challenging bitemporal high-resolution Office National d\u2019Etudes et de Recherches A\u00e9rospatiales (ONERA) Satellite Change Detection (OSCD) Sentinel-2 data set, the very high-resolution (VHR) multitemporal data set of the East Prefecture of Attica, Greece, and finally, the multitemporal VHR SpaceNet7 data set. Promising quantitative and qualitative results demonstrated that the synergy among the tasks can boost up the achieved performances. In particular, the proposed multitask framework contributed to a significant decrease in false-positive detections, with the F1 rate outperforming other state-of-the-art methods by at least 2.1% and 4.9% in the Attica VHR and SpaceNet7 data set cases, respectively. Our models and code can be found at https://github.com/mpapadomanolaki/multi-task-L-UNet.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "47058858",
                        "name": "M. Papadomanolaki"
                    },
                    {
                        "authorId": "1893915",
                        "name": "M. Vakalopoulou"
                    },
                    {
                        "authorId": "144542193",
                        "name": "K. Karantzalos"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Authors of [21] propose an hybrid architecture applied at region level."
            ],
            "citingPaper": {
                "paperId": "5c3ce7758937a43ccc1a589b63cd67e5eba4bffc",
                "externalIds": {
                    "DBLP": "conf/icpr/ChelaliKPV20",
                    "DOI": "10.1109/ICPR48806.2021.9412892",
                    "CorpusId": 233877412
                },
                "corpusId": 233877412,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5c3ce7758937a43ccc1a589b63cd67e5eba4bffc",
                "title": "Classification of spatially enriched pixel time series with convolutional neural networks",
                "abstract": "Satellite Image Time Series (SITS), MRI sequences, and more generally image time series, constitute $2D+t$ data providing spatial and temporal information about an observed scene. Given a pattern recognition task such as image classification, considering jointly such rich information is crucial during the decision process. Nevertheless, due to the complex representation of the data-cube, spatio-temporal features extraction from $2D+t$ data remains difficult to handle. We present in this article an approach to learn such features from this data, and then to proceed to their classification. Our strategy consists in enriching pixel time series with spatial information. It is based on Random Walk to build a novel segment-based representation of the data, passing from a $2D+t$ dimension to a $2D$ one, without loosing too much spatial information. Such new representation is then involved in an end-to-end learning process with a classical 2D Convolutional Neural Network (CNN) in order to learn spatiotemporal features for the classification of image time series. Our approach is evaluated on a remote sensing application for the mapping of agricultural crops. Thanks to a visual attention mechanism, the proposed $2D$ spatio-temporal representation makes also easier the interpretation of a SITS to understand spatiotemporal phenomenons related to soil management practices.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1396167230",
                        "name": "Mohamed Chelali"
                    },
                    {
                        "authorId": "2255097",
                        "name": "Camille Kurtz"
                    },
                    {
                        "authorId": "2050456759",
                        "name": "A. Puissant"
                    },
                    {
                        "authorId": "145645182",
                        "name": "N. Vincent"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "db9eb9b56c0761a0e7290130572ddb7d3a116821",
                "externalIds": {
                    "MAG": "3114377056",
                    "DBLP": "conf/csit/ShynkarenkoNC20",
                    "DOI": "10.1007/978-3-030-63270-0_76",
                    "CorpusId": 234217574
                },
                "corpusId": 234217574,
                "publicationVenue": {
                    "id": "1268cf6f-971e-46d2-aaef-1621574eacf6",
                    "name": "International Conference on Computer Science and Information Technologies",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Comput Sci Inf Technol",
                        "International Conference on Computer Science and Information Technology",
                        "ICCSIT",
                        "IEEE International Conference on Computer Science and Information Technology",
                        "CSIT",
                        "Int Conf Comput Sci Inf Technol"
                    ],
                    "url": "https://csit.ieee.org.ua/"
                },
                "url": "https://www.semanticscholar.org/paper/db9eb9b56c0761a0e7290130572ddb7d3a116821",
                "title": "Constructive-Synthesizing Modeling of Lightning Flashes in the Dynamic Thunderstorm Front",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "51407707",
                        "name": "V. Shynkarenko"
                    },
                    {
                        "authorId": "2085834621",
                        "name": "I. Nikitina"
                    },
                    {
                        "authorId": "1455747119",
                        "name": "R. Chyhir"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "We run Sainte Fare Garnot and Landrieu\u2019s [27] model since they achieve state-of-the-art performance for an object-based crop mapping task on the Sentinel2-Agri dataset [26].",
                "[26], and Sainte Fare Garnot and Landrieu [27] propose a transformer-based approach."
            ],
            "citingPaper": {
                "paperId": "47e2afe08f35cd2a82a75f20bdeac3b40e73525b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2012-02542",
                    "MAG": "3110784793",
                    "ArXiv": "2012.02542",
                    "DOI": "10.1109/TGRS.2021.3101965",
                    "CorpusId": 227305690
                },
                "corpusId": 227305690,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/47e2afe08f35cd2a82a75f20bdeac3b40e73525b",
                "title": "Crop Classification Under Varying Cloud Cover With Neural Ordinary Differential Equations",
                "abstract": "Optical satellite sensors cannot see the earth's surface through clouds. Despite the periodic revisit cycle, image sequences acquired by earth observation satellites are, therefore, irregularly sampled in time. State-of-the-art methods for crop classification (and other time-series analysis tasks) rely on techniques that implicitly assume regular temporal spacing between observations, such as recurrent neural networks (RNNs). We propose to use neural ordinary differential equations (NODEs) in combination with RNNs to classify crop types in irregularly spaced image sequences. The resulting ODE-RNN models consist of two steps: an update step, where a recurrent unit assimilates new input data into the model's hidden state, and a prediction step, in which NODE propagates the hidden state until the next observation arrives. The prediction step is based on a continuous representation of the latent dynamics, which has several advantages. At the conceptual level, it is a more natural way to describe the mechanisms that govern the phenological cycle. From a practical point of view, it makes it possible to sample the system state at arbitrary points in time such that one can integrate observations whenever they are available and extrapolate beyond the last observation. Our experiments show that ODE-RNN, indeed, improves classification accuracy over common baselines, such as LSTM, GRU, temporal convolutional network, and transformer. The gains are most prominent in the challenging scenario where only few observations are available (i.e., frequent cloud cover). Moreover, we show that the ability to extrapolate translates to better classification performance early in the season, which is important for forecasting.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2031912818",
                        "name": "Nando Metzger"
                    },
                    {
                        "authorId": "26978093",
                        "name": "Mehmet Ozgur Turkoglu"
                    },
                    {
                        "authorId": "1404069168",
                        "name": "S. D'aronco"
                    },
                    {
                        "authorId": "1753678",
                        "name": "J. D. Wegner"
                    },
                    {
                        "authorId": "144810819",
                        "name": "K. Schindler"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "They employed a Transformer encoder to learn temporal correlations from a sequence of pixel-set embeddings [26].",
                "Transformer was first introduced in NLP as an efficient alternative to RNNs [25], which has been introduced to some remote sensing tasks, such as hyperspectral image classification [51], image captioning [52], and SITS classification [26]."
            ],
            "citingPaper": {
                "paperId": "32edb525204f5821af5da38b89f66909e9a045a5",
                "externalIds": {
                    "MAG": "3095867871",
                    "DOI": "10.36227/techrxiv.13025039",
                    "CorpusId": 228975691
                },
                "corpusId": 228975691,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/32edb525204f5821af5da38b89f66909e9a045a5",
                "title": "Self-Supervised Pre-Training of Transformers for Satellite Image Time Series Classification",
                "abstract": "Satellite\nimage time series (SITS)\nclassification is a major research topic in remote sensing and is relevant for\na wide range of applications. Deep learning approaches have been commonly employed\nfor SITS classification and have provided state-of-the-art performance. However,\ndeep learning methods suffer from overfitting when labeled data is scarce. To address\nthis problem, we propose a novel self-supervised pre-training scheme to initialize\na Transformer-based network by utilizing large-scale unlabeled data. In detail,\nthe model is asked to predict randomly contaminated observations given an\nentire time series of a pixel. The main idea of our proposal is to leverage the\ninherent temporal structure of satellite time series to learn general-purpose\nspectral-temporal representations related to land cover semantics. Once\npre-training is completed, the pre-trained network can be further adapted to various\nSITS classification tasks by fine-tuning all the model parameters on small-scale\ntask-related labeled data. In this way, the general knowledge and\nrepresentations about SITS can be transferred to a label-scarce task, thereby\nimproving the generalization performance of the model as well as reducing the\nrisk of overfitting. Comprehensive experiments have been carried out on three\nbenchmark datasets over large study areas. Experimental results demonstrate the\neffectiveness of the proposed method, leading to a classification accuracy\nincrement up to 2.38% to 5.27%. The code and the pre-trained model will be\navailable at https://github.com/linlei1214/SITS-BERT upon publication.This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2116525582",
                        "name": "Yuan Yuan"
                    },
                    {
                        "authorId": "46456296",
                        "name": "Lei Lin"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "A transformer architecture for embedding time-sequences is adapted in [14, 15], in order to exploit the temporal dimension of time series data."
            ],
            "citingPaper": {
                "paperId": "10deeb0ddccb699cd123979458f8f1fb28b9ed4d",
                "externalIds": {
                    "PubMedCentral": "7521744",
                    "MAG": "3089655035",
                    "DOI": "10.1371/journal.pone.0239746",
                    "CorpusId": 222142528,
                    "PubMed": "32986785"
                },
                "corpusId": 222142528,
                "publicationVenue": {
                    "id": "0aed7a40-85f3-4c66-9e1b-c1556c57001b",
                    "name": "PLoS ONE",
                    "type": "journal",
                    "alternate_names": [
                        "Plo ONE",
                        "PLOS ONE",
                        "PLO ONE"
                    ],
                    "issn": "1932-6203",
                    "url": "https://journals.plos.org/plosone/",
                    "alternate_urls": [
                        "http://www.plosone.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/10deeb0ddccb699cd123979458f8f1fb28b9ed4d",
                "title": "On the performance of fusion based planet-scope and Sentinel-2 data for crop classification using inception inspired deep convolutional neural network",
                "abstract": "This research work aims to develop a deep learning-based crop classification framework for remotely sensed time series data. Tobacco is a major revenue generating crop of Khyber Pakhtunkhwa (KP) province of Pakistan, with over 90% of the country\u2019s Tobacco production. In order to analyze the performance of the developed classification framework, a pilot sub-region named Yar Hussain is selected for experimentation work. Yar Hussain is a tehsil of district Swabi, within KP province of Pakistan, having highest contribution to the gross production of the KP Tobacco crop. KP generally consists of a diverse crop land with different varieties of vegetation, having similar phenology which makes crop classification a challenging task. In this study, a temporal convolutional neural network (TempCNNs) model is implemented for crop classification, while considering remotely sensed imagery of the selected pilot region with specific focus on the Tobacco crop. In order to improve the performance of the proposed classification framework, instead of using the prevailing concept of utilizing a single satellite imagery, both Sentinel-2 and Planet-Scope imageries are stacked together to assist in providing more diverse features to the proposed classification framework. Furthermore, instead of using a single date satellite imagery, multiple satellite imageries with respect to the phenological cycle of Tobacco crop are temporally stacked together which resulted in a higher temporal resolution of the employed satellite imagery. The developed framework is trained using the ground truth data. The final output is obtained as an outcome of the SoftMax function of the developed model in the form of probabilistic values, for the classification of the selected classes. The proposed deep learning-based crop classification framework, while utilizing multi-satellite temporally stacked imagery resulted in an overall classification accuracy of 98.15%. Furthermore, as the developed classification framework evolved with specific focus on Tobacco crop, it resulted in best Tobacco crop classification accuracy of 99%.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2592433",
                        "name": "N. Minallah"
                    },
                    {
                        "authorId": "6693097",
                        "name": "M. Tariq"
                    },
                    {
                        "authorId": "144428110",
                        "name": "N. Aziz"
                    },
                    {
                        "authorId": "50057673",
                        "name": "W. Khan"
                    },
                    {
                        "authorId": "8031296",
                        "name": "A. Rehman"
                    },
                    {
                        "authorId": "102804035",
                        "name": "S. Belhaouari"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "f3282a2b6112652e0660ee42f799b21957b2831e",
                "externalIds": {
                    "DBLP": "conf/csit/ShynkarenkoN20",
                    "DOI": "10.1109/CSIT49958.2020.9321881",
                    "CorpusId": 231715816
                },
                "corpusId": 231715816,
                "publicationVenue": {
                    "id": "1268cf6f-971e-46d2-aaef-1621574eacf6",
                    "name": "International Conference on Computer Science and Information Technologies",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Comput Sci Inf Technol",
                        "International Conference on Computer Science and Information Technology",
                        "ICCSIT",
                        "IEEE International Conference on Computer Science and Information Technology",
                        "CSIT",
                        "Int Conf Comput Sci Inf Technol"
                    ],
                    "url": "https://csit.ieee.org.ua/"
                },
                "url": "https://www.semanticscholar.org/paper/f3282a2b6112652e0660ee42f799b21957b2831e",
                "title": "Lightning Recognition on the Filtered Videos in the Dynamic Clouds",
                "abstract": "Color models' opportunities were explored for lightning flashes extraction in significant dynamic cloudiness. It was shown that the greatest efficiently in recognition is provided by combining Lab and LCH model-based features. The ranges of color channels are defined for lightning aureoles. Linear and quadratic filters were developed for aureoles detection at the series frames of the video from meteorological satellites. An analysis of their effectiveness was done. The lightning detection filter is based on the processing a current frame of the video and the filtered one containing lightning aureoles. The method and software for lightning extraction were developed based on the image filtering.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "51407707",
                        "name": "V. Shynkarenko"
                    },
                    {
                        "authorId": "2085834621",
                        "name": "I. Nikitina"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "972bd288493631bd464c2efab2452b7f66a745e6",
                "externalIds": {
                    "MAG": "3037002701",
                    "DOI": "10.1016/j.rse.2020.111946",
                    "CorpusId": 224915900
                },
                "corpusId": 224915900,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/972bd288493631bd464c2efab2452b7f66a745e6",
                "title": "DeepCropMapping: A multi-temporal deep learning approach with improved spatial generalizability for dynamic corn and soybean mapping",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "7169468",
                        "name": "Jinfan Xu"
                    },
                    {
                        "authorId": "2109529630",
                        "name": "Yue Zhu"
                    },
                    {
                        "authorId": "35356451",
                        "name": "Renhai Zhong"
                    },
                    {
                        "authorId": "2152796416",
                        "name": "Zhixian Lin"
                    },
                    {
                        "authorId": "1390818903",
                        "name": "Jialu Xu"
                    },
                    {
                        "authorId": "2152631550",
                        "name": "Hao Jiang"
                    },
                    {
                        "authorId": "1767656",
                        "name": "Jingfeng Huang"
                    },
                    {
                        "authorId": "2108564846",
                        "name": "Haifeng Li"
                    },
                    {
                        "authorId": "2109640485",
                        "name": "Tao Lin"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "The use of more dedicated networks, such as a Transformer (Vaswani et al., 2017, Sainte Fare Garnot et al., 2020), could improve the results."
            ],
            "citingPaper": {
                "paperId": "baed69207f7abf6325ba7064e06f59c6ddc90185",
                "externalIds": {
                    "MAG": "3080696365",
                    "DOI": "10.5194/isprs-archives-xliii-b3-2020-591-2020",
                    "CorpusId": 221689385
                },
                "corpusId": 221689385,
                "publicationVenue": {
                    "id": "4ab1e1bf-98e8-4e0c-a53a-7a00e37e44e2",
                    "name": "The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences",
                    "type": "journal",
                    "alternate_names": [
                        "Int Arch Photogramm Remote Sens Spat Inf Sci"
                    ],
                    "issn": "1682-1750",
                    "url": "https://www.isprs.org/publications/archives.aspx"
                },
                "url": "https://www.semanticscholar.org/paper/baed69207f7abf6325ba7064e06f59c6ddc90185",
                "title": "ON THE JOINT EXPLOITATION OF OPTICAL AND SAR SATELLITE IMAGERY FOR GRASSLAND MONITORING",
                "abstract": "Abstract. Time series of optical and Synthetic Aperture RADAR (SAR) images provide complementary knowledge about the cover and use of the Earth surface since they exhibit information of distinct physical nature. They have proved to be particularly relevant for monitoring large areas with high temporal dynamics and related to significant ecosystem services. Grasslands are such crucial surfaces, both in terms of economic and environmental issues and the automatic and frequent monitoring of their agricultural practices is required for many purposes. To address this problem, the deep-based SenDVI framework is presented. SenDVI proposes an object-based methodology to estimate NDVI values from Sentinel-1 SAR observations and contextual knowledge (weather, terrain). Values are regressed every 6 days for compliance with monitoring purposes. Very satisfactory results are obtained with this low-level multimodal fusion strategy (R2\u2009=\u20090.84 on a Sentinel-2 tile). Finer analysis is however required to fully assess the relevance of each modality (Sentinel-1, Sentinel-2, weather, terrain) and feature sets and to propose the simplest conceivable framework. Results show that not all features are necessary and can be discarded while others have a mandatory contribution to the regression task. Moreover, experiments prove that accuracy can be improved by not saturating the network with non-essential information (among contextual knowledge in particular). This allows to move towards more operational solution.\n",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1397381817",
                        "name": "A. Garioud"
                    },
                    {
                        "authorId": "152688349",
                        "name": "S. Valero"
                    },
                    {
                        "authorId": "12465445",
                        "name": "S. Giordano"
                    },
                    {
                        "authorId": "34890364",
                        "name": "C. Mallet"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[43].",
                "Meanwhile, spatio-temporal satellite images, bolstered by their increasing attainability, are at the forefront of a comprehensive effort towards automatic Earth monitoring by international agencies [43]."
            ],
            "citingPaper": {
                "paperId": "880785e1bb10926d94f191ac01c376d46360fac4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2008-00168",
                    "ArXiv": "2008.00168",
                    "MAG": "3046711384",
                    "DOI": "10.1080/10095020.2021.2017237",
                    "CorpusId": 220936335
                },
                "corpusId": 220936335,
                "publicationVenue": {
                    "id": "2a3dc2fd-77aa-4ec6-befd-4df9954028e0",
                    "name": "Geo-Spatial Information Science",
                    "type": "journal",
                    "alternate_names": [
                        "Geo-spatial Information Science",
                        "Geo-spatial Inf Sci"
                    ],
                    "issn": "1001-4993",
                    "alternate_issns": [
                        "1009-5020"
                    ],
                    "url": "https://link.springer.com/journal/11806",
                    "alternate_urls": [
                        "http://www.tandfonline.com/toc/tgsi20/current",
                        "http://www.tandfonline.com/TGSI",
                        "https://www.tandfonline.com/action/journalInformation?journalCode=tgsi20"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/880785e1bb10926d94f191ac01c376d46360fac4",
                "title": "Land cover classification from remote sensing images based on multi-scale fully convolutional network",
                "abstract": "ABSTRACT Although the Convolutional Neural Network (CNN) has shown great potential for land cover classification, the frequently used single-scale convolution kernel limits the scope of information extraction. Therefore, we propose a Multi-Scale Fully Convolutional Network (MSFCN) with a multi-scale convolutional kernel as well as a Channel Attention Block (CAB) and a Global Pooling Module (GPM) in this paper to exploit discriminative representations from two-dimensional (2D) satellite images. Meanwhile, to explore the ability of the proposed MSFCN for spatio-temporal images, we expand our MSFCN to three-dimension using three-dimensional (3D) CNN, capable of harnessing each land cover category\u2019s time series interaction from the reshaped spatio-temporal remote sensing images. To verify the effectiveness of the proposed MSFCN, we conduct experiments on two spatial datasets and two spatio-temporal datasets. The proposed MSFCN achieves 60.366% on the WHDLD dataset and 75.127% on the GID dataset in terms of mIoU index while the figures for two spatio-temporal datasets are 87.753% and 77.156%. Extensive comparative experiments and ablation studies demonstrate the effectiveness of the proposed MSFCN. Code will be available at https://github.com/lironui/MSFCN.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2047504528",
                        "name": "Rui Li"
                    },
                    {
                        "authorId": "2272708",
                        "name": "Shunyi Zheng"
                    },
                    {
                        "authorId": "5749657",
                        "name": "Chenxi Duan"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "c786d5cf78e0dbcf8635d87ba11c72a153d0432a",
                "externalIds": {
                    "ArXiv": "2007.03047",
                    "DBLP": "conf/bmvc/GarnotL21",
                    "MAG": "3090367983",
                    "CorpusId": 222130598
                },
                "corpusId": 222130598,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/c786d5cf78e0dbcf8635d87ba11c72a153d0432a",
                "title": "Leveraging Class Hierarchies with Metric-Guided Prototype Learning",
                "abstract": "Not all errors are created equal. This is especially true for many key machine learning applications. In the case of classification tasks, the severity of errors can be summarized under the form of a cost matrix, which assesses the gravity of confusing each pair of classes. When the target classes are organized into a hierarchical structure, this matrix defines a metric. We propose to integrate this metric in a new and versatile classification layer in order to model the disparity of errors. Our method relies on jointly learning a feature-extracting network and a set of class representations, or prototypes, which incorporate the error metric into their relative arrangement in the embedding space. Our approach allows for consistent improvement of the severity of the network's errors with regard to the cost matrix. Furthermore, when the induced metric contains insight on the data structure, our approach improves the overall precision as well. Experiments on four different public datasets -- from agricultural time series classification to depth image semantic segmentation -- validate our approach.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "67228021",
                        "name": "Vivien Sainte Fare Garnot"
                    },
                    {
                        "authorId": "115987954",
                        "name": "Loic Landrieu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Compared to our method, the earth mover distance regularizer XE-EMD performs worse on CIFAR100 and NYUDv2, but better on S2-Agri.",
                "Note that for S2-Agri, following [29] we have removed all classes that had less than 100 samples among the almost 200 000 parcels to limit the imbalance of the dataset.\nthings\nliving things\nnon-living things\n(a) First level.\nliving things\nanimals\nmammals\nlarge carnivores bear, leopard, lion, tiger, wolf\nlarge omnivores and herbivores\ncamel, cattle, chimpanzee, elephant, kangaroo\nmedium-sized mammals\nfox, porcupine, possum, raccoon, skunk\nsmall mammals hamster, mouse, rabbit, shrew, squirrel\npeople baby, boy, girl, man, woman\nsea-creatures\naquatic mammals beaver, dolphin, otter, seal, whale\nfish aquarium fish, flatfish, ray, shark, trout\nnon-insect invertebrates\ncrab, lobster, snail, spider, worm\nreptiles crocodile, dinosaur, lizard, snake, turtle\ninsects bee, beetle, butterfly, caterpillar, cockroach\nplants plants\nfruit and vegetables\napples, mushrooms, oranges, pears, sweet peppers\nflowers orchids, poppies, roses, sunflowers, tulips\ntrees maple, oak, palm, pine, willow\n(b) Living things branch.\nnon-living things\nAgricultural Parcel",
                "1 Datasets and Backbones We evaluate our approach on different public datasets and classification tasks: image classification on CIFAR100 [21], RGB-D image segmentation on NYUDv2 [25], and image sequence classification on S2-Agri [29].",
                "Image sequence classification on S2-Agri: S2-Agri is a satellite time series dataset of 189 971 sequences of superspectral images of agricultural parcels.",
                "Our models also improve the ER compared to XE by 4%, 4%, and 15% for CIFAR100, NYUDv2, and S2-Agri respectively.",
                "For S2-Agri, we built the hierarchy by combining the two levels available in the dataset S2 of Garnot et al. with the fine-grained description of the agricutltural parcel classes on the French Payment Agency\u2019s website (in French):\nhttps://www1.telepac.agriculture.gouv.fr/telepac/pdf/tas/2017/ Dossier-PAC-2017_notice_cultures-precisions.pdf.",
                "We use the PSE+TAE architecture [29] as the backbone, and follow their 5-fold cross-validation scheme for training.",
                "To address the high class imbalance of S2-Agri, we weight each terms in Ldata by the inverse of the square root of the classes\u2019 frequency.",
                "Metric-guided prototype models bring improvements compared to XE of up to 9%, 7%, and 11% in AC for CIFAR100, NYUDv2, and S2-Agri respectively.",
                "We show on three public datasets (CIFAR100 [21], NYUDv2 [25], Sentinel2-Agri [29]) that our method can easily be combined with state-of-the-art backbone networks to decrease the cost of their predictions.",
                "The hierarchy of CIFAR100 is presented in Figure 4, NYUDv2 in Figure 5, and S2-Agri in Figure 6.",
                "We evaluate our approach on different public datasets and classification tasks: image classification on CIFAR100 [21], RGB-D image segmentation on NYUDv2 [25], and image sequence classification on S2-Agri [29]."
            ],
            "citingPaper": {
                "paperId": "1c4aa9cfe2084d2ea1d504e5e7c6a9646cf90235",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2007-03047",
                    "MAG": "3039362982",
                    "CorpusId": 220381160
                },
                "corpusId": 220381160,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1c4aa9cfe2084d2ea1d504e5e7c6a9646cf90235",
                "title": "Metric-Guided Prototype Learning",
                "abstract": "Not all errors are created equal. This is especially true for many key machine learning applications. In the case of classification tasks, the hierarchy of errors can be summarized under the form of a cost matrix, which assesses the gravity of confusing each pair of classes. When certain conditions are met, this matrix defines a metric, which we use in a new and versatile classification layer to model the disparity of errors. Our method relies on conjointly learning a feature-extracting network and a set of class representations, or prototypes, which incorporate the error metric into their relative arrangement. Our approach allows for consistent improvement of the network's prediction with regard to the cost matrix. Furthermore, when the induced metric contains insight on the data structure, our approach improves the overall precision. Experiments on three different tasks and public datasets -- from agricultural time series classification to depth image semantic segmentation -- validate our approach.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "67228021",
                        "name": "Vivien Sainte Fare Garnot"
                    },
                    {
                        "authorId": "2125687709",
                        "name": "Lo\u00efc Landrieu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "We evaluate the performance of our approach on the openaccess dataset Sentinel2-Agri [5].",
                "In Table 1, we report the performances of competing methods (taken from [5]) and the L-TAE architecture, all obtained with a 5-fold cross-validation scheme.",
                "In order to remove the effects of the different spatial encoders, we use the same spatial encoder (a pixel set encoder [5]) in all experiments.",
                "[5].",
                "This work has been adapted to process parcels instead of pixels [5].",
                "[13], initially developed for Natural Language Processing (NLP), has been successfully used and adapted to remote sensing tasks [11,5].",
                "18 PSE+TAE [5] 94.",
                "We evaluate our proposed method with the public dataset Sentinel2-Agri [5], comprised of 191 703 sequences of 24 superspectral images of agricultural parcels"
            ],
            "citingPaper": {
                "paperId": "b8d0b8f6e977818d9c29ac461773fa059a587c16",
                "externalIds": {
                    "MAG": "3039601016",
                    "DBLP": "conf/pkdd/GarnotL20",
                    "ArXiv": "2007.00586",
                    "DOI": "10.1007/978-3-030-65742-0_12",
                    "CorpusId": 220280405
                },
                "corpusId": 220280405,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b8d0b8f6e977818d9c29ac461773fa059a587c16",
                "title": "Lightweight Temporal Self-Attention for Classifying Satellite Image Time Series",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "67228021",
                        "name": "Vivien Sainte Fare Garnot"
                    },
                    {
                        "authorId": "115987954",
                        "name": "Loic Landrieu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "1fcf78c4757412bfa0bb312dd4a6cbe9bc830c27",
                "externalIds": {
                    "MAG": "2981830988",
                    "DBLP": "journals/corr/abs-1910-10536",
                    "ArXiv": "1910.10536",
                    "DOI": "10.1016/j.isprsjprs.2020.06.006",
                    "CorpusId": 204838392
                },
                "corpusId": 204838392,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1fcf78c4757412bfa0bb312dd4a6cbe9bc830c27",
                "title": "Self-Attention for Raw Optical Satellite Time Series Classification",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "35469144",
                        "name": "M. Ru\u00dfwurm"
                    },
                    {
                        "authorId": "2388085",
                        "name": "Marco K\u00f6rner"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "ELECTS augments and is compatible with recent advances in end-to-end trainable deep time series classification models [13, 14, 15].",
                "Meanwhile, end-to-end deep learning architectures based on recurrence [13], self-attention [14], or convolution [15] can map a variable length series into a fixed-length representation natively."
            ],
            "citingPaper": {
                "paperId": "dc3edec1404d07c729c4810c75265410067718ef",
                "externalIds": {
                    "ArXiv": "1901.10681",
                    "DOI": "10.1016/j.isprsjprs.2022.12.016",
                    "CorpusId": 254974598
                },
                "corpusId": 254974598,
                "publicationVenue": {
                    "id": "227fb221-5e57-477c-b756-e39dd8ffd538",
                    "name": "Isprs Journal of Photogrammetry and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Isprs J Photogramm Remote Sens"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dc3edec1404d07c729c4810c75265410067718ef",
                "title": "End-to-end learned early classification of time series for in-season crop type mapping",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "35469144",
                        "name": "M. Ru\u00dfwurm"
                    },
                    {
                        "authorId": "145374281",
                        "name": "N. Courty"
                    },
                    {
                        "authorId": "2003050",
                        "name": "R. Emonet"
                    },
                    {
                        "authorId": "47744684",
                        "name": "S. Lef\u00e8vre"
                    },
                    {
                        "authorId": "2977931",
                        "name": "D. Tuia"
                    },
                    {
                        "authorId": "2576923",
                        "name": "R. Tavenard"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "We argue [43] shows similarity to our work in the methodology part, because both proposed methods are applied to time-series Earth observation images.",
                "[43] took randomly sampled pixels to classify the whole image.",
                "[43] proposed a transformer network to encode a set of pixels to classify",
                "But the two models serve two different purposes, the method proposed in this manuscript is intended to segment the image, while the network of [43] is trained for image classification."
            ],
            "citingPaper": {
                "paperId": "def2beca75639d9bc96132dd6827760f163b3176",
                "externalIds": {
                    "DBLP": "journals/tgrs/ZhaoBS23",
                    "DOI": "10.1109/TGRS.2023.3287498",
                    "CorpusId": 259458795
                },
                "corpusId": 259458795,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/def2beca75639d9bc96132dd6827760f163b3176",
                "title": "Tokenized Time-Series in Satellite Image Segmentation With Transformer Network for Active Fire Detection",
                "abstract": "The Visible Infrared Imaging Radiometer Suite (VIIRS) onboard the Suomi National Polar-orbiting Partnership (Suomi-NPP) satellite has been used for the early detection and daily monitoring of active wildfires. How to effectively segment the active fire (AF) pixels from VIIRS image time-series in a reliable manner remains a challenge because of the low precision associated with high recall using automatic methods. For AF detection, multicriteria thresholding is often applied to both low-resolution and mid-resolution Earth observation images. Deep learning approaches based on convolutional neural networks (ConvNets) are also well-studied on mid-resolution images. However, ConvNet-based approaches have poor performance on low-resolution images because of the coarse spatial features. On the other hand, the high temporal resolution of VIIRS images highlights the potential of using sequential models for AF detection. Transformer networks, a recent deep learning architecture based on self-attention, offer hope as they have shown strong performance on image segmentation and sequential modeling tasks within computer vision. In this research, we propose a transformer-based solution to segment AF pixels from the VIIRS time-series. The solution feeds a time-series of tokenized pixels into a transformer network to identify AF pixels at each timestamp and achieves a significantly higher F1-score than prior approaches for AFs within the study areas in California, New Mexico, and Oregon in the U.S., and in British Columbia and Alberta in Canada, as well as in Australia, and Sweden.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2110264297",
                        "name": "Yu Zhao"
                    },
                    {
                        "authorId": "143850529",
                        "name": "Y. Ban"
                    },
                    {
                        "authorId": "50626295",
                        "name": "Josephine Sullivan"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "[26] propose the pixel-set encoder temporal attention encoder, a transformer-based strategy equipped with a pixel-set encoder and a self-attention module for agricultural parcels"
            ],
            "citingPaper": {
                "paperId": "ebfc8c128f821c721cd85dfe87370570b5c41dca",
                "externalIds": {
                    "DBLP": "journals/staeors/CapliezIGBH23",
                    "DOI": "10.1109/JSTARS.2023.3263755",
                    "CorpusId": 257881747
                },
                "corpusId": 257881747,
                "publicationVenue": {
                    "id": "849b6687-df71-4d12-9c46-59f45d5ce951",
                    "name": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE J Sel Top Appl Earth Obs Remote Sens"
                    ],
                    "issn": "1939-1404",
                    "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=4609443",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4609443"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ebfc8c128f821c721cd85dfe87370570b5c41dca",
                "title": "Temporal-Domain Adaptation for Satellite Image Time-Series Land-Cover Mapping With Adversarial Learning and Spatially Aware Self-Training",
                "abstract": "Nowadays, satellite image time series (SITS) are commonly employed to derive land-cover maps (LCM) to support decision makers in a variety of land management applications. In the most general workflow, the production of LCM strongly relies on available GT data to train supervised machine learning models. Unfortunately, these data are not always available due to time-consuming and costly field campaigns. In this scenario, the possibility to transfer a model learnt on a particular year (source domain) to a successive period of time (target domain), over the same study area, can save time and money. Such a kind of model transfer is challenging due to different acquisition conditions affecting each time period, thus resulting in possible distribution shifts between source and target domains. In the general field of machine learning, unsupervised domain adaptation (UDA) approaches are well suited to cope with the learning of models under distribution shifts between source and target domains. While widely explored in the general computer vision field, they are still underinvestigated for SITS-based land-cover mapping, especially for the temporal transfer scenario. With the aim to cope with this scenario in the context of SITS-based land-cover mapping, here we propose spatially aligned domain-adversarial neural network, a framework that combines both adversarial learning and self-training to transfer a classification model from a time period (year) to a successive one on a specific study area. Experimental assessment on a study area located in Burkina Faso characterized by challenging operational constraints demonstrates the significance of our proposal. The obtained results have shown that our proposal outperforms all the UDA competing methods by 7 to 12 points of F1-score across three different transfer tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2186379012",
                        "name": "Emmanuel Capliez"
                    },
                    {
                        "authorId": "1789397",
                        "name": "D. Ienco"
                    },
                    {
                        "authorId": "144836024",
                        "name": "R. Gaetano"
                    },
                    {
                        "authorId": "1736927",
                        "name": "N. Baghdadi"
                    },
                    {
                        "authorId": "2213054763",
                        "name": "Adrien Hadj Salah"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "RNNs, even with contemporary components such as GRUs still have much longer processing times than Temporal CNNs in general [5].",
                "More novel approaches utilise mechanisms such as self-attention [5] or modify coarsely detailed input images using approaches such as pixel set-encoders [28].",
                "Whilst additional features are valuable for land-cover classification tasks, it consequently reduces the interpretability of the data and typically enlarges their volume [5].",
                "Recurrent Neural Networks are regularly used as a comparative baseline within deep learning research for time series classification [5, 40]."
            ],
            "citingPaper": {
                "paperId": "d4f08acf3ded051a92139e632df842d4d8fcb762",
                "externalIds": {
                    "CorpusId": 248512131
                },
                "corpusId": 248512131,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d4f08acf3ded051a92139e632df842d4d8fcb762",
                "title": "I NVESTIGATING T EMPORAL C ONVOLUTIONAL N EURAL N ETWORKS FOR S ATELLITE I MAGE T IME S ERIES C LASSIFICATION \u2217",
                "abstract": "Satellite Image Time Series (SITS) of the Earth\u2019s surface provide detailed land cover maps, with their quality in the spatial and temporal dimensions consistently improving. These image time series are integral for developing systems that aim to produce accurate, up-to-date land cover maps of the Earth\u2019s surface. Applications are wide-ranging, with notable examples including ecosystem mapping, vegetation process monitoring and anthropogenic land-use change tracking. Recently proposed methods for SITS classi\ufb01cation have demonstrated respectable merit, but these methods tend to lack native mechanisms that exploit the temporal dimension of the data; commonly resulting in extensive data pre-processing prohibitively long training times. To overcome these shortcomings, this paper seeks to study and enhance the new proposed method for SITS classi\ufb01cation from literature; namely Temporal CNNs. Comprehensive experiments are carried out on two benchmark SITS datasets with the results demonstrating that Temporal CNNs display a superior or competitive performance to the benchmark algorithms for both datasets. Investigations into the Temporal CNNs architecture also highlighted the non-trivial task of optimising the model for a new dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2059790506",
                        "name": "James Brock"
                    },
                    {
                        "authorId": "3323364",
                        "name": "Z. Abdallah"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "sensors acquiring images with different spatial, spectral, and temporal resolution [1], [2]."
            ],
            "citingPaper": {
                "paperId": "5986dbda3e05745595670a9f8e64944b10e9cb8f",
                "externalIds": {
                    "DBLP": "journals/tgrs/SahaSMSZ22",
                    "DOI": "10.1109/TGRS.2022.3174651",
                    "CorpusId": 248765836
                },
                "corpusId": 248765836,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5986dbda3e05745595670a9f8e64944b10e9cb8f",
                "title": "Unsupervised Single-Scene Semantic Segmentation for Earth Observation",
                "abstract": "Earth observation data have huge potential to enrich our knowledge about our planet. An important step in many Earth observation tasks is semantic segmentation. Generally, a large number of pixelwise labeled images are required to train deep models for supervised semantic segmentation. On the contrary, strong intersensor and geographic variations impede the availability of annotated training data in Earth observation. In practice, most Earth observation tasks use only the target scene without assuming availability of any additional scene, labeled or unlabeled. Keeping in mind such constraints, we propose a semantic segmentation method that learns to segment from a single scene, without using any annotation. Earth observation scenes are generally larger than those encountered in typical computer vision datasets. Exploiting this, the proposed method samples smaller unlabeled patches from the scene. For each patch, an alternate view is generated by simple transformations, e.g., addition of noise. Both views are then processed through a two-stream network and weights are iteratively refined using deep clustering, spatial consistency, and contrastive learning in the pixel space. The proposed model automatically segregates the major classes present in the scene and produces the segmentation map. Extensive experiments on four Earth observation datasets collected by different sensors show the effectiveness of the proposed method. Implementation is available at https://gitlab.lrz.de/ai4eo/cd/-/tree/main/unsupContrastiveSemanticSeg.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2959887",
                        "name": "Sudipan Saha"
                    },
                    {
                        "authorId": "1380493607",
                        "name": "M. Shahzad"
                    },
                    {
                        "authorId": "35041003",
                        "name": "Lichao Mou"
                    },
                    {
                        "authorId": "1471606293",
                        "name": "Qian Song"
                    },
                    {
                        "authorId": "2125159330",
                        "name": "Xiao Xiang Zhu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "The Sentinel-2 mission, which collects multispectral data at up to 10 m resolution at least every 5 days, has become particularly popular for crop type classification since its launch in 2015 [27, 33, 34, 38].",
                "A temporal attention encoder with pixel-set encoders (PSE) is successfully applied to randomly sampled pixels of crop parcels in [38].",
                "Third, we follow [38] by randomly sampling pixels from a parcel as input to a temporal self-attention model.",
                "PselTae/PseTae with Planet Fusion data are the best performing models but only reach an accuracy of about two-thirds.",
                "A third variant of spatial and temporal encoding has been proposed by [12, 38] where fspat is implemented as a Pixel Set Encoder (Pse).",
                "This combination yields the PseTae [38] and a light-weight variant PseLTae [12].",
                "One of the only approaches which manage this is based on pixel-set encoding and temporal self-attention [12, 38] with a high score of about 2/3 in accuracy.",
                "S1 and S2 with hand-crafted features on their own reach accuracies of 58% and 59% respectively and 62% combined which surpasses all deep-learning models but PseLTae, PseTae and TempCNN with pixel average."
            ],
            "citingPaper": {
                "paperId": "f8dbc9488e120eccab7a8661063b4a5b1201faed",
                "externalIds": {
                    "DBLP": "conf/nips/KondmannTRCPMML21",
                    "CorpusId": 244712079
                },
                "corpusId": 244712079,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f8dbc9488e120eccab7a8661063b4a5b1201faed",
                "title": "DENETHOR: The DynamicEarthNET dataset for Harmonized, inter-Operable, analysis-Ready, daily crop monitoring from space",
                "abstract": "Recent advances in remote sensing products allow near-real time monitoring of the Earth\u2019s surface. Despite the increasing availability of near-daily time series of satellite imagery, there has been little exploration of deep learning methods to utilize the unprecedented temporal density of observations. This is particularly interesting in crop monitoring where time series remote sensing data has been used frequently to exploit phenological differences of crops in the growing cycle over time. In this work, we present DENETHOR: The DynamicEarthNET2 dataset for Harmonized, inter-Operable, analysis-Ready, daily crop monitoring from space. Our dataset contains daily, analysis-ready Planet Fusion data together with Sentinel-1 radar and Sentinel-2 optical time series for crop type classification in Northern Germany. Our baseline experiments underline that incorporating the available spatial and temporal information fully may not be straightforward and could require the design of tailored architectures. The dataset presents two main challenges to the community: Exploit the temporal dimension for improved crop classification and ensure that models can handle a domain shift to a different year.3",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2037791077",
                        "name": "L. Kondmann"
                    },
                    {
                        "authorId": "2004147017",
                        "name": "Aysim Toker"
                    },
                    {
                        "authorId": "35469144",
                        "name": "M. Ru\u00dfwurm"
                    },
                    {
                        "authorId": "144089346",
                        "name": "Andr\u00e9s Camero"
                    },
                    {
                        "authorId": "2164196366",
                        "name": "Devis Peressuti"
                    },
                    {
                        "authorId": "2827262",
                        "name": "G. Milcinski"
                    },
                    {
                        "authorId": "38936813",
                        "name": "P. Mathieu"
                    },
                    {
                        "authorId": "1802979",
                        "name": "N. Long\u00e9p\u00e9"
                    },
                    {
                        "authorId": "2149907571",
                        "name": "T. Davis"
                    },
                    {
                        "authorId": "145714260",
                        "name": "G. Marchisio"
                    },
                    {
                        "authorId": "1388407684",
                        "name": "L. Leal-Taix\u00e9"
                    },
                    {
                        "authorId": "46875623",
                        "name": "Xiaoxiang Zhu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "02ea86cf10d7d910ac7ad6ca8ef3907e1e449095",
                "externalIds": {
                    "MAG": "3110829070",
                    "DOI": "10.1016/j.isprsjprs.2020.11.007",
                    "CorpusId": 230538927
                },
                "corpusId": 230538927,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/02ea86cf10d7d910ac7ad6ca8ef3907e1e449095",
                "title": "Fully convolutional recurrent networks for multidate crop recognition from multitemporal image sequences",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2150381455",
                        "name": "J. A. C. Martinez"
                    },
                    {
                        "authorId": "145928656",
                        "name": "L. E. L. Rosa"
                    },
                    {
                        "authorId": "2017816",
                        "name": "R. Feitosa"
                    },
                    {
                        "authorId": "152775943",
                        "name": "I. Sanches"
                    },
                    {
                        "authorId": "2222679",
                        "name": "P. Happ"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "1673d8f9ff3f3363f68bf9a76217243317813fa9",
                "externalIds": {
                    "DBLP": "journals/staeors/YuanL21",
                    "DOI": "10.1109/JSTARS.2020.3036602",
                    "CorpusId": 230996931
                },
                "corpusId": 230996931,
                "publicationVenue": {
                    "id": "849b6687-df71-4d12-9c46-59f45d5ce951",
                    "name": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE J Sel Top Appl Earth Obs Remote Sens"
                    ],
                    "issn": "1939-1404",
                    "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=4609443",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4609443"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1673d8f9ff3f3363f68bf9a76217243317813fa9",
                "title": "Self-Supervised Pretraining of Transformers for Satellite Image Time Series Classification",
                "abstract": "Satellite image time series (SITS) classification is a major research topic in remote sensing and is relevant for a wide range of applications. Deep learning approaches have been commonly employed for the SITS classification and have provided state-of-the-art performance. However, deep learning methods suffer from overfitting when labeled data are scarce. To address this problem, we propose a novel self-supervised pretraining scheme to initialize a transformer-based network by utilizing large-scale unlabeled data. In detail, the model is asked to predict randomly contaminated observations given an entire time series of a pixel. The main idea of our proposal is to leverage the inherent temporal structure of satellite time series to learn general-purpose spectral-temporal representations related to land cover semantics. Once pretraining is completed, the pretrained network can be further adapted to various SITS classification tasks by fine-tuning all the model parameters on small-scale task-related labeled data. In this way, the general knowledge and representations about SITS can be transferred to a label-scarce task, thereby improving the generalization performance of the model as well as reducing the risk of overfitting. Comprehensive experiments have been carried out on three benchmark datasets over large study areas. Experimental results demonstrate the effectiveness of the proposed pretraining scheme, leading to substantial improvements in classification accuracy using transformer, 1-D convolutional neural network, and bidirectional long short-term memory network. The code and the pretrained model will be available at https://github.com/linlei1214/SITS-BERT upon publication.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2116525477",
                        "name": "Yuan Yuan"
                    },
                    {
                        "authorId": "46456296",
                        "name": "Lei Lin"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "In [18], the authors presented an architecture including pixelset and temporal attention encoders in order to improve classification precision for satellite image time series."
            ],
            "citingPaper": {
                "paperId": "cdca2b7745cb2a35db5f8120f334a75cc4be172f",
                "externalIds": {
                    "DBLP": "journals/access/KimLLHY21",
                    "DOI": "10.1109/ACCESS.2021.3074640",
                    "CorpusId": 233433975
                },
                "corpusId": 233433975,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/cdca2b7745cb2a35db5f8120f334a75cc4be172f",
                "title": "An Alternating Training Method of Attention-Based Adapters for Visual Explanation of Multi-Domain Satellite Images",
                "abstract": "Recently, satellite image analytics based on convolutional neural networks have been vigorously investigated; however, in order for the artificial intelligence systems to be applied in practice, there still exists several challenges: (a) model explanability to improve the reliability of the artificial intelligence system by providing the evidence for the prediction results; (b) dealing with domain shift among images captured by multiple satellites of which the specification of the image sensors is various. To resolve the two issues in the development of a deep model for satellite image analytics, in this paper we propose a multi-domain learning method based on attention-based adapters. As plug-ins to the backbone network, the adapter modules are designed to extract domain-specific features as well as improve visual attention for input images. In addition, we also discuss an alternating training strategy of the backbone network and the adapters in order to effectively separate domain-invariant features and -specific features, respectively. Finally, we utilize Grad-CAM/LIME to provide visual explanation on the proposed network architecture. The experimental results demonstrate that the proposed method can be used to improve test accuracy, and its enhancement in visual explanability is also validated.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2154889891",
                        "name": "Heejae Kim"
                    },
                    {
                        "authorId": "1471725904",
                        "name": "Kyungchae Lee"
                    },
                    {
                        "authorId": "2115470851",
                        "name": "Changha Lee"
                    },
                    {
                        "authorId": "9274432",
                        "name": "Sanghyun Hwang"
                    },
                    {
                        "authorId": "1715960",
                        "name": "Chan-Hyun Youn"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "3ca94b252036bec5f4002749937b08b67f704132",
                "externalIds": {
                    "DBLP": "journals/cviu/ChelaliKPV21",
                    "DOI": "10.1016/j.cviu.2021.103221",
                    "CorpusId": 235613597
                },
                "corpusId": 235613597,
                "publicationVenue": {
                    "id": "5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                    "name": "Computer Vision and Image Understanding",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Vis Image Underst"
                    ],
                    "issn": "1077-3142",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/10773142",
                        "http://www.idealibrary.com/links/toc/cviu",
                        "https://www.journals.elsevier.com/computer-vision-and-image-understanding"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3ca94b252036bec5f4002749937b08b67f704132",
                "title": "Deep-STaR: Classification of image time series based on spatio-temporal representations",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1396167230",
                        "name": "Mohamed Chelali"
                    },
                    {
                        "authorId": "2255097",
                        "name": "Camille Kurtz"
                    },
                    {
                        "authorId": "2050456759",
                        "name": "A. Puissant"
                    },
                    {
                        "authorId": "145645182",
                        "name": "N. Vincent"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "There were also several attempts to jointly exploit the spatial and temporal dimensions of SITS data by the means of deep learning [5, 6, 7]."
            ],
            "citingPaper": {
                "paperId": "3f8a64b6b83f2cefbf02b7b75c856ff833de3c30",
                "externalIds": {
                    "CorpusId": 246062651
                },
                "corpusId": 246062651,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3f8a64b6b83f2cefbf02b7b75c856ff833de3c30",
                "title": "Learning and analyzing spatio-temporal objects from high resolution satellite image time series",
                "abstract": "Context On March 7, 2017, the European Space Agency (ESA) successfully put its latest highresolution satellite Sentinel-2B into orbit. The two Sentinel-2 satellites are now capturing images of all emerged surfaces every 2 to 5 days at high spatial and spectral resolutions, which makes it possible to monitor the evolution of land surfaces on a global scale. Satellite image time series (SITS) extracted from Sentinel-2 constellations are useful for many applications such as land cover mapping [1], crop type mapping, soil moisture estimation, burnt area detection, and many more. Similarly, high resolution satellite image time series, such as the one provided by Pl\u00e9iades, are relevant for urban area analysis, disaster risk management, and rapid mapping.",
                "year": 2021,
                "authors": []
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Very recently, inspired by the Transformer scaling successes in NLP [10], researches have also successfully developed their Transformerbased or attention-based models for time series analysis task, such as video understanding [11], forecasting of multivariate time series data [14, 15], satellite image time series classification [12], and hyperspectral image (HSI) classification [16].",
                "[12] proposed a spatio-temporal classifier for automatic classification of satellite image time series, in which a Pixel-Set Encoder is used to extract spatial features, and a self-attention-based temporal encoder is used to extract temporal features."
            ],
            "citingPaper": {
                "paperId": "a325f02e6f9e99fd6f98e65f714e10e124fd160d",
                "externalIds": {
                    "DBLP": "conf/iccsa/SunBH21",
                    "DOI": "10.1007/978-3-030-87013-3_5",
                    "CorpusId": 237550734
                },
                "corpusId": 237550734,
                "publicationVenue": {
                    "id": "a210e09f-0ea1-4863-bc9c-75ddc51197ac",
                    "name": "Communication Systems and Applications",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Computer Sciences and Applications",
                        "Commun Syst Appl",
                        "International Conference on Complex Systems and Applications",
                        "CSA",
                        "Int Conf Comput Sci Appl",
                        "Conf Comput Syst Appl",
                        "ICCSA",
                        "Comput Sci it Appl",
                        "Int Conf Comput Sci It Appl",
                        "Conference on Computing Systems and Applications",
                        "International Conference on Computer Science and its Applications",
                        "Int Conf Comput Sci it Appl",
                        "Computer Science and its Applications",
                        "International Conference on Computational Science and Its Applications",
                        "Int Conf Complex Syst Appl"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=587",
                    "alternate_urls": [
                        "http://www.iccsa.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a325f02e6f9e99fd6f98e65f714e10e124fd160d",
                "title": "Machine Learning Applied for Spectra Classification",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2116970038",
                        "name": "Yue Sun"
                    },
                    {
                        "authorId": "3333900",
                        "name": "S. Brockhauser"
                    },
                    {
                        "authorId": "2076092",
                        "name": "P\u00e9ter Heged\u00fcs"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": true,
            "contexts": [
                "\u2026datasets with fine-grained class hierarchies: image classification on CIFAR100 (Krizhevsky et al., 2009) and iNaturalist-19 (Van Horn et al., 2018), RGB-D image segmentation on NYUDv2 (Nathan Silberman & Fergus, 2012), and image sequence classification on S2-Agri (Sainte Fare Garnot et al., 2020).",
                "We evaluate our approach with different tasks on public datasets with fine-grained class hierarchies: image classification on CIFAR100 (Krizhevsky et al., 2009) and iNaturalist-19 (Van Horn et al., 2018), RGB-D image segmentation on NYUDv2 (Nathan Silberman & Fergus, 2012), and image sequence classification on S2-Agri (Sainte Fare Garnot et al., 2020).",
                "We use the PSE+TAE architecture (Sainte Fare Garnot et al., 2020) as the backbone, and follow their 5-fold cross-validation scheme for training."
            ],
            "citingPaper": {
                "paperId": "7b1ff72e495dbbe74f5b9b9cb939f3240ba0d723",
                "externalIds": {
                    "CorpusId": 232128409
                },
                "corpusId": 232128409,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/7b1ff72e495dbbe74f5b9b9cb939f3240ba0d723",
                "title": "LEVERAGING CLASS HIERARCHIES",
                "abstract": "In many classification tasks, the set of classes can be organized according to a meaningful hierarchy. This structure can be used to assess the severity of confusing each pair of classes, and summarized under the form of a cost matrix which also defines a finite metric. We propose to integrate this metric in the supervision of a prototypical network in order to model the hierarchical class structure. Our method relies on jointly learning a feature-extracting network and a set of class representations, or prototypes, which incorporate the error metric into their relative arrangement in the embedding space. We show that this simultaneous training allows for consistent improvement of the severity of the network\u2019s errors with regard to the class hierarchy when compared to traditional methods and other prototypebased strategies. Furthermore, when the induced metric contains insight on the data structure, our approach improves the overall precision as well. Experiments on four different public datasets\u2014from agricultural time series classification to depth image semantic segmentation\u2014validate our approach.",
                "year": 2020,
                "authors": []
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "27f04fbdd6d25b5a97d311389bf5ddc77fe7a891",
                "externalIds": {
                    "DBLP": "conf/pkdd/2020aaltd",
                    "DOI": "10.1007/978-3-030-65742-0",
                    "CorpusId": 229163575
                },
                "corpusId": 229163575,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/27f04fbdd6d25b5a97d311389bf5ddc77fe7a891",
                "title": "Advanced Analytics and Learning on Temporal Data: 5th ECML PKDD Workshop, AALTD 2020, Ghent, Belgium, September 18, 2020, Revised Selected Papers",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "145359583",
                        "name": "V. Lemaire"
                    },
                    {
                        "authorId": "1855939",
                        "name": "S. Malinowski"
                    },
                    {
                        "authorId": "35095340",
                        "name": "A. Bagnall"
                    },
                    {
                        "authorId": "1678805",
                        "name": "T. Guyet"
                    },
                    {
                        "authorId": "2576923",
                        "name": "R. Tavenard"
                    },
                    {
                        "authorId": "2203428",
                        "name": "Georgiana Ifrim"
                    }
                ]
            }
        }
    ]
}