{
    "offset": 0,
    "data": [
        {
            "contexts": [
                "[2, 17, 18, 21, 22, 34, 43] extract table elements (cells or text lines) first, then employ a graph network to learn the relation of the extracted table elements."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3e797270bd42586b0e46ce597a5ef6d754465e43",
                "externalIds": {
                    "ArXiv": "2309.14962",
                    "CorpusId": 262825477
                },
                "corpusId": 262825477,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3e797270bd42586b0e46ce597a5ef6d754465e43",
                "title": "GridFormer: Towards Accurate Table Structure Recognition via Grid Prediction",
                "abstract": "All tables can be represented as grids. Based on this observation, we propose GridFormer, a novel approach for interpreting unconstrained table structures by predicting the vertex and edge of a grid. First, we propose a flexible table representation in the form of an MXN grid. In this representation, the vertexes and edges of the grid store the localization and adjacency information of the table. Then, we introduce a DETR-style table structure recognizer to efficiently predict this multi-objective information of the grid in a single shot. Specifically, given a set of learned row and column queries, the recognizer directly outputs the vertexes and edges information of the corresponding rows and columns. Extensive experiments on five challenging benchmarks which include wired, wireless, multi-merge-cell, oriented, and distorted tables demonstrate the competitive performance of our model over other methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "10344582",
                        "name": "Pengyuan Lyu"
                    },
                    {
                        "authorId": "47121217",
                        "name": "Weihong Ma"
                    },
                    {
                        "authorId": "2109798334",
                        "name": "Hongyi Wang"
                    },
                    {
                        "authorId": "1631405123",
                        "name": "Yu Yu"
                    },
                    {
                        "authorId": "2248958848",
                        "name": "Chengquan Zhang"
                    },
                    {
                        "authorId": "2140371004",
                        "name": "Kun Yao"
                    },
                    {
                        "authorId": "2114922667",
                        "name": "Yang Xue"
                    },
                    {
                        "authorId": "1688516",
                        "name": "Jingdong Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fd32bc409bcb26d5c4a370febbc01772a205db1a",
                "externalIds": {
                    "DBLP": "conf/kdd/JiaGJYDMSLZIH023",
                    "DOI": "10.1145/3580305.3599366",
                    "CorpusId": 260500102
                },
                "corpusId": 260500102,
                "publicationVenue": {
                    "id": "a0edb93b-1e95-4128-a295-6b1659149cef",
                    "name": "Knowledge Discovery and Data Mining",
                    "type": "conference",
                    "alternate_names": [
                        "KDD",
                        "Knowl Discov Data Min"
                    ],
                    "url": "http://www.acm.org/sigkdd/"
                },
                "url": "https://www.semanticscholar.org/paper/fd32bc409bcb26d5c4a370febbc01772a205db1a",
                "title": "GetPt: Graph-enhanced General Table Pre-training with Alternate Attention Network",
                "abstract": "Tables are widely used for data storage and presentation due to their high flexibility in layout. The importance of tables as information carriers and the complexity of tabular data understanding attract a great deal of research on large-scale pre-training for tabular data. However, most of the works design models for specific types of tables, such as relational tables and tables with well-structured headers, neglecting tables with complex layouts. In real-world scenarios, there are many such tables beyond their target scope that cannot be well supported. In this paper, we propose GetPt, a unified pre-training architecture for general table representation applicable even to tables with complex structures and layouts. First, we convert a table to a heterogeneous graph with multiple types of edges to represent the layout of the table. Based on the graph, a specially designed transformer is applied to jointly model the semantics and structure of the table. Second, we devise the Alternate Attention Network (AAN) to better model the contextual information across multiple granularities of a table including tokens, cells, and the table. To better support a wide range of downstream tasks, we further employ three pre-training objectives and pre-train the model on a large table dataset. We fine-tune and evaluate GetPt model on two representative tasks, table type classification, and table structure recognition. Experiments show that GetPt outperforms existing state-of-the-art methods on these tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2053919577",
                        "name": "Ran Jia"
                    },
                    {
                        "authorId": "2110878453",
                        "name": "Haoming Guo"
                    },
                    {
                        "authorId": "2219019849",
                        "name": "Xiaoyu Jin"
                    },
                    {
                        "authorId": "2227588659",
                        "name": "Chao Yan"
                    },
                    {
                        "authorId": "12723949",
                        "name": "Lun Du"
                    },
                    {
                        "authorId": "150344398",
                        "name": "Xiaojun Ma"
                    },
                    {
                        "authorId": "2214758877",
                        "name": "Tamara Stankovic"
                    },
                    {
                        "authorId": "2227564157",
                        "name": "Marko Lozajic"
                    },
                    {
                        "authorId": "2227571357",
                        "name": "Goran Zoranovic"
                    },
                    {
                        "authorId": "2064579585",
                        "name": "Igor Ilic"
                    },
                    {
                        "authorId": "2109750123",
                        "name": "Shi Han"
                    },
                    {
                        "authorId": "2140415600",
                        "name": "Dongmei Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "tional architecture, like graph network [Xue et al., 2021] or rule-based post-processing strategies [Qiao et al."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "13de1c39dfe5733363ff1a8d4c6d577914f79618",
                "externalIds": {
                    "DBLP": "conf/ijcai/ShenGWQZLC23",
                    "DOI": "10.24963/ijcai.2023/152",
                    "CorpusId": 260853966
                },
                "corpusId": 260853966,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/13de1c39dfe5733363ff1a8d4c6d577914f79618",
                "title": "Divide Rows and Conquer Cells: Towards Structure Recognition for Large Tables",
                "abstract": "Recent advanced Table Structure Recognition (TSR) models adopt image-to-text solutions to parse table structure. These methods can be formulated as image caption problem, i.e., input a single-table image and output table structure description in a specific text format, e.g., HTML. With the impressive success of Transformer in text generation tasks, these methods use Transformer architecture to predict HTML table text in an autoregressive manner. However, tables always emerge with a large variety of shapes and sizes. Autoregressive models usually suffer from the error accumulation problem as the length of predicted text increases, which results in unsatisfactory performance for large tables. In this paper, we propose a novel image-to-text based TSR method that relieves error accumulation problems and improves performance noticeably. At the core of our method is a cascaded two-step decoder architecture with the former decoder predicting HTML table row tags non-autoregressively and the latter predicting HTML table cell tags of each row in a semi-autoregressive manner. Compared with existing methods that predict HTML text autoregressively, the superiority of our row-to-cell progressive table parsing is twofold: (1) it generates an HTML tag sequence with a vertical-and-horizontal two-step `scanning', which better fits the inherent 2D structure of image data, (2) it performs substantially better for large tables (long sequence prediction) since it alleviates error accumulation problem specific to autoregressive models. Extensive experiments demonstrate that our method achieves competitive performance on three public benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2230137426",
                        "name": "Huawen Shen"
                    },
                    {
                        "authorId": "2149397987",
                        "name": "Xiang Gao"
                    },
                    {
                        "authorId": "2111524263",
                        "name": "Jin Wei"
                    },
                    {
                        "authorId": "2065512194",
                        "name": "Liang Qiao"
                    },
                    {
                        "authorId": "49454803",
                        "name": "Yu Zhou"
                    },
                    {
                        "authorId": "2229647956",
                        "name": "Qiang Li"
                    },
                    {
                        "authorId": "2398015",
                        "name": "Zhanzhan Cheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Additionally, graph convolutional networks [4] are used to parse table structures."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fa96163c2be80d9f4163e78e2945be051092e0c1",
                "externalIds": {
                    "DBLP": "conf/cscwd/YanTZP023",
                    "DOI": "10.1109/CSCWD57460.2023.10152650",
                    "CorpusId": 259235595
                },
                "corpusId": 259235595,
                "publicationVenue": {
                    "id": "a966c5e8-76dc-45c0-942a-3c7e41ac9b1a",
                    "name": "International Conference on Computer Supported Cooperative Work in Design",
                    "type": "conference",
                    "alternate_names": [
                        "Computer Supported Cooperative Work in Design",
                        "Int Conf Comput Support Cooperative Work Des",
                        "CSCWD",
                        "Comput Support Cooperative Work Des"
                    ],
                    "url": "http://www.cscwd.org/"
                },
                "url": "https://www.semanticscholar.org/paper/fa96163c2be80d9f4163e78e2945be051092e0c1",
                "title": "A Novel Encoder-Decoder Architecture for Table Border Segmentation of Scanned Documents",
                "abstract": "Robotic Process Automation (RPA) has been widely used in business and enterprises to automate the processing of digital documents and collect information and acquire knowledge. Table structure reconstruction in scanned documents has been extensively studied as an essential application of RPA. However, the detection of table borders often ignores broken borders, which makes it unsuitable for natural scenes. To address this, our paper heavily employs a data augmentation approach to synthesize fake scanned documents to train our table-border semantic segmentation model. We propose a novel segmentation model for table borders based on semantic segmentation. We compare traditional morphology-based line detection algorithms with existing semantic segmentation-based approaches. The results indicate that our proposed algorithm can solve the frame line detection problem effectively, even for low-quality scanned images. Actual cases show that we can reconstruct the table\u2019s structure and obtain the knowledge in the table.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2047542417",
                        "name": "Kaihong Yan"
                    },
                    {
                        "authorId": "2153135475",
                        "name": "Hao Tang"
                    },
                    {
                        "authorId": "47539632",
                        "name": "Jing Zhang"
                    },
                    {
                        "authorId": "2072677041",
                        "name": "Peng Peng"
                    },
                    {
                        "authorId": "2154853698",
                        "name": "Hongwei Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Graph Neural Network (GNN) based methods [3,6,17,18], as the name suggests, represent tables as graph structures.",
                "On the other hand, the problem of table structure recognition (TSR) is a lot more challenging and remains a very active area of research, in which many novel machine learning algorithms are being explored [3,4,5,9,11,12,13,14,17,18,21,22]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "88b556a6108b98cd0e12ae2945cc6597fff9101c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-03393",
                    "ArXiv": "2305.03393",
                    "DOI": "10.48550/arXiv.2305.03393",
                    "CorpusId": 258546918
                },
                "corpusId": 258546918,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/88b556a6108b98cd0e12ae2945cc6597fff9101c",
                "title": "Optimized Table Tokenization for Table Structure Recognition",
                "abstract": "Extracting tables from documents is a crucial task in any document conversion pipeline. Recently, transformer-based models have demonstrated that table-structure can be recognized with impressive accuracy using Image-to-Markup-Sequence (Im2Seq) approaches. Taking only the image of a table, such models predict a sequence of tokens (e.g. in HTML, LaTeX) which represent the structure of the table. Since the token representation of the table structure has a significant impact on the accuracy and run-time performance of any Im2Seq model, we investigate in this paper how table-structure representation can be optimised. We propose a new, optimised table-structure language (OTSL) with a minimized vocabulary and specific rules. The benefits of OTSL are that it reduces the number of tokens to 5 (HTML needs 28+) and shortens the sequence length to half of HTML on average. Consequently, model accuracy improves significantly, inference time is halved compared to HTML-based models, and the predicted table structures are always syntactically correct. This in turn eliminates most post-processing needs.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1578242957",
                        "name": "Maksym Lysak"
                    },
                    {
                        "authorId": "73241238",
                        "name": "Ahmed Nassar"
                    },
                    {
                        "authorId": "2051177400",
                        "name": "Nikolaos Livathinos"
                    },
                    {
                        "authorId": "2065064783",
                        "name": "Christoph Auer"
                    },
                    {
                        "authorId": "1831851",
                        "name": "P. Staar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[27] [28] [29] [30] share the identical GNN structure."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "df9045c28a2aa3e7fc76edb3620424ad19912265",
                "externalIds": {
                    "ArXiv": "2304.11810",
                    "DBLP": "journals/corr/abs-2304-11810",
                    "DOI": "10.48550/arXiv.2304.11810",
                    "CorpusId": 258298306
                },
                "corpusId": 258298306,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/df9045c28a2aa3e7fc76edb3620424ad19912265",
                "title": "PARAGRAPH2GRAPH: A GNN-based framework for layout paragraph analysis",
                "abstract": "Document layout analysis has a wide range of requirements across various domains, languages, and business scenarios. However, most current state-of-the-art algorithms are language-dependent, with architectures that rely on transformer encoders or language-specific text encoders, such as BERT, for feature extraction. These approaches are limited in their ability to handle very long documents due to input sequence length constraints and are closely tied to language-specific tokenizers. Additionally, training a cross-language text encoder can be challenging due to the lack of labeled multilingual document datasets that consider privacy. Furthermore, some layout tasks require a clean separation between different layout components without overlap, which can be difficult for image segmentation-based algorithms to achieve. In this paper, we present Paragraph2Graph, a language-independent graph neural network (GNN)-based model that achieves competitive results on common document layout datasets while being adaptable to business scenarios with strict separation. With only 19.95 million parameters, our model is suitable for industrial applications, particularly in multi-language scenarios.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2042743634",
                        "name": "Shuyong Wei"
                    },
                    {
                        "authorId": "73580202",
                        "name": "Nuo Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The code of one paper (TGRNet; [35]) was executable after we contacted the original authors.",
                "[16]7 2021 Multi-Type -TD-TSR KI ICDAR 2019 ICDAR 2019 Track-B2 X X R Xue et al.[35]8 2021 TGRNet ICCV TableGraph ICDAR 2019 X X R"
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "50903f5f5e714e5746152b3e369c9329655e0018",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-10439",
                    "ArXiv": "2304.10439",
                    "DOI": "10.48550/arXiv.2304.10439",
                    "CorpusId": 258236507
                },
                "corpusId": 258236507,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/50903f5f5e714e5746152b3e369c9329655e0018",
                "title": "A Study on Reproducibility and Replicability of Table Structure Recognition Methods",
                "abstract": "Concerns about reproducibility in artificial intelligence (AI) have emerged, as researchers have reported unsuccessful attempts to directly reproduce published findings in the field. Replicability, the ability to affirm a finding using the same procedures on new data, has not been well studied. In this paper, we examine both reproducibility and replicability of a corpus of 16 papers on table structure recognition (TSR), an AI task aimed at identifying cell locations of tables in digital documents. We attempt to reproduce published results using codes and datasets provided by the original authors. We then examine replicability using a dataset similar to the original as well as a new dataset, GenTSR, consisting of 386 annotated tables extracted from scientific papers. Out of 16 papers studied, we reproduce results consistent with the original in only four. Two of the four papers are identified as replicable using the similar dataset under certain IoU values. No paper is identified as replicable using the new dataset. We offer observations on the causes of irreproducibility and irreplicability. All code and data are available on Codeocean at https://codeocean.com/capsule/6680116/tree.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "11359490",
                        "name": "Kehinde E. Ajayi"
                    },
                    {
                        "authorId": "2214808132",
                        "name": "Muntabhir Hasan Choudhury"
                    },
                    {
                        "authorId": "2528276",
                        "name": "S. Rajtmajer"
                    },
                    {
                        "authorId": "97569165",
                        "name": "Jian Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "TGRNet [9] designed a network to jointly predict the spatial locations and spanning information of table cells."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3e0c97baa8e7b629a3d689e00aa21b94e2193766",
                "externalIds": {
                    "ArXiv": "2303.11615",
                    "DBLP": "journals/corr/abs-2303-11615",
                    "DOI": "10.48550/arXiv.2303.11615",
                    "CorpusId": 257636821
                },
                "corpusId": 257636821,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3e0c97baa8e7b629a3d689e00aa21b94e2193766",
                "title": "Robust Table Structure Recognition with Dynamic Queries Enhanced Detection Transformer",
                "abstract": "We present a new table structure recognition (TSR) approach, called TSRFormer, to robustly recognizing the structures of complex tables with geometrical distortions from various table images. Unlike previous methods, we formulate table separation line prediction as a line regression problem instead of an image segmentation problem and propose a new two-stage dynamic queries enhanced DETR based separation line regression approach, named DQ-DETR, to predict separation lines from table images directly. Compared to Vallina DETR, we propose three improvements in DQ-DETR to make the two-stage DETR framework work efficiently and effectively for the separation line prediction task: 1) A new query design, named Dynamic Query, to decouple single line query into separable point queries which could intuitively improve the localization accuracy for regression tasks; 2) A dynamic queries based progressive line regression approach to progressively regressing points on the line which further enhances localization accuracy for distorted tables; 3) A prior-enhanced matching strategy to solve the slow convergence issue of DETR. After separation line prediction, a simple relation network based cell merging module is used to recover spanning cells. With these new techniques, our TSRFormer achieves state-of-the-art performance on several benchmark datasets, including SciTSR, PubTabNet, WTW and FinTabNet. Furthermore, we have validated the robustness and high localization accuracy of our approach to tables with complex structures, borderless cells, large blank spaces, empty or spanning cells as well as distorted or even curved shapes on a more challenging real-world in-house dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2187553093",
                        "name": "Jiawei Wang"
                    },
                    {
                        "authorId": "2108811137",
                        "name": "Weihong Lin"
                    },
                    {
                        "authorId": "2894335",
                        "name": "Chixiang Ma"
                    },
                    {
                        "authorId": "2181111465",
                        "name": "Mingze Li"
                    },
                    {
                        "authorId": "2145130513",
                        "name": "Zhengmao Sun"
                    },
                    {
                        "authorId": "2110833051",
                        "name": "Lei Sun"
                    },
                    {
                        "authorId": "2316043",
                        "name": "Qiang Huo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "First, we compare LORE with models which directly predict logical locations including Res2TIM (Xue, Li, and Tao 2019) and TGRNet (Xue et al. 2021).",
                "We tune the model provided by Xue et al. (2021) on WTW dataset to make a thorough comparison.",
                "The baseline meth-\nods can only produce passable results on relatively simple benchmarks of digital-born table images from scientific articles, i.e., TableGraph-24K.",
                "Xue et al. (2021) propose to perform ordinal classification of logical indices on each detected cell for TSR, which is close to our approach.",
                "Since the markup language has plenty of control sequences formatting styles, they can be viewed as noise in labels and impede model training (Xue et al. 2021).",
                "C V\n] 7\nM ar\n2 02\ncal locations of table cells (Xue et al. 2021).",
                "\u2026(Go\u0308bel et al. 2013), SciTSR-comp (Chi et al. 2019), PubTabNet (Zhong, ShafieiBavani, and Jimeno Yepes 2020),\nTableBank (Li et al. 2020) and TableGraph-24K (Xue et al. 2021), as well as tables from scanned documents and photos, i.e., ICDAR-2019 (Gao et al. 2019) and WTW (Long et al. 2021).",
                "2017) in LORE to avoid making additional assumptions about the distribution of table structure, rather than graph neural networks employed by previous methods (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021), which will be further discussed in experiments.",
                "In experiment 2a, we replace the self-attention encoder with a graph-attention encoder similar to graph-based TSR models (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021) with an equal amount of parameters with LORE.",
                "We evaluate LORE on a wide range of benchmarks, including tables in digital-born documents, i.e., ICDAR-2013 (Go\u0308bel et al. 2013), SciTSR-comp (Chi et al. 2019), PubTabNet (Zhong, ShafieiBavani, and Jimeno Yepes 2020),\nTableBank (Li et al. 2020) and TableGraph-24K (Xue et al. 2021), as well as tables from scanned documents and photos, i.e., ICDAR-2019 (Gao et al. 2019) and WTW (Long et al. 2021).",
                "In this section, we conduct comprehensive experiments to research and answer two key questions: 1) Is the proposed LORE able to effectively predict the logical locations of table cells from input images? 2) Does the LORE framework, modeling TSR as logical location regression, overcome the limitations and cover the abilities of other paradigms? For the first question, we compare LORE with baselines directly predicting logical locations (Xue, Li, and Tao 2019; Xue et al. 2021).",
                "We also report the performance of cell spatial location prediction, using the F-1 score under the IoU threshold of 0.5, following recent works (Raja, Mondal, and Jawahar 2020; Xue et al. 2021).",
                "2020) and TableGraph-24K (Xue et al. 2021), as well as tables from scanned documents and photos, i.",
                "For the first question, we compare LORE with baselines directly predicting logical locations (Xue, Li, and Tao 2019; Xue et al. 2021).",
                "\u2026mechanism (Vaswani et al. 2017) in LORE to avoid making additional assumptions about the distribution of table structure, rather than graph neural networks employed by previous methods (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021), which will be further discussed in experiments."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "a90a77893708ae5070e2ed4572ca9e20837e69c6",
                "externalIds": {
                    "DBLP": "conf/aaai/XingGLBZLYY23",
                    "ArXiv": "2303.03730",
                    "DOI": "10.48550/arXiv.2303.03730",
                    "CorpusId": 257378294
                },
                "corpusId": 257378294,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/a90a77893708ae5070e2ed4572ca9e20837e69c6",
                "title": "LORE: Logical Location Regression Network for Table Structure Recognition",
                "abstract": "Table structure recognition (TSR) aims at extracting tables in images into machine-understandable formats. Recent methods solve this problem by predicting the adjacency relations of detected cell boxes, or learning to generate the corresponding markup sequences from the table images. However, they either count on additional heuristic rules to recover the table structures, or require a huge amount of training data and time-consuming sequential decoders. In this paper, we propose an alternative paradigm. We model TSR as a logical location regression problem and propose a new TSR framework called LORE, standing for LOgical location REgression network, which for the first time combines logical location regression together with spatial location regression of table cells. Our proposed LORE is conceptually simpler, easier to train and more accurate than previous TSR models of other paradigms. Experiments on standard benchmarks demonstrate that LORE consistently outperforms prior arts. Code is available at https:// github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LORE-TSR.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2176894025",
                        "name": "Hangdi Xing"
                    },
                    {
                        "authorId": "2112256",
                        "name": "Feiyu Gao"
                    },
                    {
                        "authorId": "143799988",
                        "name": "Rujiao Long"
                    },
                    {
                        "authorId": "2064698184",
                        "name": "Jiajun Bu"
                    },
                    {
                        "authorId": "2114172383",
                        "name": "Qi Zheng"
                    },
                    {
                        "authorId": "2145730944",
                        "name": "Liangcheng Li"
                    },
                    {
                        "authorId": "2173739231",
                        "name": "Cong Yao"
                    },
                    {
                        "authorId": "2139424603",
                        "name": "Zhi Yu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The #1 instance indicates the cell annotation object located by polygon [[19,202], [92,204], [391,212], [391,227], [168,221], [18,217]], in the tenth row and the first column of table 1 (group id=1), spanning three columns, with the text content \"\u9884\u8ba1\u8d39\u7528\u603b\u989d\"."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a262dae40469c27843dff63ea55e2d8dcfe84ecc",
                "externalIds": {
                    "PubMedCentral": "9950383",
                    "DBLP": "journals/corr/abs-2303-14884",
                    "ArXiv": "2303.14884",
                    "DOI": "10.1038/s41597-023-01985-8",
                    "CorpusId": 257084396,
                    "PubMed": "36823289"
                },
                "corpusId": 257084396,
                "publicationVenue": {
                    "id": "62924b2a-8fb8-4b93-92c6-735516b49af0",
                    "name": "Scientific Data",
                    "type": "journal",
                    "alternate_names": [
                        "Sci Data"
                    ],
                    "issn": "2052-4463",
                    "url": "http://www.nature.com/sdata/"
                },
                "url": "https://www.semanticscholar.org/paper/a262dae40469c27843dff63ea55e2d8dcfe84ecc",
                "title": "A large-scale dataset for end-to-end table recognition in the wild",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47829900",
                        "name": "Fan Yang"
                    },
                    {
                        "authorId": "2209192190",
                        "name": "Lei Hu"
                    },
                    {
                        "authorId": "2189361599",
                        "name": "Xinwu Liu"
                    },
                    {
                        "authorId": "1860840",
                        "name": "Shuangping Huang"
                    },
                    {
                        "authorId": "9238882",
                        "name": "Z. Gu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Reference [9] proposed a table graph reconstruction network for table structure recognition (TGRNet), which uses ResNet50 [10] to extract the rows and columns of the table image and the features of the original image for fusion, predicting the spatial coordinates, and used the graph convolutional networks (GCN) [11] to predict the logical coordinates."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5c3c2ac444019a96edff6ac60329aea3ef43d359",
                "externalIds": {
                    "DOI": "10.3390/electronics12030673",
                    "CorpusId": 256454161
                },
                "corpusId": 256454161,
                "publicationVenue": {
                    "id": "ccd8e532-73c6-414f-bc91-271bbb2933e2",
                    "name": "Electronics",
                    "type": "journal",
                    "issn": "1450-5843",
                    "alternate_issns": [
                        "2079-9292",
                        "0883-4989"
                    ],
                    "url": "http://www.electronics.etfbl.net/",
                    "alternate_urls": [
                        "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-247562",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-247562",
                        "https://www.mdpi.com/journal/electronics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5c3c2ac444019a96edff6ac60329aea3ef43d359",
                "title": "Table Structure Recognition Method Based on Lightweight Network and Channel Attention",
                "abstract": "The table recognition model rows and columns aggregated network (RCANet) uses a semantic segmentation approach to recognize table structure, and achieves better performance in table row and column segmentation. However, this model uses ResNet18 as the backbone network, and the model has 11.35 million parameters and a volume of 45.5 M, which is inconvenient to deploy to lightweight servers or mobile terminals. Therefore, from the perspective of model compression, this paper proposes the lightweight rows and columns attention aggregated network (LRCAANet), which uses the lightweight network ShuffleNetv2 to replace the original RCANet backbone network ResNet18 to simplify the model size. Considering that the lightweight network reduces the number of feature channels, it has a certain impact on the performance of the model. In order to strengthen the learning between feature channels, the rows attention aggregated (RAA) module and the columns attention aggregated (CAA) module are proposed. The RAA module and the CAA module add the squeeze and excitation (SE) module to the original row and column aggregated modules, respectively. Adding the SE module means the model can learn the correlation between channels and improve the prediction effect of the lightweight model. The experimental results show that our method greatly reduces the model parameters and model volume while ensuring low-performance loss. In the end, the average F1 score of our model is only 1.77% lower than the original model, the parameters are only 0.17 million, and the volume is only 0.8 M. Compared with the original model, the parameter amount and volume are reduced by more than 95%.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "103245682",
                        "name": "T. Zhang"
                    },
                    {
                        "authorId": "48184603",
                        "name": "Yi Sui"
                    },
                    {
                        "authorId": "1821383",
                        "name": "Shunyao Wu"
                    },
                    {
                        "authorId": "2096258",
                        "name": "Fengjing Shao"
                    },
                    {
                        "authorId": "39447552",
                        "name": "Rencheng Sun"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ca2fabed8604b296d713262794a427e5c4b51ffa",
                "externalIds": {
                    "DBLP": "journals/apin/WanZLZS23",
                    "DOI": "10.1007/s10489-022-04420-4",
                    "CorpusId": 255362168
                },
                "corpusId": 255362168,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ca2fabed8604b296d713262794a427e5c4b51ffa",
                "title": "Contextual transformer sequence-based recognition network for medical examination reports",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "152912519",
                        "name": "Honglin Wan"
                    },
                    {
                        "authorId": "2199057485",
                        "name": "Zongfeng Zhong"
                    },
                    {
                        "authorId": "2263987",
                        "name": "Tianping Li"
                    },
                    {
                        "authorId": "2856513",
                        "name": "Huaxiang Zhang"
                    },
                    {
                        "authorId": "51299154",
                        "name": "Jiande Sun"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[34, 37, 45, 66] treat these cells as nodes in a graph and train another Graph Neural Network (GNN) to predict the relations."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4ebf44ebb9634cb5c60f5dc7fab0c0f84aed0939",
                "externalIds": {
                    "DBLP": "conf/mm/LiL0LCNPL22",
                    "DOI": "10.1145/3503161.3547885",
                    "CorpusId": 252782335
                },
                "corpusId": 252782335,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4ebf44ebb9634cb5c60f5dc7fab0c0f84aed0939",
                "title": "End-to-End Compound Table Understanding with Multi-Modal Modeling",
                "abstract": "Table is a widely used data form in webpages, spreadsheets, or PDFs to organize and present structural data. Although studies on table structure recognition have been successfully used to convert image-based tables into digital structural formats, solving many real problems still relies on further understanding of the table, such as cell relationship extraction. The current datasets related to table understanding are all based on the digit format. To boost research development, we release a new benchmark named ComFinTab with rich annotations that support both table recognition and understanding tasks. Unlike previous datasets containing the basic tables, ComFinTab contains a large ratio of compound tables, which is much more challenging and requires methods using multiple information sources. Based on the dataset, we also propose a uniform, concise task form with the evaluation metric to better evaluate the model's performance on the table understanding task in compound tables. Finally, a framework named CTUNet is proposed to integrate the compromised visual, semantic, and position features with a graph attention network, which can solve the table recognition task and the challenging table understanding task as a whole. Experimental results compared with some previous advanced table understanding methods demonstrate the effectiveness of our proposed model. Code and dataset are available at \\urlhttps://github.com/hikopensource/DAVAR-Lab-OCR.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109614687",
                        "name": "Zaisheng Li"
                    },
                    {
                        "authorId": "2187429408",
                        "name": "Yi Li"
                    },
                    {
                        "authorId": "2187308758",
                        "name": "Qiao Liang"
                    },
                    {
                        "authorId": "2144902872",
                        "name": "Pengfei Li"
                    },
                    {
                        "authorId": "2398015",
                        "name": "Zhanzhan Cheng"
                    },
                    {
                        "authorId": "1490934795",
                        "name": "Yi Niu"
                    },
                    {
                        "authorId": "3290437",
                        "name": "Shiliang Pu"
                    },
                    {
                        "authorId": "2116227961",
                        "name": "Xi Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "have emerged as a powerful tool to tackle the problems of Key Information Extraction (KIE) [6,35], Document Layout Analysis (DLA) which includes wellstudied sub-tasks like table detection [25,26], table structure recognition [20,34] and table extraction [9], Visual Question Answering (VQA) [18,17], synthetic document generation [4] and so on."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6357238a07f0904f8279832b59f5b387a4e827f2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-11168",
                    "ArXiv": "2208.11168",
                    "DOI": "10.1007/978-3-031-25069-9_22",
                    "CorpusId": 251765056
                },
                "corpusId": 251765056,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/6357238a07f0904f8279832b59f5b387a4e827f2",
                "title": "Doc2Graph: a Task Agnostic Document Understanding Framework based on Graph Neural Networks",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2182515911",
                        "name": "Andrea Gemelli"
                    },
                    {
                        "authorId": "2150473007",
                        "name": "Sanket Biswas"
                    },
                    {
                        "authorId": "2122367862",
                        "name": "Enrico Civitelli"
                    },
                    {
                        "authorId": "2117637297",
                        "name": "Josep Llad'os"
                    },
                    {
                        "authorId": "3285734",
                        "name": "S. Marinai"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f3b6939ce0244e89656cf6ff93f6dff8b2bef547",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-11203",
                    "ArXiv": "2208.11203",
                    "DOI": "10.1109/ICPR56361.2022.9956590",
                    "CorpusId": 251765514
                },
                "corpusId": 251765514,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f3b6939ce0244e89656cf6ff93f6dff8b2bef547",
                "title": "Graph Neural Networks and Representation Embedding for Table Extraction in PDF Documents",
                "abstract": "Tables are widely used in several types of documents since they can bring important information in a structured way. In scientific papers, tables can sum up novel discoveries and summarize experimental results, making the research comparable and easily understandable by scholars. Several methods perform table analysis working on document images, losing useful information during the conversion from the PDF files since OCR tools can be prone to recognition errors, in particular for text inside tables. The main contribution of this work is to tackle the problem of table extraction, exploiting Graph Neural Networks. Node features are enriched with suitably designed representation embeddings. These representations help to better distinguish not only tables from the other parts of the paper, but also table cells from table headers. We experimentally evaluated the proposed approach on a new dataset obtained by merging the information provided in the PubLayNet and PubTables-1M datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2182515911",
                        "name": "Andrea Gemelli"
                    },
                    {
                        "authorId": "2182519264",
                        "name": "Emanuele Vivoli"
                    },
                    {
                        "authorId": "3285734",
                        "name": "S. Marinai"
                    }
                ]
            }
        },
        {
            "contexts": [
                "TGRNet [50] designed a network to jointly predict the spatial locations and spanning information of table cells."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fb6fcca5762b26f225313f86b1f33a1cf198bfd7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-04921",
                    "ArXiv": "2208.04921",
                    "DOI": "10.1145/3503161.3548038",
                    "CorpusId": 251442367
                },
                "corpusId": 251442367,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fb6fcca5762b26f225313f86b1f33a1cf198bfd7",
                "title": "TSRFormer: Table Structure Recognition with Transformers",
                "abstract": "We present a new table structure recognition (TSR) approach, called TSRFormer, to robustly recognizing the structures of complex tables with geometrical distortions from various table images. Unlike previous methods, we formulate table separation line prediction as a line regression problem instead of an image segmentation problem and propose a new two-stage DETR based separator prediction approach, dubbed Sep arator RE gression TR ansformer (SepRETR), to predict separation lines from table images directly. To make the two-stage DETR framework work efficiently and effectively for the separation line prediction task, we propose two improvements: 1) A prior-enhanced matching strategy to solve the slow convergence issue of DETR; 2) A new cross attention module to sample features from a high-resolution convolutional feature map directly so that high localization accuracy is achieved with low computational cost. After separation line prediction, a simple relation network based cell merging module is used to recover spanning cells. With these new techniques, our TSRFormer achieves state-of-the-art performance on several benchmark datasets, including SciTSR, PubTabNet and WTW. Furthermore, we have validated the robustness of our approach to tables with complex structures, borderless cells, large blank spaces, empty or spanning cells as well as distorted or even curved shapes on a more challenging real-world in-house dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108811137",
                        "name": "Weihong Lin"
                    },
                    {
                        "authorId": "2145130513",
                        "name": "Zhengmao Sun"
                    },
                    {
                        "authorId": "2894335",
                        "name": "Chixiang Ma"
                    },
                    {
                        "authorId": "2181111465",
                        "name": "Mingze Li"
                    },
                    {
                        "authorId": "2110132415",
                        "name": "Jiawei Wang"
                    },
                    {
                        "authorId": "2110833051",
                        "name": "Lei Sun"
                    },
                    {
                        "authorId": "2316043",
                        "name": "Qiang Huo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We take deep-learning-based GAN, CFM, TGRNet, and Faster RCNN, SSD as baselines.",
                "Deep learning-based algorithms such as OSTU + MSVM-rbf (Multi-class Support Vector Machine) [13], GAN [14], CFM [15], TGRNet [16] have achieved good results.",
                "[16] Xue, Wenyuan, et al. \"TGRNet: A Table Graph Reconstruction Network for Table Structure\nRecognition.\""
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ec184571336c4091e563582663b2fc138507197b",
                "externalIds": {
                    "ArXiv": "2207.00589",
                    "DBLP": "journals/corr/abs-2207-00589",
                    "DOI": "10.48550/arXiv.2207.00589",
                    "CorpusId": 250264665
                },
                "corpusId": 250264665,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/ec184571336c4091e563582663b2fc138507197b",
                "title": "SSD-Faster Net: A Hybrid Network for Industrial Defect Inspection",
                "abstract": "The quality of industrial components is critical to the production of special equipment such as robots. Defect inspection of these components is an efficient way to ensure quality. In this paper, we propose a hybrid network, SSD-Faster Net, for industrial defect inspection of rails, insulators, commutators etc. SSD-Faster Net is a two-stage network, including SSD for quickly locating defective blocks, and an improved Faster R-CNN for defect segmentation. For the former, we propose a novel slice localization mechanism to help SSD scan quickly. The second stage is based on improved Faster R-CNN, using FPN, deformable kernel(DK) to enhance representation ability. It fuses multi-scale information, and self-adapts the receptive field. We also propose a novel loss function and use ROI Align to improve accuracy. Experiments show that our SSD-Faster Net achieves an average accuracy of 84.03%, which is 13.42% higher than the nearest competitor based on Faster R-CNN, 4.14% better than GAN-based methods, more than 10% higher than that of DNN-based detectors. And the computing speed is improved by nearly 7%, which proves its robustness and superior performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115891552",
                        "name": "Jingyao Wang"
                    },
                    {
                        "authorId": "1945512",
                        "name": "Naigong Yu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To obtain the table-structure, one creates an initial graph, where each of the text-cells becomes a node in the graph similar to [33, 34, 2]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "081312b993ef1df7e64e1a5f8715852a2e7ed527",
                "externalIds": {
                    "ArXiv": "2203.01017",
                    "DBLP": "journals/corr/abs-2203-01017",
                    "DOI": "10.1109/CVPR52688.2022.00457",
                    "CorpusId": 247218660
                },
                "corpusId": 247218660,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/081312b993ef1df7e64e1a5f8715852a2e7ed527",
                "title": "TableFormer: Table Structure Understanding with Transformers",
                "abstract": "Tables organize valuable content in a concise and compact representation. This content is extremely valuable for systems such as search engines, Knowledge Graph's, etc, since they enhance their predictive capabilities. Unfortu-nately, tables come in a large variety of shapes and sizes. Furthermore, they can have complex column/row-header configurations, multiline rows, different variety of separation lines, missing entries, etc. As such, the correct iden-tification of the table-structure from an image is a nontrivial task. In this paper, we present a new table-structure identification model. The latter improves the latest end-to-end deep learning model (i.e. encoder-dual-decoder from PubTabNet) in two significant ways. First, we introduce a new object detection decoder for table-cells. In this way, we can obtain the content of the table-cells from program-matic PDF's directly from the PDF source and avoid the training of the custom OCR decoders. This architectural change leads to more accurate table-content extraction and allows us to tackle non-english tables. Second, we replace the LSTM decoders with transformer based decoders. This upgrade improves significantly the previous state-of-the-art tree-editing-distance-score (TEDS) from 91% to 98.5% on simple tables and from 88.7% to 95% on complex tables.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "37525891",
                        "name": "A. Nassar"
                    },
                    {
                        "authorId": "2051177400",
                        "name": "Nikolaos Livathinos"
                    },
                    {
                        "authorId": "1578242957",
                        "name": "Maksym Lysak"
                    },
                    {
                        "authorId": "1831851",
                        "name": "P. Staar"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a9e00a1c3de05e3d06a4287b8ef07096f0cfe609",
                "externalIds": {
                    "DBLP": "journals/pr/RibaGTRFL22",
                    "DOI": "10.1016/j.patcog.2022.108641",
                    "CorpusId": 247427729
                },
                "corpusId": 247427729,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a9e00a1c3de05e3d06a4287b8ef07096f0cfe609",
                "title": "Table detection in business document images by message passing networks",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40420775",
                        "name": "Pau Riba"
                    },
                    {
                        "authorId": "145029669",
                        "name": "Lutz Goldmann"
                    },
                    {
                        "authorId": "3045937",
                        "name": "O. R. Terrades"
                    },
                    {
                        "authorId": "1491424368",
                        "name": "Diede Rusticus"
                    },
                    {
                        "authorId": "1686569",
                        "name": "A. Forn\u00e9s"
                    },
                    {
                        "authorId": "143826881",
                        "name": "J. Llad\u00f3s"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The success of DL has marked the revisiting of table structure parsing by [7], which inspired follow-up research [27, 1, 6, 2, 28, 29, 30, 19, 31, 18, 32, 17].",
                "[29] proposed TGRNet as an effective end-to-end trainable table graph construction network, which encodes a table by combining the cell location detection and cell relation prediction."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "10c3efc40e72674b615864c94a231e1f11913619",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-01654",
                    "ArXiv": "2201.01654",
                    "CorpusId": 245704311
                },
                "corpusId": 245704311,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/10c3efc40e72674b615864c94a231e1f11913619",
                "title": "TableParser: Automatic Table Parsing with Weak Supervision from Spreadsheets",
                "abstract": "Tables have been an ever-existing structure to store data. There exist now different approaches to store tabular data physically. PDFs, images, spreadsheets, and CSVs are leading examples. Being able to parse table structures and extract content bounded by these structures is of high importance in many applications. In this paper, we devise TableParser, a system capable of parsing tables in both native PDFs and scanned images with high precision. We have conducted extensive experiments to show the efficacy of domain adaptation in developing such a tool. Moreover, we create TableAnnotator and ExcelAnnotator, which constitute a spreadsheet-based weak supervision mechanism and a pipeline to enable table parsing. We share these resources with the research community to facilitate further research in this interesting direction.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1576005199",
                        "name": "Susie Xi Rao"
                    },
                    {
                        "authorId": "5185738",
                        "name": "Johannes Rausch"
                    },
                    {
                        "authorId": "2074406990",
                        "name": "P. Egger"
                    },
                    {
                        "authorId": "1776014",
                        "name": "Ce Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[16] proposed TGRNet that jointly predicts the cell spatial location and logical location for the downstream table parsing task.",
                "To answer questions over unstructured table images, both computer vision (CV) and natural language processing (NLP) methods are required [4, 10, 16, 17].",
                ", SQA [5] and WikiSQL [18]) following the way in [16]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0ab6cfb57d3de5159c8d6b36f38d1efc199de11b",
                "externalIds": {
                    "DBLP": "conf/mm/XueCWLYZT21",
                    "DOI": "10.1145/3474085.3478558",
                    "CorpusId": 239011591
                },
                "corpusId": 239011591,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0ab6cfb57d3de5159c8d6b36f38d1efc199de11b",
                "title": "A Question Answering System for Unstructured Table Images",
                "abstract": "Question answering over tables is a very popular semantic parsing task in natural language processing (NLP). However, few existing methods focus on table images, even though there are usually large-scale unstructured tables in practice (e.g., table images). Table parsing from images is nontrivial since it is closely related to not only NLP but also computer vision (CV) to parse the tabular structure from an image. In this demo, we present a question answering system for unstructured table images. The proposed system mainly consists of 1) a table recognizer to recognize the tabular structure from an image and 2) a table parser to generate the answer to a natural language question over the table. In addition, to train the model, we further provide table images and structure annotations for two widely used semantic parsing datasets. Specifically, the test set is used for this demo, from where the users can either choose from default questions or enter a new custom question.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51469630",
                        "name": "Wenyuan Xue"
                    },
                    {
                        "authorId": "2112619444",
                        "name": "Siqi Cai"
                    },
                    {
                        "authorId": "2119293226",
                        "name": "Wen Wang"
                    },
                    {
                        "authorId": "1612980447",
                        "name": "Qingyong Li"
                    },
                    {
                        "authorId": "2110431812",
                        "name": "Baosheng Yu"
                    },
                    {
                        "authorId": "1895813",
                        "name": "Yibing Zhan"
                    },
                    {
                        "authorId": "143719920",
                        "name": "D. Tao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For the table structure recognition, each of the text cells is represented as a vertex in the graph (Xue et al., 2019, 2021; Chi et al., 2019a)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c41fb12333871a6bc52083aae43fb823a75ab01b",
                "externalIds": {
                    "DBLP": "conf/acl/ChenHZL023",
                    "ACL": "2023.acl-long.137",
                    "DOI": "10.18653/v1/2023.acl-long.137",
                    "CorpusId": 259370808
                },
                "corpusId": 259370808,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/c41fb12333871a6bc52083aae43fb823a75ab01b",
                "title": "TableVLM: Multi-modal Pre-training for Table Structure Recognition",
                "abstract": "Tables are widely used in research and business, which are suitable for human consumption, but not easily machine-processable, particularly when tables are present in images.One of the main challenges to extracting data from images of tables is accurately recognizing table structures, especially for complex tables with cross rows and columns.In this study, we propose a novel multi-modal pre-training model for table structure recognition, named TableVLM.With a two-stream multi-modal transformer-based encoder-decoder architecture, TableVLM learns to capture rich table structure-related features by multiple carefully-designed unsupervised objectives inspired by the notion of masked visual-language modeling.To pre-train this model, we also created a dataset, called ComplexTable, which consists of 1,000K samples to be released publicly. Experiment results show that the model built on pre-trained TableVLM can improve the performance up to 1.97% in tree-editing-distance-score on ComplexTable.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2146073369",
                        "name": "Lei Chen"
                    },
                    {
                        "authorId": "31937655",
                        "name": "Chengsong Huang"
                    },
                    {
                        "authorId": "2152196565",
                        "name": "Xiaoqing Zheng"
                    },
                    {
                        "authorId": "2118747855",
                        "name": "Jinshu Lin"
                    },
                    {
                        "authorId": "1790227",
                        "name": "Xuanjing Huang"
                    }
                ]
            }
        }
    ]
}