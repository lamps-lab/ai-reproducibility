{
    "offset": 0,
    "data": [
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fee447ee994fe9371ac2b4b0bf729ebd178b54b1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-10722",
                    "ArXiv": "2308.10722",
                    "DOI": "10.48550/arXiv.2308.10722",
                    "CorpusId": 261049038
                },
                "corpusId": 261049038,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/fee447ee994fe9371ac2b4b0bf729ebd178b54b1",
                "title": "Clustered Linear Contextual Bandits with Knapsacks",
                "abstract": "In this work, we study clustered contextual bandits where rewards and resource consumption are the outcomes of cluster-specific linear models. The arms are divided in clusters, with the cluster memberships being unknown to an algorithm. Pulling an arm in a time period results in a reward and in consumption for each one of multiple resources, and with the total consumption of any resource exceeding a constraint implying the termination of the algorithm. Thus, maximizing the total reward requires learning not only models about the reward and the resource consumption, but also cluster memberships. We provide an algorithm that achieves regret sublinear in the number of time periods, without requiring access to all of the arms. In particular, we show that it suffices to perform clustering only once to a randomly selected subset of the arms. To achieve this result, we provide a sophisticated combination of techniques from the literature of econometrics and of bandits with constraints.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3437152",
                        "name": "Yichuan Deng"
                    },
                    {
                        "authorId": "15770660",
                        "name": "M. Mamakos"
                    },
                    {
                        "authorId": "2214956470",
                        "name": "Zhao Song"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "In\nparticular, Nguyen and Lauw (2014), Gentile et al. (2014), Li et al. (2016), and Carlsson et al.\n(2021) assume that users can be divided into groups and the users within each group receive similar\nrewards for each arm."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ddf88f7f1f74746cc887ff14e002b8cded71551b",
                "externalIds": {
                    "ArXiv": "2202.04294",
                    "DBLP": "journals/corr/abs-2202-04294",
                    "CorpusId": 246679848
                },
                "corpusId": 246679848,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/ddf88f7f1f74746cc887ff14e002b8cded71551b",
                "title": "Optimal Clustering with Bandit Feedback",
                "abstract": "Junwen Yang Institute of Operations Research and Analytics, National University of Singapore, Singapore 117602, junwen yang@u.nus.edu Zixin Zhong Department of Electrical and Computer Engineering, National University of Singapore, Singapore 117583, Department of Mathematics, National University of Singapore, Singapore 119076, zixin.zhong@u.nus.edu Vincent Y. F. Tan Department of Mathematics, National University of Singapore, Singapore 119076, Department of Electrical and Computer Engineering, National University of Singapore, Singapore 117583, Institute of Operations Research and Analytics, National University of Singapore, Singapore 117602, vtan@nus.edu.sg",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "46478481",
                        "name": "Junwen Yang"
                    },
                    {
                        "authorId": "84487055",
                        "name": "Zixin Zhong"
                    },
                    {
                        "authorId": "1717080",
                        "name": "V. Tan"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "[9] show how a clustered structure of bandit arms can be exploited to improve the Thompson sampling strategy."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0426cdaea93d6d232976a9ebba5ee8a6f34f5f5a",
                "externalIds": {
                    "DBLP": "conf/iccbr/KorgerB23",
                    "DOI": "10.1007/978-3-031-40177-0_8",
                    "CorpusId": 260382876
                },
                "corpusId": 260382876,
                "publicationVenue": {
                    "id": "20233170-d1e5-4b98-97e5-e630606bafe1",
                    "name": "International Conference on Case-Based Reasoning",
                    "type": "conference",
                    "alternate_names": [
                        "ICCBR",
                        "Int Conf Case-based Reason"
                    ],
                    "url": "http://www.iccbr.org/"
                },
                "url": "https://www.semanticscholar.org/paper/0426cdaea93d6d232976a9ebba5ee8a6f34f5f5a",
                "title": "Case-Based Sample Generation Using Multi-Armed Bandits",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2265510",
                        "name": "Andreas Korger"
                    },
                    {
                        "authorId": "47759272",
                        "name": "Joachim Baumeister"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2430c028c60310d2d1db100ff9c73f8eb5154d36",
                "externalIds": {
                    "DBLP": "conf/pkdd/ZhaoZL22",
                    "DOI": "10.1007/978-3-031-26412-2_17",
                    "CorpusId": 252493967
                },
                "corpusId": 252493967,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2430c028c60310d2d1db100ff9c73f8eb5154d36",
                "title": "Hierarchical Unimodal Bandits",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "121362266",
                        "name": "Tianchi Zhao"
                    },
                    {
                        "authorId": "40201729",
                        "name": "Chicheng Zhang"
                    },
                    {
                        "authorId": "2150654382",
                        "name": "Ming Li"
                    }
                ]
            }
        }
    ]
}