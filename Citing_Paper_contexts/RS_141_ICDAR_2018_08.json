{
    "offset": 0,
    "data": [
        {
            "contexts": [
                "In recent years, a split-merge approach has emerged as a popular technique for TSR, in which the separators between cells are initially detected and then subsequently merged [45,14,48,19,25]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "eca4dfc1703529bd87e1b4fea1fad1baa06e0ac9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-00630",
                    "ArXiv": "2305.00630",
                    "DOI": "10.48550/arXiv.2305.00630",
                    "CorpusId": 258427145
                },
                "corpusId": 258427145,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/eca4dfc1703529bd87e1b4fea1fad1baa06e0ac9",
                "title": "TRACE: Table Reconstruction Aligned to Corner and Edges",
                "abstract": "A table is an object that captures structured and informative content within a document, and recognizing a table in an image is challenging due to the complexity and variety of table layouts. Many previous works typically adopt a two-stage approach; (1) Table detection(TD) localizes the table region in an image and (2) Table Structure Recognition(TSR) identifies row- and column-wise adjacency relations between the cells. The use of a two-stage approach often entails the consequences of error propagation between the modules and raises training and inference inefficiency. In this work, we analyze the natural characteristics of a table, where a table is composed of cells and each cell is made up of borders consisting of edges. We propose a novel method to reconstruct the table in a bottom-up manner. Through a simple process, the proposed method separates cell boundaries from low-level features, such as corners and edges, and localizes table positions by combining the cells. A simple design makes the model easier to train and requires less computation than previous two-stage methods. We achieve state-of-the-art performance on the ICDAR2013 table competition benchmark and Wired Table in the Wild(WTW) dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2057310228",
                        "name": "Youngmin Baek"
                    },
                    {
                        "authorId": "2064808754",
                        "name": "Daehyun Nam"
                    },
                    {
                        "authorId": "10787779",
                        "name": "Jaeheung Surh"
                    },
                    {
                        "authorId": "2111068603",
                        "name": "Seung Shin"
                    },
                    {
                        "authorId": "2109603647",
                        "name": "Seonghyeon Kim"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "fe211819c3959eaa5382177016e8091465e84861",
                "externalIds": {
                    "DBLP": "journals/pr/MondalAJ23",
                    "DOI": "10.1016/j.patcog.2023.109698",
                    "CorpusId": 258826399
                },
                "corpusId": 258826399,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fe211819c3959eaa5382177016e8091465e84861",
                "title": "Dataset agnostic document object detection",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2896521",
                        "name": "Ajoy Mondal"
                    },
                    {
                        "authorId": "2148629212",
                        "name": "Madhav Agarwal"
                    },
                    {
                        "authorId": "1694502",
                        "name": "C. V. Jawahar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",
                "Khan et al.[33]3 2020 No name ICDAR UNLV ICDAR 2013 - X NR"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "50903f5f5e714e5746152b3e369c9329655e0018",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-10439",
                    "ArXiv": "2304.10439",
                    "DOI": "10.48550/arXiv.2304.10439",
                    "CorpusId": 258236507
                },
                "corpusId": 258236507,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/50903f5f5e714e5746152b3e369c9329655e0018",
                "title": "A Study on Reproducibility and Replicability of Table Structure Recognition Methods",
                "abstract": "Concerns about reproducibility in artificial intelligence (AI) have emerged, as researchers have reported unsuccessful attempts to directly reproduce published findings in the field. Replicability, the ability to affirm a finding using the same procedures on new data, has not been well studied. In this paper, we examine both reproducibility and replicability of a corpus of 16 papers on table structure recognition (TSR), an AI task aimed at identifying cell locations of tables in digital documents. We attempt to reproduce published results using codes and datasets provided by the original authors. We then examine replicability using a dataset similar to the original as well as a new dataset, GenTSR, consisting of 386 annotated tables extracted from scientific papers. Out of 16 papers studied, we reproduce results consistent with the original in only four. Two of the four papers are identified as replicable using the similar dataset under certain IoU values. No paper is identified as replicable using the new dataset. We offer observations on the causes of irreproducibility and irreplicability. All code and data are available on Codeocean at https://codeocean.com/capsule/6680116/tree.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "11359490",
                        "name": "Kehinde E. Ajayi"
                    },
                    {
                        "authorId": "2214808132",
                        "name": "Muntabhir Hasan Choudhury"
                    },
                    {
                        "authorId": "2528276",
                        "name": "S. Rajtmajer"
                    },
                    {
                        "authorId": "97569165",
                        "name": "Jian Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To alleviate this problem, methods like [4, 6, 29] tried different context enhancement techniques, e."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3e0c97baa8e7b629a3d689e00aa21b94e2193766",
                "externalIds": {
                    "ArXiv": "2303.11615",
                    "DBLP": "journals/corr/abs-2303-11615",
                    "DOI": "10.48550/arXiv.2303.11615",
                    "CorpusId": 257636821
                },
                "corpusId": 257636821,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3e0c97baa8e7b629a3d689e00aa21b94e2193766",
                "title": "Robust Table Structure Recognition with Dynamic Queries Enhanced Detection Transformer",
                "abstract": "We present a new table structure recognition (TSR) approach, called TSRFormer, to robustly recognizing the structures of complex tables with geometrical distortions from various table images. Unlike previous methods, we formulate table separation line prediction as a line regression problem instead of an image segmentation problem and propose a new two-stage dynamic queries enhanced DETR based separation line regression approach, named DQ-DETR, to predict separation lines from table images directly. Compared to Vallina DETR, we propose three improvements in DQ-DETR to make the two-stage DETR framework work efficiently and effectively for the separation line prediction task: 1) A new query design, named Dynamic Query, to decouple single line query into separable point queries which could intuitively improve the localization accuracy for regression tasks; 2) A dynamic queries based progressive line regression approach to progressively regressing points on the line which further enhances localization accuracy for distorted tables; 3) A prior-enhanced matching strategy to solve the slow convergence issue of DETR. After separation line prediction, a simple relation network based cell merging module is used to recover spanning cells. With these new techniques, our TSRFormer achieves state-of-the-art performance on several benchmark datasets, including SciTSR, PubTabNet, WTW and FinTabNet. Furthermore, we have validated the robustness and high localization accuracy of our approach to tables with complex structures, borderless cells, large blank spaces, empty or spanning cells as well as distorted or even curved shapes on a more challenging real-world in-house dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2187553093",
                        "name": "Jiawei Wang"
                    },
                    {
                        "authorId": "2108811137",
                        "name": "Weihong Lin"
                    },
                    {
                        "authorId": "2894335",
                        "name": "Chixiang Ma"
                    },
                    {
                        "authorId": "2181111465",
                        "name": "Mingze Li"
                    },
                    {
                        "authorId": "2145130513",
                        "name": "Zhengmao Sun"
                    },
                    {
                        "authorId": "2110833051",
                        "name": "Lei Sun"
                    },
                    {
                        "authorId": "2316043",
                        "name": "Qiang Huo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "With the same goal, bidirectional GRUs [15] extracts the boundaries of rows and columns in a context-driven manner.",
                "With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",
                "the filed, which can be mainly categorized into boundary extraction-based methods [38, 31, 15, 41, 25] and element relationship-based methods [23, 4, 34, 36] according to the component type leveraged.",
                "The first group are the single component-based methods, which rely on either boundary extraction [15, 25, 31, 38, 41] or element relationship [4, 23, 34, 36].",
                "To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in"
            ],
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "2c267f43aca9bfb2f01e5400fca14545c4aa14b3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-09174",
                    "ArXiv": "2303.09174",
                    "DOI": "10.48550/arXiv.2303.09174",
                    "CorpusId": 257557431
                },
                "corpusId": 257557431,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2c267f43aca9bfb2f01e5400fca14545c4aa14b3",
                "title": "Grab What You Need: Rethinking Complex Table Structure Recognition with Flexible Components Deliberation",
                "abstract": "Recently, Table Structure Recognition (TSR) task, aiming at identifying table structure into machine readable formats, has received increasing interest in the community. While impressive success, most single table component-based methods can not perform well on unregularized table cases distracted by not only complicated inner structure but also exterior capture distortion. In this paper, we raise it as Complex TSR problem, where the performance degeneration of existing methods is attributable to their inefficient component usage and redundant post-processing. To mitigate it, we shift our perspective from table component extraction towards the efficient multiple components leverage, which awaits further exploration in the field. Specifically, we propose a seminal method, termed GrabTab, equipped with newly proposed Component Deliberator. Thanks to its progressive deliberation mechanism, our GrabTab can flexibly accommodate to most complex tables with reasonable components selected but without complicated post-processing involved. Quantitative experimental results on public benchmarks demonstrate that our method significantly outperforms the state-of-the-arts, especially under more challenging scenes.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2216764712",
                        "name": "Hao Liu"
                    },
                    {
                        "authorId": "2153898418",
                        "name": "Xin Li"
                    },
                    {
                        "authorId": "2150155841",
                        "name": "Ming Gong"
                    },
                    {
                        "authorId": "47655556",
                        "name": "Bin Liu"
                    },
                    {
                        "authorId": "2164224877",
                        "name": "Yunfei Wu"
                    },
                    {
                        "authorId": "3336726",
                        "name": "Deqiang Jiang"
                    },
                    {
                        "authorId": "2136370566",
                        "name": "Yinsong Liu"
                    },
                    {
                        "authorId": "143900241",
                        "name": "Xing Sun"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "5966cd3ac4460a97b27b4177a89c0d1041726881",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-06949",
                    "ArXiv": "2303.06949",
                    "DOI": "10.1109/CVPR52729.2023.01071",
                    "CorpusId": 257495840
                },
                "corpusId": 257495840,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5966cd3ac4460a97b27b4177a89c0d1041726881",
                "title": "Improving Table Structure Recognition with Visual-Alignment Sequential Coordinate Modeling",
                "abstract": "Table structure recognition aims to extract the logical and physical structure of unstructured table images into a machine-readable format. The latest end-to-end image-to-text approaches simultaneously predict the two structures by two decoders, where the prediction of the physical structure (the bounding boxes of the cells) is based on the representation of the logical structure. However, the previous methods struggle with imprecise bounding boxes as the logical representation lacks local visual information. To address this issue, we propose an end-to-end sequential modeling framework for table structure recognition called VAST. It contains a novel coordinate sequence decoder triggered by the representation of the non-empty cell from the logical structure decoder. In the coordinate sequence decoder, we model the bounding box coordinates as a language sequence, where the left, top, right and bottom coordinates are decoded sequentially to leverage the inter-coordinate dependency. Furthermore, we propose an auxiliary visual-alignment loss to enforce the logical representation of the non-empty cells to contain more local visual details, which helps produce better cell bounding boxes. Extensive experiments demonstrate that our proposed method can achieve state-of-the-art results in both logical and physical structure recognition. The ablation study also validates that the proposed coordinate sequence decoder and the visual-alignment loss are the keys to the success of our method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "145769099",
                        "name": "Yongshuai Huang"
                    },
                    {
                        "authorId": "2054645836",
                        "name": "Ning Lu"
                    },
                    {
                        "authorId": "1679279",
                        "name": "Dapeng Chen"
                    },
                    {
                        "authorId": "2110470261",
                        "name": "Yibo Li"
                    },
                    {
                        "authorId": "2002678",
                        "name": "Zecheng Xie"
                    },
                    {
                        "authorId": "2901597",
                        "name": "Shenggao Zhu"
                    },
                    {
                        "authorId": "1777642",
                        "name": "Liangcai Gao"
                    },
                    {
                        "authorId": "2187312795",
                        "name": "Wei Peng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We build the TFE as an attention bi-directional GRU network [38], [39] to recurrently process word embeddings in"
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5825dfbdaafc0baf71b7831c9508a71007de5616",
                "externalIds": {
                    "DBLP": "journals/tbd/KouZSW23",
                    "DOI": "10.1109/TBDATA.2021.3130165",
                    "CorpusId": 244563275
                },
                "corpusId": 244563275,
                "publicationVenue": {
                    "id": "9cc701cf-1f49-4121-8ea9-11bac24d61ad",
                    "name": "IEEE Transactions on Big Data",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Big Data"
                    ],
                    "issn": "2332-7790",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6687317",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6687317",
                        "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6687317"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5825dfbdaafc0baf71b7831c9508a71007de5616",
                "title": "What and Why? Towards Duo Explainable Fauxtography Detection Under Constrained Supervision",
                "abstract": "Fauxtography is a category of multi-modal posts that spread misleading information on various big data online social platforms that generate billions of posts on a daily basis (e.g., Facebook, Twitter, Reddit). A fauxtography post usually consists of an image, a text description and comments from its readers. In this paper, we focus on explaining fauxtography posts by identifying what specific component and why that component of a post leads to the fauxtography (i.e., duo explanations). This problem is motivated by the limitations of current fauxtography detection solutions that only focus on the detection but ignore the important explanation aspect of their results. Two critical challenges exist in solving our problem: i) it is difficult to accurately identify the \u201cguilty\u201d component of a fauxtography post given the fact that different components of the post and their associations could all lead to the fauxtography; ii) it is expensive and time-consuming to obtain a good training set with fine-grained labels of fauxtography posts in terms of explainability, making it challenging to develop fully supervised explainable solutions. To address the above challenges, we develop a Duo Explainable Fauxtography Detection Framework under a Constrained Supervision (DExFC) to generate duo explanations from both content and comment parts of fauxtography posts. We evaluate the DExFC by creating real-world datasets from different online social media platforms (Twitter and Reddit). The results show that DExFC not only detects the fauxtography posts more accurately than the state-of-the-art solutions but also provides well-justified explanations to its results without the full supervision.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "16132631",
                        "name": "Ziyi Kou"
                    },
                    {
                        "authorId": "35429704",
                        "name": "D. Zhang"
                    },
                    {
                        "authorId": "65855502",
                        "name": "Lanyu Shang"
                    },
                    {
                        "authorId": "2152686930",
                        "name": "Dong Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[12] tried to use a variant of recurrent neural network (RNN) [13\u201315], gated recurrent units (GRU) [16], to identify table structure."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5c3c2ac444019a96edff6ac60329aea3ef43d359",
                "externalIds": {
                    "DOI": "10.3390/electronics12030673",
                    "CorpusId": 256454161
                },
                "corpusId": 256454161,
                "publicationVenue": {
                    "id": "ccd8e532-73c6-414f-bc91-271bbb2933e2",
                    "name": "Electronics",
                    "type": "journal",
                    "issn": "1450-5843",
                    "alternate_issns": [
                        "2079-9292",
                        "0883-4989"
                    ],
                    "url": "http://www.electronics.etfbl.net/",
                    "alternate_urls": [
                        "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-247562",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-247562",
                        "https://www.mdpi.com/journal/electronics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5c3c2ac444019a96edff6ac60329aea3ef43d359",
                "title": "Table Structure Recognition Method Based on Lightweight Network and Channel Attention",
                "abstract": "The table recognition model rows and columns aggregated network (RCANet) uses a semantic segmentation approach to recognize table structure, and achieves better performance in table row and column segmentation. However, this model uses ResNet18 as the backbone network, and the model has 11.35 million parameters and a volume of 45.5 M, which is inconvenient to deploy to lightweight servers or mobile terminals. Therefore, from the perspective of model compression, this paper proposes the lightweight rows and columns attention aggregated network (LRCAANet), which uses the lightweight network ShuffleNetv2 to replace the original RCANet backbone network ResNet18 to simplify the model size. Considering that the lightweight network reduces the number of feature channels, it has a certain impact on the performance of the model. In order to strengthen the learning between feature channels, the rows attention aggregated (RAA) module and the columns attention aggregated (CAA) module are proposed. The RAA module and the CAA module add the squeeze and excitation (SE) module to the original row and column aggregated modules, respectively. Adding the SE module means the model can learn the correlation between channels and improve the prediction effect of the lightweight model. The experimental results show that our method greatly reduces the model parameters and model volume while ensuring low-performance loss. In the end, the average F1 score of our model is only 1.77% lower than the original model, the parameters are only 0.17 million, and the volume is only 0.8 M. Compared with the original model, the parameter amount and volume are reduced by more than 95%.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "103245682",
                        "name": "T. Zhang"
                    },
                    {
                        "authorId": "48184603",
                        "name": "Yi Sui"
                    },
                    {
                        "authorId": "1821383",
                        "name": "Shunyao Wu"
                    },
                    {
                        "authorId": "2096258",
                        "name": "Fengjing Shao"
                    },
                    {
                        "authorId": "39447552",
                        "name": "Rencheng Sun"
                    }
                ]
            }
        },
        {
            "contexts": [
                "SA Khan [113] RNN The reduced receptive field of CNNs is solved by the bi-directional GRU.",
                "SA Khan [113] presents a robust deep learning-based solution for extracting rows and columns from a recognized table in document pictures in this work.",
                "SA Khan[113] ICDAR2013 Bi-directional RNN Precision 96."
            ],
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "a81f504a1a101b9c6fe4a88957dd9ec450cf389d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-08469",
                    "ArXiv": "2211.08469",
                    "DOI": "10.48550/arXiv.2211.08469",
                    "CorpusId": 253553399
                },
                "corpusId": 253553399,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a81f504a1a101b9c6fe4a88957dd9ec450cf389d",
                "title": "Deep learning for table detection and structure recognition: A survey",
                "abstract": "Tables are everywhere, from scientific journals, papers, websites, and newspapers all the way to items we buy at the supermarket. Detecting them is thus of utmost importance to automatically understanding the content of a document. The performance of table detection has substantially increased thanks to the rapid development of deep learning networks. The goals of this survey are to provide a profound comprehension of the major developments in the field of Table Detection, offer insight into the different methodologies, and provide a systematic taxonomy of the different approaches. Furthermore, we provide an analysis of both classic and new applications in the field. Lastly, the datasets and source code of the existing models are organized to provide the reader with a compass on this vast literature. Finally, we go over the architecture of utilizing various object detection and table structure recognition methods to create an effective and efficient system, as well as a set of development trends to keep up with state-of-the-art algorithms and future research. We have also set up a public GitHub repository where we will be updating the most recent publications, open data, and source code. The GitHub repository is available at https://github.com/abdoelsayed2016/ table-detection-structure-recognition. Preprint submitted to Elsevier November 17, 2022 ar X iv :2 21 1. 08 46 9v 1 [ cs .C V ] 1 5 N ov 2 02 2",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "87034581",
                        "name": "M. Kasem"
                    },
                    {
                        "authorId": "115665360",
                        "name": "Abdelrahman Abdallah"
                    },
                    {
                        "authorId": "2115948777",
                        "name": "Alexander Berendeyev"
                    },
                    {
                        "authorId": "2190955162",
                        "name": "Ebrahem Elkady"
                    },
                    {
                        "authorId": "2190955581",
                        "name": "Mahmoud Abdalla"
                    },
                    {
                        "authorId": "2163883464",
                        "name": "Mohamed Mahmoud"
                    },
                    {
                        "authorId": "2057870328",
                        "name": "Mohamed Hamada"
                    },
                    {
                        "authorId": "3253700",
                        "name": "D. Nurseitov"
                    },
                    {
                        "authorId": "1405340824",
                        "name": "I. Taj-Eddin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "299a74663a5230545ba9549b226d7116d1a31b43",
                "externalIds": {
                    "DOI": "10.23919/APSIPAASC55919.2022.9980172",
                    "CorpusId": 254930638
                },
                "corpusId": 254930638,
                "publicationVenue": {
                    "id": "5b924e1a-30f3-4275-bdb8-5a15517c0fde",
                    "name": "Asia-Pacific Signal and Information Processing Association Annual Summit and Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Asia-pacific Signal Inf Process Assoc Annu Summit Conf",
                        "APSIPA"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/299a74663a5230545ba9549b226d7116d1a31b43",
                "title": "Table Structure Recognition Based on Grid Shape Graph",
                "abstract": "Since tables in documents provide important information in compact form, table understanding has been an essential topic in document image processing. Researchers represented table structures in various formats for table understanding, such as simple grid structure, a graph with text/cell boxes as nodes, or a sequence of HTML tokens. However, these approaches have difficulties in handling regularities, e.g., global row and column information, and spanning cells simultaneously. In this paper, we propose a new table recognition method based on a grid shape graph and present grid localization and grid elements grouping networks. This approach is designed to exploit the grid structure and deal with spanning cells. To convert grid structure into cell structure, we only have to test adjacent pairs of grid elements, enabling efficient inference. In addition, we have discovered that predicting row/column-based relationships between grid elements improve cell-based connectivity estimation performance. We demonstrate the effectiveness of the proposed method through experiments on three benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115242015",
                        "name": "Eunji Lee"
                    },
                    {
                        "authorId": "151053767",
                        "name": "Junhyeong Kwon"
                    },
                    {
                        "authorId": "2109472075",
                        "name": "Haeyoon Yang"
                    },
                    {
                        "authorId": "2370571",
                        "name": "Jaewoo Park"
                    },
                    {
                        "authorId": "2144550201",
                        "name": "Soonyoung Lee"
                    },
                    {
                        "authorId": "2463454",
                        "name": "H. Koo"
                    },
                    {
                        "authorId": "1707645",
                        "name": "N. Cho"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recurring neural networks [27] were also utilized to tackle the task of tabular structure extraction [28], [29]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "e35ef6f4cfdc2319a641735608562d3886fa9fdd",
                "externalIds": {
                    "DOI": "10.1109/ICCCIS56430.2022.10037664",
                    "CorpusId": 256743427
                },
                "corpusId": 256743427,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e35ef6f4cfdc2319a641735608562d3886fa9fdd",
                "title": "Using CoordConv for Tabular Data Detection and Structure Recognition",
                "abstract": "This paper explores the usage of CoordConv, the novel upgrade to general convolutional layers in the problem of Tabular Data Detection and Cell-Based Structure Recognition. CoordConv has been shown to provide considerably better results in the domain of Object Detection than its counterpart. The authors integrate it within the established Anchor optimization approach which leverages guided anchors to accomplish the task of recognizing rows and columns present in tabular data. In contrast to the majority of techniques implemented for Table Structure Recognition, the authors attempt to recognize the cells present in the tabular images instead of the rows and columns. They evaluate this method on the coveted ICDAR-19 dataset (International Conference on Document Analysis and Recognition - 2019) which comprises of scanned document images containing tabular regions and achieve results surpassing those of many popular techniques. They also apply this approach for the task of Table Detection and achieve results comparable to other established techniques.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2205330992",
                        "name": "Apoorva Ambulgekar"
                    },
                    {
                        "authorId": "2205330976",
                        "name": "Naman Lad"
                    },
                    {
                        "authorId": "2183415732",
                        "name": "Krunal Doshi"
                    },
                    {
                        "authorId": "2128946657",
                        "name": "Pranit Bari"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Targeting wide classes of documents, many recent works often use neural networks [19, 20, 21, 22] to recognize table structures in documents by means of large training sets."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "dc2e74d762ee2edb34acd2837cf568734a13c6df",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-04716",
                    "ArXiv": "2210.04716",
                    "DOI": "10.48550/arXiv.2210.04716",
                    "CorpusId": 252780248
                },
                "corpusId": 252780248,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/dc2e74d762ee2edb34acd2837cf568734a13c6df",
                "title": "A two-stage approach for table extraction in invoices",
                "abstract": "The automated analysis of administrative documents is an important field in document recognition that is studied for decades. Invoices are key documents among these huge amounts of documents available in companies and public services. Invoices contain most of the time data that are presented in tables that should be clearly identified to extract suitable information. In this paper, we propose an approach that combines an image processing based estimation of the shape of the tables with a graph-based representation of the document, which is used to identify complex tables precisely. We propose an experimental evaluation using a real case application.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2187298852",
                        "name": "Thomas Saout"
                    },
                    {
                        "authorId": "2266965",
                        "name": "F. Lardeux"
                    },
                    {
                        "authorId": "1726003",
                        "name": "F. Saubion"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[36] provides a bidirectional GRU recurrent neural network to detect rows and columns in a table.",
                "[36] uses Gated Recurrent Unit (GRU) based sequential deep models for table structure extraction."
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "84ae5630601b634b1be90ceb6223ae687b9407c4",
                "externalIds": {
                    "DBLP": "conf/icpr/LiuLCDTFC22",
                    "DOI": "10.1109/ICPR56361.2022.9956139",
                    "CorpusId": 254100141
                },
                "corpusId": 254100141,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/84ae5630601b634b1be90ceb6223ae687b9407c4",
                "title": "Table information extraction and analysis: A robust geometric approach based on GatedGCN",
                "abstract": "With the rapid development of Artificial Intelligence, Optical Character Recognition(OCR) is applied to analyze and understand the contents of various images, which has a very important effect on online office and makes business more intelligent. As downstream tasks of OCR, information extraction and table analysis are indispensable for acquisition of target information. However, when the texts information are gained from an invoice image or a table image by detection and recognition methods, how to further extract necessary information from a mass of texts or to analyze table information by reconstruction method is still difficult and challenging. In the paper, based on gated graph convolutional networks (GatedGCNs), we propose a novel model to extract key information in documents and reconstruct table information from listing images. Different from manual methods, the GatedGCN-based model considers three kinds of features for the semantic entities, including the position of an entity, the box containing the entity and texts inside the box. The proposed model also considers the relationship between semantic entities, which is a key factor to improve the classification accuracy. Since the update of gated edges in GatedGCN can be treated as a new way to implement attention mechanism, the model can integrate more critical information and discard unnecessary information. Therefore, combining with the node features and the edge features we have extracted, when applying the model on key field extraction (which can be treated as node classification problems) and table reconstruction (that can be treated as link-prediction problems), the model reaches overall excellent results in terms of precision, recall, F1 score and accuracy, evaluated on Medical Invoice, Train Tickets, SciTSR, ICDAR2013 datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1679704",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2192834525",
                        "name": "Xiaoyun Liang"
                    },
                    {
                        "authorId": "2193211589",
                        "name": "Shaoqiong Chen"
                    },
                    {
                        "authorId": "2059827588",
                        "name": "Liang Diao"
                    },
                    {
                        "authorId": "2109887784",
                        "name": "Xin Tang"
                    },
                    {
                        "authorId": "2055079520",
                        "name": "Rui Fang"
                    },
                    {
                        "authorId": "2067611",
                        "name": "Weifu Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To alleviate this problem, methods like [13, 43, 45] tried different context enhancement techniques, e."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "fb6fcca5762b26f225313f86b1f33a1cf198bfd7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-04921",
                    "ArXiv": "2208.04921",
                    "DOI": "10.1145/3503161.3548038",
                    "CorpusId": 251442367
                },
                "corpusId": 251442367,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fb6fcca5762b26f225313f86b1f33a1cf198bfd7",
                "title": "TSRFormer: Table Structure Recognition with Transformers",
                "abstract": "We present a new table structure recognition (TSR) approach, called TSRFormer, to robustly recognizing the structures of complex tables with geometrical distortions from various table images. Unlike previous methods, we formulate table separation line prediction as a line regression problem instead of an image segmentation problem and propose a new two-stage DETR based separator prediction approach, dubbed Sep arator RE gression TR ansformer (SepRETR), to predict separation lines from table images directly. To make the two-stage DETR framework work efficiently and effectively for the separation line prediction task, we propose two improvements: 1) A prior-enhanced matching strategy to solve the slow convergence issue of DETR; 2) A new cross attention module to sample features from a high-resolution convolutional feature map directly so that high localization accuracy is achieved with low computational cost. After separation line prediction, a simple relation network based cell merging module is used to recover spanning cells. With these new techniques, our TSRFormer achieves state-of-the-art performance on several benchmark datasets, including SciTSR, PubTabNet and WTW. Furthermore, we have validated the robustness of our approach to tables with complex structures, borderless cells, large blank spaces, empty or spanning cells as well as distorted or even curved shapes on a more challenging real-world in-house dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108811137",
                        "name": "Weihong Lin"
                    },
                    {
                        "authorId": "2145130513",
                        "name": "Zhengmao Sun"
                    },
                    {
                        "authorId": "2894335",
                        "name": "Chixiang Ma"
                    },
                    {
                        "authorId": "2181111465",
                        "name": "Mingze Li"
                    },
                    {
                        "authorId": "2110132415",
                        "name": "Jiawei Wang"
                    },
                    {
                        "authorId": "2110833051",
                        "name": "Lei Sun"
                    },
                    {
                        "authorId": "2316043",
                        "name": "Qiang Huo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There are three approaches in the literature to handle table detection in documents: conventional rule-based [30, 87], metadata extraction [6, 31, 57], and machine learning and deep learning approaches [5, 25, 41, 47, 89].",
                "[41] used the CNNmodel introduced by Gilani et al.",
                "[41] used the CNN model introduced by Gilani et al.",
                "We unfortunately could not directly evaluate the approaches presented in References [5, 25, 30, 41, 47, 89] using our cybersecurity corpus documents, because their respective implementations were not available online.",
                "Researchmodels trained on reference datasets such as References [5, 25, 30, 41, 47, 89] often have difficulties coping with the complexity of real world document layouts [15].",
                "(2019) [41] Faster R-CNN + PDF Table Boundary Detection Relies on heuristics Gated Recurrent Columns and Rows Detection Fails to return text Unit (GRU) Fails to detect cell structures Zheng et al."
            ],
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "87cb212eeb40171b32a4411a6919e22c36822140",
                "externalIds": {
                    "DBLP": "journals/tmis/AmeriHSLP23",
                    "DOI": "10.1145/3546580",
                    "CorpusId": 250496865
                },
                "corpusId": 250496865,
                "publicationVenue": {
                    "id": "a0b9dfee-fbf4-4bea-835f-20d6db1ce53a",
                    "name": "ACM Transactions on Management Information Systems",
                    "alternate_names": [
                        "ACM Trans Manag Inf Syst"
                    ],
                    "issn": "2158-656X",
                    "url": "http://dl.acm.org/citation.cfm?CFID=72370079&CFTOKEN=39904203&id=J1320",
                    "alternate_urls": [
                        "http://portal.acm.org/tmis",
                        "http://portal.acm.org/citation.cfm?id=J1320&picked=prox",
                        "https://tmis.acm.org/",
                        "http://tmis.acm.org/index.html"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/87cb212eeb40171b32a4411a6919e22c36822140",
                "title": "Design of a Novel Information System for Semi-automated Management of Cybersecurity in Industrial Control Systems",
                "abstract": "There is an urgent need in many critical infrastructure sectors, including the energy sector, for attaining detailed insights into cybersecurity features and compliance with cybersecurity requirements related to their Operational Technology (OT) deployments. Frequent feature changes of OT devices interfere with this need, posing a great risk to customers. One effective way to address this challenge is via a semi-automated cyber-physical security assurance approach, which enables verification and validation of the OT device cybersecurity claims against actual capabilities, both pre- and post-deployment. To realize this approach, this article presents new methodology and algorithms to automatically identify cybersecurity-related claims expressed in natural language form in ICS device documents. We developed an identification process that employs natural language processing (NLP) techniques with the goal of semi-automated vetting of detected claims against their device implementation. We also present our novel NLP components for verifying feature claims against relevant cybersecurity requirements. The verification pipeline includes components such as automated vendor identification, device document curation, feature claim identification utilizing sentiment analysis for conflict resolution, and reporting of features that are claimed to be supported or indicated as unsupported. Our novel matching engine represents the first automated information system available in the cybersecurity domain that directly aids the generation of ICS compliance reports.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "134238540",
                        "name": "Kimia Ameri"
                    },
                    {
                        "authorId": "35380390",
                        "name": "M. Hempel"
                    },
                    {
                        "authorId": "145505074",
                        "name": "H. Sharif"
                    },
                    {
                        "authorId": "2150338498",
                        "name": "Juan Lopez"
                    },
                    {
                        "authorId": "1750770",
                        "name": "K. Perumalla"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "59b414e6f0eb2e1db326015a9e70d0666dbc7783",
                "externalIds": {
                    "ArXiv": "2207.06695",
                    "DBLP": "conf/mm/QiaoJCLLLZGXXCN22",
                    "DOI": "10.1145/3503161.3548547",
                    "CorpusId": 250526105
                },
                "corpusId": 250526105,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/59b414e6f0eb2e1db326015a9e70d0666dbc7783",
                "title": "DavarOCR: A Toolbox for OCR and Multi-Modal Document Understanding",
                "abstract": "This paper presents DavarOCR, an open-source toolbox for OCR and document understanding tasks. DavarOCR currently implements 19 advanced algorithms, covering 9 different task forms. DavarOCR provides detailed usage instructions and the trained models for each algorithm. Compared with the previous open-source OCR toolbox, DavarOCR has relatively more complete support for the sub-tasks of the cutting-edge technology of document understanding. In order to promote the development and application of OCR technology in academia and industry, we pay more attention to the use of modules that different sub-domains of technology can share. DavarOCR is publicly released at https://github.com/hikopensource/Davar-Lab-OCR.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2065512194",
                        "name": "Liang Qiao"
                    },
                    {
                        "authorId": "2169216245",
                        "name": "Hui Jiang"
                    },
                    {
                        "authorId": "2144541900",
                        "name": "Ying Chen"
                    },
                    {
                        "authorId": "2118037394",
                        "name": "Can Li"
                    },
                    {
                        "authorId": "2144902872",
                        "name": "Pengfei Li"
                    },
                    {
                        "authorId": "2109614687",
                        "name": "Zaisheng Li"
                    },
                    {
                        "authorId": "1720803198",
                        "name": "Baorui Zou"
                    },
                    {
                        "authorId": "20412557",
                        "name": "Dashan Guo"
                    },
                    {
                        "authorId": "2110289747",
                        "name": "Yi Xu"
                    },
                    {
                        "authorId": "47103450",
                        "name": "Yunlu Xu"
                    },
                    {
                        "authorId": "2398015",
                        "name": "Zhanzhan Cheng"
                    },
                    {
                        "authorId": "1490934795",
                        "name": "Yi Niu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "644b991959bf5fb036d28d67e9918d419b212e75",
                "externalIds": {
                    "DBLP": "journals/pr/LiYDL22",
                    "DOI": "10.1016/j.patcog.2022.108946",
                    "CorpusId": 251140530
                },
                "corpusId": 251140530,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/644b991959bf5fb036d28d67e9918d419b212e75",
                "title": "Table Structure Recognition and Form Parsing by End-to-End Object Detection and Relation Parsing",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118890077",
                        "name": "Xiaohui Li"
                    },
                    {
                        "authorId": "145820427",
                        "name": "Fei Yin"
                    },
                    {
                        "authorId": "2179477671",
                        "name": "He-Sen Dai"
                    },
                    {
                        "authorId": "1689269",
                        "name": "Cheng-Lin Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "564acb3b027a439b1a44e5b2d73ff5814312ad58",
                "externalIds": {
                    "DBLP": "journals/asc/KashinathJAAS22",
                    "DOI": "10.1016/j.asoc.2022.108942",
                    "CorpusId": 248716737
                },
                "corpusId": 248716737,
                "publicationVenue": {
                    "id": "b1994124-f1e8-4f96-a165-b6f19a04fe7e",
                    "name": "Applied Soft Computing",
                    "type": "journal",
                    "alternate_names": [
                        "Appl Soft Comput"
                    ],
                    "issn": "1568-4946",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/621920/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/applied-soft-computing",
                        "http://www.sciencedirect.com/science/journal/15684946"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/564acb3b027a439b1a44e5b2d73ff5814312ad58",
                "title": "End-to-end table structure recognition and extraction in heterogeneous documents",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2164965360",
                        "name": "Tejas Kashinath"
                    },
                    {
                        "authorId": "2164964715",
                        "name": "Twisha Jain"
                    },
                    {
                        "authorId": "2066307014",
                        "name": "Yash Agrawal"
                    },
                    {
                        "authorId": "1455135470",
                        "name": "Tanvi Anand"
                    },
                    {
                        "authorId": "2118414009",
                        "name": "S. Singh"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Thus, this paper proposes a novel token-level metaphor identification method based on pre-training of deep bidirectional transformers (BERT) [6], Bi-Gated Recurrent Unit (Bi-GRU) [10] and Conditional Random Field (CRF) [13]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "1e4a62cffdbc857293891dfbfdbb13605262c7b3",
                "externalIds": {
                    "DBLP": "conf/www/ZhangZP022",
                    "DOI": "10.1145/3487553.3524935",
                    "CorpusId": 248363951
                },
                "corpusId": 248363951,
                "publicationVenue": {
                    "id": "e07422f9-c065-40c3-a37b-75e98dce79fe",
                    "name": "The Web Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Web Conf",
                        "WWW"
                    ],
                    "url": "http://www.iw3c2.org/"
                },
                "url": "https://www.semanticscholar.org/paper/1e4a62cffdbc857293891dfbfdbb13605262c7b3",
                "title": "Expressing Metaphorically, Writing Creatively: Metaphor Identification for Creativity Assessment in Writing",
                "abstract": "Metaphor, which can implicitly express profound meanings and emotions, is a unique writing technique frequently used in human language. In writing, meaningful metaphorical expressions can enhance the literariness and creativity of texts. Therefore, the usage of metaphor is a significant impact factor when assessing the creativity and literariness of writing. However, little to no automatic writing assessment system considers metaphorical expressions when giving the score of creativity. For improving the accuracy of automatic writing assessment, this paper proposes a novel creativity assessment model that imports a token-level metaphor identification method to extract metaphors as the indicators for creativity scoring. The experimental results show that our model can accurately assess the creativity of different texts with precise metaphor identification. To the best of our knowledge, we are the first to apply automatic metaphor identification to assess writing creativity. Moreover, identifying features (e.g., metaphors) that influence writing creativity using computational approaches can offer fair and reliable assessment methods for educational settings.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "46334785",
                        "name": "Dongyu Zhang"
                    },
                    {
                        "authorId": "2112152933",
                        "name": "Minghao Zhang"
                    },
                    {
                        "authorId": "1726114642",
                        "name": "Ciyuan Peng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[18] proposed to use sequential models like bi-directional gated recurrent unit networks"
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "29942b5588d9978af5da046ebfc642e4779b8597",
                "externalIds": {
                    "ArXiv": "2203.09056",
                    "DBLP": "journals/pr/MaLSH23",
                    "DOI": "10.1016/j.patcog.2022.109006",
                    "CorpusId": 247518554
                },
                "corpusId": 247518554,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/29942b5588d9978af5da046ebfc642e4779b8597",
                "title": "Robust Table Detection and Structure Recognition from Heterogeneous Document Images",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2894335",
                        "name": "Chixiang Ma"
                    },
                    {
                        "authorId": "2108811137",
                        "name": "Weihong Lin"
                    },
                    {
                        "authorId": "2110833051",
                        "name": "Lei Sun"
                    },
                    {
                        "authorId": "2316043",
                        "name": "Qiang Huo"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "d9c676eccdff80a7d1154660a09c4d2ea5164610",
                "externalIds": {
                    "DOI": "10.1007/s11042-021-11819-7",
                    "CorpusId": 254860167
                },
                "corpusId": 254860167,
                "publicationVenue": {
                    "id": "477368e9-7a8e-475a-8c93-6d623797fd06",
                    "name": "Multimedia tools and applications",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Tools and Applications",
                        "Multimedia Tool Appl",
                        "Multimedia tool appl"
                    ],
                    "issn": "1380-7501",
                    "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d9c676eccdff80a7d1154660a09c4d2ea5164610",
                "title": "Deep-learning and graph-based approach to table structure recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2115242015",
                        "name": "Eunji Lee"
                    },
                    {
                        "authorId": "2370571",
                        "name": "Jaewoo Park"
                    },
                    {
                        "authorId": "2463454",
                        "name": "H. Koo"
                    },
                    {
                        "authorId": "1707645",
                        "name": "N. Cho"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Experimentation achieved the highest accuracy of 90.17 for Bi-GRU, applying learned word class features along with embedding with GloVe.",
                "(ii) LSTM [42], Bi-LSTM [43], GRU [44], and Bi-GRU [45] are investigated as classifiers (with one-dimensional convolution layer).",
                "Maximum average accuracy is achieved by the GloVe-WCFBi-GRU model, which is 90.41% for the Saraiki-Hindi dataset, while for the English-Bengali-Saraiki-Hindi-Roman Urdu mix dataset, minimum accuracy is observed (i.e., 85% in Figure 7).",
                "Moreover, through experimental investigation, different architectures are optimized for the task associated with Long Short-Term Memory (LSTM), Bidirectional LSTM, Gated Recurrent Unit (GRU), and Bidirectional Gated Recurrent Unit (Bi-GRU).",
                "*e highest average accuracy is achieved for the GloVe-WCFBi-GRU model for which the optimized approach is presented\nin Figure 7.",
                "On the other hand, for the Parzen estimator, highest accuracy is achieved by Bi-GRU implemented on top of GloVe for Eng-Bengali scripts.",
                "It is done with its variants LSTM, Bi-LSTM, GRU, and Bi-GRU.",
                "More variations in standard LSTM such as Bi-LST [60], GRU [5], and Bi-GRU [61] are found to be adequate to address the mentioned issues.",
                "According to [4, 45, 62], Bi-LSTM can capture or calculate both directions of contexts, such as upcoming and previous hidden layers.",
                "*e architecture gets data and performs on dataset word-by-word analysis and feeds the representation into LSTM, Bi-LSTM, GRU, and Bi-GRU.",
                "In our work, the input is captured by tweet as the token as an underlying layer of RNN variants as LSTM, BI-LSTM, GRU, and Bi-GRU as word embedding.",
                "*erefore, dataset consisting of five different languages (3 cursive and 2 noncursive) is selected for effective validation of the proposed method\n*e significance of this study is to explore (1) two kinds of word embeddings; (2) four classifiers (LSTM, Bi-LSTM, GRU, and Bi-GRU); (3) various deep neural network architectures; (4) optimal value of different hyperparameters to find the optimal language detection for the mixed-script dataset consisting of Roman Urdu, English, Saraiki, Hindi, and Bengali languages."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "1a6220def2a8987d5316054d9fa884f2e5ec0a67",
                "externalIds": {
                    "DBLP": "journals/cin/Yasir0KMA21",
                    "PubMedCentral": "8683192",
                    "DOI": "10.1155/2021/8415333",
                    "CorpusId": 245183014,
                    "PubMed": "34925496"
                },
                "corpusId": 245183014,
                "publicationVenue": {
                    "id": "f32b7322-b69c-4e63-801d-8f50784ef778",
                    "name": "Computational Intelligence and Neuroscience",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Intell Neurosci"
                    ],
                    "issn": "1687-5265",
                    "url": "https://www.hindawi.com/journals/cin/"
                },
                "url": "https://www.semanticscholar.org/paper/1a6220def2a8987d5316054d9fa884f2e5ec0a67",
                "title": "Mixed Script Identification Using Automated DNN Hyperparameter Optimization",
                "abstract": "Mixed script identification is a hindrance for automated natural language processing systems. Mixing cursive scripts of different languages is a challenge because NLP methods like POS tagging and word sense disambiguation suffer from noisy text. This study tackles the challenge of mixed script identification for mixed-code dataset consisting of Roman Urdu, Hindi, Saraiki, Bengali, and English. The language identification model is trained using word vectorization and RNN variants. Moreover, through experimental investigation, different architectures are optimized for the task associated with Long Short-Term Memory (LSTM), Bidirectional LSTM, Gated Recurrent Unit (GRU), and Bidirectional Gated Recurrent Unit (Bi-GRU). Experimentation achieved the highest accuracy of 90.17 for Bi-GRU, applying learned word class features along with embedding with GloVe. Moreover, this study addresses the issues related to multilingual environments, such as Roman words merged with English characters, generative spellings, and phonetic typing.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2059751963",
                        "name": "Muhammad Yasir"
                    },
                    {
                        "authorId": "2118871555",
                        "name": "Chen Li"
                    },
                    {
                        "authorId": "1388829167",
                        "name": "Amna Khatoon"
                    },
                    {
                        "authorId": "2052343190",
                        "name": "Muhammad Amir Malik"
                    },
                    {
                        "authorId": "152868960",
                        "name": "Fazeel Abid"
                    }
                ]
            }
        },
        {
            "contexts": [
                "With the development of deep learning, table structure recognition methods have recently advanced substantially on performance, which can be classified into three categories: boundary extractionbased [13, 22, 27, 35, 40], generative model-based [18, 46], and graph-based [2, 20, 30, 34] methods.",
                "Although many previous algorithms [2,13,18,20,22,30,31,34,35,40,45,46] have achieved impressive progress in the community, TSR is still a challenging task due to two factors of complicated tables.",
                "Besides, another technique [13] exploits bi-directional GRUs to establish row and column boundaries in a context driven manner.",
                "Table structure recognition (TSR) aims to recognize the table internal structure to the machine readable data mainly presented in two formats: logical structure [18, 46] and physical structure [2, 13, 20, 22, 27, 30, 31, 34, 35, 40, 45]."
            ],
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "9fb2744ef2b91033de39c121be25d3f86f759458",
                "externalIds": {
                    "DBLP": "conf/cvpr/0003LLJL022",
                    "ArXiv": "2111.13359",
                    "DOI": "10.1109/CVPR52688.2022.00449",
                    "CorpusId": 244709555
                },
                "corpusId": 244709555,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9fb2744ef2b91033de39c121be25d3f86f759458",
                "title": "Neural Collaborative Graph Machines for Table Structure Recognition",
                "abstract": "Recently, table structure recognition has achieved impressive progress with the help of deep graph models. Most of them exploit single visual cues of tabular elements or simply combine visual cues with other modalities via early fusion to reason their graph relationships. However, neither early fusion nor individually reasoning in terms of multiple modalities can be appropriate for all varieties of table structures with great diversity. Instead, different modalities are expected to collaborate with each other in different patterns for different table cases. In the community, the importance of intrainter modality interactions for table structure reasoning is still unexplored. In this paper, we define it as heterogeneous table structure recognition (HeteroTSR) problem. With the aim offilling this gap, we present a novel Neural Collaborative Graph Machines (NCGM) equipped with stacked collaborative blocks, which alternatively extracts intramodality context and models inter-modality interactions in a hierarchical way. It can represent the intrainter modality relationships of tabular elements more robustly, which significantly improves the recognition performance. We also show that the proposed NCGM can modulate collaborative pattern of different modalities conditioned on the context of intramodality cues, which is vital for diversified table cases. Experimental results on benchmarks demonstrate our proposed NCGM achieves state-of-the-art performance and beats other contemporary methods by a large margin especially under challenging scenarios.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "48446712",
                        "name": "Hao Liu"
                    },
                    {
                        "authorId": "2153898418",
                        "name": "Xin Li"
                    },
                    {
                        "authorId": "2149124539",
                        "name": "Bing Liu"
                    },
                    {
                        "authorId": "3336726",
                        "name": "Deqiang Jiang"
                    },
                    {
                        "authorId": "2136370566",
                        "name": "Yinsong Liu"
                    },
                    {
                        "authorId": "2064646914",
                        "name": "Bo Ren"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Cognitive methods in this space broadly classified into five categories \u2014 image-to-sequence models [17, 2, 14], segmentation networks [26, 18, 20, 23], graph formulations [22, 4, 24], conditional generative adversarial networks [16] and a recent multi-modal method by [40]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "d499cd8a77e7fc4e12d1f5bd7875ce2e3f5465a4",
                "externalIds": {
                    "DBLP": "conf/wacv/RajaMV22",
                    "ArXiv": "2111.07129",
                    "DOI": "10.1109/WACV51458.2022.00260",
                    "CorpusId": 240285297
                },
                "corpusId": 240285297,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/d499cd8a77e7fc4e12d1f5bd7875ce2e3f5465a4",
                "title": "Visual Understanding of Complex Table Structures from Document Images",
                "abstract": "Table structure recognition is necessary for a comprehensive understanding of documents. Tables in unstructured business documents are tough to parse due to the high diversity of layouts, varying alignments of contents, and the presence of empty cells. The problem is particularly difficult because of challenges in identifying individual cells using visual or linguistic contexts or both. Accurate detection of table cells (including empty cells) simplifies structure extraction and hence, it becomes the prime focus of our work. We propose a novel object-detection-based deep model that captures the inherent alignments of cells within tables and is fine-tuned for fast optimization. Despite accurate detection of cells, recognizing structures for dense tables may still be challenging because of difficulties in capturing long-range row/column dependencies in presence of multi-row/column spanning cells. Therefore, we also aim to improve structure recognition by deducing a novel rectilinear graph-based formulation. From a semantics perspective, we highlight the significance of empty cells in a table. To take these cells into account, we suggest an enhancement to a popular evaluation criterion. Finally, we introduce a modestly sized evaluation dataset with an annotation style inspired by human cognition to encourage new approaches to the problem. Our framework improves the previous state-of-the-art performance by a 2.7% average F1-score on benchmark datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2053910624",
                        "name": "S. Raja"
                    },
                    {
                        "authorId": "2896521",
                        "name": "Ajoy Mondal"
                    },
                    {
                        "authorId": "2226828175",
                        "name": "Jawahar C V"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "32d61e4dfb039e126c1b54cae7bac0d33ffcd51f",
                "externalIds": {
                    "DBLP": "journals/aei/ZhouHGLPZSB21",
                    "DOI": "10.1016/j.aei.2021.101441",
                    "CorpusId": 242072273
                },
                "corpusId": 242072273,
                "publicationVenue": {
                    "id": "ec497fa8-833a-4d68-873a-539c20989c22",
                    "name": "Advanced Engineering Informatics",
                    "type": "journal",
                    "alternate_names": [
                        "Adv Eng Informatics"
                    ],
                    "issn": "1474-0346",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622240/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/14740346"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/32d61e4dfb039e126c1b54cae7bac0d33ffcd51f",
                "title": "An end-to-end tabular information-oriented causality event evolutionary knowledge graph for manufacturing documents",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118870182",
                        "name": "Bin Zhou"
                    },
                    {
                        "authorId": "2064244474",
                        "name": "B. Hua"
                    },
                    {
                        "authorId": "2118713039",
                        "name": "X. Gu"
                    },
                    {
                        "authorId": "1390856745",
                        "name": "Yuqian Lu"
                    },
                    {
                        "authorId": "2143986469",
                        "name": "Tao Peng"
                    },
                    {
                        "authorId": "2149515768",
                        "name": "Yu Zheng"
                    },
                    {
                        "authorId": "9375754",
                        "name": "Xingwang Shen"
                    },
                    {
                        "authorId": "2072742582",
                        "name": "Jinsong Bao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To achieve this purpose, existing computer vision methods either predict cell bounding boxes [6, 13], explore the adjacency relation between different cells [11, 15], or transform a table image into the markup sequence (e."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0ab6cfb57d3de5159c8d6b36f38d1efc199de11b",
                "externalIds": {
                    "DBLP": "conf/mm/XueCWLYZT21",
                    "DOI": "10.1145/3474085.3478558",
                    "CorpusId": 239011591
                },
                "corpusId": 239011591,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0ab6cfb57d3de5159c8d6b36f38d1efc199de11b",
                "title": "A Question Answering System for Unstructured Table Images",
                "abstract": "Question answering over tables is a very popular semantic parsing task in natural language processing (NLP). However, few existing methods focus on table images, even though there are usually large-scale unstructured tables in practice (e.g., table images). Table parsing from images is nontrivial since it is closely related to not only NLP but also computer vision (CV) to parse the tabular structure from an image. In this demo, we present a question answering system for unstructured table images. The proposed system mainly consists of 1) a table recognizer to recognize the tabular structure from an image and 2) a table parser to generate the answer to a natural language question over the table. In addition, to train the model, we further provide table images and structure annotations for two widely used semantic parsing datasets. Specifically, the test set is used for this demo, from where the users can either choose from default questions or enter a new custom question.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51469630",
                        "name": "Wenyuan Xue"
                    },
                    {
                        "authorId": "2112619444",
                        "name": "Siqi Cai"
                    },
                    {
                        "authorId": "2119293226",
                        "name": "Wen Wang"
                    },
                    {
                        "authorId": "1612980447",
                        "name": "Qingyong Li"
                    },
                    {
                        "authorId": "2110431812",
                        "name": "Baosheng Yu"
                    },
                    {
                        "authorId": "1895813",
                        "name": "Yibing Zhan"
                    },
                    {
                        "authorId": "143719920",
                        "name": "D. Tao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[13, 25, 32] attempt to predict row/column boundaries or even invisible grid lines, which are limited in identifying cells spanning multiple rows and columns.",
                "They can be categorized into two groups: non-table-element-based approaches [13, 17, 25, 32, 35, 44] and tableelement-based approaches [2, 19, 27\u201329, 31, 41, 43]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "7b99f9995a4b086c0e6913a8d2f109a5dbaa5014",
                "externalIds": {
                    "DBLP": "conf/mm/LiuLLJLRJ21",
                    "DOI": "10.1145/3474085.3481534",
                    "CorpusId": 239011898
                },
                "corpusId": 239011898,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7b99f9995a4b086c0e6913a8d2f109a5dbaa5014",
                "title": "Show, Read and Reason: Table Structure Recognition with Flexible Context Aggregator",
                "abstract": "We investigate the challenging problem of table structure recognition in this work. Many recent methods adopt graph-based context aggregator with strong inductive bias to reason sparse contextual relationships of table elements. However, the strong constraints may be too restrictive to represent the complicated table relationships. In order to learn more appropriate inductive bias from data, we try to introduce Transformer as context aggregator in this work. Nevertheless, Transformer taking dense context as input requires larger scale data and may suffer from unstable training procedure due to the weakening of inductive bias. To overcome the above limitations, we in this paper design a FLAG (FLexible context AGgregator), which marries Transformer with graph-based context aggregator in an adaptive way. Based on FLAG, an end-to-end framework requiring no extra meta-data or OCR information, termed FLAG-Net, is proposed to flexibly modulate the aggregation of dense context and sparse one for the relational reasoning of table elements. We investigate the modulation pattern in FLAG and show what contextual information is focused, which is vital for recognizing table structure. Extensive experimental results on benchmarks demonstrate the performance of our proposed FLAG-Net surpasses other compared methods by a large margin.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "48446712",
                        "name": "Hao Liu"
                    },
                    {
                        "authorId": "2153898418",
                        "name": "Xin Li"
                    },
                    {
                        "authorId": "2149124539",
                        "name": "Bing Liu"
                    },
                    {
                        "authorId": "3336726",
                        "name": "Deqiang Jiang"
                    },
                    {
                        "authorId": "2136370566",
                        "name": "Yinsong Liu"
                    },
                    {
                        "authorId": "2064646914",
                        "name": "Bo Ren"
                    },
                    {
                        "authorId": "145592290",
                        "name": "R. Ji"
                    }
                ]
            }
        },
        {
            "contexts": [
                "2, with the success of deep learning, recent deep learning-based table structure recognition approaches can be divided into three categories: 1) identify cell bounding boxes through visual detection and segmentation methods [8], [25], [27]\u2013[29]; 2)",
                "In [8], [28], [29], they classify an entire row or column into the cell or non-cell categories instead of the pixel-wise classification."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "6e26602986e56d3524c325601674decb05cd8f2b",
                "externalIds": {
                    "DBLP": "conf/iccv/XueYWTL21",
                    "ArXiv": "2106.10598",
                    "DOI": "10.1109/ICCV48922.2021.00133",
                    "CorpusId": 235490364
                },
                "corpusId": 235490364,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/6e26602986e56d3524c325601674decb05cd8f2b",
                "title": "TGRNet: A Table Graph Reconstruction Network for Table Structure Recognition",
                "abstract": "A table arranging data in rows and columns is a very effective data structure, which has been widely used in business and scientific research. Considering large-scale tabular data in online and offline documents, automatic table recognition has attracted increasing attention from the document analysis community. Though human can easily understand the structure of tables, it remains a challenge for machines to understand that, especially due to a variety of different table layouts and styles. Existing methods usually model a table as either the markup sequence or the adjacency matrix between different table cells, failing to address the importance of the logical location of table cells, e.g., a cell is located in the first row and the second column of the table. In this paper, we reformulate the problem of table structure recognition as the table graph reconstruction, and propose an end-to-end trainable table graph reconstruction network (TGRNet) for table structure recognition. Specifically, the proposed method has two main branches, a cell detection branch and a cell logical location branch, to jointly predict the spatial location and the logical location of different cells. Experimental results on three popular table recognition datasets and a new dataset with table graph annotations (TableGraph-350K) demonstrate the effectiveness of the proposed TGRNet for table structure recognition. Code and annotations will be made publicly available at https://github.com/xuewenyuan/TGRNet.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51469630",
                        "name": "Wenyuan Xue"
                    },
                    {
                        "authorId": "2110431812",
                        "name": "Baosheng Yu"
                    },
                    {
                        "authorId": "2119293226",
                        "name": "Wen Wang"
                    },
                    {
                        "authorId": "2075330732",
                        "name": "Dacheng Tao"
                    },
                    {
                        "authorId": "1612980447",
                        "name": "Qingyong Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "With the great success of deep neural network in computer vision field, works began to focus on the image-based table with more general structures [21,30,24,9,13,36,23,14,33]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "ea25282d27368d3d04db91b165b5003d63e335d6",
                "externalIds": {
                    "DBLP": "conf/icdar/QiaoLCZPNRT021",
                    "ArXiv": "2105.06224",
                    "DOI": "10.1007/978-3-030-86549-8_7",
                    "CorpusId": 234482682
                },
                "corpusId": 234482682,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/ea25282d27368d3d04db91b165b5003d63e335d6",
                "title": "LGPMA: Complicated Table Structure Recognition with Local and Global Pyramid Mask Alignment",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2065512194",
                        "name": "Liang Qiao"
                    },
                    {
                        "authorId": "2109614687",
                        "name": "Zaisheng Li"
                    },
                    {
                        "authorId": "2398015",
                        "name": "Zhanzhan Cheng"
                    },
                    {
                        "authorId": "2151333065",
                        "name": "Peng Zhang"
                    },
                    {
                        "authorId": "3290437",
                        "name": "Shiliang Pu"
                    },
                    {
                        "authorId": "1490934795",
                        "name": "Yi Niu"
                    },
                    {
                        "authorId": "144850642",
                        "name": "Wenqi Ren"
                    },
                    {
                        "authorId": "51151126",
                        "name": "Wenming Tan"
                    },
                    {
                        "authorId": "144894837",
                        "name": "Fei Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[102] has experimented with bi-directional recurrent neural networks along with Gated Recurrent Units (GRU) [103] to extract the structure of the table."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "bc8863440e26e48866a64f63438051d24880b793",
                "externalIds": {
                    "DBLP": "journals/access/HashmiLSAAA21",
                    "ArXiv": "2104.14272",
                    "DOI": "10.1109/ACCESS.2021.3087865",
                    "CorpusId": 233444247
                },
                "corpusId": 233444247,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/bc8863440e26e48866a64f63438051d24880b793",
                "title": "Current Status and Performance Analysis of Table Recognition in Document Images With Deep Neural Networks",
                "abstract": "The first phase of table recognition is to detect the tabular area in a document. Subsequently, the tabular structures are recognized in the second phase in order to extract information from the respective cells. Table detection and structural recognition are pivotal problems in the domain of table understanding. However, table analysis is a perplexing task due to the colossal amount of diversity and asymmetry in tables. Therefore, it is an active area of research in document image analysis. Recent advances in the computing capabilities of graphical processing units have enabled the deep neural networks to outperform traditional state-of-the-art machine learning methods. Table understanding has substantially benefited from the recent breakthroughs in deep neural networks. However, there has not been a consolidated description of the deep learning methods for table detection and table structure recognition. This review paper provides a thorough analysis of the modern methodologies that utilize deep neural networks. Moreover, it presents a comprehensive understanding of the current state-of-the-art and related challenges of table understanding in document images. The leading datasets and their intricacies have been elaborated along with the quantitative results. Furthermore, a brief overview is given regarding the promising directions that can further improve table analysis in document images.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1403379889",
                        "name": "K. Hashmi"
                    },
                    {
                        "authorId": "1743758",
                        "name": "M. Liwicki"
                    },
                    {
                        "authorId": "143749919",
                        "name": "D. Stricker"
                    },
                    {
                        "authorId": "2206035070",
                        "name": "Muhammad Adnan Afzal"
                    },
                    {
                        "authorId": "2206035072",
                        "name": "Muhammad Ahtsham Afzal"
                    },
                    {
                        "authorId": "145181206",
                        "name": "Muhammad Zeshan Afzal"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recurrent neural networks [29] have also been employed to handle the problem of table structure extraction [30], [31]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "2a242e4a54323eee9e0f514510b008d9b2119641",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2104-10538",
                    "ArXiv": "2104.10538",
                    "DOI": "10.1109/ACCESS.2021.3103413",
                    "CorpusId": 233324171
                },
                "corpusId": 233324171,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2a242e4a54323eee9e0f514510b008d9b2119641",
                "title": "Guided Table Structure Recognition Through Anchor Optimization",
                "abstract": "This paper presents the novel approach towards table structure recognition by leveraging the guided anchors. The concept differs from current state-of-the-art systems for table structure recognition that naively apply object detection methods. In contrast to prior techniques, first, we estimate the viable anchors for table structure recognition. Subsequently, these anchors are exploited to locate the rows and columns in tabular images. Furthermore, the paper introduces a simple and effective method that improves the results using tabular layouts in realistic scenarios. The proposed method is exhaustively evaluated on the two publicly available datasets of table structure recognition: ICDAR-2013 and TabStructDB. Moreover, we empirically established the validity of our method by implementing it on the previous approaches. We accomplished state-of-the-art results on the ICDAR-2013 dataset with an average F1-measure of 94.19% (92.06% for rows and 96.32% for columns). Thus, a relative error reduction of more than 25% is achieved. Furthermore, our proposed post-processing improves the average F1-measure to 95.46% that results in a relative error reduction of more than 35%. Moreover, we surpassed the baseline results on the TabStructDB dataset with an average F1-measure of 94.57% (94.08% for rows and 95.06% for columns).",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1403379889",
                        "name": "K. Hashmi"
                    },
                    {
                        "authorId": "143749919",
                        "name": "D. Stricker"
                    },
                    {
                        "authorId": "1743758",
                        "name": "M. Liwicki"
                    },
                    {
                        "authorId": "2207509298",
                        "name": "Muhammad Noman Afzal"
                    },
                    {
                        "authorId": "145181206",
                        "name": "Muhammad Zeshan Afzal"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[9] proposed to use the recurrent neural networks (RNN) to identify the table structure according to the characteristics that the cells have repetitive sequence characteristics on the row and column."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "e9c50d3d75798ef5265a2ab3253669df6246267d",
                "externalIds": {
                    "DBLP": "conf/icmlc2/KongBWCZ21",
                    "DOI": "10.1145/3457682.3457752",
                    "CorpusId": 235495067
                },
                "corpusId": 235495067,
                "publicationVenue": {
                    "id": "d79c0d2a-37de-4287-87e7-1e57576dcae7",
                    "name": "International Conference on Machine Learning and Computing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Mach Learn Cybern",
                        "International Conference on Machine Learning and Cybernetics",
                        "International Conference Machine Learning and Computing",
                        "Int Conf Mach Learn Comput",
                        "ICMLC"
                    ],
                    "url": "http://www.icmlc.com/"
                },
                "url": "https://www.semanticscholar.org/paper/e9c50d3d75798ef5265a2ab3253669df6246267d",
                "title": "A Gradient heatmap based Table Structure Recognition",
                "abstract": "Most methods to recognize the structure of a table are to use the object detection approach to directly locate each cell in the table or to segment the table line based on the fully convolutional network (FCN). The problem of the former is that it is laborious to recognize the distorted table, while the problem of the latter is that the sample imbalance makes it difficult to train the model. In this paper, a gradient heatmap based table structure recognition method is proposed, by exploring the gradient heatmaps of the vertical lines and horizontal lines in the table. Specifically, the pixels of the vertical lines of the table are obtained according to the gradient heatmap, then the pixels of the horizontal lines are obtained using the same method, and finally the table structure is restored by using the connected domain search method. Compared with the Single Shot MultiBox Detector (SSD) and Faster RCNN that directly detects cells, our Average Precision (AP) value reached up to 99.5%, which is much higher than the above models. Additionally, we demonstrate that the AP values of the proposed models are reduced almost negligibly when the IoU threshold increased from 0.5 to 0.75, while the AP value of the fast RCNN and SSD model decreased significantly.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2069275327",
                        "name": "Lingjun Kong"
                    },
                    {
                        "authorId": "2106679362",
                        "name": "Yunchao Bao"
                    },
                    {
                        "authorId": "1934355987",
                        "name": "Qianwen Wang"
                    },
                    {
                        "authorId": "47238733",
                        "name": "Lijun Cao"
                    },
                    {
                        "authorId": "2903770",
                        "name": "Shengmei Zhao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[21] exploit RNN based sequence model to capture the repetitive row/column structures."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5afded5e53199d2bee71c2067afde4b338d6d49c",
                "externalIds": {
                    "DOI": "10.1109/ICSP48669.2020.9321003",
                    "CorpusId": 231682183
                },
                "corpusId": 231682183,
                "publicationVenue": {
                    "id": "63410070-a9b9-46ac-bdec-92b016246795",
                    "name": "International Conference on the Software Process",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Signal Process",
                        "ICSP",
                        "Int Conf Softw Process",
                        "International Conference on Signal Processing"
                    ],
                    "url": "http://www.ece.utexas.edu/~perry/prof/ispa/index.html"
                },
                "url": "https://www.semanticscholar.org/paper/5afded5e53199d2bee71c2067afde4b338d6d49c",
                "title": "A Deep Semantic Segmentation Model for Image-based Table Structure Recognition",
                "abstract": "Table structure recognition is a crucial step for automatic table information extraction. It is conventional to utilize the features such as ruling lines or words for parsing the rows, columns and cells in a table. However, these conventional methods are ineffective for image-based tables when ruling lines are not visible or the words cannot be recognized through the OCR system. In order to overcome these problems, we propose a deep semantic segmentation model for image-based table structure recognition. Specifically, it is an end-to-end semantic segmentation neural network to determine a pixel-wise prediction map for an input table image where the labels are row separator, column separator, cell content and background. Moreover, by making the connected componnet analysis on the prediction map, we can obtain the bounding boxes of row separators, column separators and cell contents, more accurately. Then we number row/column separators in order by coordinate sorting. Thus, we can make full use of relative positions between row/column separators and cell contents, and further assign the row/column number to each cell. Due to the lack of training data, a large amount of synthetic data are automatically generated in our experiments. It is demonstrated by the experimental results that our proposed model is suitable for various table types, which can achieve 0.9769 and 0.9343 average F1 scores on a generative dataset when the IoU threshold is set to 0.6 and 0.8, respectively.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2047123130",
                        "name": "Y. Zou"
                    },
                    {
                        "authorId": "1685259",
                        "name": "Jinwen Ma"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recurrent neural networks (RNNs) are used to predict independent outputs and future input information [2]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "79ab8dc2fd4b7e07652198ad0b092de33ffe37a3",
                "externalIds": {
                    "DOI": "10.1109/CSCI51800.2020.00096",
                    "CorpusId": 235616380
                },
                "corpusId": 235616380,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/79ab8dc2fd4b7e07652198ad0b092de33ffe37a3",
                "title": "Forecasting Method based upon GRU-based Deep Learning Model",
                "abstract": "In this research, the world model has a modified RNN model carried out by a bi-directional gated recurrent unit (BGRU) as opposed to a traditional long short-term memory (LSTM) model. BGRU tends to use less memory while executing and training faster than an LSTM, as it uses fewer training parameters. However, the LSTM model provides greater accuracy with datasets using longer sequences. Based upon practical implementation, the BGRU model produced better performance results. In BGRU, the memory is combined with the network. There is no update gate and forget in the GRU. The forget and update gate are treated as one unit thus it is the primary reason of parameter reduction.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2114851599",
                        "name": "A. Almalki"
                    },
                    {
                        "authorId": "1678900",
                        "name": "P. Wocjan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "and scanned tables, and bidirectional RNNs and LSTMs are frequently adopted in web tables to capture the order of rows and columns [15, 16, 21, 28]."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "088cb72b70055713a89184633769b0c6e5dba1aa",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2010-12537",
                    "MAG": "3094024803",
                    "CorpusId": 225062068
                },
                "corpusId": 225062068,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/088cb72b70055713a89184633769b0c6e5dba1aa",
                "title": "Structure-aware Pre-training for Table Understanding with Tree-based Transformers",
                "abstract": "Tables are widely used with various structures to organize and present data. Recent attempts on table understanding mainly focus on relational tables, yet overlook to other common table structures. In this paper, we propose TUTA, a unified pre-training architecture for understanding generally structured tables. Since understanding a table needs to leverage both spatial, hierarchical, and semantic information, we adapt the self-attention strategy with several key structure-aware mechanisms. First, we propose a novel tree-based structure called a bi-dimensional coordinate tree, to describe both the spatial and hierarchical information in tables. Upon this, we extend the pre-training architecture with two core mechanisms, namely the tree-based attention and tree-based position embedding. Moreover, to capture table information in a progressive manner, we devise three pre-training objectives to enable representations at the token, cell, and table levels. TUTA pre-trains on a wide range of unlabeled tables and fine-tunes on a critical task in the field of table structure understanding, i.e. cell type classification. Experiment results show that TUTA is highly effective, achieving state-of-the-art on four well-annotated cell type classification datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1390877035",
                        "name": "Zhiruo Wang"
                    },
                    {
                        "authorId": "2113413583",
                        "name": "Haoyu Dong"
                    },
                    {
                        "authorId": "2053919577",
                        "name": "Ran Jia"
                    },
                    {
                        "authorId": "2133337119",
                        "name": "Jia Li"
                    },
                    {
                        "authorId": "2068057294",
                        "name": "Zhiyi Fu"
                    },
                    {
                        "authorId": "123443478",
                        "name": "Shi Han"
                    },
                    {
                        "authorId": "1485159990",
                        "name": "Dongmei Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Among these, the problem of table structure recognition has been of high interest in the community [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20].",
                "In the space of document images, researchers have been working on understanding equations [30,31], figures [32,33] and tables [6,7,8,9,10,11,12,13,14,15,16,17].",
                "Table structure recognition is a challenging problem due to complex structures and high variability in table layouts [4,5,6,7,8,9,10,11,12,13,14,15,16,17].",
                "[15], through their gru based sequential models, showed improvements over several cnn based methods for table structure extraction.",
                "Many cognitive methods [6,7,8,9,10,11,12,14,15,16,37,38,39,40,41,42,43] have also been presented to understand table structures as they are robust to the input type (whether being scanned images or native digital).",
                "We compare the performance of our tabstruct-net against seven benchmark methods \u2014 deepdesrt [7], tablenet [12], graphtsr [14], splerge [10], dgcnn [9], Bi-directional gru [15] and Image-to-Text [11]."
            ],
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "30860e7c569d777db8d2b6fb0f7c374965ac62dd",
                "externalIds": {
                    "MAG": "3109870706",
                    "DBLP": "conf/eccv/RajaMJ20",
                    "ArXiv": "2010.04565",
                    "DOI": "10.1007/978-3-030-58604-1_5",
                    "CorpusId": 221990801
                },
                "corpusId": 221990801,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/30860e7c569d777db8d2b6fb0f7c374965ac62dd",
                "title": "Table Structure Recognition using Top-Down and Bottom-Up Cues",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2053910624",
                        "name": "S. Raja"
                    },
                    {
                        "authorId": "2896521",
                        "name": "Ajoy Mondal"
                    },
                    {
                        "authorId": "1694502",
                        "name": "C. V. Jawahar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[46] Marmot 2K ICDAR-2013 204 ICDAR-2013 34 0."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "08b65e546c84f36e81010798a1c64e49372ea5c9",
                "externalIds": {
                    "ArXiv": "2008.10831",
                    "DBLP": "conf/icpr/AgarwalMJ20",
                    "MAG": "3081020959",
                    "DOI": "10.1109/ICPR48806.2021.9411922",
                    "CorpusId": 221293251
                },
                "corpusId": 221293251,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/08b65e546c84f36e81010798a1c64e49372ea5c9",
                "title": "CDeC-Net: Composite Deformable Cascade Network for Table Detection in Document Images",
                "abstract": "Localizing page elements/objects such as tables, figures, equations, etc. is the primary step in extracting information from document images. We propose a novel end-to-end trainable deep network, (cnec-xet) for detecting tables present in the documents. The proposed network consists of a multistage extension of Mask R-CNN with a dual backbone having deformable convolution for detecting tables varying in scale with high detection accuracy at higher IoU threshold. We empirically evaluate CDeC-Net on the publicly available benchmark datasets with extensive experiments. Our solution has three important properties: (i) a single trained model CDeC-Net\u2021that performs well across all the popular benchmark datasets; (ii) we report excellent performances across multiple, including higher, thresholds of IoU; (iii) by following the same protocol of the recent papers for each of the benchmarks, we consistently demonstrate the superior quantitative performance. Our code and models are publicly available at https://github.com/mdv3101/CDeCNet for enabling reproducibility of the results.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2148629212",
                        "name": "Madhav Agarwal"
                    },
                    {
                        "authorId": "2896521",
                        "name": "Ajoy Mondal"
                    },
                    {
                        "authorId": "1694502",
                        "name": "C. V. Jawahar"
                    }
                ]
            }
        },
        {
            "contexts": [
                " 57.40 52.20 pdf2table [40] N 59.51 57.52 58.50 TABFIND [36] N 70.52 68.74 69.62 Ours GTE N 94.70 94.49 94.57 Academic Systems Tensmeyer [37] Y 94.64 95.89 95.26 Nurminen [7] Y 94.09 95.12 94.60 Khan [17] Y 90.12 96.92 93.39 TABFIND [36] Y 64.01 61.44 62.70 Ours GTE Y 95.74 95.39 95.55 Cell Structure Ablation Study To analyze our GTE-Cell network further, we compare the several variations in Table 4 u"
            ],
            "isInfluential": true,
            "intents": [],
            "citingPaper": {
                "paperId": "73a906a988e54defee536a120125f957059d595e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2005-00589",
                    "MAG": "3022479961",
                    "ArXiv": "2005.00589",
                    "DOI": "10.1109/WACV48630.2021.00074",
                    "CorpusId": 218487305
                },
                "corpusId": 218487305,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/73a906a988e54defee536a120125f957059d595e",
                "title": "Global Table Extractor (GTE): A Framework for Joint Table Identification and Cell Structure Recognition Using Visual Context",
                "abstract": "Documents are often used for knowledge sharing and preservation in business and science, within which are tables that capture most of the critical data. Unfortunately, most documents are stored and distributed as PDF or scanned images, which fail to preserve logical table structure. Recent vision-based deep learning approaches have been proposed to address this gap, but most still cannot achieve state-of-the-art results. We present Global Table Extractor (GTE), a vision-guided systematic framework for joint table detection and cell structured recognition, which could be built on top of any object detection model. With GTE-Table, we invent a new penalty based on the natural cell containment constraint of tables to train our table network aided by cell location predictions. GTE-Cell is a new hierarchical cell detection network that leverages table styles. Further, we design a method to automatically label table and cell structure in existing documents to cheaply create a large corpus of training and test data. We use this to enhance PubTabNet with cell labels and create FinTabNet, real-world and complex scientific and financial datasets with detailed table structure annotations to help train and test structure recognition. Our framework surpasses previous state-of-the-art results on the ICDAR 2013 and ICDAR 2019 table competition in both table detection and cell structure recognition. Further experiments demonstrate a greater than 45% improvement in cell structure recognition when compared to a vanilla RetinaNet object detection model in our new out-of-domain FinTabNet.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1662767314",
                        "name": "Xinyi Zheng"
                    },
                    {
                        "authorId": "143894459",
                        "name": "D. Burdick"
                    },
                    {
                        "authorId": "145378077",
                        "name": "Lucian Popa"
                    },
                    {
                        "authorId": "31856827",
                        "name": "N. Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Disadvantages of neural networks: \uf0b7 a high probability of the training and adaptation method hitting a local extremum [13]; \uf0b7 inaccessibility for human understanding of the knowledge accumulated by the network (it is impossible to represent the relationship between input and output in the form of rules), since they are distributed among all of the elements of the neural network and are presented in the form of its weight coefficients [14, 15]; \uf0b7 difficulty in determining the structure of the network, since there are no algorithms for calculating the number of layers and neurons in each layer for specific applications [8, 16]; \uf0b7 difficulty in forming a representative sample [17, 18]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c6af8e50939ff7e945019f98dc2c94d230643cb0",
                "externalIds": {
                    "DBLP": "conf/intelitsis/FedorovNN23",
                    "CorpusId": 258218452
                },
                "corpusId": 258218452,
                "publicationVenue": {
                    "id": "2fbc399d-2fbd-4281-b999-990521efd96e",
                    "name": "International Workshop on Intelligent Information Technologies & Systems of Information Security",
                    "type": "conference",
                    "alternate_names": [
                        "IntelITSIS",
                        "Int Workshop Intell Inf Technol  Syst Inf Secur"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c6af8e50939ff7e945019f98dc2c94d230643cb0",
                "title": "Method for Creating a Computer Agent Based on the Jordan-Elman Neural Network for Supply Chains",
                "abstract": "The paper proposes a method for creating a computer agent for supply chains. The novelty of the research lies in the fact that to increase the efficiency of the computer agent, its functioning is based on the connectionist approach instead of using the classical production and logical approach. To expand the range of tasks solved by agents, the article proposes a reactive agent with feedback, which makes a decision based on perception or a sequence of perceptions and a previous action or a sequence of previous actions, as well as a reactive agent with an internal state and feedback, which is an extension of the reactive agent with an internal state and makes a decision based on perception, previous internal state, and previous action. For a reactive agent with an internal state and feedback, a Jordan-Elman artificial neural network was proposed, which is a combination of Jordan and Elman neural networks, and the structure of its model was determined in the course of a numerical study. The experiments performed showed that when the number of hidden neurons is not less than the number of neurons in the input layer, the value of the root mean square error does not change significantly, and the selected network gives results with a minimum error. Methods for determining the parameters of the proposed Jordan-Elman neural network model were proposed. This made it possible to ensure high speed and accuracy of calculations based on the model. The proposed method for creating an agent based on artificial neural networks can be used in various intelligent computer systems that use multi-agent interaction.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47289941",
                        "name": "E. Fedorov"
                    },
                    {
                        "authorId": "65905228",
                        "name": "O. Nechyporenko"
                    },
                    {
                        "authorId": "2161999025",
                        "name": "Tetiana Neskorodieva"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The following recurrent networks are most often used as neural networks for translation: \u2022 Elman neural network (ENN or SRN) [12, 13], the simplest of recurrent neural networks; \u2022 bidirectional recurrent neural network (BRNN) [14, 15], which is built based on two Elman neural networks; \u2022 long short-term memory (LSTM) [16, 17]; \u2022 bidirectional recurrent neural network (BLSTM) [18, 19], which is built based on two LSTM neural networks; \u2022 gated recurrent unit (GRU) [20, 21]; \u2022 bidirectional recurrent neural network (BGRU) [22], which is built based on two GRU neural networks."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3a94fc32beb35feefa5ab623018f6058aa58193b",
                "externalIds": {
                    "DBLP": "conf/colins/FedorovN23",
                    "CorpusId": 259288496
                },
                "corpusId": 259288496,
                "publicationVenue": {
                    "id": "983aa6ce-f5da-4978-9b44-638d68ddac50",
                    "name": "International Conference on Computational Linguistics and Intelligent Systems",
                    "type": "conference",
                    "alternate_names": [
                        "COLINS",
                        "Int Conf Comput Linguistics Intell Syst"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3a94fc32beb35feefa5ab623018f6058aa58193b",
                "title": "Linguistic Constructions Translation Method Based on Neural Networks",
                "abstract": "The paper proposes a linguistic constructions translation method based on recurrent neural networks. The novelty of the study lies in the fact that to ensure the interaction of software agents representing subjects within supply chains, four artificial neural network models for the translation of the linguistic structures were created, a criterion for evaluating the training effectiveness of the proposed models was selected, and the parameters of the proposed models were identified based on the Adam method. In the created models, unlike the existing translational neural networks, the decoder does not have feedback from the output layer to the hidden layer. The developed models and methods for their parametric identification make it possible to improve the accuracy of translation of natural language constructions. The created natural language constructions translation method based on neural networks can be used in various intelligent computer systems that use the translation of linguistic constructions.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47289941",
                        "name": "E. Fedorov"
                    },
                    {
                        "authorId": "65905228",
                        "name": "O. Nechyporenko"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "6c411f52c151fe537ee76c310f45f0dd3da88e92",
                "externalIds": {
                    "DBLP": "series/sbcs/Bhowmik23",
                    "DOI": "10.1007/978-981-99-4277-0",
                    "CorpusId": 260337124
                },
                "corpusId": 260337124,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/6c411f52c151fe537ee76c310f45f0dd3da88e92",
                "title": "Document Layout Analysis",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3272848",
                        "name": "Showmik Bhowmik"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The disadvantages are a higher complexity of determining the architecture, a lower learning rate than in a conventional Elman neural network; \u2022 idirectional recurrent neural network (BGRU) [25], which is a recurrent network and is built on the basis of two GRU neural networks."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "9a0b307eb6f6d87d28a860e9e88b5912c5e0a658",
                "externalIds": {
                    "DBLP": "conf/colins/FedorovN22",
                    "CorpusId": 250625462
                },
                "corpusId": 250625462,
                "publicationVenue": {
                    "id": "983aa6ce-f5da-4978-9b44-638d68ddac50",
                    "name": "International Conference on Computational Linguistics and Intelligent Systems",
                    "type": "conference",
                    "alternate_names": [
                        "COLINS",
                        "Int Conf Comput Linguistics Intell Syst"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9a0b307eb6f6d87d28a860e9e88b5912c5e0a658",
                "title": "Method for Recognizing Linguistic Constructions Based on Stochastic Neural Networks",
                "abstract": "The paper proposes a method for recognizing linguistic constructions based on stochastic neural networks. The novelty of the study lies in the fact that in order to ensure the interaction of software agents representing subjects that operate within supply chains, two models of an artificial neural network were created to recognize natural language structures based on the restricted Boltzmann machine (in contrast to it, the neurons of the hidden layer were interconnected), a criterion for evaluating the effectiveness of training the proposed models was chosen, the parameters of the proposed models were identified based on the contrastive divergence. The proposed models and methods for their parametric identification make it possible to improve the recognition accuracy of natural language constructions. The proposed method for recognizing linguistic structures based on stochastic neural networks can be used in various intelligent systems that use the recognition of natural language structures.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47289941",
                        "name": "E. Fedorov"
                    },
                    {
                        "authorId": "65905228",
                        "name": "O. Nechyporenko"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Top-down methods [19,33,34,37] try to split entire table images into rows and columns using detection or segmentation models, then cells can be obtained through row-column intersection."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "24dd39035349c38d0bff17bbe5203cfcfd0ad79a",
                "externalIds": {
                    "DBLP": "conf/icdar/LiYZL21",
                    "DOI": "10.1007/978-3-030-86549-8_6",
                    "CorpusId": 237458405
                },
                "corpusId": 237458405,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/24dd39035349c38d0bff17bbe5203cfcfd0ad79a",
                "title": "Adaptive Scaling for Archival Table Structure Recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118890804",
                        "name": "Xiaohe Li"
                    },
                    {
                        "authorId": "145820427",
                        "name": "Fei Yin"
                    },
                    {
                        "authorId": "2870877",
                        "name": "Xu-Yao Zhang"
                    },
                    {
                        "authorId": "1689269",
                        "name": "Cheng-Lin Liu"
                    }
                ]
            }
        }
    ]
}