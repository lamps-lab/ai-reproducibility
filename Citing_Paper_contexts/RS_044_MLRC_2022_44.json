{
    "offset": 0,
    "data": [
        {
            "contexts": [
                "samples into splits with disjoint compositional structures [23, 52].",
                "[52] Peter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "16be9876eebcda031c15efaf4cfe3ba49146b329",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-13883",
                    "ArXiv": "2307.13883",
                    "DOI": "10.48550/arXiv.2307.13883",
                    "CorpusId": 260164542
                },
                "corpusId": 260164542,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/16be9876eebcda031c15efaf4cfe3ba49146b329",
                "title": "ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis",
                "abstract": "When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder. We then propose ExeDec, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step. ExeDec has better synthesis performance and greatly improved compositional generalization ability compared to baselines.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2362367",
                        "name": "Kensen Shi"
                    },
                    {
                        "authorId": "2110597723",
                        "name": "Joey Hong"
                    },
                    {
                        "authorId": "1771307",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "38253388",
                        "name": "Pengcheng Yin"
                    },
                    {
                        "authorId": "152549864",
                        "name": "Charles Sutton"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As the posed question does not follow the identical distribution of the training dataset adopted by the semantic parsing model (Shaw et al., 2021; Yin et al., 2021), it is falsely parsed with the Or operator, which should be an And operator, causing the structure error of the KB query."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "398488059cc7591789d4885895aae0119fa96246",
                "externalIds": {
                    "ArXiv": "2307.03130",
                    "DBLP": "conf/acl/0002CLCXYJXZHL23",
                    "ACL": "2023.acl-demo.17",
                    "DOI": "10.48550/arXiv.2307.03130",
                    "CorpusId": 259360898
                },
                "corpusId": 259360898,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/398488059cc7591789d4885895aae0119fa96246",
                "title": "VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge Base Question Answering",
                "abstract": "We present Visual Knowledge oriented Programming platform (VisKoP), a knowledge base question answering (KBQA) system that integrates human into the loop to edit and debug the knowledge base (KB) queries. VisKoP not only provides a neural program induction module, which converts natural language questions into knowledge oriented program language (KoPL), but also maps KoPL programs into graphical elements. KoPL programs can be edited with simple graphical operators, such as \u201ddragging\u201d to add knowledge operators and \u201dslot filling\u201d to designate operator arguments. Moreover, VisKoP provides auto-completion for its knowledge base schema and users can easily debug the KoPL program by checking its intermediate results. To facilitate the practical KBQA on a million-entity-level KB, we design a highly efficient KoPL execution engine for the back-end. Experiment results show that VisKoP is highly efficient and user interaction can fix a large portion of wrong KoPL programs to acquire the correct answer. The VisKoP online demo, highly efficient KoPL engine, and screencast video are now publicly available.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1423719712",
                        "name": "Zijun Yao"
                    },
                    {
                        "authorId": "2703296",
                        "name": "Yuan-Kuo Chen"
                    },
                    {
                        "authorId": "48574888",
                        "name": "Xin Lv"
                    },
                    {
                        "authorId": "1712738522",
                        "name": "S. Cao"
                    },
                    {
                        "authorId": "2220101512",
                        "name": "Amy Xin"
                    },
                    {
                        "authorId": "2116034394",
                        "name": "Jifan Yu"
                    },
                    {
                        "authorId": "2109790016",
                        "name": "Hailong Jin"
                    },
                    {
                        "authorId": "2187441024",
                        "name": "Jianjun Xu"
                    },
                    {
                        "authorId": "2151330832",
                        "name": "Peng Zhang"
                    },
                    {
                        "authorId": "2055765060",
                        "name": "Lei Hou"
                    },
                    {
                        "authorId": "2133353675",
                        "name": "Juanzi Li"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "a8e19d99cf2796f2f91f239f822e2fc40e699bd3",
                "externalIds": {
                    "ArXiv": "2306.11420",
                    "DBLP": "journals/corr/abs-2306-11420",
                    "ACL": "2023.acl-long.93",
                    "DOI": "10.48550/arXiv.2306.11420",
                    "CorpusId": 259202876
                },
                "corpusId": 259202876,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/a8e19d99cf2796f2f91f239f822e2fc40e699bd3",
                "title": "On Evaluating Multilingual Compositional Generalization with Translated Datasets",
                "abstract": "Compositional generalization allows efficient learning and human-like inductive biases. Since most research investigating compositional generalization in NLP is done on English, important questions remain underexplored. Do the necessary compositional generalization abilities differ across languages? Can models compositionally generalize cross-lingually? As a first step to answering these questions, recent work used neural machine translation to translate datasets for evaluating compositional generalization in semantic parsing. However, we show that this entails critical semantic distortion. To address this limitation, we craft a faithful rule-based translation of the MCWQ dataset from English to Chinese and Japanese. Even with the resulting robust benchmark, which we call MCWQ-R, we show that the distribution of compositions still suffers due to linguistic divergences, and that multilingual models still struggle with cross-lingual compositional generalization. Our dataset and methodology will serve as useful resources for the study of cross-lingual compositional generalization in other tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Zi Wang"
                    },
                    {
                        "authorId": "2086349",
                        "name": "Daniel Hershcovich"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For database schema serialization, previous PLM-basedworks [17, 29, 36, 37] directly concatenate the table/column names and require the model to output these names to form an SQL query.",
                "SMBOP introduces a semi-autoregressive bottom-upNL2SQLmodel as an alternative approach to top-down autoregressive model.",
                "Type Perturbation # Test SMBOP [34] T5-3B LK [37] Picard [36] RESDSQL [17] ChatGPT ChatGPT + ZeroNL2SQL",
                "The first type is the SOTA PLM-based models fine-tuned on the Spider training set, including SMBOP [34], T5-3B LK [37], Picard [36] and RESDSQL [17].",
                "For example, on the DBcontent-equivalence test set, the EX accuracy of SMBOP [37] is only 37.2%, which is much worse than its average performance.",
                "For example, on the DBcontent-equivalence test set, the EX accuracy of SMBOP [37] is only 37.",
                "Previous methods [17, 29, 36, 37] cannot guarantee this when test environment changes."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "71e996ff55b972946b9fe0f88394c19425f5a3ab",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-08891",
                    "ArXiv": "2306.08891",
                    "DOI": "10.48550/arXiv.2306.08891",
                    "CorpusId": 259165667
                },
                "corpusId": 259165667,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/71e996ff55b972946b9fe0f88394c19425f5a3ab",
                "title": "Interleaving Pre-Trained Language Models and Large Language Models for Zero-Shot NL2SQL Generation",
                "abstract": "Zero-shot NL2SQL is crucial in achieving natural language to SQL that is adaptive to new environments (e.g., new databases, new linguistic phenomena or SQL structures) with zero annotated NL2SQL samples from such environments. Existing approaches either fine-tune pre-trained language models (PLMs) based on annotated data or use prompts to guide fixed large language models (LLMs) such as ChatGPT. PLMs can perform well in schema alignment but struggle to achieve complex reasoning, while LLMs is superior in complex reasoning tasks but cannot achieve precise schema alignment. In this paper, we propose a ZeroNL2SQL framework that combines the complementary advantages of PLMs and LLMs for supporting zero-shot NL2SQL. ZeroNL2SQL first uses PLMs to generate an SQL sketch via schema alignment, then uses LLMs to fill the missing information via complex reasoning. Moreover, in order to better align the generated SQL queries with values in the given database instances, we design a predicate calibration method to guide the LLM in completing the SQL sketches based on the database instances and select the optimal SQL query via an execution-based strategy. Comprehensive experiments show that ZeroNL2SQL can achieve the best zero-shot NL2SQL performance on real-world benchmarks. Specifically, ZeroNL2SQL outperforms the state-of-the-art PLM-based methods by 3.2% to 13% and exceeds LLM-based methods by 10% to 20% on execution accuracy.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2082344591",
                        "name": "Zihui Gu"
                    },
                    {
                        "authorId": "1704755170",
                        "name": "Ju Fan"
                    },
                    {
                        "authorId": "2213989628",
                        "name": "Nan Tang"
                    },
                    {
                        "authorId": "151226330",
                        "name": "Songyue Zhang"
                    },
                    {
                        "authorId": "2220137935",
                        "name": "Yuxin Zhang"
                    },
                    {
                        "authorId": "48354042",
                        "name": "Zui Chen"
                    },
                    {
                        "authorId": "50260667",
                        "name": "Lei Cao"
                    },
                    {
                        "authorId": "2108491555",
                        "name": "Guoliang Li"
                    },
                    {
                        "authorId": "2053630301",
                        "name": "Sam Madden"
                    },
                    {
                        "authorId": "2152944669",
                        "name": "Xiaoyong Du"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To support Text-to-SQL, similar to [24, 26], we fine-tune the model in an end-to-end manner.",
                "Different from the previous methods with task-specific design, PLM-based methods [24, 26] can be applied to different text-to-SQL datasets without specific modifications to the base PLMs.",
                "Specifically, Picard [24] and [26] also achieve good performance in the few-shot scenario using general PLMs (e.",
                "Transformer-based encoder-decoder models have been widely used to support Text-to-SQL, and representative models include NQG-T5 [26], PICARD [24], UnifiedSKG [34], etc."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "9c8fdba35813e5a56b0445cd8b8c13a9187c047f",
                "externalIds": {
                    "DBLP": "journals/pacmmod/GuF00JM023",
                    "DOI": "10.1145/3589292",
                    "CorpusId": 259213208
                },
                "corpusId": 259213208,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/9c8fdba35813e5a56b0445cd8b8c13a9187c047f",
                "title": "Few-shot Text-to-SQL Translation using Structure and Content Prompt Learning",
                "abstract": "A common problem with adopting Text-to-SQL translation in database systems is poor generalization. Specifically, when there is limited training data on new datasets, existing few-shot Text-to-SQL techniques, even with carefully designed textual prompts on pre-trained language models (PLMs), tend to be ineffective. In this paper, we present a divide-and-conquer framework to better support few-shot Text-to-SQL translation, which divides Text-to-SQL translation into two stages (or sub-tasks), such that each sub-task is simpler to be tackled. The first stage, called the structure stage, steers a PLM to generate an SQL structure (including SQL commands such as SELECT, FROM, WHERE and SQL operators such as <\", ?>\") with placeholders for missing identifiers. The second stage, called the content stage, guides a PLM to populate the placeholders in the generated SQL structure with concrete values (including SQL identifies such as table names, column names, and constant values). We propose a hybrid prompt strategy that combines learnable vectors and fixed vectors (i.e., word embeddings of textual prompts), such that the hybrid prompt can learn contextual information to better guide PLMs for prediction in both stages. In addition, we design keyword constrained decoding to ensure the validity of generated SQL structures, and structure guided decoding to guarantee the model to fill correct content. Extensive experiments, by comparing with ten state-of-the-art Text-to-SQL solutions at the time of writing, show that SC-Prompt significantly outperforms them in the few-shot scenario. In particular, on the widely-adopted Spider dataset, given less than 500 labeled training examples (5% of the official training set), SC-Prompt outperforms the previous SOTA methods by around 5% on accuracy.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2082344591",
                        "name": "Zihui Gu"
                    },
                    {
                        "authorId": "1704755170",
                        "name": "Ju Fan"
                    },
                    {
                        "authorId": "2213989628",
                        "name": "Nan Tang"
                    },
                    {
                        "authorId": "50260667",
                        "name": "Lei Cao"
                    },
                    {
                        "authorId": "2220348399",
                        "name": "Bowen Jia"
                    },
                    {
                        "authorId": "2053630301",
                        "name": "Sam Madden"
                    },
                    {
                        "authorId": "2152944669",
                        "name": "Xiaoyong Du"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These benchmarks contain not only synthetic evaluations deliberately designed for diverse categories of systematic generalization but also non-synthetic ones additionally requiring capabilities of neural models in handling natural language variations (Shaw et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "11bfa65df6d7ee514c7f9e404b9c59cda66851e5",
                "externalIds": {
                    "DBLP": "conf/acl/Li0L23",
                    "ACL": "2023.acl-long.157",
                    "ArXiv": "2306.02840",
                    "DOI": "10.48550/arXiv.2306.02840",
                    "CorpusId": 259076194
                },
                "corpusId": 259076194,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/11bfa65df6d7ee514c7f9e404b9c59cda66851e5",
                "title": "Learning to Substitute Spans towards Improving Compositional Generalization",
                "abstract": "Despite the rising prevalence of neural sequence models, recent empirical evidences suggest their deficiency in compositional generalization. One of the current de-facto solutions to this problem is compositional data augmentation, aiming to incur additional compositional inductive bias. Nonetheless, the improvement offered by existing handcrafted augmentation strategies is limited when successful systematic generalization of neural sequence models requires multi-grained compositional bias (i.e., not limited to either lexical or structural biases only) or differentiation of training sequences in an imbalanced difficulty distribution. To address the two challenges, we first propose a novel compositional augmentation strategy dubbed Span Substitution (SpanSub) that enables multi-grained composition of substantial substructures in the whole training set. Over and above that, we introduce the Learning to Substitute Span (L2S2) framework which empowers the learning of span substitution probabilities in SpanSub in an end-to-end manner by maximizing the loss of neural sequence models, so as to outweigh those challenging compositions with elusive concepts and novel surroundings. Our empirical results on three standard compositional generalization benchmarks, including SCAN, COGS and GeoQuery (with an improvement of at most 66.5%, 10.3%, 1.2%, respectively), demonstrate the superiority of SpanSub, L2S2 and their combination.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2186651937",
                        "name": "Zhaoyi Li"
                    },
                    {
                        "authorId": "2112556840",
                        "name": "Ying Wei"
                    },
                    {
                        "authorId": "1862782",
                        "name": "Defu Lian"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(2) Because finding the most probable string t2 from p\u03b8(t2|t1) is NP-hard (Sima\u2019an, 1996; Lyngs\u00f8 and Pedersen, 2002), we follow Kim (2021) to use a decoding strategy with heavy sampling."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "74a4f61b00ed6b809cb8c6a04ffe9f2a46238fcb",
                "externalIds": {
                    "ArXiv": "2306.02671",
                    "ACL": "2023.acl-short.163",
                    "DBLP": "conf/acl/LouT23",
                    "DOI": "10.48550/arXiv.2306.02671",
                    "CorpusId": 259076423
                },
                "corpusId": 259076423,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/74a4f61b00ed6b809cb8c6a04ffe9f2a46238fcb",
                "title": "Improving Grammar-based Sequence-to-Sequence Modeling with Decomposition and Constraints",
                "abstract": "Neural QCFG is a grammar-based sequence-to-sequence model with strong inductive biases on hierarchical structures. It excels in interpretability and generalization but suffers from expensive inference. In this paper, we study two low-rank variants of Neural QCFG for faster inference with different trade-offs between efficiency and expressiveness. Furthermore, utilizing the symbolic interface provided by the grammar, we introduce two soft constraints over tree hierarchy and source coverage. We experiment with various datasets and find that our models outperform vanilla Neural QCFG in most settings.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2061806821",
                        "name": "Chao Lou"
                    },
                    {
                        "authorId": "40341553",
                        "name": "Kewei Tu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "964dcd26e9e2b5bb2c309181b0796ad11e0b18e2",
                "externalIds": {
                    "DOI": "10.1109/icassp49357.2023.10097246",
                    "CorpusId": 258545704
                },
                "corpusId": 258545704,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/964dcd26e9e2b5bb2c309181b0796ad11e0b18e2",
                "title": "Database-Aware ASR Error Correction for Speech-to-SQL Parsing",
                "abstract": "RESEARCH INTERESTS Databases and data management/systems for machine learning/artificial intelligencebased data analytics, with a focus on problems related to usability, scalability, resource efficiency, and ease of development/deployment. I enjoy working on problems that are motivated by real applications and are formally grounded. My work spans the whole gamut of building new systems, new algorithmics, theoretical analysis, empirical analysis, and working with data practitioners (data scientists, ML/data/software engineers, and domain scientists) to deploy my research.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "30046004",
                        "name": "Yutong Shao"
                    },
                    {
                        "authorId": "30512587",
                        "name": "Arun C. S. Kumar"
                    },
                    {
                        "authorId": "3115592",
                        "name": "Ndapandula Nakashole"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2021b) and NLP fields (Shaw et al., 2021; Furrer et al., 2020), but it\u2019s under-explored in dialogue, and also, we argue that data-level explicit dividing is simple and more interpretable than that of implicit representation-level dividing.",
                "\u2026disenchanted representation effectively improves the zero-shot generalization in the CV (Chen et al., 2021; Ye et al., 2021b) and NLP fields (Shaw et al., 2021; Furrer et al., 2020), but it\u2019s under-explored in dialogue, and also, we argue that data-level explicit dividing is simple and more\u2026"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "8392a47db625470e04214334967f79f02950cc31",
                "externalIds": {
                    "DBLP": "conf/acl/WangDCZ0WT023",
                    "ArXiv": "2306.00434",
                    "ACL": "2023.acl-long.114",
                    "DOI": "10.48550/arXiv.2306.00434",
                    "CorpusId": 258999590
                },
                "corpusId": 258999590,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/8392a47db625470e04214334967f79f02950cc31",
                "title": "Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking",
                "abstract": "Zero-shot transfer learning for Dialogue State Tracking (DST) helps to handle a variety of task-oriented dialogue domains without the cost of collecting in-domain data. Existing works mainly study common data- or model-level augmentation methods to enhance the generalization but fail to effectively decouple semantics of samples, limiting the zero-shot performance of DST. In this paper, we present a simple and effective \u201cdivide, conquer and combine\u201d solution, which explicitly disentangles the semantics of seen data, and leverages the performance and robustness with the mixture-of-experts mechanism. Specifically, we divide the seen data into semantically independent subsets and train corresponding experts, the newly unseen samples are mapped and inferred with mixture-of-experts with our designed ensemble inference.Extensive experiments on MultiWOZ2.1 upon T5-Adapter show our schema significantly and consistently improves the zero-shot performance, achieving the SOTA on settings without external knowledge, with only 10M trainable parameters.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2115979374",
                        "name": "Qingyue Wang"
                    },
                    {
                        "authorId": "46573238",
                        "name": "Liang Ding"
                    },
                    {
                        "authorId": "9310727",
                        "name": "Yanan Cao"
                    },
                    {
                        "authorId": "1895813",
                        "name": "Yibing Zhan"
                    },
                    {
                        "authorId": "1390641501",
                        "name": "Zheng Lin"
                    },
                    {
                        "authorId": "2108668664",
                        "name": "Shi Wang"
                    },
                    {
                        "authorId": "2140448089",
                        "name": "Dacheng Tao"
                    },
                    {
                        "authorId": "2148933499",
                        "name": "Li Guo"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "af705d648b5b16daa3dcc593bc593f2574d76c07",
                "externalIds": {
                    "ArXiv": "2305.19234",
                    "DBLP": "journals/corr/abs-2305-19234",
                    "DOI": "10.48550/arXiv.2305.19234",
                    "CorpusId": 258967345
                },
                "corpusId": 258967345,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/af705d648b5b16daa3dcc593bc593f2574d76c07",
                "title": "Grammar Prompting for Domain-Specific Language Generation with Large Language Models",
                "abstract": "Large language models (LLMs) can learn to perform a wide range of natural language tasks from just a handful of in-context examples. However, for generating strings from highly structured languages (e.g., semantic parsing to complex domain-specific languages), it is challenging for the LLM to generalize from just a few exemplars. We explore $\\textbf{grammar prompting}$ as a simple approach for enabling LLMs to use external knowledge and domain-specific constraints, expressed through a grammar expressed in Backus--Naur Form (BNF), during in-context learning. Grammar prompting augments each demonstration example with a specialized grammar that is minimally sufficient for generating the particular output example, where the specialized grammar is a subset of the full DSL grammar. For inference, the LLM first predicts a BNF grammar given a test input, and then generates the output according to the rules of the grammar. Experiments demonstrate that grammar prompting can enable LLMs to perform competitively on a diverse set of DSL generation tasks, including semantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and even molecule generation (SMILES).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2118640406",
                        "name": "Bailin Wang"
                    },
                    {
                        "authorId": null,
                        "name": "Zi Wang"
                    },
                    {
                        "authorId": "1524732527",
                        "name": "Xuezhi Wang"
                    },
                    {
                        "authorId": "145144022",
                        "name": "Yuan Cao"
                    },
                    {
                        "authorId": "2278009",
                        "name": "R. Saurous"
                    },
                    {
                        "authorId": "143827730",
                        "name": "Yoon Kim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Shaw et al. (2021) define the atom and compound for SQL statements and propose the TMCD split to repartition the dataset.",
                "Shaw et al. (2021) define the atom and compound for SQL statements and prop se the TMCD split to repartition the dataset.",
                "From another point of view, our compositional generalization scenario could also be viewed as a special case of TMCD split (Shaw et al., 2021), where the SQL templates and modification templates could be seen as atoms and their combination results are the compounds."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "51634b20d8bd8641eb4e22e11707a02b99c5d3db",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-04480",
                    "ArXiv": "2306.04480",
                    "DOI": "10.48550/arXiv.2306.04480",
                    "CorpusId": 259095732
                },
                "corpusId": 259095732,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/51634b20d8bd8641eb4e22e11707a02b99c5d3db",
                "title": "Exploring the Compositional Generalization in Context Dependent Text-to-SQL Parsing",
                "abstract": "In the context-dependent Text-to-SQL task, the generated SQL statements are refined iteratively based on the user input utterance from each interaction. The input text from each interaction can be viewed as component modifications to the previous SQL statements, which could be further extracted as the modification patterns. Since these modification patterns could also be combined with other SQL statements, the models are supposed to have the compositional generalization to these novel combinations. This work is the first exploration of compositional generalization in context-dependent Text-to-SQL scenarios. To facilitate related studies, we constructed two challenging benchmarks named \\textsc{CoSQL-CG} and \\textsc{SParC-CG} by recombining the modification patterns and existing SQL statements. The following experiments show that all current models struggle on our proposed benchmarks. Furthermore, we found that better aligning the previous SQL statements with the input utterance could give models better compositional generalization ability. Based on these observations, we propose a method named \\texttt{p-align} to improve the compositional generalization of Text-to-SQL models. Further experiments validate the effectiveness of our method. Source code and data are available.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "10017193",
                        "name": "Aiwei Liu"
                    },
                    {
                        "authorId": "46641573",
                        "name": "W. Liu"
                    },
                    {
                        "authorId": "2109906988",
                        "name": "Xuming Hu"
                    },
                    {
                        "authorId": "2133436155",
                        "name": "Shuang Li"
                    },
                    {
                        "authorId": "14885748",
                        "name": "Fukun Ma"
                    },
                    {
                        "authorId": "2109040042",
                        "name": "Yawen Yang"
                    },
                    {
                        "authorId": "2114092431",
                        "name": "Lijie Wen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026architectures for this task (Yu et al., 2018a; Zhang et al., 2019; Wang et al., 2020; Lin et al., 2020), there has been a trend of directly fine-tuning pre-trained sequenceto-sequence models as semantic parsers (Shaw et al., 2021; Scholak et al., 2021; Xie et al., 2022; Qi et al., 2022).",
                ", 2020) have now been more and more widely adopted for semantic parsing due to their promising performance and straightforward architectures (Shaw et al., 2021; Scholak et al., 2021; Yin et al., 2021; Qi et al., 2022; Xie et al., 2022; Qiu et al., 2021).",
                ", 2020), there has been a trend of directly fine-tuning pre-trained sequenceto-sequence models as semantic parsers (Shaw et al., 2021; Scholak et al., 2021; Xie et al., 2022; Qi et al., 2022).",
                "\u2026models (LMs)2 such as T5 (Raffel et al., 2020) have now been more and more widely adopted for semantic parsing due to their promising performance and straightforward architectures (Shaw et al., 2021; Scholak et al., 2021; Yin et al., 2021; Qi et al., 2022; Xie et al., 2022; Qiu et al., 2021).",
                "However, recent work revealed that these LMs still struggle to generalize on outof-distribution (OOD) samples (Lake and Baroni, 2018; Keysers et al., 2019; Shaw et al., 2021; Qiu et al., 2022b).",
                "Strong priors in the form of specialized model architectures (Shaw et al., 2021; Herzig and Berant, 2021; Wang et al., 2021) are either too expensive or not applicable across domains."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "b0cf4c64467a0529ca3d5be5dc326a21269257b6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-17378",
                    "ArXiv": "2305.17378",
                    "ACL": "2023.acl-short.15",
                    "DOI": "10.48550/arXiv.2305.17378",
                    "CorpusId": 258960278
                },
                "corpusId": 258960278,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/b0cf4c64467a0529ca3d5be5dc326a21269257b6",
                "title": "Improving Generalization in Language Model-based Text-to-SQL Semantic Parsing: Two Simple Semantic Boundary-based Techniques",
                "abstract": "Compositional and domain generalization present significant challenges in semantic parsing, even for state-of-the-art semantic parsers based on pre-trained language models (LMs). In this study, we empirically investigate improving an LM\u2019s generalization in semantic parsing with two simple techniques: at the token level, we introduce a token preprocessing method to preserve the semantic boundaries of tokens produced by LM tokenizers; at the sequence level, we propose to use special tokens to mark the boundaries of components aligned between input and output. Our experimental results on two text-to-SQL semantic parsing datasets show that our token preprocessing, although simple, can substantially improve the LM performance on both types of generalization, and our component boundary marking method is particularly helpful for compositional generalization.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2203429265",
                        "name": "Daking Rai"
                    },
                    {
                        "authorId": "2118640406",
                        "name": "Bailin Wang"
                    },
                    {
                        "authorId": "2110339246",
                        "name": "Yilun Zhou"
                    },
                    {
                        "authorId": "3366595",
                        "name": "Ziyu Yao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The state table is passed into the dialogue context by simple \u201clinearisation\u201d (Suhr et al., 2020; Scholak et al., 2021; Shaw et al., 2021): the rows are converted to",
                "The state table is passed into the dialogue context by simple \u201clinearisation\u201d (Suhr et al., 2020; Scholak et al., 2021; Shaw et al., 2021): the rows are converted to slot-value tuples, cast to a string using the template {slot} = {value}, and concatenated together using ; as a separator.2 During\u2026"
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "1e60f922460a7d32e2aee151e7cf65ab2d0cc74e",
                "externalIds": {
                    "DBLP": "conf/acl/LesciFHSM23",
                    "ArXiv": "2305.17020",
                    "DOI": "10.48550/arXiv.2305.17020",
                    "CorpusId": 258947518
                },
                "corpusId": 258947518,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/1e60f922460a7d32e2aee151e7cf65ab2d0cc74e",
                "title": "Diable: Efficient Dialogue State Tracking as Operations on Tables",
                "abstract": "Sequence-to-sequence state-of-the-art systems for dialogue state tracking (DST) use the full dialogue history as input, represent the current state as a list with all the slots, and generate the entire state from scratch at each dialogue turn. This approach is inefficient, especially when the number of slots is large and the conversation is long. We propose Diable, a new task formalisation that simplifies the design and implementation of efficient DST systems and allows one to easily plug and play large language models. We represent the dialogue state as a table and formalise DST as a table manipulation task. At each turn, the system updates the previous state by generating table operations based on the dialogue context. Extensive experimentation on the MultiWoz datasets demonstrates that Diable (i) outperforms strong efficient DST baselines, (ii) is 2.4x more time efficient than current state-of-the-art methods while retaining competitive Joint Goal Accuracy, and (iii) is robust to noisy data annotations due to the table operations approach.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2219036385",
                        "name": "Pietro Lesci"
                    },
                    {
                        "authorId": "31482660",
                        "name": "Yoshinari Fujinuma"
                    },
                    {
                        "authorId": "3255454",
                        "name": "Momchil Hardalov"
                    },
                    {
                        "authorId": "2062997508",
                        "name": "Chao Shang"
                    },
                    {
                        "authorId": "36714059",
                        "name": "L. M\u00e0rquez"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "40de0ed08de4141908796110511763477d333e30",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-16265",
                    "ArXiv": "2305.16265",
                    "DOI": "10.48550/arXiv.2305.16265",
                    "CorpusId": 258888094
                },
                "corpusId": 258888094,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/40de0ed08de4141908796110511763477d333e30",
                "title": "UNITE: A Unified Benchmark for Text-to-SQL Evaluation",
                "abstract": "A practical text-to-SQL system should generalize well on a wide variety of natural language questions, unseen database schemas, and novel SQL query structures. To comprehensively evaluate text-to-SQL systems, we introduce a UNIfied benchmark for Text-to-SQL Evaluation (UNITE). It is composed of publicly available text-to-SQL datasets, containing natural language questions from more than 12 domains, SQL queries from more than 3.9K patterns, and 29K databases. Compared to the widely used Spider benchmark, we introduce $\\sim$120K additional examples and a threefold increase in SQL patterns, such as comparative and boolean questions. We conduct a systematic study of six state-of-the-art (SOTA) text-to-SQL parsers on our new benchmark and show that: 1) Codex performs surprisingly well on out-of-domain datasets; 2) specially designed decoding methods (e.g. constrained beam search) can improve performance for both in-domain and out-of-domain settings; 3) explicitly modeling the relationship between questions and schemas further improves the Seq2Seq models. More importantly, our benchmark presents key challenges towards compositional generalization and robustness issues -- which these SOTA models cannot address well. Our code and data processing script are available at https://github.com/awslabs/unified-text2sql-benchmark",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "37852874",
                        "name": "Wuwei Lan"
                    },
                    {
                        "authorId": "40296541",
                        "name": "Zhiguo Wang"
                    },
                    {
                        "authorId": "2196898765",
                        "name": "Anuj Chauhan"
                    },
                    {
                        "authorId": "1787682",
                        "name": "Henghui Zhu"
                    },
                    {
                        "authorId": "2123247219",
                        "name": "A. Li"
                    },
                    {
                        "authorId": "144084849",
                        "name": "Jiang Guo"
                    },
                    {
                        "authorId": "38654394",
                        "name": "Shenmin Zhang"
                    },
                    {
                        "authorId": "2236867",
                        "name": "Chung-Wei Hang"
                    },
                    {
                        "authorId": "1393866988",
                        "name": "Joseph Lilien"
                    },
                    {
                        "authorId": "2186873589",
                        "name": "Yiqun Hu"
                    },
                    {
                        "authorId": "2101328894",
                        "name": "Lin Pan"
                    },
                    {
                        "authorId": "2196939793",
                        "name": "Mingwen Dong"
                    },
                    {
                        "authorId": "66063792",
                        "name": "J. Wang"
                    },
                    {
                        "authorId": "3024518",
                        "name": "Jiarong Jiang"
                    },
                    {
                        "authorId": "2962851",
                        "name": "Stephen M. Ash"
                    },
                    {
                        "authorId": "2879453",
                        "name": "Vittorio Castelli"
                    },
                    {
                        "authorId": "145878390",
                        "name": "Patrick Ng"
                    },
                    {
                        "authorId": "144028698",
                        "name": "Bing Xiang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To develop a text-to-SQL parser, a prevalent approach is to collect labeled data and train a model via supervised learning (Shaw et al., 2021; Scholak et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "450e03734f6638855683b41632243f77511b853f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-14215",
                    "ArXiv": "2305.14215",
                    "DOI": "10.48550/arXiv.2305.14215",
                    "CorpusId": 258841412
                },
                "corpusId": 258841412,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/450e03734f6638855683b41632243f77511b853f",
                "title": "Exploring Chain-of-Thought Style Prompting for Text-to-SQL",
                "abstract": "Conventional supervised approaches for text-to-SQL parsing often require large amounts of annotated data, which is costly to obtain in practice. Recently, in-context learning with large language models (LLMs) has caught increasing attention due to its superior few-shot performance in a wide range of tasks. However, most attempts to use in-context learning for text-to-SQL parsing still lag behind supervised methods. We hypothesize that the under-performance is because text-to-SQL parsing requires complex, multi-step reasoning. In this paper, we systematically study how to enhance the reasoning ability of LLMs for text-to-SQL parsing through chain-of-thought (CoT) style promptings including CoT prompting and Least-to-Most prompting. Our experiments demonstrate that iterative prompting as in Least-to-Most prompting may be unnecessary for text-to-SQL parsing and directly applying existing CoT style prompting methods leads to error propagation issues. By improving multi-step reasoning while avoiding much detailed information in the reasoning steps which may lead to error propagation, our new method outperforms existing ones by 2.4 point absolute gains on the Spider development set.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "77145310",
                        "name": "Chang-You Tai"
                    },
                    {
                        "authorId": "11832104",
                        "name": "Ziru Chen"
                    },
                    {
                        "authorId": "2167773622",
                        "name": "Tianshu Zhang"
                    },
                    {
                        "authorId": "145924070",
                        "name": "Xiang Deng"
                    },
                    {
                        "authorId": "1515546612",
                        "name": "Huan Sun"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Alternatively, other studies (Guo et al., 2019; Lin et al., 2020; Shaw et al., 2020) have converted table schemas into a sequence to effectively leverage pretrained language models,",
                "Alternatively, other studies (Guo et al., 2019; Lin et al., 2020; Shaw et al., 2020) have converted table schemas into a sequence to effectively leverage pretrained language models,\nsuch as BERT (Devlin et al., 2018) and T5 (Raffel et al., 2020).",
                "question-specific table content by identifying the relevant table content mentioned in the question through string matching (Lin et al., 2020; Shaw et al., 2020; Wang et al., 2019).",
                "To incorporate table content into neural models, prior work with supervised models provides question-specific table content by identifying the relevant table content mentioned in the question through string matching (Lin et al., 2020; Shaw et al., 2020; Wang et al., 2019)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "2d765d953efd738034782f9afdb311e3ba015edd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-11853",
                    "ArXiv": "2305.11853",
                    "DOI": "10.48550/arXiv.2305.11853",
                    "CorpusId": 258823166
                },
                "corpusId": 258823166,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2d765d953efd738034782f9afdb311e3ba015edd",
                "title": "How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings",
                "abstract": "Large language models (LLMs) with in-context learning have demonstrated remarkable capability in the text-to-SQL task. Previous research has prompted LLMs with various demonstration-retrieval strategies and intermediate reasoning steps to enhance the performance of LLMs. However, those works often employ varied strategies when constructing the prompt text for text-to-SQL inputs, such as databases and demonstration examples. This leads to a lack of comparability in both the prompt constructions and their primary contributions. Furthermore, selecting an effective prompt construction has emerged as a persistent problem for future research. To address this limitation, we comprehensively investigate the impact of prompt constructions across various settings and provide insights for future work.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46923811",
                        "name": "Shuaichen Chang"
                    },
                    {
                        "authorId": "1398481836",
                        "name": "E. Fosler-Lussier"
                    }
                ]
            }
        },
        {
            "contexts": [
                "By fine-tuning generic neural models on these benchmarks, much work reported that these models exhibit poor compositional generalization (Furrer et al., 2020; Shaw et al., 2021; Bogin et al., 2022).",
                "Many approaches were proposed to enhance the CG on general-purpose models (Andreas, 2020; Aky\u00fcrek et al., 2020; Guo et al., 2021; Oren et al., 2021; Shaw et al., 2021; Zhu et al., 2021) or design task-specific methods (Liu et al.",
                "Moreover, some work has suggested that the challenge of compositional generalization under fine-tuning lies in unobserved structures (Keysers et al., 2019; Shaw et al., 2021; Bogin et al., 2022).",
                "3 In-Context Learning vs Fine-Tuning Compositional generalization under the fine-tuning paradigm has been widely studied (Furrer et al., 2020; Shaw et al., 2021; Bogin et al., 2022), while there is little observation under in-context learning.",
                "Many approaches were proposed to enhance the CG on general-purpose models (Andreas, 2020; Aky\u00fcrek et al., 2020; Guo et al., 2021; Oren et al., 2021; Shaw et al., 2021; Zhu et al., 2021) or design task-specific methods (Liu et al., 2020; Herzig\n6The term \u201cfictional words\u201d means that these words are\u2026",
                "Compositional generalization under the fine-tuning paradigm has been widely studied (Furrer et al., 2020; Shaw et al., 2021; Bogin et al., 2022), while there is little observation under in-context learning."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "0ae12d63f77f40b430f17c791a5191ff5fee5086",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-04835",
                    "ACL": "2023.acl-long.618",
                    "ArXiv": "2305.04835",
                    "DOI": "10.48550/arXiv.2305.04835",
                    "CorpusId": 258558112
                },
                "corpusId": 258558112,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/0ae12d63f77f40b430f17c791a5191ff5fee5086",
                "title": "How Do In-Context Examples Affect Compositional Generalization?",
                "abstract": "Compositional generalization\u2013understanding unseen combinations of seen primitives\u2013is an essential reasoning capability in human intelligence.The AI community mainly studies this capability by fine-tuning neural networks on lots of training samples, while it is still unclear whether and how in-context learning\u2013the prevailing few-shot paradigm based on large language models\u2013exhibits compositional generalization.In this paper, we present CoFe, a test suite to investigate in-context compositional generalization.We find that the compositional generalization performance can be easily affected by the selection of in-context examples, thus raising the research question what the key factors are to make good in-context examples for compositional generalization.We study three potential factors: similarity, diversity and complexity. Our systematic experiments indicate that in-context examples should be structurally similar to the test case, diverse from each other, and individually simple.Furthermore, two strong limitations are observed: in-context compositional generalization on fictional words is much weaker than that on commonly used ones; it is still critical that the in-context examples should cover required linguistic structures, even though the backbone model has been pre-trained on large corpus.We hope our analysis would facilitate the understanding and utilization of in-context learning paradigm.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2119217081",
                        "name": "Shengnan An"
                    },
                    {
                        "authorId": "2284174",
                        "name": "Zeqi Lin"
                    },
                    {
                        "authorId": "2113771309",
                        "name": "Qiang Fu"
                    },
                    {
                        "authorId": "143876723",
                        "name": "B. Chen"
                    },
                    {
                        "authorId": "2144620206",
                        "name": "Nanning Zheng"
                    },
                    {
                        "authorId": "153249455",
                        "name": "Jian-Guang Lou"
                    },
                    {
                        "authorId": "46334641",
                        "name": "D. Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "approaches for compositional generalization (Shaw et al., 2021).",
                "Task-specific representations and encoding schemes are very common with state-of-the-art approaches for compositional generalization (Shaw et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "53f59f389ed55b1576f65058123f5234f65b576e",
                "externalIds": {
                    "ACL": "2023.acl-long.470",
                    "DBLP": "journals/corr/abs-2305-04346",
                    "ArXiv": "2305.04346",
                    "DOI": "10.48550/arXiv.2305.04346",
                    "CorpusId": 258557790
                },
                "corpusId": 258557790,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/53f59f389ed55b1576f65058123f5234f65b576e",
                "title": "Laziness Is a Virtue When It Comes to Compositionality in Neural Semantic Parsing",
                "abstract": "Nearly all general-purpose neural semantic parsers generate logical forms in a strictly top-down autoregressive fashion. Though such systems have achieved impressive results across a variety of datasets and domains, recent works have called into question whether they are ultimately limited in their ability to compositionally generalize. In this work, we approach semantic parsing from, quite literally, the opposite direction; that is, we introduce a neural semantic parsing generation method that constructs logical forms from the bottom up, beginning from the logical form\u2019s leaves. The system we introduce is lazy in that it incrementally builds up a set of potential semantic parses, but only expands and processes the most promising candidate parses at each generation step. Such a parsimonious expansion scheme allows the system to maintain an arbitrarily large set of parse hypotheses that are never realized and thus incur minimal computational overhead. We evaluate our approach on compositional generalization; specifically, on the challenging CFQ dataset and two other Text-to-SQL datasets where we show that our novel, bottom-up semantic parsing technique outperforms general-purpose semantic parsers while also being competitive with semantic parsers that have been tailored to each task.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "41036307",
                        "name": "M. Crouse"
                    },
                    {
                        "authorId": "2123450380",
                        "name": "P. Kapanipathi"
                    },
                    {
                        "authorId": "34597365",
                        "name": "Subhajit Chaudhury"
                    },
                    {
                        "authorId": "2138053379",
                        "name": "Tahira Naseem"
                    },
                    {
                        "authorId": "3394760",
                        "name": "Ram\u00f3n Fern\u00e1ndez Astudillo"
                    },
                    {
                        "authorId": "2297836",
                        "name": "Achille Fokoue"
                    },
                    {
                        "authorId": "2652016",
                        "name": "Tim Klinger"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To improve compositionality of LMs, previous works propose to parameterize grammatical rules (Kim, 2021; Shaw et al., 2021) but show that those hybrid models are inefficient and usually underperform neural counterparts."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "44772fe1c3fa422a3da7e25092db2544893d6bfb",
                "externalIds": {
                    "ArXiv": "2305.03742",
                    "DBLP": "conf/acl/ZhangHLNX23",
                    "DOI": "10.48550/arXiv.2305.03742",
                    "CorpusId": 252760744
                },
                "corpusId": 252760744,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/44772fe1c3fa422a3da7e25092db2544893d6bfb",
                "title": "Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming",
                "abstract": "Pre-trained large language models (LMs) struggle to perform logical reasoning reliably despite advances in scale and compositionality. In this work, we tackle this challenge through the lens of symbolic programming. We propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning. In contrast to works that rely on hand-crafted logic rules, our differentiable symbolic reasoning framework efficiently learns weighted rules and applies semantic loss to further improve LMs. DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion. The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks. Furthermore, DSR-LM outperforms a variety of competitive baselines when faced with systematic changes in sequence length.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2119078297",
                        "name": "Hanlin Zhang"
                    },
                    {
                        "authorId": "2135649449",
                        "name": "Jiani Huang"
                    },
                    {
                        "authorId": "2118275056",
                        "name": "Ziyang Li"
                    },
                    {
                        "authorId": "145835621",
                        "name": "M. Naik"
                    },
                    {
                        "authorId": "2064963077",
                        "name": "Eric P. Xing"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "1ae8546a59ae525258fd8e7f4facf25162d7d168",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-03111",
                    "ArXiv": "2305.03111",
                    "DOI": "10.48550/arXiv.2305.03111",
                    "CorpusId": 258547040
                },
                "corpusId": 258547040,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1ae8546a59ae525258fd8e7f4facf25162d7d168",
                "title": "Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs",
                "abstract": "Text-to-SQL parsing, which aims at converting natural language instructions into executable SQLs, has gained increasing attention in recent years. In particular, Codex and ChatGPT have shown impressive results in this task. However, most of the prevalent benchmarks, i.e., Spider, and WikiSQL, focus on database schema with few rows of database contents leaving the gap between academic study and real-world applications. To mitigate this gap, we present Bird, a big benchmark for large-scale database grounded in text-to-SQL tasks, containing 12,751 pairs of text-to-SQL data and 95 databases with a total size of 33.4 GB, spanning 37 professional domains. Our emphasis on database values highlights the new challenges of dirty database contents, external knowledge between NL questions and database contents, and SQL efficiency, particularly in the context of massive databases. To solve these problems, text-to-SQL models must feature database value comprehension in addition to semantic parsing. The experimental results demonstrate the significance of database values in generating accurate text-to-SQLs for big databases. Furthermore, even the most effective text-to-SQL models, i.e. ChatGPT, only achieves 40.08% in execution accuracy, which is still far from the human result of 92.96%, proving that challenges still stand. Besides, we also provide an efficiency analysis to offer insights into generating text-to-efficient-SQLs that are beneficial to industries. We believe that BIRD will contribute to advancing real-world applications of text-to-SQL research. The leaderboard and source code are available: https://bird-bench.github.io/.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2154860526",
                        "name": "Jinyang Li"
                    },
                    {
                        "authorId": "151471590",
                        "name": "Binyuan Hui"
                    },
                    {
                        "authorId": "2216486244",
                        "name": "Ge Qu"
                    },
                    {
                        "authorId": "66200440",
                        "name": "Binhua Li"
                    },
                    {
                        "authorId": "2135964855",
                        "name": "Jiaxi Yang"
                    },
                    {
                        "authorId": "2132475886",
                        "name": "Bowen Li"
                    },
                    {
                        "authorId": "2118640406",
                        "name": "Bailin Wang"
                    },
                    {
                        "authorId": "50379530",
                        "name": "Bowen Qin"
                    },
                    {
                        "authorId": "5973047",
                        "name": "Rongyu Cao"
                    },
                    {
                        "authorId": "9706609",
                        "name": "Ruiying Geng"
                    },
                    {
                        "authorId": "2147322690",
                        "name": "Nan Huo"
                    },
                    {
                        "authorId": "2108786828",
                        "name": "Chenhao Ma"
                    },
                    {
                        "authorId": "152608657",
                        "name": "K. Chang"
                    },
                    {
                        "authorId": "143857288",
                        "name": "Fei Huang"
                    },
                    {
                        "authorId": "2114454192",
                        "name": "Reynold Cheng"
                    },
                    {
                        "authorId": "1527090216",
                        "name": "Yongbin Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", [15, 22, 31, 63]), prompt engineering with pre-trained language models such as Codex and GPT-4 [45, 46], and fine-tuned large language models [51, 54]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "ab9485a6564cdbe5b5ce2233d5b00c64ceaa518c",
                "externalIds": {
                    "ArXiv": "2305.01598",
                    "DBLP": "journals/corr/abs-2305-01598",
                    "DOI": "10.48550/arXiv.2305.01598",
                    "CorpusId": 258437108
                },
                "corpusId": 258437108,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/ab9485a6564cdbe5b5ce2233d5b00c64ceaa518c",
                "title": "From Words to Code: Harnessing Data for Program Synthesis from Natural Language",
                "abstract": "Creating programs to correctly manipulate data is a difficult task, as the underlying programming languages and APIs can be challenging to learn for many users who are not skilled programmers. Large language models (LLMs) demonstrate remarkable potential for generating code from natural language, but in the data manipulation domain, apart from the natural language (NL) description of the intended task, we also have the dataset on which the task is to be performed, or the\"data context\". Existing approaches have utilized data context in a limited way by simply adding relevant information from the input data into the prompts sent to the LLM. In this work, we utilize the available input data to execute the candidate programs generated by the LLMs and gather their outputs. We introduce semantic reranking, a technique to rerank the programs generated by LLMs based on three signals coming the program outputs: (a) semantic filtering and well-formedness based score tuning: do programs even generate well-formed outputs, (b) semantic interleaving: how do the outputs from different candidates compare to each other, and (c) output-based score tuning: how do the outputs compare to outputs predicted for the same task. We provide theoretical justification for semantic interleaving. We also introduce temperature mixing, where we combine samples generated by LLMs using both high and low temperatures. We extensively evaluate our approach in three domains, namely databases (SQL), data science (Pandas) and business intelligence (Excel's Power Query M) on a variety of new and existing benchmarks. We observe substantial gains across domains, with improvements of up to 45% in top-1 accuracy and 34% in top-3 accuracy.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2162046116",
                        "name": "Anirudh Khatry"
                    },
                    {
                        "authorId": "150140157",
                        "name": "Joyce Cahoon"
                    },
                    {
                        "authorId": "40282163",
                        "name": "Jordan Henkel"
                    },
                    {
                        "authorId": "34691891",
                        "name": "Shaleen Deep"
                    },
                    {
                        "authorId": "2179556445",
                        "name": "Venkatesh Emani"
                    },
                    {
                        "authorId": "2327080",
                        "name": "A. Floratou"
                    },
                    {
                        "authorId": "2108314",
                        "name": "Sumit Gulwani"
                    },
                    {
                        "authorId": "143914877",
                        "name": "Vu Le"
                    },
                    {
                        "authorId": "35965224",
                        "name": "Mohammad Raza"
                    },
                    {
                        "authorId": "2113258914",
                        "name": "Sherry Shi"
                    },
                    {
                        "authorId": "2134941824",
                        "name": "Mukul Singh"
                    },
                    {
                        "authorId": "145219494",
                        "name": "A. Tiwari"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These methods have achieved success when trained and tested on a specifc dataset or domain [2, 7, 8, 10, 18, 21, 22, 25]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8ed0ee821e28ff01d1e275a4728f248e3bbeff9a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-08697",
                    "ArXiv": "2303.08697",
                    "DOI": "10.1145/3543873.3587309",
                    "CorpusId": 257532430
                },
                "corpusId": 257532430,
                "publicationVenue": {
                    "id": "e07422f9-c065-40c3-a37b-75e98dce79fe",
                    "name": "The Web Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Web Conf",
                        "WWW"
                    ],
                    "url": "http://www.iw3c2.org/"
                },
                "url": "https://www.semanticscholar.org/paper/8ed0ee821e28ff01d1e275a4728f248e3bbeff9a",
                "title": "Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization",
                "abstract": "We present Mirror, an open-source platform for data exploration and analysis powered by large language models. Mirror offers an intuitive natural language interface for querying databases, and automatically generates executable SQL commands to retrieve relevant data and summarize it in natural language. In addition, users can preview and manually edit the generated SQL commands to ensure the accuracy of their queries. Mirror also generates visualizations to facilitate understanding of the data. Designed with flexibility and human input in mind, Mirror is suitable for both experienced data analysts and non-technical professionals looking to gain insights from their data.1",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "66247317",
                        "name": "Canwen Xu"
                    },
                    {
                        "authorId": "35660011",
                        "name": "Julian McAuley"
                    },
                    {
                        "authorId": "2108242653",
                        "name": "Penghan Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "With the recent advances in pre-trained language models (PLMs), many existing works formulate the Text-to-SQL task as a semantic parsing problem and use a sequence-tosequence (seq2seq) model to solve it (Scholak, Schucher, and Bahdanau 2021; Shi et al. 2021; Shaw et al. 2021).",
                "Following Shaw et al. (2021); Scholak, Schucher, and Bahdanau (2021), we treat Text-to-SQL as a translation task, which can be solved by an encoder-decoder transformer model.",
                "However, even the T5-3B model only achieves about 70% accuracy (Shaw et al. 2021; Scholak, Schucher, and Bahdanau 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6d51f4b220cb2c8321dc5f9755b7d66f10f1cad6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-05965",
                    "ArXiv": "2302.05965",
                    "DOI": "10.48550/arXiv.2302.05965",
                    "CorpusId": 257078956
                },
                "corpusId": 257078956,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/6d51f4b220cb2c8321dc5f9755b7d66f10f1cad6",
                "title": "RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL",
                "abstract": "One of the recent best attempts at Text-to-SQL is the pre-trained language model. Due to the structural property of the SQL queries, the seq2seq model takes the responsibility of parsing both the schema items (i.e., tables and columns) and the skeleton (i.e., SQL keywords). Such coupled targets increase the difficulty of parsing the correct SQL queries especially when they involve many schema items and logic operators. This paper proposes a ranking-enhanced encoding and skeleton-aware decoding framework to decouple the schema linking and the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its encoder is injected by the most relevant schema items instead of the whole unordered ones, which could alleviate the schema linking effort during SQL parsing, and its decoder first generates the skeleton and then the actual SQL query, which could implicitly constrain the SQL parsing. We evaluate our proposed framework on Spider and its three robustness variants: Spider-DK, Spider-Syn, and Spider-Realistic. The experimental results show that our framework delivers promising performance and robustness. Our code is available at https://github.com/RUCKBReasoning/RESDSQL.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "144911687",
                        "name": "Haoyang Li"
                    },
                    {
                        "authorId": "2155700347",
                        "name": "Jing Zhang"
                    },
                    {
                        "authorId": "1625473962",
                        "name": "Cuiping Li"
                    },
                    {
                        "authorId": "2191043357",
                        "name": "Hong Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "48abfc41a0abf023d2037ebb2f274835e0d322d0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-05698",
                    "ArXiv": "2302.05698",
                    "DOI": "10.48550/arXiv.2302.05698",
                    "CorpusId": 256826793
                },
                "corpusId": 256826793,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/48abfc41a0abf023d2037ebb2f274835e0d322d0",
                "title": "Compositional Exemplars for In-context Learning",
                "abstract": "Large pretrained language models (LMs) have shown impressive In-Context Learning (ICL) ability, where the model learns to do an unseen task via a prompt consisting of input-output examples as the demonstration, without any parameter updates. The performance of ICL is highly dominated by the quality of the selected in-context examples. However, previous selection methods are mostly based on simple heuristics, leading to sub-optimal performance. In this work, we formulate in-context example selection as a subset selection problem. We propose CEIL (Compositional Exemplars for In-context Learning), which is instantiated by Determinantal Point Processes (DPPs) to model the interaction between the given input and in-context examples, and optimized through a carefully-designed contrastive learning objective to obtain preference from LMs. We validate CEIL on 12 classification and generation datasets from 7 distinct NLP tasks, including sentiment analysis, paraphrase detection, natural language inference, commonsense reasoning, open-domain question answering, code generation, and semantic parsing. Extensive experiments demonstrate not only the state-of-the-art performance but also the transferability and compositionality of CEIL, shedding new light on effective and efficient in-context learning. Our code is released at https://github.com/HKUNLP/icl-ceil.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "65846898",
                        "name": "Jiacheng Ye"
                    },
                    {
                        "authorId": "150358371",
                        "name": "Zhiyong Wu"
                    },
                    {
                        "authorId": "2093485",
                        "name": "Jiangtao Feng"
                    },
                    {
                        "authorId": "2117900202",
                        "name": "Tao Yu"
                    },
                    {
                        "authorId": "47648549",
                        "name": "Lingpeng Kong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "An example compositionality metric for semantic parsing is maximum compound divergence (Keysers et al., 2019; Shaw et al., 2021), that minimises train-test differences in word distributions while maximising the differences in compound usage."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "8d591175f8d034812c928c70f68e2757eb22689d",
                "externalIds": {
                    "ArXiv": "2301.13714",
                    "DBLP": "journals/corr/abs-2301-13714",
                    "DOI": "10.48550/arXiv.2301.13714",
                    "CorpusId": 256415939
                },
                "corpusId": 256415939,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/8d591175f8d034812c928c70f68e2757eb22689d",
                "title": "Recursive Neural Networks with Bottlenecks Diagnose (Non-)Compositionality",
                "abstract": "A recent line of work in NLP focuses on the (dis)ability of models to generalise compositionally for artificial languages. However, when considering natural language tasks, the data involved is not strictly, or locally, compositional. Quantifying the compositionality of data is a challenging task, which has been investigated primarily for short utterances. We use recursive neural models (Tree-LSTMs) with bottlenecks that limit the transfer of information between nodes. We illustrate that comparing data's representations in models with and without the bottleneck can be used to produce a compositionality metric. The procedure is applied to the evaluation of arithmetic expressions using synthetic data, and sentiment classification using natural language data. We demonstrate that compression through a bottleneck impacts non-compositional examples disproportionately and then use the bottleneck compositionality metric (BCM) to distinguish compositional from non-compositional samples, yielding a compositionality ranking over a dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "74461595",
                        "name": "Verna Dankers"
                    },
                    {
                        "authorId": "144889265",
                        "name": "Ivan Titov"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "e19a0d4ba1baa8d8291a59a4a32a89ea4433d0c8",
                "externalIds": {
                    "DBLP": "conf/eacl/LiH23",
                    "ACL": "2023.findings-eacl.47",
                    "ArXiv": "2301.12920",
                    "DOI": "10.48550/arXiv.2301.12920",
                    "CorpusId": 256389803
                },
                "corpusId": 256389803,
                "publicationVenue": {
                    "id": "479d5605-51be-4346-b1d6-4334084504df",
                    "name": "Findings",
                    "type": "journal",
                    "issn": "2652-8800",
                    "url": "https://findingspress.org/"
                },
                "url": "https://www.semanticscholar.org/paper/e19a0d4ba1baa8d8291a59a4a32a89ea4433d0c8",
                "title": "Active Learning for Multilingual Semantic Parser",
                "abstract": "Current multilingual semantic parsing (MSP) datasets are almost all collected by translating the utterances in the existing datasets from the resource-rich language to the target language. However, manual translation is costly. To reduce the translation effort, this paper proposes the first active learning procedure for MSP (AL-MSP). AL-MSP selects only a subset from the existing datasets to be translated. We also propose a novel selection method that prioritizes the examples diversifying the logical form structures with more lexical choices, and a novel hyperparameter tuning method that needs no extra annotation cost. Our experiments show that AL-MSP significantly reduces translation costs with ideal selection methods. Our selection method with proper hyperparameters yields better parsing performance than the other baselines on two multilingual datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1455835132",
                        "name": "Zhuang Li"
                    },
                    {
                        "authorId": "2561045",
                        "name": "Gholamreza Haffari"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, these models often generalize poorly to out-of-distribution (OOD) and tail examples (Cheng et al., 2019; Shaw et al., 2021; Kim, 2021; Lin et al., 2022), while grammar or rule-based parser work relatively robustly across different linguistic phenomena and language domains (Cao et al.,\u2026",
                "However, these models often generalize poorly to out-of-distribution (OOD) and tail examples (Cheng et al., 2019; Shaw et al., 2021; Kim, 2021; Lin et al., 2022), while grammar or rule-based parser work relatively robustly across different linguistic phenomena and language domains (Cao et al.",
                "The baseline models also include a similar practice with (Shaw et al., 2021) and (Hoang et al., 2021).",
                "This has motivated the work in neuralsymbolic parsing where symbolic approaches are imported as inductive bias (Shaw et al., 2021; Kim, 2021; Cheng et al., 2019; Cole et al., 2021)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "67c0b0f0b1efb2e25084d23ed310109fb3c451aa",
                "externalIds": {
                    "ACL": "2022.emnlp-main.314",
                    "DBLP": "journals/corr/abs-2301-11459",
                    "ArXiv": "2301.11459",
                    "DOI": "10.48550/arXiv.2301.11459",
                    "CorpusId": 256358379
                },
                "corpusId": 256358379,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/67c0b0f0b1efb2e25084d23ed310109fb3c451aa",
                "title": "Neural-Symbolic Inference for Robust Autoregressive Graph Parsing via Compositional Uncertainty Quantification",
                "abstract": "Pre-trained seq2seq models excel at graph semantic parsing with rich annotated data, but generalize worse to out-of-distribution (OOD) and long-tail examples. In comparison, symbolic parsers under-perform on population-level metrics, but exhibit unique strength in OOD and tail generalization. In this work, we study compositionality-aware approach to neural-symbolic inference informed by model confidence, performing fine-grained neural-symbolic reasoning at subgraph level (i.e., nodes and edges) and precisely targeting subgraph components with high uncertainty in the neural parser. As a result, the method combines the distinct strength of the neural and symbolic approaches in capturing different aspects of the graph prediction, leading to well-rounded generalization performance both across domains and in the tail. We empirically investigate the approach in the English Resource Grammar (ERG) parsing problem on a diverse suite of standard in-domain and seven OOD corpora. Our approach leads to 35.26% and 35.60% error reduction in aggregated SMATCH score over neural and symbolic approaches respectively, and 14% absolute accuracy gain in key tail linguistic categories over the neural model, outperforming prior state-of-art methods that do not account for compositionality or uncertainty.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2112304965",
                        "name": "Zi Lin"
                    },
                    {
                        "authorId": "2108345570",
                        "name": "J. Liu"
                    },
                    {
                        "authorId": "2884976",
                        "name": "Jingbo Shang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(5) T5-3B LK (Shaw et al., 2021): A T5-3B model with an entity linking between question and DB content."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "7195ed3c7f11220f29634cecb68b1d39db2e36d9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2301-08881",
                    "ArXiv": "2301.08881",
                    "DOI": "10.48550/arXiv.2301.08881",
                    "CorpusId": 256105733
                },
                "corpusId": 256105733,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/7195ed3c7f11220f29634cecb68b1d39db2e36d9",
                "title": "Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness",
                "abstract": "Neural text-to-SQL models have achieved remarkable performance in translating natural language questions into SQL queries. However, recent studies reveal that text-to-SQL models are vulnerable to task-specific perturbations. Previous curated robustness test sets usually focus on individual phenomena. In this paper, we propose a comprehensive robustness benchmark based on Spider, a cross-domain text-to-SQL benchmark, to diagnose the model robustness. We design 17 perturbations on databases, natural language questions, and SQL queries to measure the robustness from different angles. In order to collect more diversified natural question perturbations, we utilize large pretrained language models (PLMs) to simulate human behaviors in creating natural questions. We conduct a diagnostic study of the state-of-the-art models on the robustness set. Experimental results reveal that even the most robust model suffers from a 14.0% performance drop overall and a 50.7% performance drop on the most challenging perturbation. We also present a breakdown analysis regarding text-to-SQL model designs and provide insights for improving model robustness.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46923811",
                        "name": "Shuaichen Chang"
                    },
                    {
                        "authorId": "66063792",
                        "name": "J. Wang"
                    },
                    {
                        "authorId": "2196939793",
                        "name": "Mingwen Dong"
                    },
                    {
                        "authorId": "2101328894",
                        "name": "Lin Pan"
                    },
                    {
                        "authorId": "1787682",
                        "name": "Henghui Zhu"
                    },
                    {
                        "authorId": "2123247219",
                        "name": "A. Li"
                    },
                    {
                        "authorId": "37852874",
                        "name": "Wuwei Lan"
                    },
                    {
                        "authorId": "38654394",
                        "name": "Shenmin Zhang"
                    },
                    {
                        "authorId": "3024518",
                        "name": "Jiarong Jiang"
                    },
                    {
                        "authorId": "1393866988",
                        "name": "Joseph Lilien"
                    },
                    {
                        "authorId": "2962851",
                        "name": "Stephen M. Ash"
                    },
                    {
                        "authorId": "1682479",
                        "name": "William Yang Wang"
                    },
                    {
                        "authorId": "40296541",
                        "name": "Zhiguo Wang"
                    },
                    {
                        "authorId": "2879453",
                        "name": "Vittorio Castelli"
                    },
                    {
                        "authorId": "145878390",
                        "name": "Patrick Ng"
                    },
                    {
                        "authorId": "144028698",
                        "name": "Bing Xiang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "dcffef7c94546389c02c837e0e9290039938b4d2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2301-07507",
                    "ArXiv": "2301.07507",
                    "DOI": "10.48550/arXiv.2301.07507",
                    "CorpusId": 255998567
                },
                "corpusId": 255998567,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/dcffef7c94546389c02c837e0e9290039938b4d2",
                "title": "Graphix-T5: Mixing Pre-Trained Transformers with Graph-Aware Layers for Text-to-SQL Parsing",
                "abstract": "The task of text-to-SQL parsing, which aims at converting natural language questions into executable SQL queries, has garnered increasing attention in recent years. One of the major challenges in text-to-SQL parsing is domain generalization, i.e., how to generalize well to unseen databases. Recently, the pre-trained text-to-text transformer model, namely T5, though not specialized for text-to-SQL parsing, has achieved state-of-the-art performance on standard benchmarks targeting domain generalization. In this work, we explore ways to further augment the pre-trained T5 model with specialized components for text-to-SQL parsing. Such components are expected to introduce structural inductive bias into text-to-SQL parsers thus improving the model\u2019s capacity on (potentially multi-hop) reasoning, which is critical for generating structure-rich SQLs. To this end, we propose a new architecture GRAPHIX-T5, a mixed model with the standard pre-trained transformer model augmented by specially-designed graph-aware layers. Extensive experiments and analysis demonstrate the effectiveness of GRAPHIX-T5 across four text-to-SQL benchmarks: SPIDER, SYN, REALISTIC and DK. GRAPHIX-T5 surpasses all other T5-based parsers with a significant margin, achieving new state-of-the-art performance. Notably, GRAPHIX-T5-large reaches performance superior to the original T5-large by 5.7% on exact match (EM) accuracy and 6.6% on execution accuracy (EX). This even outperforms the T5-3B by 1.2% on EM and 1.5% on EX",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2154860526",
                        "name": "Jinyang Li"
                    },
                    {
                        "authorId": "151471590",
                        "name": "Binyuan Hui"
                    },
                    {
                        "authorId": "2114454192",
                        "name": "Reynold Cheng"
                    },
                    {
                        "authorId": "50379530",
                        "name": "Bowen Qin"
                    },
                    {
                        "authorId": "2108786828",
                        "name": "Chenhao Ma"
                    },
                    {
                        "authorId": "2147322690",
                        "name": "Nan Huo"
                    },
                    {
                        "authorId": "2087380523",
                        "name": "Fei Huang"
                    },
                    {
                        "authorId": "2072591656",
                        "name": "Wenyu Du"
                    },
                    {
                        "authorId": "2161888510",
                        "name": "Luo Si"
                    },
                    {
                        "authorId": "1527090216",
                        "name": "Yongbin Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Compositional generalization benchmarks such as SCAN and COGS are often used to evaluate pretrained models.",
                "\u2026(typically, \u201clanguage modeling\u201d) such as T5 (Raffel et al., 2020), mT5 (Xue et al., 2021), CodeT5 (Wang et al., 2021) and pretrained convolutional sequence-to-sequence (seq2seq) networks achieve high generalization accuracy on SCAN and COGS (Shaw et al., 2021; Tay et al., 2021; Orhan, 2021).",
                "\u2026impact the interpretation of a large body of existing work in this domain that uses pretrained models (Furrer et al., 2020; Tay et al., 2021; Shaw et al., 2021; Orhan, 2021; Qiu et al., 2021; Zhu et al., 2021; Herzig et al., 2021; Qiu et al., 2022; Zheng and Lapata, 2022; Drozdov et al.,\u2026",
                "Among such work, some report that models pretrained on context reconstruction (typically, \u201clanguage modeling\u201d) such as T5 (Raffel et al., 2020), mT5 (Xue et al., 2021), CodeT5 (Wang et al., 2021) and pretrained convolutional sequence-to-sequence (seq2seq) networks achieve high generalization accuracy on SCAN and COGS (Shaw et al., 2021; Tay et al., 2021; Orhan, 2021).",
                ", 2021) and pretrained convolutional sequence-to-sequence (seq2seq) networks achieve high generalization accuracy on SCAN and COGS (Shaw et al., 2021; Tay et al., 2021; Orhan, 2021)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8969ea3d254e149aebcfd1ffc8f46910d7cb160e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-10769",
                    "ArXiv": "2212.10769",
                    "DOI": "10.48550/arXiv.2212.10769",
                    "CorpusId": 254926486
                },
                "corpusId": 254926486,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8969ea3d254e149aebcfd1ffc8f46910d7cb160e",
                "title": "Uncontrolled Lexical Exposure Leads to Overestimation of Compositional Generalization in Pretrained Models",
                "abstract": "Human linguistic capacity is often characterized by compositionality and the generalization it enables -- human learners can produce and comprehend novel complex expressions by composing known parts. Several benchmarks exploit distributional control across training and test to gauge compositional generalization, where certain lexical items only occur in limited contexts during training. While recent work using these benchmarks suggests that pretrained models achieve impressive generalization performance, we argue that exposure to pretraining data may break the aforementioned distributional control. Using the COGS benchmark of Kim and Linzen (2020), we test two modified evaluation setups that control for this issue: (1) substituting context-controlled lexical items with novel character sequences, and (2) substituting them with special tokens represented by novel embeddings. We find that both of these setups lead to lower generalization performance in T5 (Raffel et al., 2020), suggesting that previously reported results have been overestimated due to uncontrolled lexical exposure during pretraining. The performance degradation is more extreme with novel embeddings, and the degradation increases with the amount of pretraining data, highlighting an interesting case of inverse scaling.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "8756748",
                        "name": "Najoung Kim"
                    },
                    {
                        "authorId": "2467508",
                        "name": "Tal Linzen"
                    },
                    {
                        "authorId": "1748557",
                        "name": "P. Smolensky"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "d574160b1441270b4968e270acf92fea7f0cd8da",
                "externalIds": {
                    "ArXiv": "2212.08785",
                    "DBLP": "conf/acl/HuZJLZCLPWHZGDL23",
                    "DOI": "10.48550/arXiv.2212.08785",
                    "CorpusId": 254854461
                },
                "corpusId": 254854461,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/d574160b1441270b4968e270acf92fea7f0cd8da",
                "title": "Importance of Synthesizing High-quality Data for Text-to-SQL Parsing",
                "abstract": "Recently, there has been increasing interest in synthesizing data to improve downstream text-to-SQL tasks. In this paper, we first examined the existing synthesized datasets and discovered that state-of-the-art text-to-SQL algorithms did not further improve on popular benchmarks when trained with augmented synthetic data. We observed two shortcomings: illogical synthetic SQL queries from independent column sampling and arbitrary table joins. To address these issues, we propose a novel synthesis framework that incorporates key relationships from schema, imposes strong typing, and conducts schema-distance-weighted column sampling. We also adopt an intermediate representation (IR) for the SQL-to-text task to further improve the quality of the generated natural language questions. When existing powerful semantic parsers are pre-finetuned on our high-quality synthesized data, our experiments show that these models have significant accuracy boosts on popular benchmarks, including new state-of-the-art performance on Spider.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "71078011",
                        "name": "Yiyun Zhao"
                    },
                    {
                        "authorId": "3024518",
                        "name": "Jiarong Jiang"
                    },
                    {
                        "authorId": "2186873589",
                        "name": "Yiqun Hu"
                    },
                    {
                        "authorId": "37852874",
                        "name": "Wuwei Lan"
                    },
                    {
                        "authorId": "2117693830",
                        "name": "He Zhu"
                    },
                    {
                        "authorId": "2196898765",
                        "name": "Anuj Chauhan"
                    },
                    {
                        "authorId": "2123247219",
                        "name": "A. Li"
                    },
                    {
                        "authorId": "2101328894",
                        "name": "Lin Pan"
                    },
                    {
                        "authorId": "66063792",
                        "name": "J. Wang"
                    },
                    {
                        "authorId": "2236867",
                        "name": "Chung-Wei Hang"
                    },
                    {
                        "authorId": "38654394",
                        "name": "Shenmin Zhang"
                    },
                    {
                        "authorId": "2196939793",
                        "name": "Mingwen Dong"
                    },
                    {
                        "authorId": "1393866988",
                        "name": "Joseph Lilien"
                    },
                    {
                        "authorId": "145878390",
                        "name": "Patrick Ng"
                    },
                    {
                        "authorId": "40296541",
                        "name": "Zhiguo Wang"
                    },
                    {
                        "authorId": "2879453",
                        "name": "Vittorio Castelli"
                    },
                    {
                        "authorId": "144028698",
                        "name": "Bing Xiang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Despite strong performance of pre-trained language models (LMs) across many tasks, they have been shown to struggle in a compositional generalization setting (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021), when tested on their ability to process and generate novel combinations of previously observed elements.",
                "\u2026pre-trained language models (LMs) across many tasks, they have been shown to struggle in a compositional generalization setting (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021), when tested on their ability to process and generate novel combinations of previously observed elements.",
                "We use the standard (i.i.d.) and compositional splits created by Shaw et al. (2021): (1) template split, where target programs are anonymized into templates and then the templates are randomly split between training and test sets (Finegan-Dollak et al., 2018); (2) TMCD split, which makes the\u2026"
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "34ff1da13770908ef0bf389365cdde743d3c9db1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-06800",
                    "ArXiv": "2212.06800",
                    "ACL": "2023.acl-long.78",
                    "DOI": "10.48550/arXiv.2212.06800",
                    "CorpusId": 254591242
                },
                "corpusId": 254591242,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/34ff1da13770908ef0bf389365cdde743d3c9db1",
                "title": "Diverse Demonstrations Improve In-context Compositional Generalization",
                "abstract": "In-context learning has shown great success in i.i.d semantic parsing splits, where the training and test sets are drawn from the same distribution. In this setup, models are typically prompted with demonstrations that are similar to the input utterance. However, in the setup of compositional generalization, where models are tested on outputs with structures that are absent from the training set, selecting similar demonstrations is insufficient, as often no example will be similar enough to the input. In this work, we propose a method to select diverse demonstrations that aims to collectively cover all of the structures required in the output program, in order to encourage the model to generalize to new structures from these demonstrations. We empirically show that combining diverse demonstrations with in-context learning substantially improves performance across three compositional generalization semantic parsing datasets in the pure in-context learning setup and when combined with finetuning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1422883272",
                        "name": "Itay Levy"
                    },
                    {
                        "authorId": "50757607",
                        "name": "Ben Bogin"
                    },
                    {
                        "authorId": "1750652",
                        "name": "Jonathan Berant"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Other benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2021) focus on naturally occurring examples but create train-test splits based on the properties of their formal meaning representations (e."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4a43a773f0725c998c65f2d51ddd49d5919183f7",
                "externalIds": {
                    "ArXiv": "2212.05982",
                    "DBLP": "journals/corr/abs-2212-05982",
                    "DOI": "10.48550/arXiv.2212.05982",
                    "CorpusId": 254563860
                },
                "corpusId": 254563860,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/4a43a773f0725c998c65f2d51ddd49d5919183f7",
                "title": "Real-World Compositional Generalization with Disentangled Sequence-to-Sequence Learning",
                "abstract": "Compositional generalization is a basic mechanism in human language learning, which current neural networks struggle with. A recently proposed Disentangled sequence-to-sequence model (Dangle) shows promising generalization capability by learning specialized encodings for each decoding step. We introduce two key modifications to this model which encourage more disentangled representations and improve its compute and memory efficiency, allowing us to tackle compositional generalization in a more realistic setting. Specifically, instead of adaptively re-encoding source keys and values at each time step, we disentangle their representations and only re-encode keys periodically, at some interval. Our new architecture leads to better generalization performance across existing tasks and datasets, and a new machine translation benchmark which we create by detecting naturally occurring compositional patterns in relation to a training set. We show this methodology better emulates real-world requirements than artificial challenges.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115239329",
                        "name": "Hao Zheng"
                    },
                    {
                        "authorId": "1747893",
                        "name": "Mirella Lapata"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "704332d287bc78ac95fea3d90ec3945e9cec9ab3",
                "externalIds": {
                    "DOI": "10.1016/j.aiopen.2022.12.003",
                    "CorpusId": 255082967
                },
                "corpusId": 255082967,
                "publicationVenue": {
                    "id": "6c35576a-a87d-4dc1-a576-780572d8d0e6",
                    "name": "AI Open",
                    "type": "journal",
                    "issn": "2666-6510",
                    "url": "https://www.keaipublishing.com/en/journals/ai-open/"
                },
                "url": "https://www.semanticscholar.org/paper/704332d287bc78ac95fea3d90ec3945e9cec9ab3",
                "title": "A survey on complex factual question answering",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2145402325",
                        "name": "Lingxi Zhang"
                    },
                    {
                        "authorId": "2158144101",
                        "name": "Jing Zhang"
                    },
                    {
                        "authorId": "1993985136",
                        "name": "Xirui Ke"
                    },
                    {
                        "authorId": "144911687",
                        "name": "Haoyang Li"
                    },
                    {
                        "authorId": "2198199708",
                        "name": "Xinmei Huang"
                    },
                    {
                        "authorId": "2198102520",
                        "name": "Zhonghui Shao"
                    },
                    {
                        "authorId": "1712738522",
                        "name": "S. Cao"
                    },
                    {
                        "authorId": "48574888",
                        "name": "Xin Lv"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2020), architecture improvements (Dess\u00ec and Baroni, 2019; Gordon et al., 2020; Oren et al., 2020; Zheng and Lapata, 2021; Herzig et al., 2021; Shaw et al., 2021), task decomposition (Liu et al.",
                "\u2026al., 2020), architecture improvements (Dess\u00ec and Baroni, 2019; Gordon et al., 2020; Oren et al., 2020; Zheng and Lapata, 2021; Herzig et al., 2021; Shaw et al., 2021), task decomposition (Liu et al., 2020, 2021), semi-supervised learning (Guo et al., 2021), multi-task learning (Jiang and Bansal,\u2026"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "2e935268b66e12dd310af5c715013147d454e560",
                "externalIds": {
                    "ACL": "2022.emnlp-main.808",
                    "ArXiv": "2211.15578",
                    "DBLP": "conf/emnlp/JiangZB22",
                    "DOI": "10.48550/arXiv.2211.15578",
                    "CorpusId": 254043511
                },
                "corpusId": 254043511,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/2e935268b66e12dd310af5c715013147d454e560",
                "title": "Mutual Exclusivity Training and Primitive Augmentation to Induce Compositionality",
                "abstract": "Recent datasets expose the lack of the systematic generalization ability in standard sequence-to-sequence models. In this work, we analyze this behavior of seq2seq models and identify two contributing factors: a lack of mutual exclusivity bias (one target sequence can only be mapped to one source sequence), and the tendency to memorize whole examples rather than separating structures from contents. We propose two techniques to address these two issues respectively: Mutual Exclusivity Training that prevents the model from producing seen generations when facing novel examples via an unlikelihood-based loss, and prim2primX data augmentation that automatically diversifies the arguments of every syntactic function to prevent memorizing and provide a compositional inductive bias without exposing test-set data. Combining these two techniques, we show substantial empirical improvements using standard sequence-to-sequence models (LSTMs and Transformers) on two widely-used compositionality datasets: SCAN and COGS. Finally, we provide analysis characterizing the improvements as well as the remaining challenges, and provide detailed ablations of our method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "31688795",
                        "name": "Yichen Jiang"
                    },
                    {
                        "authorId": "144401309",
                        "name": "Xiang Zhou"
                    },
                    {
                        "authorId": "143977268",
                        "name": "Mohit Bansal"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The Semantic Parsing approach also addresses part of the problem (Shaw et al. 2021).",
                "GeoQuery (Shaw et al. 2021) is a non-synthetic dataset with pairs of questions and meaning representations annotated by humans."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "30977afbd4501249e1a320bd2e48581197914ab8",
                "externalIds": {
                    "ArXiv": "2211.11956",
                    "DBLP": "journals/corr/abs-2211-11956",
                    "DOI": "10.48550/arXiv.2211.11956",
                    "CorpusId": 253761414
                },
                "corpusId": 253761414,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/30977afbd4501249e1a320bd2e48581197914ab8",
                "title": "A Short Survey of Systematic Generalization",
                "abstract": "This survey includes systematic generalization and a history of how machine learning addresses it. We aim to summarize and organize the related information of both conventional and recent improvements. We first look at the definition of systematic generalization, then introduce Classicist and Connectionist. We then discuss different types of Connectionists and how they approach the generalization. Two crucial problems of variable binding and causality are discussed. We look into systematic generalization in language, vision, and VQA fields. Recent improvements from different aspects are discussed. Systematic generalization has a long history in artificial intelligence. We could cover only a small portion of many contributions. We hope this paper provides a background and is beneficial for discoveries in future work.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2111188503",
                        "name": "Yuanpeng Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2020), but they still fail on tasks that require compositional generalization (Shaw et al., 2021; Furrer et al., 2020).",
                "Big language models have impressive performance on many language understanding tasks (Devlin et al., 2019; Raffel et al., 2020; Chowdhery et al., 2022; Lewis et al., 2020), but they still fail on tasks that require compositional generalization (Shaw et al., 2021; Furrer et al., 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "95915aa592fdfc73f039c13472a21d3e4220f129",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-08473",
                    "ACL": "2022.blackboxnlp-1.22",
                    "ArXiv": "2211.08473",
                    "DOI": "10.48550/arXiv.2211.08473",
                    "CorpusId": 253553137
                },
                "corpusId": 253553137,
                "publicationVenue": {
                    "id": "738626d7-5b8c-497d-9fd6-64bdb6dbf440",
                    "name": "BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
                    "type": "conference",
                    "alternate_names": [
                        "BlackboxNLP",
                        "Blackboxnlp Workshop Anal Interpr\u00e8t Neural Netw NLP"
                    ],
                    "url": "https://aclanthology.org/venues/blackboxnlp/"
                },
                "url": "https://www.semanticscholar.org/paper/95915aa592fdfc73f039c13472a21d3e4220f129",
                "title": "On the Compositional Generalization Gap of In-Context Learning",
                "abstract": "Pretrained large generative language models have shown great performance on many tasks, but exhibit low compositional generalization abilities. Scaling such models has been shown to improve their performance on various NLP tasks even just by conditioning them on a few examples to solve the task without any fine-tuning (also known as in-context learning). In this work, we look at the gap between the in-distribution (ID) and out-of-distribution (OOD) performance of such models in semantic parsing tasks with in-context learning. In the ID settings, the demonstrations are from the same split (\\textit{test} or \\textit{train}) that the model is being evaluated on, and in the OOD settings, they are from the other split. We look at how the relative generalization gap of in-context learning evolves as models are scaled up. We evaluate four model families, OPT, BLOOM, CodeGen and Codex on three semantic parsing datasets, CFQ, SCAN and GeoQuery with different number of exemplars, and observe a trend of decreasing relative generalization gap as models are scaled up.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2090537547",
                        "name": "Arian Hosseini"
                    },
                    {
                        "authorId": "34360821",
                        "name": "A. Vani"
                    },
                    {
                        "authorId": "3335364",
                        "name": "Dzmitry Bahdanau"
                    },
                    {
                        "authorId": "2041695",
                        "name": "Alessandro Sordoni"
                    },
                    {
                        "authorId": "2058336670",
                        "name": "Aaron C. Courville"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2020) architectures, both of which have frequently been applied to semantic parsing benchmarks (Shaw et al., 2021; Scholak et al., 2021; Desai and Aly, 2021; Banerjee et al., 2022)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c428f1621f79925311082d8d7425dd4d50cd64ed",
                "externalIds": {
                    "ArXiv": "2211.07443",
                    "DBLP": "journals/corr/abs-2211-07443",
                    "DOI": "10.1162/tacl_a_00598",
                    "CorpusId": 253510101
                },
                "corpusId": 253510101,
                "publicationVenue": {
                    "id": "e0dbf116-86aa-418d-859f-a49952d7e44a",
                    "name": "Transactions of the Association for Computational Linguistics",
                    "type": "journal",
                    "alternate_names": [
                        "Trans Assoc Comput Linguistics",
                        "TACL"
                    ],
                    "issn": "2307-387X",
                    "url": "https://www.mitpressjournals.org/loi/tacl",
                    "alternate_urls": [
                        "http://www.transacl.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c428f1621f79925311082d8d7425dd4d50cd64ed",
                "title": "Calibrated Interpretation: Confidence Estimation in Semantic Parsing",
                "abstract": "Abstract Sequence generation models are increasingly being used to translate natural language into programs, i.e., to perform executable semantic parsing. The fact that semantic parsing aims to predict programs that can lead to executed actions in the real world motivates developing safe systems. This in turn makes measuring calibration\u2014a central component to safety\u2014particularly important. We investigate the calibration of popular generation models across four popular semantic parsing datasets, finding that it varies across models and datasets. We then analyze factors associated with calibration error and release new confidence-based challenge splits of two parsing datasets. To facilitate the inclusion of calibration in semantic parsing evaluations, we release a library for computing calibration metrics.1",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1405407255",
                        "name": "Elias Stengel-Eskin"
                    },
                    {
                        "authorId": "7536576",
                        "name": "Benjamin Van Durme"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "3de49a44cd46943afb4483a799a78248107bbd06",
                "externalIds": {
                    "ArXiv": "2211.07514",
                    "DBLP": "journals/corr/abs-2211-07514",
                    "DOI": "10.48550/arXiv.2211.07514",
                    "CorpusId": 253511178
                },
                "corpusId": 253511178,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3de49a44cd46943afb4483a799a78248107bbd06",
                "title": "CST5: Data Augmentation for Code-Switched Semantic Parsing",
                "abstract": "Extending semantic parsers to code-switched input has been a challenging problem, primarily due to a lack of supervised training data. In this work, we introduce CST5, a new data augmentation technique that finetunes a T5 model using a small seed set ($\\approx$100 utterances) to generate code-switched utterances from English utterances. We show that CST5 generates high quality code-switched data, both intrinsically (per human evaluation) and extrinsically by comparing baseline models which are trained without data augmentation to models which are trained with augmented data. Empirically we observe that using CST5, one can achieve the same semantic parsing performance by using up to 20x less labeled data. To aid further research in this area, we are also releasing (a) Hinglish-TOP, the largest human annotated code-switched semantic parsing dataset to date, containing 10k human annotated Hindi-English (Hinglish) code-switched utterances, and (b) Over 170K CST5 generated code-switched utterances from the TOPv2 dataset. Human evaluation shows that both the human annotated data as well as the CST5 generated data is of good quality.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2149663958",
                        "name": "Anmol Agarwal"
                    },
                    {
                        "authorId": "2190754791",
                        "name": "Jigar Gupta"
                    },
                    {
                        "authorId": "2061600973",
                        "name": "Rahul Goel"
                    },
                    {
                        "authorId": "33145619",
                        "name": "Shyam Upadhyay"
                    },
                    {
                        "authorId": "2066882823",
                        "name": "Pankaj Joshi"
                    },
                    {
                        "authorId": "41133605",
                        "name": "R. Aravamudhan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Shaw et al. (2020) first shows that the pre-trained Seq2Seq model (Raffel et al., 2020) with 3 Billion parameters achieves competitive performance on the Spider dataset."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "4dbd5febea8968acda097642e3daf2c312618bed",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-05165",
                    "ArXiv": "2211.05165",
                    "ACL": "2022.emnlp-main.605",
                    "DOI": "10.48550/arXiv.2211.05165",
                    "CorpusId": 253447215
                },
                "corpusId": 253447215,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/4dbd5febea8968acda097642e3daf2c312618bed",
                "title": "Uni-Parser: Unified Semantic Parser for Question Answering on Knowledge Base and Database",
                "abstract": "Parsing natural language questions into executable logical forms is a useful and interpretable way to perform question answering on structured data such as knowledge bases (KB) or databases (DB). However, existing approaches on semantic parsing cannot adapt to both modalities, as they suffer from the exponential growth of the logical form candidates and can hardly generalize to unseen data.In this work, we propose Uni-Parser, a unified semantic parser for question answering (QA) on both KB and DB. We define the primitive (relation and entity in KB, and table name, column name and cell value in DB) as the essential element in our framework. The number of primitives grows only at a linear rate to the number of retrieved relations in KB and DB, preventing us from exponential logic form candidates. We leverage the generator to predict final logical forms by altering and composing top-ranked primitives with different operations (e.g. select, where, count). With sufficiently pruned search space by a contrastive primitive ranker, the generator is empowered to capture the composition of primitives enhancing its generalization ability. We achieve competitive results on multiple KB and DB QA benchmarks with more efficiency, especially in the compositional and zero-shot settings.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108334982",
                        "name": "Ye Liu"
                    },
                    {
                        "authorId": "3014143",
                        "name": "Semih Yavuz"
                    },
                    {
                        "authorId": "2087884364",
                        "name": "Rui Meng"
                    },
                    {
                        "authorId": "9215251",
                        "name": "Dragomir R. Radev"
                    },
                    {
                        "authorId": "2054594326",
                        "name": "Caiming Xiong"
                    },
                    {
                        "authorId": "2118860628",
                        "name": "Yingbo Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "7e942e813e3fb814f2d0b997ae849548a9e40638",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-12674",
                    "ArXiv": "2210.12674",
                    "DOI": "10.48550/arXiv.2210.12674",
                    "CorpusId": 253098392
                },
                "corpusId": 253098392,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/7e942e813e3fb814f2d0b997ae849548a9e40638",
                "title": "Towards Generalizable and Robust Text-to-SQL Parsing",
                "abstract": "Text-to-SQL parsing tackles the problem of mapping natural language questions to executable SQL queries. In practice, text-to-SQL parsers often encounter various challenging scenarios, requiring them to be generalizable and robust. While most existing work addresses a particular generalization or robustness challenge, we aim to study it in a more comprehensive manner. In specific, we believe that text-to-SQL parsers should be (1) generalizable at three levels of generalization, namely i.i.d., zero-shot, and compositional, and (2) robust against input perturbations. To enhance these capabilities of the parser, we propose a novel TKK framework consisting of Task decomposition, Knowledge acquisition, and Knowledge composition to learn text-to-SQL parsing in stages. By dividing the learning process into multiple stages, our framework improves the parser's ability to acquire general SQL knowledge instead of capturing spurious patterns, making it more generalizable and robust. Experimental results under various generalization and robustness settings show that our framework is effective in all scenarios and achieves state-of-the-art performance on the Spider, SParC, and CoSQL datasets. Code can be found at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/tkk.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2090142517",
                        "name": "Chang Gao"
                    },
                    {
                        "authorId": "2132475886",
                        "name": "Bowen Li"
                    },
                    {
                        "authorId": "150341144",
                        "name": "Wenxuan Zhang"
                    },
                    {
                        "authorId": "1380007189",
                        "name": "W. Lam"
                    },
                    {
                        "authorId": "66200440",
                        "name": "Binhua Li"
                    },
                    {
                        "authorId": "2087380523",
                        "name": "Fei Huang"
                    },
                    {
                        "authorId": "2161888510",
                        "name": "Luo Si"
                    },
                    {
                        "authorId": "1527090216",
                        "name": "Yongbin Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Further works have explored both problems\u2014multi-hop reasoning and compositional generalization\u2014through the lens of semantic parsing (Wolfson et al., 2020; Shaw et al., 2021).",
                "Recent work in compositionality in NLP has been mostly limited to semantic parsing and multihop reasoning for the purpose of Q&A (Shaw et al.,\n2021; Wolfson et al., 2020; Min et al., 2019).",
                "Many recent works in the Q&A literature have strived to study compositionality on either a question or system level."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "798abf86efae9e37b9b6a694ef87b6c1dbaab263",
                "externalIds": {
                    "ArXiv": "2210.12607",
                    "DBLP": "conf/emnlp/BursztynDDB22",
                    "DOI": "10.48550/arXiv.2210.12607",
                    "CorpusId": 253098647
                },
                "corpusId": 253098647,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/798abf86efae9e37b9b6a694ef87b6c1dbaab263",
                "title": "Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models",
                "abstract": "How to usefully encode compositional task structure has long been a core challenge in AI. Recent work in chain of thought prompting has shown that for very large neural language models (LMs), explicitly demonstrating the inferential steps involved in a target task may improve performance over end-to-end learning that focuses on the target task alone. However, chain of thought prompting has significant limitations due to its dependency on huge pretrained LMs. In this work, we present compositional fine-tuning (CFT): an approach based on explicitly decomposing a target task into component tasks, and then fine-tuning smaller LMs on a curriculum of such component tasks. We apply CFT to recommendation tasks in two domains, world travel and local dining, as well as a previously studied inferential task (sports understanding). We show that CFT outperforms end-to-end learning even with equal amounts of data, and gets consistently better as more component tasks are modeled via fine-tuning. Compared with chain of thought prompting, CFT performs at least as well using LMs only 7.4% of the size, and is moreover applicable to task domains for which data are not available during pretraining.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2957094",
                        "name": "Victor S. Bursztyn"
                    },
                    {
                        "authorId": "48418509",
                        "name": "David Demeter"
                    },
                    {
                        "authorId": "145612610",
                        "name": "Doug Downey"
                    },
                    {
                        "authorId": "2065599650",
                        "name": "Larry Birnbaum"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Shaw et al. (2021) also address the challenge of natural language variation in compositional generalization, but they experiment on semantic parsing, where the knowledge is highly consistent and can be inducted with grammar rules."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c6e4518dfd687a2a5bed4e78d5d9f999292a1746",
                "externalIds": {
                    "ACL": "2022.emnlp-main.497",
                    "DBLP": "conf/emnlp/0032FTH022",
                    "ArXiv": "2210.11431",
                    "DOI": "10.48550/arXiv.2210.11431",
                    "CorpusId": 253018602
                },
                "corpusId": 253018602,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/c6e4518dfd687a2a5bed4e78d5d9f999292a1746",
                "title": "Counterfactual Recipe Generation: Exploring Compositional Generalization in a Realistic Scenario",
                "abstract": "People can acquire knowledge in an unsupervised manner by reading, and compose the knowledge to make novel combinations. In this paper, we investigate whether pretrained language models can perform compositional generalization in a realistic setting: recipe generation. We design the counterfactual recipe generation task, which asks models to modify a base recipe according to the change of an ingredient. This task requires compositional generalization at two levels: the surface level of incorporating the new ingredient into the base recipe, and the deeper level of adjusting actions related to the changing ingredient. We collect a large-scale recipe dataset in Chinese for models to learn culinary knowledge, and a subset of action-level fine-grained annotations for evaluation.We finetune pretrained language models on the recipe corpus, and use unsupervised counterfactual generation methods to generate modified recipes.Results show that existing models have difficulties in modifying the ingredients while preserving the original text style, and often miss actions that need to be adjusted. Although pretrained language models can generate fluent recipe texts, they fail to truly learn and use the culinary knowledge in a compositional way. Code and data are available at https://github.com/xxxiaol/counterfactual-recipe-generation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "49543720",
                        "name": "Xiao Liu"
                    },
                    {
                        "authorId": "2115387922",
                        "name": "Yansong Feng"
                    },
                    {
                        "authorId": "51119232",
                        "name": "Jizhi Tang"
                    },
                    {
                        "authorId": "2188573668",
                        "name": "ChenGang Hu"
                    },
                    {
                        "authorId": "144060462",
                        "name": "Dongyan Zhao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We take the serialization scheme mentioned in [45] and enable database content by appending database values to the column names [15]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "4431a39f677fe59b07b3f0cfde7b10f7208cf46c",
                "externalIds": {
                    "ArXiv": "2210.10668",
                    "DBLP": "conf/slt/ZengPH22",
                    "DOI": "10.1109/SLT54892.2023.10023434",
                    "CorpusId": 252992481
                },
                "corpusId": 252992481,
                "publicationVenue": {
                    "id": "d8dfb5ba-9312-410c-a361-8ad05f945939",
                    "name": "Spoken Language Technology Workshop",
                    "type": "conference",
                    "alternate_names": [
                        "SLT",
                        "Spok Lang Technol Workshop"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4431a39f677fe59b07b3f0cfde7b10f7208cf46c",
                "title": "N-Best Hypotheses Reranking for Text-to-SQL Systems",
                "abstract": "Text-to-SQL task maps natural language utterances to structured queries that can be issued to a database. State-of-the-art (SOTA) systems rely on finetuning large, pre-trained language models in conjunction with constrained decoding applying a SQL parser. On the well established Spider dataset, we begin with Oracle studies: specifically, choosing an Oracle hypothesis from a SOTA model's 10-best list, yields a 7.7% absolute improvement in both exact match (EM) and execution (EX) accuracy, showing significant potential improvements with reranking. Identifying coherence and correctness as reranking approaches, we design a model generating a query plan and propose a heuristic schema linking algorithm. Combining both approaches, with T5-Large, we obtain a consistent 1% improvement in EM accuracy, and a 2.5% improvement in EX, establishing a new SOTA for this task. Our comprehensive error studies on DEV data show the underlying difficulty in making progress on this task.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2176186004",
                        "name": "Lu Zeng"
                    },
                    {
                        "authorId": "2181961",
                        "name": "S. Parthasarathi"
                    },
                    {
                        "authorId": "1395813836",
                        "name": "Dilek Z. Hakkani-T\u00fcr"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following Shaw et al. (2021), we benchmark the competitive T5-base model (Raffel et al., 2020) on all splits of the SPIDER dataset.",
                "Other approaches create dataset splits that test for specific skills, such as length generalization (Lake and Baroni, 2018) and compositional generalization (Shaw et al., 2021), but they only apply to a narrow subset of tasks.",
                "For SPIDER, we follow Shaw et al. (2021) and tune the learning rate, batch size and maximum training steps for a T5-base model (Raffel et al., 2020) on a random split of the SPIDER dataset.",
                "Other approaches create dataset splits that test for specific skills, such as length generalization (Lake and Baroni, 2018) and compositional generalization (Shaw et al., 2021), ar X iv :2 21 0.",
                "\u2026of programming languages makes semantic parsing, the task of translating a natural language utterance into a logical program, a good testbed for evaluating compositional generalization (Lake and Baroni, 2018; Kim and Linzen, 2020; Hupkes et al., 2020; Key-\nsers et al., 2020; Shaw et al., 2021).",
                "Shaw et al. (2021), one of the alternative splits that we compare against, use a subset of 4000 examples from the 7000 training examples.",
                "We follow Shaw et al. (2021) and swap examples between the train and evaluation sets such that every logical program atom in the evaluation set appears at least once in the train set.",
                "Following Shaw et al. (2021), we report atom and compound divergences of the various splits in Table 13 of Appendix A.4.",
                "The deterministic grammar of programming languages makes semantic parsing, the task of translating a natural language utterance into a logical program, a good testbed for evaluating compositional generalization (Lake and Baroni, 2018; Kim and Linzen, 2020; Hupkes et al., 2020; Keysers et al., 2020; Shaw et al., 2021)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "49aec6fb44ab52181960512a6067eded0ce4182b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-06799",
                    "ArXiv": "2210.06799",
                    "ACL": "2023.findings-eacl.71",
                    "DOI": "10.48550/arXiv.2210.06799",
                    "CorpusId": 252873216
                },
                "corpusId": 252873216,
                "publicationVenue": {
                    "id": "479d5605-51be-4346-b1d6-4334084504df",
                    "name": "Findings",
                    "type": "journal",
                    "issn": "2652-8800",
                    "url": "https://findingspress.org/"
                },
                "url": "https://www.semanticscholar.org/paper/49aec6fb44ab52181960512a6067eded0ce4182b",
                "title": "Benchmarking Long-tail Generalization with Likelihood Splits",
                "abstract": "In order to reliably process natural language, NLP systems must generalize to the long tail of rare utterances. We propose a method to create challenging benchmarks that require generalizing to the tail of the distribution by re-splitting existing datasets. We create \u2018Likelihood Splits\u2019 where examples that are assigned lower likelihood by a pre-trained language model (LM) are placed in the test set, and more likely examples are in the training set. This simple approach can be customized to construct meaningful train-test splits for a wide range of tasks. Likelihood Splits surface more challenges than random splits: relative error rates of state-of-the-art models increase by 59% for semantic parsing on Spider, 93% for natural language inference on SNLI, and 33% for yes/no question answering on BoolQ, on our splits compared with the corresponding random splits. Moreover, Likelihood Splits create fairer benchmarks than adversarial filtering; when the LM used to create the splits is also employed as the task model, our splits do not unfairly penalize the LM.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "36851489",
                        "name": "Ameya Godbole"
                    },
                    {
                        "authorId": "3422908",
                        "name": "Robin Jia"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently, Shaw et al. (2021); Scholak et al. (2021) successfully applied T5 for the text-to-SQL task.",
                "Correspondence to: ramild.yar@gmail.com\nShaw et al. (2021) continued the study in the multidatabase setting and showed that the compositional generalization was hard to achieve, and even to measure it, one should be very careful with splits.",
                "These pre-trained decoders, like the one of T5, can also be successfully applied to the text-to-SQL task (Shaw et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3f2fa77ce40d21a7cf5e9a4dbf594c85a31576d0",
                "externalIds": {
                    "DBLP": "conf/eacl/OsokinSY23",
                    "ACL": "2023.findings-eacl.168",
                    "ArXiv": "2210.07201",
                    "DOI": "10.48550/arXiv.2210.07201",
                    "CorpusId": 252873443
                },
                "corpusId": 252873443,
                "publicationVenue": {
                    "id": "479d5605-51be-4346-b1d6-4334084504df",
                    "name": "Findings",
                    "type": "journal",
                    "issn": "2652-8800",
                    "url": "https://findingspress.org/"
                },
                "url": "https://www.semanticscholar.org/paper/3f2fa77ce40d21a7cf5e9a4dbf594c85a31576d0",
                "title": "Searching for Better Database Queries in the Outputs of Semantic Parsers",
                "abstract": "The task of generating a database query from a question in natural language suffers from ambiguity and insufficiently precise description of the goal. The problem is amplified when the system needs to generalize to databases unseen at training. In this paper, we consider the case when, at the test time, the system has access to an external criterion that evaluates the generated queries. The criterion can vary from checking that a query executes without errors to verifying the query on a set of tests. In this setting, we augment neural autoregressive models with a search algorithm that looks for a query satisfying the criterion. We apply our approach to the state-of-the-art semantic parsers and report that it allows us to find many queries passing all the tests on different datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145319877",
                        "name": "A. Osokin"
                    },
                    {
                        "authorId": "1452680271",
                        "name": "Irina Saparina"
                    },
                    {
                        "authorId": "94927688",
                        "name": "R. B. Yarullin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "a19d9fd97cf172e1eb742053770c397d80468448",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-04878",
                    "ArXiv": "2210.04878",
                    "ACL": "2023.findings-eacl.17",
                    "DOI": "10.48550/arXiv.2210.04878",
                    "CorpusId": 252780640
                },
                "corpusId": 252780640,
                "publicationVenue": {
                    "id": "479d5605-51be-4346-b1d6-4334084504df",
                    "name": "Findings",
                    "type": "journal",
                    "issn": "2652-8800",
                    "url": "https://findingspress.org/"
                },
                "url": "https://www.semanticscholar.org/paper/a19d9fd97cf172e1eb742053770c397d80468448",
                "title": "Translate First Reorder Later: Leveraging Monotonicity in Semantic Parsing",
                "abstract": "Prior work in semantic parsing has shown that conventional seq2seq models fail at compositional generalization tasks. This limitation led to a resurgence of methods that model alignments between sentences and their corresponding meaning representations, either implicitly through latent variables or explicitly by taking advantage of alignment annotations. We take the second direction and propose TPol, a two-step approach that first translates input sentences monotonically and then reorders them to obtain the correct output. This is achieved with a modular framework comprising a Translator and a Reorderer component. We test our approach on two popular semantic parsing datasets. Our experiments show that by means of the monotonic translations, TPol can learn reliable lexico-logical patterns from aligned data, significantly improving compositional generalization both over conventional seq2seq models, as well as over other approaches that exploit gold alignments.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2187298458",
                        "name": "Francesco Cazzaro"
                    },
                    {
                        "authorId": "2187298466",
                        "name": "Davide Locatelli"
                    },
                    {
                        "authorId": "3171632",
                        "name": "A. Quattoni"
                    },
                    {
                        "authorId": "1701734",
                        "name": "X. Carreras"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Structured knowledge grounding tasks mainly adopt semantic parsing since symbolic languages like SQL, SPARQL can be executed on them (Berant et al., 2013; Liang et al., 2017; Yin & Neubig, 2017; Zhong et al., 2018; Yu et al., 2018; Shaw et al., 2021; Scholak et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "f58ca7ba4a08b7082e86b7a5989b4b0fda2107ab",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-02875",
                    "ArXiv": "2210.02875",
                    "DOI": "10.48550/arXiv.2210.02875",
                    "CorpusId": 252734772
                },
                "corpusId": 252734772,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/f58ca7ba4a08b7082e86b7a5989b4b0fda2107ab",
                "title": "Binding Language Models in Symbolic Languages",
                "abstract": "Though end-to-end neural approaches have recently been dominating NLP tasks in both performance and ease-of-use, they lack interpretability and robustness. We propose Binder, a training-free neural-symbolic framework that maps the task input to a program, which (1) allows binding a unified API of language model (LM) functionalities to a programming language (e.g., SQL, Python) to extend its grammar coverage and thus tackle more diverse questions, (2) adopts an LM as both the program parser and the underlying model called by the API during execution, and (3) requires only a few in-context exemplar annotations. Specifically, we employ GPT-3 Codex as the LM. In the parsing stage, with only a few in-context exemplars, Codex is able to identify the part of the task input that cannot be answerable by the original programming language, correctly generate API calls to prompt Codex to solve the unanswerable part, and identify where to place the API calls while being compatible with the original grammar. In the execution stage, Codex can perform versatile functionalities (e.g., commonsense QA, information extraction) given proper prompts in the API calls. Binder achieves state-of-the-art results on WikiTableQuestions and TabFact datasets, with explicit output programs that benefit human debugging. Note that previous best systems are all finetuned on tens of thousands of task-specific samples, while Binder only uses dozens of annotations as in-context exemplars without any training. Our code is available at https://github.com/HKUNLP/Binder .",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1471878967",
                        "name": "Zhoujun Cheng"
                    },
                    {
                        "authorId": "2057038673",
                        "name": "Tianbao Xie"
                    },
                    {
                        "authorId": "2055356856",
                        "name": "Peng Shi"
                    },
                    {
                        "authorId": "2155795167",
                        "name": "Chengzu Li"
                    },
                    {
                        "authorId": "40027281",
                        "name": "R.K. Nadkarni"
                    },
                    {
                        "authorId": "2112209725",
                        "name": "Yushi Hu"
                    },
                    {
                        "authorId": "2054594326",
                        "name": "Caiming Xiong"
                    },
                    {
                        "authorId": "9215251",
                        "name": "Dragomir R. Radev"
                    },
                    {
                        "authorId": "81444299",
                        "name": "M. Ostendorf"
                    },
                    {
                        "authorId": "2137813791",
                        "name": "Luke Zettlemoyer"
                    },
                    {
                        "authorId": "2116827887",
                        "name": "N. A. Smith"
                    },
                    {
                        "authorId": null,
                        "name": "Tao Yu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Shaw et al. (2021) heuristically induce a QCFG and create an ensemble of a QCFG-based parser and a seq2seq model."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a0f40a1e4b11f286c87952d0cf7db9429c4f1c53",
                "externalIds": {
                    "ACL": "2023.eacl-main.159",
                    "ArXiv": "2210.03183",
                    "DBLP": "journals/corr/abs-2210-03183",
                    "DOI": "10.48550/arXiv.2210.03183",
                    "CorpusId": 252762446
                },
                "corpusId": 252762446,
                "publicationVenue": {
                    "id": "8de18c35-6785-4e54-99f2-21ee961302c6",
                    "name": "Conference of the European Chapter of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Conf Eur Chapter Assoc Comput Linguistics",
                        "EACL"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/eacl/"
                },
                "url": "https://www.semanticscholar.org/paper/a0f40a1e4b11f286c87952d0cf7db9429c4f1c53",
                "title": "Compositional Generalisation with Structured Reordering and Fertility Layers",
                "abstract": "Seq2seq models have been shown to struggle with compositional generalisation, i.e. generalising to new and potentially more complex structures than seen during training. Taking inspiration from grammar-based models that excel at compositional generalisation, we present a flexible end-to-end differentiable neural model that composes two structural operations: a fertility step, which we introduce in this work, and a reordering step based on previous work (Wang et al., 2021). To ensure differentiability, we use the expected value of each step, which we compute using dynamic programming. Our model outperforms seq2seq models by a wide margin on challenging compositional splits of realistic semantic parsing tasks that require generalisation to longer examples. It also compares favourably to other models targeting compositional generalisation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "46233689",
                        "name": "Matthias Lindemann"
                    },
                    {
                        "authorId": "145542037",
                        "name": "Alexander Koller"
                    },
                    {
                        "authorId": "144889265",
                        "name": "Ivan Titov"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2019), semantic parsing (e.g. Finegan-Dollak et al., 2018; Keysers et al., 2019; Kim and Linzen, 2020; Shaw et al., 2021) or other kinds of generation tasks (e.",
                "\u20262016), machine translation (e.g. Dankers et al., 2022; Liu et al., 2021b; Raunak et al., 2019), semantic parsing (e.g. Finegan-Dollak et al., 2018; Keysers et al., 2019; Kim and Linzen, 2020; Shaw et al., 2021) or other kinds of generation tasks (e.g. Hupkes et al., 2020; Lake and Baroni, 2018)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "559bfba3bee31f6061a5d5c7061f22794de47e39",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-03050",
                    "ArXiv": "2210.03050",
                    "DOI": "10.48550/arXiv.2210.03050",
                    "CorpusId": 252735124
                },
                "corpusId": 252735124,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/559bfba3bee31f6061a5d5c7061f22794de47e39",
                "title": "State-of-the-art generalisation research in NLP: a taxonomy and review",
                "abstract": "The ability to generalise well is one of the primary desiderata of natural language processing (NLP). Yet, what \u2018good generalisation\u2019 entails and how it should be evaluated is not well understood, nor are there any common standards to evaluate it. In this paper, we aim to lay the groundwork to improve both of these issues. We present a taxonomy for characterising and understanding generalisation research in NLP, we use that taxonomy to present a comprehensive map of published generalisation studies, and we make recommendations for which areas might deserve attention in the future. Our taxonomy is based on an extensive literature review of generalisation research, and contains five axes along which studies can differ: their main motivation, the type of generalisation they aim to solve, the type of data shift they consider, the source by which this data shift is obtained, and the locus of the shift within the modelling pipeline. We use our taxonomy to classify over 400 previous papers that test generalisation, for a total of more than 600 individual experiments. Considering the results of this review, we present an in-depth analysis of the current state of generalisation research in NLP, and make recommendations for the future. Along with this paper, we release a webpage where the results of our review can be dynamically explored, and which we intend to update as new NLP generalisation studies are published. With this work, we aim to make steps towards making state-of-the-art generalisation testing the new status quo in NLP.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3449411",
                        "name": "D. Hupkes"
                    },
                    {
                        "authorId": "24068173",
                        "name": "Mario Giulianelli"
                    },
                    {
                        "authorId": "74461595",
                        "name": "Verna Dankers"
                    },
                    {
                        "authorId": "2347956",
                        "name": "Mikel Artetxe"
                    },
                    {
                        "authorId": "51131518",
                        "name": "Yanai Elazar"
                    },
                    {
                        "authorId": "1388571351",
                        "name": "Tiago Pimentel"
                    },
                    {
                        "authorId": "2718039",
                        "name": "Christos Christodoulopoulos"
                    },
                    {
                        "authorId": "51121444",
                        "name": "Karim Lasri"
                    },
                    {
                        "authorId": "2362960",
                        "name": "Naomi Saphra"
                    },
                    {
                        "authorId": "153915609",
                        "name": "Arabella J. Sinclair"
                    },
                    {
                        "authorId": "133864309",
                        "name": "Dennis Ulmer"
                    },
                    {
                        "authorId": "2187058204",
                        "name": "Florian Schottmann"
                    },
                    {
                        "authorId": "2049136",
                        "name": "Khuyagbaatar Batsuren"
                    },
                    {
                        "authorId": "2087314342",
                        "name": "Kaiser Sun"
                    },
                    {
                        "authorId": "40910779",
                        "name": "Koustuv Sinha"
                    },
                    {
                        "authorId": "50824937",
                        "name": "Leila Khalatbari"
                    },
                    {
                        "authorId": "1410648718",
                        "name": "Maria Ryskina"
                    },
                    {
                        "authorId": "1397300094",
                        "name": "Rita Frieske"
                    },
                    {
                        "authorId": "2070989574",
                        "name": "Ryan Cotterell"
                    },
                    {
                        "authorId": "2111472502",
                        "name": "Zhijing Jin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, SCAN is an artificial task built upon a synthetic language with a tiny vocabulary and is generated from a small set of grammar rules, and it is unclear whether strong results transfer to more realistic tasks that are based on a larger vocabulary and more complicated grammars (Furrer et al., 2020).",
                "Similarly to symbolic grammar learning techniques on SCAN, these approaches achieve impressive performance on several benchmarks, and represent the previous state of the art on CFQ (Keysers et al., 2020) and COGS (Kim & Linzen, 2020).",
                "Since SCAN commands are generated by a simple grammar of only 20 rules, this decomposition task can be performed using a prompt consisting of only 8 decomposition exemplars.",
                "C L\n] 3\n0 Se\np 20\n22\nWe evaluate our approach on two realistic benchmarks that, like SCAN, are designed to measure compositional generalization: CFQ (Keysers et al., 2020) and COGS (Kim & Linzen, 2020).",
                "Indeed, while decomposing SCAN commands is similar to decomposing mathematical expressions with standard arithmetic operations, decomposing sentences corresponding to more realistic subsets of natural language essentially becomes a problem of syntactic parsing.",
                "As an illustration, consider the application of least-to-most prompting to SCAN.",
                "A number of approaches have been proposed to improve compositional generalization on SCAN (Lake & Baroni, 2018; Loula et al., 2018), including specialized design of neural model architectures (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021; Russin et al., 2019; Li et al., 2019; Gordon et al., 2020; Herzig & Berant, 2021) and training algorithms (Lake, 2019; Kim, 2021), training data augmentation (Andreas, 2020; Akyu\u0308rek et al., 2021), and prompting (Zhou et al., 2022).",
                "In particular, recent work (Zhou et al., 2022) found that least-to-most prompting shows a lot of potential for adapting LLMs for compositional generalization, achieving 99.7% accuracy on SCAN, a commonly used compositional generalization benchmark.",
                "As for CFQ and SCAN, the training data for COGS contains multiple systematic gaps that can only be addressed by compositional generalization; these include new combinations of familiar syntactic structures and familiar structures.",
                "Roughly, the decomposition of a SCAN statement resembles that of a mathematical expression with standard arithmetic operations.",
                "Even more general purpose methods that rely on data augmentation are limited in the class of data it can support (Shaw et al., 2021; Qiu et al., 2022a).",
                "Compared to SCAN, CFQ is based on a much larger vocabulary as well as more complex linguistic structures produced by a unification-based grammar (Shieber, 2003).",
                "Recent work has achieved perfect generalization accuracy on SCAN by inferring grammar rules in symbolic form (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021).",
                "While 100% accuracy has been accomplished on SCAN (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021), good performance on SCAN does not necessarily transfer to more challenging compositional generalization problems (Furrer et al.",
                "Notably, although least-to-most prompting has achieved 99.7% accuracy on SCAN (Zhou et al., 2022), prior attempts on prompting for semantic parsing still demonstrate limited compositional generalization performance (Qiu et al., 2022b).",
                "\u2026problem that attracts attention across fields, including vision (Johnson et al., 2017; Bahdanau et al., 2019; Ruis et al., 2020; Nikolaus et al., 2019) and language domains (Lake & Baroni, 2018; Keysers et al., 2020; Kim & Linzen, 2020; Shaw et al., 2021; Yin et al., 2021; Gan et al., 2022).",
                "\u20262018; Loula et al., 2018), including specialized design of neural model architectures (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021; Russin et al., 2019; Li et al., 2019; Gordon et al., 2020; Herzig & Berant, 2021) and training algorithms (Lake, 2019; Kim, 2021),\u2026",
                "As an illustration of the context-free nature of SCAN, consider the expression \u201cwalk twice\u201d, which always translates to \u201cWALK WALK\u201d.",
                "While the performance of least-to-most prompting on SCAN is impressive, it is not clear whether and how the same technique can be applied to compositional generalization problems that are based on a more realistic subset of natural language.",
                "As discussed in Section 2.3, decomposition is more challenging for realistic tasks such as CFQ and COGS than for artificial tasks like SCAN.",
                "Single Prompt Insufficient to Represent Full Label Space In the case of SCAN, the knowledge needed to translate a command into a sequence of actions is small enough that it can be captured with about a dozen examples.",
                ", 2018), including specialized design of neural model architectures (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021; Russin et al., 2019; Li et al., 2019; Gordon et al., 2020; Herzig & Berant, 2021) and training algorithms (Lake, 2019; Kim, 2021), training data augmentation (Andreas, 2020; Aky\u00fcrek et al.",
                "While 100% accuracy has been accomplished on SCAN (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021), good performance on SCAN does not necessarily transfer to more challenging compositional generalization problems (Furrer et al., 2020).",
                "Natural Language is Challenging to Decompose SCAN commands are constructed from eight distinct symbols with a fixed precedence (\u201cleft\u201d, \u201cright\u201d, \u201ctwice\u201d, \u201cthrice\u201d, \u201copposite\u201d, \u201caround\u201d, \u201cand\u201d, and \u201cafter\u201d).",
                "In practice, the decomposition for SCAN can be predicted by a language model using a simple prompt.",
                "SCAN (Lake & Baroni, 2018; Loula et al., 2018) is one of the earliest benchmarks that shows neural sequence models cannot systematically generalize to novel combinations of the primitive items of the language.",
                "Also, decomposing a problem is more difficult than with SCAN, exacerbated by constituents that cannot be translated independent of their context.",
                "Most recently, Zhou et al. (2022) demonstrate that SCAN can be solved by least-to-most prompting, which leverages a pretrained large language model (LLM) and a prompt consisting of only 14 exemplars, which is less than 0.1% of the training data used by previous approaches."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "40047a74b707743157051d38f76061ba5ff9aab4",
                "externalIds": {
                    "ArXiv": "2209.15003",
                    "DBLP": "journals/corr/abs-2209-15003",
                    "CorpusId": 252596001
                },
                "corpusId": 252596001,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/40047a74b707743157051d38f76061ba5ff9aab4",
                "title": "Compositional Semantic Parsing with Large Language Models",
                "abstract": "Humans can reason compositionally when presented with new tasks. Previous research shows that appropriate prompting techniques enable large language models (LLMs) to solve artificial compositional generalization tasks such as SCAN. In this work, we identify additional challenges in more realistic semantic parsing tasks with larger vocabulary and refine these prompting techniques to address them. Our best method is based on least-to-most prompting: it decomposes the problem using prompting-based syntactic parsing, then uses this decomposition to select appropriate exemplars and to sequentially generate the semantic parse. This method allows us to set a new state of the art for CFQ while requiring only 1% of the training data used by traditional approaches. Due to the general nature of our approach, we expect similar efforts will lead to new results in other tasks and domains, especially for knowledge-intensive applications.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "32573794",
                        "name": "Andrew Drozdov"
                    },
                    {
                        "authorId": "1821614764",
                        "name": "Nathanael Scharli"
                    },
                    {
                        "authorId": "2186405627",
                        "name": "Ekin Akyuurek"
                    },
                    {
                        "authorId": "1471909492",
                        "name": "Nathan Scales"
                    },
                    {
                        "authorId": "2831106",
                        "name": "Xinying Song"
                    },
                    {
                        "authorId": "1425082935",
                        "name": "Xinyun Chen"
                    },
                    {
                        "authorId": "1698617",
                        "name": "O. Bousquet"
                    },
                    {
                        "authorId": "65855107",
                        "name": "Denny Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Shaw et al. (2021) already reported that T5-Base model struggles in most splitting strategies, particularly when using length-based split and TMCD split; we reproduce those results in Table 1 in rows T5-Base and T5-3B.",
                "Shaw et al. (2021)\npropose Spider-SSP, a dataset that can be used to measure the compositional generalization of SQL generation methods.",
                ", 2019), Spider-SSP (Shaw et al., 2021), and CoSQL (Yu et al.",
                "Thus, in order to properly evaluate and compare methods\u2019 performance, multiple benchmark datasets have been proposed, namely Spider (Raffel et al., 2019), Spider-SSP (Shaw et al., 2021), and CoSQL (Yu et al., 2019).",
                "We evaluate T5QL on three benchmark datasets: Spider (Raffel et al., 2019), Spider-SSP (Shaw et al., 2021), and CoSQL (Yu et al., 2019).",
                "To the best of our knowledge, Shaw et al. (2021) were the first to propose a method that uses an LLM, namely T5, and evaluate it on Spider.",
                "Thus, we evaluate two different models: T5-Base, which is similar to the model evaluated by Shaw et al. (2021), and T5QL-Base wo/ CD which is T5QL without the constrained decoding component (and without the ranker)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "result",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "885676b8a05437868f7b83c134a99f991190a1de",
                "externalIds": {
                    "ACL": "2022.gem-1.23",
                    "ArXiv": "2209.10254",
                    "DBLP": "journals/corr/abs-2209-10254",
                    "DOI": "10.48550/arXiv.2209.10254",
                    "CorpusId": 252408708
                },
                "corpusId": 252408708,
                "publicationVenue": {
                    "id": "b1dc244e-c5b3-447d-b200-a46d55e8d8ee",
                    "name": "IEEE Games Entertainment Media Conference",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Game Entertain Media Conf",
                        "GEM",
                        "Int Conf Genet Evol Method",
                        "International Conference on Genetic and Evolutionary Methods"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/885676b8a05437868f7b83c134a99f991190a1de",
                "title": "T5QL: Taming language models for SQL generation",
                "abstract": "Automatic SQL generation has been an active research area, aiming at streamlining the access to databases by writing natural language with the given intent instead of writing SQL. Current SOTA methods for semantic parsing depend on LLMs to achieve high predictive accuracy on benchmark datasets. This reduces their applicability, since LLMs requires expensive GPUs. Furthermore, SOTA methods are ungrounded and thus not guaranteed to always generate valid SQL. Here we propose T5QL, a new SQL generation method that improves the performance in benchmark datasets when using smaller LMs, namely T5-Base, by 13pp when compared against SOTA methods. Additionally, T5QL is guaranteed to always output valid SQL using a context-free grammar to constrain SQL generation. Finally, we show that dividing semantic parsing in two tasks, candidate SQLs generation and candidate re-ranking, is a promising research avenue that can reduce the need for large LMs.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "88727011",
                        "name": "Samuel Arcadinho"
                    },
                    {
                        "authorId": "2818844",
                        "name": "David Oliveira Apar\u00edcio"
                    },
                    {
                        "authorId": "2119536688",
                        "name": "Hugo Veiga"
                    },
                    {
                        "authorId": "2077034872",
                        "name": "Ant\u00f3nio Alegria"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "83d879a830ac4286945e628e670c30fefb1493c6",
                "externalIds": {
                    "ArXiv": "2209.08834",
                    "DBLP": "journals/corr/abs-2209-08834",
                    "DOI": "10.48550/arXiv.2209.08834",
                    "CorpusId": 252367337
                },
                "corpusId": 252367337,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/83d879a830ac4286945e628e670c30fefb1493c6",
                "title": "NL2INTERFACE: Interactive Visualization Interface Generation from Natural Language Queries",
                "abstract": "We develop NL2INTERFACE to explore the potential of generating usable interactive multi-visualization interfaces from natural language queries. With NL2INTERFACE, users can directly write natural language queries to automatically generate a fully interactive multi-visualization interface without any extra effort of learning a tool or programming language. Further, users can interact with the interfaces to easily transform the data and quickly see the results in the visualizations.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108952064",
                        "name": "Yiru Chen"
                    },
                    {
                        "authorId": "2185500259",
                        "name": "Ryan Li"
                    },
                    {
                        "authorId": "2185412348",
                        "name": "Austin Mac"
                    },
                    {
                        "authorId": "2057038673",
                        "name": "Tianbao Xie"
                    },
                    {
                        "authorId": "48881008",
                        "name": "Tao Yu"
                    },
                    {
                        "authorId": "2149474618",
                        "name": "Eugene Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following previous implementation5, \u03b1 in DBCA is set as 0.1 and 0.5 for DBCAa and DBCAc, respectively.",
                "Different datasets have therefore been introduced to support the compositional generalization research on Language-driven Navigation [28], [29], Question Answering [6], [30], [31], Emergent Languages [32] and text2SQL [33].",
                "I, existing work [5], [6] has proposed their method based on distribution-based compositional assessment (DBCA) to create compositional splits for KBQA",
                "Next, DBCAa is derived from the frequency of cluster indexes after traversing the expression tree.",
                "The detailed algorithm could be found in original work [5].",
                "The compositional data sets all have high DBCAc but low DBCAa, which indicates the datasets indeed follow our expected objective of maximizing the compound divergence with great control of small constituent divergence.",
                "C L\n] 3\nS ep\n2 02\n2\non the one hand, we adopt a data splitting method, which is built upon DBCA [5] and holds the objective of maximizing the compositional gap with control of constituent difference between training and test.",
                "Therefore, it is reasonable for us to split MWPs data and obtain the compositional data sets with DBCAc performing as the measurement criteria.\nb) Effect of Different Composition Types: SD dataset that we introduced in Sec.",
                "We choose k value from range {5, 10, 20} based on the highest DBCAc it could achieve after splitting.",
                "built upon DBCA [5] and holds the objective of maximizing the compositional gap with control of constituent difference between training and test.",
                "Like many other tasks such as Question Answering [5], [6], MWP solving methods are expected to exhibit Compositional Generalization, an important capability to handle novel compositions of known components after learning the \u201crules of composition\u201d from the training data.",
                "In more detail, they obtain atom and compound distributions based on their frequencies, and then compute Atom Divergence DBCAa and Compound Divergence DBCAc, respectively.",
                "I, existing work [5], [6] has proposed their method based on distribution-based compositional assessment (DBCA) to create compositional splits for KBQA task, which could be summarized as follows:\n\u2022 Each data is represented using a graph, where the nodes are considered as Atoms and the rule applications on the graph are treated as Compounds.",
                "As we can see, the performance of MathEN on both Math23K and MAWPS datasets decreases dramatically with the increase of compound divergence DBCAc.",
                "To obtain DBCAc, we exhaustively search sub-expression trees in a complete expression tree.",
                "\u2022 A distribution-based compositional assessment [6] is utilized to measure the divergence: DBCA(Dp,Dq) = 1\u2212C\u03b1(P\u2016Q), where C\u03b1(P\u2016Q) = \u2211 i p \u03b1 i q 1\u2212\u03b1 i \u2208 [0, 1] is\nthe Chernoff coefficient [34], P and Q are distributions deriving from training and test sets, respectively.",
                "\u2022 Starting from a data pool D, they apply a greedy algorithm to assign each data to form Dp and Dq , the objective of which is to maximize DBCAc with the control of an upper bound of DBCAa."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "60f208b19bb63d82fda5759897677f92d4e1e2fc",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-01352",
                    "ArXiv": "2209.01352",
                    "DOI": "10.48550/arXiv.2209.01352",
                    "CorpusId": 252089970
                },
                "corpusId": 252089970,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/60f208b19bb63d82fda5759897677f92d4e1e2fc",
                "title": "Improving Compositional Generalization in Math Word Problem Solving",
                "abstract": "Compositional generalization refers to a model's capability to generalize to newly composed input data based on the data components observed during training. It has triggered a series of compositional generalization analysis on different tasks as generalization is an important aspect of language and problem solving skills. However, the similar discussion on math word problems (MWPs) is limited. In this manuscript, we study compositional generalization in MWP solving. Specifically, we first introduce a data splitting method to create compositional splits from existing MWP datasets. Meanwhile, we synthesize data to isolate the effect of compositions. To improve the compositional generalization in MWP solving, we propose an iterative data augmentation method that includes diverse compositional variation into training data and could collaborate with MWP methods. During the evaluation, we examine a set of methods and find all of them encounter severe performance loss on the evaluated datasets. We also find our data augmentation method could significantly improve the compositional generalization of general MWP methods. Code is available at https://github.com/demoleiwang/CGMWP.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3458560",
                        "name": "Yunshi Lan"
                    },
                    {
                        "authorId": "2152514225",
                        "name": "Lei Wang"
                    },
                    {
                        "authorId": "92992254",
                        "name": "Jingwu Jiang"
                    },
                    {
                        "authorId": "1709901",
                        "name": "Ee-Peng Lim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There are also several works [46, 66, 67] which neglect the SQL grammar during the decoding process, by leveraging the powerful large scale pre-trained language model like T5 [68] finetuned on the text-to-SQL training set for SQL query generation."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "1aac692ca061feb846cf32cd61a1d422f89593a1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-13629",
                    "ArXiv": "2208.13629",
                    "DOI": "10.48550/arXiv.2208.13629",
                    "CorpusId": 251903737
                },
                "corpusId": 251903737,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1aac692ca061feb846cf32cd61a1d422f89593a1",
                "title": "A Survey on Text-to-SQL Parsing: Concepts, Methods, and Future Directions",
                "abstract": "Text-to-SQL parsing is an essential and challenging task. The goal of text-to-SQL parsing is to convert a natural language (NL) question to its corresponding structured query language (SQL) based on the evidences provided by relational databases. Early text-to-SQL parsing systems from the database community achieved a noticeable progress with the cost of heavy human engineering and user interactions with the systems. In recent years, deep neural networks have significantly advanced this task by neural generation models, which automatically learn a mapping function from an input NL question to an output SQL query. Subsequently, the large pre-trained language models have taken the state-of-the-art of the text-to-SQL parsing task to a new level. In this survey, we present a comprehensive review on deep learning approaches for text-to-SQL parsing. First, we introduce the text-to-SQL parsing corpora which can be categorized as single-turn and multi-turn. Second, we provide a systematical overview of pre-trained language models and existing methods for text-to-SQL parsing. Third, we present readers with the challenges faced by text-to-SQL parsing and explore some potential future directions in this field.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "50379530",
                        "name": "Bowen Qin"
                    },
                    {
                        "authorId": "151471590",
                        "name": "Binyuan Hui"
                    },
                    {
                        "authorId": "2118872648",
                        "name": "Lihan Wang"
                    },
                    {
                        "authorId": "2144399900",
                        "name": "Min Yang"
                    },
                    {
                        "authorId": "2154860526",
                        "name": "Jinyang Li"
                    },
                    {
                        "authorId": "66200440",
                        "name": "Binhua Li"
                    },
                    {
                        "authorId": "9706609",
                        "name": "Ruiying Geng"
                    },
                    {
                        "authorId": "5973047",
                        "name": "Rongyu Cao"
                    },
                    {
                        "authorId": "2152147863",
                        "name": "Jian Sun"
                    },
                    {
                        "authorId": "2161888510",
                        "name": "Luo Si"
                    },
                    {
                        "authorId": "2087380523",
                        "name": "Fei Huang"
                    },
                    {
                        "authorId": "1527090216",
                        "name": "Yongbin Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Architectures and training methods that target this specific problem are often developed based on synthetic tasks whose creation rules are known (Das et al., 1992; Li et al., 2019b; Russin et al., 2019; Andreas, 2020; Liu et al., 2020a; Chen et al., 2020; Herzig and Berant, 2021; Shaw et al., 2021; Zhu et al., 2021).",
                "\u2026methods that target this specific problem are often developed based on synthetic tasks whose creation rules are known (Das et al., 1992; Li et al., 2019b; Russin et al., 2019; Andreas, 2020; Liu et al., 2020a; Chen et al., 2020; Herzig and Berant, 2021; Shaw et al., 2021; Zhu et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "108c25905be36b2a7a0fc7256ac314985ecd9699",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-11445",
                    "ArXiv": "2208.11445",
                    "ACL": "2022.mathnlp-1.3",
                    "DOI": "10.48550/arXiv.2208.11445",
                    "CorpusId": 251765206
                },
                "corpusId": 251765206,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/108c25905be36b2a7a0fc7256ac314985ecd9699",
                "title": "Induced Natural Language Rationales and Interleaved Markup Tokens Enable Extrapolation in Large Language Models",
                "abstract": "The ability to extrapolate, i.e., to make predictions on sequences that are longer than those presented as training examples, is a challenging problem for current deep learning models. Recent work shows that this limitation persists in state-of-the-art Transformer-based models. Most solutions to this problem use specific architectures or training methods that do not generalize to other tasks. We demonstrate that large language models can succeed in extrapolation without modifying their architecture or training procedure. Our experimental results show that generating step-by-step rationales and introducing marker tokens are both required for effective extrapolation. First, we induce a language model to produce step-by-step rationales before outputting the answer to effectively communicate the task to the model. However, as sequences become longer, we find that current models struggle to keep track of token positions. To address this issue, we interleave output tokens with markup tokens that act as explicit positional and counting symbols. Our findings show how these two complementary approaches enable remarkable sequence extrapolation and highlight a limitation of current architectures to effectively generalize without explicit surface form guidance. Code available at https://anonymous.4open.science/r/induced-rationales-markup-tokens-0650/README.md",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51107945",
                        "name": "M. Bueno"
                    },
                    {
                        "authorId": "2182518941",
                        "name": "Carlos Gemmel"
                    },
                    {
                        "authorId": "49694325",
                        "name": "Jeffrey Stephen Dalton"
                    },
                    {
                        "authorId": "1809633",
                        "name": "R. Lotufo"
                    },
                    {
                        "authorId": "143744603",
                        "name": "Rodrigo Nogueira"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Other splitting methods also exist to help different research topics (Shaw et al., 2021; Chang et al., 2020).",
                "Shaw et al. (2021) use a hybrid model which firstly uses a high precision grammar-based approach (NQG) to generate SQL queries, then uses T5 (Raffel et al., 2019) as a back-up if NQG fails."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a814b76e589ef27e3f4af379d319d02d2110faa1",
                "externalIds": {
                    "ACL": "2022.coling-1.190",
                    "DBLP": "conf/coling/Deng0022",
                    "ArXiv": "2208.10099",
                    "DOI": "10.48550/arXiv.2208.10099",
                    "CorpusId": 251719280
                },
                "corpusId": 251719280,
                "publicationVenue": {
                    "id": "f51ff783-cdff-4e22-94fb-28e6336d17b3",
                    "name": "International Conference on Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Comput Linguistics",
                        "COLING"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/coling/"
                },
                "url": "https://www.semanticscholar.org/paper/a814b76e589ef27e3f4af379d319d02d2110faa1",
                "title": "Recent Advances in Text-to-SQL: A Survey of What We Have and What We Expect",
                "abstract": "Text-to-SQL has attracted attention from both the natural language processing and database communities because of its ability to convert the semantics in natural language into SQL queries and its practical application in building natural language interfaces to database systems. The major challenges in text-to-SQL lie in encoding the meaning of natural utterances, decoding to SQL queries, and translating the semantics between these two forms. These challenges have been addressed to different extents by the recent advances. However, there is still a lack of comprehensive surveys for this task. To this end, we review recent progress on text-to-SQL for datasets, methods, and evaluation and provide this systematic survey, addressing the aforementioned challenges and discussing potential future directions. We hope this survey can serve as quick access to existing work and motivate future research.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2142468208",
                        "name": "Naihao Deng"
                    },
                    {
                        "authorId": "2109404730",
                        "name": "Yulong Chen"
                    },
                    {
                        "authorId": "39939186",
                        "name": "Yue Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We report results on the standard data split as well as three compositional splits based on those introduced in Shaw et al. (2021): (1) the template split, where abstract output templates in training and test data are disjoint (Finegan-Dollak et al., 2018); (2) the TMCD split, which makes the\u2026",
                "Despite their strong performance on many tasks, pre-trained language models1 (LMs) such as T5 (Raffel et al., 2020) have been shown to struggle on compositional generalization (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021).",
                "\u2026flat or negative scaling curves when fine-tuning LMs except on the CFQ dataset, suggesting scaling with full finetuning is unlikely to be an effective solution for compositional generalization in semantic parsing as observed in Shaw et al. (2021), Herzig et al. (2021), and Furrer et al. (2020).",
                ", 2021), ensemble models (Shaw et al., 2021), different Transformer variations (Csord\u00e1s et al.",
                "Full fine-tuning of model parameters is a standard approach for applying LMs to end tasks, and T5 performance with fine-tuning has been measured for compositional generalization up to the scale of 11 billion parameters (Shaw et al., 2021; Furrer et al., 2020).",
                ", 2020) have been shown to struggle on compositional generalization (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021).",
                "We define compounds as combinations of parent and child symbols in the output, similarly to Shaw et al. (2021).",
                "\u20262020; Chen et al., 2020; Zheng and Lapata, 2021; Oren et al., 2020; Herzig and Berant, 2021; Ruiz et al., 2021; Wang et al., 2021), ensemble models (Shaw et al., 2021), different Transformer variations (Csord\u00e1s et al., 2021; Ontan\u00f3n et al., 2021), intermediate representations (Herzig et al., 2021;\u2026"
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6e10343767ab09dde83cf99ea3442907402a9810",
                "externalIds": {
                    "DBLP": "conf/emnlp/QiuSPSHPST22",
                    "ArXiv": "2205.12253",
                    "ACL": "2022.emnlp-main.624",
                    "DOI": "10.48550/arXiv.2205.12253",
                    "CorpusId": 249017865
                },
                "corpusId": 249017865,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/6e10343767ab09dde83cf99ea3442907402a9810",
                "title": "Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing",
                "abstract": "Despite their strong performance on many tasks, pre-trained language models have been shown to struggle on out-of-distribution compositional generalization. Meanwhile, recent work has shown considerable improvements on many NLP tasks from model scaling. Can scaling up model size also improve compositional generalization in semantic parsing? We evaluate encoder-decoder models up to 11B parameters and decoder-only models up to 540B parameters, and compare model scaling curves for three different methods for applying a pre-trained language model to a new task: fine-tuning all parameters, prompt tuning, and in-context learning. We observe that fine-tuning generally has flat or negative scaling curves on out-of-distribution compositional generalization in semantic parsing evaluations. In-context learning has positive scaling curves, but is generally outperformed by much smaller fine-tuned models. Prompt-tuning can outperform fine-tuning, suggesting further potential improvements from scaling as it exhibits a more positive scaling curve. Additionally, we identify several error trends that vary with model scale. For example, larger models are generally better at modeling the syntax of the output space, but are also more prone to certain types of overfitting. Overall, our study highlights limitations of current techniques for effectively leveraging model scale for compositional generalization, while our analysis also suggests promising directions for future work.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1742081895",
                        "name": "Linlu Qiu"
                    },
                    {
                        "authorId": "38759328",
                        "name": "Peter Shaw"
                    },
                    {
                        "authorId": "2616463",
                        "name": "Panupong Pasupat"
                    },
                    {
                        "authorId": "2068916949",
                        "name": "Tianze Shi"
                    },
                    {
                        "authorId": "47426264",
                        "name": "Jonathan Herzig"
                    },
                    {
                        "authorId": "2585932",
                        "name": "Emily Pitler"
                    },
                    {
                        "authorId": "145757665",
                        "name": "Fei Sha"
                    },
                    {
                        "authorId": "3259253",
                        "name": "Kristina Toutanova"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In the prompt constructed to solve SCAN, we actually used both natural language and Python notation.",
                "The full prompt contexts for SCAN are shown in Appendix B.1.",
                "The 14 command-mapping demonstration examples are supposed to be able to fully cover the semantics of SCAN commands.",
                "One contains 8 command-reduction examples to demonstrate how to reduce a long command to a list of short commands (see some of them in Table 6), and the other contains 14 command-mapping examples to demonstrate how\n4See the \u201clength train-test split\u201d section in https://github.com/brendenlake/SCAN.",
                "In this section we present the prompt contexts used for the SCAN benchmark in Section 3.2.",
                "The two benchmarks considered in this paper, SCAN (Lake & Baroni, 2018) and DROP (Dua et al., 2019), have often been tackled by neural-symbolic methods (Andor et al., 2019; Chen et al., 2019, 2020; Nye et al., 2020; Shaw et al., 2021; Kim, 2021).",
                "SCAN (Lake & Baroni, 2018) is probably the most popular benchmark for evaluating compositional generalization.",
                ", 2019), have often been tackled by neural-symbolic methods (Andor et al., 2019; Chen et al., 2019, 2020; Nye et al., 2020; Shaw et al., 2021; Kim, 2021).",
                "We show here that SCAN can essentially be solved using least-to-most prompting with 14 examples, compared to those neural-symbolic methods where the full training set is used.",
                "Many specialized neural-symbolic models have been proposed to solve SCAN (Chen et al., 2020; Nye et al., 2020; Shaw et al., 2021; Kim, 2021)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5437e8adab596d7294124c0e798708e050e25321",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-10625",
                    "ArXiv": "2205.10625",
                    "DOI": "10.48550/arXiv.2205.10625",
                    "CorpusId": 248986239
                },
                "corpusId": 248986239,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/5437e8adab596d7294124c0e798708e050e25321",
                "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models",
                "abstract": "Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99% using just 14 exemplars, compared to only 16% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "65855107",
                        "name": "Denny Zhou"
                    },
                    {
                        "authorId": "1821614764",
                        "name": "Nathanael Scharli"
                    },
                    {
                        "authorId": "2153400663",
                        "name": "Le Hou"
                    },
                    {
                        "authorId": "119640649",
                        "name": "Jason Wei"
                    },
                    {
                        "authorId": "1471909492",
                        "name": "Nathan Scales"
                    },
                    {
                        "authorId": "1524732527",
                        "name": "Xuezhi Wang"
                    },
                    {
                        "authorId": "50319359",
                        "name": "D. Schuurmans"
                    },
                    {
                        "authorId": "1698617",
                        "name": "O. Bousquet"
                    },
                    {
                        "authorId": "1998340269",
                        "name": "Quoc Le"
                    },
                    {
                        "authorId": "143829044",
                        "name": "E. Chi"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2020) and natural benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2020), researchers have been studying systematic generalization of existing semantic parsing methods as well as proposing new approaches such as",
                "Using synthetic (Bahdanau et al., 2019; Kim and Linzen, 2020a; Keysers et al., 2020) and natural benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2020), researchers have been studying systematic generalization of existing semantic parsing methods as well as proposing new approaches such as\u2026"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "a122909a31acf41cb2d9eb602c01b24b9b85a061",
                "externalIds": {
                    "ACL": "2022.acl-long.233",
                    "ArXiv": "2205.09607",
                    "DBLP": "conf/acl/JamborB22",
                    "DOI": "10.48550/arXiv.2205.09607",
                    "CorpusId": 248780474
                },
                "corpusId": 248780474,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/a122909a31acf41cb2d9eb602c01b24b9b85a061",
                "title": "LAGr: Label Aligned Graphs for Better Systematic Generalization in Semantic Parsing",
                "abstract": "Semantic parsing is the task of producing structured meaning representations for natural language sentences. Recent research has pointed out that the commonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to generalize systematically, i.e. to handle examples that require recombining known knowledge in novel settings. In this work, we show that better systematic generalization can be achieved by producing the meaning representation directly as a graph and not as a sequence. To this end we propose LAGr (Label Aligned Graphs), a general framework to produce semantic parses by independently predicting node and edge labels for a complete multi-layer input-aligned graph. The strongly-supervised LAGr algorithm requires aligned graphs as inputs, whereas weakly-supervised LAGr infers alignments for originally unaligned target graphs using approximate maximum-a-posteriori inference. Experiments demonstrate that LAGr achieves significant improvements in systematic generalization upon the baseline seq2seq parsers in both strongly- and weakly-supervised settings.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "123658753",
                        "name": "Dora Jambor"
                    },
                    {
                        "authorId": "3335364",
                        "name": "Dzmitry Bahdanau"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We align most of the hyperparameter settings with Shaw et al. (2021) to provide a fair comparison.",
                "We mostly follow Shaw et al. (2021) and Scholak et al. (2021) to serialize the inputs.",
                "Recent attempts by Shaw et al. (2021) show that directly fine-tuning a T5 model (Raffel et al., 2020) on this task without presenting any relational structures could achieve satisfying results.",
                "Recently, Shaw et al. (2021) showed that finetuning a pre-trained T5-3B model could yield results competitive to the then-state-of-the-art.",
                ", 2022), T5 (Shaw et al., 2021) and PICARD (Scholak et al."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "14793aa93920cb8f748776cc45c3895de6df5fbf",
                "externalIds": {
                    "ACL": "2022.emnlp-main.211",
                    "ArXiv": "2205.06983",
                    "DBLP": "journals/corr/abs-2205-06983",
                    "DOI": "10.48550/arXiv.2205.06983",
                    "CorpusId": 248810824
                },
                "corpusId": 248810824,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/14793aa93920cb8f748776cc45c3895de6df5fbf",
                "title": "RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL",
                "abstract": "Relational structures such as schema linking and schema encoding have been validated as a key component to qualitatively translating natural language into SQL queries. However, introducing these structural relations comes with prices: they often result in a specialized model structure, which largely prohibits using large pretrained models in text-to-SQL. To address this problem, we propose RASAT: a Transformer seq2seq architecture augmented with relation-aware self-attention that could leverage a variety of relational structures while inheriting the pretrained parameters from the T5 model effectively. Our model can incorporate almost all types of existing relations in the literature, and in addition, we propose introducing co-reference relations for the multi-turn scenario. Experimental results on three widely used text-to-SQL datasets, covering both single-turn and multi-turn scenarios, have shown that RASAT could achieve competitive results in all three benchmarks, achieving state-of-the-art execution accuracy (75.5% EX on Spider, 52.6% IEX on SParC, and 37.4% IEX on CoSQL).",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2165381168",
                        "name": "Jiexing Qi"
                    },
                    {
                        "authorId": "1962427042",
                        "name": "Jingyao Tang"
                    },
                    {
                        "authorId": "2165399443",
                        "name": "Ziwei He"
                    },
                    {
                        "authorId": "73446139",
                        "name": "Xiangpeng Wan"
                    },
                    {
                        "authorId": "47110820",
                        "name": "Chenghu Zhou"
                    },
                    {
                        "authorId": "2107937507",
                        "name": "Xinbing Wang"
                    },
                    {
                        "authorId": "22063226",
                        "name": "Quanshi Zhang"
                    },
                    {
                        "authorId": "3146592",
                        "name": "Zhouhan Lin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "bc16284f517dd0011dcf64ea1c8fe6d6576494a4",
                "externalIds": {
                    "ArXiv": "2205.06149",
                    "DBLP": "journals/corr/abs-2205-06149",
                    "DOI": "10.48550/arXiv.2205.06149",
                    "CorpusId": 248721910
                },
                "corpusId": 248721910,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/bc16284f517dd0011dcf64ea1c8fe6d6576494a4",
                "title": "Is the Computation of Abstract Sameness Relations Human-Like in Neural Language Models?",
                "abstract": "In recent years, deep neural language models have made strong progress in various NLP tasks. This work explores one facet of the question whether state-of-the-art NLP models exhibit elementary mechanisms known from human cognition. The exploration is focused on a relatively primitive mechanism for which there is a lot of evidence from various psycholinguistic experiments with infants. The computation of\"abstract sameness relations\"is assumed to play an important role in human language acquisition and processing, especially in learning more complex grammar rules. In order to investigate this mechanism in BERT and other pre-trained language models (PLMs), the experiment designs from studies with infants were taken as the starting point. On this basis, we designed experimental settings in which each element from the original studies was mapped to a component of language models. Even though the task in our experiments was relatively simple, the results suggest that the cognitive faculty of computing abstract sameness relations is stronger in infants than in all investigated PLMs.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2164989100",
                        "name": "Lukas Thoma"
                    },
                    {
                        "authorId": "143862204",
                        "name": "Benjamin Roth"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Experiments with111 RATSQL+GAP (Shi et al., 2021) show that our112 Spider-CG is more challenging than the existing113 TMCD split (Shaw et al., 2021).114 To improve the generalization performance of115\ntext-to-SQL models, we modify several previous 116 state-of-the-art models so that they can be\u2026",
                "Ensuring a 049 reasonable data split may also lead to a reduction in 050 dataset size: e.g., the training set drops from 7000 051 to 3282 in the Spider TCMD split (Yu et al., 2018b; 052 Shaw et al., 2021).",
                "On the other hand, Shaw et al. (2021) in- 559 troduces TMCD splits for studying compositional 560 generalization in semantic parsing, where they aim 561 to maximize the divergence of SQL compounds 562 between the training and test sets."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a40693eefd351659cdeb3885917b1506ea01c38a",
                "externalIds": {
                    "ArXiv": "2205.02054",
                    "DBLP": "conf/naacl/GanCHP22",
                    "DOI": "10.48550/arXiv.2205.02054",
                    "CorpusId": 248512587
                },
                "corpusId": 248512587,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a40693eefd351659cdeb3885917b1506ea01c38a",
                "title": "Measuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment",
                "abstract": "In text-to-SQL tasks -- as in much of NLP -- compositional generalization is a major challenge: neural networks struggle with compositional generalization where training and test distributions differ. However, most recent attempts to improve this are based on word-level synthetic data or specific dataset splits to generate compositional biases. In this work, we propose a clause-level compositional example generation method. We first split the sentences in the Spider text-to-SQL dataset into sub-sentences, annotating each sub-sentence with its corresponding SQL clause, resulting in a new dataset Spider-SS. We then construct a further dataset, Spider-CG, by composing Spider-SS sub-sentences in different combinations, to test the ability of models to generalize compositionally. Experiments show that existing models suffer significant performance degradation when evaluated on Spider-CG, even though every sub-sentence is seen during training. To deal with this problem, we modify a number of state-of-the-art models to train on the segmented data of Spider-SS, and we show that this method improves the generalization performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "120624606",
                        "name": "Yujian Gan"
                    },
                    {
                        "authorId": "1425082935",
                        "name": "Xinyun Chen"
                    },
                    {
                        "authorId": "47809462",
                        "name": "Qiuping Huang"
                    },
                    {
                        "authorId": "1701461",
                        "name": "Matthew Purver"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For non-KG semantic parsing, PLMs have been evaluated recently with a focus on compositional generalisation [30]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "b42501d9f418bf11d1886e617ab125b37fd2d87c",
                "externalIds": {
                    "ArXiv": "2204.12793",
                    "DBLP": "conf/sigir/BanerjeeNKUB22",
                    "DOI": "10.1145/3477495.3531841",
                    "CorpusId": 248405891
                },
                "corpusId": 248405891,
                "publicationVenue": {
                    "id": "8dce23a9-44e0-4381-a39e-2acc1edff700",
                    "name": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
                    "type": "conference",
                    "alternate_names": [
                        "International ACM SIGIR Conference on Research and Development in Information Retrieval",
                        "Int ACM SIGIR Conf Res Dev Inf Retr",
                        "SIGIR",
                        "Annu Int ACM SIGIR Conf Res Dev Inf Retr"
                    ],
                    "url": "http://www.acm.org/sigir/"
                },
                "url": "https://www.semanticscholar.org/paper/b42501d9f418bf11d1886e617ab125b37fd2d87c",
                "title": "Modern Baselines for SPARQL Semantic Parsing",
                "abstract": "In this work, we focus on the task of generating SPARQL queries from natural language questions, which can then be executed on Knowledge Graphs (KGs). We assume that gold entity and relations have been provided, and the remaining task is to arrange them in the right order along with SPARQL vocabulary, and input tokens to produce the correct SPARQL query. Pre-trained Language Models (PLMs) have not been explored in depth on this task so far, so we experiment with BART, T5 and PGNs (Pointer Generator Networks) with BERT embeddings, looking for new baselines in the PLM era for this task, on DBpedia and Wikidata KGs. We show that T5 requires special input tokenisation, but produces state of the art performance on LC-QuAD 1.0 and LC-QuAD 2.0 datasets, and outperforms task-specific models from previous works. Moreover, the methods enable semantic parsing for questions where a part of the input needs to be copied to the output query, thus enabling a new paradigm in KG semantic parsing.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "35635012",
                        "name": "Debayan Banerjee"
                    },
                    {
                        "authorId": "83623712",
                        "name": "Pranav Ajit Nair"
                    },
                    {
                        "authorId": "2084554148",
                        "name": "Jivat Neet Kaur"
                    },
                    {
                        "authorId": "2370666",
                        "name": "Ricardo Usbeck"
                    },
                    {
                        "authorId": "66911936",
                        "name": "Chris Biemann"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Subsequent work has yielded a number of studies that attempt to identify properties of datasets (Keysers et al., 2020; Shaw et al., 2021) and instances (Bogin et al., 2022; Tamari et al., 2021) that make generalization hard and use these properties to construct hard generalization splits.",
                "Subsequent work has yielded a number of studies that attempt to identify properties of datasets (Keysers et al., 2020; Shaw et al., 2021)"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "cb16b85891172572cd856142880b503db0c2bc61",
                "externalIds": {
                    "ACL": "2022.emnlp-main.27",
                    "DBLP": "conf/emnlp/Finlayson0SC22",
                    "ArXiv": "2204.09148",
                    "DOI": "10.48550/arXiv.2204.09148",
                    "CorpusId": 248266490
                },
                "corpusId": 248266490,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/cb16b85891172572cd856142880b503db0c2bc61",
                "title": "What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment",
                "abstract": "The instruction learning paradigm\u2014where a model learns to perform new tasks from task descriptions alone\u2014has become popular in research on general-purpose models. The capabilities of large transformer models as instruction learners, however, remain poorly understood. We use a controlled synthetic environment to characterize such capabilities. Specifically, we use the task of deciding whether a given string matches a regular expression (viewed as an instruction) to identify properties of tasks, instructions, and instances that make instruction learning challenging. For instance, we find that our model, a fine-tuned T5-based text2text transformer, struggles with large regular languages, suggesting that less precise instructions are challenging for models. Instruction executions that require tracking longer contexts of prior steps are also difficult. We use our findings to systematically construct a challenging instruction learning dataset, which we call Hard RegSet. Fine-tuning on Hard RegSet, our large transformer learns to correctly interpret (with at least 90% accuracy) only 65.6% of test instructions, and 11%-24% of the instructions in out-of-distribution generalization settings. We thus propose Hard RegSet as a challenging instruction learning dataset, and a controlled environment for studying instruction learning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1580418311",
                        "name": "Matthew Finlayson"
                    },
                    {
                        "authorId": "46666605",
                        "name": "Kyle Richardson"
                    },
                    {
                        "authorId": "48229640",
                        "name": "Ashish Sabharwal"
                    },
                    {
                        "authorId": "48323507",
                        "name": "Peter Clark"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For instance, it has been applied to the text-to-SQL generation problem [15, 43], where the output is a code to be executed."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "4bb51778a5dee0a7a2ebd5fbfa8bec01dcd0c280",
                "externalIds": {
                    "ArXiv": "2204.04221",
                    "DBLP": "journals/corr/abs-2204-04221",
                    "DOI": "10.48550/arXiv.2204.04221",
                    "CorpusId": 248085416
                },
                "corpusId": 248085416,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4bb51778a5dee0a7a2ebd5fbfa8bec01dcd0c280",
                "title": "CookieEnforcer: Automated Cookie Notice Analysis and Enforcement",
                "abstract": "Online websites use cookie notices to elicit consent from the users, as required by recent privacy regulations like the GDPR and the CCPA. Prior work has shown that these notices use dark patterns to manipulate users into making website-friendly choices which put users\u2019 privacy at risk. In this work, we develop CookieEnforcer , a new system for automatically discovering cookie notices and deciding on the options that result in disabling all non-essential cookies. In order to achieve this, we \ufb01rst build an automatic cookie notice detector that utilizes the rendering pattern of the HTML elements to identify the cookie notices. Next, CookieEnforcer analyzes the cookie notices and predicts the set of actions required to disable all unnecessary cookies. This is done by modeling the problem as a sequence-to-sequence task, where the input is a machine-readable cookie notice and the output is the set of clicks to make. We demonstrate the ef\ufb01cacy of CookieEnforcer via an end-to-end accuracy evaluation, showing that it can generate the required steps in 91% of the cases. Via a user study, we show that CookieEnforcer can signi\ufb01cantly reduce the user effort. Finally, we use our system to perform several measurements on the top 5k websites from the Tranco list (as accessed from the US and the UK), drawing comparisons and observations at scale.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2065836355",
                        "name": "Rishabh Khandelwal"
                    },
                    {
                        "authorId": "2008169056",
                        "name": "Asmit Nayak"
                    },
                    {
                        "authorId": "2720602",
                        "name": "Hamza Harkous"
                    },
                    {
                        "authorId": "1910642",
                        "name": "Kassem Fawaz"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026based on a fine-grained schema of generalization patterns like this work (Bahdanau et al., 2019; Keysers et al., 2020; Kim & Linzen, 2020), or by repartitioning existing datasets with i.i.d. samples into splits with disjoint compositional structures (Finegan-Dollak et al., 2018; Shaw et al., 2021).",
                "samples into splits with disjoint compositional structures (Finegan-Dollak et al., 2018; Shaw et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "6a250b904965732840a75b6a13e35ac15f5cce4d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-03758",
                    "ArXiv": "2204.03758",
                    "DOI": "10.48550/arXiv.2204.03758",
                    "CorpusId": 248069409
                },
                "corpusId": 248069409,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6a250b904965732840a75b6a13e35ac15f5cce4d",
                "title": "Compositional Generalization and Decomposition in Neural Program Synthesis",
                "abstract": "When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, what we can measure is whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we focus on measuring the ability of learned program synthesizers to compositionally generalize. We first characterize several different axes along which program synthesis methods would be desired to generalize, e.g., length generalization, or the ability to combine known subroutines in new ways that do not occur in the training data. Based on this characterization, we introduce a benchmark suite of tasks to assess these abilities based on two popular existing datasets, SCAN and RobustFill. Finally, we make first attempts to improve the compositional generalization ability of Transformer models along these axes through novel attention mechanisms that draw inspiration from a human-like decomposition strategy. Empirically, we find our modified Transformer models generally perform better than natural baselines, but the tasks remain challenging.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2362367",
                        "name": "Kensen Shi"
                    },
                    {
                        "authorId": "2110597723",
                        "name": "Joey Hong"
                    },
                    {
                        "authorId": "1771307",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "38253388",
                        "name": "Pengcheng Yin"
                    },
                    {
                        "authorId": "152549864",
                        "name": "Charles Sutton"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "6913d3f23d13416407b7fcd03bea3231b268a20a",
                "externalIds": {
                    "DBLP": "conf/emnlp/Gupta0G22",
                    "ArXiv": "2203.08445",
                    "DOI": "10.18653/v1/2022.findings-emnlp.365",
                    "CorpusId": 253254777
                },
                "corpusId": 253254777,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/6913d3f23d13416407b7fcd03bea3231b268a20a",
                "title": "Structurally Diverse Sampling for Sample-Efficient Training and Comprehensive Evaluation",
                "abstract": "A growing body of research has demonstrated the inability of NLP models to generalize compositionally and has tried to alleviate it through specialized architectures, training schemes, and data augmentation, among other approaches. In this work, we study a different approach: training on instances with diverse structures. We propose a model-agnostic algorithm for subsampling such sets of instances from a labeled instance pool with structured outputs. Evaluating on both compositional template splits and traditional IID splits of 5 semantic parsing datasets of varying complexity, we show that structurally diverse training using our algorithm leads to comparable or better generalization than prior algorithms in 9 out of 10 dataset-split type pairs. In general, we find structural diversity to consistently improve sample efficiency compared to random train sets. Moreover, we show that structurally diverse sampling yields comprehensive test sets that are a lot more challenging than IID test sets. Finally, we provide two explanations for improved generalization from diverse train sets: 1) improved coverage of output substructures, and 2) a reduction in spurious correlations between these substructures.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1698760333",
                        "name": "Shivanshu Gupta"
                    },
                    {
                        "authorId": "34650964",
                        "name": "Sameer Singh"
                    },
                    {
                        "authorId": "40642935",
                        "name": "Matt Gardner"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Non-invasive Approaches T5-Base (Shaw et al., 2021) 57."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "910c4957c3476899869e4bf580fe9971cab9caf6",
                "externalIds": {
                    "ArXiv": "2203.07781",
                    "DBLP": "journals/corr/abs-2203-07781",
                    "DOI": "10.48550/arXiv.2203.07781",
                    "CorpusId": 247450666
                },
                "corpusId": 247450666,
                "publicationVenue": {
                    "id": "a0c45882-7c78-4f0c-8886-d3481ba02586",
                    "name": "International Journal of Machine Learning and Cybernetics",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Mach Learn Cybern"
                    ],
                    "issn": "1868-8071",
                    "url": "http://www.springer.com/engineering/mathematical/journal/13042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/13042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/910c4957c3476899869e4bf580fe9971cab9caf6",
                "title": "UniSAr: A Unified Structure-Aware Autoregressive Language Model for Text-to-SQL",
                "abstract": "Existing text-to-SQL semantic parsers are typically designed for particular settings such as handling queries that span multiple tables, domains or turns which makes them ineffective when applied to different settings. We present UniSAr (Unified Structure-Aware Autoregressive Language Model), which benefits from directly using an off-the-shelf language model architecture and demonstrates consistently high performance under different settings. Specifically, UniSAr extends existing autoregressive language models to incorporate three non-invasive extensions to make them structure-aware: (1) adding structure mark to encode database schema, conversation context, and their relationships; (2) constrained decoding to decode well structured SQL for a given database schema; and (3) SQL completion to complete potential missing JOIN relationships in SQL based on database schema. On seven well-known text-to-SQL datasets covering multi-domain, multi-table and multi-turn, UniSAr demonstrates highly comparable or better performance to the most advanced specifically-designed text-to-SQL models. Importantly, our UniSAr is non-invasive, such that other core model advances in text-to-SQL can also adopt our extensions to further enhance performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "49093992",
                        "name": "Longxu Dou"
                    },
                    {
                        "authorId": "152673873",
                        "name": "Yan Gao"
                    },
                    {
                        "authorId": "2061165595",
                        "name": "Mingyang Pan"
                    },
                    {
                        "authorId": "2159084043",
                        "name": "Dingzirui Wang"
                    },
                    {
                        "authorId": "153249455",
                        "name": "Jian-Guang Lou"
                    },
                    {
                        "authorId": "2256319",
                        "name": "Wanxiang Che"
                    },
                    {
                        "authorId": "2064372086",
                        "name": "Dechen Zhan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We compare GPT-3 and Codex against methods from Shaw et al. (2021) using the T5 encoder-decoder\n1See Appendix A.2 for a discussion on parameter counts.\nar X\niv :2\n20 4.",
                "A clear trend in this area is to finetune models pretrained on natural language; notably, performance significantly improves as larger pretrained models are used (Shaw et al., 2021; Scholak et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "51000d9f79be0eefd7972fe94e3c71dddc90d2c6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-00498",
                    "ArXiv": "2204.00498",
                    "DOI": "10.48550/arXiv.2204.00498",
                    "CorpusId": 247922681
                },
                "corpusId": 247922681,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/51000d9f79be0eefd7972fe94e3c71dddc90d2c6",
                "title": "Evaluating the Text-to-SQL Capabilities of Large Language Models",
                "abstract": "We perform an empirical evaluation of Text-to-SQL capabilities of the Codex language model. We find that, without any finetuning, Codex is a strong baseline on the Spider benchmark; we also analyze the failure modes of Codex in this setting. Furthermore, we demonstrate on the GeoQuery and Scholar benchmarks that a small number of in-domain examples provided in the prompt enables Codex to perform better than state-of-the-art models finetuned on such few-shot examples.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1420542737",
                        "name": "Nitarshan Rajkumar"
                    },
                    {
                        "authorId": "2116277958",
                        "name": "Raymond Li"
                    },
                    {
                        "authorId": "3335364",
                        "name": "Dzmitry Bahdanau"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "557ebd17b7c7ac4e09bd167d7b8909b8d74d1153",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2202-11937",
                    "ArXiv": "2202.11937",
                    "CorpusId": 247084084
                },
                "corpusId": 247084084,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/557ebd17b7c7ac4e09bd167d7b8909b8d74d1153",
                "title": "Compositional Generalization Requires Compositional Parsers",
                "abstract": "A rapidly growing body of research on compositional generalization investigates the ability of a semantic parser to dynamically recombine linguistic elements seen in training into unseen sequences. We present a systematic comparison of sequence-to-sequence models and models guided by compositional principles on the recent COGS corpus (Kim and Linzen, 2020). Though seq2seq models can perform well on lexical tasks, they perform with near-zero accuracy on structural generalization tasks that require novel syntactic structures; this holds true even when they are trained to predict syntax instead of semantics. In contrast, compositional models achieve near-perfect accuracy on structural generalization; we present new results confirming this from the AM parser (Groschwitz et al., 2021). Our findings show structural generalization is a key measure of compositional generalization and requires models that are aware of complex structure.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1412898731",
                        "name": "Pia Weissenhorn"
                    },
                    {
                        "authorId": "1733485928",
                        "name": "Yuekun Yao"
                    },
                    {
                        "authorId": "51225576",
                        "name": "L. Donatelli"
                    },
                    {
                        "authorId": "145542037",
                        "name": "Alexander Koller"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recent work has introduced several compositional data augmentation schemes: rule-based procedures or learned models that synthesize artificial training examples to promote generalization (Andreas, 2020; Shaw et al., 2021; Aky\u00fcrek et al., 2021; Zhang et al., 2022, inter alia).",
                "Data Augmentation Data augmentation approaches are widely used across machine learning application domains featuring known invariances of the data distribution (Japkowicz et al., 2000; Jia and Liang, 2016; Shaw et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "882d31ef9b6441661394b45291a1b1c6017b8972",
                "externalIds": {
                    "ACL": "2023.acl-long.38",
                    "DBLP": "conf/acl/AkyurekA23",
                    "ArXiv": "2201.12926",
                    "DOI": "10.18653/v1/2023.acl-long.38",
                    "CorpusId": 246430154
                },
                "corpusId": 246430154,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/882d31ef9b6441661394b45291a1b1c6017b8972",
                "title": "LexSym: Compositionality as Lexical Symmetry",
                "abstract": "In tasks like semantic parsing, instruction following, and question answering, standard deep networks fail to generalize compositionally from small datasets. Many existing approaches overcome this limitation with model architectures that enforce a compositional process of sentence interpretation. In this paper, we present a domain-general and model-agnostic formulation of compositionality as a constraint on symmetries of data distributions rather than models. Informally, we prove that whenever a task can be solved by a compositional model, there is a corresponding data augmentation scheme \u2014 a procedure for transforming examples into other well-formed examples \u2014 that imparts compositional inductive bias on any model trained to solve the same task. We describe a procedure called LexSym that discovers these transformations automatically, then applies them to training data for ordinary neural sequence models. Unlike existing compositional data augmentation procedures, LexSym can be deployed agnostically across text, structured data, and even images. It matches or surpasses state-of-the-art, task-specific models on COGS semantic parsing, SCAN and Alchemy instruction following, and CLEVR-CoGenT visual question answering datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1992708068",
                        "name": "Ekin Aky\u00fcrek"
                    },
                    {
                        "authorId": "2112400",
                        "name": "Jacob Andreas"
                    }
                ]
            }
        },
        {
            "contexts": [
                "While previous works also cast SKG tasks into the textto-text format (Hosseini-Asl et al., 2020; Shaw et al., 2021; Liu et al., 2021), their independent choices of pretrained language models (PLMs), input-output formats, and frameworks make our unification non-trivial."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "53c0abe83fe9b4fdaf2208295d8504fcf5241694",
                "externalIds": {
                    "DBLP": "conf/emnlp/XieW0ZSYWZYWZWL22",
                    "ArXiv": "2201.05966",
                    "ACL": "2022.emnlp-main.39",
                    "DOI": "10.18653/v1/2022.emnlp-main.39",
                    "CorpusId": 246016124
                },
                "corpusId": 246016124,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/53c0abe83fe9b4fdaf2208295d8504fcf5241694",
                "title": "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models",
                "abstract": "Structured knowledge grounding (SKG) leverages structured knowledge to complete user requests, such as semantic parsing over databases and question answering over knowledge bases. Since the inputs and outputs of SKG tasks are heterogeneous, they have been studied separately by different communities, which limits systematic and compatible research on SKG. In this paper, we overcome this limitation by proposing the UnifiedSKG framework, which unifies 21 SKG tasks into a text-to-text format, aiming to promote systematic SKG research, instead of being exclusive to a single task, domain, or dataset. We use UnifiedSKG to benchmark T5 with different sizes and show that T5, with simple modifications when necessary, achieves state-of-the-art performance on almost all of the 21 tasks. We further demonstrate that multi-task prefix-tuning improves the performance on most tasks, largely improving the overall performance. UnifiedSKG also facilitates the investigation of zero-shot and few-shot learning, and we show that T0, GPT-3, and Codex struggle in zero-shot and few-shot learning for SKG. We also use UnifiedSKG to conduct a series of controlled experiments on structured knowledge encoding variants across SKG tasks. UnifiedSKG is easily extensible to more tasks, and it is open-sourced at https://github.com/hkunlp/unifiedskg.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2057038673",
                        "name": "Tianbao Xie"
                    },
                    {
                        "authorId": "114621402",
                        "name": "Chen Henry Wu"
                    },
                    {
                        "authorId": "2055357805",
                        "name": "Peng Shi"
                    },
                    {
                        "authorId": "51011000",
                        "name": "Ruiqi Zhong"
                    },
                    {
                        "authorId": "11869783",
                        "name": "Torsten Scholak"
                    },
                    {
                        "authorId": "19168196",
                        "name": "Michihiro Yasunaga"
                    },
                    {
                        "authorId": "30340989",
                        "name": "Chien-Sheng Wu"
                    },
                    {
                        "authorId": "1606040932",
                        "name": "Ming Zhong"
                    },
                    {
                        "authorId": "38253388",
                        "name": "Pengcheng Yin"
                    },
                    {
                        "authorId": "8729431",
                        "name": "Sida I. Wang"
                    },
                    {
                        "authorId": "3428769",
                        "name": "Victor Zhong"
                    },
                    {
                        "authorId": "2118640406",
                        "name": "Bailin Wang"
                    },
                    {
                        "authorId": "2155795167",
                        "name": "Chengzu Li"
                    },
                    {
                        "authorId": "2143195008",
                        "name": "Connor Boyle"
                    },
                    {
                        "authorId": "33981736",
                        "name": "Ansong Ni"
                    },
                    {
                        "authorId": "3366595",
                        "name": "Ziyu Yao"
                    },
                    {
                        "authorId": "9215251",
                        "name": "Dragomir R. Radev"
                    },
                    {
                        "authorId": "2054594326",
                        "name": "Caiming Xiong"
                    },
                    {
                        "authorId": "47648549",
                        "name": "Lingpeng Kong"
                    },
                    {
                        "authorId": "15176410",
                        "name": "Rui Zhang"
                    },
                    {
                        "authorId": "144365875",
                        "name": "Noah A. Smith"
                    },
                    {
                        "authorId": "1982950",
                        "name": "Luke Zettlemoyer"
                    },
                    {
                        "authorId": "48881008",
                        "name": "Tao Yu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, since MCD and TMCD were designed to generate compositional splits, they were not tested on whether they predict difficulty of other splits, such as the template split.",
                "Similarly to TMCD, we define atoms and compounds over the program tree T , over the graph defined in \u00a74.1.",
                "As discussed (\u00a74.4), Maximum Compound Divergence (MCD) and its variation TMCD, are recently proposed metrics for estimating the difficulty of a test set, while we measure difficulty at the in-\nstance level.",
                "Measuring compositional difficulty The most closely related methods to our work are MCD and its variation TMCD (Keysers et al., 2020; Shaw et al., 2021), designed to create compositional splits.",
                "In addition, while in TMCD the difficulty is over an entire test set, we predict the difficulty of specific instances.",
                "In MCD, it is created from the tree of derivation rules that generates the program, and in TMCD from the program parse tree, similar to our approach.",
                "We measure compound divergence of the distributions of compounds and atoms on the program graph, following Keysers et al. (2020) and Shaw et al. (2021).",
                "TMCD The MCD and TMCD methods (Keysers et al., 2020; Shaw et al., 2021) have been used to create compositional splits, by maximizing compound divergence across the training and test splits.",
                "While the two\nmethods are not directly comparable, since we focus on instance-level generalization, we extend our approach for computing the easiness of a split and compare to TMCD in \u00a75.",
                "For TMCD, we compute the compound divergence of each split (high compound divergence indicates a more difficult split, or lower easiness) following Shaw et al. (2021), see details in App.",
                "Instancelevel analysis can better characterize the challenges of compositional generalization, and as we show in \u00a75.2 it is a better predictor of difficulty compared to TMCD even at the split level.",
                "Automatic methods include splitting examples by output length (Lake and Baroni, 2018), by anonymizing programs (Finegan-Dollak et al., 2018), and by maximizing divergence between distribution across the training and test set (Keysers et al., 2020; Shaw et al., 2021)."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "9fe39e0f2cf3b6d5f70a379654f9c08ffa48ddee",
                "externalIds": {
                    "DBLP": "conf/emnlp/BoginGB22",
                    "ACL": "2022.emnlp-main.175",
                    "ArXiv": "2201.05899",
                    "DOI": "10.18653/v1/2022.emnlp-main.175",
                    "CorpusId": 246015393
                },
                "corpusId": 246015393,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/9fe39e0f2cf3b6d5f70a379654f9c08ffa48ddee",
                "title": "Unobserved Local Structures Make Compositional Generalization Hard",
                "abstract": "While recent work has shown that sequence-to-sequence models struggle to generalize to new compositions (termed compositional generalization), little is known on what makes compositional generalization hard on a particular test instance. In this work, we investigate the factors that make generalization to certain test instances challenging. We first substantiate that some examples are more difficult than others by showing that different models consistently fail or succeed on the same test instances. Then, we propose a criterion for the difficulty of an example: a test instance is hard if it contains a local structure that was not observed at training time. We formulate a simple decision rule based on this criterion and empirically show it predicts instance-level generalization well across 5 different semantic parsing datasets, substantially better than alternative decision rules. Last, we show local structures can be leveraged for creating difficult adversarial compositional splits and also to improve compositional generalization under limited training budgets by strategically selecting examples for the training set.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "50757607",
                        "name": "Ben Bogin"
                    },
                    {
                        "authorId": "1698760333",
                        "name": "Shivanshu Gupta"
                    },
                    {
                        "authorId": "1750652",
                        "name": "Jonathan Berant"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "a85c6a003450ef1e6caed8a6494301ad581957ee",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-01787",
                    "ArXiv": "2201.01787",
                    "CorpusId": 245769925
                },
                "corpusId": 245769925,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a85c6a003450ef1e6caed8a6494301ad581957ee",
                "title": "Does entity abstraction help generative Transformers reason?",
                "abstract": "We study the utility of incorporating entity type abstractions into pre-trained Transformers and test these methods on four NLP tasks requiring different forms of logical reasoning: (1) compositional language understanding with text-based relational reasoning (CLUTRR), (2) abductive reasoning (ProofWriter), (3) multi-hop question answering (HotpotQA), and (4) conversational question answering (CoQA). We propose and empirically explore three ways to add such abstraction: (i) as additional input embeddings, (ii) as a separate sequence to encode, and (iii) as an auxiliary prediction task for the model. Overall, our analysis demonstrates that models with abstract entity knowledge performs better than without it. The best abstraction aware models achieved an overall accuracy of 88.8% and 91.8% compared to the baseline model achieving 62.9% and 89.8% on CLUTRR and ProofWriter respectively. However, for HotpotQA and CoQA, we find that F1 scores improve by only 0.5% on average. Our results suggest that the benefit of explicit abstraction is significant in formally defined logical reasoning settings requiring many reasoning hops, but point to the notion that it is less beneficial for NLP tasks having less formal logical structure.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51921879",
                        "name": "Nicolas Gontier"
                    },
                    {
                        "authorId": "145732771",
                        "name": "Siva Reddy"
                    },
                    {
                        "authorId": "2061666830",
                        "name": "C. Pal"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "0b483b550b21ec42d693fc04a372dbb10dd07019",
                "externalIds": {
                    "DBLP": "conf/naacl/PoradaSC22",
                    "ArXiv": "2112.08583",
                    "ACL": "2022.naacl-main.337",
                    "DOI": "10.18653/v1/2022.naacl-main.337",
                    "CorpusId": 245218685
                },
                "corpusId": 245218685,
                "publicationVenue": {
                    "id": "01103732-3808-4930-b8e4-7e9e68d5c68d",
                    "name": "North American Chapter of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "North Am Chapter Assoc Comput Linguistics",
                        "NAACL"
                    ],
                    "url": "https://www.aclweb.org/portal/naacl"
                },
                "url": "https://www.semanticscholar.org/paper/0b483b550b21ec42d693fc04a372dbb10dd07019",
                "title": "Does Pre-training Induce Systematic Inference? How Masked Language Models Acquire Commonsense Knowledge",
                "abstract": "Transformer models pre-trained with a masked-language-modeling objective (e.g., BERT) encode commonsense knowledge as evidenced by behavioral probes; however, the extent to which this knowledge is acquired by systematic inference over the semantics of the pre-training corpora is an open question. To answer this question, we selectively inject verbalized knowledge into the pre-training minibatches of BERT and evaluate how well the model generalizes to supported inferences after pre-training on the injected knowledge. We find generalization does not improve over the course of pre-training BERT from scratch, suggesting that commonsense knowledge is acquired from surface-level, co-occurrence patterns rather than induced, systematic reasoning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "108508643",
                        "name": "Ian Porada"
                    },
                    {
                        "authorId": "2041695",
                        "name": "Alessandro Sordoni"
                    },
                    {
                        "authorId": "3159752",
                        "name": "J. Cheung"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2020) and COGS (Kim and Linzen, 2020) have been created, and several approaches achieve good performance on these tasks, the out-of-distribution generalization ability of state-of-the-art models on real-world, nonsynthetic tasks is still far from sufficient (Shaw et al., 2021; Yin et al., 2021).",
                "18We do not show LeAR results for SCAN and GeoQuery as Liu et al. (2021) did not report results for SCAN and reported GeoQuery results using a different template split and a different evaluation metric.",
                "GeoQuery We use the same variant of FunQL (Kate et al., 2005) as Shaw et al. (2021), with entities replaced with placeholder values.",
                "However, these models often perform poorly on out-of-distribution compositional generalization tasks (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021).\nar X\niv :2\n11 2.",
                "19Some of our results for NQG-T5 are different than those reported in Shaw et al. (2021) as we average over 3 new GeoQuery template and TMCD splits, as described in \u00a74.1.",
                "In contrast, specialized architectures with discrete latent structure (Chen et al., 2020; Liu et al., 2020; Nye et al., 2020; Herzig and Berant, 2021; Shaw et al., 2021) have made strides in compositional generalization, but without task-specific engineering or ensembling, the gains have been limited to synthetic semantic parsing tasks.",
                "CSL and NQG of Shaw et al. (2021) vary across several dimensions, as the two systems use different grammar induction algorithms and different model parameterizations.",
                "For the TMCD splits, we changed the atom constraint slightly, based on the error analysis in Shaw et al. (2021) which found that a disproportionate amount of the errors on the TMCD test set were in cases where an \u201catom\u201d was seen in only a single context during training.",
                "T5 Fine-Tuning We started with the same configuration for fine-tuning T5 as Shaw et al. (2021).",
                "For SCAN, NQG-T5 (Shaw et al., 2021) is one of several specialized models that achieves 100% accuracy across multiple splits (Chen et al., 2020; Liu et al., 2020; Nye et al., 2020; Herzig and Berant, 2021).",
                "\u2026contrast, specialized architectures with discrete latent structure (Chen et al., 2020; Liu et al., 2020; Nye et al., 2020; Herzig and Berant, 2021; Shaw et al., 2021) have made strides in compositional generalization, but without task-specific engineering or ensembling, the gains have been\u2026",
                "\u20262021; Ruiz et al., 2021; Wang et al., 2021a), different Transformer variations (Csord\u00e1s et al., 2021; Ontan\u00f3n et al., 2021), ensemble models (Shaw et al., 2021), intermediate representations (Herzig et al., 2021), meta-learning (Lake, 2019; Conklin et al., 2021; Zhu et al., 2021), and\u2026",
                "\u2026(x \u2208 XCSL) to x /\u2208 XCSL.\nComparison with NQG We cannot compare using CSL for data augmentation directly with using its closely related predecessor NQG (Shaw et al., 2021) for data augmentation, as NQG is a discriminative parsing model and not a probabilistic generative model that enables sampling\u2026",
                "Comparison with NQG We cannot compare using CSL for data augmentation directly with using its closely related predecessor NQG (Shaw et al., 2021) for data augmentation, as NQG is a discriminative parsing model and not a probabilistic generative model that enables sampling new examples.",
                ", 2021), ensemble models (Shaw et al., 2021), intermediate representations (Herzig et al.",
                "We report results on the standard data split as well as three compositional splits based on those introduced in Shaw et al. (2021): the template split (where abstract output templates in training and test data are disjoint (Finegan-Dollak et al., 2018)), the TMCD split (an extension of MCD for\u2026",
                "For SCAN, NQG-T5 (Shaw et al., 2021) is one of several specialized models that achieves 100% accuracy across multiple splits (Chen et al.",
                "Using CSL for data augmentation outperforms using GECA on SCAN and GeoQuery.",
                "Our method for inducing a QCFG is based on that of Shaw et al. (2021), but with several modifications, which improve the computational scalability of the algorithm as well as the precision and coverage of the induced grammar.",
                "However, these models often perform poorly on out-of-distribution compositional generalization tasks (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021).",
                "CSL builds on the NQG model of Shaw et al. (2021), a discriminative parsing model over an induced QCFG backbone, which Shaw et al. (2021) proposed to ensemble with T5.",
                "CSL builds on the NQG model of Shaw et al. (2021), with several key differences discussed in the following sections:\n\u2022 Unlike NQG, which is discriminative, CSL is a generative model that admits efficient sampling from the joint distribution p(x, y).",
                "Prior work found T5-Base to perform best on the compositional splits of SCAN and GeoQuery (Furrer et al., 2020; Shaw et al., 2021).",
                "\u2026rules in \u00a73.\nbe quasi-synchronous (Smith and Eisner, 2006) because we allow a one-to-many alignment between non-terminals.6 Unlike the formalism of Shaw et al. (2021), which limited rules to contain \u2264 2 nonterminals, in the current work the maximal number of non-terminals is a configurable\u2026",
                "We generate new length, template, and TMCD splits following the methodology of Shaw et al. (2021), so that we could evaluate our method on dev sets, which the original splits did not include.",
                "\u20262020) and COGS (Kim and Linzen, 2020) have been created, and several approaches achieve good performance on these tasks, the out-of-distribution generalization ability of state-of-the-art models on real-world, nonsynthetic tasks is still far from sufficient (Shaw et al., 2021; Yin et al., 2021).",
                "\u2026and \u03b8 given D would be to find the MAP estimate based on some prior, p(G, \u03b8), that encourages compositionality:\nargmax G,\u03b8 p(G, \u03b8)\u00d7 \u220f \u3008x,y\u3009\u2208D pG,\u03b8(x, y) (5)\nHowever, since optimizing G and \u03b8 jointly is computationally challenging, we adopt a two-stage process similar to that of Shaw et al. (2021)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5626e1db3d4fa8f8de79b604ce9fb8eb96a75883",
                "externalIds": {
                    "ACL": "2022.naacl-main.323",
                    "ArXiv": "2112.07610",
                    "DBLP": "journals/corr/abs-2112-07610",
                    "DOI": "10.18653/v1/2022.naacl-main.323",
                    "CorpusId": 245131376
                },
                "corpusId": 245131376,
                "publicationVenue": {
                    "id": "01103732-3808-4930-b8e4-7e9e68d5c68d",
                    "name": "North American Chapter of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "North Am Chapter Assoc Comput Linguistics",
                        "NAACL"
                    ],
                    "url": "https://www.aclweb.org/portal/naacl"
                },
                "url": "https://www.semanticscholar.org/paper/5626e1db3d4fa8f8de79b604ce9fb8eb96a75883",
                "title": "Improving Compositional Generalization with Latent Structure and Data Augmentation",
                "abstract": "Generic unstructured neural networks have been shown to struggle on out-of-distribution compositional generalization. Compositional data augmentation via example recombination has transferred some prior knowledge about compositionality to such black-box neural models for several semantic parsing tasks, but this often required task-specific engineering or provided limited gains. We present a more powerful data recombination method using a model called Compositional Structure Learner (CSL). CSL is a generative model with a quasi-synchronous context-free grammar backbone, which we induce from the training data. We sample recombined examples from CSL and add them to the fine-tuning data of a pre-trained sequence-to-sequence model (T5). This procedure effectively transfers most of CSL\u2019s compositional bias to T5 for diagnostic tasks, and results in a model even stronger than a T5-CSL ensemble on two real world compositional generalization tasks. This results in new state-of-the-art performance for these challenging semantic parsing tasks requiring generalization to both natural language variation and novel compositions of elements.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1742081895",
                        "name": "Linlu Qiu"
                    },
                    {
                        "authorId": "38759328",
                        "name": "Peter Shaw"
                    },
                    {
                        "authorId": "2616463",
                        "name": "Panupong Pasupat"
                    },
                    {
                        "authorId": "5274550",
                        "name": "Pawel Krzysztof Nowak"
                    },
                    {
                        "authorId": "2467508",
                        "name": "Tal Linzen"
                    },
                    {
                        "authorId": "145757665",
                        "name": "Fei Sha"
                    },
                    {
                        "authorId": "3259253",
                        "name": "Kristina Toutanova"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Namely, it has been shown to perform competitively on different text-to-SQL datasets, regardless of their SQL conventions (Shaw et al., 2021; Herzig et al., 2021).",
                "Following past work (Shaw et al., 2021; Herzig et al., 2021), we fine-tune T5 to map text to SQL."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "4bcf3b1562e16e95cb033c257bbb61cd9a9920f7",
                "externalIds": {
                    "ArXiv": "2112.06311",
                    "DBLP": "conf/naacl/WolfsonDB22",
                    "DOI": "10.18653/v1/2022.findings-naacl.193",
                    "CorpusId": 248377741
                },
                "corpusId": 248377741,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/4bcf3b1562e16e95cb033c257bbb61cd9a9920f7",
                "title": "Weakly Supervised Text-to-SQL Parsing through Question Decomposition",
                "abstract": "Text-to-SQL parsers are crucial in enabling non-experts to effortlessly query relational data. Training such parsers, by contrast, generally requires expertise in annotating natural language (NL) utterances with corresponding SQL queries. In this work, we propose a weak supervision approach for training text-to-SQL parsers. We take advantage of the recently proposed question meaning representation called QDMR, an intermediate between NL and formal query languages. Given questions, their QDMR structures (annotated by non-experts or automatically predicted), and the answers, we are able to automatically synthesize SQL queries that are used to train text-to-SQL models. We test our approach by experimenting on five benchmark datasets. Our results show that the weakly supervised models perform competitively with those trained on annotated NL-SQL data. Overall, we effectively train text-to-SQL parsers, while using zero SQL annotations.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51174907",
                        "name": "Tomer Wolfson"
                    },
                    {
                        "authorId": "1682639",
                        "name": "Daniel Deutch"
                    },
                    {
                        "authorId": "1750652",
                        "name": "Jonathan Berant"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently, there has been a growing interest in compositional generalization in the NLIs to other formal representations [3, 13, 15, 17, 19, 21, 26] which enables these systems to systematically compose complex examples after being exposed to simple components during training.",
                "[26] both evaluated their models on a subset of GeoQuery dataset splits and achieved strong performance.",
                "specialized architecture models [3, 19, 21, 26] which learn and incorporate grammar or structure to tackle compositional generalization challenges.",
                "[26] highlighted in their work that evaluating NLIs on a diverse set of benchmarks is important and the performance on synthetic datasets [15, 17] is not well-correlated with performance on nonsynthetic tasks with natural language variation.",
                "The only method with perfect scores on all SCAN split which doesn\u2019t require task specific resources is NQG-T5 [26].",
                "[26] leveraged the GeoQuery dataset [32] to evaluate the compositional generalization on a non-synthetic dataset.",
                "While these models fail in Length splits for both SCAN and Okapi datasets, several models with specialized architectures [19, 26] have been proposed for SCAN dataset which achieve 100% accuracy on Length and MCD splits."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a576512a7562597fd30719a834d5866d010ef6ab",
                "externalIds": {
                    "ArXiv": "2112.05209",
                    "DBLP": "journals/corr/abs-2112-05209",
                    "CorpusId": 245117798
                },
                "corpusId": 245117798,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a576512a7562597fd30719a834d5866d010ef6ab",
                "title": "Compositional Generalization for Natural Language Interfaces to Web APIs",
                "abstract": "This paper presents Okapi, a new dataset for Natural Language to executable web Application Programming Interfaces (NL2API). This dataset is in English and contains 22,508 questions and 9,019 unique API calls, covering three domains. We define new compositional generalization tasks for NL2API which explore the models' ability to extrapolate from simple API calls in the training set to new and more complex API calls in the inference phase. Also, the models are required to generate API calls that execute correctly as opposed to the existing approaches which evaluate queries with placeholder values. Our dataset is different than most of the existing compositional semantic parsing datasets because it is a non-synthetic dataset studying the compositional generalization in a low-resource setting. Okapi is a step towards creating realistic datasets and benchmarks for studying compositional generalization alongside the existing datasets and tasks. We report the generalization capabilities of sequence-to-sequence baseline models trained on a variety of the SCAN and Okapi datasets tasks. The best model achieves 15\\% exact match accuracy when generalizing from simple API calls to more complex API calls. This highlights some challenges for future research. Okapi dataset and tasks are publicly available at https://aka.ms/nl2api/data.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2195458",
                        "name": "Saghar Hosseini"
                    },
                    {
                        "authorId": "2072795428",
                        "name": "A. Awadallah"
                    },
                    {
                        "authorId": "1758652",
                        "name": "Yu Su"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We use the MCD split generated for SCAN from Keysers et al. (2020) and the Target Maximum Compound Divergence (TMCD) splits generated for GeoQuery from Shaw et al. (2021).",
                "We use the same pre-processing as in Shaw et al. (2021), replacing entity mentions with placeholders in the Functional Query Language (FunQL; Kate et al. 2005) output representations.",
                "For GEO cd, our approach beats the state-of-the-art, established by a hybrid neurosymbolic model (Shaw et al., 2021); for GEO len, we substantially improved over the baselines.",
                "In particular, pre-finetuning on SCAN cd leads to an accuracy of 57.8% on GEO TMCD2, surpassing \u2014 with a neural-only approach \u2014 the previous state-of-the-art of 56.6%, which was established by NQG-T5, a hybrid model that combines a grammar-based approach with T5 (Shaw et al., 2021).",
                "The state-of-the-art results on this task is 52.2% from the NQG-T5 model (Shaw et al., 2021).",
                "We adopt the length and TMCD splits from Shaw et al. (2021).",
                "6%, which was established by NQG-T5, a hybrid model that combines a grammar-based approach with T5 (Shaw et al., 2021).",
                "\u2026NLP. Specifically, recent work has proposed new or\nmodified model architectures (Li et al., 2019; Russin et al., 2019; Gordon et al., 2020; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020b; Zheng & Lapata, 2020; Oren et al., 2020; Herzig & Berant, 2020; Shaw et al., 2021; Yin et al., 2021).",
                "Recent work has spotlighted significant shortcomings of neural network approaches to NLP in coping with compositional generalization (CG) (Lake & Baroni, 2018; Finegan-Dollak et al., 2018; Keysers et al., 2020; Kim & Linzen, 2020; Shaw et al., 2021)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "c764ecba2bace12b9bfb9c2b0651a12ff6888ea7",
                "externalIds": {
                    "ArXiv": "2111.05013",
                    "DBLP": "journals/corr/abs-2111-05013",
                    "CorpusId": 243861166
                },
                "corpusId": 243861166,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c764ecba2bace12b9bfb9c2b0651a12ff6888ea7",
                "title": "Learning to Generalize Compositionally by Transferring Across Semantic Parsing Tasks",
                "abstract": "Neural network models often generalize poorly to mismatched domains or distributions. In NLP, this issue arises in particular when models are expected to generalize compositionally, that is, to novel combinations of familiar words and constructions. We investigate learning representations that facilitate transfer learning from one compositional task to another: the representation and the task-specific layers of the models are strategically trained differently on a pre-finetuning task such that they generalize well on mismatched splits that require compositionality. We apply this method to semantic parsing, using three very different datasets, COGS, GeoQuery and SCAN, used alternately as the pre-finetuning and target task. Our method significantly improves compositional generalization over baselines on the test set of the target task, which is held out during fine-tuning. Ablation studies characterize the utility of the major steps in the proposed algorithm and support our hypothesis.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "143750633",
                        "name": "Wang Zhu"
                    },
                    {
                        "authorId": "38759328",
                        "name": "Peter Shaw"
                    },
                    {
                        "authorId": "51223875",
                        "name": "Tal Linzen"
                    },
                    {
                        "authorId": "145757665",
                        "name": "Fei Sha"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently, it has been shown that T5 can be successfully fine-tuned on a large-scale text-to-sql dataset (Shaw et al., 2021; Scholak et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "2f05cb3dd8194276aa26c4e71841a86edb51914f",
                "externalIds": {
                    "DBLP": "conf/acl/SchucherRV22",
                    "ACL": "2022.acl-short.17",
                    "ArXiv": "2110.08525",
                    "DOI": "10.18653/v1/2022.acl-short.17",
                    "CorpusId": 239016577
                },
                "corpusId": 239016577,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/2f05cb3dd8194276aa26c4e71841a86edb51914f",
                "title": "The Power of Prompt Tuning for Low-Resource Semantic Parsing",
                "abstract": "Prompt tuning has recently emerged as an effective method for adapting pre-trained language models to a number of language understanding and generation tasks. In this paper, we investigate prompt tuning for semantic parsing\u2014the task of mapping natural language utterances onto formal meaning representations. On the low-resource splits of Overnight and TOPv2, we find that a prompt tuned T5-xl significantly outperforms its fine-tuned counterpart, as well as strong GPT-3 and BART baselines. We also conduct ablation studies across different model scales and target representations, finding that, with increasing model scale, prompt tuned T5 models improve at generating target representations that are far from the pre-training distribution.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "74530494",
                        "name": "Nathan Schucher"
                    },
                    {
                        "authorId": "145732771",
                        "name": "Siva Reddy"
                    },
                    {
                        "authorId": "153559313",
                        "name": "Harm de Vries"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "e528466e2aff981511d4ca6e063211297c0b4175",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-07732",
                    "ArXiv": "2110.07732",
                    "CorpusId": 239009538
                },
                "corpusId": 239009538,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/e528466e2aff981511d4ca6e063211297c0b4175",
                "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization",
                "abstract": "Despite progress across a broad range of applications, Transformers have limited success in systematic generalization. The situation is especially frustrating in the case of algorithmic tasks, where they often fail to find intuitive solutions that route relevant information to the right node/operation at the right time in the grid represented by Transformer columns. To facilitate the learning of useful control flow, we propose two modifications to the Transformer architecture, copy gate and geometric attention. Our novel Neural Data Router (NDR) achieves 100% length generalization accuracy on the classic compositional table lookup task, as well as near-perfect accuracy on the simple arithmetic task and a new variant of ListOps testing for generalization across computational depths. NDR's attention and gating patterns tend to be interpretable as an intuitive form of neural routing. Our code is public.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3190548",
                        "name": "R. Csord\u00e1s"
                    },
                    {
                        "authorId": "2350348",
                        "name": "Kazuki Irie"
                    },
                    {
                        "authorId": "145341374",
                        "name": "J. Schmidhuber"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2020) and natural benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2020), researchers have been studying systematic generalization of existing semantic parsing methods as well as proposing new approaches such as",
                "Using synthetic (Bahdanau et al., 2019; Kim and Linzen, 2020a; Keysers et al., 2020) and natural benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2020), researchers have been studying systematic generalization of existing semantic parsing methods as well as proposing new approaches such as\u2026"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "00050c15896e8ae6bb534f10d072351547993f72",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-07572",
                    "ArXiv": "2110.07572",
                    "CorpusId": 238856769
                },
                "corpusId": 238856769,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/00050c15896e8ae6bb534f10d072351547993f72",
                "title": "LAGr: Labeling Aligned Graphs for Improving Systematic Generalization in Semantic Parsing",
                "abstract": "Semantic parsing is the task of producing a structured meaning representation for natural language utterances or questions. Recent research has pointed out that the commonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to generalize systematically, i.e. to handle examples that require recombining known knowledge in novel settings. In this work, we show that better systematic generalization can be achieved by producing the meaning representation (MR) directly as a graph and not as a sequence. To this end we propose LAGr, the Labeling Aligned Graphs algorithm that produces semantic parses by predicting node and edge labels for a complete multi-layer input-aligned graph. The strongly-supervised LAGr algorithm requires aligned graphs as inputs, whereas weakly-supervised LAGr infers alignments for originally unaligned target graphs using an approximate MAP inference procedure. On the COGS and CFQ compositional generalization benchmarks the strongly- and weakly- supervised LAGr algorithms achieve significant improvements upon the baseline seq2seq parsers.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "123658753",
                        "name": "Dora Jambor"
                    },
                    {
                        "authorId": "3335364",
                        "name": "Dzmitry Bahdanau"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "bb0ab8591d6d57c7e2bd1ec35d806b3f25277752",
                "externalIds": {
                    "ACL": "2021.emnlp-main.505",
                    "DBLP": "conf/emnlp/JiangB21",
                    "ArXiv": "2109.15256",
                    "DOI": "10.18653/v1/2021.emnlp-main.505",
                    "CorpusId": 238227171
                },
                "corpusId": 238227171,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/bb0ab8591d6d57c7e2bd1ec35d806b3f25277752",
                "title": "Inducing Transformer\u2019s Compositional Generalization Ability via Auxiliary Sequence Prediction Tasks",
                "abstract": "Systematic compositionality is an essential mechanism in human language, allowing the recombination of known parts to create novel expressions. However, existing neural models have been shown to lack this basic ability in learning symbolic structures. Motivated by the failure of a Transformer model on the SCAN compositionality challenge (Lake and Baroni, 2018), which requires parsing a command into actions, we propose two auxiliary sequence prediction tasks as additional training supervision. These automatically-generated sequences are more representative of the underlying compositional symbolic structures of the input data. During inference, the model jointly predicts the next action and the next tokens in the auxiliary sequences at each step. Experiments on the SCAN dataset show that our method encourages the Transformer to understand compositional structures of the command, improving its accuracy on multiple challenging splits from \u2264 10% to 100%. With only 418 (5%) training instances, our approach still achieves 97.8% accuracy on the MCD1 split. Therefore, we argue that compositionality can be induced in Transformers given minimal but proper guidance. We also show that a better result is achieved using less contextualized vectors as the attention\u2019s query, providing insights into architecture choices in achieving systematic compositionality. Finally, we show positive generalization results on the grounded-SCAN task (Ruis et al., 2020).",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "31688795",
                        "name": "Yichen Jiang"
                    },
                    {
                        "authorId": "143977268",
                        "name": "Mohit Bansal"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These predicates correspond to the \u201ccompounds\u201d defined in (Keysers et al., 2020; Shaw et al., 2020), and the objective is to maximize the divergence between compound distribution of the evaluation data to the training data.",
                "To generate evaluations of compositional generalization, we use a method similar to that of Shaw et al. (2020) and Keysers et al. (2020) which maximizes compound divergence between the distribution of compounds in the evaluation set and in the training set.",
                "We validate the generalization capability of COMPOSER by designing an evaluation procedure for a more challenging compositional generalization task that uses test examples with maximum compound divergence (MCD) to the training data (Shaw et al., 2020; Keysers et al., 2020).",
                "As mentioned in the main text, we generate compositional generalization (CG) splits with 1,000 images and 5,000 text queries, maximizing the Compound Divergence (MCD) as Shaw et al. (2020)3, to assess models\u2019 capability in generalizing to the data with different predicate distribution."
            ],
            "isInfluential": true,
            "intents": [],
            "citingPaper": {
                "paperId": "cdb2a71f42c88be6d5c5e4fecb8288a9a315f094",
                "externalIds": {
                    "ArXiv": "2109.14115",
                    "DBLP": "journals/corr/abs-2109-14115",
                    "DOI": "10.18653/v1/2021.findings-emnlp.20",
                    "CorpusId": 238215187
                },
                "corpusId": 238215187,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/cdb2a71f42c88be6d5c5e4fecb8288a9a315f094",
                "title": "Visually Grounded Concept Composition",
                "abstract": "We investigate ways to compose complex concepts in texts from primitive ones while grounding them in images. We propose Concept and Relation Graph (CRG), which builds on top of constituency analysis and consists of recursively combined concepts with predicate functions. Meanwhile, we propose a concept composition neural network called Composer to leverage the CRG for visually grounded concept learning. Specifically, we learn the grounding of both primitive and all composed concepts by aligning them to images and show that learning to compose leads to more robust grounding results, measured in text-to-image matching accuracy. Notably, our model can model grounded concepts forming at both the finer-grained sentence level and the coarser-grained intermediate level (or word-level). Composer leads to pronounced improvement in matching accuracy when the evaluation data has significant compound divergence from the training data.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3047890",
                        "name": "Bowen Zhang"
                    },
                    {
                        "authorId": "2112393041",
                        "name": "Hexiang Hu"
                    },
                    {
                        "authorId": "1742081895",
                        "name": "Linlu Qiu"
                    },
                    {
                        "authorId": "38759328",
                        "name": "Peter Shaw"
                    },
                    {
                        "authorId": "145757665",
                        "name": "Fei Sha"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following Shaw et al. (2021); Hazoom et al. (2021), we use T5 as our baseline model.",
                "Similar to Shaw et al. (2021), we identify examples from training set databases that contain more than 50 examples to ensure sufficient coverage over table and column names in the training data.",
                "Following Shaw et al. (2021), we adopt a setting similar to an alternative setting called the example split in the original dataset (Yu et al., 2018) where the databases are shared between train and test examples."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "2222fe87201177339c89fbfe9ef3c9c8e67674a5",
                "externalIds": {
                    "ArXiv": "2109.13066",
                    "DBLP": "journals/corr/abs-2109-13066",
                    "CorpusId": 237941070
                },
                "corpusId": 237941070,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2222fe87201177339c89fbfe9ef3c9c8e67674a5",
                "title": "Prefix-to-SQL: Text-to-SQL Generation from Incomplete User Questions",
                "abstract": "Existing text-to-SQL research only considers complete questions as the input, but lay-users might strive to formulate a complete question. To build a smarter natural language interface to database systems (NLIDB) that also processes incomplete questions, we propose a new task, prefix-to-SQL which takes question prefix from users as the input and predicts the intended SQL. We construct a new benchmark called PAGSAS that contains 124K user question prefixes and the intended SQL for 5 sub-tasks Advising, GeoQuery, Scholar, ATIS, and Spider. Additionally, we propose a new metric SAVE to measure how much effort can be saved by users. Experimental results show that PAGSAS is challenging even for strong baseline models such as T5. As we observe the difficulty of prefix-to-SQL is related to the number of omitted tokens, we incorporate curriculum learning of feeding examples with an increasing number of omitted tokens. This improves scores on various sub-tasks by as much as 9% recall scores on sub-task GeoQuery in PAGSAS.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2142468208",
                        "name": "Naihao Deng"
                    },
                    {
                        "authorId": "46923811",
                        "name": "Shuaichen Chang"
                    },
                    {
                        "authorId": "2055357805",
                        "name": "Peng Shi"
                    },
                    {
                        "authorId": "48881008",
                        "name": "Tao Yu"
                    },
                    {
                        "authorId": "15176410",
                        "name": "Rui Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, the follow-up studies from Deng et al. (2021); Gan et al. (2021); Suhr et al. (2020); Shaw et al. (2021); Oren et al. (2020); Keysers et al. (2020)\n1Our dataset is available at https://github.com/ygan/SpiderDK.\nshow that the generalization performance is much worse in more challenging\u2026"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "0b3863c21a7fb5ac61a447611cba0ec9ce1ab4a4",
                "externalIds": {
                    "ArXiv": "2109.05157",
                    "DBLP": "journals/corr/abs-2109-05157",
                    "ACL": "2021.emnlp-main.702",
                    "DOI": "10.18653/v1/2021.emnlp-main.702",
                    "CorpusId": 237491444
                },
                "corpusId": 237491444,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/0b3863c21a7fb5ac61a447611cba0ec9ce1ab4a4",
                "title": "Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization",
                "abstract": "Recently, there has been significant progress in studying neural networks for translating text descriptions into SQL queries under the zero-shot cross-domain setting. Despite achieving good performance on some public benchmarks, we observe that existing text-to-SQL models do not generalize when facing domain knowledge that does not frequently appear in the training data, which may render the worse prediction performance for unseen domains. In this work, we investigate the robustness of text-to-SQL models when the questions require rarely observed domain knowledge. In particular, we define five types of domain knowledge and introduce Spider-DK (DK is the abbreviation of domain knowledge), a human-curated dataset based on the Spider benchmark for text-to-SQL translation. NL questions in Spider-DK are selected from Spider, and we modify some samples by adding domain knowledge that reflects real-world question paraphrases. We demonstrate that the prediction accuracy dramatically drops on samples that require such domain knowledge, even if the domain knowledge appears in the training set, and the model provides the correct predictions for related training samples.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "120624606",
                        "name": "Yujian Gan"
                    },
                    {
                        "authorId": "1425082935",
                        "name": "Xinyun Chen"
                    },
                    {
                        "authorId": "1701461",
                        "name": "Matthew Purver"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We use the same serialization scheme used by Shaw et al. (2021).",
                "We are encouraged by results by Shaw et al. (2021), who showed that a pre-trained T5-Base or T5-3B model can not only learn the text-toSQL task, but also generalize to unseen databases, and even that T5-3B can be competitive with the then-state-of-the-art (Choi et al., 2021; Wang et al., 2020)\u2014all\u2026",
                "Our reproductions of Shaw et al. (2021)\u2019s results with T5 cannot compete with the current state of the art on Spider."
            ],
            "isInfluential": true,
            "intents": [
                "result",
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5fbcfccd3736969d95ed660d8e6962c86b7a9113",
                "externalIds": {
                    "ACL": "2021.emnlp-main.779",
                    "DBLP": "conf/emnlp/ScholakSB21",
                    "ArXiv": "2109.05093",
                    "DOI": "10.18653/v1/2021.emnlp-main.779",
                    "CorpusId": 237491759
                },
                "corpusId": 237491759,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/5fbcfccd3736969d95ed660d8e6962c86b7a9113",
                "title": "PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models",
                "abstract": "Large pre-trained language models for textual data have an unconstrained output space; at each decoding step, they can produce any of 10,000s of sub-word tokens. When fine-tuned to target constrained formal languages like SQL, these models often generate invalid code, rendering it unusable. We propose PICARD (code available at https://github.com/ElementAI/picard), a method for constraining auto-regressive decoders of language models through incremental parsing. PICARD helps to find valid output sequences by rejecting inadmissible tokens at each decoding step. On the challenging Spider and CoSQL text-to-SQL translation tasks, we show that PICARD transforms fine-tuned T5 models with passable performance into state-of-the-art solutions.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "11869783",
                        "name": "Torsten Scholak"
                    },
                    {
                        "authorId": "74530494",
                        "name": "Nathan Schucher"
                    },
                    {
                        "authorId": "3335364",
                        "name": "Dzmitry Bahdanau"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026model architectures (Li et al., 2019; Gordon et al., 2020; Guo et al., 2020b; Oren et al., 2020; Zheng and Lapata, 2020; Herzig and Berant, 2021; Shaw et al., 2020), pre-trained language models (Furrer et al., 2020), intermediate representations (Herzig et al., 2021), and meta learning (Lake,\u2026",
                "Recently, Keysers et al. (2020) and Shaw et al. (2020) used the notion of sub-structures, to construct a compositional test set."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "676fa805bd715591f99bb17e36d673a6a14e92fe",
                "externalIds": {
                    "ACL": "2021.emnlp-main.843",
                    "DBLP": "conf/emnlp/OrenHB21",
                    "ArXiv": "2109.02575",
                    "DOI": "10.18653/v1/2021.emnlp-main.843",
                    "CorpusId": 237420426
                },
                "corpusId": 237420426,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/676fa805bd715591f99bb17e36d673a6a14e92fe",
                "title": "Finding needles in a haystack: Sampling Structurally-diverse Training Sets from Synthetic Data for Compositional Generalization",
                "abstract": "Modern semantic parsers suffer from two principal limitations. First, training requires expensive collection of utterance-program pairs. Second, semantic parsers fail to generalize at test time to new compositions/structures that have not been observed during training. Recent research has shown that automatic generation of synthetic utterance-program pairs can alleviate the first problem, but its potential for the second has thus far been under-explored. In this work, we investigate automatic generation of synthetic utterance-program pairs for improving compositional generalization in semantic parsing. Given a small training set of annotated examples and an \u201cinfinite\u201d pool of synthetic examples, we select a subset of synthetic examples that are structurally-diverse and use them to improve compositional generalization. We evaluate our approach on a new split of the schema2QA dataset, and show that it leads to dramatic improvements in compositional generalization as well as moderate improvements in the traditional i.i.d setup. Moreover, structurally-diverse sampling achieves these improvements with as few as 5K examples, compared to 1M examples when sampling uniformly at random \u2013 a 200x improvement in data efficiency.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1994235702",
                        "name": "I. Oren"
                    },
                    {
                        "authorId": "47426264",
                        "name": "Jonathan Herzig"
                    },
                    {
                        "authorId": "2125719901",
                        "name": "Jonathan Berant"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There has since been a large body of work on compositional sequence-tosequence learning through various approaches including modifications to existing architectures [70, 94, 44, 17, 26], grammars and neuro-symbolic models [86, 98, 85, 19, 76], meta-learning [67, 25], and data augmentation [6, 49, 50, 4].",
                "Our approach is closely related to NQG-T5 [98] which uses a rules-based approach to induce a non-probabilistic QCFG and then backs off to a flexible sequence-to-sequence model during prediction if the grammar cannot parse the input sequence."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "b7b97fff93bcd32aa2d1c9bc1acc3827bb3d4347",
                "externalIds": {
                    "ArXiv": "2109.01135",
                    "DBLP": "journals/corr/abs-2109-01135",
                    "CorpusId": 237385685
                },
                "corpusId": 237385685,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b7b97fff93bcd32aa2d1c9bc1acc3827bb3d4347",
                "title": "Sequence-to-Sequence Learning with Latent Neural Grammars",
                "abstract": "Sequence-to-sequence learning with neural networks has become the de facto standard for sequence prediction tasks. This approach typically models the local distribution over the next word with a powerful neural network that can condition on arbitrary context. While flexible and performant, these models often require large datasets for training and can fail spectacularly on benchmarks designed to test for compositional generalization. This work explores an alternative, hierarchical approach to sequence-to-sequence learning with quasi-synchronous grammars, where each node in the target tree is transduced by a node in the source tree. Both the source and target trees are treated as latent and induced during training. We develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. We apply this latent neural grammar to various domains -- a diagnostic language navigation task designed to test for compositional generalization (SCAN), style transfer, and small-scale machine translation -- and find that it performs respectably compared to standard baselines.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "152847918",
                        "name": "Yoon Kim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In fact, the existing SCAN-inspired solutions have limited performance gains on other datasets (Furrer et al., 2020; Shaw et al., 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "ed535e93d5b5a8b689e861e9c6083a806d1535c2",
                "externalIds": {
                    "ArXiv": "2108.12284",
                    "DBLP": "journals/corr/abs-2108-12284",
                    "ACL": "2021.emnlp-main.49",
                    "DOI": "10.18653/v1/2021.emnlp-main.49",
                    "CorpusId": 237346897
                },
                "corpusId": 237346897,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/ed535e93d5b5a8b689e861e9c6083a806d1535c2",
                "title": "The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers",
                "abstract": "Recently, many datasets have been proposed to test the systematic generalization ability of neural networks. The companion baseline Transformers, typically trained with default hyper-parameters from standard tasks, are shown to fail dramatically. Here we demonstrate that by revisiting model configurations as basic as scaling of embeddings, early stopping, relative positional embedding, and Universal Transformer variants, we can drastically improve the performance of Transformers on systematic generalization. We report improvements on five popular datasets: SCAN, CFQ, PCFG, COGS, and Mathematics dataset. Our models improve accuracy from 50% to 85% on the PCFG productivity split, and from 35% to 81% on COGS. On SCAN, relative positional embedding largely mitigates the EOS decision problem (Newman et al., 2020), yielding 100% accuracy on the length split with a cutoff at 26. Importantly, performance differences between these models are typically invisible on the IID data split. This calls for proper generalization validation sets for developing neural networks that generalize systematically. We publicly release the code to reproduce our results.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3190548",
                        "name": "R. Csord\u00e1s"
                    },
                    {
                        "authorId": "2350348",
                        "name": "Kazuki Irie"
                    },
                    {
                        "authorId": "145341374",
                        "name": "J. Schmidhuber"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Although some related work managed to improve compositional generalization on general semantic parsing tasks [113], [114], there is few work investigating this topic on complex KBQA task."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "7088e2b21e88b698ae5ed38008c46fa170c6e987",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-06688",
                    "ArXiv": "2108.06688",
                    "DOI": "10.1109/TKDE.2022.3223858",
                    "CorpusId": 237091715
                },
                "corpusId": 237091715,
                "publicationVenue": {
                    "id": "c6840156-ee10-4d78-8832-7f8909811576",
                    "name": "IEEE Transactions on Knowledge and Data Engineering",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Knowl Data Eng"
                    ],
                    "issn": "1041-4347",
                    "url": "https://www.computer.org/web/tkde",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=69"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7088e2b21e88b698ae5ed38008c46fa170c6e987",
                "title": "Complex Knowledge Base Question Answering: A Survey",
                "abstract": "Knowledge base question answering (KBQA) aims to answer a question over a knowledge base (KB). Early studies mainly focused on answering simple questions over KBs and achieved great success. However, their performances on complex questions are still far from satisfactory. Therefore, in recent years, researchers propose a large number of novel methods, which looked into the challenges of answering complex questions. In this survey, we review recent advances in KBQA with the focus on solving complex questions, which usually contain multiple subjects, express compound relations, or involve numerical operations. In detail, we begin with introducing the complex KBQA task and relevant background. Then, we present two mainstream categories of methods for complex KBQA, namely semantic parsing-based (SP-based) methods and information retrieval-based (IR-based) methods. Specifically, we illustrate their procedures with flow designs and discuss their difference and similarity. Next, we summarize the challenges that these two categories of methods encounter when answering complex questions, and explicate advanced solutions as well as techniques used in existing work. After that, we discuss the potential impact of pre-trained language models (PLMs) on complex KBQA. To help readers catch up with SOTA methods, we also provide a comprehensive evaluation and resource about complex KBQA task. Finally, we conclude and discuss several promising directions related to complex KBQA for future research.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3458560",
                        "name": "Yunshi Lan"
                    },
                    {
                        "authorId": "51149404",
                        "name": "Gaole He"
                    },
                    {
                        "authorId": "2118240359",
                        "name": "Jinhao Jiang"
                    },
                    {
                        "authorId": "144924128",
                        "name": "Jing Jiang"
                    },
                    {
                        "authorId": "2542603",
                        "name": "Wayne Xin Zhao"
                    },
                    {
                        "authorId": "153693432",
                        "name": "Ji-rong Wen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Such studies typically focus on either MT (Lake and Baroni, 2018; Raunak et al., 2019; Li et al., 2021) or semantic parsing (Finegan-Dollak et al., 2018; Keysers et al., 2019; Kim and Linzen, 2020; Shaw et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "b3f644a5ea1fdd8cec1c34ebed69125838a50de3",
                "externalIds": {
                    "ACL": "2022.acl-long.286",
                    "DBLP": "conf/acl/DankersBH22",
                    "ArXiv": "2108.05885",
                    "DOI": "10.18653/v1/2022.acl-long.286",
                    "CorpusId": 236987160
                },
                "corpusId": 236987160,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/b3f644a5ea1fdd8cec1c34ebed69125838a50de3",
                "title": "The Paradox of the Compositionality of Natural Language: A Neural Machine Translation Case Study",
                "abstract": "Obtaining human-like performance in NLP is often argued to require compositional generalisation. Whether neural networks exhibit this ability is usually studied by training models on highly compositional synthetic data. However, compositionality in natural language is much more complex than the rigid, arithmetic-like version such data adheres to, and artificial compositionality tests thus do not allow us to determine how neural models deal with more realistic forms of compositionality. In this work, we re-instantiate three compositionality tests from the literature and reformulate them for neural machine translation (NMT).Our results highlight that: i) unfavourably, models trained on more data are more compositional; ii) models are sometimes less compositional than expected, but sometimes more, exemplifying that different levels of compositionality are required, and models are not always able to modulate between them correctly; iii) some of the non-compositional behaviours are mistakes, whereas others reflect the natural variation in data. Apart from an empirical study, our work is a call to action: we should rethink the evaluation of compositionality in neural networks and develop benchmarks using real data to evaluate compositionality on natural language, where composing meaning is not as straightforward as doing the math.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "74461595",
                        "name": "Verna Dankers"
                    },
                    {
                        "authorId": "2552871",
                        "name": "Elia Bruni"
                    },
                    {
                        "authorId": "3449411",
                        "name": "D. Hupkes"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[10] claim that the SCAN benchmark does not correlate well with non-synthetic data, and argue that most research on compositional generalization focuses on specialized architectures that introduce strong compositional biases."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "d839256cf7445748c4cf7354d2c6a1ff94efb694",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-02319",
                    "ArXiv": "2108.02319",
                    "DOI": "10.1109/IJCNN52387.2021.9534275",
                    "CorpusId": 236924338
                },
                "corpusId": 236924338,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/d839256cf7445748c4cf7354d2c6a1ff94efb694",
                "title": "Generalization in Multimodal Language Learning from Simulation",
                "abstract": "Neural networks can be powerful function approximators, which are able to model high-dimensional feature distributions from a subset of examples drawn from the target distribution. Naturally, they perform well at generalizing within the limits of their target function, but they often fail to generalize outside of the explicitly learned feature space. It is therefore an open research topic whether and how neural network-based architectures can be deployed for systematic reasoning. Many studies have shown evidence for poor generalization, but they often work with abstract data or are limited to single-channel input. Humans, however, learn and interact through a combination of multiple sensory modalities, and rarely rely on just one. To investigate compositional generalization in a multimodal setting, we generate an extensible dataset with multimodal input sequences from simulation. We investigate the influence of the underlying training data distribution on compostional generalization in a minimal LSTM-based network trained in a supervised, time continuous setting. We find compositional generalization to fail in simple setups while improving with the number of objects, actions, and particularly with a lot of color overlaps between objects. Furthermore, multimodality strongly improves compositional generalization in settings where a pure vision model struggles to generalize.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2122778864",
                        "name": "Aaron Eisermann"
                    },
                    {
                        "authorId": "39061055",
                        "name": "Jae Hee Lee"
                    },
                    {
                        "authorId": "1798067",
                        "name": "C. Weber"
                    },
                    {
                        "authorId": "1736513",
                        "name": "S. Wermter"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2020), language modeling (Andreas, 2020; Shaw et al., 2020), and text generation (Feng et al."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "013eb12ce5468f79d58bf859653f4929c5a2bd14",
                "externalIds": {
                    "ArXiv": "2106.07499",
                    "DBLP": "journals/corr/abs-2106-07499",
                    "ACL": "2023.tacl-1.12",
                    "DOI": "10.1162/tacl_a_00542",
                    "CorpusId": 235422524
                },
                "corpusId": 235422524,
                "publicationVenue": {
                    "id": "f613fad9-da81-41c5-841d-e2c01b5d33cb",
                    "name": "International Conference on Topology, Algebra and Categories in Logic",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Topol Algebra Category Log"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/013eb12ce5468f79d58bf859653f4929c5a2bd14",
                "title": "An Empirical Survey of Data Augmentation for Limited Data Learning in NLP",
                "abstract": "NLP has achieved great progress in the past decade through the use of neural models and large labeled datasets. The dependence on abundant data prevents NLP models from being applied to low-resource settings or novel tasks where significant time, money, or expertise is required to label massive amounts of textual data. Recently, data augmentation methods have been explored as a means of improving data efficiency in NLP. To date, there has been no systematic empirical overview of data augmentation for NLP in the limited labeled data setting, making it difficult to understand which methods work in which settings. In this paper, we provide an empirical survey of recent progress on data augmentation for NLP in the limited labeled data setting, summarizing the landscape of methods (including token-level augmentations, sentence-level augmentations, adversarial augmentations, and hidden-space augmentations) and carrying out experiments on 11 datasets covering topics/news classification, inference tasks, paraphrasing tasks, and single-sentence tasks. Based on the results, we draw several conclusions to help practitioners choose appropriate augmentations in different settings and discuss the current challenges and future directions for limited data learning in NLP.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "47739850",
                        "name": "Jiaao Chen"
                    },
                    {
                        "authorId": "1390031652",
                        "name": "Derek Tam"
                    },
                    {
                        "authorId": "2402716",
                        "name": "Colin Raffel"
                    },
                    {
                        "authorId": "143977268",
                        "name": "Mohit Bansal"
                    },
                    {
                        "authorId": "2143919864",
                        "name": "Diyi Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Thus, following Shaw et al. (2020), we use a general-purpose pretrained sequence-to-sequence model, T5 (Raffel et al., 2020), which was shown to be competitive with Spider\u2019s state-of-the-art models."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "67e8e2d3b276c339588b9551e6b20cd62ebdda7c",
                "externalIds": {
                    "ACL": "2021.nlp4prog-1.9",
                    "DBLP": "journals/corr/abs-2106-05006",
                    "ArXiv": "2106.05006",
                    "DOI": "10.18653/v1/2021.nlp4prog-1.9",
                    "CorpusId": 235377010
                },
                "corpusId": 235377010,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/67e8e2d3b276c339588b9551e6b20cd62ebdda7c",
                "title": "Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data",
                "abstract": "Most available semantic parsing datasets, comprising of pairs of natural utterances and logical forms, were collected solely for the purpose of training and evaluation of natural language understanding systems. As a result, they do not contain any of the richness and variety of natural-occurring utterances, where humans ask about data they need or are curious about. In this work, we release SEDE, a dataset with 12,023 pairs of utterances and SQL queries collected from real usage on the Stack Exchange website. We show that these pairs contain a variety of real-world challenges which were rarely reflected so far in any other semantic parsing dataset, propose an evaluation metric based on comparison of partial query clauses that is more suitable for real-world queries, and conduct experiments with strong baselines, showing a large gap between the performance on SEDE compared to other common datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3294447",
                        "name": "Moshe Hazoom"
                    },
                    {
                        "authorId": "2108693624",
                        "name": "Vibhor Malik"
                    },
                    {
                        "authorId": "50757607",
                        "name": "Ben Bogin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "70a136547d81290b9f4dbc1fac49d31bc010bd3c",
                "externalIds": {
                    "ACL": "2021.acl-long.258",
                    "DBLP": "conf/acl/ConklinWST20",
                    "ArXiv": "2106.04252",
                    "DOI": "10.18653/v1/2021.acl-long.258",
                    "CorpusId": 235367710
                },
                "corpusId": 235367710,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/70a136547d81290b9f4dbc1fac49d31bc010bd3c",
                "title": "Meta-Learning to Compositionally Generalize",
                "abstract": "Natural language is compositional; the meaning of a sentence is a function of the meaning of its parts. This property allows humans to create and interpret novel sentences, generalizing robustly outside their prior experience. Neural networks have been shown to struggle with this kind of generalization, in particular performing poorly on tasks designed to assess compositional generalization (i.e. where training and testing distributions differ in ways that would be trivial for a compositional strategy to resolve). Their poor performance on these tasks may in part be due to the nature of supervised learning which assumes training and testing data to be drawn from the same distribution. We implement a meta-learning augmented version of supervised learning whose objective directly optimizes for out-of-distribution generalization. We construct pairs of tasks for meta-learning by sub-sampling existing training data. Each pair of tasks is constructed to contain relevant examples, as determined by a similarity metric, in an effort to inhibit models from memorizing their input. Experimental results on the COGS and SCAN datasets show that our similarity-driven meta-learning can improve generalization performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2107677996",
                        "name": "Henry Conklin"
                    },
                    {
                        "authorId": "2118640406",
                        "name": "Bailin Wang"
                    },
                    {
                        "authorId": "3054578",
                        "name": "Kenny Smith"
                    },
                    {
                        "authorId": "144889265",
                        "name": "Ivan Titov"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Neural semantic parsing is more promising for coverage but is still brittle in real-world applications where queries can involve novel compositions of learned patterns (Finegan-Dollak et al., 2018; Shaw et al., 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4f05aba9dea39063c77f3f186aab4547dde2993e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-04559",
                    "ACL": "2021.acl-demo.36",
                    "ArXiv": "2106.04559",
                    "DOI": "10.18653/v1/2021.acl-demo.36",
                    "CorpusId": 235368091
                },
                "corpusId": 235368091,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/4f05aba9dea39063c77f3f186aab4547dde2993e",
                "title": "TURING: an Accurate and Interpretable Multi-Hypothesis Cross-Domain Natural Language Database Interface",
                "abstract": "A natural language database interface (NLDB) can democratize data-driven insights for non-technical users. However, existing Text-to-SQL semantic parsers cannot achieve high enough accuracy in the cross-database setting to allow good usability in practice. This work presents TURING, a NLDB system toward bridging this gap. The cross-domain semantic parser of TURING with our novel value prediction method achieves 75.1% execution accuracy, and 78.3% top-5 beam execution accuracy on the Spider validation set (Yu et al., 2018b). To benefit from the higher beam accuracy, we design an interactive system where the SQL hypotheses in the beam are explained step-by-step in natural language, with their differences highlighted. The user can then compare and judge the hypotheses to select which one reflects their intention if any. The English explanations of SQL queries in TURING are produced by our high-precision natural language generation system based on synchronous grammars.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145612634",
                        "name": "Peng Xu"
                    },
                    {
                        "authorId": "2088910563",
                        "name": "Wenjie Zi"
                    },
                    {
                        "authorId": "1387982258",
                        "name": "H. Shahidi"
                    },
                    {
                        "authorId": "1400413081",
                        "name": "'Akos K'ad'ar"
                    },
                    {
                        "authorId": "1995851674",
                        "name": "Keyi Tang"
                    },
                    {
                        "authorId": "144205313",
                        "name": "Wei Yang"
                    },
                    {
                        "authorId": "8467956",
                        "name": "Jawad Ateeq"
                    },
                    {
                        "authorId": "82258487",
                        "name": "Harsh Barot"
                    },
                    {
                        "authorId": "2107696510",
                        "name": "Meidan Alon"
                    },
                    {
                        "authorId": "2902068",
                        "name": "Yanshuai Cao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Grammars have proven essential in statistical semantic parsing in the pre-neural era [51, 57], and have gained renewed interest now as a means of achieving systematic generalization [18, 41].",
                "Thus, our model bridges the gap between conventional seq2seq models and specialized state-of-the-art grammar-based models [18, 41].",
                "6 We use the varaible-free form, as opposed to other alternatives such lambda calculus, for two reasons: 1) variable-free programs have been commonly used in systematic generalization settings [18, 41], probably it is easier to construct generalization splits using this form; 2) the variable-free form is more suitable for modeling alignments since variables in programs usually make alignments hard to define."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "c0e059c46aea358872b4760aed53c4da3beaaeee",
                "externalIds": {
                    "ArXiv": "2106.03257",
                    "DBLP": "conf/nips/WangLT21",
                    "CorpusId": 235358760
                },
                "corpusId": 235358760,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/c0e059c46aea358872b4760aed53c4da3beaaeee",
                "title": "Structured Reordering for Modeling Latent Alignments in Sequence Transduction",
                "abstract": "Despite success in many domains, neural models struggle in settings where train and test examples are drawn from different distributions. In particular, in contrast to humans, conventional sequence-to-sequence (seq2seq) models fail to generalize systematically, i.e., interpret sentences representing novel combinations of concepts (e.g., text segments) seen in training. Traditional grammar formalisms excel in such settings by implicitly encoding alignments between input and output segments, but are hard to scale and maintain. Instead of engineering a grammar, we directly model segment-to-segment alignments as discrete structured latent variables within a neural seq2seq model. To efficiently explore the large space of alignments, we introduce a reorder-first align-later framework whose central component is a neural reordering module producing {\\it separable} permutations. We present an efficient dynamic programming algorithm performing exact marginal inference of separable permutations, and, thus, enabling end-to-end differentiable training of our model. The resulting seq2seq model exhibits better systematic generalization than standard models on synthetic problems and NLP tasks (i.e., semantic parsing and machine translation).",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118640406",
                        "name": "Bailin Wang"
                    },
                    {
                        "authorId": "1747893",
                        "name": "Mirella Lapata"
                    },
                    {
                        "authorId": "144889265",
                        "name": "Ivan Titov"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Pre-trained encoder-decoder transformer models such as BART (Lewis et al., 2020a) and T5 (Raffel et al., 2020) have enjoyed dramatic success on semantic parsing (Lin et al., 2018; Hwang et al., 2019; Shaw et al., 2020; Suhr et al., 2020).",
                ", 2020) have enjoyed dramatic success on semantic parsing (Lin et al., 2018; Hwang et al., 2019; Shaw et al., 2020; Suhr et al., 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a07a94168608322600fd3cab54df1410b96852b6",
                "externalIds": {
                    "DBLP": "conf/emnlp/DasZTGPLTPM21",
                    "ACL": "2021.emnlp-main.755",
                    "ArXiv": "2104.08762",
                    "DOI": "10.18653/v1/2021.emnlp-main.755",
                    "CorpusId": 233296655
                },
                "corpusId": 233296655,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/a07a94168608322600fd3cab54df1410b96852b6",
                "title": "Case-based Reasoning for Natural Language Queries over Knowledge Bases",
                "abstract": "It is often challenging to solve a complex problem from scratch, but much easier if we can access other similar problems with their solutions \u2014 a paradigm known as case-based reasoning (CBR). We propose a neuro-symbolic CBR approach (CBR-KBQA) for question answering over large knowledge bases. CBR-KBQA consists of a nonparametric memory that stores cases (question and logical forms) and a parametric model that can generate a logical form for a new question by retrieving cases that are relevant to it. On several KBQA datasets that contain complex questions, CBR-KBQA achieves competitive performance. For example, on the CWQ dataset, CBR-KBQA outperforms the current state of the art by 11% on accuracy. Furthermore, we show that CBR-KBQA is capable of using new cases without any further training: by incorporating a few human-labeled examples in the case memory, CBR-KBQA is able to successfully generate logical forms containing unseen KB entities as well as relations.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "143863023",
                        "name": "R. Das"
                    },
                    {
                        "authorId": "1771307",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "2064894364",
                        "name": "Dung Ngoc Thai"
                    },
                    {
                        "authorId": "36851489",
                        "name": "Ameya Godbole"
                    },
                    {
                        "authorId": "3439053",
                        "name": "Ethan Perez"
                    },
                    {
                        "authorId": "1520031992",
                        "name": "Jay Yoon Lee"
                    },
                    {
                        "authorId": "2087344242",
                        "name": "Lizhen Tan"
                    },
                    {
                        "authorId": "1725498",
                        "name": "L. Polymenakos"
                    },
                    {
                        "authorId": "143753639",
                        "name": "A. McCallum"
                    }
                ]
            }
        },
        {
            "contexts": [
                "performance in general remains a significant challenge (Shaw et al., 2020; Furrer et al., 2020).",
                ", 2020; Herzig and Berant, 2020), hybrid models (Shaw et al., 2020), meta-learning (Lake, 2019), and compositional data augmentation (Andreas, 2020).",
                "\u2026(Li et al., 2019; Russin et al., 2019; Gordon et al., 2020; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020; Zheng and Lapata, 2020; Oren et al., 2020; Herzig and Berant, 2020), hybrid models (Shaw et al., 2020), meta-learning (Lake, 2019), and compositional data augmentation (Andreas, 2020).",
                "For both our T5 baseline and LIRd+RIR, further increasing model capacity beyond T5-base does not give further improvements, which is consistent with previous work on similar tasks with small train set sizes (Shaw et al., 2020; Furrer et al., 2020).",
                "\u2026Chen et al., 2020, inter alia) and general-purpose pre-trained seq2seq models such as T5 (Raffel et al., 2020) have shown improvements on some evaluations of compositional generalization, but strong performance in general remains a significant challenge (Shaw et al., 2020; Furrer et al., 2020).",
                "our T5 baseline and LIRd+RIR, further increasing model capacity beyond T5-base does not give further improvements, which is consistent with previous work on similar tasks with small train set sizes (Shaw et al., 2020; Furrer et al., 2020)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "result"
            ],
            "citingPaper": {
                "paperId": "2040baf092ba73dfdffd97ae467e38ac0470520d",
                "externalIds": {
                    "ArXiv": "2104.07478",
                    "DBLP": "journals/corr/abs-2104-07478",
                    "CorpusId": 233240659
                },
                "corpusId": 233240659,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2040baf092ba73dfdffd97ae467e38ac0470520d",
                "title": "Unlocking Compositional Generalization in Pre-trained Models Using Intermediate Representations",
                "abstract": "Sequence-to-sequence (seq2seq) models are prevalent in semantic parsing, but have been found to struggle at out-of-distribution compositional generalization. While specialized model architectures and pre-training of seq2seq models have been proposed to address this issue, the former often comes at the cost of generality and the latter only shows limited success. In this paper, we study the impact of intermediate representations on compositional generalization in pre-trained seq2seq models, without changing the model architecture at all, and identify key aspects for designing effective representations. Instead of training to directly map natural language to an executable form, we map to a reversible or lossy intermediate representation that has stronger structural correspondence with natural language. The combination of our proposed intermediate representations and pre-trained models is surprisingly effective, where the best combinations obtain a new state-of-the-art on CFQ (+14.8 accuracy points) and on the template-splits of three text-to-SQL datasets (+15.0 to +19.4 accuracy points). This work highlights that intermediate representations provide an important and potentially overlooked degree of freedom for improving the compositional generalization abilities of pre-trained seq2seq models.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "47426264",
                        "name": "Jonathan Herzig"
                    },
                    {
                        "authorId": "38759328",
                        "name": "Peter Shaw"
                    },
                    {
                        "authorId": "1744179",
                        "name": "Ming-Wei Chang"
                    },
                    {
                        "authorId": "2091768",
                        "name": "Kelvin Guu"
                    },
                    {
                        "authorId": "2616463",
                        "name": "Panupong Pasupat"
                    },
                    {
                        "authorId": "1703465",
                        "name": "Yuan Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2019c) can significantly boost parsing accuracy by enhancing generalization over natural language variations and capturing long-term dependencies (Shaw et al., 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "232b40980acb55afa89ec50dd9806a5e551f699b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2012-12627",
                    "ArXiv": "2012.12627",
                    "ACL": "2020.findings-emnlp.438",
                    "MAG": "3103801878",
                    "DOI": "10.18653/v1/2020.findings-emnlp.438",
                    "CorpusId": 226283779
                },
                "corpusId": 226283779,
                "publicationVenue": {
                    "id": "479d5605-51be-4346-b1d6-4334084504df",
                    "name": "Findings",
                    "type": "journal",
                    "issn": "2652-8800",
                    "url": "https://findingspress.org/"
                },
                "url": "https://www.semanticscholar.org/paper/232b40980acb55afa89ec50dd9806a5e551f699b",
                "title": "Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic Parsing",
                "abstract": "We present BRIDGE, a powerful sequential architecture for modeling dependencies between natural language questions and relational databases in cross-DB semantic parsing. BRIDGE represents the question and DB schema in a tagged sequence where a subset of the fields are augmented with cell values mentioned in the question. The hybrid sequence is encoded by BERT with minimal subsequent layers and the text-DB contextualization is realized via the fine-tuned deep attention in BERT. Combined with a pointer-generator decoder with schema-consistency driven search space pruning, BRIDGE attained state-of-the-art performance on the well-studied Spider benchmark (65.5% dev, 59.2% test), despite being much simpler than most recently proposed models for this task. Our analysis shows that BRIDGE effectively captures the desired cross-modal dependencies and has the potential to generalize to more text-DB related tasks. Our model implementation is available at https://github.com/ salesforce/TabularSemanticParsing.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "143724481",
                        "name": "Xi Victoria Lin"
                    },
                    {
                        "authorId": "2166511",
                        "name": "R. Socher"
                    },
                    {
                        "authorId": "2228109",
                        "name": "Caiming Xiong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Finally, concurrently to us, Shaw et al. (2020) induced a synchronous grammar over program and utterance pairs and used it to introduce a compositional bias, showing certain improvements over compositional splits."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "307ec233777755b3d89b2096f4b54c83d9cd80ba",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2009-06040",
                    "ACL": "2021.acl-long.74",
                    "MAG": "3086307406",
                    "ArXiv": "2009.06040",
                    "DOI": "10.18653/v1/2021.acl-long.74",
                    "CorpusId": 221655744
                },
                "corpusId": 221655744,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/307ec233777755b3d89b2096f4b54c83d9cd80ba",
                "title": "Span-based Semantic Parsing for Compositional Generalization",
                "abstract": "Despite the success of sequence-to-sequence (seq2seq) models in semantic parsing, recent work has shown that they fail in compositional generalization, i.e., the ability to generalize to new structures built of components observed during training. In this work, we posit that a span-based parser should lead to better compositional generalization. we propose SpanBasedSP, a parser that predicts a span tree over an input utterance, explicitly encoding how partial programs compose over spans in the input. SpanBasedSP extends Pasupat et al. (2019) to be comparable to seq2seq models by (i) training from programs, without access to gold trees, treating trees as latent variables, (ii) parsing a class of non-projective trees through an extension to standard CKY. On GeoQuery, SCAN and CLOSURE datasets, SpanBasedSP performs similarly to strong seq2seq baselines on random splits, but dramatically improves performance compared to baselines on splits that require compositional generalization: from 61.0 \u2192 88.9 average accuracy.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "47426264",
                        "name": "Jonathan Herzig"
                    },
                    {
                        "authorId": "1750652",
                        "name": "Jonathan Berant"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following previous works, we conduct the \u201cproductivity\u201d experiment (Lake and Baroni, 2018; Shaw et al., 2021), which focuses on generalization to longer sequences or to greater compositional depths than have been seen in training (for example, from a length 4 program to a length 5 program)."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "2aa1d4350e80613feed88d5a6337e79693f7aa57",
                "externalIds": {
                    "DBLP": "conf/acl/CaoSPNX0LHZ22",
                    "ACL": "2022.acl-long.422",
                    "ArXiv": "2007.03875",
                    "DOI": "10.18653/v1/2022.acl-long.422",
                    "CorpusId": 247362971
                },
                "corpusId": 247362971,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/2aa1d4350e80613feed88d5a6337e79693f7aa57",
                "title": "KQA Pro: A Dataset with Explicit Compositional Programs for Complex Question Answering over Knowledge Base",
                "abstract": "Complex question answering over knowledge base (Complex KBQA) is challenging because it requires various compositional reasoning capabilities, such as multi-hop inference, attribute comparison, set operation, etc. Existing benchmarks have some shortcomings that limit the development of Complex KBQA: 1) they only provide QA pairs without explicit reasoning processes; 2) questions are poor in diversity or scale. To this end, we introduce KQA Pro, a dataset for Complex KBQA including around 120K diverse natural language questions. We introduce a compositional and interpretable programming language KoPL to represent the reasoning process of complex questions. For each question, we provide the corresponding KoPL program and SPARQL query, so that KQA Pro can serve for both KBQA and semantic parsing tasks. Experimental results show that state-of-the-art KBQA methods cannot achieve promising results on KQA Pro as on current datasets, which suggests that KQA Pro is challenging and Complex KBQA requires further research efforts. We also treat KQA Pro as a diagnostic dataset for testing multiple reasoning skills, conduct a thorough evaluation of existing models and discuss further directions for Complex KBQA. Our codes and datasets can be obtained from https://github.com/shijx12/KQAPro_Baselines.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1712738522",
                        "name": "S. Cao"
                    },
                    {
                        "authorId": "2522647",
                        "name": "Jiaxin Shi"
                    },
                    {
                        "authorId": "3470231",
                        "name": "Liangming Pan"
                    },
                    {
                        "authorId": "115361209",
                        "name": "L. Nie"
                    },
                    {
                        "authorId": "2068340987",
                        "name": "Yutong Xiang"
                    },
                    {
                        "authorId": "145779862",
                        "name": "Lei Hou"
                    },
                    {
                        "authorId": "2133353675",
                        "name": "Juanzi Li"
                    },
                    {
                        "authorId": "1631386300",
                        "name": "Bin He"
                    },
                    {
                        "authorId": "2119078220",
                        "name": "Hanwang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u20262020; Oren et al., 2020; Akyurek and Andreas, 2021; Chaabouni et al., 2021), meta-learning (Lake, 2019; Conklin et al., 2021), grammar (Kim, 2021; Shaw et al., 2021), neuro-symbolic models (Chen et al., 2020; Liu et al., 2020; Nye et al., 2020), data augmentation (Andreas, 2020; Aky\u00fcrek et al.,\u2026",
                ", 2021), grammar (Kim, 2021; Shaw et al., 2021), neuro-symbolic models (Chen et al."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "6f0be1f9bda7530b1fa654cac84d595ca9d53740",
                "externalIds": {
                    "DBLP": "conf/blackboxnlp/ShiWWLL22",
                    "ACL": "2022.blackboxnlp-1.6",
                    "ArXiv": "2003.06658",
                    "DOI": "10.18653/v1/2022.blackboxnlp-1.6",
                    "CorpusId": 252968426
                },
                "corpusId": 252968426,
                "publicationVenue": {
                    "id": "738626d7-5b8c-497d-9fd6-64bdb6dbf440",
                    "name": "BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
                    "type": "conference",
                    "alternate_names": [
                        "BlackboxNLP",
                        "Blackboxnlp Workshop Anal Interpr\u00e8t Neural Netw NLP"
                    ],
                    "url": "https://aclanthology.org/venues/blackboxnlp/"
                },
                "url": "https://www.semanticscholar.org/paper/6f0be1f9bda7530b1fa654cac84d595ca9d53740",
                "title": "Revisit Systematic Generalization via Meaningful Learning",
                "abstract": "Humans can systematically generalize to novel compositions of existing concepts. Recent studies argue that neural networks appear inherently ineffective in such cognitive capacity, leading to a pessimistic view and a lack of attention to optimistic results. We revisit this controversial topic from the perspective of meaningful learning, an exceptional capability of humans to learn novel concepts by connecting them with known ones. We reassess the compositional skills of sequence-to-sequence models conditioned on the semantic links between new and old concepts. Our observations suggest that models can successfully one-shot generalize to novel concepts and compositions through semantic linking, either inductively or deductively. We demonstrate that prior knowledge plays a key role as well. In addition to synthetic tests, we further conduct proof-of-concept experiments in machine translation and semantic parsing, showing the benefits of meaningful learning in applications. We hope our positive findings will encourage excavating modern neural networks\u2019 potential in systematic generalization through more advanced learning schemes.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "49402878",
                        "name": "Ning Shi"
                    },
                    {
                        "authorId": "2153207717",
                        "name": "Boxin Wang"
                    },
                    {
                        "authorId": "40397893",
                        "name": "Wei Wang"
                    },
                    {
                        "authorId": "2144225204",
                        "name": "Xiangyu Liu"
                    },
                    {
                        "authorId": "3146592",
                        "name": "Zhouhan Lin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To support Text-to-SQL, similar to [24, 26], we fine-tune the model in an end-to-end manner.",
                "Different from the previous methods with task-specific design, PLM-based methods [24, 26] can be applied to different text-to-SQL datasets without specific modifications to the base PLMs.",
                "Specifically, Picard [24] and [26] also achieve good performance in the few-shot scenario using general PLMs (e.",
                "Transformer-based encoder-decoder models have been widely used to support Text-to-SQL, and representative models include NQG-T5 [26], PICARD [24], UnifiedSKG [34], etc."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "c04b461cc31ea87350c4c0d2dc62d1c836b93ee4",
                "externalIds": {
                    "CorpusId": 259141387
                },
                "corpusId": 259141387,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c04b461cc31ea87350c4c0d2dc62d1c836b93ee4",
                "title": "Few-shot Text-to-SQL Translation using Structure and Content Prompt Learning",
                "abstract": "A common problem with adopting Text-to-SQL translation in database systems is poor generalization. Specifically, when there is limited training data on new datasets, existing few-shot Text-to-SQL techniques, even with carefully designed textual prompts on pre-trained language models (PLMs), tend to be ineffective. In this paper, we present a divide-and-conquer framework to better support few-shot Text-to-SQL translation, which divides Text-to-SQL translation into two stages (or sub-tasks), such that each sub-task is simpler to be tackled. The first stage, called the structure stage , steers a PLM to generate an SQL structure (including SQL commands such as SELECT, FROM, WHERE and SQL operators such as \u201c < \u201d, \u201c > \u201d) with placeholders for missing identifiers. The second stage, called the content stage , guides a PLM to populate the placeholders in the generated SQL structure with concrete values (including SQL identifies such as table names, column names, and constant values). We propose a hybrid prompt strategy that combines learnable vectors and fixed vectors ( i.e., word embeddings of textual prompts), such that the hybrid prompt can learn contextual information to better guide PLMs for prediction in both stages. In addition, we design keyword constrained decoding to ensure the validity of generated SQL structures, and structure guided decoding to guarantee the model to fill correct content. Extensive experiments, by comparing with ten state-of-the-art Text-to-SQL solutions at the time of writing, show that SC-Prompt significantly outperforms them in the few-shot scenario. In particular, on the widely-adopted Spider dataset, given less than 500 labeled training examples (5% of the official training set), SC-Prompt outperforms",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1704755170",
                        "name": "Ju Fan"
                    },
                    {
                        "authorId": "2219964694",
                        "name": "Qcri Hkust Qatar NAN TANG"
                    },
                    {
                        "authorId": "2219964715",
                        "name": "Mit Csail Usa SAM MADDEN"
                    }
                ]
            }
        },
        {
            "contexts": [
                "With the recent advances in pre-trained language models (PLMs), many existing works formulate the Text-to-SQL task as a semantic parsing problem and use a sequence-tosequence (seq2seq) model to solve it (Scholak, Schucher, and Bahdanau 2021; Shi et al. 2021; Shaw et al. 2021).",
                "Following Shaw et al. (2021); Scholak, Schucher, and Bahdanau (2021), we treat Text-to-SQL as a translation task, which can be solved by an encoder-decoder transformer model.",
                "However, even the T5-3B model only achieves about 70% accuracy (Shaw et al. 2021; Scholak, Schucher, and Bahdanau 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a9528ddf85d781877a983bc992af16524b1a6be5",
                "externalIds": {
                    "CorpusId": 256826818
                },
                "corpusId": 256826818,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a9528ddf85d781877a983bc992af16524b1a6be5",
                "title": "Decoupling the Skeleton Parsing and Schema Linking for Text-to-SQL",
                "abstract": "One of the recent best attempts at Text-to-SQL is the pre- trained language model. Due to the structural property of the SQL queries, the seq2seq model takes the responsibility of parsing both the schema items ( i.e. , tables and columns) and the skeleton ( i.e. , SQL keywords). Such coupled targets in-crease the dif\ufb01culty of parsing the correct SQL queries es- pecially when they involve many schema items and logic operators. This paper proposes a ranking-enhanced encod- ing and skeleton-aware decoding framework to decouple the schema linking and the skeleton parsing. Speci\ufb01cally, for a seq2seq encoder-decode model, its encoder is injected by the most relevant schema items instead of the whole un- ordered ones, which could alleviate the schema linking effort during SQL parsing, and its decoder \ufb01rst generates the skeleton and then the actual SQL query, which could implicitly constrain the SQL parsing. We evaluate our pro- posed framework on Spider and its three robustness variants: Spider-DK, Spider-Syn, and Spider-Realistic. The ex- perimental results show that our framework delivers promis-ing performance and robustness. Our code is available at https://github.com/RUCKBReasoning/RESDSQL.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "144911687",
                        "name": "Haoyang Li"
                    },
                    {
                        "authorId": "2155700347",
                        "name": "Jing Zhang"
                    },
                    {
                        "authorId": "1625473962",
                        "name": "Cuiping Li"
                    },
                    {
                        "authorId": "2191043357",
                        "name": "Hong Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Although it is easier to define these distributions for synthetic data, as in the CFQ dataset described by Keysers, it can also be applied to natural data, for example in semantic parsing (Shaw et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "50740be0c5f5349aeda0cfe061b8716e99f18c80",
                "externalIds": {
                    "DBLP": "conf/nodalida/MoisioCK23",
                    "ACL": "2023.nodalida-1.75",
                    "CorpusId": 258765262
                },
                "corpusId": 258765262,
                "publicationVenue": {
                    "id": "e1fe3df7-d2f1-40a5-8885-155f479eb07c",
                    "name": "Nordic Conference of Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "NODALIDA",
                        "Nord Conf Comput Linguistics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/50740be0c5f5349aeda0cfe061b8716e99f18c80",
                "title": "Evaluating Morphological Generalisation in Machine Translation by Distribution-Based Compositionality Assessment",
                "abstract": "Compositional generalisation refers to the ability to understand and generate a potentially infinite number of novel meanings using a finite group of known primitives and a set of rules to combine them. The degree to which artificial neural networks can learn this ability is an open question. Recently, some evaluation methods and benchmarks have been proposed to test compositional generalisation, but not many have focused on the morphological level of language. We propose an application of the previously developed distribution-based compositionality assessment method to assess morphological generalisation in NLP tasks, such as machine translation or paraphrase detection. We demonstrate the use of our method by comparing translation systems with different BPE vocabulary sizes. The evaluation method we propose suggests that small vocabularies help with morphological generalisation in NMT.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "108740247",
                        "name": "Anssi Moisio"
                    },
                    {
                        "authorId": "2219854",
                        "name": "Mathias Creutz"
                    },
                    {
                        "authorId": "1719346",
                        "name": "M. Kurimo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "On the other hand, humans and classical AI algorithms (grammar and search-based systems) are not troubled by compositional tasks [6, 7].",
                "The existing work surrounding compositional generalization includes a variety of approaches including data augmentation [9, 10, 11], Syntactic Attention [12], compositional parsers [6, 13], intermediate representations [14, 15] and structure annotations [7]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "facaf5d9d99af1528d75212691f185b2f6911365",
                "externalIds": {
                    "CorpusId": 259278196
                },
                "corpusId": 259278196,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/facaf5d9d99af1528d75212691f185b2f6911365",
                "title": "Compositional Generalization Based on Semantic Interpretation: Where can Neural Networks Improve?",
                "abstract": "Recent research suggests that compositional generalization in Natural Language processing remains a challenge, even for state-of-the-art neural models such as Transformers. This paper explores various model configurations, techniques, and hyperparameters for the Transformer model to see how we can improve it on compositional generalization tasks. Within the design space of Transformers, we explore various techniques such as the decoding strategy, attention variants, oracle evaluation, and the optimizer type. We find that top-p sampling increases model accuracy across almost all the datasets we used to measure compositional generalization. This suggests that relying solely on greedy decoding can lead to suboptimal results, even in low-entropy tasks such as compositional generalization. Our research shows that because the greedy decoder is more prone to getting stuck in local minima, introducing entropy in the form of top-p sampling can actually be beneficial for the model. Our modified Transformer achieves state-of-the-art results in a semantic parsing compositional generalization benchmark (COGS), which we will publicly release so that one can reproduce our results. These findings could also have broader implications beyond compositional generalization testing, such as in the field of machine translation. 1 Key Information to include \u2022 Mentor: John Hewitt \u2022 External Collaborators (if you have any): None. \u2022 Sharing project: No",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2220770593",
                        "name": "Carolyn Qu"
                    },
                    {
                        "authorId": "2220779710",
                        "name": "Rodrigo Nieto"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "5316cb94704b088b2b091741dfbf49b8bc9755bd",
                "externalIds": {
                    "CorpusId": 259311798
                },
                "corpusId": 259311798,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/5316cb94704b088b2b091741dfbf49b8bc9755bd",
                "title": "Compositional generalization in Neuro-Symbolic Visual Question Answering",
                "abstract": "Compositional generalization is a key challenge in artificial intelligence. This paper investigates compositional generalization capabilities in multimodal mathematical reasoning problems. We introduce compositional generalization splits for CLEVRMath for reasoning hopand attribute generalization, testing both systematicity and productivity. We evaluate the NS-VQA architecture and compare it to two neural baselines, ViLT and CLIP. Our results show that none of the models generalize to longer reasoning chains than trained on, while showing similar patterns on fewer hops. For our compositional generalization split, ViLT and the CLIP-based model performs better then NS-VQA on the objects held out during training. However, all models see a significant drop in performance. For length generalization, we propose that explicitly learning recursive definitions can be important for compositional generalization. We discuss how knowledge-based curriculum learning can help future architectures achieve such capabilities.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2059761581",
                        "name": "Adam Dahlgren Lindstr\u00f6m"
                    },
                    {
                        "authorId": "3420683",
                        "name": "Soham Dan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Compositional Generalization has attracted increasing attention with dedicated datasets (Lake and Baroni, 2018; Keysers et al., 2020a; Kim and Linzen, 2020; Li et al., 2021; Shaw et al., 2021; Dankers et al., 2022)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "7c104fbe5e379b4de17a93682cf925b314de0fc9",
                "externalIds": {
                    "DBLP": "conf/acl/YinZLMZ023",
                    "ACL": "2023.acl-long.72",
                    "DOI": "10.18653/v1/2023.acl-long.72",
                    "CorpusId": 259370677
                },
                "corpusId": 259370677,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/7c104fbe5e379b4de17a93682cf925b314de0fc9",
                "title": "Consistency Regularization Training for Compositional Generalization",
                "abstract": "Existing neural models have difficulty generalizing to unseen combinations of seen components. To achieve compositional generalization, models are required to consistently interpret (sub)expressions across contexts. Without modifying model architectures, we improve the capability of Transformer on compositional generalization through consistency regularization training, which promotes representation consistency across samples and prediction consistency for a single sample. Experimental results on semantic parsing and machine translation benchmarks empirically demonstrate the effectiveness and generality of our method. In addition, we find that the prediction consistency scores on in-distribution validation sets can be an alternative for evaluating models during training, when commonly-used metrics are not informative.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "79701068",
                        "name": "Yongjing Yin"
                    },
                    {
                        "authorId": "50409899",
                        "name": "Jiali Zeng"
                    },
                    {
                        "authorId": "2110450452",
                        "name": "Yafu Li"
                    },
                    {
                        "authorId": "33427918",
                        "name": "Fandong Meng"
                    },
                    {
                        "authorId": "48128428",
                        "name": "Jie Zhou"
                    },
                    {
                        "authorId": "39939186",
                        "name": "Yue Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This model has been shown to have a strong performance on a variety of NLP tasks ranging from classification to generation problems [23, 29, 48]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4da4baab8422143cd8aa5af87ae2234ad087cd69",
                "externalIds": {
                    "DBLP": "conf/uss/KhandelwalNHF23",
                    "CorpusId": 260006167
                },
                "corpusId": 260006167,
                "publicationVenue": {
                    "id": "54649c1d-6bcc-4232-9cd1-aa446867b8d0",
                    "name": "USENIX Security Symposium",
                    "type": "conference",
                    "alternate_names": [
                        "USENIX Secur Symp"
                    ],
                    "url": "http://www.usenix.org/events/bytopic/security.html"
                },
                "url": "https://www.semanticscholar.org/paper/4da4baab8422143cd8aa5af87ae2234ad087cd69",
                "title": "Automated Cookie Notice Analysis and Enforcement",
                "abstract": "Online websites use cookie notices to elicit consent from the users, as required by recent privacy regulations like the GDPR and the CCPA. Prior work has shown that these notices are designed in a way to manipulate users into making website-friendly choices which put users\u2019 privacy at risk. In this work, we present CookieEnforcer , a new system for automatically discovering cookie notices and extracting a set of instructions that result in disabling all non-essential cookies. In order to achieve this, we \ufb01rst build an automatic cookie notice detector that utilizes the rendering pattern of the HTML elements to identify the cookie notices. Next, we analyze the cookie notices and predict the set of actions required to disable all unnecessary cookies. This is done by modeling the problem as a sequence-to-sequence task, where the input is a machine-readable cookie notice and the output is the set of clicks to make. We demonstrate the ef\ufb01cacy of CookieEnforcer via an end-to-end accuracy evaluation, showing that it can generate the required steps in 93.7% of the cases. Via a user study, we also show that CookieEnforcer can signi\ufb01cantly reduce the user effort. Finally, we characterize the behavior of CookieEnforcer on the top 100k websites from the Tranco list, showcasing its stability and scalability.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2065836355",
                        "name": "Rishabh Khandelwal"
                    },
                    {
                        "authorId": "2008169056",
                        "name": "Asmit Nayak"
                    },
                    {
                        "authorId": "121135136",
                        "name": "Hamza Harkous"
                    },
                    {
                        "authorId": "1910642",
                        "name": "Kassem Fawaz"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026been created automatically from existing semantic parsing datasets by splitting by output length (Lake and Baroni, 2018), holding out program templates (Finegan-Dollak et al., 2018), and by maximizing compound divergence between the training and test sets (Keysers et al., 2020; Shaw et al., 2021).",
                "Our work, especially that on sampling diverse test sets, is also related to work on creating compositional splits from existing datasets (Keysers et al., 2020; Shaw et al., 2021; Bogin et al., 2022) and reducing biases in datasets via adversarial filtering or other means (Bras et al.",
                "\u2026that on sampling diverse test sets, is also related to work on creating compositional splits from existing datasets (Keysers et al., 2020; Shaw et al., 2021; Bogin et al., 2022) and reducing biases in datasets via adversarial filtering or other means (Bras et al.,\n2020; Sakaguchi et al.,\u2026",
                ", 2018), and by maximizing compound divergence between the training and test sets (Keysers et al., 2020; Shaw et al., 2021)."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "4c430e6c3a72626bd4cb1893960c7c26dfec6c79",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-08445",
                    "DOI": "10.48550/arXiv.2203.08445",
                    "CorpusId": 247475777
                },
                "corpusId": 247475777,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4c430e6c3a72626bd4cb1893960c7c26dfec6c79",
                "title": "Structurally Diverse Sampling Reduces Spurious Correlations in Semantic Parsing Datasets",
                "abstract": "A rapidly growing body of research has demonstrated the inability of NLP models to generalize compositionally and has tried to alleviate it through specialized architectures, training schemes, and data augmentation, among other approaches. In this work, we study a different relatively under-explored approach: sampling diverse train sets that encourage compositional generalization. We propose a novel algorithm for sampling a structurally diverse set of instances from a labeled instance pool with structured outputs. Evaluating on 5 semantic parsing datasets of varying complexity, we show that our algorithm performs competitively with or better than prior algorithms in not only compositional template splits but also traditional IID splits of all but the least structurally diverse datasets. In general, we \ufb01nd that diverse train sets lead to better generalization than random training sets of same size in 9 out of 10 dataset-split pairs, with over 10% absolute improvement in 5, pro-viding further evidence to their sample ef\ufb01ciency. Moreover, we show that structural diversity also makes for more comprehensive test sets that require diverse training to succeed on. Finally, we use information theory to show that reduction in spurious correlations between substructures may be one reason why diverse training sets improve generalization.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1698760333",
                        "name": "Shivanshu Gupta"
                    },
                    {
                        "authorId": "34650964",
                        "name": "Sameer Singh"
                    },
                    {
                        "authorId": "40642935",
                        "name": "Matt Gardner"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026based on a fine-grained schema of generalization patterns like this work (Bahdanau et al., 2019; Keysers et al., 2020; Kim & Linzen, 2020), or by repartitioning existing datasets with i.i.d. samples into splits with disjoint compositional structures (Finegan-Dollak et al., 2018; Shaw et al., 2021).",
                "samples into splits with disjoint compositional structures (Finegan-Dollak et al., 2018; Shaw et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": null,
                "externalIds": null,
                "corpusId": "248238766",
                "publicationVenue": null,
                "url": null,
                "title": "DECOMPOSITION IN NEURAL PROGRAM SYNTHESIS",
                "abstract": null,
                "year": 2022,
                "authors": []
            }
        },
        {
            "contexts": [
                "Both approaches have generally shown that compositional generalization remains an important challenge (e.g., Shaw et al., 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "474c954231413f2a249f04272dbeda19cd8ff09b",
                "externalIds": {
                    "DBLP": "conf/acl/Zhao0PP22",
                    "ACL": "2022.acl-long.381",
                    "DOI": "10.18653/v1/2022.acl-long.381",
                    "CorpusId": 248780134
                },
                "corpusId": 248780134,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/474c954231413f2a249f04272dbeda19cd8ff09b",
                "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
                "abstract": "Text-to-SQL parsers map natural language questions to programs that are executable over tables to generate answers, and are typically evaluated on large-scale datasets like Spider (Yu et al., 2018). We argue that existing benchmarks fail to capture a certain out-of-domain generalization problem that is of significant practical importance: matching domain specific phrases to composite operation over columns. To study this problem, we first propose a synthetic dataset along with a re-purposed train/test split of the Squall dataset (Shi et al., 2020) as new benchmarks to quantify domain generalization over column operations, and find existing state-of-the-art parsers struggle in these benchmarks. We propose to address this problem by incorporating prior domain knowledge by preprocessing table schemas, and design a method that consists of two components: schema expansion and schema pruning. This method can be easily applied to multiple existing base parsers, and we show that it significantly outperforms baseline parsers on this domain generalization problem, boosting the underlying parsers\u2019 overall performance by up to 13.8% relative accuracy gain (5.1% absolute) on the new Squall data split.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145756130",
                        "name": "Chen Zhao"
                    },
                    {
                        "authorId": "1758652",
                        "name": "Yu Su"
                    },
                    {
                        "authorId": "13461242",
                        "name": "Adam Pauls"
                    },
                    {
                        "authorId": "144888672",
                        "name": "Emmanouil Antonios Platanios"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "3e60cba99b4e8a45f2e3ba3df462ac949a720833",
                "externalIds": {
                    "ACL": "2022.findings-acl.328",
                    "DBLP": "conf/acl/LinLS22",
                    "DOI": "10.18653/v1/2022.findings-acl.328",
                    "CorpusId": 248780252
                },
                "corpusId": 248780252,
                "publicationVenue": {
                    "id": "479d5605-51be-4346-b1d6-4334084504df",
                    "name": "Findings",
                    "type": "journal",
                    "issn": "2652-8800",
                    "url": "https://findingspress.org/"
                },
                "url": "https://www.semanticscholar.org/paper/3e60cba99b4e8a45f2e3ba3df462ac949a720833",
                "title": "Towards Collaborative Neural-Symbolic Graph Semantic Parsing via Uncertainty",
                "abstract": "Recent work in task-independent graph semantic parsing has shifted from grammar-based symbolic approaches to neural models, showing strong performance on different types of meaning representations. However, it is still unclear that what are the limitations of these neural parsers, and whether these limitations can be compensated by incorporating symbolic knowledge into model inference. In this paper, we address these questions by taking English Resource Grammar (ERG) parsing as a case study. Specifically, we first develop a state-of-the-art, T5-based neural ERG parser, and conduct detail analyses of parser performance within fine-grained linguistic categories.The neural parser attains superior performance on in-distribution test set, but degrades significantly on long-tail situations, while the symbolic parser performs more robustly. To address this, we further propose a simple yet principled collaborative framework for neural-symbolic semantic parsing, by designing a decision criterion for beam search that incorporates the prior knowledge from a symbolic parser and accounts for model uncertainty. Experimental results show that the proposed framework yields comprehensive improvement over neural baseline across long-tail categories, yielding the best known Smatch score (97.01) on the well-studied DeepBank benchmark.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2112304965",
                        "name": "Zi Lin"
                    },
                    {
                        "authorId": "2108345570",
                        "name": "J. Liu"
                    },
                    {
                        "authorId": "2884976",
                        "name": "Jingbo Shang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This points to a fundamental tension between broad-coverage semantic parsing on natural text and the ability to generalize compositionally from structurally limited synthetic training sets (see also Shaw et al., 2021).",
                "For instance, Shaw et al. (2021) describe a synchronous grammar induction approach that achieves perfect accuracy on SCAN (Lake and Baroni, 2018), but has very low accuracy on corpora of naturally occurring text such as GeoQuery (Zelle and Mooney, 1996) and Spider (Yu et al., 2018)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "90c1a63aada7704eadc4324c16a66ec793d4b698",
                "externalIds": {
                    "ACL": "2022.starsem-1.4",
                    "DBLP": "conf/starsem/WeissenhornDK22",
                    "DOI": "10.18653/v1/2022.starsem-1.4",
                    "CorpusId": 250390632
                },
                "corpusId": 250390632,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/90c1a63aada7704eadc4324c16a66ec793d4b698",
                "title": "Compositional generalization with a broad-coverage semantic parser",
                "abstract": "We show how the AM parser, a compositional semantic parser (Groschwitz et al., 2018) can solve compositional generalization on the COGS dataset. It is the first semantic parser that achieves high accuracy on both naturally occurring language and the synthetic COGS dataset. We discuss implications for corpus and model design for learning human-like generalization. Our results suggest that compositional generalization can be best achieved by building compositionality into semantic parsers.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1412898731",
                        "name": "Pia Weissenhorn"
                    },
                    {
                        "authorId": "51225576",
                        "name": "L. Donatelli"
                    },
                    {
                        "authorId": "145542037",
                        "name": "Alexander Koller"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026in547 joint neural models of text and images.548\nData Augmentation Data augmentation ap- 549 proaches are widely used across machine learn- 550 ing application domains featuring known invari- 551 ances of the data distribution (Japkowicz et al., 552 2000; Jia and Liang, 2016; Shaw et al., 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "39f604fdd3ade5bd5a67d5284a6d9c12e535db85",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-12926",
                    "CorpusId": 260669688
                },
                "corpusId": 260669688,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/39f604fdd3ade5bd5a67d5284a6d9c12e535db85",
                "title": "Compositionality as Lexical Symmetry",
                "abstract": "Standard deep network models lack the inductive biases needed to generalize compositionally in tasks like semantic parsing, translation, and question answering. A large body of work in natural language processing seeks to over-come this limitation with new model architectures that enforce a compositional process of sentence interpretation. In this paper, we present a domain-general framework for compositional modeling that instead formulates compositionality as a constraint on data distributions. We prove that for any task factorizable into a lexicon and a composition function, there exists a family of data transformation functions that are guaranteed to produce new, well-formed examples when applied to training data. We further show that it is possible to identify these data transformations even when the composition function is unknown (e.g. when we do not know how to write or infer a symbolic grammar). Using these transformation functions to perform data augmentation for ordinary RNN and transformer sequence models, we obtain state-of-the-art results on the CLEVR-CoGenT visual question answering dataset, and results comparable to specialized model architectures on the COGS semantic parsing dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "39021671",
                        "name": "Ekin Aky\u00fcrek"
                    },
                    {
                        "authorId": "2112400",
                        "name": "Jacob Andreas"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following past work [23, 48] we use T5-large as our NL-to-SQL model.",
                "As our NLIDB of choice, we follow past work [23, 48] and fine-tune the state-of-the-art T5 language model [40] on mapping NL-to-SQL.",
                "Recent approaches have heavily relied on specialized architectures [19, 48, 58] combined with pre-trained language models [14, 33, 40].",
                "Specifically, we use theT5-large model [40] as it has been previously shown to perform competitively with state-of-the-art methods [11, 48]."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8b7dbf3b88bce56d08bd37bc318141638a3dfece",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-06311",
                    "CorpusId": 245123972
                },
                "corpusId": 245123972,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8b7dbf3b88bce56d08bd37bc318141638a3dfece",
                "title": "Weakly Supervised Mapping of Natural Language to SQL through Question Decomposition",
                "abstract": "Natural Language Interfaces to Databases (NLIDBs), where users pose queries in Natural Language (NL), are crucial for enabling non-experts to gain insights from data. Developing such interfaces, by contrast, is dependent on experts who often code heuristics for mapping NL to SQL. Alternatively, NLIDBs based on machine learning models rely on supervised examples of NL to SQL mappings (NL-SQL pairs) used as training data. Such examples are again procured using experts, which typically involves more than a one-off interaction. Namely, each data domain in which the NLIDB is deployed may have different characteristics and therefore require either dedicated heuristics or domain-specific training examples. To this end, we propose an alternative approach for training machine learning-based NLIDBs, using weak supervision . We use the recently proposed question decomposition representation called QDMR, an intermediate between NL and formal query languages. Recent work has shown that non-experts are generally successful in translating NL to QDMR. We consequently use NL-QDMR pairs, along with the question answers, as supervision for automatically synthesizing SQL queries. The NL questions and synthesized SQL are then used to train NL-to-SQL models, which we test on five benchmark datasets. Extensive experiments show that our solution, requiring zero expert annotations, performs competitively with models trained on expert annotated data.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51174907",
                        "name": "Tomer Wolfson"
                    },
                    {
                        "authorId": "1750652",
                        "name": "Jonathan Berant"
                    },
                    {
                        "authorId": "1682639",
                        "name": "Daniel Deutch"
                    }
                ]
            }
        },
        {
            "contexts": [
                "sented with novel user utterances (Suhr et al., 2020; Radhakrishnan et al., 2020; Shaw et al., 2021), databases (Suhr et al.",
                "\u2026show that the models tend to fail on challenging cases that involve novel user expression (Suhr et al., 2020) and SQL structures (Suhr et al., 2020; Shaw et al., 2021), our diagnosis exposes more robustness issues in their surface form understanding (even with seemingly simple inputs), and\u2026",
                ", 2020) and SQL structures (Suhr et al., 2020; Shaw et al., 2021), our diagnosis exposes more robustness issues in their surface form understanding (even with seemingly simple inputs), and highlights the importance of addressing such issues in the modeling foundation (Bommasani et al.",
                "\u2026when pre-\n\u02daWork done during an internship at Salesforce Research.\nsented with novel user utterances (Suhr et al., 2020; Radhakrishnan et al., 2020; Shaw et al., 2021), databases (Suhr et al., 2020) and SQL query structures (Finegan-Dollak et al., 2018; Suhr et al., 2020; Shaw et al., 2021)."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "d9b3f5e7a37655159fa158210a8e83897eddee9a",
                "externalIds": {
                    "CorpusId": 247717201
                },
                "corpusId": 247717201,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d9b3f5e7a37655159fa158210a8e83897eddee9a",
                "title": "Testing Cross-Database Semantic Parsers Using Canonical Utterances",
                "abstract": "The benchmark performance of cross-database semantic parsing has climbed steadily in recent years, catalyzed by the wide adoption of pre-trained language models. Yet existing work have shown that state-of-the-art crossdatabase semantic parsers struggle to generalize to novel user utterances, databases and query structures. To obtain transparent details on the strengths and limitation of these models, we propose a diagnostic testing approach based on controlled synthesis of canonical natural language and SQL pairs. Inspired by the CheckList (Ribeiro et al., 2020), we characterize a set of essential capabilities for cross-database semantic parsing models, and detailed the method for synthesizing the corresponding test data. We evaluated a variety of high performing models using the proposed approach, and identified several non-obvious weaknesses across models (e.g. unable to correctly select many columns). Our dataset and code are released as a test suite at http://github.com/hclent/ BehaviorCheckingSemPar.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "49568895",
                        "name": "Heather Lent"
                    },
                    {
                        "authorId": "3014143",
                        "name": "Semih Yavuz"
                    },
                    {
                        "authorId": "48881008",
                        "name": "Tao Yu"
                    },
                    {
                        "authorId": "144412704",
                        "name": "Tong Niu"
                    },
                    {
                        "authorId": "2118860628",
                        "name": "Yingbo Zhou"
                    },
                    {
                        "authorId": "9215251",
                        "name": "Dragomir R. Radev"
                    },
                    {
                        "authorId": "143724481",
                        "name": "Xi Victoria Lin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[16] Peter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova.",
                "However, their applicability to other datasets remains limited [15, 16]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c735740b26ceaa4db9d77233116434c0e8b311d8",
                "externalIds": {
                    "CorpusId": 249121033
                },
                "corpusId": 249121033,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c735740b26ceaa4db9d77233116434c0e8b311d8",
                "title": "Learning Adaptive Control Flow in Transformers for Improved Systematic Generalization",
                "abstract": "Despite successes across a broad range of applications, Transformers have limited success in systematic generalization. The situation is especially frustrating in the case of algorithmic tasks, where they often fail to \ufb01nd intuitive solutions that route relevant information to the right node/operation at the right time in the grid represented by Transformer columns. To facilitate the learning of useful control \ufb02ow, we propose two modi\ufb01cations to the Transformer architecture, copy gate and geometric attention. Our novel Neural Data Router (NDR) achieves 100% length generalization accuracy on the compositional table lookup task. NDR\u2019s attention and gating patterns tend to be interpretable as an intuitive form of neural routing . 1 or \u2018 b a d 101 \u2019. We thus study both forward (former) and backward (latter) variants of the task. To evaluate systematic generalization, the train/valid/test sets have different numbers of compositions: samples of up to 5/6-8/9-10 operations respectively.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3190548",
                        "name": "R. Csord\u00e1s"
                    },
                    {
                        "authorId": "2350348",
                        "name": "Kazuki Irie"
                    },
                    {
                        "authorId": "145341374",
                        "name": "J. Schmidhuber"
                    }
                ]
            }
        }
    ]
}