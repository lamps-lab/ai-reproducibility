{
    "offset": 0,
    "data": [
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "At last, we mention NGAR [74] and GEN [85] as works that can predict the graph topology alongside node-level signals.",
                "DCRNN [71] 2018 ICLR M-S D-C Spatial GNN T-R No R SP STGCN [58] 2018 IJCAI M-S D-F Spectral GNN T-C No R SP ST-MetaNet [73] 2019 KDD M-S D-F Spatial GNN T-R No R SP, PC NGAR [74] 2019 IEEE IJCNN S-S D-F Spatial GNN T-R No R ASTGCN [75] 2019 AAAI M-S D-F Spectral GNN T-H No R SP, PC ST-MGCN [46] 2019 AAAI S-S D-F Spectral GNN T-R No R - SP, PC, PS Graph WaveNet [76] 2019 IJCAI M-S D-F Spatial GNN T-C No O S SP MRA-BGCN [77] 2020 AAAI M-S D-C Spatial GNN T-R No R SP MTGNN [53] 2020 KDD S-S, M-S D-F Spatial GNN T-C No NR S STGNN* [78] 2020 WWW M-S D-C Spatial GNN T-H No R SP GMAN [79] 2020 AAAI M-S D-C Spatial GNN T-A No R SP SLCNN [80] 2020 AAAI M-S D-F Hybrid T-C No NR S STSGCN [81] 2020 AAAI M-S D-C Spatial GNN T No R PC StemGNN [54] 2020 NeurIPS M-S D-F Spectral GNN F-C No NR S AGCRN [82] 2020 NeurIPS M-S D-C Spatial GNN T-R No NR S LSGCN [83] 2020 IJCAI M-S D-F Spectral GNN T-C No R SP STAR [84] 2020 ECCV M-S D-F Spatial GNN T-A No R PC GTS [56] 2021 ICLR M-S D-C Spatial GNN T-R No NR S GEN [85] 2021 ICLR S-S D-F Spatial GNN T-R No R Z-GCNETs [86] 2021 ICML M-S D-C Spatial GNN T-C No NR S STGODE [70] 2021 KDD M-S C-F Spatial GNN T-C No R SP, PS STFGNN [49] 2021 AAAI M-S D-F Spatial GNN T-C No R SP, PS DSTAGNN [87] 2022 ICML M-S D-F Spectral GNN T-H No R - PC, PS TPGNN [88] 2022 NeurIPS S-S, M-S D-F Spatial GNN T-A No NR D MTGODE [23] 2022 IEEE TKDE S-S, M-S C-C Spatial GNN T-C No NR S STG-NCDE [89] 2022 AAAI M-S C-C Spatial GNN T-C Yes NR S STEP [90] 2022 KDD M-S D-F Spatial GNN T-A No NR S Chauhan et al."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d3dbbd0f0de51b421a6220bd6480b8d2e99a88e9",
                "externalIds": {
                    "ArXiv": "2307.03759",
                    "DBLP": "journals/corr/abs-2307-03759",
                    "DOI": "10.48550/arXiv.2307.03759",
                    "CorpusId": 259501265
                },
                "corpusId": 259501265,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d3dbbd0f0de51b421a6220bd6480b8d2e99a88e9",
                "title": "A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection",
                "abstract": "Time series are the primary data type used to record dynamic system measurements and generated in great volume by both physical sensors and online processes (virtual sensors). Time series analytics is therefore crucial to unlocking the wealth of information implicit in available data. With the recent advancements in graph neural networks (GNNs), there has been a surge in GNN-based approaches for time series analysis. These approaches can explicitly model inter-temporal and inter-variable relationships, which traditional and other deep neural network-based methods struggle to do. In this survey, we provide a comprehensive review of graph neural networks for time series analysis (GNN4TS), encompassing four fundamental dimensions: forecasting, classification, anomaly detection, and imputation. Our aim is to guide designers and practitioners to understand, build applications, and advance research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy of GNN4TS. Then, we present and discuss representative research works and introduce mainstream applications of GNN4TS. A comprehensive discussion of potential future research directions completes the survey. This survey, for the first time, brings together a vast array of knowledge on GNN-based time series research, highlighting foundations, practical applications, and opportunities of graph neural networks for time series analysis.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2072905592",
                        "name": "Ming Jin"
                    },
                    {
                        "authorId": "2134585717",
                        "name": "Huan Yee Koh"
                    },
                    {
                        "authorId": "3308963",
                        "name": "Qingsong Wen"
                    },
                    {
                        "authorId": "48283854",
                        "name": "Daniele Zambon"
                    },
                    {
                        "authorId": "1785004",
                        "name": "C. Alippi"
                    },
                    {
                        "authorId": "2098367190",
                        "name": "G. I. Webb"
                    },
                    {
                        "authorId": "2161241744",
                        "name": "Irwin King"
                    },
                    {
                        "authorId": "2153326034",
                        "name": "Shirui Pan"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ef3f94b0490f9a1a35313d99da8bfaab90c48538",
                "externalIds": {
                    "DOI": "10.3389/fenvs.2022.1025268",
                    "CorpusId": 253500763
                },
                "corpusId": 253500763,
                "publicationVenue": {
                    "id": "c0ded351-0e49-473e-816e-23b84c9f8dd3",
                    "name": "Frontiers in Environmental Science",
                    "type": "journal",
                    "alternate_names": [
                        "Front Environ Sci"
                    ],
                    "issn": "2296-665X",
                    "url": "http://www.frontiersin.org/Environmental_Science",
                    "alternate_urls": [
                        "https://www.frontiersin.org/journals/environmental-science"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ef3f94b0490f9a1a35313d99da8bfaab90c48538",
                "title": "Adaptive graph convolutional imputation network for environmental sensor data recovery",
                "abstract": "Environmental sensors are essential for tracking weather conditions and changing trends, thus preventing adverse effects on species and environment. Missing values are inevitable in sensor recordings due to equipment malfunctions and measurement errors. Recent representation learning methods attempt to reconstruct missing values by capturing the temporal dependencies of sensor signals as handling time series data. However, existing approaches fall short of simultaneously capturing spatio-temporal dependencies in the network and fail to explicitly model sensor relations in a data-driven manner. In this work, we propose a novel Adaptive Graph Convolutional Imputation Network for missing value imputation in environmental sensor networks. A bidirectional graph convolutional gated recurrent unit module is introduced to extract spatio-temporal features which takes full advantage of the available observations from the target sensor and its neighboring sensors to recover the missing values. In addition, we design an adaptive graph learning layer that learns a sensor network topology in an end-to-end framework, in which no prior network information is needed for capturing spatial dependencies. Extensive experiments on three real-world environmental sensor datasets (solar radiation, air quality, relative humidity) in both in-sample and out-of-sample settings demonstrate the superior performance of the proposed framework for completing missing values in the environmental sensor network, which could potentially support environmental monitoring and assessment.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "49102991",
                        "name": "Fanglan Chen"
                    },
                    {
                        "authorId": "1669829502",
                        "name": "Dongjie Wang"
                    },
                    {
                        "authorId": "3433489",
                        "name": "Shuo Lei"
                    },
                    {
                        "authorId": "47752577",
                        "name": "Jianfeng He"
                    },
                    {
                        "authorId": "2274395",
                        "name": "Yanjie Fu"
                    },
                    {
                        "authorId": "2110142089",
                        "name": "Chang-Tien Lu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "39e1fe46ec31d4c1dd7dd24df087d7119828451d",
                "externalIds": {
                    "DOI": "10.1109/TNNLS.2022.3185527",
                    "CorpusId": 253019529,
                    "PubMed": "36264724"
                },
                "corpusId": 253019529,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/39e1fe46ec31d4c1dd7dd24df087d7119828451d",
                "title": "DyGCN: Efficient Dynamic Graph Embedding With Graph Convolutional Network.",
                "abstract": "Graph embedding, aiming to learn low-dimensional representations (aka. embeddings) of nodes in graphs, has received significant attention. In recent years, there has been a surge of efforts, among which graph convolutional networks (GCNs) have emerged as an effective class of models. However, these methods mainly focus on the static graph embedding. In the present work, an efficient dynamic graph embedding approach is proposed, called dynamic GCN (DyGCN), which is an extension of the GCN-based methods. The embedding propagation scheme of GCN is naturally generalized to a dynamic setting in an efficient manner, which propagates the change in topological structure and neighborhood embeddings along the graph to update the node embeddings. The most affected nodes are updated first, and then their changes are propagated to further nodes, which in turn are updated. Extensive experiments on various dynamic graphs showed that the proposed model can update the node embeddings in a time-saving and performance-preserving way.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "72723327",
                        "name": "Zeyu Cui"
                    },
                    {
                        "authorId": "2109964198",
                        "name": "Zekun Li"
                    },
                    {
                        "authorId": "50425438",
                        "name": "Shu Wu"
                    },
                    {
                        "authorId": "2115796365",
                        "name": "Xiaoyu Zhang"
                    },
                    {
                        "authorId": "48873756",
                        "name": "Q. Liu"
                    },
                    {
                        "authorId": "2155131551",
                        "name": "Liang Wang"
                    },
                    {
                        "authorId": "2067296348",
                        "name": "Mengmeng Ai"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "cessing point clouds by Graph Neural Networks (GNNs) [34], [35], [36], [37], [38], [39], which can be considered an extension of PointNet."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7d5c0ae2985e0c665cb3713aaa169ee5c7c9794f",
                "externalIds": {
                    "ArXiv": "2209.11796",
                    "DBLP": "journals/corr/abs-2209-11796",
                    "DOI": "10.48550/arXiv.2209.11796",
                    "CorpusId": 252532031
                },
                "corpusId": 252532031,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7d5c0ae2985e0c665cb3713aaa169ee5c7c9794f",
                "title": "Composite Layers for Deep Anomaly Detection on 3D Point Clouds",
                "abstract": "Deep neural networks require specific layers to process point clouds, as the scattered and irregular location of points prevents us from using convolutional filters. Here we introduce the composite layer, a new convolutional operator for point clouds. The peculiarity of our composite layer is that it extracts and compresses the spatial information from the position of points before combining it with their feature vectors. Compared to well-known point-convolutional layers such as those of ConvPoint and KPConv, our composite layer provides additional regularization and guarantees greater flexibility in terms of design and number of parameters. To demonstrate the design flexibility, we also define an aggregate composite layer that combines spatial information and features in a nonlinear manner, and we use these layers to implement a convolutional and an aggregate CompositeNet. We train our CompositeNets to perform classification and, most remarkably, unsupervised anomaly detection. Our experiments on synthetic and real-world datasets show that, in both tasks, our CompositeNets outperform ConvPoint and achieve similar results as KPConv despite having a much simpler architecture. Moreover, our CompositeNets substantially outperform existing solutions for anomaly detection on point clouds.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "34523894",
                        "name": "A. Floris"
                    },
                    {
                        "authorId": "1788584596",
                        "name": "Luca Frittoli"
                    },
                    {
                        "authorId": "145931074",
                        "name": "Diego Carrera"
                    },
                    {
                        "authorId": "2772474",
                        "name": "G. Boracchi"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c432a67b61590cd815970bdbaaff9f968efd39f7",
                "externalIds": {
                    "ArXiv": "2203.15009",
                    "DBLP": "journals/corr/abs-2203-15009",
                    "DOI": "10.48550/arXiv.2203.15009",
                    "CorpusId": 247778708
                },
                "corpusId": 247778708,
                "publicationVenue": {
                    "id": "50534c12-f4ba-4c64-806b-01647d1baacf",
                    "name": "LOG IN",
                    "type": "journal",
                    "alternate_names": [
                        "Log in",
                        "Log",
                        "LOG"
                    ],
                    "issn": "0720-8642",
                    "alternate_issns": [
                        "1547-4690",
                        "0024-5798"
                    ],
                    "url": "https://www.log-in-verlag.de/informatische_bildung/",
                    "alternate_urls": [
                        "https://www.anycorp.com/log/about",
                        "https://www.jstor.org/journal/log",
                        "https://www.anycorp.com/",
                        "http://www.jstor.org/action/showPublication?journalCode=log",
                        "http://www.anycorp.com/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c432a67b61590cd815970bdbaaff9f968efd39f7",
                "title": "DAMNETS: A Deep Autoregressive Model for Generating Markovian Network Time Series",
                "abstract": "In this work, we introduce DAMNETS, a deep generative model for Markovian network time series. Time series of networks are found in many fields such as trade or payment networks in economics, contact networks in epidemiology or social media posts over time. Generative models of such data are useful for Monte-Carlo estimation and data set expansion, which is of interest for both data privacy and model fitting. Using recent ideas from the Graph Neural Network (GNN) literature, we introduce a novel GNN encoder-decoder structure in which an encoder GNN learns a latent representation of the input graph, and a decoder GNN uses this representation to simulate the network dynamics. We show using synthetic data sets that DAMNETS can replicate features of network topology across time observed in the real world, such as changing community structure and preferential attachment. DAMNETS outperforms competing methods on all of our measures of sample quality over several real and synthetic data sets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2052152016",
                        "name": "J. Clarkson"
                    },
                    {
                        "authorId": "2162064",
                        "name": "Mihai Cucuringu"
                    },
                    {
                        "authorId": "2064013905",
                        "name": "Andrew Elliott"
                    },
                    {
                        "authorId": "2666765",
                        "name": "G. Reinert"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "There are several research that conduct a more general study in which a full graph (nodes, edges, and attributes) is predicted [37], [38]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e494fbb4621aa115f1901f32fb3e3fc9ae757119",
                "externalIds": {
                    "ArXiv": "2109.02474",
                    "DBLP": "journals/corr/abs-2109-02474",
                    "DOI": "10.1109/TNNLS.2022.3186103",
                    "CorpusId": 237420889,
                    "PubMed": "35834453"
                },
                "corpusId": 237420889,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e494fbb4621aa115f1901f32fb3e3fc9ae757119",
                "title": "TraverseNet: Unifying Space and Time in Message Passing",
                "abstract": "This article aims to unify spatial dependency and temporal dependency in a non-Euclidean space while capturing the inner spatial-temporal dependencies for traffic data. For spatial-temporal attribute entities with topological structure, the space-time is consecutive and unified while each node's current status is influenced by its neighbors' past states over variant periods of each neighbor. Most spatial-temporal neural networks for traffic forecasting study spatial dependency and temporal correlation separately in processing, gravely impaired the spatial-temporal integrity, and ignore the fact that the neighbors' temporal dependency period for a node can be delayed and dynamic. To model this actual condition, we propose TraverseNet, a novel spatial-temporal graph neural network, viewing space and time as an inseparable whole, to mine spatial-temporal graphs while exploiting the evolving spatial-temporal dependencies for each node via message traverse mechanisms. Experiments with ablation and parameter studies have validated the effectiveness of the proposed TraverseNet, and the detailed implementation can be found from https://github.com/nnzhan/TraverseNet.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109557884",
                        "name": "Zonghan Wu"
                    },
                    {
                        "authorId": "122579067",
                        "name": "Da Zheng"
                    },
                    {
                        "authorId": "2585415",
                        "name": "Shirui Pan"
                    },
                    {
                        "authorId": "47594426",
                        "name": "Quan Gan"
                    },
                    {
                        "authorId": "2062835",
                        "name": "Guodong Long"
                    },
                    {
                        "authorId": "50877490",
                        "name": "G. Karypis"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "While previously mentioned approaches focus on multivariate time series prediction, other methods aim at predicting changes in graph topology (Zambon et al., 2019; Paassen et al., 2020)."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2e08a508fa9c6ae7195aa14dfe6c9e695e19aa33",
                "externalIds": {
                    "ArXiv": "2108.00298",
                    "DBLP": "conf/iclr/CiniMA22",
                    "CorpusId": 246705934
                },
                "corpusId": 246705934,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2e08a508fa9c6ae7195aa14dfe6c9e695e19aa33",
                "title": "Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks",
                "abstract": "Dealing with missing values and incomplete time series is a labor-intensive, tedious, inevitable task when handling data coming from real-world applications. Effective spatio-temporal representations would allow imputation methods to reconstruct missing temporal data by exploiting information coming from sensors at different locations. However, standard methods fall short in capturing the nonlinear time and space dependencies existing within networks of interconnected sensors and do not take full advantage of the available - and often strong - relational information. Notably, most state-of-the-art imputation methods based on deep learning do not explicitly model relational aspects and, in any case, do not exploit processing frameworks able to adequately represent structured spatio-temporal data. Conversely, graph neural networks have recently surged in popularity as both expressive and scalable tools for processing sequential data with relational inductive biases. In this work, we present the first assessment of graph neural networks in the context of multivariate time series imputation. In particular, we introduce a novel graph neural network architecture, named GRIN, which aims at reconstructing missing data in the different channels of a multivariate time series by learning spatio-temporal representations through message passing. Empirical results show that our model outperforms state-of-the-art methods in the imputation task on relevant real-world benchmarks with mean absolute error improvements often higher than 20%.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "115461566",
                        "name": "Andrea Cini"
                    },
                    {
                        "authorId": "2122337667",
                        "name": "Ivan Marisca"
                    },
                    {
                        "authorId": "1785004",
                        "name": "C. Alippi"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "cd73da1d36cc0607ecad69633645583e4b922ad0",
                "externalIds": {
                    "MAG": "3110130954",
                    "DBLP": "journals/corr/abs-2012-02097",
                    "ArXiv": "2012.02097",
                    "DOI": "10.1007/s10994-022-06223-7",
                    "CorpusId": 227254446
                },
                "corpusId": 227254446,
                "publicationVenue": {
                    "id": "22c9862f-a25e-40cd-9d31-d09e68a293e6",
                    "name": "Machine-mediated learning",
                    "type": "journal",
                    "alternate_names": [
                        "Mach learn",
                        "Machine Learning",
                        "Mach Learn"
                    ],
                    "issn": "0732-6718",
                    "alternate_issns": [
                        "0885-6125"
                    ],
                    "url": "http://www.springer.com/computer/artificial/journal/10994",
                    "alternate_urls": [
                        "https://link.springer.com/journal/10994",
                        "http://www.springer.com/west/home/computer/artificial?SGWID=4-147-70-35726603-0"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/cd73da1d36cc0607ecad69633645583e4b922ad0",
                "title": "Recursive tree grammar autoencoders",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2076081",
                        "name": "Benjamin Paassen"
                    },
                    {
                        "authorId": "1751995",
                        "name": "I. Koprinska"
                    },
                    {
                        "authorId": "1763220",
                        "name": "K. Yacef"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "While previously mentioned approaches focus on multivariate time series prediction, other methods aim at predicting changes in graph topology (Zambon et al., 2019; Paassen et al., 2020)."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "51d72e98d46ecd05a2c343c23c0bc44b39a1a4bb",
                "externalIds": {
                    "CorpusId": 254074906
                },
                "corpusId": 254074906,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/51d72e98d46ecd05a2c343c23c0bc44b39a1a4bb",
                "title": "F ILLING THE G AP S : M ULTIVARIATE T IME S ERIES I MPUTATION BY G RAPH N EURAL N ETWORKS",
                "abstract": "Dealing",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2122337667",
                        "name": "Ivan Marisca"
                    },
                    {
                        "authorId": "1785004",
                        "name": "C. Alippi"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "While the above approaches focus on multivariate time series prediction and use the graph structure only as a representational tool, other methods aim at predicting changes in the graph topology [Zambon et al., 2019, Paassen et al., 2020]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6c4d78c28a75b21385de4172e7b4f5a625be6b7c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-00298",
                    "CorpusId": 236772243
                },
                "corpusId": 236772243,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6c4d78c28a75b21385de4172e7b4f5a625be6b7c",
                "title": "Multivariate Time Series Imputation by Graph Neural Networks",
                "abstract": "Dealing with missing values and incomplete time series is a labor-intensive and time-consuming inevitable task when handling data coming from real-world applications. Effective spatio-temporal representations would allow imputation methods to reconstruct missing temporal data by exploiting information coming from sensors at different locations. However, standard methods fall short in capturing the nonlinear time and space dependencies existing within networks of interconnected sensors and do not take full advantage of the available \u2013 and often strong \u2013 relational information. Notably, most of state-of-the-art imputation methods based on deep learning do not explicitly model relational aspects and, in any case, do not exploit processing frameworks able to adequately represent structured spatio-temporal data. Conversely, graph neural networks have recently surged in popularity as both expressive and scalable tools for processing sequential data with relational inductive biases. In this work, we present the \ufb01rst assessment of graph neural networks in the context of multivariate time series imputation. In particular, we introduce a novel graph neural network architecture, named GRIL , which aims at reconstructing missing data in the different channels of a multivariate time series by learning spatial-temporal representations through message passing. Preliminary empirical results show that our model outperforms state-of-the-art methods in the imputation task on relevant benchmarks with mean absolute error improvements often higher than 20% .",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "115461566",
                        "name": "Andrea Cini"
                    },
                    {
                        "authorId": "2122337667",
                        "name": "Ivan Marisca"
                    },
                    {
                        "authorId": "1785004",
                        "name": "C. Alippi"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "While some recent approaches are more flexible in both respects [27, 32], it remains a hard problem to accurately characterize the distribution of large graphs.",
                "Second, decoders that generate graphs by a sequence of edits [27, 29, 30, 31], e.",
                "Theory of deep learning for graphs: While theoretical studies have found crucial relations between the Weisfeiler-Lehman test and the graph edit distance [8, 10, 27], it is still not fully clear how these connections relate to learning.",
                "For example, users enter or leave social networks and change their connections over time [27].",
                "Conversely, graph edit networks only use embedding information at time t but can predict changes in the node set via node deletions or insertions [27].",
                "However, in many applications we need to decode graphs from vectors, such as in molecule design [24, 25, 26] or when performing time series prediction [27].",
                "Promising results have been achieved for chemical molecules [24, 25, 26] and computer programs [40, 27].",
                "Some recent approaches offer a compromise by first determining the nodes of a graph in a sequential fashion and, afterwards, all edges are generated in a single step [27, 32]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "deada43d43f2687a1a475058f9542c10ff612801",
                "externalIds": {
                    "MAG": "3021565446",
                    "DBLP": "conf/esann/BacciuBPA21",
                    "DOI": "10.1007/978-3-030-43883-8_5",
                    "CorpusId": 219065756
                },
                "corpusId": 219065756,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/deada43d43f2687a1a475058f9542c10ff612801",
                "title": "Deep Learning for Graphs",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "3224102",
                        "name": "D. Bacciu"
                    },
                    {
                        "authorId": "41231471",
                        "name": "A. Micheli"
                    }
                ]
            }
        }
    ]
}