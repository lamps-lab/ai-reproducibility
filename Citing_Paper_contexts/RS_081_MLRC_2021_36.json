{
    "offset": 0,
    "data": [
        {
            "contexts": [
                "d) Other methods: For the trajectory prediction, SocialNCE [38] considers unfavorable events like discomfort and",
                "Multi-modal distributions can overcome the drawback of converging to average behaviors by outputting several plausible behaviors, and are used by studies such as [31], [33], [35], [38], [40], [44], [47], [50], [51], and [58].",
                "Social-NCE [38] applied LSTM model based on"
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "de4bca486236aa40e4d4a69b353883bb7c1064fd",
                "externalIds": {
                    "DOI": "10.1109/TITS.2023.3281393",
                    "CorpusId": 259391437
                },
                "corpusId": 259391437,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/de4bca486236aa40e4d4a69b353883bb7c1064fd",
                "title": "Pedestrian Behavior Prediction Using Deep Learning Methods for Urban Scenarios: A Review",
                "abstract": "The prediction of pedestrian behavior is essential for automated driving in urban traffic and has attracted increasing attention in the vehicle industry. This task is challenging because pedestrian behavior is driven by various factors, including their individual properties, the interactions with other road users, and the interactions with the environment. Deep learning approaches have become increasingly popular because of their superior performance in complex scenarios compared to traditional approaches such as the social force or constant velocity models. In this paper, we provide a comprehensive review of deep learning-based approaches for pedestrian behavior prediction. We review and categorize a large selection of scientific contributions covering both trajectory and intention prediction from the last five years. We categorize existing works by prediction tasks, input data, model features, and network structures. Besides, we provide an overview of existing datasets and the evaluation metrics. We analyze, compare, and discuss the performance of existing work. Finally, we point out the research gaps and outline possible directions for future research.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2115811509",
                        "name": "Chi Zhang"
                    },
                    {
                        "authorId": "2220345997",
                        "name": "Christian Berger"
                    }
                ]
            }
        },
        {
            "contexts": [
                "deep learning models such as [17], [18], [25].",
                "Some of the most important ML-based prediction frameworks which have shown their potential in the context of social navigation are Social-LSTM [16], Social-GAN [17], Social-NCE [18], and sparse Gaussian processes [19]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "d1fd2ab495381b0863e4ce58e85021b83570439d",
                "externalIds": {
                    "ArXiv": "2309.16838",
                    "CorpusId": 263310479
                },
                "corpusId": 263310479,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d1fd2ab495381b0863e4ce58e85021b83570439d",
                "title": "Social Navigation in Crowded Environments with Model Predictive Control and Deep Learning-Based Human Trajectory Prediction",
                "abstract": "Crowd navigation has received increasing attention from researchers over the last few decades, resulting in the emergence of numerous approaches aimed at addressing this problem to date. Our proposed approach couples agent motion prediction and planning to avoid the freezing robot problem while simultaneously capturing multi-agent social interactions by utilizing a state-of-the-art trajectory prediction model i.e., social long short-term memory model (Social-LSTM). Leveraging the output of Social-LSTM for the prediction of future trajectories of pedestrians at each time-step given the robot's possible actions, our framework computes the optimal control action using Model Predictive Control (MPC) for the robot to navigate among pedestrians. We demonstrate the effectiveness of our proposed approach in multiple scenarios of simulated crowd navigation and compare it against several state-of-the-art reinforcement learning-based methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2249542901",
                        "name": "Viet-Anh Le"
                    },
                    {
                        "authorId": "2126487751",
                        "name": "Behdad Chalaki"
                    },
                    {
                        "authorId": "66857335",
                        "name": "Vaishnav Tadiparthi"
                    },
                    {
                        "authorId": "51186799",
                        "name": "Hossein Nourkhiz Mahjoub"
                    },
                    {
                        "authorId": "2211340412",
                        "name": "Jovin D'sa"
                    },
                    {
                        "authorId": "1403036177",
                        "name": "Ehsan Moradi-Pari"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "77adac59b9a61af0ccbfceafde70032a9980facb",
                "externalIds": {
                    "ArXiv": "2309.15234",
                    "CorpusId": 263152753
                },
                "corpusId": 263152753,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/77adac59b9a61af0ccbfceafde70032a9980facb",
                "title": "Multi-Robot Cooperative Socially-Aware Navigation Using Multi-Agent Reinforcement Learning",
                "abstract": "In public spaces shared with humans, ensuring multi-robot systems navigate without collisions while respecting social norms is challenging, particularly with limited communication. Although current robot social navigation techniques leverage advances in reinforcement learning and deep learning, they frequently overlook robot dynamics in simulations, leading to a simulation-to-reality gap. In this paper, we bridge this gap by presenting a new multi-robot social navigation environment crafted using Dec-POSMDP and multi-agent reinforcement learning. Furthermore, we introduce SAMARL: a novel benchmark for cooperative multi-robot social navigation. SAMARL employs a unique spatial-temporal transformer combined with multi-agent reinforcement learning. This approach effectively captures the complex interactions between robots and humans, thus promoting cooperative tendencies in multi-robot systems. Our extensive experiments reveal that SAMARL outperforms existing baseline and ablation models in our designed environment. Demo videos for this work can be found at: https://sites.google.com/view/samarl",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2247827277",
                        "name": "Weizheng Wang"
                    },
                    {
                        "authorId": "2213987478",
                        "name": "Le Mao"
                    },
                    {
                        "authorId": "1390826784",
                        "name": "Ruiqi Wang"
                    },
                    {
                        "authorId": "2247857569",
                        "name": "Byung-Cheol Min"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "dad09452b94e9ba03a26c02f107f83272aee000e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-08947",
                    "ArXiv": "2309.08947",
                    "DOI": "10.48550/arXiv.2309.08947",
                    "CorpusId": 262043278
                },
                "corpusId": 262043278,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/dad09452b94e9ba03a26c02f107f83272aee000e",
                "title": "Staged Contact-Aware Global Human Motion Forecasting",
                "abstract": "Scene-aware global human motion forecasting is critical for manifold applications, including virtual reality, robotics, and sports. The task combines human trajectory and pose forecasting within the provided scene context, which represents a significant challenge. So far, only Mao et al. NeurIPS'22 have addressed scene-aware global motion, cascading the prediction of future scene contact points and the global motion estimation. They perform the latter as the end-to-end forecasting of future trajectories and poses. However, end-to-end contrasts with the coarse-to-fine nature of the task and it results in lower performance, as we demonstrate here empirically. We propose a STAGed contact-aware global human motion forecasting STAG, a novel three-stage pipeline for predicting global human motion in a 3D environment. We first consider the scene and the respective human interaction as contact points. Secondly, we model the human trajectory forecasting within the scene, predicting the coarse motion of the human body as a whole. The third and last stage matches a plausible fine human joint motion to complement the trajectory considering the estimated contacts. Compared to the state-of-the-art (SoA), STAG achieves a 1.8% and 16.2% overall improvement in pose and trajectory prediction, respectively, on the scene-aware GTA-IM dataset. A comprehensive ablation study confirms the advantages of staged modeling over end-to-end approaches. Furthermore, we establish the significance of a newly proposed temporal counter called the\"time-to-go\", which tells how long it is before reaching scene contact and endpoints. Notably, STAG showcases its ability to generalize to datasets lacking a scene and achieves a new state-of-the-art performance on CMU-Mocap, without leveraging any social cues. Our code is released at: https://github.com/L-Scofano/STAG",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2214189233",
                        "name": "Luca Scofano"
                    },
                    {
                        "authorId": "2131867709",
                        "name": "Alessio Sampieri"
                    },
                    {
                        "authorId": "2243180958",
                        "name": "Elisabeth Schiele"
                    },
                    {
                        "authorId": "2214192004",
                        "name": "Edoardo De Matteis"
                    },
                    {
                        "authorId": "2243180936",
                        "name": "Laura Leal-Taix'e"
                    },
                    {
                        "authorId": "1787725",
                        "name": "Fabio Galasso"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Reference [26] decides to deter the model from predicting collision or too uncomfortable"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "002ba4591e3300421ef43c90c30f17a219e0a2e7",
                "externalIds": {
                    "DBLP": "journals/tits/ZhongYYHJLW23",
                    "DOI": "10.1109/TITS.2023.3266762",
                    "CorpusId": 258208666
                },
                "corpusId": 258208666,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/002ba4591e3300421ef43c90c30f17a219e0a2e7",
                "title": "Visual Exposes You: Pedestrian Trajectory Prediction Meets Visual Intention",
                "abstract": "Pedestrian trajectory prediction in multiple scenarios is of immense importance in autonomous driving and disentanglement of human behavior but is limited in catching human intention and initiative. Most previous works tend to predict the trajectory using only 2D coordinates, which generally cause two common problems: a) Overlooking the subjective initiative, including sudden swerve and erratic movement; b) A potential challenge called abnormal collision caused by unlabeled pedestrians on dataset is not being identified and resolved, which would ruin the model prediction. To break those limitations, we introduce visual localization and orientation as Visual Intention Knowledge to help the trajectory prediction, which is learned directly from visual scenarios. It benefits to comprehend human intention and formulates decision-making processes. Moreover, by learning from the visual information and decision-making policy, we construct the Visual Intention Knowledge associated spatio-temporal Transformer (VIKT) to predict human trajectory by combining the intention knowledge with the novel Transformer. Extensive experimental results demonstrate that our VIKT model could achieve competitive performance by the Visual Intention Knowledge through optimizing the model prediction compared with state-of-the-art methods in terms of prediction accuracy on ETH/UCY and SDD benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46812609",
                        "name": "X. Zhong"
                    },
                    {
                        "authorId": "2156497547",
                        "name": "Xu Yan"
                    },
                    {
                        "authorId": "2149232317",
                        "name": "Zhengwei Yang"
                    },
                    {
                        "authorId": "1500393994",
                        "name": "Wenxin Huang"
                    },
                    {
                        "authorId": "51360637",
                        "name": "Kui Jiang"
                    },
                    {
                        "authorId": "2124017717",
                        "name": "R. Liu"
                    },
                    {
                        "authorId": "50219447",
                        "name": "Zheng Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Representation learning [15] of safer motion representations can be facilitated by contrastive estimation from simulated negative behavior."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "f99b6b06b820577bb85ccf15c1c4627427205d53",
                "externalIds": {
                    "ArXiv": "2308.06137",
                    "DBLP": "journals/corr/abs-2308-06137",
                    "DOI": "10.48550/arXiv.2308.06137",
                    "CorpusId": 260865945
                },
                "corpusId": 260865945,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f99b6b06b820577bb85ccf15c1c4627427205d53",
                "title": "A Game-Theoretic Framework for Joint Forecasting and Planning",
                "abstract": "Planning safe robot motions in the presence of humans requires reliable forecasts of future human motion. However, simply predicting the most likely motion from prior interactions does not guarantee safety. Such forecasts fail to model the long tail of possible events, which are rarely observed in limited datasets. On the other hand, planning for worst-case motions leads to overtly conservative behavior and a ``frozen robot''. Instead, we aim to learn forecasts that predict counterfactuals that humans guard against. We propose a novel game-theoretic framework for joint planning and forecasting with the payoff being the performance of the planner against the demonstrator, and present practical algorithms to train models in an end-to-end fashion. We demonstrate that our proposed algorithm results in safer plans in a crowd navigation simulator and real-world datasets of pedestrian motion. We release our code at https://github.com/portal-cornell/Game-Theoretic-Forecasting-Planning.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "34904511",
                        "name": "K. Kedia"
                    },
                    {
                        "authorId": "2228665381",
                        "name": "Prithwish Dan"
                    },
                    {
                        "authorId": "2487768",
                        "name": "Sanjiban Choudhury"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The most popular trajectory prediction models, including [21, 23, 72, 18, 52, 66, 94, 19, 55, 73, 26, 90], are all very large with stochastic output.",
                "Among these methods, works utilizing generation frameworks, such as [21, 23, 27, 43, 65, 72, 96, 4, 24, 48, 77] using GAN [25] and [18, 35, 45, 52, 66, 75, 94] using CAVE [71], have achieved good experimental performance."
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "ec6ad2e940e3313ac04c8b9e9c80804560f2cc3d",
                "externalIds": {
                    "ArXiv": "2308.05985",
                    "DBLP": "journals/corr/abs-2308-05985",
                    "DOI": "10.48550/arXiv.2308.05985",
                    "CorpusId": 260866005
                },
                "corpusId": 260866005,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/ec6ad2e940e3313ac04c8b9e9c80804560f2cc3d",
                "title": "TrajPAC: Towards Robustness Verification of Pedestrian Trajectory Prediction Models",
                "abstract": "Robust pedestrian trajectory forecasting is crucial to developing safe autonomous vehicles. Although previous works have studied adversarial robustness in the context of trajectory forecasting, some significant issues remain unaddressed. In this work, we try to tackle these crucial problems. Firstly, the previous definitions of robustness in trajectory prediction are ambiguous. We thus provide formal definitions for two kinds of robustness, namely label robustness and pure robustness. Secondly, as previous works fail to consider robustness about all points in a disturbance interval, we utilise a probably approximately correct (PAC) framework for robustness verification. Additionally, this framework can not only identify potential counterexamples, but also provides interpretable analyses of the original methods. Our approach is applied using a prototype tool named TrajPAC. With TrajPAC, we evaluate the robustness of four state-of-the-art trajectory prediction models -- Trajectron++, MemoNet, AgentFormer, and MID -- on trajectories from five scenes of the ETH/UCY dataset and scenes of the Stanford Drone Dataset. Using our framework, we also experimentally study various factors that could influence robustness performance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2146645078",
                        "name": "Liang Zhang"
                    },
                    {
                        "authorId": "2228305265",
                        "name": "Nathaniel Xu"
                    },
                    {
                        "authorId": "49731702",
                        "name": "Pengfei Yang"
                    },
                    {
                        "authorId": "2071131446",
                        "name": "Gao Jin"
                    },
                    {
                        "authorId": "2150607419",
                        "name": "Cheng-Chao Huang"
                    },
                    {
                        "authorId": "2143381297",
                        "name": "Lijun Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "90f3b09ef6f56589d18435daff20856b8a8998af",
                "externalIds": {
                    "DOI": "10.23919/CCC58697.2023.10240400",
                    "CorpusId": 262075453
                },
                "corpusId": 262075453,
                "publicationVenue": {
                    "id": "23f8fe4c-6537-4027-a334-6a5863115984",
                    "name": "Cybersecurity and Cyberforensics Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Chin Control Conf",
                        "Computational Complexity Conference",
                        "CCC",
                        "Comput Complex Conf",
                        "Cybersecur Cyberforensics Conf",
                        "Conference on Computational Complexity",
                        "Computing Colombian Conference",
                        "Conf Comput Complex",
                        "Comput Colomb Conf",
                        "Chinese Control Conference"
                    ],
                    "url": "http://computationalcomplexity.org/"
                },
                "url": "https://www.semanticscholar.org/paper/90f3b09ef6f56589d18435daff20856b8a8998af",
                "title": "Robot-Crowd Navigation with Socially-Aware Reinforcement Learning Over Graphs",
                "abstract": "Robots typically perform navigation task in a crowd environment, where the navigation task requires robots to reach a target point safely and efficiently, and to have the least impact on crowd trajectories. To this end, we propose a graph-based socially aware reinforcement learning navigation algorithm, in which the robot-crowd interactions are modeled as a directed spatio-temporal graph. We utilize graph convolutional networks, attention mechanism and long short term memory networks to encode robot-crowd interaction features, which are subsequently leveraged for state value estimation and robot action selection. Our method is demonstrated to have high success rate and short navigation time in various environments and outperform existing methods in terms of security and efficiency.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2243355230",
                        "name": "Benfan Li"
                    },
                    {
                        "authorId": "2152148509",
                        "name": "Jian Sun"
                    },
                    {
                        "authorId": "2243373365",
                        "name": "Zhuo Li"
                    },
                    {
                        "authorId": "2096527",
                        "name": "G. Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "b5d799b1f3aebd7549d2945f42691346418192f0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-09306",
                    "ArXiv": "2307.09306",
                    "DOI": "10.48550/arXiv.2307.09306",
                    "CorpusId": 259950884
                },
                "corpusId": 259950884,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b5d799b1f3aebd7549d2945f42691346418192f0",
                "title": "EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory Forecasting",
                "abstract": "Capturing high-dimensional social interactions and feasible futures is essential for predicting trajectories. To address this complex nature, several attempts have been devoted to reducing the dimensionality of the output variables via parametric curve fitting such as the B\\'ezier curve and B-spline function. However, these functions, which originate in computer graphics fields, are not suitable to account for socially acceptable human dynamics. In this paper, we present EigenTrajectory ($\\mathbb{ET}$), a trajectory prediction approach that uses a novel trajectory descriptor to form a compact space, known here as $\\mathbb{ET}$ space, in place of Euclidean space, for representing pedestrian movements. We first reduce the complexity of the trajectory descriptor via a low-rank approximation. We transform the pedestrians' history paths into our $\\mathbb{ET}$ space represented by spatio-temporal principle components, and feed them into off-the-shelf trajectory forecasting models. The inputs and outputs of the models as well as social interactions are all gathered and aggregated in the corresponding $\\mathbb{ET}$ space. Lastly, we propose a trajectory anchor-based refinement method to cover all possible futures in the proposed $\\mathbb{ET}$ space. Extensive experiments demonstrate that our EigenTrajectory predictor can significantly improve both the prediction accuracy and reliability of existing trajectory forecasting models on public benchmarks, indicating that the proposed descriptor is suited to represent pedestrian behaviors. Code is publicly available at https://github.com/inhwanbae/EigenTrajectory .",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2064764883",
                        "name": "Inhwan Bae"
                    },
                    {
                        "authorId": "143904954",
                        "name": "Jean Oh"
                    },
                    {
                        "authorId": "39060641",
                        "name": "Hae-Gon Jeon"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In contrast to the introduction of additional reward functions to regulate the action trajectory of unmanned ships, such as the terms of a ship sailing with a large angular speed [9], an inappropriate distance between two ships [10], or a violation of maritime social norms [11], the knowledge distillation approach in this paper relies mainly on human crew expert strategies , i."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "71bee9c699cad8649c3cfa61a6e2e53ea5129058",
                "externalIds": {
                    "DOI": "10.1117/12.2683345",
                    "CorpusId": 259263273
                },
                "corpusId": 259263273,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/71bee9c699cad8649c3cfa61a6e2e53ea5129058",
                "title": "Personified multi-ship collision avoidance navigation on knowledge distillation",
                "abstract": "In systems where unmanned navigation and manned behavior of ships coexist, the intelligence-driven unmanned ships lack the adaptability to complex environments that humans exhibit when faced with realistic navigation environments and will affect the decision judgment of manned ships. To solve the problem, a knowledge distillation-based multi-intelligent body maritime collision avoidance navigation method for human-like behavior is proposed. The method first preprocesses the AIS data, and the core technique is to use the knowledge distillation method to combine the expert strategy with the reinforcement learning method, which introduces the human piloting ship habits and makes the ship\u2019s automatic navigation exhibit human characteristics. The test results show that the unmanned ship trained by the method can learn human driving ship habits outside the reinforcement learning reward function setting, and enhance the training efficiency of reinforcement learning.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2125181044",
                        "name": "Qinyan Zhong"
                    },
                    {
                        "authorId": "2145954296",
                        "name": "Yang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In spite of the progress, human trajectory prediction still remains a challenging problem since the social environments are complex and biased (Liu, Yan, and Alahi 2021; Chen et al. 2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "610924a1aa60494f01158fdb9cb680d0e6203148",
                "externalIds": {
                    "DBLP": "conf/aaai/GeSH23",
                    "DOI": "10.1609/aaai.v37i1.25142",
                    "CorpusId": 259687748
                },
                "corpusId": 259687748,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/610924a1aa60494f01158fdb9cb680d0e6203148",
                "title": "Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism",
                "abstract": "Human trajectory Prediction (HTP) in complex social environments plays a crucial and fundamental role in artificial intelligence systems. Conventional methods make use of both history behaviors and social interactions to forecast future trajectories. However, we demonstrate that the social environment is a confounder that misleads the model to learn spurious correlations between history and future trajectories. To end this, we first formulate the social environment, history and future trajectory variables into a structural causal model to analyze the causalities among them. Based on causal intervention rather than conventional likelihood, we propose a Social Environment ADjustment (SEAD) method, to remove the confounding effect of the social environment. The core of our method is implemented by a Social Cross Attention (SCA) module, which is universal, simple and effective. Our method has consistent improvements on ETH-UCY datasets with three baseline models and achieves competitive performances with existing methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2130368185",
                        "name": "Chunjiang Ge"
                    },
                    {
                        "authorId": "30619669",
                        "name": "S. Song"
                    },
                    {
                        "authorId": "2115218570",
                        "name": "Gao Huang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "8c6eef90065c8c35e6051e80478c993b48a783e8",
                "externalIds": {
                    "DBLP": "conf/aaai/BaeJ23",
                    "DOI": "10.1609/aaai.v37i5.25759",
                    "CorpusId": 259697264
                },
                "corpusId": 259697264,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/8c6eef90065c8c35e6051e80478c993b48a783e8",
                "title": "A Set of Control Points Conditioned Pedestrian Trajectory Prediction",
                "abstract": "Predicting the trajectories of pedestrians in crowded conditions is an important task for applications like autonomous navigation systems. Previous studies have tackled this problem using two strategies. They (1) infer all future steps recursively, or (2) predict the potential destinations of pedestrians at once and interpolate the intermediate steps to arrive there. However, these strategies often suffer from the accumulated errors of the recursive inference, or restrictive assumptions about social relations in the intermediate path. In this paper, we present a graph convolutional network-based trajectory prediction. Firstly, we propose a control point prediction that divides the future path into three sections and infers the intermediate destinations of pedestrians to reduce the accumulated error. To do this, we construct multi-relational weighted graphs to account for their physical and complex social relations. We then introduce a trajectory refinement step based on a spatio-temporal and multi-relational graph. By considering the social interactions between neighbors, better prediction results are achievable. In experiments, the proposed network achieves state-of-the-art performance on various real-world trajectory prediction benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2064764883",
                        "name": "Inhwan Bae"
                    },
                    {
                        "authorId": "39060641",
                        "name": "Hae-Gon Jeon"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Self-supervised contrastive learning (SSCL) has demonstrated remarkable performance in computer vision (CV) (He et al., 2020; Chen et al., 2020a; Kotar et al., 2021), natural language processing (NLP) (Gao et al., 2021; Liu et al., 2021a) and many other domains (Liu et al., 2021c,b)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "2c0bf423b46b911918519f65a5853dd2eaf238da",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-12086",
                    "ArXiv": "2306.12086",
                    "DOI": "10.48550/arXiv.2306.12086",
                    "CorpusId": 259211907
                },
                "corpusId": 259211907,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2c0bf423b46b911918519f65a5853dd2eaf238da",
                "title": "What Constitutes Good Contrastive Learning in Time-Series Forecasting?",
                "abstract": "In recent years, the introduction of self-supervised contrastive learning (SSCL) has demonstrated remarkable improvements in representation learning across various domains, including natural language processing and computer vision. By leveraging the inherent benefits of self-supervision, SSCL enables the pre-training of representation models using vast amounts of unlabeled data. Despite these advances, there remains a significant gap in understanding the impact of different SSCL strategies on time series forecasting performance, as well as the specific benefits that SSCL can bring. This paper aims to address these gaps by conducting a comprehensive analysis of the effectiveness of various training variables, including different SSCL algorithms, learning strategies, model architectures, and their interplay. Additionally, to gain deeper insights into the improvements brought about by SSCL in the context of time-series forecasting, a qualitative analysis of the empirical receptive field is performed. Through our experiments, we demonstrate that the end-to-end training of a Transformer model using the Mean Squared Error (MSE) loss and SSCL emerges as the most effective approach in time series forecasting. Notably, the incorporation of the contrastive objective enables the model to prioritize more pertinent information for forecasting, such as scale and periodic relationships. These findings contribute to a better understanding of the benefits of SSCL in time series forecasting and provide valuable insights for future research in this area. Our codes are available at https://github.com/chiyuzhang94/contrastive_learning_time-series_e2e.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2115813573",
                        "name": "Chiyu Zhang"
                    },
                    {
                        "authorId": "2072779974",
                        "name": "Qi Yan"
                    },
                    {
                        "authorId": "2152000330",
                        "name": "Li Meng"
                    },
                    {
                        "authorId": "8118056",
                        "name": "Tristan Sylvain"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Among multi-future trajectory prediction methods, some researches [9], [12], [13] learned the pattern of agent behavior only using the history trajectories of agents.",
                "(3)Social-NCE [13]: A method that learned socially-aware motion representations using illdistributed data."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "663672f4b937e367b5fa6c51388671952d5d892a",
                "externalIds": {
                    "DBLP": "conf/ijcnn/YangHCG23",
                    "DOI": "10.1109/IJCNN54540.2023.10191508",
                    "CorpusId": 260385444
                },
                "corpusId": 260385444,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/663672f4b937e367b5fa6c51388671952d5d892a",
                "title": "Learn to Encode Heterogeneous Data: A Heterogeneous Aware Network for Multi-Future Trajectory Prediction",
                "abstract": "With the development of intelligent transportation and human-robot interaction systems in recent years, the demand for multi-future trajectory prediction is increasing rapidly. A key challenge is to model the stochasticity of future agents motion, which affects the prediction for Multi-Future Trajectory directly. Numerous trajectory prediction methods have been proposed by using heterogeneous data composed of High Definition (HD) maps and agents' history trajectories to model the future agents motion. As we know, regions where there is an object will enter contain more valuable features than regions where there is an object has already passed through. But existing methods are usually influenced by the passed regions in HD maps, which leads to unreasonable predictions. To mitigate this problem, we present a conditional variational autoencoder based model, called Heterogeneous Aware Network (HANet), to forecast trajectories of agents in real-world scenes. The HANet is embedded with a carefully designed Discriminative Region Exploring module (DRE) to encode heterogeneous data. We also tailor a Predictive Sampling Strategy (PSS) to help the DRE focus on regions that agents will enter. The proposed HANet achieves competitive results on a real-world public dataset nuScenes compared with SOTA methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "15556874",
                        "name": "Zheng Yang"
                    },
                    {
                        "authorId": "1596815357",
                        "name": "B. Han"
                    },
                    {
                        "authorId": "2193068478",
                        "name": "Weiming Chen"
                    },
                    {
                        "authorId": "2228210089",
                        "name": "Xin Gao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "SOTA methods have employed a variety of techniques for better modeling, such as using waypoints and goals to break the forecasting problem into a series of hierarchical steps [11, 34, 63, 7, 8, 61, 64, 54, 52], mathematical and physical modeling techniques such as social forces [17] alongside deep architectures [61, 52, 31], and other paradigms and techniques such as memory retrieval [53], contrastive learning [33], and causal disentanglement [32].",
                "Collision Rate (CR) is a joint evaluation metric that has seen greater attention in more recent works as members of the trajectory forecasting community begin to pay more attention to social compliance and effective joint modeling [25, 46, 23, 26, 33, 43]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "b0cd566b562eff918d9b9c8dd897672ac26cd9b2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-06292",
                    "ArXiv": "2305.06292",
                    "DOI": "10.48550/arXiv.2305.06292",
                    "CorpusId": 258588337
                },
                "corpusId": 258588337,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b0cd566b562eff918d9b9c8dd897672ac26cd9b2",
                "title": "Joint Metrics Matter: A Better Standard for Trajectory Forecasting",
                "abstract": "Multi-modal trajectory forecasting methods commonly evaluate using single-agent metrics (marginal metrics), such as minimum Average Displacement Error (ADE) and Final Displacement Error (FDE), which fail to capture joint performance of multiple interacting agents. Only focusing on marginal metrics can lead to unnatural predictions, such as colliding trajectories or diverging trajectories for people who are clearly walking together as a group. Consequently, methods optimized for marginal metrics lead to overly-optimistic estimations of performance, which is detrimental to progress in trajectory forecasting research. In response to the limitations of marginal metrics, we present the first comprehensive evaluation of state-of-the-art (SOTA) trajectory forecasting methods with respect to multi-agent metrics (joint metrics): JADE, JFDE, and collision rate. We demonstrate the importance of joint metrics as opposed to marginal metrics with quantitative evidence and qualitative examples drawn from the ETH / UCY and Stanford Drone datasets. We introduce a new loss function incorporating joint metrics that, when applied to a SOTA trajectory forecasting method, achieves a 7% improvement in JADE / JFDE on the ETH / UCY datasets with respect to the previous SOTA. Our results also indicate that optimizing for joint metrics naturally leads to an improvement in interaction modeling, as evidenced by a 16% decrease in mean collision rate on the ETH / UCY datasets with respect to the previous SOTA.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1403697181",
                        "name": "Erica Weng"
                    },
                    {
                        "authorId": "47379300",
                        "name": "Hanako Hoshino"
                    },
                    {
                        "authorId": "1770537",
                        "name": "Deva Ramanan"
                    },
                    {
                        "authorId": "37991449",
                        "name": "Kris M. Kitani"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Learning socially aware motion representations is at the core of recent advances in multiagent problems [7]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "af6b99ca8730934658a3a505dfa8a58b2f011b90",
                "externalIds": {
                    "DBLP": "journals/iotj/LiSGHYW23",
                    "DOI": "10.1109/JIOT.2022.3228818",
                    "CorpusId": 254662719
                },
                "corpusId": 254662719,
                "publicationVenue": {
                    "id": "228761ec-c40a-479b-8309-9dcbe9851bcd",
                    "name": "IEEE Internet of Things Journal",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Internet Thing J"
                    ],
                    "issn": "2327-4662",
                    "url": "https://www.ieee.org/membership-catalog/productdetail/showProductDetailPage.html?product=PER288-ELE",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/servlet/opac?punumber=6488907",
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6488907",
                        "http://ieee-iotj.org/#"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/af6b99ca8730934658a3a505dfa8a58b2f011b90",
                "title": "TraGCAN: Trajectory Prediction of Heterogeneous Traffic Agents in IoV Systems",
                "abstract": "As a core component of the Internet of Vehicles, reasoning about the trajectory of pedestrians or vehicles in complex road conditions plays a critical role in autonomous driving and socially aware robotic navigation. Most existing methods do not adequately consider the effects of heterogeneous traffic agents. Toward this end, we propose the traffic trajectory prediction algorithm based on the convolutional attention network (TraGCAN) to predict the trajectories of heterogeneous traffic agents in dense traffic. The algorithm of the proposed method examines the behavior of different traffic agents in terms of both time and space dimensions to identify their movement patterns and interactions. We construct the spatial relationship of traffic agents as a graph structure and introduce a graph convolutional network to extract spatial interactions. In addition, we design a spatial attention mechanism to adaptively calculate weights for all spatial interactions to capture different influences from neighboring agents. To improve the accuracy of trajectory prediction, the algorithm considers the influence of the heterogeneous characteristics of traffic agents on their motion behaviors. We evaluated the performance of the proposed TraGCAN on heterogeneous traffic data sets, and the results demonstrate that the error of TraGCAN is reduced by 15% compared to existing methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47786295",
                        "name": "Jie Li"
                    },
                    {
                        "authorId": "2196051817",
                        "name": "Han Shi"
                    },
                    {
                        "authorId": "2124928567",
                        "name": "Yue Guo"
                    },
                    {
                        "authorId": "2069677071",
                        "name": "Guangjie Han"
                    },
                    {
                        "authorId": "2277305",
                        "name": "Ruiyun Yu"
                    },
                    {
                        "authorId": "2144805093",
                        "name": "Xingwei Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Another kind of methods [8,9,19,21,25,59,63] formulates the trajectory prediction as CVAE [45], which applies observed trajectory as condition and learn a latent random variable to model multimodality.",
                "For a GAN-based model, pz is a multivariate normal distribution, and for a CVAEbased model, pz is a latent distribution.",
                "Another category exploits the variational auto-encoder (VAE) [21,26,30,41,51] that uses the observed\n*Authors contributed equally and are listed alphabetically by first name.\nhistory trajectories as a condition to learn the latent variable.",
                "Another category exploits the variational auto-encoder (VAE) [21,26,30,41,50] that uses the observed",
                "Trajectron++ [41] uses the observation as the condition to learn a CVAE with the learned discrete latent variable.",
                "We optimize these end-points whose prior is the learned Endpoint VAE."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "ecff6ecf349f3b2ea36bc666acf5671f836f4e7d",
                "externalIds": {
                    "DBLP": "conf/cvpr/ChenCFZ23",
                    "ArXiv": "2304.04298",
                    "DOI": "10.1109/CVPR52729.2023.01714",
                    "CorpusId": 258048886
                },
                "corpusId": 258048886,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ecff6ecf349f3b2ea36bc666acf5671f836f4e7d",
                "title": "Unsupervised Sampling Promoting for Stochastic Human Trajectory Prediction",
                "abstract": "The indeterminate nature of human motion requires trajectory prediction systems to use a probabilistic model to formulate the multi-modality phenomenon and infer a finite set of future trajectories. However, the inference processes of most existing methods rely on Monte Carlo random sampling, which is insufficient to cover the realistic paths with finite samples, due to the long tail effect of the predicted distribution. To promote the sampling process of stochastic prediction, we propose a novel method, called BOsampler, to adaptively mine potential paths with Bayesian optimization in an unsupervised manner, as a sequential design strategy in which new prediction is dependent on the previously drawn samples. Specifically, we model the trajectory sampling as a Gaussian process and construct an acquisition function to measure the potential sampling value. This acquisition function applies the original distribution as prior and encourages exploring paths in the long-tail region. This sampling method can be integrated with existing stochastic predictive models without retraining. Experimental results on various baseline methods demonstrate the effectiveness of our method. The source code is released in this link.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2155315836",
                        "name": "Guan-Hong Chen"
                    },
                    {
                        "authorId": "2144321586",
                        "name": "Zhe Chen"
                    },
                    {
                        "authorId": "2213753651",
                        "name": "Shunxing Fan"
                    },
                    {
                        "authorId": "2175349484",
                        "name": "Kun Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Social-NCE [26] uses contrastive learning to make the predictions away from their simulated collision cases."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "0acce07a83281dfae981c3230e224e8c9eb6c015",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-16574",
                    "ArXiv": "2303.16574",
                    "DOI": "10.1109/CVPR52729.2023.00141",
                    "CorpusId": 257804547
                },
                "corpusId": 257804547,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0acce07a83281dfae981c3230e224e8c9eb6c015",
                "title": "FEND: A Future Enhanced Distribution-Aware Contrastive Learning Framework for Long-Tail Trajectory Prediction",
                "abstract": "Predicting the future trajectories of the traffic agents is a gordian technique in autonomous driving. However, trajectory prediction suffers from data imbalance in the prevalent datasets, and the tailed data is often more complicated and safety-critical. In this paper, we focus on dealing with the long-tail phenomenon in trajectory prediction. Previous methods dealing with long-tail data did not take into account the variety of motion patterns in the tailed data. In this paper, we put forward a future enhanced contrastive learning framework to recognize tail trajectory patterns and form a feature space with separate pattern clusters. Furthermore, a distribution aware hyper predictor is brought up to better utilize the shaped feature space. Our method is a model-agnostic framework and can be plugged into many well-known baselines. Experimental results show that our framework outperforms the state-of-the-art long-tail prediction method on tailed samples by 9.5% on ADE and 8.5% on FDE, while maintaining or slightly improving the averaged performance. Our method also surpasses many long-tail techniques on trajectory prediction task.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2107924952",
                        "name": "Yuning Wang"
                    },
                    {
                        "authorId": "2110106505",
                        "name": "Pu Zhang"
                    },
                    {
                        "authorId": "50010487",
                        "name": "Lei Bai"
                    },
                    {
                        "authorId": "2189422900",
                        "name": "Jianru Xue"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In particular, the spatial correlation among pedestrians is attributed to the result of social factors [15, 1, 29].",
                "Other than the deterministic approaches SocialLSTM [1] and STT [33], the rest include models with implicit density functions: SocialGAN [14], SoPhie [37], Social-BIGAT [24], MGGAN [9], as well as the explicit ones: Trajectron++ [38], S-STGCNN [32], C-STGCNN [6], N-STGCNN [29] and DMRGCN [3]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "4ced6412d07a986d468bef9f4021398d978807b5",
                "externalIds": {
                    "ArXiv": "2303.08367",
                    "DBLP": "journals/corr/abs-2303-08367",
                    "DOI": "10.48550/arXiv.2303.08367",
                    "CorpusId": 257532281
                },
                "corpusId": 257532281,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4ced6412d07a986d468bef9f4021398d978807b5",
                "title": "Uncertainty-Aware Pedestrian Trajectory Prediction via Distributional Diffusion",
                "abstract": "Tremendous efforts have been devoted to pedestrian trajectory prediction using generative modeling for accommodating uncertainty and multi-modality in human behaviors. An individual's inherent uncertainty, e.g., change of destination, can be masked by complex patterns resulting from the movements of interacting pedestrians. However, latent variable-based generative models often entangle such uncertainty with complexity, leading to either limited expressivity or overconfident predictions. In this work, we propose to separately model these two factors by implicitly deriving a flexible distribution that describes complex pedestrians' movements, whereas incorporating predictive uncertainty of individuals with explicit density functions over their future locations. More specifically, we present an uncertainty-aware pedestrian trajectory prediction framework, parameterizing sufficient statistics for the distributions of locations that jointly comprise the multi-modal trajectories. We further estimate these parameters of interest by approximating a denoising process that progressively recovers pedestrian movements from noise. Unlike prior studies, we translate the predictive stochasticity to the explicit distribution, making it readily used to generate plausible future trajectories indicating individuals' self-uncertainty. Moreover, our framework is model-agnostic for compatibility with different neural network architectures. We empirically show the performance advantages of our framework on widely-used benchmarks, outperforming state-of-the-art in most scenes even with lighter backbones.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2185944320",
                        "name": "Yao Liu"
                    },
                    {
                        "authorId": "2158121071",
                        "name": "Zesheng Ye"
                    },
                    {
                        "authorId": "3125448",
                        "name": "Binghao Li"
                    },
                    {
                        "authorId": "145095579",
                        "name": "L. Yao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Some methods explicitly model the social interactions between pedestrians using attention [14, 29] or contrastive learning [19] in order to enhance future trajectory prediction."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "c513bfe63399034be632cc65e45f115abef7d530",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-01426",
                    "ArXiv": "2212.01426",
                    "DOI": "10.48550/arXiv.2212.01426",
                    "CorpusId": 254247297
                },
                "corpusId": 254247297,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c513bfe63399034be632cc65e45f115abef7d530",
                "title": "Learning a Pedestrian Social Behavior Dictionary",
                "abstract": "Understanding pedestrian behavior patterns is a key component to building autonomous agents that can navigate among humans. We seek a learned dictionary of pedestrian behavior to obtain a semantic description of pedestrian trajectories. Supervised methods for dictionary learning are impractical since pedestrian behaviors may be unknown a priori and the process of manually generating behavior labels is prohibitively time consuming. We instead utilize a novel, unsupervised framework to create a taxonomy of pedestrian behavior observed in a specific space. First, we learn a trajectory latent space that enables unsupervised clustering to create an interpretable pedestrian behavior dictionary. We show the utility of this dictionary for building pedestrian behavior maps to visualize space usage patterns and for computing the distributions of behaviors. We demonstrate a simple but effective trajectory prediction by conditioning on these behavior labels. While many trajectory analysis methods rely on RNNs or transformers, we develop a lightweight, low-parameter approach and show results comparable to SOTA on the ETH and UCY datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "143672988",
                        "name": "Faith Johnson"
                    },
                    {
                        "authorId": "1710772",
                        "name": "Kristin J. Dana"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[21] introduced a social contrastive loss that regularizes the extracted motion representation by discerning the ground truth positive events from synthetic negative ones."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "b1da8de77face6abc54529b81ee97d38f95826e0",
                "externalIds": {
                    "DBLP": "journals/sensors/ChenCLGTL22",
                    "PubMedCentral": "9788537",
                    "DOI": "10.3390/s22249943",
                    "CorpusId": 254921418,
                    "PubMed": "36560308"
                },
                "corpusId": 254921418,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b1da8de77face6abc54529b81ee97d38f95826e0",
                "title": "Driver Intent-Based Intersection Autonomous Driving Collision Avoidance Reinforcement Learning Algorithm",
                "abstract": "With the rapid development of artificial intelligent technology, the deep learning method is widely applied to predict human driving intentions due to its relative accuracy of prediction, which is one of critical links for security guarantee in the distributed, mixed driving scenario. In order to sense the intention of human-driven vehicles and reduce the self-driving collision avoidance rate, an improved intention prediction method for human-driving vehicles based on unsupervised, deep inverse reinforcement learning is proposed. Firstly, a contrast discriminator module was proposed to extract richer features. Then, the residual module was created to overcome the drawbacks of gradient disappearance and network degradation with the increase in network layers. Furthermore, the dropout layer was generated to prevent the over-fitting phenomenon in the whole training process of the GRU network, so as to improve the generalization ability of the network model. Finally, abundant experiments were conducted on datasets to evaluate our proposed method. The pass rate of self-driving vehicles with conservative driver probabilities of p = 0.25, p = 0.4, and p = 0.6 improved by a maximum of 8%, 10%, and 3%, compared with the classical method LSTM and VAE + RNN. It indicates that the prediction results of our proposed method fit more with the basic structure of the given traffic scenario in a long-term prediction range, which verifies the effectiveness of our proposed method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145358509",
                        "name": "Ting Chen"
                    },
                    {
                        "authorId": "2197589918",
                        "name": "Youjing Chen"
                    },
                    {
                        "authorId": "1706574",
                        "name": "Hao Li"
                    },
                    {
                        "authorId": "2072687022",
                        "name": "Tao Gao"
                    },
                    {
                        "authorId": "2014673",
                        "name": "H. Tu"
                    },
                    {
                        "authorId": "2118155902",
                        "name": "Siyu Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In the motion context, negative data augmentation techniques have been applied in a limited scope to reduce collisions [10] and off-road predictions [24] on new domains.",
                "Some recent methods propose to incorporate strong priors robust to the underlying distribution shifts [9, 10, 11]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "f258807dd9e9d7ab26bba8d821780a6ea399a089",
                "externalIds": {
                    "DBLP": "conf/corl/KothariLLA22",
                    "ArXiv": "2211.03165",
                    "DOI": "10.48550/arXiv.2211.03165",
                    "CorpusId": 253384604
                },
                "corpusId": 253384604,
                "publicationVenue": {
                    "id": "fbfbf10a-faa4-4d2a-85be-3ac660454ce3",
                    "name": "Conference on Robot Learning",
                    "type": "conference",
                    "alternate_names": [
                        "CoRL",
                        "Conf Robot Learn"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f258807dd9e9d7ab26bba8d821780a6ea399a089",
                "title": "Motion Style Transfer: Modular Low-Rank Adaptation for Deep Motion Forecasting",
                "abstract": "Deep motion forecasting models have achieved great success when trained on a massive amount of data. Yet, they often perform poorly when training data is limited. To address this challenge, we propose a transfer learning approach for efficiently adapting pre-trained forecasting models to new domains, such as unseen agent types and scene contexts. Unlike the conventional fine-tuning approach that updates the whole encoder, our main idea is to reduce the amount of tunable parameters that can precisely account for the target domain-specific motion style. To this end, we introduce two components that exploit our prior knowledge of motion style shifts: (i) a low-rank motion style adapter that projects and adjusts the style features at a low-dimensional bottleneck; and (ii) a modular adapter strategy that disentangles the features of scene context and motion history to facilitate a fine-grained choice of adaptation layers. Through extensive experimentation, we show that our proposed adapter design, coined MoSA, outperforms prior methods on several forecasting benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "81029804",
                        "name": "Parth Kothari"
                    },
                    {
                        "authorId": "2187698193",
                        "name": "Danyang Li"
                    },
                    {
                        "authorId": "14772333",
                        "name": "Yuejiang Liu"
                    },
                    {
                        "authorId": "3304525",
                        "name": "Alexandre Alahi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(DRL) [4], [5], [6] have outperformed classical approaches in the field of dynamic obstacle avoidance without map constraints, their performance degrades when subjected to complex layouts without pre-computed map in presence of several moving obstacles."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "971f8f87aca4a3a1f36eff2c58ecaec6909618bd",
                "externalIds": {
                    "DBLP": "conf/iros/PandyaPL22",
                    "DOI": "10.1109/IROS47612.2022.9981479",
                    "CorpusId": 250385223
                },
                "corpusId": 250385223,
                "publicationVenue": {
                    "id": "37275deb-3fcf-4d16-ae77-95db9899b1f3",
                    "name": "IEEE/RJS International Conference on Intelligent RObots and Systems",
                    "type": "conference",
                    "alternate_names": [
                        "IROS",
                        "Intelligent Robots and Systems",
                        "Intell Robot Syst",
                        "IEEE/RJS Int Conf Intell Robot Syst"
                    ],
                    "url": "http://www.iros.org/"
                },
                "url": "https://www.semanticscholar.org/paper/971f8f87aca4a3a1f36eff2c58ecaec6909618bd",
                "title": "CoMBiNED: Multi-Constrained Model Based Planning for Navigation in Dynamic Environments",
                "abstract": "Recent deep reinforcement learning (DRL) approaches have achieved high success rate in map-less dynamic obstacle avoidance tasks. However, navigation in unseen dynamic scenarios without a pre-built map in the presence of dynamic obstacles still remains an open challenge. Since, learning accurate models for complex robotic scenarios such as navigation directly from high dimensional sensory measurements requires a large amount of data and training. Furthermore, even a small change on robot configuration such as kino-dynamics or sensor in the inference time requires re-training of the policy. In this paper, we address these issues in a principled fashion through a multi-constraint model based online planning (CoMBiNED) framework that does not require any retraining or modifications on the existing policy. We disentangle the given task into sub-tasks and learn dynamical models for them. Treating these dynamical models as soft-constraints, we employ stochastic optimisation to jointly optimize these sub-tasks on-the-fly at the inference time. We consider navigation as central application in this work and evaluate our approach on publicly available benchmark with complex dynamic scenarios and achieved significant improvement over recent approaches both in the cases of with-and-without given map of the environment.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3072183",
                        "name": "Harit Pandya"
                    },
                    {
                        "authorId": "143840956",
                        "name": "Rudra P. K. Poudel"
                    },
                    {
                        "authorId": "2297234",
                        "name": "Stephan Liwicki"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In the fully supervised learning domain, previous works have shown that utilizing contrastive loss as an auxiliary loss can encourage learning more robust features with higher generalization abilities through careful contrastive pair construction [22, 23].",
                "CL has shown great promise in self-supervised regimes [6, 9, 13] while recently, it has also been applied to the supervised learning domain and achieved promising results [19, 22, 23]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "161ece0ce6c22a8060eabf41369c4b1447b27c09",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-02748",
                    "ArXiv": "2210.02748",
                    "DOI": "10.48550/arXiv.2210.02748",
                    "CorpusId": 252734881
                },
                "corpusId": 252734881,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/161ece0ce6c22a8060eabf41369c4b1447b27c09",
                "title": "CLAD: A Contrastive Learning based Approach for Background Debiasing",
                "abstract": "Convolutional neural networks (CNNs) have achieved superhuman performance in multiple vision tasks, especially image classification. However, unlike humans, CNNs leverage spurious features, such as background information to make decisions. This tendency creates different problems in terms of robustness or weak generalization performance. Through our work, we introduce a contrastive learning-based approach (CLAD) to mitigate the background bias in CNNs. CLAD encourages semantic focus on object foregrounds and penalizes learning features from irrelavant backgrounds. Our method also introduces an efficient way of sampling negative samples. We achieve state-of-the-art results on the Background Challenge dataset, outperforming the previous benchmark with a margin of 4.1\\%. Our paper shows how CLAD serves as a proof of concept for debiasing of spurious features, such as background and texture (in supplementary material).",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2133843028",
                        "name": "Ke Wang"
                    },
                    {
                        "authorId": "51265012",
                        "name": "Harshitha Machiraju"
                    },
                    {
                        "authorId": "3829343",
                        "name": "Oh-hyeon Choung"
                    },
                    {
                        "authorId": "2065431850",
                        "name": "Michael Herzog"
                    },
                    {
                        "authorId": "1703189",
                        "name": "P. Frossard"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Social-NCE [58] adopts contrastive loss in order to encourage keeping the positive event information from the negative information."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "e4d6d3b50207dffbc16e1ecf14d7bcb99cbdec80",
                "externalIds": {
                    "PubMedCentral": "9609386",
                    "DBLP": "journals/sensors/YooLB22",
                    "DOI": "10.3390/s22207943",
                    "CorpusId": 253033841,
                    "PubMed": "36298293"
                },
                "corpusId": 253033841,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e4d6d3b50207dffbc16e1ecf14d7bcb99cbdec80",
                "title": "Effective Multi-Object Tracking via Global Object Models and Object Constraint Learning",
                "abstract": "Effective multi-object tracking is still challenging due to the trade-off between tracking accuracy and speed. Because the recent multi-object tracking (MOT) methods leverage object appearance and motion models so as to associate detections between consecutive frames, the key for effective multi-object tracking is to reduce the computational complexity of learning both models. To this end, this work proposes global appearance and motion models to discriminate multiple objects instead of learning local object-specific models. In concrete detail, it learns a global appearance model using contrastive learning between object appearances. In addition, we learn a global relation motion model using relative motion learning between objects. Moreover, this paper proposes object constraint learning for improving tracking efficiency. This study considers the discriminability of the models as a constraint, and learns both models when inconsistency with the constraint occurs. Therefore, object constraint learning differs from the conventional online learning for multi-object tracking which updates learnable parameters per frame. This work incorporates global models and object constraint learning into the confidence-based association method, and compare our tracker with the state-of-the-art methods on public available MOT Challenge datasets. As a result, we achieve 64.5% MOTA (multi-object tracking accuracy) and 6.54 Hz tracking speed on the MOT16 test dataset. The comparison results show that our methods can contribute to improve tracking accuracy and tracking speed together.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2061176497",
                        "name": "Yong-Sang Yoo"
                    },
                    {
                        "authorId": "2188453124",
                        "name": "Seong-Ho Lee"
                    },
                    {
                        "authorId": "9431105",
                        "name": "Seung-Hwan Bae"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The first part of Table V reports simple baselines and the top-3 official submissions on AICrowd made by different works literature [23], [24], [40]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c21537ddf9258840f5ab8db19577001950592193",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-12243",
                    "ArXiv": "2209.12243",
                    "DOI": "10.1109/TITS.2022.3233906",
                    "CorpusId": 252532079
                },
                "corpusId": 252532079,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c21537ddf9258840f5ab8db19577001950592193",
                "title": "Safety-Compliant Generative Adversarial Networks for Human Trajectory Forecasting",
                "abstract": "Human trajectory forecasting in crowds presents the challenges of modelling social interactions and outputting collision-free multimodal distribution. Following the success of Social Generative Adversarial Networks (SGAN), recent works propose various GAN-based designs to better model human motion in crowds. Despite superior performance in reducing distance-based metrics, current networks fail to output socially acceptable trajectories, as evidenced by high collisions in model predictions. To counter this, we introduce SGANv2: an improved safety-compliant SGAN architecture equipped with spatio-temporal interaction modelling and a transformer-based discriminator. The spatio-temporal modelling ability helps to learn the human social interactions better while the transformer-based discriminator design improves temporal sequence modelling. Additionally, SGANv2 utilizes the learned discriminator even at test-time via a collaborative sampling strategy that not only refines the colliding trajectories but also prevents mode collapse, a common phenomenon in GAN training. Through extensive experimentation on multiple real-world and synthetic datasets, we demonstrate the efficacy of SGANv2 to provide socially-compliant multimodal trajectories.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "81029804",
                        "name": "Parth Kothari"
                    },
                    {
                        "authorId": "3304525",
                        "name": "Alexandre Alahi"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "63eef713881eb0b98274d738591b95e078f54436",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-09284",
                    "ArXiv": "2208.09284",
                    "DOI": "10.5281/zenodo.6574697",
                    "CorpusId": 247581833
                },
                "corpusId": 247581833,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/63eef713881eb0b98274d738591b95e078f54436",
                "title": "Reproducibility Report: Contrastive Learning of Socially-aware Motion Representations",
                "abstract": "The following paper is a reproducibility report for\"Social NCE: Contrastive Learning of Socially-aware Motion Representations\"{\\cite{liu2020snce}} published in ICCV 2021 as part of the ML Reproducibility Challenge 2021. The original code was made available by the author \\footnote{\\href{https://github.com/vita-epfl/social-nce}{https://github.com/vita-epfl/social-nce}}. We attempted to verify the results claimed by the authors and reimplemented their code in PyTorch Lightning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2158737448",
                        "name": "Roop Sen"
                    },
                    {
                        "authorId": "2182222377",
                        "name": "Sidharth Sinha"
                    },
                    {
                        "authorId": "2126964836",
                        "name": "Parv Maheshwari"
                    },
                    {
                        "authorId": "2131121790",
                        "name": "Animesh Jha"
                    },
                    {
                        "authorId": "2086973907",
                        "name": "Debashish Chakravarty"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Since there is no ground truth, to evaluate the prediction plausibility, we employ collision rate because it is widely adopted [34] and parsimonious: regardless of the specific behaviors of agents, they do not penetrate each other in the real world."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a4e3dd8af9fe7982b5599ce32e96371b15a3aa43",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-10435",
                    "ArXiv": "2207.10435",
                    "DOI": "10.48550/arXiv.2207.10435",
                    "CorpusId": 250919939
                },
                "corpusId": 250919939,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/a4e3dd8af9fe7982b5599ce32e96371b15a3aa43",
                "title": "Human Trajectory Prediction via Neural Social Physics",
                "abstract": "Trajectory prediction has been widely pursued in many fields, and many model-based and model-free methods have been explored. The former include rule-based, geometric or optimization-based models, and the latter are mainly comprised of deep learning approaches. In this paper, we propose a new method combining both methodologies based on a new Neural Differential Equation model. Our new model (Neural Social Physics or NSP) is a deep neural network within which we use an explicit physics model with learnable parameters. The explicit physics model serves as a strong inductive bias in modeling pedestrian behaviors, while the rest of the network provides a strong data-fitting capability in terms of system parameter estimation and dynamics stochasticity modeling. We compare NSP with 15 recent deep learning methods on 6 datasets and improve the state-of-the-art performance by 5.56%-70%. Besides, we show that NSP has better generalizability in predicting plausible trajectories in drastically different scenarios where the density is 2-5 times as high as the testing data. Finally, we show that the physics model in NSP can provide plausible explanations for pedestrian behaviors, as opposed to black-box deep learning. Code is available: https://github.com/realcrane/Human-Trajectory-Prediction-via-Neural-Social-Physics.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2178356020",
                        "name": "Jiangbei Yue"
                    },
                    {
                        "authorId": "1699159",
                        "name": "Dinesh Manocha"
                    },
                    {
                        "authorId": "2149698569",
                        "name": "He Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We use same evaluation metrics of previous works [1,17,61,34] for future trajectory prediction."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "1f1fb046452db5b05762973a4fa2b7b63488129a",
                "externalIds": {
                    "DBLP": "conf/eccv/BaePJ22",
                    "ArXiv": "2207.09953",
                    "DOI": "10.48550/arXiv.2207.09953",
                    "CorpusId": 250698905
                },
                "corpusId": 250698905,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/1f1fb046452db5b05762973a4fa2b7b63488129a",
                "title": "Learning Pedestrian Group Representations for Multi-modal Trajectory Prediction",
                "abstract": ". Modeling the dynamics of people walking is a problem of long-standing interest in computer vision. Many previous works involving pedestrian trajectory prediction define a particular set of individual ac-tions to implicitly model group actions. In this paper, we present a novel architecture named GP-Graph which has collective group representations for effective pedestrian trajectory prediction in crowded environments, and is compatible with all types of existing approaches. A key idea of GP-Graph is to model both individual-wise and group-wise relations as graph representations. To do this, GP-Graph first learns to assign each pedestrian into the most likely behavior group. Using this assignment information, GP-Graph then forms both intra- and inter-group interactions as graphs, accounting for human-human relations within a group and group-group relations, respectively. To be specific, for the intra-group interaction, we mask pedestrian graph edges out of an associated group. We also propose group pooling&unpooling operations to represent a group with multiple pedestrians as one graph node. Lastly, GP-Graph infers a probability map for socially-acceptable future trajectories from the integrated features of both group interactions. Moreover, we introduce a group-level latent vector sampling to ensure collective inferences over a set of possible future trajectories. Extensive experiments are conducted to validate the effectiveness of our architecture, which demonstrates consistent performance improvements with publicly available benchmarks. Code is publicly available at https://github.com/inhwanbae/GPGraph .",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2064764883",
                        "name": "Inhwan Bae"
                    },
                    {
                        "authorId": "2160691331",
                        "name": "Jin-Hwi Park"
                    },
                    {
                        "authorId": "39060641",
                        "name": "Hae-Gon Jeon"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Moreover, we also add an augmented version S \u2032 of the anchor trajectory as a positive sample, following [23], which is created by adding small white noise \u03b5 to the bounding box coordinates of the anchor trajectory.",
                "[23] proposed a social sampling strategy that relies on augmenting negative samples with prior knowledge about undesired scenarios in the multi-agent setting.",
                "Few works attempt to address this issue via designing special heuristics for negative mining [23, 38, 13]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "870726ece607b6b8fb7810322fee3092cff80e1d",
                "externalIds": {
                    "DBLP": "conf/eccv/HalawaHB22",
                    "ArXiv": "2207.08664",
                    "DOI": "10.48550/arXiv.2207.08664",
                    "CorpusId": 250627278
                },
                "corpusId": 250627278,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/870726ece607b6b8fb7810322fee3092cff80e1d",
                "title": "Action-based Contrastive Learning for Trajectory Prediction",
                "abstract": ". Trajectory prediction is an essential task for successful human-robot interaction, such as in autonomous driving. In this work, we address the problem of predicting future pedestrian trajectories in a first-person view setting with a moving camera. To that end, we propose a novel action-based contrastive learning loss, that utilizes pedestrian action information to improve the learned trajectory embeddings. The fundamental idea behind this new loss is that trajectories of pedestrians performing the same action should be closer to each other in the feature space than the trajectories of pedestrians with significantly different actions. In other words, we argue that behavioral information about pedestrian action influences their future trajectory. Furthermore, we introduce a novel sampling strategy for trajectories that is able to effectively increase negative and positive contrastive samples. Additional synthetic trajectory samples are generated using a trained Conditional Variational Autoencoder (CVAE), which is at the core of several models developed for trajectory prediction. Results show that our proposed contrastive framework employs contextual information about pedestrian behavior, i.e. action, effectively, and it learns a better trajectory representation. Thus, integrating the proposed contrastive framework within a trajectory prediction model improves its results and outperforms state-of-the-art methods on three trajectory prediction benchmarks [31,32,26]. learning rate of 0.001. On training datasets, we perform hyper-parameter tuning for \u03b2 (Eq. 2). We achieve our best results using \u03b2 = 0 . for all datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1879581146",
                        "name": "Marah Halawa"
                    },
                    {
                        "authorId": "69010848",
                        "name": "O. Hellwich"
                    },
                    {
                        "authorId": "1409487749",
                        "name": "Pia Bideau"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Another set of approach try to refine the learning algorithm by training the model with negative samples of knowledge-driven methods [11], or adding the processed knowledge information to the training data."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "d67cc3c3028a7835ca1b4abf483d0937568dc3d6",
                "externalIds": {
                    "DOI": "10.1088/1742-6596/2303/1/012034",
                    "CorpusId": 251127553
                },
                "corpusId": 251127553,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d67cc3c3028a7835ca1b4abf483d0937568dc3d6",
                "title": "Combining Domain Knowledge and Deep Learning Methods for Vehicle Trajectory Prediction",
                "abstract": "Predicting the future trajectory of surrounding agents is especially crucial for autonomous vehicles applied in dense traffic streams. Majority of the approaches presently implemented for vehicle trajectory prediction can be generally classified into domain knowledge-driven method and deep learning approach. Although domain priori knowledge such as traffic rules implementing in knowledge-driven method has realistic output, the interactive performance with other traffic agents is constrained. Conversely, data-driven approach can acquire superior interactive performance by training the model with huge amounts of data, but the trajectory prediction cannot completely satisfy kinematic constraints, especially to datasets the model has not been explicitly trained on. After carefully design and verification, we put forward a method that combining domain knowledge and deep learning model to output accurate and realistic trajectory prediction. Lastly, we evaluate the result on a public available dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2179544521",
                        "name": "Lihui Lu"
                    },
                    {
                        "authorId": "2108310433",
                        "name": "Qizhong Li"
                    },
                    {
                        "authorId": "35963797",
                        "name": "Jiyuan Liu"
                    },
                    {
                        "authorId": "7956328",
                        "name": "Miaohua Huang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "74a184436ce058caf6f821f16dd7dbac9f652ca2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-02583",
                    "ArXiv": "2206.02583",
                    "DOI": "10.48550/arXiv.2206.02583",
                    "CorpusId": 249395662
                },
                "corpusId": 249395662,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/74a184436ce058caf6f821f16dd7dbac9f652ca2",
                "title": "Consensus Learning for Cooperative Multi-Agent Reinforcement Learning",
                "abstract": "Almost all multi-agent reinforcement learning algorithms without communication follow the principle of centralized training with decentralized execution. During the centralized training, agents can be guided by the same signals, such as the global state. However, agents lack the shared signal and choose actions given local observations during execution. Inspired by viewpoint invariance and contrastive learning, we propose consensus learning for cooperative multi-agent reinforcement learning in this study. Although based on local observations, different agents can infer the same consensus in discrete spaces without communication. We feed the inferred one-hot consensus to the network of agents as an explicit input in a decentralized way, thereby fostering their cooperative spirit. With minor model modifications, our suggested framework can be extended to a variety of multi-agent reinforcement learning algorithms. Moreover, we carry out these variants on some fully cooperative tasks and get convincing results.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "153008118",
                        "name": "Zhiwei Xu"
                    },
                    {
                        "authorId": "2119453124",
                        "name": "Bin Zhang"
                    },
                    {
                        "authorId": "2115499783",
                        "name": "Dapeng Li"
                    },
                    {
                        "authorId": "2048590587",
                        "name": "Zeren Zhang"
                    },
                    {
                        "authorId": "2168379436",
                        "name": "Guangchong Zhou"
                    },
                    {
                        "authorId": "2067827377",
                        "name": "Guoliang Fan"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "8706070056a7c637449f7bc4b40ebb4e3c0a901d",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiP022",
                    "ArXiv": "2206.05712",
                    "DOI": "10.1109/CVPR52688.2022.00227",
                    "CorpusId": 249625717
                },
                "corpusId": 249625717,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8706070056a7c637449f7bc4b40ebb4e3c0a901d",
                "title": "Graph-based Spatial Transformer with Memory Replay for Multi-future Pedestrian Trajectory Prediction",
                "abstract": "Pedestrian trajectory prediction is an essential and challenging task for a variety of real-life applications such as autonomous driving and robotic motion planning. Besides generating a single future path, predicting multiple plausible future paths is becoming popular in some recent work on trajectory prediction. However, existing methods typically emphasize spatial interactions between pedestrians and surrounding areas but ignore the smoothness and temporal consistency of predictions. Our model aims to forecast multiple paths based on a historical trajectory by modeling multi-scale graph-based spatial transformers combined with a trajectory smoothing algorithm named \u201cMemory Replay\u201d utilizing a memory graph. Our method can comprehensively exploit the spatial information as well as correct the temporally inconsistent trajectories (e.g., sharp turns). We also propose a new evaluation metric named \u201cPercentage of Trajectory Usage\u201d to evaluate the comprehensiveness of diverse multi-future predictions. Our extensive experiments show that the proposed model achieves state-of-the-art performance on multi-future prediction and competitive results for single-future prediction. Code released at https://github.com/Jacobieee/ST-MR.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2170231348",
                        "name": "Lihuan Li"
                    },
                    {
                        "authorId": "1783801",
                        "name": "M. Pagnucco"
                    },
                    {
                        "authorId": "2157995570",
                        "name": "Yang Song"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Other approaches [24, 28, 44] propose other strategies such as state refinements, spatiotemporal graph neural networks [18, 39], and social contrastive losses."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "eb4e042dfd21fcd080d80970c7247f68740b2bb7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-11561",
                    "ArXiv": "2204.11561",
                    "DOI": "10.1109/CVPRW56347.2022.00282",
                    "CorpusId": 248377731
                },
                "corpusId": 248377731,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/eb4e042dfd21fcd080d80970c7247f68740b2bb7",
                "title": "Goal-driven Self-Attentive Recurrent Networks for Trajectory Prediction",
                "abstract": "Human trajectory forecasting is a key component of autonomous vehicles, social-aware robots and advanced video-surveillance applications. This challenging task typically requires knowledge about past motion, the environment and likely destination areas. In this context, multi-modality is a fundamental aspect and its effective modeling can be beneficial to any architecture. Inferring accurate trajectories is nevertheless challenging, due to the inherently uncertain nature of the future. To overcome these difficulties, recent models use different inputs and propose to model human intentions using complex fusion mechanisms. In this respect, we propose a lightweight attention-based recurrent backbone that acts solely on past observed positions. Although this backbone already provides promising results, we demonstrate that its prediction accuracy can be improved considerably when combined with a scene-aware goal-estimation module. To this end, we employ a common goal module, based on a U-Net architecture, which additionally extracts semantic information to predict scene-compliant destinations. We conduct extensive experiments on publicly-available datasets (i.e. SDD, inD, ETH/UCY) and show that our approach performs on par with state-of-the-art techniques while reducing model complexity.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2163452124",
                        "name": "Luigi Filippo Chiara"
                    },
                    {
                        "authorId": "29776698",
                        "name": "Pasquale Coscia"
                    },
                    {
                        "authorId": "2109605310",
                        "name": "Sourav Das"
                    },
                    {
                        "authorId": "2175529",
                        "name": "S. Calderara"
                    },
                    {
                        "authorId": "1741922",
                        "name": "R. Cucchiara"
                    },
                    {
                        "authorId": "1795847",
                        "name": "Lamberto Ballan"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "16b8d33462f92cf1c27ab589380c1f2fb42209da",
                "externalIds": {
                    "ArXiv": "2204.10128",
                    "DBLP": "journals/corr/abs-2204-10128",
                    "DOI": "10.48550/arXiv.2204.10128",
                    "CorpusId": 248300015
                },
                "corpusId": 248300015,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/16b8d33462f92cf1c27ab589380c1f2fb42209da",
                "title": "Learnable Model Augmentation Self-Supervised Learning for Sequential Recommendation",
                "abstract": "Sequential Recommendation aims to predict the next item based on user behaviour. Recently, Self-Supervised Learning (SSL) has been proposed to improve recommendation performance. However, most of existing SSL methods use a uniform data augmentation scheme, which loses the sequence correlation of an original sequence. To this end, in this paper, we propose a Learnable Model Augmentation self-supervised learning for sequential Recommendation (LMA4Rec). Specifically, LMA4Rec first takes model augmentation as a supplementary method for data augmentation to generate views. Then, LMA4Rec uses learnable Bernoulli dropout to implement model augmentation learnable operations. Next, self-supervised learning is used between the contrastive views to extract self-supervised signals from an original sequence. Finally, experiments on three public datasets show that the LMA4Rec method effectively improves sequential recommendation performance compared with baseline methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2087103417",
                        "name": "Yongjing Hao"
                    },
                    {
                        "authorId": "2927967",
                        "name": "Pengpeng Zhao"
                    },
                    {
                        "authorId": "2241389",
                        "name": "Xuefeng Xian"
                    },
                    {
                        "authorId": "8540458",
                        "name": "Guanfeng Liu"
                    },
                    {
                        "authorId": "2118962452",
                        "name": "Deqing Wang"
                    },
                    {
                        "authorId": "98756666",
                        "name": "Lei Zhao"
                    },
                    {
                        "authorId": "3215702",
                        "name": "Yanchi Liu"
                    },
                    {
                        "authorId": "2858764",
                        "name": "V. Sheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In particular, when NPSN is incorporated into the combinational approach of Trajectron++ [47] and NCE [32], it achieves the best performances on the benchmark.",
                "Our NPSN is embedded into the state-of-the-art pedestrian trajectory prediction models [6, 13, 17, 32, 34, 39, 47, 49] by simply replacing their random sampling part.",
                "The parameters of the models are initialized using the weights provided by the authors, except for four models [17, 32, 34, 47] which use weights reproduced from the authors\u2019 source codes.",
                "We prove that all of the expected values in the generated trajectory distributions with Generative Adversarial Networks (GANs) [6, 13, 17], Conditional Variational Auto-Encoders (CVAEs) [32, 34, 47], and Gaussian methods [39, 49] are biased.",
                "This approach provides a diverse set of plausible predictions without the variety loss, and shares inspiration to objectives in many CVAE-based models [18, 32, 34, 47, 60].",
                "We evaluate QMC and NPSN sampling methods with representative stochastic pedestrian trajectory prediction models: 1) Gaussian distribution-based model - SocialSTGCNN [39], SGCN [49]; 2) GAN-based model - SocialGAN [13], STGAT [17], Causal-STGAT [6]; 3) CVAEbased model - Trajectron++ [47], PECNet [34], and NCETrajectron++ [32].",
                "Our NPSN is trained to only control the latent vector samples for the baseline models, and synergizes well with the inference step that comes after both the initial prediction of Trajectron++ and the collision avoidance of NCE."
            ],
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "5d8b1eda7d5db0d588b2e1310e759d9d47addb43",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-13471",
                    "ArXiv": "2203.13471",
                    "DOI": "10.1109/CVPR52688.2022.00637",
                    "CorpusId": 247749077
                },
                "corpusId": 247749077,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5d8b1eda7d5db0d588b2e1310e759d9d47addb43",
                "title": "Non-Probability Sampling Network for Stochastic Human Trajectory Prediction",
                "abstract": "Capturing multimodal natures is essential for stochastic pedestrian trajectory prediction, to infer a finite set of future trajectories. The inferred trajectories are based on observation paths and the latent vectors of potential decisions of pedestrians in the inference step. However, stochastic approaches provide varying results for the same data and parameter settings, due to the random sampling of the latent vector. In this paper, we analyze the problem by reconstructing and comparing probabilistic distributions from prediction samples and socially-acceptable paths, respectively. Through this analysis, we observe that the inferences of all stochastic models are biased toward the random sampling, and fail to generate a set of realistic paths from finite samples. The problem cannot be resolved unless an infinite number of samples is available, which is infeasible in practice. We introduce that the Quasi-Monte Carlo (QMC) method, ensuring uniform coverage on the sampling space, as an alternative to the conventional random sampling. With the same finite number of samples, the QMC improves all the multimodal prediction results. We take an additional step ahead by incorporating a learnable sampling network into the existing networks for trajectory prediction. For this purpose, we propose the Non-Probability Sampling Network (NPSN), a very small network (~5K parameters) that generates purposive sample sequences using the past paths of pedestrians and their social interactions. Extensive experiments confirm that NPSN can significantly improve both the prediction accuracy (up to 60%) and reliability of the public pedestrian trajectory prediction benchmark. Code is publicly available at https://github.com/inhwanbae/NPSN.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2064764883",
                        "name": "Inhwan Bae"
                    },
                    {
                        "authorId": "2160691331",
                        "name": "Jin-Hwi Park"
                    },
                    {
                        "authorId": "39060641",
                        "name": "Hae-Gon Jeon"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Some methods [6,9,12,19,37,43,54] employ GANs [11] to model the multi-modality with a noise variable, and another line of methods [3,16,20,25,38,46] apply the CVAE [41] instead.",
                "For instance, some methods [6,9,12,19,37,43,54] utilize generative adversarial networks (GANs) to spread the distribution over all possible future trajectories, while other methods [3,16,20,25,38,46] exploit conditional variational auto-encoder (CVAE) to encode the multi-modal distribution of future trajectories."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "13b5aae86ac2a4daae35ce31de726e55dd77e0ba",
                "externalIds": {
                    "ArXiv": "2203.13777",
                    "DBLP": "conf/cvpr/Gu0LLR0L22",
                    "DOI": "10.1109/CVPR52688.2022.01660",
                    "CorpusId": 247748591
                },
                "corpusId": 247748591,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/13b5aae86ac2a4daae35ce31de726e55dd77e0ba",
                "title": "Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion",
                "abstract": "Human behavior has the nature of indeterminacy, which requires the pedestrian trajectory prediction system to model the multi-modality of future motion states. Unlike existing stochastic trajectory prediction methods which usually use a latent variable to represent multi-modality, we explicitly simulate the process of human motion variation from indeterminate to determinate. In this paper, we present a new framework to formulate the trajectory prediction task as a reverse process of motion indeterminacy diffusion (MID), in which we progressively discard indeterminacy from all the walkable areas until reaching the desired trajectory. This process is learned with a parameterized Markov chain conditioned by the observed trajectories. We can adjust the length of the chain to control the degree of indeterminacy and balance the diversity and determinacy of the predictions. Specifically, we encode the history behavior information and the social interactions as a state embedding and devise a Transformer-based diffusion model to capture the temporal dependencies of trajectories. Extensive experiments on the human trajectory prediction benchmarks including the Stanford Drone and ETH/UCY datasets demonstrate the superiority of our method. Code is available at https://github.com/gutianpei/MID.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2124439724",
                        "name": "Tianpei Gu"
                    },
                    {
                        "authorId": "1734615",
                        "name": "Guangyi Chen"
                    },
                    {
                        "authorId": null,
                        "name": "Junlong Li"
                    },
                    {
                        "authorId": "51510731",
                        "name": "Chunze Lin"
                    },
                    {
                        "authorId": "39358728",
                        "name": "Yongming Rao"
                    },
                    {
                        "authorId": "48128428",
                        "name": "Jie Zhou"
                    },
                    {
                        "authorId": "1697700",
                        "name": "Jiwen Lu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "6fe5953976bd2fa0bf1cccc409fcc67268006e51",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-12446",
                    "ArXiv": "2203.12446",
                    "DOI": "10.48550/arXiv.2203.12446",
                    "CorpusId": 247618948
                },
                "corpusId": 247618948,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6fe5953976bd2fa0bf1cccc409fcc67268006e51",
                "title": "SMEMO: Social Memory for Trajectory Forecasting",
                "abstract": "Effective modeling of human interactions is of utmost importance when forecasting behaviors such as future trajectories. Each individual, with its motion, influences surrounding agents since everyone obeys to social non-written rules such as collision avoidance or group following. In this paper we model such interactions, which constantly evolve through time, by looking at the problem from an algorithmic point of view, i.e. as a data manipulation task. We present a neural network based on an end-to-end trainable working memory, which acts as an external storage where information about each agent can be continuously written, updated and recalled. We show that our method is capable of learning explainable cause-effect relationships between motions of different agents, obtaining state-of-the-art results on multiple trajectory forecasting datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2084645394",
                        "name": "Francesco Marchetti"
                    },
                    {
                        "authorId": "41172759",
                        "name": "Federico Becattini"
                    },
                    {
                        "authorId": "2831602",
                        "name": "Lorenzo Seidenari"
                    },
                    {
                        "authorId": "8196487",
                        "name": "A. Bimbo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Another issue we noticed that the recent models [36,43,26,23] which are state-of-the-art based on the ADE/FDE metric only differ by 1cm ADE and few centimeters FDE on the ETH [29] and UCY [16] datasets, one of the most commonly used datasets in this area."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "6dd962e9199082880e653ad512704cc97871798d",
                "externalIds": {
                    "DBLP": "conf/eccv/MohamedZVEC22",
                    "ArXiv": "2203.03057",
                    "DOI": "10.48550/arXiv.2203.03057",
                    "CorpusId": 247292580
                },
                "corpusId": 247292580,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/6dd962e9199082880e653ad512704cc97871798d",
                "title": "Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation",
                "abstract": "Best-of-N (BoN) Average Displacement Error (ADE)/ Final Displacement Error (FDE) is the most used metric for evaluating trajectory prediction models. Yet, the BoN does not quantify the whole generated samples, resulting in an incomplete view of the model's prediction quality and performance. We propose a new metric, Average Mahalanobis Distance (AMD) to tackle this issue. AMD is a metric that quantifies how close the whole generated samples are to the ground truth. We also introduce the Average Maximum Eigenvalue (AMV) metric that quantifies the overall spread of the predictions. Our metrics are validated empirically by showing that the ADE/FDE is not sensitive to distribution shifts, giving a biased sense of accuracy, unlike the AMD/AMV metrics. We introduce the usage of Implicit Maximum Likelihood Estimation (IMLE) as a replacement for traditional generative models to train our model, Social-Implicit. IMLE training mechanism aligns with AMD/AMV objective of predicting trajectories that are close to the ground truth with a tight spread. Social-Implicit is a memory efficient deep model with only 5.8K parameters that runs in real time of about 580Hz and achieves competitive results. Interactive demo of the problem can be seen at https://www.abduallahmohamed.com/social-implicit-amdamv-adefde-demo . Code is available at https://github.com/abduallahmohamed/Social-Implicit .",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51210562",
                        "name": "Abduallah A. Mohamed"
                    },
                    {
                        "authorId": "1388731230",
                        "name": "Deyao Zhu"
                    },
                    {
                        "authorId": "2157863363",
                        "name": "Warren Vu"
                    },
                    {
                        "authorId": "1712479",
                        "name": "Mohamed Elhoseiny"
                    },
                    {
                        "authorId": "1678595",
                        "name": "C. Claudel"
                    }
                ]
            }
        },
        {
            "contexts": [
                "A large body of work on pedestrian motion prediction uses past observed trajectories to forecast the future locations [3], [4], [5]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "1f53c193b09a4f98c5cdd9738342dabca1a6b643",
                "externalIds": {
                    "ArXiv": "2203.02489",
                    "DBLP": "conf/icra/GuoMA22",
                    "DOI": "10.48550/arXiv.2203.02489",
                    "CorpusId": 247244899
                },
                "corpusId": 247244899,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1f53c193b09a4f98c5cdd9738342dabca1a6b643",
                "title": "Pedestrian Stop and Go Forecasting with Hybrid Feature Fusion",
                "abstract": "Forecasting pedestrians' future motions is essential for autonomous driving systems to safely navigate in urban areas. However, existing prediction algorithms often overly rely on past observed trajectories and tend to fail around abrupt dynamic changes, such as when pedestrians suddenly start or stop walking. We suggest that predicting these highly non-linear transitions should form a core component to improve the robustness of motion prediction algorithms. In this paper, we introduce the new task of pedestrian stop and go forecasting. Considering the lack of suitable existing datasets for it, we release TRANS, a benchmark for explicitly studying the stop and go behaviors of pedestrians in urban traffic. We build it from several existing datasets annotated with pedestrians' walking motions, in order to have various scenarios and behaviors. We also propose a novel hybrid model that leverages pedestrian-specific and scene features from several modalities, both video sequences and high-level attributes, and gradually fuses them to integrate multiple levels of context. We evaluate our model and several baselines on TRANS, and set a new benchmark for the community to work on pedestrian stop and go forecasting.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "32361111",
                        "name": "Dongxu Guo"
                    },
                    {
                        "authorId": "20525031",
                        "name": "Taylor Mordan"
                    },
                    {
                        "authorId": "3304525",
                        "name": "Alexandre Alahi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[24] introduced a method to encourage encoded motion through social contrastive loss to preserve the information to distinguish a positive trajectory from the other negative ones."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0aa711f8b3dc66e1c233d4ecea138c9cc479e4dd",
                "externalIds": {
                    "DBLP": "journals/apin/SinghS22",
                    "DOI": "10.1007/s10489-021-03120-9",
                    "CorpusId": 246886549
                },
                "corpusId": 246886549,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0aa711f8b3dc66e1c233d4ecea138c9cc479e4dd",
                "title": "Graph Neural Network with RNNs based trajectory prediction of dynamic agents for autonomous vehicle",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2112755563",
                        "name": "Divya Singh"
                    },
                    {
                        "authorId": "144681901",
                        "name": "R. Srivastava"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026(2012); Gaydashenko et al. (2018) CFF (Alahi et al., 2014) 2014 42 million 1 Outdoor Top-down RGB-D Trajectories, Bounding Boxes Alahi et al. (2014); Liu et al. (2020b); Kothari et al. (2020) Stanford Drone Dataset (Robicquet et al., 2016)\n2016 11 ,216 8 Outdoor Top-down Mono Trajectories\u2026"
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "6cb7fd11450540ca82efcb8cda3029cbe9669f95",
                "externalIds": {
                    "DBLP": "journals/firai/GaoH21",
                    "PubMedCentral": "8791647",
                    "DOI": "10.3389/frobt.2021.721317",
                    "CorpusId": 245856331,
                    "PubMed": "35096978"
                },
                "corpusId": 245856331,
                "publicationVenue": {
                    "id": "2ee61499-676f-46c2-afde-d4c0cb4393e6",
                    "name": "Frontiers in Robotics and AI",
                    "type": "journal",
                    "alternate_names": [
                        "Front Robot AI"
                    ],
                    "issn": "2296-9144",
                    "url": "https://www.frontiersin.org/journals/robotics-and-ai",
                    "alternate_urls": [
                        "http://www.frontiersin.org/Robotics_and_AI/archive",
                        "http://www.frontiersin.org/Robotics_and_AI/about",
                        "http://www.frontiersin.org/Robotics_and_AI"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6cb7fd11450540ca82efcb8cda3029cbe9669f95",
                "title": "Evaluation of Socially-Aware Robot Navigation",
                "abstract": "As mobile robots are increasingly introduced into our daily lives, it grows ever more imperative that these robots navigate with and among people in a safe and socially acceptable manner, particularly in shared spaces. While research on enabling socially-aware robot navigation has expanded over the years, there are no agreed-upon evaluation protocols or benchmarks to allow for the systematic development and evaluation of socially-aware navigation. As an effort to aid more productive development and progress comparisons, in this paper we review the evaluation methods, scenarios, datasets, and metrics commonly used in previous socially-aware navigation research, discuss the limitations of existing evaluation protocols, and highlight research opportunities for advancing socially-aware robot navigation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2145028180",
                        "name": "Yuxiang Gao"
                    },
                    {
                        "authorId": "2805730",
                        "name": "Chien-Ming Huang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Contrastive learning has been extensively used on human motion sequences to perform action recognition using 3D pose data (Liu et al., 2020; Su et al., 2020; Lin et al., 2020) and video-based action understanding (Pan et al."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "418daf978334a2f54ad8f84e6185deb9517607c9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-01176",
                    "ArXiv": "2112.01176",
                    "DOI": "10.1007/s11263-022-01713-6",
                    "CorpusId": 244799318
                },
                "corpusId": 244799318,
                "publicationVenue": {
                    "id": "939ee07c-6009-43f8-b884-69238b40659e",
                    "name": "International Journal of Computer Vision",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Comput Vis"
                    ],
                    "issn": "0920-5691",
                    "url": "https://www.springer.com/computer/image+processing/journal/11263",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11263",
                        "http://link.springer.com/journal/11263"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/418daf978334a2f54ad8f84e6185deb9517607c9",
                "title": "Overcoming the Domain Gap in Neural Action Representations",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2142446611",
                        "name": "Semih Gunel"
                    },
                    {
                        "authorId": "82880764",
                        "name": "Florian Aymanns"
                    },
                    {
                        "authorId": "25056820",
                        "name": "S. Honari"
                    },
                    {
                        "authorId": "1989624",
                        "name": "Pavan Ramdya"
                    },
                    {
                        "authorId": "153918727",
                        "name": "P. Fua"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In this context, recent methods have also studied the use of RNNs [2,15,53,56,57], GANs [23,29,52], graph neural networks [11,26,70], and attention mechanisms [35,36,40,54], but also of reinforcement [32] and contrastive [39] learning."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "693654a0ebe99ac91c5dde8e3652480815f170da",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-00396",
                    "ArXiv": "2112.00396",
                    "CorpusId": 244773014
                },
                "corpusId": 244773014,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/693654a0ebe99ac91c5dde8e3652480815f170da",
                "title": "Dyadic Human Motion Prediction",
                "abstract": "Prior work on human motion forecasting has mostly focused on predicting the future motion of single subjects in isolation from their past pose sequence. In the presence of closely interacting people, however, this strategy fails to account for the dependencies between the different subject's motions. In this paper, we therefore introduce a motion prediction framework that explicitly reasons about the interactions of two observed subjects. Specifically, we achieve this by introducing a pairwise attention mechanism that models the mutual dependencies in the motion history of the two subjects. This allows us to preserve the long-term motion dynamics in a more realistic way and more robustly predict unusual and fast-paced movements, such as the ones occurring in a dance scenario. To evaluate this, and because no existing motion prediction datasets depict two closely-interacting subjects, we introduce the LindyHop600K dance dataset. Our results evidence that our approach outperforms the state-of-the-art single person motion prediction techniques.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3407292",
                        "name": "Isinsu Katircioglu"
                    },
                    {
                        "authorId": "2142739410",
                        "name": "Costa Georgantas"
                    },
                    {
                        "authorId": "2862871",
                        "name": "M. Salzmann"
                    },
                    {
                        "authorId": "153918727",
                        "name": "P. Fua"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "1632e0ce53261e1e6ef7a0edea359b6569af0aa0",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiuCSBA22",
                    "ArXiv": "2111.14820",
                    "DOI": "10.1109/CVPR52688.2022.01657",
                    "CorpusId": 244714689
                },
                "corpusId": 244714689,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1632e0ce53261e1e6ef7a0edea359b6569af0aa0",
                "title": "Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective",
                "abstract": "Learning behavioral patterns from observational data has been a de-facto approach to motion forecasting. Yet, the current paradigm suffers from two shortcomings: brittle under distribution shifts and inefficient for knowledge transfer. In this work, we propose to address these challenges from a causal representation perspective. We first introduce a causal formalism of motion forecasting, which casts the problem as a dynamic process with three groups of latent variables, namely invariant variables, style confounders, and spurious features. We then introduce a learning framework that treats each group separately: (i) unlike the common practice mixing datasets collected from different locations, we exploit their subtle distinctions by means of an invariance loss encouraging the model to suppress spurious correlations; (ii) we devise a modular architecture that factorizes the representations of invariant mechanisms and style confounders to approximate a sparse causal graph; (iii) we introduce a style contrastive loss that not only enforces the structure of style representations but also serves as a self-supervisory signal for test-time refinement on the fly. Experiments on synthetic and real datasets show that our proposed method improves the robustness and reusability of learned motion representations, significantly outperforming prior state-of-the-art motion forecasting models for out-of-distribution generalization and low-shot transfer.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "14772333",
                        "name": "Yuejiang Liu"
                    },
                    {
                        "authorId": "2122899467",
                        "name": "Riccardo Cadei"
                    },
                    {
                        "authorId": "2142457296",
                        "name": "Jonas Schweizer"
                    },
                    {
                        "authorId": "2142454988",
                        "name": "Sherwin Bahmani"
                    },
                    {
                        "authorId": "3304525",
                        "name": "Alexandre Alahi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[41] Yuejiang Liu, Qi Yan, and Alexandre Alahi.",
                "Contrastive learning also has been applied to unimodal datasets, including the study of human motion sequences [41, 42, 43], medical imaging [44, 45], video understanding [46, 47], and pose estimation [48, 49]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "b2452a8ee1d192fec40625319eb36e87f347e637",
                "externalIds": {
                    "ArXiv": "2111.14595",
                    "DBLP": "journals/corr/abs-2111-14595",
                    "CorpusId": 244714873
                },
                "corpusId": 244714873,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b2452a8ee1d192fec40625319eb36e87f347e637",
                "title": "Overcoming the Domain Gap in Contrastive Learning of Neural Action Representations",
                "abstract": "A fundamental goal in neuroscience is to understand the relationship between neural activity and behavior. For example, the ability to extract behavioral intentions from neural data, or neural decoding, is critical for developing effective brain machine interfaces. Although simple linear models have been applied to this challenge, they cannot identify important non-linear relationships. Thus, a self-supervised means of identifying non-linear relationships between neural dynamics and behavior, in order to compute neural representations, remains an important open problem. To address this challenge, we generated a new multimodal dataset consisting of the spontaneous behaviors generated by fruit flies, Drosophila melanogaster -- a popular model organism in neuroscience research. The dataset includes 3D markerless motion capture data from six camera views of the animal generating spontaneous actions, as well as synchronously acquired two-photon microscope images capturing the activity of descending neuron populations that are thought to drive actions. Standard contrastive learning and unsupervised domain adaptation techniques struggle to learn neural action representations (embeddings computed from the neural data describing action labels) due to large inter-animal differences in both neural and behavioral modalities. To overcome this deficiency, we developed simple yet effective augmentations that close the inter-animal domain gap, allowing us to extract behaviorally relevant, yet domain agnostic, information from neural data. This multimodal dataset and our new set of augmentations promise to accelerate the application of self-supervised learning methods in neuroscience.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2142446611",
                        "name": "Semih Gunel"
                    },
                    {
                        "authorId": "82880764",
                        "name": "Florian Aymanns"
                    },
                    {
                        "authorId": "25056820",
                        "name": "S. Honari"
                    },
                    {
                        "authorId": "1989624",
                        "name": "Pavan Ramdya"
                    },
                    {
                        "authorId": "153918727",
                        "name": "P. Fua"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The data-driven and deep learning methods have been proposed to increase the prediction accuracy [17, 20, 31, 3, 23, 7, 30, 29, 32] of the hand-crafted models."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "ec2bdd29502069e04ddfd5a779648b0147bf6e6d",
                "externalIds": {
                    "DBLP": "conf/iccvw/ParsaeifardSLMA21",
                    "DOI": "10.1109/ICCVW54120.2021.00259",
                    "CorpusId": 244475724
                },
                "corpusId": 244475724,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ec2bdd29502069e04ddfd5a779648b0147bf6e6d",
                "title": "Learning Decoupled Representations for Human Pose Forecasting",
                "abstract": "Human pose forecasting involves complex spatiotemporal interactions between body parts (e.g., arms, legs, spine). State-of-the-art approaches use Long Short-Term Memories (LSTMs) or Variational AutoEncoders (VAEs) to solve the problem. Yet, they do not effectively predict human motions when both global trajectory and local pose movements exist. We propose to learn decoupled representations for the global and local pose forecasting tasks. We also show that it is better to stop the prediction when the uncertainty in human motion increases. Our forecasting model outperforms all existing methods on the pose forecasting benchmark to date by over 20%. The code is available online \u2020.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "150045991",
                        "name": "Behnam Parsaeifard"
                    },
                    {
                        "authorId": "2114406635",
                        "name": "Saeed Saadatnejad"
                    },
                    {
                        "authorId": "14772333",
                        "name": "Yuejiang Liu"
                    },
                    {
                        "authorId": "20525031",
                        "name": "Taylor Mordan"
                    },
                    {
                        "authorId": "3304525",
                        "name": "Alexandre Alahi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Contrastive learning is widely used to learn representations from sequential data such as videos and pedestrian trajectories [18]\u2013[20]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4b6324c6ac5d343983ff4153bc0fd21475c268c6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2109-06783",
                    "ArXiv": "2109.06783",
                    "DOI": "10.1109/icra46639.2022.9811635",
                    "CorpusId": 237502742
                },
                "corpusId": 237502742,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4b6324c6ac5d343983ff4153bc0fd21475c268c6",
                "title": "Learning to Navigate Intersections with Unsupervised Driver Trait Inference",
                "abstract": "Navigation through uncontrolled intersections is one of the key challenges for autonomous vehicles. Identifying the subtle differences in hidden traits of other drivers can bring significant benefits when navigating in such environments. We propose an unsupervised method for inferring driver traits such as driving styles from observed vehicle trajectories. We use a variational autoencoder with recurrent neural networks to learn a latent representation of traits without any ground truth trait labels. Then, we use this trait representation to learn a policy for an autonomous vehicle to navigate through a T-intersection with deep reinforcement learning. Our pipeline enables the autonomous vehicle to adjust its actions when dealing with drivers of different traits to ensure safety and efficiency. Our method demonstrates promising performance and outperforms state-of-the-art baselines in the T-intersection scenario.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "30507647",
                        "name": "Shuijing Liu"
                    },
                    {
                        "authorId": "72314218",
                        "name": "Peixin Chang"
                    },
                    {
                        "authorId": "2035571489",
                        "name": "Haonan Chen"
                    },
                    {
                        "authorId": "2067025553",
                        "name": "Neeloy Chakraborty"
                    },
                    {
                        "authorId": "49917048",
                        "name": "Katherine Driggs Campbell"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In [27], a relational graph is paired with \u201cnegative examples\u201d (e."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "90d3ef730d13bb0b827f190169b9dff527feaed8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-13667",
                    "ArXiv": "2106.13667",
                    "DOI": "10.15607/RSS.2021.XVII.053",
                    "CorpusId": 235651179
                },
                "corpusId": 235651179,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/90d3ef730d13bb0b827f190169b9dff527feaed8",
                "title": "Move Beyond Trajectories: Distribution Space Coupling for Crowd Navigation",
                "abstract": "Cooperatively avoiding collision is a critical functionality for robots navigating in dense human crowds, failure of which could lead to either overaggressive or overcautious behavior. A necessary condition for cooperative collision avoidance is to couple the prediction of the agents' trajectories with the planning of the robot's trajectory. However, it is unclear that trajectory based cooperative collision avoidance captures the correct agent attributes. In this work we migrate from trajectory based coupling to a formalism that couples agent preference distributions. In particular, we show that preference distributions (probability density functions representing agents' intentions) can capture higher order statistics of agent behaviors, such as willingness to cooperate. Thus, coupling in distribution space exploits more information about inter-agent cooperation than coupling in trajectory space. We thus introduce a general objective for coupled prediction and planning in distribution space, and propose an iterative best response optimization method based on variational analysis with guaranteed sufficient decrease. Based on this analysis, we develop a sampling-based motion planning framework called DistNav that runs in real time on a laptop CPU. We evaluate our approach on challenging scenarios from both real world datasets and simulation environments, and benchmark against a wide variety of model based and machine learning based approaches. The safety and efficiency statistics of our approach outperform all other models. Finally, we find that DistNav is competitive with human safety and efficiency performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "93223196",
                        "name": "Muchen Sun"
                    },
                    {
                        "authorId": "40363948",
                        "name": "Francesca Baldini"
                    },
                    {
                        "authorId": "1909226",
                        "name": "Pete Trautman"
                    },
                    {
                        "authorId": "2750574",
                        "name": "T. Murphey"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Most of past years research focused on improving the interaction module, with only limited new methods since SocialLSTM [1], or in developing approaches that take inspiration in popular frameworks such as Transformers [10] or contrastive learning [11].",
                "Some authors have recently applied contrastive learning with success to pedestrian trajectory prediction [11] in order to"
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "cfa39203395b45edde6e0fb39c8ac14326839715",
                "externalIds": {
                    "ArXiv": "2106.04419",
                    "DBLP": "journals/corr/abs-2106-04419",
                    "CorpusId": 235367806
                },
                "corpusId": 235367806,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/cfa39203395b45edde6e0fb39c8ac14326839715",
                "title": "Asymmetrical Bi-RNN for pedestrian trajectory encoding",
                "abstract": "Pedestrian motion behavior involves a combination of individual goals and social interactions with other agents. In this article, we present an asymmetrical bidirectional recurrent neural network architecture called U-RNN to encode pedestrian trajectories and evaluate its relevance to replace LSTMs for various forecasting models. Experimental results on the Trajnet++ benchmark show that the U-LSTM variant yields better results regarding every available metrics (ADE, FDE, Collision rate) than common trajectory encoders for a variety of approaches and interaction modules, suggesting that the proposed approach is a viable alternative to the de facto sequence encoding RNNs. Our implementation of the asymmetrical Bi-RNNs for the Trajnet++ benchmark is available at: github.com/JosephGesnouin/Asymmetrical-Bi-RNNs-to-encode-pedestrian-trajectories",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2107654391",
                        "name": "Raphael Rozenberg"
                    },
                    {
                        "authorId": "2044450158",
                        "name": "Joseph Gesnouin"
                    },
                    {
                        "authorId": "1748488",
                        "name": "F. Moutarde"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Despite lacking theoretical collision avoidance guarantees, such approaches allow for better generalization to new environments and conditions as compared to local planning methods, with some of the most recent works enabling crowdaware navigation for physical robots [6, 29, 30] as well as fully distributed multi-robot navigation [5, 31].",
                "As opposed to introducing additional reward terms to regularize the agent trajectories, such as penalties for large angular speeds [5] and uncomfortable distances [30] or terms that promote social norms [10], our work mainly relies on human expert policies, fe(oi,t), extracted from real crowds trajectories to shape the reward.",
                "The recent works of [11, 30, 47] on socially-aware robot navigation and of [48, 49] on generating socially compliant behaviors in multi-agent environments can provide some interesting ideas towards this research direction."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4d75db2bdbdb395c105a8acb9bdd3793b8789902",
                "externalIds": {
                    "DBLP": "conf/iros/XuK21",
                    "ArXiv": "2103.10000",
                    "DOI": "10.1109/IROS51168.2021.9636463",
                    "CorpusId": 232269903
                },
                "corpusId": 232269903,
                "publicationVenue": {
                    "id": "37275deb-3fcf-4d16-ae77-95db9899b1f3",
                    "name": "IEEE/RJS International Conference on Intelligent RObots and Systems",
                    "type": "conference",
                    "alternate_names": [
                        "IROS",
                        "Intelligent Robots and Systems",
                        "Intell Robot Syst",
                        "IEEE/RJS Int Conf Intell Robot Syst"
                    ],
                    "url": "http://www.iros.org/"
                },
                "url": "https://www.semanticscholar.org/paper/4d75db2bdbdb395c105a8acb9bdd3793b8789902",
                "title": "Human-Inspired Multi-Agent Navigation using Knowledge Distillation",
                "abstract": "Despite significant advancements in the field of multi-agent navigation, agents still lack the sophistication and intelligence that humans exhibit in multi-agent settings. In this paper, we propose a framework for learning a human-like general collision avoidance policy for agent-agent interactions in fully decentralized, multi-agent environments. Our approach uses knowledge distillation with reinforcement learning to shape the reward function based on expert policies extracted from human trajectory demonstrations through behavior cloning. We show that agents trained with our approach can take human-like trajectories in collision avoidance and goal-directed steering tasks not provided by the demonstrations, outperforming the experts as well as learning-based agents trained without knowledge distillation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2087067124",
                        "name": "Pei Xu"
                    },
                    {
                        "authorId": "2478994",
                        "name": "Ioannis Karamouzas"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This can be done by exposing knowledgedriven negative samples to the model (Liu et al., 2020) or adding constraints to the outputs of the network (von Rueden et al."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "02bbb816ef6a2b9a1076342de5574cbc75e3e904",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-04854",
                    "MAG": "3156168097",
                    "ArXiv": "2103.04854",
                    "DOI": "10.1016/j.trc.2021.103010",
                    "CorpusId": 232146827
                },
                "corpusId": 232146827,
                "publicationVenue": {
                    "id": "a8fbd64a-2df2-4275-b527-7935d0142fff",
                    "name": "Transportation Research Part C: Emerging Technologies",
                    "type": "journal",
                    "alternate_names": [
                        "Transp Res Part C-emerging Technol",
                        "Transp Res Part C Emerg Technol",
                        "Transportation Research Part C-emerging Technologies"
                    ],
                    "issn": "0968-090X",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/130/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/0968090X"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/02bbb816ef6a2b9a1076342de5574cbc75e3e904",
                "title": "Injecting Knowledge in Data-driven Vehicle Trajectory Predictors",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "152588781",
                        "name": "Mohammadhossein Bahari"
                    },
                    {
                        "authorId": "2052092647",
                        "name": "Ismail Nejjar"
                    },
                    {
                        "authorId": "3304525",
                        "name": "Alexandre Alahi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This policy uses behavior cloning using a trained SARL policy as the expert [53].",
                "This policy uses a contrastive loss function to represent \u2018negative\u2019 examples such as collisions to improve social compliance [53]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "9f3e320f2d27a58d5c2cc98f56385e5cdf373a72",
                "externalIds": {
                    "DBLP": "conf/iros/KatyalGMPRW022",
                    "ArXiv": "2012.12291",
                    "DOI": "10.1109/IROS47612.2022.9981183",
                    "CorpusId": 244400688
                },
                "corpusId": 244400688,
                "publicationVenue": {
                    "id": "37275deb-3fcf-4d16-ae77-95db9899b1f3",
                    "name": "IEEE/RJS International Conference on Intelligent RObots and Systems",
                    "type": "conference",
                    "alternate_names": [
                        "IROS",
                        "Intelligent Robots and Systems",
                        "Intell Robot Syst",
                        "IEEE/RJS Int Conf Intell Robot Syst"
                    ],
                    "url": "http://www.iros.org/"
                },
                "url": "https://www.semanticscholar.org/paper/9f3e320f2d27a58d5c2cc98f56385e5cdf373a72",
                "title": "Learning a Group-Aware Policy for Robot Navigation",
                "abstract": "Human-aware robot navigation promises a range of applications in which mobile robots bring versatile assistance to people in common human environments. While prior research has mostly focused on modeling pedestrians as independent, intentional individuals, people move in groups; consequently, it is imperative for mobile robots to respect human groups when navigating around people. This paper explores learning group-aware navigation policies based on dynamic group formation using deep reinforcement learning. Through simulation experiments, we show that group-aware policies, compared to baseline policies that neglect human groups, achieve greater robot navigation performance (e.g., fewer collisions), minimize violation of social norms and discomfort, and reduce the robot's movement impact on pedestrians. Our results contribute to the development of social navigation and the integration of mobile robots into human environments.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2788711",
                        "name": "Kapil D. Katyal"
                    },
                    {
                        "authorId": "2145028180",
                        "name": "Yuxiang Gao"
                    },
                    {
                        "authorId": "40293098",
                        "name": "Jared Markowitz"
                    },
                    {
                        "authorId": "1629297026",
                        "name": "Sara Pohland"
                    },
                    {
                        "authorId": "144194990",
                        "name": "Corban G. Rivera"
                    },
                    {
                        "authorId": "48812691",
                        "name": "I-J. Wang"
                    },
                    {
                        "authorId": "2136578960",
                        "name": "Chien-Ming Huang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "769c99bcda09175353c2cefa4698a92d84cf856c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2005-08307",
                    "ArXiv": "2005.08307",
                    "MAG": "3024186890",
                    "DOI": "10.1016/j.cviu.2021.103245",
                    "CorpusId": 218674106
                },
                "corpusId": 218674106,
                "publicationVenue": {
                    "id": "5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                    "name": "Computer Vision and Image Understanding",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Vis Image Underst"
                    ],
                    "issn": "1077-3142",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/10773142",
                        "http://www.idealibrary.com/links/toc/cviu",
                        "https://www.journals.elsevier.com/computer-vision-and-image-understanding"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/769c99bcda09175353c2cefa4698a92d84cf856c",
                "title": "AC-VRNN: Attentive Conditional-VRNN for Multi-Future Trajectory Prediction",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "151482633",
                        "name": "Alessia Bertugli"
                    },
                    {
                        "authorId": "2175529",
                        "name": "S. Calderara"
                    },
                    {
                        "authorId": "29776698",
                        "name": "Pasquale Coscia"
                    },
                    {
                        "authorId": "1795847",
                        "name": "Lamberto Ballan"
                    },
                    {
                        "authorId": "1741922",
                        "name": "R. Cucchiara"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "025a44bf059aef8b9ee2e6ca598bebefc59a4a61",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1806-11230",
                    "MAG": "2810685774",
                    "ArXiv": "1806.11230",
                    "DOI": "10.1007/s11263-022-01594-9",
                    "CorpusId": 49551723
                },
                "corpusId": 49551723,
                "publicationVenue": {
                    "id": "939ee07c-6009-43f8-b884-69238b40659e",
                    "name": "International Journal of Computer Vision",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Comput Vis"
                    ],
                    "issn": "0920-5691",
                    "url": "https://www.springer.com/computer/image+processing/journal/11263",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11263",
                        "http://link.springer.com/journal/11263"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61",
                "title": "Human Action Recognition and Prediction: A Survey",
                "abstract": null,
                "year": 2018,
                "authors": [
                    {
                        "authorId": "145873652",
                        "name": "Yu Kong"
                    },
                    {
                        "authorId": "46956675",
                        "name": "Y. Fu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "808256502cdfffdd35896e2f9b3677e73a4a7e7c",
                "externalIds": {
                    "DOI": "10.1109/OJITS.2023.3282237",
                    "CorpusId": 259057563
                },
                "corpusId": 259057563,
                "publicationVenue": {
                    "id": "7c539343-bf1b-42ab-a5ee-acc958da6743",
                    "name": "IEEE Open Journal of Intelligent Transportation Systems",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Open J Intell Transp Syst"
                    ],
                    "issn": "2687-7813",
                    "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8784355"
                },
                "url": "https://www.semanticscholar.org/paper/808256502cdfffdd35896e2f9b3677e73a4a7e7c",
                "title": "HISS: A Pedestrian Trajectory Planning Framework Using Receding Horizon Optimization",
                "abstract": "The paper proposes a generative pedestrian trajectory modeling framework named HISS - Human Interactions in Shared Space. The trajectory modeling framework is based on a receding horizon optimization approach utilizing pedestrian behavior and interactions that seeks to capture pedestrian trajectory planning and execution. The benefit of the proposed dynamic optimization trajectory generation approach is that it requires minimal calibration data under a variety of traffic scenarios. In this paper, we formalize several pedestrian-pedestrian interaction scenarios and implement trajectories\u2019 conflict avoidance through mixed integer linear programming (MILP). We validate the proposed framework on two benchmark datasets - DUT and TrajNet++. The paper shows that when the framework\u2019s parameters are tuned to certain initial conditions and pedestrian behavior and interaction rules, the framework generates pedestrian trajectories similar to those observable in real-world scenarios, justifying the framework\u2019s capability to provide explanations and solutions to various traffic situations. This feature makes the proposed framework useful for modelers and urban city planners in making policy decisions.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "49436962",
                        "name": "Saumya Gupta"
                    },
                    {
                        "authorId": "1967762",
                        "name": "M. Zaki"
                    },
                    {
                        "authorId": "143691598",
                        "name": "A. Vela"
                    }
                ]
            }
        },
        {
            "contexts": [
                "They may be the front cars, another pedestrian on the left, traffic lights, a repaired road, or sudden heavy rain Kothari et al. (2021a); Liu et al. (2021).",
                "There have released several public datasets Ma et al. (2018); liu; Rasouli et al.",
                "Some works adopt individual features, such as observed trajectories, motion states, and pose, to forecast future locationsKothari et al. (2021a;b); Liu et al. (2021)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "604983042e5f745b4f36e31fa10a481acac1c844",
                "externalIds": {
                    "CorpusId": 259289164
                },
                "corpusId": 259289164,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/604983042e5f745b4f36e31fa10a481acac1c844",
                "title": "PEDESTRIAN CROSS FORECASTING WITH HYBRID FEATURE FUSION",
                "abstract": "Forecasting the crossing intention of pedestrians is critical for the growth of Autonomous Vehicles (AVs) in the real world. Pedestrians\u2019 movements are usually influenced by their surroundings in traffic scenes. Recent works extract explicit and individual information from collected data to perform prediction. However, there still exists much implicit information which is not considered ever, such as interactions between features, location of pedestrians, and distance towards the ego-car. Properly exploring and utilizing the implicit information will promote the prediction of future behaviors. To this end, the surrounding interactions from semantic segmentation and local context, together with two novel introduced attributes: the pedestrian\u2019s location at road or sidewalk, and the relative distance from target pedestrian to ego-car are adopted as critical features in this paper. The location and distance attributes are derived from the semantic map and depth map combined with bounding boxes information separately. A hybrid network based on multi-modal, which incorporates interactions between individual features, is proposed to forecast cross or not. Evaluated by two public pedestrian crossing datasets, PIE and JAAD, the proposed features and fusing strategy achieve stateof-the-art performance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2069775764",
                        "name": "Mengyuan Dong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Another interesting avenue of research is to deploy robots in a heterogeneous setting and extend our work to socially-intelligent agents that interact with human beings [53, 22, 41]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "d0cb68724576e2c1a5d24186882ed6ec651e9748",
                "externalIds": {
                    "CorpusId": 236473516
                },
                "corpusId": 236473516,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d0cb68724576e2c1a5d24186882ed6ec651e9748",
                "title": "Learning Multi-Agent Navigation from Human Crowd Data",
                "abstract": "The task of safely steering agents amidst static and dynamic obstacles has many applications in robotics, graphics, and traffic engineering. While decentralized solutions are essential for scalability and robustness, achieving globally efficient motions for the entire system of agents is equally important. In a traditional decentralized setting, each agent relies on an underlying local planning algorithm that takes as input a preferred velocity and the current state of the agent\u2019s neighborhood and then computes a new velocity for the next time-step that is collision-free and as close as possible to the preferred one. Typically, each agent promotes a goal-oriented preferred velocity, which can result in myopic behaviors as actions that are locally optimal for one agent is not necessarily optimal for the global system of agents. In this thesis, we explore a human-inspired approach for efficient multi-agent navigation that allows each agent to intelligently adapt its preferred velocity based on feedback from the environment. Using supervised learning, we investigate different egocentric representations of the local conditions that the agents face and train various deep neural network architectures on extensive collections of human trajectory datasets to learn corresponding life-like velocities. During simulation, we use the learned velocities as high-level, preferred velocities signals passed as input to the underlying local planning algorithm of the agents. We evaluate our proposed framework using two state-of-the-art local methods, the ORCA method, and the PowerLaw method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2121341423",
                        "name": "Joshi"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "257e70eb918515135336039f5a0fb75a3fe36c31",
                "externalIds": {
                    "DBLP": "conf/nips/LiuKDBMA21",
                    "CorpusId": 247410579
                },
                "corpusId": 247410579,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/257e70eb918515135336039f5a0fb75a3fe36c31",
                "title": "TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?",
                "abstract": "Test-time training (TTT) through self-supervised learning (SSL) is an emerging paradigm to tackle distributional shifts. Despite encouraging results, it remains unclear when this approach thrives or fails. In this work, we \ufb01rst provide an in-depth look at its limitations and show that TTT can possibly deteriorate, instead of improving, the test-time performance in the presence of severe distribution shifts. To address this issue, we introduce a test-time feature alignment strategy utilizing of\ufb02ine feature summarization and online moment matching, which regularizes adaptation without revisiting training data. We further scale this strategy in the online setting through batch-queue decoupling to enable robust moment estimates even with limited batch size. Given aligned feature distributions, we then shed light on the strong potential of TTT by theoretically analyzing its performance post adaptation. This analysis motivates our use of more informative self-supervision in the form of contrastive learning for visual recognition problems. We empirically demonstrate that our modi\ufb01ed version of test-time training, termed TTT++ , outperforms state-of-the-art methods by signi\ufb01cant margins on several benchmarks. Our result indicates that storing and exploiting extra information, in addition to model parameters, can be a promising direction towards robust test-time adaptation. Our code is available at https://github.com/vita-epfl/ttt-plus-plus .",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "14772333",
                        "name": "Yuejiang Liu"
                    },
                    {
                        "authorId": "81029804",
                        "name": "Parth Kothari"
                    },
                    {
                        "authorId": "123750697",
                        "name": "B. V. Delft"
                    },
                    {
                        "authorId": "2158653633",
                        "name": "Baptiste Bellot-Gurlet"
                    },
                    {
                        "authorId": "20525031",
                        "name": "Taylor Mordan"
                    },
                    {
                        "authorId": "3304525",
                        "name": "Alexandre Alahi"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "f345b0d13b950a6d8fec2d1476f75e3453ba1b9f",
                "externalIds": {
                    "DBLP": "conf/corl/PriisaluPPS21",
                    "CorpusId": 246037546
                },
                "corpusId": 246037546,
                "publicationVenue": {
                    "id": "fbfbf10a-faa4-4d2a-85be-3ac660454ce3",
                    "name": "Conference on Robot Learning",
                    "type": "conference",
                    "alternate_names": [
                        "CoRL",
                        "Conf Robot Learn"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f345b0d13b950a6d8fec2d1476f75e3453ba1b9f",
                "title": "Generating Scenarios with Diverse Pedestrian Behaviors for Autonomous Vehicle Testing",
                "abstract": ": There exist several datasets for developing self-driving car methodolo-gies. Manually collected datasets impose inherent limitations on the variability of test cases and it is particularly dif\ufb01cult to acquire challenging scenarios, e.g. ones involving collisions with pedestrians. A way to alleviate this is to consider automatic generation of safety-critical scenarios for autonomous vehicle (AV) testing. Existing approaches for scenario generation use heuristic pedestrian behavior models. We instead propose a framework that can use state-of-the-art pedestrian motion models, which is achieved by reformulating the problem as learning where to place pedestrians such that the induced scenarios are collision prone for a given AV. Our pedestrian initial location model can be used in conjunction with any goal driven pedestrian model which makes it possible to challenge an AV with a wide range of pedestrian behaviors \u2013 this ensures that the AV can avoid collisions with any pedestrian it encounters. We show that it is possible to learn a collision seeking scenario generation model when both the pedestrian and AV are collision avoiding. The initial location model is conditioned on scene semantics and occlusions to ensure semantic and visual plausibility, which increases the realism of generated scenarios. Our model can be used to test any AV model given suf\ufb01cient constraints.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "73488896",
                        "name": "Maria Priisalu"
                    },
                    {
                        "authorId": "7254236",
                        "name": "Aleksis Pirinen"
                    },
                    {
                        "authorId": "1948653",
                        "name": "C. Paduraru"
                    },
                    {
                        "authorId": "1781120",
                        "name": "C. Sminchisescu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "9099a5112042412cea9663d4d7b675fd4d449bff",
                "externalIds": {
                    "CorpusId": 263259874
                },
                "corpusId": 263259874,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/9099a5112042412cea9663d4d7b675fd4d449bff",
                "title": "Robots Capable of Norm-Appropriate Action (not Moral Agency)",
                "abstract": "Norms are indispensable for human communities, and so they will be for robot-human communities. We analyze some of the requirements for a robot to have norms and conform its actions to them. These requirements include cognitive properties and social properties that human norms have. And at least some of these properties need to be implemented in a robot\u2019s computational architecture if it should be capable of norm-appropriate action. We review some previous computational approaches and sketch a new one we are developing. All in all, we are not offering a robot with \u201cmoral agency\u201d but one that is able to take socially and morally appropriate actions.",
                "year": null,
                "authors": [
                    {
                        "authorId": "2248696359",
                        "name": "Dev Ramesh"
                    },
                    {
                        "authorId": "2248965063",
                        "name": "Bertram F. Malle"
                    },
                    {
                        "authorId": "152156591",
                        "name": "Eric Rosen"
                    },
                    {
                        "authorId": "1996176878",
                        "name": "V. B. Chi"
                    },
                    {
                        "authorId": "2249056422",
                        "name": "Robots"
                    }
                ]
            }
        }
    ]
}