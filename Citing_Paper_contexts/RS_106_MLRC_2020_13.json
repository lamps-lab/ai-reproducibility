{
    "offset": 0,
    "data": [
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "fd4a85d6ef23f8386900ad83b803bf763938b1e1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-00894",
                    "ArXiv": "2309.00894",
                    "DOI": "10.48550/arXiv.2309.00894",
                    "CorpusId": 261530876
                },
                "corpusId": 261530876,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/fd4a85d6ef23f8386900ad83b803bf763938b1e1",
                "title": "Regularly Truncated M-estimators for Learning with Noisy Labels",
                "abstract": "The sample selection approach is very popular in learning with noisy labels. As deep networks learn pattern first, prior methods built on sample selection share a similar training procedure: the small-loss examples can be regarded as clean examples and used for helping generalization, while the large-loss examples are treated as mislabeled ones and excluded from network parameter updates. However, such a procedure is arguably debatable from two folds: (a) it does not consider the bad influence of noisy labels in selected small-loss examples; (b) it does not make good use of the discarded large-loss examples, which may be clean or have meaningful information for generalization. In this paper, we propose regularly truncated M-estimators (RTME) to address the above two issues simultaneously. Specifically, RTME can alternately switch modes between truncated M-estimators and original M-estimators. The former can adaptively select small-losses examples without knowing the noise rate and reduce the side-effects of noisy labels in them. The latter makes the possibly clean examples but with large losses involved to help generalization. Theoretically, we demonstrate that our strategies are label-noise-tolerant. Empirically, comprehensive experimental results show that our method can outperform multiple baselines and is robust to broad noise types and levels.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2077454998",
                        "name": "Xiaobo Xia"
                    },
                    {
                        "authorId": "2237809694",
                        "name": "Pengqian Lu"
                    },
                    {
                        "authorId": "2171109070",
                        "name": "Chen Gong"
                    },
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "1491885364",
                        "name": "Jun Yu"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "c98d420c7ee2d8e5bb72701e00be7143ef9912c9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-12064",
                    "ArXiv": "2308.12064",
                    "DOI": "10.48550/arXiv.2308.12064",
                    "CorpusId": 261075889
                },
                "corpusId": 261075889,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c98d420c7ee2d8e5bb72701e00be7143ef9912c9",
                "title": "SILT: Shadow-aware Iterative Label Tuning for Learning to Detect Shadows from Noisy Labels",
                "abstract": "Existing shadow detection datasets often contain missing or mislabeled shadows, which can hinder the performance of deep learning models trained directly on such data. To address this issue, we propose SILT, the Shadow-aware Iterative Label Tuning framework, which explicitly considers noise in shadow labels and trains the deep model in a self-training manner. Specifically, we incorporate strong data augmentations with shadow counterfeiting to help the network better recognize non-shadow regions and alleviate overfitting. We also devise a simple yet effective label tuning strategy with global-local fusion and shadow-aware filtering to encourage the network to make significant refinements on the noisy labels. We evaluate the performance of SILT by relabeling the test set of the SBU dataset and conducting various experiments. Our results show that even a simple U-Net trained with SILT can outperform all state-of-the-art methods by a large margin. When trained on SBU / UCF / ISTD, our network can successfully reduce the Balanced Error Rate by 25.2% / 36.9% / 21.3% over the best state-of-the-art method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2109713886",
                        "name": "Han Yang"
                    },
                    {
                        "authorId": "49980987",
                        "name": "Tianyu Wang"
                    },
                    {
                        "authorId": "2109788956",
                        "name": "Xiao Hu"
                    },
                    {
                        "authorId": "144856288",
                        "name": "Chi-Wing Fu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "0456cd227edb95e596e3915ebcfd1133bcc8d725",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-15411",
                    "ArXiv": "2307.15411",
                    "DOI": "10.48550/arXiv.2307.15411",
                    "CorpusId": 260315960
                },
                "corpusId": 260315960,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0456cd227edb95e596e3915ebcfd1133bcc8d725",
                "title": "Investigating the Learning Behaviour of In-context Learning: A Comparison with Supervised Learning",
                "abstract": "Large language models (LLMs) have shown remarkable capacity for in-context learning (ICL), where learning a new task from just a few training examples is done without being explicitly pre-trained. However, despite the success of LLMs, there has been little understanding of how ICL learns the knowledge from the given prompts. In this paper, to make progress toward understanding the learning behaviour of ICL, we train the same LLMs with the same demonstration examples via ICL and supervised learning (SL), respectively, and investigate their performance under label perturbations (i.e., noisy labels and label imbalance) on a range of classification tasks. First, via extensive experiments, we find that gold labels have significant impacts on the downstream in-context performance, especially for large language models; however, imbalanced labels matter little to ICL across all model sizes. Second, when comparing with SL, we show empirically that ICL is less sensitive to label perturbations than SL, and ICL gradually attains comparable performance to SL as the model size increases.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108048327",
                        "name": "Xindi Wang"
                    },
                    {
                        "authorId": "46395829",
                        "name": "Yufei Wang"
                    },
                    {
                        "authorId": "46747953",
                        "name": "Can Xu"
                    },
                    {
                        "authorId": "2442662",
                        "name": "Xiubo Geng"
                    },
                    {
                        "authorId": null,
                        "name": "Bowen Zhang"
                    },
                    {
                        "authorId": "8801869",
                        "name": "Chongyang Tao"
                    },
                    {
                        "authorId": "2479037",
                        "name": "Frank Rudzicz"
                    },
                    {
                        "authorId": "1738694265",
                        "name": "Robert E. Mercer"
                    },
                    {
                        "authorId": "2086994543",
                        "name": "Daxin Jiang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "555fff9a86e3fabf008b02a878142430ae6c714a",
                "externalIds": {
                    "ArXiv": "2307.13680",
                    "DBLP": "journals/corr/abs-2307-13680",
                    "DOI": "10.48550/arXiv.2307.13680",
                    "CorpusId": 260154959
                },
                "corpusId": 260154959,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/555fff9a86e3fabf008b02a878142430ae6c714a",
                "title": "High Probability Analysis for Non-Convex Stochastic Optimization with Clipping",
                "abstract": "Gradient clipping is a commonly used technique to stabilize the training process of neural networks. A growing body of studies has shown that gradient clipping is a promising technique for dealing with the heavy-tailed behavior that emerged in stochastic optimization as well. While gradient clipping is significant, its theoretical guarantees are scarce. Most theoretical guarantees only provide an in-expectation analysis and only focus on optimization performance. In this paper, we provide high probability analysis in the non-convex setting and derive the optimization bound and the generalization bound simultaneously for popular stochastic optimization algorithms with gradient clipping, including stochastic gradient descent and its variants of momentum and adaptive stepsizes. With the gradient clipping, we study a heavy-tailed assumption that the gradients only have bounded $\\alpha$-th moments for some $\\alpha \\in (1, 2]$, which is much weaker than the standard bounded second-moment assumption. Overall, our study provides a relatively complete picture for the theoretical guarantee of stochastic optimization algorithms with clipping.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "50341794",
                        "name": "Shaojie Li"
                    },
                    {
                        "authorId": "2144384857",
                        "name": "Yong Liu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "1f799e663c78c2a41d61bdd4368624adab0a951f",
                "externalIds": {
                    "DBLP": "journals/pami/LiuLDTY23",
                    "DOI": "10.1109/TPAMI.2023.3296156",
                    "CorpusId": 259946892,
                    "PubMed": "37459268"
                },
                "corpusId": 259946892,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1f799e663c78c2a41d61bdd4368624adab0a951f",
                "title": "Noisy Label Learning With Provable Consistency for a Wider Family of Losses",
                "abstract": "Deep models have achieved state-of-the-art performance on a broad range of visual recognition tasks. Nevertheless, the generalization ability of deep models is seriously affected by noisy labels. Though deep learning packages have different losses, this is not transparent for users to choose consistent losses. This paper addresses the problem of how to use abundant loss functions designed for the traditional classification problem in the presence of label noise. We present a dynamic label learning (DLL) algorithm for noisy label learning and then prove that any surrogate loss function can be used for classification with noisy labels by using our proposed algorithm, with a consistency guarantee that the label noise does not ultimately hinder the search for the optimal classifier of the noise-free sample. In addition, we provide a depth theoretical analysis of our algorithm to verify the justifies\u2019 correctness and explain the powerful robustness. Finally, experimental results on synthetic and real datasets confirm the efficiency of our algorithm and the correctness of our justifies and show that our proposed algorithm significantly outperforms or is comparable to current state-of-the-art counterparts.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1590059708",
                        "name": "Defu Liu"
                    },
                    {
                        "authorId": "2145169829",
                        "name": "Wen Li"
                    },
                    {
                        "authorId": "2055900",
                        "name": "Lixin Duan"
                    },
                    {
                        "authorId": "1807998",
                        "name": "I. Tsang"
                    },
                    {
                        "authorId": "1805650",
                        "name": "Guowu Yang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Noise-Robust Loss Functions Prior work examines how regularization techniques can be adapted to the noisy labels setting, addressing issues related to overfitting on noisy data (Menon et al., 2019; Lukasik et al., 2020; Englesson and Azizpour, 2021)."
            ],
            "citingPaper": {
                "paperId": "1cf2baa7b60e9c449959d9ce6334148d62305a8d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-04868",
                    "ArXiv": "2307.04868",
                    "DOI": "10.48550/arXiv.2307.04868",
                    "CorpusId": 259766120
                },
                "corpusId": 259766120,
                "publicationVenue": {
                    "id": "67d171e0-fd12-4512-a35d-c4d7af1bd5b3",
                    "name": "ACM Conference on Health, Inference, and Learning",
                    "type": "conference",
                    "alternate_names": [
                        "CHIL",
                        "ACM Conf Health Inference Learn"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1cf2baa7b60e9c449959d9ce6334148d62305a8d",
                "title": "Leveraging an Alignment Set in Tackling Instance-Dependent Label Noise",
                "abstract": "Noisy training labels can hurt model performance. Most approaches that aim to address label noise assume label noise is independent from the input features. In practice, however, label noise is often feature or \\textit{instance-dependent}, and therefore biased (i.e., some instances are more likely to be mislabeled than others). E.g., in clinical care, female patients are more likely to be under-diagnosed for cardiovascular disease compared to male patients. Approaches that ignore this dependence can produce models with poor discriminative performance, and in many healthcare settings, can exacerbate issues around health disparities. In light of these limitations, we propose a two-stage approach to learn in the presence instance-dependent label noise. Our approach utilizes \\textit{\\anchor points}, a small subset of data for which we know the observed and ground truth labels. On several tasks, our approach leads to consistent improvements over the state-of-the-art in discriminative performance (AUROC) while mitigating bias (area under the equalized odds curve, AUEOC). For example, when predicting acute respiratory failure onset on the MIMIC-III dataset, our approach achieves a harmonic mean (AUROC and AUEOC) of 0.84 (SD [standard deviation] 0.01) while that of the next best baseline is 0.81 (SD 0.01). Overall, our approach improves accuracy while mitigating potential bias compared to existing approaches in the presence of instance-dependent label noise.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "79654724",
                        "name": "Donna Tjandra"
                    },
                    {
                        "authorId": "38556322",
                        "name": "J. Wiens"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "When done separately and at the level of a minibatch, clipping [16, 29] or noising [9] effectively regularize learning because they respectively control the dynamics of iterates and smoothen the loss landscape."
            ],
            "citingPaper": {
                "paperId": "792c8ce21cd01c0889b124b35da4f64d74817ef3",
                "externalIds": {
                    "DBLP": "journals/popets/ShamsabadiP23",
                    "DOI": "10.56553/popets-2023-0083",
                    "CorpusId": 258738267
                },
                "corpusId": 258738267,
                "publicationVenue": {
                    "id": "d5dc4224-e4c3-43c9-918a-bd6326650b5b",
                    "name": "Proceedings on Privacy Enhancing Technologies",
                    "alternate_names": [
                        "Proc Priv Enhancing Technol"
                    ],
                    "issn": "2299-0984",
                    "url": "https://www.degruyter.com/view/j/popets"
                },
                "url": "https://www.semanticscholar.org/paper/792c8ce21cd01c0889b124b35da4f64d74817ef3",
                "title": "Losing Less: A Loss for Differentially Private Deep Learning",
                "abstract": "Differentially Private Stochastic Gradient Descent, DP-SGD, is the canonical approach to training deep neural networks with guarantees of Differential Privacy (DP). However, the modifications DP-SGD introduces to vanilla gradient descent negatively impact the accuracy of deep neural networks. In this paper, we are the first to observe that some of this performance can be recovered when training with a loss tailored to DP-SGD; we challenge cross-entropy as the de facto loss for deep learning with DP. Specifically, we introduce a loss combining three terms: the summed squared error, the focal loss, and a regularization penalty. The first term encourages learning with faster convergence. The second term emphasizes hard-to-learn examples in the later stages of training. Both are beneficial because the privacy cost of learning increases with every step of DP-SGD. The third term helps control the sensitivity of learning, decreasing the bias introduced by gradient clipping in DP-SGD. Using our loss function, we achieve new state-of-the-art tradeoffs between privacy and accuracy on MNIST, FashionMNIST, and CIFAR10. Most importantly, we improve the accuracy of DP-SGD on CIFAR10 by 4% for a DP guarantee of \ud835\udf00 = 3.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "9920557",
                        "name": "A. Shamsabadi"
                    },
                    {
                        "authorId": "1967156",
                        "name": "Nicolas Papernot"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Many approaches [23, 25, 36, 37, 42, 45, 72] have been proposed to address this problem, but most of them focus on designing robust loss functions for classiiers that can handle noisy labels."
            ],
            "citingPaper": {
                "paperId": "e35ea45b5ecccc73326e5556520b6db9492372d0",
                "externalIds": {
                    "DOI": "10.1145/3603709",
                    "CorpusId": 259245950
                },
                "corpusId": 259245950,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e35ea45b5ecccc73326e5556520b6db9492372d0",
                "title": "A data centric AI framework for automating exploratory data analysis and data quality tasks",
                "abstract": "Democratisation of machine learning (ML) has been an important theme in the research community for the last several years with notable progress made by the model-building community with automated machine learning models. However, data plays a central role in building ML models and there is a need to focus on data-centric AI innovations. In this paper, we first map the steps taken by data scientists for the data preparation phase and identify open areas and pain points via user interviews. We then propose a framework and four novel algorithms for exploratory data analysis and data quality for AI steps addressing the pain points from user interviews. We also validate our algorithms with open-source datasets and show the effectiveness of our proposed methods. Next, we build a tool that automatically generates python code encompassing the above algorithms and study the usefulness of these algorithms via two user studies with data scientists. We observe from the first study results that the participants who used the tool were able to gain 2X productivity and 6% model improvement over the control group. The second study is performed in a more realistic environment to understand how the tool would be used in real-world scenarios. The results from this study are coherent with the first study and show an average of 30-50% of time savings that can be attributed to the tool.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1557607422",
                        "name": "Hima Patel"
                    },
                    {
                        "authorId": "52205085",
                        "name": "Shanmukha C. Guttula"
                    },
                    {
                        "authorId": "2089178586",
                        "name": "Nitin Gupta"
                    },
                    {
                        "authorId": "46957785",
                        "name": "Sandeep Hans"
                    },
                    {
                        "authorId": "41051307",
                        "name": "Ruhi Sharma Mittal"
                    },
                    {
                        "authorId": "2220517382",
                        "name": "Lokesh N"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "GCE [37], DAC [31], PHuber loss [23], Curriculum loss [21], and other robust losses are designed to reduce the effect of noise labels on the model."
            ],
            "citingPaper": {
                "paperId": "b34a6494e34c72ed0b9c1621f21152e72ff483cd",
                "externalIds": {
                    "DBLP": "conf/ijcnn/LuoJ23",
                    "DOI": "10.1109/IJCNN54540.2023.10191077",
                    "CorpusId": 260386957
                },
                "corpusId": 260386957,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/b34a6494e34c72ed0b9c1621f21152e72ff483cd",
                "title": "Solving Continual Learning with Noisy Labels by Sample Selection and Replay",
                "abstract": "One of the major distinguishing features of Continual Learning(Cl)is that training tasks will change over time, so how to adjust the model to learn different tasks is a challenge. One of the promising solutions is to use stored historical task data to help the model retain old knowledge in the training process for new tasks. However, most existing methods do not take into account that there may be noisy labels in the training data, which will aggravate the forgetting of the old task. In this paper, we propose a replay-based method to solve the continual learning with noisy labels. We first filter the data through the consistency of labels and their feature distribution in the feature space and add it to the replay buffer for the model training. We use supervised contrastive learning to train the model. In order to avoid the loss of other data information, we use the distribution of samples in the feature space to add a pseudo label. To verify the effectiveness of our algorithm, we conducted experiments on four datasets, including three artificial noise datasets MINST, cifar10, cifar100, and a real-world noise dataset Webvision, our method can achieve the best results. The experimental results show that the way we filter data and the way we update buffer data have a very important impact on the performance of the model.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "18160260",
                        "name": "Yiwei Luo"
                    },
                    {
                        "authorId": "2023650049",
                        "name": "Min Jiang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Gradient clipping techniques [11, 57, 92] were proposed to boost test accuracy or reduce training time, without any resilience considerations."
            ],
            "citingPaper": {
                "paperId": "10621513de36fe9d1adea4a10effdb9d18c7800d",
                "externalIds": {
                    "DBLP": "conf/isca/0010HCGGPL23",
                    "DOI": "10.1145/3579371.3589105",
                    "CorpusId": 259177811
                },
                "corpusId": 259177811,
                "publicationVenue": {
                    "id": "deedf64a-dd5c-4b33-b345-ff83bfb93d71",
                    "name": "International Symposium on Computer Architecture",
                    "type": "conference",
                    "alternate_names": [
                        "Int Symp Comput Archit",
                        "ISCA"
                    ],
                    "url": "http://www.cs.wisc.edu/~arch/www/"
                },
                "url": "https://www.semanticscholar.org/paper/10621513de36fe9d1adea4a10effdb9d18c7800d",
                "title": "Understanding and Mitigating Hardware Failures in Deep Learning Training Systems",
                "abstract": "Deep neural network (DNN) training workloads are increasingly susceptible to hardware failures in datacenters. For example, Google experienced \"mysterious, difficult to identify problems\" in their TPU training systems due to hardware failures [7]. Although these particular problems were subsequently corrected through significant efforts, they have raised the urgency of addressing the growing challenges emerging from hardware failures impacting many DNN training workloads. In this paper, we present the first in-depth resilience study targeting DNN training workloads and hardware failures that occur in the logic portion of deep learning (DL) accelerator systems. We developed a fault injection framework to accurately simulate the effects of various hardware failures based on the design of an industrial DL accelerator, and conducted > 2.9M experiments (> 490K node-hours) using representative workloads. Based on our experiments, we present (1) a comprehensive characterization of hardware failure effects, (2) the fundamental understanding on how hardware failures propagate in training devices and interact with training workloads, and (3) the necessary conditions that must be satisfied for these failures to eventually cause unexpected training outcomes. The insights obtained from our study enabled us to develop ultralight-weight software techniques to mitigate hardware failures. Our techniques require 24--32 lines of code change, and introduce 0.003% -- 0.025% performance overhead for various representative workloads. Our observations and techniques are generally applicable to mitigate various hardware failures in DL training accelerator systems.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2119042896",
                        "name": "Yi He"
                    },
                    {
                        "authorId": "144424294",
                        "name": "M. Hutton"
                    },
                    {
                        "authorId": "2118787053",
                        "name": "Steven Chan"
                    },
                    {
                        "authorId": "2220159733",
                        "name": "Robert De Gruijl"
                    },
                    {
                        "authorId": "39979032",
                        "name": "R. Govindaraju"
                    },
                    {
                        "authorId": "2056800684",
                        "name": "Nishant Patil"
                    },
                    {
                        "authorId": "1527110250",
                        "name": "Yanjing Li"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", partial labels [76, 68, 80, 15] and noisy labels [43, 47, 74, 29, 70, 71]."
            ],
            "citingPaper": {
                "paperId": "e6ee723680a19478b36e811c45e061ae3a1acf23",
                "externalIds": {
                    "ArXiv": "2306.07036",
                    "DBLP": "journals/corr/abs-2306-07036",
                    "DOI": "10.48550/arXiv.2306.07036",
                    "CorpusId": 259138656
                },
                "corpusId": 259138656,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e6ee723680a19478b36e811c45e061ae3a1acf23",
                "title": "Making Binary Classification from Multiple Unlabeled Datasets Almost Free of Supervision",
                "abstract": "Training a classifier exploiting a huge amount of supervised data is expensive or even prohibited in a situation, where the labeling cost is high. The remarkable progress in working with weaker forms of supervision is binary classification from multiple unlabeled datasets which requires the knowledge of exact class priors for all unlabeled datasets. However, the availability of class priors is restrictive in many real-world scenarios. To address this issue, we propose to solve a new problem setting, i.e., binary classification from multiple unlabeled datasets with only one pairwise numerical relationship of class priors (MU-OPPO), which knows the relative order (which unlabeled dataset has a higher proportion of positive examples) of two class-prior probabilities for two datasets among multiple unlabeled datasets. In MU-OPPO, we do not need the class priors for all unlabeled datasets, but we only require that there exists a pair of unlabeled datasets for which we know which unlabeled dataset has a larger class prior. Clearly, this form of supervision is easier to be obtained, which can make labeling costs almost free. We propose a novel framework to handle the MU-OPPO problem, which consists of four sequential modules: (i) pseudo label assignment; (ii) confident example collection; (iii) class prior estimation; (iv) classifier training with estimated class priors. Theoretically, we analyze the gap between estimated class priors and true class priors under the proposed framework. Empirically, we confirm the superiority of our framework with comprehensive experiments. Experimental results demonstrate that our framework brings smaller estimation errors of class priors and better performance of binary classification.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2223670108",
                        "name": "Yuhao Wu"
                    },
                    {
                        "authorId": "2077454998",
                        "name": "Xiaobo Xia"
                    },
                    {
                        "authorId": "1491885364",
                        "name": "Jun Yu"
                    },
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    },
                    {
                        "authorId": "67154907",
                        "name": "Masashi Sugiyama"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "73f2ad9d33104a31377849b713d42818c773e9cf",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-03899",
                    "ArXiv": "2306.03899",
                    "DOI": "10.48550/arXiv.2306.03899",
                    "CorpusId": 259088858
                },
                "corpusId": 259088858,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/73f2ad9d33104a31377849b713d42818c773e9cf",
                "title": "Towards Label-free Scene Understanding by Vision Foundation Models",
                "abstract": "Vision foundation models such as Contrastive Vision-Language Pre-training (CLIP) and Segment Anything (SAM) have demonstrated impressive zero-shot performance on image classification and segmentation tasks. However, the incorporation of CLIP and SAM for label-free scene understanding has yet to be explored. In this paper, we investigate the potential of vision foundation models in enabling networks to comprehend 2D and 3D worlds without labelled data. The primary challenge lies in effectively supervising networks under extremely noisy pseudo labels, which are generated by CLIP and further exacerbated during the propagation from the 2D to the 3D domain. To tackle these challenges, we propose a novel Cross-modality Noisy Supervision (CNS) method that leverages the strengths of CLIP and SAM to supervise 2D and 3D networks simultaneously. In particular, we introduce a prediction consistency regularization to co-train 2D and 3D networks, then further impose the networks' latent space consistency using the SAM's robust feature representation. Experiments conducted on diverse indoor and outdoor datasets demonstrate the superior performance of our method in understanding 2D and 3D open environments. Our 2D and 3D network achieves label-free semantic segmentation with 28.4% and 33.5% mIoU on ScanNet, improving 4.7% and 7.9%, respectively. And for nuScenes dataset, our performance is 26.8% with an improvement of 6%. Code will be released (https://github.com/runnanchen/Label-Free-Scene-Understanding).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "14936414",
                        "name": "Runnan Chen"
                    },
                    {
                        "authorId": "2108175790",
                        "name": "You-Chen Liu"
                    },
                    {
                        "authorId": "2152007435",
                        "name": "Lingdong Kong"
                    },
                    {
                        "authorId": "1646842231",
                        "name": "Nenglun Chen"
                    },
                    {
                        "authorId": "22689408",
                        "name": "Xinge Zhu"
                    },
                    {
                        "authorId": "2109386135",
                        "name": "Yuexin Ma"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    },
                    {
                        "authorId": "2108349601",
                        "name": "Wenping Wang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "49e5a11759a6735a9a8dea819fb4b5f04c7928b8",
                "externalIds": {
                    "DBLP": "conf/cvpr/BucarelliCSMS23",
                    "DOI": "10.1109/CVPR52729.2023.00335",
                    "CorpusId": 260068692
                },
                "corpusId": 260068692,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/49e5a11759a6735a9a8dea819fb4b5f04c7928b8",
                "title": "Leveraging Inter-Rater Agreement for Classification in the Presence of Noisy Labels",
                "abstract": "In practical settings, classification datasets are obtained through a labelling process that is usually done by humans. Labels can be noisy as they are obtained by aggregating the different individual labels assigned to the same sample by multiple, and possibly disagreeing, annotators. The interrater agreement on these datasets can be measured while the underlying noise distribution to which the labels are subject is assumed to be unknown. In this work, we: (i) show how to leverage the inter-annotator statistics to estimate the noise distribution to which labels are subject; (ii) introduce methods that use the estimate of the noise distribution to learn from the noisy dataset; and (iii) establish generalization bounds in the empirical risk minimization framework that depend on the estimated quantities. We conclude the paper by providing experiments that illustrate our findings.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2131012031",
                        "name": "Maria Sofia Bucarelli"
                    },
                    {
                        "authorId": "48447105",
                        "name": "Lucas Cassano"
                    },
                    {
                        "authorId": "1752951302",
                        "name": "F. Siciliano"
                    },
                    {
                        "authorId": "3105979",
                        "name": "Amin Mantrach"
                    },
                    {
                        "authorId": "2192306989",
                        "name": "Fabrizio Silvestri"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Besides, methodologies accompanying classical losses for robustness have been proposed, such as gradient-clipping [Menon et al., 2020] or sub-gradient optimization methods [Ma and Fattahi, 2022]."
            ],
            "citingPaper": {
                "paperId": "079b8a865ef0c90ad2eed714416acfb49a6eaae3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-13764",
                    "ArXiv": "2305.13764",
                    "DOI": "10.48550/arXiv.2305.13764",
                    "CorpusId": 258841723
                },
                "corpusId": 258841723,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/079b8a865ef0c90ad2eed714416acfb49a6eaae3",
                "title": "Mitigating Label Noise through Data Ambiguation",
                "abstract": "Label noise poses an important challenge in machine learning, especially in deep learning, in which large models with high expressive power dominate the field. Models of that kind are prone to memorizing incorrect labels, thereby harming generalization performance. Many methods have been proposed to address this problem, including robust loss functions and more complex label correction approaches. Robust loss functions are appealing due to their simplicity, but typically lack flexibility, while label correction usually adds substantial complexity to the training setup. In this paper, we suggest to address the shortcomings of both methodologies by\"ambiguating\"the target information, adding additional, complementary candidate labels in case the learner is not sufficiently convinced of the observed training label. More precisely, we leverage the framework of so-called superset learning to construct set-valued targets based on a confidence threshold, which deliver imprecise yet more reliable beliefs about the ground-truth, effectively helping the learner to suppress the memorization effect. In an extensive empirical evaluation, our method demonstrates favorable learning behavior on synthetic and real-world noise, confirming the effectiveness in detecting and correcting erroneous training labels.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2003600371",
                        "name": "Julian Lienen"
                    },
                    {
                        "authorId": "152345923",
                        "name": "E. Hullermeier"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "For instance, multiple works iteratively modified the labels to better align with the model\u2019s predictions [25, 27], estimated the noise transition matrix [8], or applied a regularization [21, 37]."
            ],
            "citingPaper": {
                "paperId": "0add9cc6c3e6329ab9d94765ebc1b5e236480c3e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-12961",
                    "ArXiv": "2305.12961",
                    "DOI": "10.48550/arXiv.2305.12961",
                    "CorpusId": 258832322
                },
                "corpusId": 258832322,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0add9cc6c3e6329ab9d94765ebc1b5e236480c3e",
                "title": "Enhanced Meta Label Correction for Coping with Label Corruption",
                "abstract": "Traditional methods for learning with the presence of noisy labels have successfully handled datasets with artificially injected noise but still fall short of adequately handling real-world noise. With the increasing use of meta-learning in the diverse fields of machine learning, researchers leveraged auxiliary small clean datasets to meta-correct the training labels. Nonetheless, existing meta-label correction approaches are not fully exploiting their potential. In this study, we propose an Enhanced Meta Label Correction approach abbreviated as EMLC for the learning with noisy labels (LNL) problem. We re-examine the meta-learning process and introduce faster and more accurate meta-gradient derivations. We propose a novel teacher architecture tailored explicitly to the LNL problem, equipped with novel training objectives. EMLC outperforms prior approaches and achieves state-of-the-art results in all standard benchmarks. Notably, EMLC enhances the previous art on the noisy real-world dataset Clothing1M by $1.52\\%$ while requiring $\\times 0.5$ the time per epoch and with much faster convergence of the meta-objective when compared to the baseline approach.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2218295676",
                        "name": "Mitchell Keren Taraday"
                    },
                    {
                        "authorId": "46906102",
                        "name": "Chaim Baskin"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "The scaling is done to ensure that the gradient norm strictly stays below a predetermined \u201cclipping constant\u201d [18, 30]."
            ],
            "citingPaper": {
                "paperId": "2d21be35e828e76e7108f3f1f8eec8ec1464c7f0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-12125",
                    "ArXiv": "2305.12125",
                    "DOI": "10.48550/arXiv.2305.12125",
                    "CorpusId": 258832486
                },
                "corpusId": 258832486,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2d21be35e828e76e7108f3f1f8eec8ec1464c7f0",
                "title": "A Framework for Provably Stable and Consistent Training of Deep Feedforward Networks",
                "abstract": "We present a novel algorithm for training deep neural networks in supervised (classification and regression) and unsupervised (reinforcement learning) scenarios. This algorithm combines the standard stochastic gradient descent and the gradient clipping method. The output layer is updated using clipped gradients, the rest of the neural network is updated using standard gradients. Updating the output layer using clipped gradient stabilizes it. We show that the remaining layers are automatically stabilized provided the neural network is only composed of squashing (compact range) activations. We also present a novel squashing activation function - it is obtained by modifying a Gaussian Error Linear Unit (GELU) to have compact range - we call it Truncated GELU (tGELU). Unlike other squashing activations, such as sigmoid, the range of tGELU can be explicitly specified. As a consequence, the problem of vanishing gradients that arise due to a small range, e.g., in the case of a sigmoid activation, is eliminated. We prove that a NN composed of squashing activations (tGELU, sigmoid, etc.), when updated using the algorithm presented herein, is numerically stable and has consistent performance (low variance). The theory is supported by extensive experiments. Within reinforcement learning, as a consequence of our study, we show that target networks in Deep Q-Learning can be omitted, greatly speeding up learning and alleviating memory requirements. Cross-entropy based classification algorithms that suffer from high variance issues are more consistent when trained using our framework. One symptom of numerical instability in training is the high variance of the neural network update values. We show, in theory and through experiments, that our algorithm updates have low variance, and the training loss reduces in a smooth manner.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "37764846",
                        "name": "Arunselvan Ramaswamy"
                    },
                    {
                        "authorId": "143683893",
                        "name": "S. Bhatnagar"
                    },
                    {
                        "authorId": "3311554",
                        "name": "Naman Saxena"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "To address this challenge, numerous studies have explored supervised learning under the label noise setting, leading to the development of various techniques, such as robust loss functions [45], sample selection [22, 30, 32, 39], robust regularization [28, 48, 65], and robust architecture [11,21,34,69]."
            ],
            "citingPaper": {
                "paperId": "41c29fcea1e685627e35ecb7c051d099fc52d547",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-10802",
                    "ArXiv": "2303.10802",
                    "DOI": "10.48550/arXiv.2303.10802",
                    "CorpusId": 257631715
                },
                "corpusId": 257631715,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/41c29fcea1e685627e35ecb7c051d099fc52d547",
                "title": "PASS: Peer-Agreement based Sample Selection for training with Noisy Labels",
                "abstract": "Noisy labels present a significant challenge in deep learning because models are prone to overfitting. This problem has driven the development of sophisticated techniques to address the issue, with one critical component being the selection of clean and noisy label samples. Selecting noisy label samples is commonly based on the small-loss hypothesis or on feature-based sampling, but we present empirical evidence that shows that both strategies struggle to differentiate between noisy label and hard samples, resulting in relatively large proportions of samples falsely selected as clean. To address this limitation, we propose a novel peer-agreement based sample selection (PASS). An automated thresholding technique is then applied to the agreement score to select clean and noisy label samples. PASS is designed to be easily integrated into existing noisy label robust frameworks, and it involves training a set of classifiers in a round-robin fashion, with peer models used for sample selection. In the experiments, we integrate our PASS with several state-of-the-art (SOTA) models, including InstanceGM, DivideMix, SSR, FaMUS, AugDesc, and C2D, and evaluate their effectiveness on several noisy label benchmark datasets, such as CIFAR-100, CIFAR-N, Animal-10N, Red Mini-Imagenet, Clothing1M, Mini-Webvision, and Imagenet. Our results demonstrate that our new sample selection approach improves the existing SOTA results of algorithms.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2075458292",
                        "name": "Arpit Garg"
                    },
                    {
                        "authorId": "2061205329",
                        "name": "Cuong Q. Nguyen"
                    },
                    {
                        "authorId": "145326496",
                        "name": "Rafael Felix"
                    },
                    {
                        "authorId": "3354627",
                        "name": "Thanh-Toan Do"
                    },
                    {
                        "authorId": "145575177",
                        "name": "G. Carneiro"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Menon et al. (2019) showed that gradient clipping can help mitigate label noise."
            ],
            "citingPaper": {
                "paperId": "b827ca1a0bf9e90ff5738c93409fb2b26a5edfe0",
                "externalIds": {
                    "DBLP": "conf/iclr/CrawshawBL23",
                    "ArXiv": "2302.07155",
                    "DOI": "10.48550/arXiv.2302.07155",
                    "CorpusId": 256846667
                },
                "corpusId": 256846667,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b827ca1a0bf9e90ff5738c93409fb2b26a5edfe0",
                "title": "EPISODE: Episodic Gradient Clipping with Periodic Resampled Corrections for Federated Learning with Heterogeneous Data",
                "abstract": "Gradient clipping is an important technique for deep neural networks with exploding gradients, such as recurrent neural networks. Recent studies have shown that the loss functions of these networks do not satisfy the conventional smoothness condition, but instead satisfy a relaxed smoothness condition, i.e., the Lipschitz constant of the gradient scales linearly in terms of the gradient norm. Due to this observation, several gradient clipping algorithms have been developed for nonconvex and relaxed-smooth functions. However, the existing algorithms only apply to the single-machine or multiple-machine setting with homogeneous data across machines. It remains unclear how to design provably efficient gradient clipping algorithms in the general Federated Learning (FL) setting with heterogeneous data and limited communication rounds. In this paper, we design EPISODE, the very first algorithm to solve FL problems with heterogeneous data in the nonconvex and relaxed smoothness setting. The key ingredients of the algorithm are two new techniques called \\textit{episodic gradient clipping} and \\textit{periodic resampled corrections}. At the beginning of each round, EPISODE resamples stochastic gradients from each client and obtains the global averaged gradient, which is used to (1) determine whether to apply gradient clipping for the entire round and (2) construct local gradient corrections for each client. Notably, our algorithm and analysis provide a unified framework for both homogeneous and heterogeneous data under any noise level of the stochastic gradient, and it achieves state-of-the-art complexity results. In particular, we prove that EPISODE can achieve linear speedup in the number of machines, and it requires significantly fewer communication rounds. Experiments on several heterogeneous datasets show the superior performance of EPISODE over several strong baselines in FL.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "145868671",
                        "name": "M. Crawshaw"
                    },
                    {
                        "authorId": "2075376698",
                        "name": "Yajie Bao"
                    },
                    {
                        "authorId": "14697929",
                        "name": "Mingrui Liu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "The lower norm implies that the magnitude of gradient is lower, and it won\u2019t cause any significant changes to the current model state [38]."
            ],
            "citingPaper": {
                "paperId": "1bf235be519b99f590b191add568e0c2f6e41265",
                "externalIds": {
                    "DBLP": "journals/titb/ThakurAYEC23",
                    "DOI": "10.1109/JBHI.2023.3237592",
                    "CorpusId": 256653610,
                    "PubMed": "37022415"
                },
                "corpusId": 256653610,
                "publicationVenue": {
                    "id": "eac74c9c-a5c0-417d-8088-8164a6a8bfb3",
                    "name": "IEEE journal of biomedical and health informatics",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Journal of Biomedical and Health Informatics",
                        "IEEE j biomed health informatics",
                        "IEEE J Biomed Health Informatics"
                    ],
                    "issn": "2168-2194",
                    "url": "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6221020",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1bf235be519b99f590b191add568e0c2f6e41265",
                "title": "Self-Aware SGD: Reliable Incremental Adaptation Framework for Clinical AI Models",
                "abstract": "Healthcare is dynamic as demographics, diseases, and therapeutics constantly evolve. This dynamic nature induces inevitable distribution shifts in populations targeted by clinical AI models, often rendering them ineffective. Incremental learning provides an effective method of adapting deployed clinical models to accommodate these contemporary distribution shifts. However, since incremental learning involves modifying a deployed or in-use model, it can be considered unreliable as any adverse modification due to maliciously compromised or incorrectly labelled data can make the model unsuitable for the targeted application. This paper introduces self-aware stochastic gradient descent (SGD), an incremental deep learning algorithm that utilises a contextual bandit-like sanity check to only allow reliable modifications to a model. The contextual bandit analyses incremental gradient updates to isolate and filter unreliable gradients. This behaviour allows self-aware SGD to balance incremental training and integrity of a deployed model. Experimental evaluations on the Oxford University Hospital datasets highlight that self-aware SGD can provide reliable incremental updates for overcoming distribution shifts in challenging conditions induced by label noise.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2070335142",
                        "name": "Anshul Thakur"
                    },
                    {
                        "authorId": "2176154638",
                        "name": "Jacob Armstrong"
                    },
                    {
                        "authorId": "2061392802",
                        "name": "Alexey Youssef"
                    },
                    {
                        "authorId": "2204913616",
                        "name": "David W Eyre"
                    },
                    {
                        "authorId": "31799453",
                        "name": "D. Clifton"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "4a8a2bf7c74ba92517121135704ad90b74dd60cf",
                "externalIds": {
                    "ArXiv": "2301.00545",
                    "DBLP": "journals/corr/abs-2301-00545",
                    "DOI": "10.48550/arXiv.2301.00545",
                    "CorpusId": 255372337
                },
                "corpusId": 255372337,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4a8a2bf7c74ba92517121135704ad90b74dd60cf",
                "title": "Knockoffs-SPR: Clean Sample Selection in Learning with Noisy Labels",
                "abstract": "A noisy training set usually leads to the degradation of the generalization and robustness of neural networks. In this paper, we propose a novel theoretically guaranteed clean sample selection framework for learning with noisy labels. Specifically, we first present a Scalable Penalized Regression (SPR) method, to model the linear relation between network features and one-hot labels. In SPR, the clean data are identified by the zero mean-shift parameters solved in the regression model. We theoretically show that SPR can recover clean data under some conditions. Under general scenarios, the conditions may be no longer satisfied; and some noisy data are falsely selected as clean data. To solve this problem, we propose a data-adaptive method for Scalable Penalized Regression with Knockoff filters (Knockoffs-SPR), which is provable to control the False-Selection-Rate (FSR) in the selected clean data. To improve the efficiency, we further present a split algorithm that divides the whole training set into small pieces that can be solved in parallel to make the framework scalable to large datasets. While Knockoffs-SPR can be regarded as a sample selection module for a standard supervised training pipeline, we further combine it with a semi-supervised algorithm to exploit the support of noisy data as unlabeled data. Experimental results on several benchmark datasets and real-world noisy datasets show the effectiveness of our framework and validate the theoretical results of Knockoffs-SPR. Our code and pre-trained models are available at https://github.com/Yikai-Wang/Knockoffs-SPR.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108853258",
                        "name": "Yikai Wang"
                    },
                    {
                        "authorId": "35782003",
                        "name": "Yanwei Fu"
                    },
                    {
                        "authorId": "8283163",
                        "name": "Xinwei Sun"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "1, 3 [23] Aditya Krishna Menon, Ankit Singh Rawat, Sashank J.",
                "[23] suggests a composite loss-based gradient clipping for label noise robustness."
            ],
            "citingPaper": {
                "paperId": "280cf75d6221e015fdc2de447ea9394f9fd7388a",
                "externalIds": {
                    "ArXiv": "2301.00524",
                    "DBLP": "journals/corr/abs-2301-00524",
                    "DOI": "10.48550/arXiv.2301.00524",
                    "CorpusId": 255372891
                },
                "corpusId": 255372891,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/280cf75d6221e015fdc2de447ea9394f9fd7388a",
                "title": "In Quest of Ground Truth: Learning Confident Models and Estimating Uncertainty in the Presence of Annotator Noise",
                "abstract": "The performance of the Deep Learning (DL) models depends on the quality of labels. In some areas, the involvement of human annotators may lead to noise in the data. When these corrupted labels are blindly regarded as the ground truth (GT), DL models suffer from performance deficiency. This paper presents a method that aims to learn a confident model in the presence of noisy labels. This is done in conjunction with estimating the uncertainty of multiple annotators. We robustly estimate the predictions given only the noisy labels by adding entropy or information-based regularizer to the classifier network. We conduct our experiments on a noisy version of MNIST, CIFAR-10, and FMNIST datasets. Our empirical results demonstrate the robustness of our method as it outperforms or performs comparably to other state-of-the-art (SOTA) methods. In addition, we evaluated the proposed method on the curated dataset, where the noise type and level of various annotators depend on the input image style. We show that our approach performs well and is adept at learning annotators' confusion. Moreover, we demonstrate how our model is more confident in predicting GT than other baselines. Finally, we assess our approach for segmentation problem and showcase its effectiveness with experiments.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2199119366",
                        "name": "Asma Ahmed Hashmi"
                    },
                    {
                        "authorId": "152954133",
                        "name": "A. Agafonov"
                    },
                    {
                        "authorId": "1394561344",
                        "name": "A. Zhumabayeva"
                    },
                    {
                        "authorId": "145628052",
                        "name": "Mohammad Yaqub"
                    },
                    {
                        "authorId": "1469440742",
                        "name": "Martin Tak'avc"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "More specifically, the common label noise has two types: class-conditional noise (CCN) [44, 28, 27] and instancedependent noise (IDN) [3, 6, 7]."
            ],
            "citingPaper": {
                "paperId": "ae0925f43017dc99865bd9408ff15e40da755396",
                "externalIds": {
                    "DBLP": "conf/wacv/XianYYZS23",
                    "DOI": "10.1109/WACV56688.2023.00477",
                    "CorpusId": 256647596
                },
                "corpusId": 256647596,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/ae0925f43017dc99865bd9408ff15e40da755396",
                "title": "Graph-Based Self-Learning for Robust Person Re-identification",
                "abstract": "Existing deep learning approaches for person re-identification (Re-ID) mostly rely on large-scale and well-annotated training data. However, human-annotated labels are prone to label noise in real-world applications. Previous person Re-ID works mainly focus on random label noise, which doesn\u2019t properly reflect the characteristic of label noise in practical human-annotated process. In this work, we find the visual ambiguity noise is more common and reasonable noise assumption in annotation of person Re-ID. To handle the kind of noise, we propose a simple and effective robust person Re-ID framework, namely Graph-Based Self-Learning (GBSL), to iteratively learn discriminative representation and rectify noisy labels with limited annotated samples for each identity. Meanwhile, considering the practical annotation process in person Re-ID, we further extend the visual ambiguity noise assumption and propose a type of more practical label noise in person Re-ID, namely the tracklet-level label noise (TLN). Without modifying network architecture or loss function, our approach significantly improves the robustness against label noise of the Re-ID system. Our model obtains competitive performance with training data corrupted by various types of label noise and outperforms the existing methods for robust Re-ID on public benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2069504204",
                        "name": "Yuqiao Xian"
                    },
                    {
                        "authorId": "2109732008",
                        "name": "Jinrui Yang"
                    },
                    {
                        "authorId": "1940021679",
                        "name": "Fufu Yu"
                    },
                    {
                        "authorId": "2155662139",
                        "name": "Jun Zhang"
                    },
                    {
                        "authorId": "2109230606",
                        "name": "Xing Sun"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Methods modeling label noise implicitly include noise-tolerant loss function [22, 31\u201336] and regularization [37, 38]."
            ],
            "citingPaper": {
                "paperId": "960142cd8239bb9f155368d76c0b66377e0c987a",
                "externalIds": {
                    "ArXiv": "2212.08380",
                    "DBLP": "journals/corr/abs-2212-08380",
                    "DOI": "10.48550/arXiv.2212.08380",
                    "CorpusId": 254823368
                },
                "corpusId": 254823368,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/960142cd8239bb9f155368d76c0b66377e0c987a",
                "title": "Instance-specific Label Distribution Regularization for Learning with Label Noise",
                "abstract": "Modeling noise transition matrix is a kind of promising method for learning with label noise. Based on the estimated noise transition matrix and the noisy posterior probabilities, the clean posterior probabilities, which are jointly called Label Distribution (LD) in this paper, can be calculated as the supervision. To reliably estimate the noise transition matrix, some methods assume that anchor points are available during training. Nonetheless, if anchor points are invalid, the noise transition matrix might be poorly learned, resulting in poor performance. Consequently, other methods treat reliable data points, extracted from training data, as pseudo anchor points. However, from a statistical point of view, the noise transition matrix can be inferred from data with noisy labels under the clean-label-domination assumption. Therefore, we aim to estimate the noise transition matrix without (pseudo) anchor points. There is evidence showing that samples are more likely to be mislabeled as other similar class labels, which means the mislabeling probability is highly correlated with the inter-class correlation. Inspired by this observation, we propose an instance-specific Label Distribution Regularization (LDR), in which the instance-specific LD is estimated as the supervision, to prevent DCNNs from memorizing noisy labels. Specifically, we estimate the noisy posterior under the supervision of noisy labels, and approximate the batch-level noise transition matrix by estimating the inter-class correlation matrix with neither anchor points nor pseudo anchor points. Experimental results on two synthetic noisy datasets and two real-world noisy datasets demonstrate that our LDR outperforms existing methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2028786413",
                        "name": "Zehui Liao"
                    },
                    {
                        "authorId": "1988754778",
                        "name": "Shishuai Hu"
                    },
                    {
                        "authorId": "2154709897",
                        "name": "Yutong Xie"
                    },
                    {
                        "authorId": "2190919982",
                        "name": "Yong Xia"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                ", 2017), PHuber-CE (Menon et al., 2020), SCE (Wang et al.",
                "Partial Huberised Cross Entropy (PHuber-CE) (Menon et al., 2020) enhances the noise robustness of CE with a loss variant of gradient clipping.",
                "(4) PHuber-CE (Menon et al., 2020), a loss variant of gradient clipping for learning with noisy labels.",
                "\u2026we show that LogitClip can boost the performance of a wide range of popular robust loss functions, including MAE (Ghosh et al., 2017), PHuber-CE (Menon et al., 2020), SCE (Wang et al., 2019), GCE (Zhang & Sabuncu, 2018), Taylor-CE (Feng et al., 2020), NCE (Ma et al., 2020), AEL, AUL (Zhou et\u2026",
                "Indeed, recent work (Menon et al., 2020) has shown that gradient clipping alone does not endow label noise robustness to neural networks."
            ],
            "citingPaper": {
                "paperId": "033e330e4de11816edf0cf2d74d7377b0e9d9c30",
                "externalIds": {
                    "DBLP": "conf/icml/WeiZXF00L23",
                    "ArXiv": "2212.04055",
                    "CorpusId": 259138834
                },
                "corpusId": 259138834,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/033e330e4de11816edf0cf2d74d7377b0e9d9c30",
                "title": "Mitigating Memorization of Noisy Labels by Clipping the Model Prediction",
                "abstract": "In the presence of noisy labels, designing robust loss functions is critical for securing the generalization performance of deep neural networks. Cross Entropy (CE) loss has been shown to be not robust to noisy labels due to its unboundedness. To alleviate this issue, existing works typically design specialized robust losses with the symmetric condition, which usually lead to the underfitting issue. In this paper, our key idea is to induce a loss bound at the logit level, thus universally enhancing the noise robustness of existing losses. Specifically, we propose logit clipping (LogitClip), which clamps the norm of the logit vector to ensure that it is upper bounded by a constant. In this manner, CE loss equipped with our LogitClip method is effectively bounded, mitigating the overfitting to examples with noisy labels. Moreover, we present theoretical analyses to certify the noise-tolerant ability of LogitClip. Extensive experiments show that LogitClip not only significantly improves the noise robustness of CE loss, but also broadly enhances the generalization performance of popular robust losses.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115312735",
                        "name": "Hongxin Wei"
                    },
                    {
                        "authorId": "8841273",
                        "name": "Huiping Zhuang"
                    },
                    {
                        "authorId": "1381430534",
                        "name": "Renchunzi Xie"
                    },
                    {
                        "authorId": "47010134",
                        "name": "Lei Feng"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    },
                    {
                        "authorId": "2057964623",
                        "name": "Bo An"
                    },
                    {
                        "authorId": "1527103472",
                        "name": "Yixuan Li"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Several noise-robust losses have been proposed for training models with noisy labels (Reed et al., 2015; Zhang and Sabuncu, 2018; Wang et al., 2019; Ma et al., 2020; Menon et al., 2020; Jin et al., 2021; Zhou and Chen, 2021), which were shown to be more robust than CE.",
                "One direction is to develop noise-robust losses that can mitigate the effect of noisy labels (Ghosh et al., 2017; Zhang and Sabuncu, 2018; Charoenphakdee et al., 2019; Kim et al., 2019; Lyu and Tsang, 2019; Menon et al., 2020; Thulasidasan et al., 2019)."
            ],
            "citingPaper": {
                "paperId": "6e05e11eb95894d9d97acf6ecc5fa26a65a8b140",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-13883",
                    "ArXiv": "2211.13883",
                    "DOI": "10.48550/arXiv.2211.13883",
                    "CorpusId": 254018114
                },
                "corpusId": 254018114,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6e05e11eb95894d9d97acf6ecc5fa26a65a8b140",
                "title": "Learning with Silver Standard Data for Zero-shot Relation Extraction",
                "abstract": "The superior performance of supervised relation extraction (RE) methods heavily relies on a large amount of gold standard data. Recent zero-shot relation extraction methods converted the RE task to other NLP tasks and used off-the-shelf models of these NLP tasks to directly perform inference on the test data without using a large amount of RE annota-tion data. A potentially valuable by-product of these methods is the large-scale silver standard data. However, there is no further investigation on the use of potentially valuable silver standard data. In this paper, we propose to \ufb01rst detect a small amount of clean data from silver standard data and then use the selected clean data to \ufb01netune the pretrained model. We then use the \ufb01netuned model to infer relation types. We also propose a class-aware clean data detection module to consider class information when selecting clean data. The experimental results show that our method can outperform the baseline by 12% and 11% on TACRED and Wiki80 dataset in the zero-shot RE task. By using extra silver standard data of different distributions, the performance can be further improved.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118914471",
                        "name": "Tianyi Wang"
                    },
                    {
                        "authorId": "2163388664",
                        "name": "Jianwei Wang"
                    },
                    {
                        "authorId": "1844229",
                        "name": "Ziqian Zeng"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "6213c5433ca1eb627c2dc6539cfd0e1d08217f44",
                "externalIds": {
                    "DBLP": "conf/cikm/SugiyamaL0L022",
                    "DOI": "10.1145/3511808.3557504",
                    "CorpusId": 252904689
                },
                "corpusId": 252904689,
                "publicationVenue": {
                    "id": "7431ff67-91dc-41fa-b322-1b1ca657025f",
                    "name": "International Conference on Information and Knowledge Management",
                    "type": "conference",
                    "alternate_names": [
                        "Conference on Information and Knowledge Management",
                        "Conf Inf Knowl Manag",
                        "Int Conf Inf Knowl Manag",
                        "CIKM"
                    ],
                    "url": "http://www.cikm.org/"
                },
                "url": "https://www.semanticscholar.org/paper/6213c5433ca1eb627c2dc6539cfd0e1d08217f44",
                "title": "Learning and Mining with Noisy Labels",
                "abstract": "''Knowledge should not be accessible only to those who can pay\" said Robert May, chair of UC's faculty Academic Senate. Similarly, machine learning should not be accessible only to those who can pay. Thus, machine learning should benefit to the whole world, especially for developing countries in Africa and Asia. When dataset sizes grow bigger, it is laborious and expensive to obtain clean supervision, especially for developing countries. As a result, the volume of noisy supervision becomes enormous, e.g., web-scale image and speech data with noisy labels. However, standard machine learning assumes that the supervised information is fully clean and intact. Therefore, noisy data harms the performance of most of the standard learning algorithms, and sometimes even makes existing algorithms broken down. There are bunch of theories and approaches proposed to deal with noisy data. As far as we know, learning and mining with noisy labels spans over two important ages in machine learning, data mining and knowledge management community: statistical learning (i.e., shallow learning) and deep learning. In the age of statistical learning, learning and mining with noisy labels focused on designing noise-tolerant losses or unbiased risk estimators. Nonetheless, in the age of deep learning, learning and mining with noisy labels has more options to combat with noisy labels, such as designing biased risk estimators or leveraging memorization effects of deep networks. In this tutorial, we summarize the foundations and go through the most recent noisy-label-tolerant techniques. By participating the tutorial, the audience will gain a broad knowledge of learning and mining with noisy labels from the viewpoint of statistical learning theory, deep learning, detailed analysis of typical algorithms and frameworks, and their real-world data mining applications.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "67154907",
                        "name": "Masashi Sugiyama"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    },
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "2152799147",
                        "name": "Yang Liu"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Domain adaptation (DA) [15, 18, 22, 31] relieves the burden of manual annotation by leveraging the knowledge from related source domains with rich labeling.",
                "Among them, robust regularization is the most direct approach, which is mainly composed of two commonly used types: explicit regularization [7, 8, 15, 29, 31] and implicit regularization [18, 32]."
            ],
            "citingPaper": {
                "paperId": "0845909f66329bd58306a1ede76834275a751fed",
                "externalIds": {
                    "DBLP": "conf/cikm/Qin0022",
                    "DOI": "10.1145/3511808.3557685",
                    "CorpusId": 252904746
                },
                "corpusId": 252904746,
                "publicationVenue": {
                    "id": "7431ff67-91dc-41fa-b322-1b1ca657025f",
                    "name": "International Conference on Information and Knowledge Management",
                    "type": "conference",
                    "alternate_names": [
                        "Conference on Information and Knowledge Management",
                        "Conf Inf Knowl Manag",
                        "Int Conf Inf Knowl Manag",
                        "CIKM"
                    ],
                    "url": "http://www.cikm.org/"
                },
                "url": "https://www.semanticscholar.org/paper/0845909f66329bd58306a1ede76834275a751fed",
                "title": "Robust Semi-supervised Domain Adaptation against Noisy Labels",
                "abstract": "Built upon clean/correct labels, semi-supervised domain adaptation (SSDA) is a well-explored task, which, however, may not be easily obtained. This paper considers a challenging but practical scenario, i.e., the noisy SSDA with polluted labels. Specifically, it is observed that abnormal samples appear to have more randomness and inconsistency among the various views. To this end, we have devised an anomaly score function to detect noisy samples based on the similarity of differently augmented instances. The noisy labeled target samples are re-weighted according to such anomaly scores where the abnormal data contribute less to model training. Moreover, pseudo labeling usually suffers from confirmation bias. To remedy it, we have introduced the adversarial disturbance to raise the divergence across differently augmented views. The experimental results on the contaminated SSDA benchmarks demonstrate the effectiveness of our method over the baselines in both robustness and accuracy.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "12282768",
                        "name": "Can Qin"
                    },
                    {
                        "authorId": "1717863",
                        "name": "Yizhou Wang"
                    },
                    {
                        "authorId": "46956675",
                        "name": "Y. Fu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "In recent years, an increasing number of studies are using deep learning techniques to overcome the issue of noisy labels [19, 27, 35]."
            ],
            "citingPaper": {
                "paperId": "f1bbf9c46364a4a64cfa0328e455eecb4f23d240",
                "externalIds": {
                    "DBLP": "conf/kbse/00020LS22",
                    "DOI": "10.1145/3551349.3560418",
                    "CorpusId": 255441329
                },
                "corpusId": 255441329,
                "publicationVenue": {
                    "id": "1c2ab05c-7d69-465e-929d-0920857aedce",
                    "name": "International Conference on Automated Software Engineering",
                    "type": "conference",
                    "alternate_names": [
                        "Autom Softw Eng",
                        "ASE",
                        "Automated Software Engineering",
                        "Int Conf Autom Softw Eng"
                    ],
                    "url": "http://ase.informatik.uni-essen.de/"
                },
                "url": "https://www.semanticscholar.org/paper/f1bbf9c46364a4a64cfa0328e455eecb4f23d240",
                "title": "MalWhiteout: Reducing Label Errors in Android Malware Detection",
                "abstract": "Machine learning based Android malware detection has attracted a great deal of research work in recent years. A reliable malware dataset is critical to evaluate the effectiveness of malware detection approaches. Unfortunately, existing malware datasets used in our community are mainly labelled by leveraging existing anti-virus services (i.e., VirusTotal), which are prone to mislabelling. This, however, would lead to the inaccurate evaluation of the malware detection techniques. Removing label noises from Android malware datasets can be quite challenging, especially at a large data scale. To address this problem, we propose an effective approach called MalWhiteout to reduce label errors in Android malware datasets. Specifically, we creatively introduce Confident Learning (CL), an advanced noise estimation approach, to the domain of Android malware detection. To combat false positives introduced by CL, we incorporate the idea of ensemble learning and inter-app relation to achieve a more robust capability in noise detection. We evaluate MalWhiteout on a curated large-scale and reliable benchmark dataset. Experimental results show that MalWhiteout is capable of detecting label noises with over 94% accuracy even at a high noise ratio (i.e., 30%) of the dataset. MalWhiteout outperforms the state-of-the-art approach in terms of both effectiveness (8% to 218% improvement) and efficiency (70 to 249 times faster) across different settings. By reducing label noises, we show that the performance of existing malware detection approaches can be improved.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108551924",
                        "name": "Liu Wang"
                    },
                    {
                        "authorId": "2145339122",
                        "name": "Haoyu Wang"
                    },
                    {
                        "authorId": "1708419",
                        "name": "Xiapu Luo"
                    },
                    {
                        "authorId": "34296085",
                        "name": "Yulei Sui"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "[21] went further and proposed a partially Huberised Cross Entropy loss, which utilized gradient clipping to arrive at a more robust training solution.",
                "\u2022 GCE: Generalised Cross-Entropy [20] \u2022 PHuber: partially Huberised Cross-Entropy [21]"
            ],
            "citingPaper": {
                "paperId": "f9e066eb323ff906594004e2523272b746433db4",
                "externalIds": {
                    "ArXiv": "2209.14553",
                    "DBLP": "journals/corr/abs-2209-14553",
                    "DOI": "10.1109/DICTA56598.2022.10034562",
                    "CorpusId": 252596077
                },
                "corpusId": 252596077,
                "publicationVenue": {
                    "id": "375cb686-e96e-4b79-825c-1589c99aca1d",
                    "name": "International Conference on Digital Image Computing: Techniques and Applications",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Digit Image Comput Tech Appl",
                        "DICTA",
                        "Digital Image Computing: Techniques and Applications",
                        "Digit Image Comput Tech Appl"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=710"
                },
                "url": "https://www.semanticscholar.org/paper/f9e066eb323ff906594004e2523272b746433db4",
                "title": "Regularizing Neural Network Training via Identity-wise Discriminative Feature Suppression",
                "abstract": "It is well-known that a deep neural network has a strong fitting capability and can easily achieve a low training error even with randomly assigned class labels. When the number of training samples is small, or the class labels are noisy, networks tend to memorize patterns specific to individual instances to minimize the training error. This leads to the issue of overfitting and poor generalisation performance. This paper explores a remedy by suppressing the network's tendency to rely on instance-specific patterns for empirical error minimisation. The proposed method is based on an adversarial training framework. It suppresses features that can be utilized to identify individual instances among samples within each class. This leads to classifiers only using features that are both discriminative across classes and common within each class. We call our method Adversarial Suppression of Identity Features (ASIF), and demonstrate the usefulness of this technique in boosting generalisation accuracy when faced with small datasets or noisy labels. Our source code is available.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2186405710",
                        "name": "Avraham Chapman"
                    },
                    {
                        "authorId": "2161037",
                        "name": "Lingqiao Liu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Several studies have, therefore, been conducted to investigate supervised learning under the label noise setting, including robust loss function [41, 58], sample selection [53, 55, 59], robust regularisation [14, 23, 43, 60] and robust architecture [11,16,29,64]."
            ],
            "citingPaper": {
                "paperId": "e1170425e3fa2f61336477ea52e6712f446f4ed2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-00906",
                    "ArXiv": "2209.00906",
                    "DOI": "10.1109/WACV56688.2023.00232",
                    "CorpusId": 252070494
                },
                "corpusId": 252070494,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/e1170425e3fa2f61336477ea52e6712f446f4ed2",
                "title": "Instance-Dependent Noisy Label Learning via Graphical Modelling",
                "abstract": "Noisy labels are unavoidable yet troublesome in the ecosystem of deep learning because models can easily overfit them. There are many types of label noise, such as symmetric, asymmetric and instance-dependent noise (IDN), with IDN being the only type that depends on image information. Such dependence on image information makes IDN a critical type of label noise to study, given that labelling mistakes are caused in large part by insufficient or ambiguous information about the visual classes present in images. Aiming to provide an effective technique to address IDN, we present a new graphical modelling approach called InstanceGM, that combines discriminative and generative models. The main contributions of InstanceGM are: i) the use of the continuous Bernoulli distribution to train the generative model, offering significant training advantages, and ii) the exploration of a state-of-the-art noisy-label discriminative classifier to generate clean labels from instance-dependent noisy-label samples. InstanceGM is competitive with current noisy-label learning approaches, particularly in IDN benchmarks using synthetic and real-world datasets, where our method shows better accuracy than the competitors in most experiments1.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2075458292",
                        "name": "Arpit Garg"
                    },
                    {
                        "authorId": null,
                        "name": "Cuong Nguyen"
                    },
                    {
                        "authorId": "145326496",
                        "name": "Rafael Felix"
                    },
                    {
                        "authorId": "3354627",
                        "name": "Thanh-Toan Do"
                    },
                    {
                        "authorId": "145575177",
                        "name": "G. Carneiro"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "cc395eec81f421a6d9d0386f891e43fa597d792a",
                "externalIds": {
                    "DOI": "10.1007/s11431-022-2091-9",
                    "CorpusId": 251418931
                },
                "corpusId": 251418931,
                "publicationVenue": {
                    "id": "e66be951-1e6a-417b-b768-fa43c83c31f6",
                    "name": "Science China Technological Sciences",
                    "type": "journal",
                    "alternate_names": [
                        "Sci China Technol Sci",
                        "Sci China-technological Sci",
                        "Science China-technological Sciences"
                    ],
                    "issn": "1869-1900",
                    "url": "https://link.springer.com/journal/volumesAndIssues/11431"
                },
                "url": "https://www.semanticscholar.org/paper/cc395eec81f421a6d9d0386f891e43fa597d792a",
                "title": "Active label-denoising algorithm based on broad learning for annotation of machine health status",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1390722278",
                        "name": "Guokai Liu"
                    },
                    {
                        "authorId": "2117664427",
                        "name": "Weiming Shen"
                    },
                    {
                        "authorId": "2148990145",
                        "name": "Liang Gao"
                    },
                    {
                        "authorId": "143692578",
                        "name": "A. Kusiak"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "1d091415de4f1a4b369d72cdbf4a3545d9f74cb7",
                "externalIds": {
                    "DBLP": "conf/aaai/TsaiLF22",
                    "DOI": "10.1609/aaai.v36i10.21391",
                    "CorpusId": 250287102
                },
                "corpusId": 250287102,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/1d091415de4f1a4b369d72cdbf4a3545d9f74cb7",
                "title": "Contrast-Enhanced Semi-supervised Text Classification with Few Labels",
                "abstract": "Traditional text classification requires thousands of annotated data or an additional Neural Machine Translation (NMT) system, which are expensive to obtain in real applications. This paper presents a Contrast-Enhanced Semi-supervised Text Classification (CEST) framework under label-limited settings without incorporating any NMT systems. We propose a certainty-driven sample selection method and a contrast-enhanced similarity graph to utilize data more efficiently in self-training, alleviating the annotation-starving problem. The graph imposes a smoothness constraint on the unlabeled data to improve the coherence and the accuracy of pseudo-labels. Moreover, CEST formulates the training as a \u201clearning from noisy labels\u201d problem and performs the optimization accordingly. A salient feature of this formulation is the explicit suppression of the severe error propagation problem in conventional semi-supervised learning. With solely 30 labeled data per class for both training and validation dataset, CEST outperforms the previous state-of-the-art algorithms by 2.11% accuracy and only falls within the 3.04% accuracy range of fully-supervised pre-training language model fine-tuning on thousands of labeled data.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2128479172",
                        "name": "Austin Cheng-Yun Tsai"
                    },
                    {
                        "authorId": "2174980400",
                        "name": "Sheng-Ya Lin"
                    },
                    {
                        "authorId": "144906905",
                        "name": "L. Fu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "7f53c70a3b5aa22e2843db16c00bb4a3cbb0ba41",
                "externalIds": {
                    "DBLP": "conf/aaai/Silva0KL22",
                    "DOI": "10.1609/aaai.v36i8.20806",
                    "CorpusId": 250289029
                },
                "corpusId": 250289029,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/7f53c70a3b5aa22e2843db16c00bb4a3cbb0ba41",
                "title": "Noise-Robust Learning from Multiple Unsupervised Sources of Inferred Labels",
                "abstract": "Deep Neural Networks (DNNs) generally require large-scale datasets for training. Since manually obtaining clean labels for large datasets is extremely expensive, unsupervised models based on domain-specific heuristics can be used to efficiently infer the labels for such datasets. However, the labels from such inferred sources are typically noisy, which could easily mislead and lessen the generalizability of DNNs. Most approaches proposed in the literature to address this problem assume the label noise depends only on the true class of an instance (i.e., class-conditional noise). However, this assumption is not realistic for the inferred labels as they are typically inferred based on the features of the instances. The few recent attempts to model such instance-dependent (i.e., feature-dependent) noise require auxiliary information about the label noise (e.g., noise rates or clean samples). This work proposes a theoretically motivated framework to correct label noise in the presence of multiple labels inferred from unsupervised models. The framework consists of two modules: (1) MULTI-IDNC, a novel approach to correct label noise that is instance-dependent yet not class-conditional; (2) MULTI-CCNC, which extends an existing class-conditional noise-robust approach to yield improved class-conditional noise correction using multiple noisy label sources. We conduct experiments using nine real-world datasets for three different classification tasks (images, text and graph nodes). Our results show that our approach achieves notable improvements (e.g., 6.4% in accuracy) against state-of-the-art baselines while dealing with both instance-dependent and class-conditional noise in inferred label sources.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "49915323",
                        "name": "Amila Silva"
                    },
                    {
                        "authorId": "2114162969",
                        "name": "Ling Luo"
                    },
                    {
                        "authorId": "2476111",
                        "name": "S. Karunasekera"
                    },
                    {
                        "authorId": "1688394",
                        "name": "C. Leckie"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "This approach has been pursued in a large body of work (Long & Servedio, 2008; Wang et al., 2019a; Liu & Guo, 2020; Lyu & Tsang, 2020; Menon et al., 2020; Feng et al., 2020) that embraces new loss functions, especially symmetric losses and their variants (van Rooyen et al., 2015; Ghosh et al.,\u2026",
                "This approach has been pursued in a large body of work (Long & Servedio, 2008; Wang et al., 2019a; Liu & Guo, 2020; Lyu & Tsang, 2020; Menon et al., 2020; Feng et al., 2020) that embraces new loss functions, especially symmetric losses and their variants (van Rooyen et al."
            ],
            "citingPaper": {
                "paperId": "ea1f1d59e6ca77b3f8484af00b3bca83c5688e12",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-11602",
                    "ArXiv": "2206.11602",
                    "DOI": "10.48550/arXiv.2206.11602",
                    "CorpusId": 249953544
                },
                "corpusId": 249953544,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/ea1f1d59e6ca77b3f8484af00b3bca83c5688e12",
                "title": "Prototype-Anchored Learning for Learning with Imperfect Annotations",
                "abstract": "The success of deep neural networks greatly relies on the availability of large amounts of high-quality annotated data, which however are difficult or expensive to obtain. The resulting labels may be class imbalanced, noisy or human biased. It is challenging to learn unbiased classification models from imperfectly annotated datasets, on which we usually suffer from overfitting or underfitting. In this work, we thoroughly investigate the popular softmax loss and margin-based loss, and offer a feasible approach to tighten the generalization error bound by maximizing the minimal sample margin. We further derive the optimality condition for this purpose, which indicates how the class prototypes should be anchored. Motivated by theoretical analysis, we propose a simple yet effective method, namely prototype-anchored learning (PAL), which can be easily incorporated into various learning-based classification schemes to handle imperfect annotation. We verify the effectiveness of PAL on class-imbalanced learning and noise-tolerant learning by extensive experiments on synthetic and real-world datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109520799",
                        "name": "Xiong Zhou"
                    },
                    {
                        "authorId": "2110655701",
                        "name": "Xianming Liu"
                    },
                    {
                        "authorId": "2431195",
                        "name": "Deming Zhai"
                    },
                    {
                        "authorId": "2141510194",
                        "name": "Junjun Jiang"
                    },
                    {
                        "authorId": "2109103156",
                        "name": "Xin Gao"
                    },
                    {
                        "authorId": "2152001711",
                        "name": "Xiangyang Ji"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", 2019), gradient clipping (Menon et al., 2020), label smoothing (Lukasik et al."
            ],
            "citingPaper": {
                "paperId": "b8f4469596d08471daac086f6379131aa60f5a0d",
                "externalIds": {
                    "ArXiv": "2206.08063",
                    "DBLP": "journals/corr/abs-2206-08063",
                    "DOI": "10.48550/arXiv.2206.08063",
                    "CorpusId": 249712198
                },
                "corpusId": 249712198,
                "publicationVenue": {
                    "id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                    "name": "Annual Meeting of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Annu Meet Assoc Comput Linguistics",
                        "Meeting of the Association for Computational Linguistics",
                        "ACL",
                        "Meet Assoc Comput Linguistics"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/acl/"
                },
                "url": "https://www.semanticscholar.org/paper/b8f4469596d08471daac086f6379131aa60f5a0d",
                "title": "Towards Robust Ranker for Text Retrieval",
                "abstract": "A ranker plays an indispensable role in the de facto 'retrieval&rerank' pipeline, but its training still lags behind -- learning from moderate negatives or/and serving as an auxiliary module for a retriever. In this work, we first identify two major barriers to a robust ranker, i.e., inherent label noises caused by a well-trained retriever and non-ideal negatives sampled for a high-capable ranker. Thereby, we propose multiple retrievers as negative generators improve the ranker's robustness, where i) involving extensive out-of-distribution label noises renders the ranker against each noise distribution, and ii) diverse hard negatives from a joint distribution are relatively close to the ranker's negative distribution, leading to more challenging thus effective training. To evaluate our robust ranker (dubbed R$^2$anker), we conduct experiments in various settings on the popular passage retrieval benchmark, including BM25-reranking, full-ranking, retriever distillation, etc. The empirical results verify the new state-of-the-art effectiveness of our model.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2110348767",
                        "name": "Yucheng Zhou"
                    },
                    {
                        "authorId": "143681703",
                        "name": "Tao Shen"
                    },
                    {
                        "authorId": "2442662",
                        "name": "Xiubo Geng"
                    },
                    {
                        "authorId": "8801869",
                        "name": "Chongyang Tao"
                    },
                    {
                        "authorId": "46747953",
                        "name": "Can Xu"
                    },
                    {
                        "authorId": "2062835",
                        "name": "Guodong Long"
                    },
                    {
                        "authorId": "24128606",
                        "name": "Binxing Jiao"
                    },
                    {
                        "authorId": "2086994543",
                        "name": "Daxin Jiang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "One representative class of methods aims to reduce noisy samples\u2019 impact with carefully designed losses [12], [22], [23], regularization terms [24], [25] or adaptive sample re-weighting [13], [26]\u2013[28]."
            ],
            "citingPaper": {
                "paperId": "bf0557544a19a8a2e699394d0ad864b719b9b13f",
                "externalIds": {
                    "ArXiv": "2206.05708",
                    "DBLP": "journals/tip/WangGLH22",
                    "DOI": "10.1109/TIP.2022.3211468",
                    "CorpusId": 249626217
                },
                "corpusId": 249626217,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/bf0557544a19a8a2e699394d0ad864b719b9b13f",
                "title": "Narrowing the Gap: Improved Detector Training With Noisy Location Annotations",
                "abstract": "Deep learning methods require massive of annotated data for optimizing parameters. For example, datasets attached with accurate bounding box annotations are essential for modern object detection tasks. However, labeling with such pixel-wise accuracy is laborious and time-consuming, and elaborate labeling procedures are indispensable for reducing man-made noise, involving annotation review and acceptance testing. In this paper, we focus on the impact of noisy location annotations on the performance of object detection approaches and aim to, on the user side, reduce the adverse effect of the noise. First, noticeable performance degradation is experimentally observed for both one-stage and two-stage detectors when noise is introduced to the bounding box annotations. For instance, our synthesized noise results in performance decrease from 38.9% AP to 33.6% AP for FCOS detector on COCO test split, and 37.8%AP to 33.7%AP for Faster R-CNN. Second, a self-correction technique based on a Bayesian filter for prediction ensemble is proposed to better exploit the noisy location annotations following a Teacher-Student learning paradigm. Experiments for both synthesized and real-world scenarios consistently demonstrate the effectiveness of our approach, e.g., our method increases the degraded performance of the FCOS detector from 33.6% AP to 35.6% AP on COCO.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "49184541",
                        "name": "Shaoru Wang"
                    },
                    {
                        "authorId": "144306542",
                        "name": "Jin Gao"
                    },
                    {
                        "authorId": "2152691925",
                        "name": "Bing Li"
                    },
                    {
                        "authorId": "2146242065",
                        "name": "Weiming Hu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "4025b14ceb367bbf6102ff8f06872308291ca3fb",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-05040",
                    "ArXiv": "2205.05040",
                    "DOI": "10.48550/arXiv.2205.05040",
                    "CorpusId": 248666063
                },
                "corpusId": 248666063,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/4025b14ceb367bbf6102ff8f06872308291ca3fb",
                "title": "A Communication-Efficient Distributed Gradient Clipping Algorithm for Training Deep Neural Networks",
                "abstract": "In distributed training of deep neural networks, people usually run Stochastic Gradient Descent (SGD) or its variants on each machine and communicate with other machines periodically. However, SGD might converge slowly in training some deep neural networks (e.g., RNN, LSTM) because of the exploding gradient issue. Gradient clipping is usually employed to address this issue in the single machine setting, but exploring this technique in the distributed setting is still in its infancy: it remains mysterious whether the gradient clipping scheme can take advantage of multiple machines to enjoy parallel speedup. The main technical difficulty lies in dealing with nonconvex loss function, non-Lipschitz continuous gradient, and skipping communication rounds simultaneously. In this paper, we explore a relaxed-smoothness assumption of the loss landscape which LSTM was shown to satisfy in previous works, and design a communication-efficient gradient clipping algorithm. This algorithm can be run on multiple machines, where each machine employs a gradient clipping scheme and communicate with other machines after multiple steps of gradient-based updates. Our algorithm is proved to have $O\\left(\\frac{1}{N\\epsilon^4}\\right)$ iteration complexity and $O(\\frac{1}{\\epsilon^3})$ communication complexity for finding an $\\epsilon$-stationary point in the homogeneous data setting, where $N$ is the number of machines. This indicates that our algorithm enjoys linear speedup and reduced communication rounds. Our proof relies on novel analysis techniques of estimating truncated random variables, which we believe are of independent interest. Our experiments on several benchmark datasets and various scenarios demonstrate that our algorithm indeed exhibits fast convergence speed in practice and thus validates our theory.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "14697929",
                        "name": "Mingrui Liu"
                    },
                    {
                        "authorId": "50713711",
                        "name": "Zhenxun Zhuang"
                    },
                    {
                        "authorId": "2165084386",
                        "name": "Yunwei Lei"
                    },
                    {
                        "authorId": "2067760056",
                        "name": "Chunyang Liao"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Robust loss to label noise Another direction of research is to design loss functions that are robust to label noise (Ghosh et al., 2015; 2017; Zhang & Sabuncu, 2018; Wang et al., 2019; Oksuz et al., 2020; Menon et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "30c6126b7bb567d06c5c62ad811175fd400a38f8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-12511",
                    "ArXiv": "2204.12511",
                    "DOI": "10.48550/arXiv.2204.12511",
                    "CorpusId": 248405706
                },
                "corpusId": 248405706,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/30c6126b7bb567d06c5c62ad811175fd400a38f8",
                "title": "PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions",
                "abstract": "Cross-entropy loss and focal loss are the most common choices when training deep neural networks for classification problems. Generally speaking, however, a good loss function can take on much more flexible forms, and should be tailored for different tasks and datasets. Motivated by how functions can be approximated via Taylor expansion, we propose a simple framework, named PolyLoss, to view and design loss functions as a linear combination of polynomial functions. Our PolyLoss allows the importance of different polynomial bases to be easily adjusted depending on the targeting tasks and datasets, while naturally subsuming the aforementioned cross-entropy loss and focal loss as special cases. Extensive experimental results show that the optimal choice within the PolyLoss is indeed dependent on the task and dataset. Simply by introducing one extra hyperparameter and adding one line of code, our Poly-1 formulation outperforms the cross-entropy loss and focal loss on 2D image classification, instance segmentation, object detection, and 3D object detection tasks, sometimes by a large margin.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2127987192",
                        "name": "Zhaoqi Leng"
                    },
                    {
                        "authorId": "120805419",
                        "name": "Mingxing Tan"
                    },
                    {
                        "authorId": "50557601",
                        "name": "Chenxi Liu"
                    },
                    {
                        "authorId": "8132903",
                        "name": "E. D. Cubuk"
                    },
                    {
                        "authorId": "2119204001",
                        "name": "Xiaojie Shi"
                    },
                    {
                        "authorId": "46378690",
                        "name": "Shuyang Cheng"
                    },
                    {
                        "authorId": "1881964177",
                        "name": "Drago Anguelov"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Methods following this direction includes constructing robust network [6, 12, 13, 59], robust loss function [11, 27, 53, 65, 68, 69], robust regularization [31, 47, 58] against noisy labels."
            ],
            "citingPaper": {
                "paperId": "3a9e5a5ab70f433905e365c0c91115d92c3eb305",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-07788",
                    "ArXiv": "2203.07788",
                    "DOI": "10.1109/CVPR52688.2022.00044",
                    "CorpusId": 247450936
                },
                "corpusId": 247450936,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3a9e5a5ab70f433905e365c0c91115d92c3eb305",
                "title": "Scalable Penalized Regression for Noise Detection in Learning with Noisy Labels",
                "abstract": "Noisy training set usually leads to the degradation of generalization and robustness of neural networks. In this paper, we propose using a theoretically guaranteed noisy label detection framework to detect and remove noisy data for Learning with Noisy Labels (LNL). Specifically, we design a penalized regression to model the linear relation between network features and one-hot labels, where the noisy data are identified by the non-zero mean shift parameters solved in the regression model. To make the framework scalable to datasets that contain a large number of categories and training data, we propose a split algorithm to divide the whole training set into small pieces that can be solved by the penalized regression in parallel, leading to the Scalable Penalized Regression (SPR) framework. We provide the non-asymptotic probabilistic condition for SP R to correctly identify the noisy data. While SPR can be regarded as a sample selection module for standard supervised training pipeline, we further combine it with semi-supervised algorithm to further exploit the support of noisy data as unlabeled data. Experimental results on several benchmark datasets and real-world noisy datasets show the effectiveness of our framework. Our code and pretrained models are released at https://github.com/Yikai-Wang/SPR-LNL.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108853258",
                        "name": "Yikai Wang"
                    },
                    {
                        "authorId": "8283163",
                        "name": "Xinwei Sun"
                    },
                    {
                        "authorId": "35782003",
                        "name": "Yanwei Fu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "result"
            ],
            "isInfluential": false,
            "contexts": [
                ", ptar that is closer to p \u2217, leads to better generalization performance; this is supported by results of Menon et al. (2021) and further empirical suggestions given here.",
                "This hypothesis is suggested by Proposition 3 of Menon et al. (2021), which shows (tracking constants omitted in their proof) that for any predictor f and loss bounded as L(y, \u0177) \u2264 `,",
                "There are various ways to cope with it; for instance, Menon et al. (2019) use gradient clipping, Patrini et al. (2017) use loss correction, Huang et al. (2020) change the supervision during training, and Zhang et al. (2020) employ extra information."
            ],
            "citingPaper": {
                "paperId": "91db2f1dae977f2cf139ce194173487133b1ad67",
                "externalIds": {
                    "ArXiv": "2203.02485",
                    "DBLP": "journals/corr/abs-2203-02485",
                    "DOI": "10.48550/arXiv.2203.02485",
                    "CorpusId": 247244493
                },
                "corpusId": 247244493,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/91db2f1dae977f2cf139ce194173487133b1ad67",
                "title": "Better Supervisory Signals by Observing Learning Paths",
                "abstract": "Better-supervised models might have better performance. In this paper, we first clarify what makes for good supervision for a classification problem, and then explain two existing label refining methods, label smoothing and knowledge distillation, in terms of our proposed criterion. To further answer why and how better supervision emerges, we observe the learning path, i.e., the trajectory of the model's predictions during training, for each training sample. We find that the model can spontaneously refine\"bad\"labels through a\"zig-zag\"learning path, which occurs on both toy and real datasets. Observing the learning path not only provides a new perspective for understanding knowledge distillation, overfitting, and learning dynamics, but also reveals that the supervisory signal of a teacher network can be very unstable near the best points in training on real tasks. Inspired by this, we propose a new knowledge distillation scheme, Filter-KD, which improves downstream classification performance in various settings.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115242507",
                        "name": "Yi Ren"
                    },
                    {
                        "authorId": "3431365",
                        "name": "Shangmin Guo"
                    },
                    {
                        "authorId": "36326783",
                        "name": "Danica J. Sutherland"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Gradient clipping [9, 32] is a functionality of an optimizer to prevent gradient explosion [56]."
            ],
            "citingPaper": {
                "paperId": "72e480bdf17dcc3f12bd34d76852d982093eacc1",
                "externalIds": {
                    "DBLP": "journals/nca/HurtikTHH22",
                    "DOI": "10.1007/s00521-022-07091-x",
                    "CorpusId": 248104824
                },
                "corpusId": 248104824,
                "publicationVenue": {
                    "id": "702e18c0-c8c6-4800-a398-42aa159394d1",
                    "name": "Neural computing & applications (Print)",
                    "type": "journal",
                    "alternate_names": [
                        "Neural comput  appl (print",
                        "Neural Comput Appl",
                        "Neural Computing and Applications"
                    ],
                    "issn": "0941-0643",
                    "url": "https://link.springer.com/journal/521"
                },
                "url": "https://www.semanticscholar.org/paper/72e480bdf17dcc3f12bd34d76852d982093eacc1",
                "title": "Binary cross-entropy with dynamical clipping",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2481156",
                        "name": "P. Hurt\u00edk"
                    },
                    {
                        "authorId": "1721601",
                        "name": "S. Tomasiello"
                    },
                    {
                        "authorId": "47655060",
                        "name": "Jan Hula"
                    },
                    {
                        "authorId": "1392312246",
                        "name": "David H\u00fdnar"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "A similar idea is also explored in gradient clipping (Menon et al., 2019) and loss reweighting (Liu & Tao, 2015; Wang et al.",
                "A similar idea is also explored in gradient clipping (Menon et al., 2019) and loss reweighting (Liu & Tao, 2015; Wang et al., 2017; Chang et al., 2017; Zhang et al., 2021b; Zetterqvist et al., 2021) methods."
            ],
            "citingPaper": {
                "paperId": "d237e110e233e13474e68ccd6580971926616577",
                "externalIds": {
                    "DBLP": "conf/icml/LiuZQY22",
                    "ArXiv": "2202.14026",
                    "CorpusId": 247158103
                },
                "corpusId": 247158103,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/d237e110e233e13474e68ccd6580971926616577",
                "title": "Robust Training under Label Noise by Over-parameterization",
                "abstract": "Recently, over-parameterized deep networks, with increasingly more network parameters than training samples, have dominated the performances of modern machine learning. However, when the training data is corrupted, it has been well-known that over-parameterized networks tend to overfit and do not generalize. In this work, we propose a principled approach for robust training of over-parameterized deep networks in classification tasks where a proportion of training labels are corrupted. The main idea is yet very simple: label noise is sparse and incoherent with the network learned from clean data, so we model the noise and learn to separate it from the data. Specifically, we model the label noise via another sparse over-parameterization term, and exploit implicit algorithmic regularizations to recover and separate the underlying corruptions. Remarkably, when trained using such a simple method in practice, we demonstrate state-of-the-art test accuracy against label noise on a variety of real datasets. Furthermore, our experimental results are corroborated by theory on simplified linear models, showing that exact separation between sparse noise and low-rank data can be achieved under incoherent conditions. The work opens many interesting directions for improving over-parameterized models by using sparse over-parameterization and implicit regularization.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "94035244",
                        "name": "Sheng Liu"
                    },
                    {
                        "authorId": "145687539",
                        "name": "Zhihui Zhu"
                    },
                    {
                        "authorId": "144403436",
                        "name": "Qing Qu"
                    },
                    {
                        "authorId": "1878841",
                        "name": "Chong You"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "leveraged gradient clipping for designing new loss functions [21]."
            ],
            "citingPaper": {
                "paperId": "26b0fe8c8c1398ddd767c8626762e3693ae17ea0",
                "externalIds": {
                    "DBLP": "journals/fi/ShiGW22",
                    "DOI": "10.3390/fi14020041",
                    "CorpusId": 246312562
                },
                "corpusId": 246312562,
                "publicationVenue": {
                    "id": "c3e5f1c8-9ba7-47e5-acde-53063a69d483",
                    "name": "Future Internet",
                    "type": "journal",
                    "issn": "1999-5903",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-156830",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-156830",
                        "https://www.mdpi.com/journal/futureinternet"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/26b0fe8c8c1398ddd767c8626762e3693ae17ea0",
                "title": "A Hybrid Robust-Learning Architecture for Medical Image Segmentation with Noisy Labels",
                "abstract": "Deep-learning models require large amounts of accurately labeled data. However, for medical image segmentation, high-quality labels rely on expert experience, and less-experienced operators provide noisy labels. How one might mitigate the negative effects caused by noisy labels for 3D medical image segmentation has not been fully investigated. In this paper, our purpose is to propose a novel hybrid robust-learning architecture to combat noisy labels for 3D medical image segmentation. Our method consists of three components. First, we focus on the noisy annotations of slices and propose a slice-level label-quality awareness method, which automatically generates label-quality scores for slices in a set. Second, we propose a shape-awareness regularization loss based on distance transform maps to introduce prior shape information and provide extra performance gains. Third, based on a re-weighting strategy, we propose an end-to-end hybrid robust-learning architecture to weaken the negative effects caused by noisy labels. Extensive experiments are performed on two representative datasets (i.e., liver segmentation and multi-organ segmentation). Our hybrid noise-robust architecture has shown competitive performance, compared to other methods. Ablation studies also demonstrate the effectiveness of slice-level label-quality awareness and a shape-awareness regularization loss for combating noisy labels.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "49887347",
                        "name": "Jialin Shi"
                    },
                    {
                        "authorId": "2110230055",
                        "name": "Chenyi Guo"
                    },
                    {
                        "authorId": "2115565474",
                        "name": "Ji Wu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Compare to standard lossl [12][13][14], the output of l is smaller when confronting noisy labels which will avoid models overfitting noisy labels during backward propagation."
            ],
            "citingPaper": {
                "paperId": "7b60b4de93be373871e32292de33a1feb7431386",
                "externalIds": {
                    "DOI": "10.1109/ICCECE54139.2022.9712750",
                    "CorpusId": 247045151
                },
                "corpusId": 247045151,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/7b60b4de93be373871e32292de33a1feb7431386",
                "title": "Combat Noisy Labels by Joint Training",
                "abstract": "Learning with noisy labels is one of the most challenging problems in WSL. Classical supervised learning assumes that models are trained with instances from clean data distribution. But in real world, instances with noisy labels are ubiquitous. With the development of Deep Learning, researchers find that Deep Neural Networks (DNN) are prone to overfit noisy instances gradually due to memorization effects. To tackle this problem, many seminal works in label-noise representation learning (LNRL) have been proposed to improve the performance of Deep Learning models. In this paper, we proposed a new learning paradigm via the lens of optimization. Specifically, we train two identical networks and each network utilizes small-loss policy to select reliable instances from mini-batch data. And then we take the union of selected instances from two networks as training examples. From the perspective of supervised information, we argue that our proposed approach can augment the supervision of LNRL via two networks' diversity. Empirical results on noisy version of MNIST, CIFAR-10 and CIFAR-100 demonstrate that our approach is superior towards other state-of-the-art approaches in LNRL and can effectively avoid overfitting noisy labels.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2155878840",
                        "name": "Hui Li"
                    },
                    {
                        "authorId": "30916396",
                        "name": "Z. Niu"
                    },
                    {
                        "authorId": "2155813912",
                        "name": "Lingxiang Peng"
                    },
                    {
                        "authorId": "2155826995",
                        "name": "Xiangtang Cui"
                    },
                    {
                        "authorId": "2125070764",
                        "name": "Yupeng Wang"
                    },
                    {
                        "authorId": "2158012166",
                        "name": "Peiqin Li"
                    },
                    {
                        "authorId": "2151195940",
                        "name": "Weijun Zhong"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", 2019; 2020), or outlier/noisy sample detection (Huber, 1992; Bhatia et al., 2015; Menon et al., 2019; Li et al., 2020).",
                "\u2026of distributional robustness (Duchi et al., 2019; Wang et al., 2020; Zhang et al., 2021; Ben-Tal et al., 2013), fairness (Hardt et al., 2016; Agarwal et al., 2018; Li et al., 2019; 2020), or outlier/noisy sample detection (Huber, 1992; Bhatia et al., 2015; Menon et al., 2019; Li et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "49750bf1dd5e66025c18adfce5ce7fef445fb9d4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-00072",
                    "ArXiv": "2201.00072",
                    "CorpusId": 245650903
                },
                "corpusId": 245650903,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/49750bf1dd5e66025c18adfce5ce7fef445fb9d4",
                "title": "BARACK: Partially Supervised Group Robustness With Guarantees",
                "abstract": "While neural networks have shown remarkable success on classification tasks in terms of average-case performance, they often fail to perform well on certain groups of the data. Such group information may be expensive to obtain; thus, recent works in robustness and fairness have proposed ways to improve worst-group performance even when group labels are unavailable for the training data. However, these methods generally underperform methods that utilize group information at training time. In this work, we assume access to a small number of group labels alongside a larger dataset without group labels. We propose BARACK, a simple two-step framework to utilize this partial group information to improve worst-group performance: train a model to predict the missing group labels for the training data, and then use these predicted group labels in a robust optimization objective. Theoretically, we provide generalization bounds for our approach in terms of the worst-group performance, which scale with respect to both the total number of training points and the number of training points with group labels. Empirically, our method outperforms the baselines that do not use group information, even when only 1-33% of points have group labels. We provide ablation studies to support the robustness and extensibility of our framework.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145193121",
                        "name": "N. Sohoni"
                    },
                    {
                        "authorId": "2095979",
                        "name": "Maziar Sanjabi"
                    },
                    {
                        "authorId": "2482072",
                        "name": "Nicolas Ballas"
                    },
                    {
                        "authorId": "1954250",
                        "name": "Aditya Grover"
                    },
                    {
                        "authorId": "35557488",
                        "name": "Shaoliang Nie"
                    },
                    {
                        "authorId": "22593971",
                        "name": "Hamed Firooz"
                    },
                    {
                        "authorId": "1803218",
                        "name": "Christopher R\u00e9"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "They can be further categorized as follows: various loss functions [21, 54, 58\u201360, 68, 72, 90, 90, 96, 112], regularizations [2, 10, 34, 35, 37, 38, 41, 44, 50, 52, 54, 56, 59, 61, 62, 70, 71, 83, 110], re-weighting training samples [14, 42, 43, 57, 64, 74, 76, 89, 95, 98, 99, 99], and correcting noisy labels [29, 33, 82, 86, 107, 114]."
            ],
            "citingPaper": {
                "paperId": "185d022c76e55dd3fa4134becc50c0ab0cdeb3a0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-14932",
                    "ArXiv": "2111.14932",
                    "DOI": "10.1007/978-3-031-19806-9_41",
                    "CorpusId": 244729337
                },
                "corpusId": 244729337,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/185d022c76e55dd3fa4134becc50c0ab0cdeb3a0",
                "title": "Learning with Noisy Labels by Efficient Transition Matrix Estimation to Combat Label Miscorrection",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1509424106",
                        "name": "Seong Min Kye"
                    },
                    {
                        "authorId": "2110459735",
                        "name": "Kwanghee Choi"
                    },
                    {
                        "authorId": "134234025",
                        "name": "Joonyoung Yi"
                    },
                    {
                        "authorId": "50814662",
                        "name": "Buru Chang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "However, it has been proven that in classification problems standard gradient clipping does not in general provide robustness to label noise [20]."
            ],
            "citingPaper": {
                "paperId": "bfb220f40ea2f6fd091cb7994f22612d4b6ba10e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-08462",
                    "ArXiv": "2111.08462",
                    "CorpusId": 244130142
                },
                "corpusId": 244130142,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/bfb220f40ea2f6fd091cb7994f22612d4b6ba10e",
                "title": "Towards Lightweight Controllable Audio Synthesis with Conditional Implicit Neural Representations",
                "abstract": "The high temporal resolution of audio and our perceptual sensitivity to small irregularities in waveforms make synthesizing at high sampling rates a complex and computationally intensive task, prohibiting real-time, controllable synthesis within many approaches. In this work we aim to shed light on the potential of Conditional Implicit Neural Representations (CINRs) as lightweight backbones in generative frameworks for audio synthesis. Our experiments show that small Periodic Conditional INRs (PCINRs) learn faster and generally produce quantitatively better audio reconstructions than Transposed Convolutional Neural Networks with equal parameter counts. However, their performance is very sensitive to activation scaling hyperparameters. When learning to represent more uniform sets, PCINRs tend to introduce artificial high-frequency components in reconstructions. We validate this noise can be minimized by applying standard weight regularization during training or decreasing the compositional depth of PCINRs, and suggest directions for future research.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2140578249",
                        "name": "Jan Zuiderveld"
                    },
                    {
                        "authorId": "8300792",
                        "name": "M. Federici"
                    },
                    {
                        "authorId": "2231179",
                        "name": "E. Bekkers"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "\u20262016, Han et al., 2018a], (2) loss regularization techniques [Goodfellow et al., 2015, Pereyra et al., 2017, Tanno et al., 2019, Hendrycks et al., 2019, Menon et al., 2020], and (3) loss correction techniques [Patrini et al., 2017, Chang et al., 2017, Ma et al., 2018, Arazo et al., 2019]."
            ],
            "citingPaper": {
                "paperId": "2505543a8458e6bcc0f3c3e715b419593c1b59f7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-14222",
                    "ArXiv": "2110.14222",
                    "CorpusId": 239998264
                },
                "corpusId": 239998264,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2505543a8458e6bcc0f3c3e715b419593c1b59f7",
                "title": "Sample Selection for Fair and Robust Training",
                "abstract": "Fairness and robustness are critical elements of Trustworthy AI that need to be addressed together. Fairness is about learning an unbiased model while robustness is about learning from corrupted data, and it is known that addressing only one of them may have an adverse affect on the other. In this work, we propose a sample selection-based algorithm for fair and robust training. To this end, we formulate a combinatorial optimization problem for the unbiased selection of samples in the presence of data corruption. Observing that solving this optimization problem is strongly NP-hard, we propose a greedy algorithm that is efficient and effective in practice. Experiments show that our algorithm obtains fairness and robustness that are better than or comparable to the state-of-the-art technique, both on synthetic and benchmark real datasets. Moreover, unlike other fair and robust training baselines, our algorithm can be used by only modifying the sampling step in batch selection without changing the training algorithm or leveraging additional clean data.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "30840932",
                        "name": "Yuji Roh"
                    },
                    {
                        "authorId": "2115495251",
                        "name": "Kangwook Lee"
                    },
                    {
                        "authorId": "3288247",
                        "name": "Steven Euijong Whang"
                    },
                    {
                        "authorId": "47808468",
                        "name": "Changho Suh"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "c8ab118f732ef5b1b25af4be5dbb043dc44ef653",
                "externalIds": {
                    "DBLP": "conf/iecon/ZhaoLC21",
                    "DOI": "10.1109/IECON48115.2021.9589632",
                    "CorpusId": 243945960
                },
                "corpusId": 243945960,
                "publicationVenue": {
                    "id": "625842ea-b2ac-4832-aa41-6bd142cfc9d9",
                    "name": "Annual Conference of the IEEE Industrial Electronics Society",
                    "type": "conference",
                    "alternate_names": [
                        "Conference of the Industrial Electronics Society",
                        "IECON",
                        "Conf Ind Electron Soc",
                        "Annu Conf IEEE Ind Electron Soc"
                    ],
                    "issn": "2162-4704",
                    "alternate_issns": [
                        "2379-9633"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000352"
                },
                "url": "https://www.semanticscholar.org/paper/c8ab118f732ef5b1b25af4be5dbb043dc44ef653",
                "title": "Robust Classification with Noisy Labels for Manufacturing Applications: A Hybrid Approach Based on Active Learning and Data Cleaning",
                "abstract": "Classification is an important machine learning technique that attracts growing interests in various manufacturing applications. Learning an accurate classifier generally requires a large-scale perfectly-labeled training dataset. However, such \"golden\" labels are not only expensive but also difficult to collect in practice. To facilitate accurate classification in the presence of noisy labels, we propose a novel hybrid method based on active learning and data cleaning. Specifically, we first train an initial classifier with noisily- labeled data. Based on its prediction outcomes, a set of most informative samples is queried for manual annotation. To effectively correct other incorrect labels, we further self-label the unqueried samples based on the true labels provided by human experts and the estimated labels predicted by the initial classifier. As demonstrated by the experimental results based on two industrial datasets, the proposed approach achieves superior accuracy over other conventional methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2111308868",
                        "name": "Shuo Zhao"
                    },
                    {
                        "authorId": "2153901172",
                        "name": "Xin Li"
                    },
                    {
                        "authorId": "1993125108",
                        "name": "Ying-Chi Chen"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "f581e1789824ad03d9cab89aaf5ec413f42b3afc",
                "externalIds": {
                    "ArXiv": "2109.14563",
                    "DBLP": "journals/corr/abs-2109-14563",
                    "CorpusId": 238215308
                },
                "corpusId": 238215308,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f581e1789824ad03d9cab89aaf5ec413f42b3afc",
                "title": "Robust Temporal Ensembling for Learning with Noisy Labels",
                "abstract": "Successful training of deep neural networks with noisy labels is an essential capability as most real-world datasets contain some amount of mislabeled data. Left unmitigated, label noise can sharply degrade typical supervised learning approaches. In this paper, we present robust temporal ensembling (RTE), which combines robust loss with semi-supervised regularization methods to achieve noise-robust learning. We demonstrate that RTE achieves state-of-the-art performance across the CIFAR-10, CIFAR-100, ImageNet, WebVision, and Food-101N datasets, while forgoing the recent trend of label filtering and/or fixing. Finally, we show that RTE also retains competitive corruption robustness to unforeseen input noise using CIFAR-10-C, obtaining a mean corruption error (mCE) of 13.50% even in the presence of an 80% noise ratio, versus 26.9% mCE with standard methods on clean data.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2110970811",
                        "name": "Abel Brown"
                    },
                    {
                        "authorId": "2080538157",
                        "name": "Benedikt D. Schifferer"
                    },
                    {
                        "authorId": "33452695",
                        "name": "R. DiPietro"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", 2012; Zhang and Sabuncu, 2018) or gradient clipping (Menon et al., 2020).",
                "Losses can also be modified to address outliers by favoring small losses (Yu et al., 2012; Zhang and Sabuncu, 2018) or gradient clipping (Menon et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "37f66334db859eaed3fbbd52b2da2d0207749711",
                "externalIds": {
                    "ArXiv": "2109.06141",
                    "DBLP": "journals/jmlr/0005BSS23",
                    "CorpusId": 237491713
                },
                "corpusId": 237491713,
                "publicationVenue": {
                    "id": "c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                    "name": "Journal of machine learning research",
                    "type": "journal",
                    "alternate_names": [
                        "Journal of Machine Learning Research",
                        "J mach learn res",
                        "J Mach Learn Res"
                    ],
                    "issn": "1532-4435",
                    "alternate_issns": [
                        "1533-7928"
                    ],
                    "url": "http://www.ai.mit.edu/projects/jmlr/",
                    "alternate_urls": [
                        "http://jmlr.csail.mit.edu/",
                        "http://www.jmlr.org/",
                        "http://portal.acm.org/affiliated/jmlr"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/37f66334db859eaed3fbbd52b2da2d0207749711",
                "title": "On Tilted Losses in Machine Learning: Theory and Applications",
                "abstract": "Exponential tilting is a technique commonly used in fields such as statistics, probability, information theory, and optimization to create parametric distribution shifts. Despite its prevalence in related fields, tilting has not seen widespread use in machine learning. In this work, we aim to bridge this gap by exploring the use of tilting in risk minimization. We study a simple extension to ERM -- tilted empirical risk minimization (TERM) -- which uses exponential tilting to flexibly tune the impact of individual losses. The resulting framework has several useful properties: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to the tail probability of losses. Our work makes rigorous connections between TERM and related objectives, such as Value-at-Risk, Conditional Value-at-Risk, and distributionally robust optimization (DRO). We develop batch and stochastic first-order optimization methods for solving TERM, provide convergence guarantees for the solvers, and show that the framework can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications in machine learning, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. Despite the straightforward modification TERM makes to traditional ERM objectives, we find that the framework can consistently outperform ERM and deliver competitive performance with state-of-the-art, problem-specific approaches.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145530218",
                        "name": "Tian Li"
                    },
                    {
                        "authorId": "1791052",
                        "name": "Ahmad Beirami"
                    },
                    {
                        "authorId": "2095979",
                        "name": "Maziar Sanjabi"
                    },
                    {
                        "authorId": "145260024",
                        "name": "Virginia Smith"
                    }
                ]
            }
        },
        {
            "intents": [
                "result"
            ],
            "isInfluential": false,
            "contexts": [
                "We also compare with Co-teaching[9], which is the representative work of sample selection, and PHuber-CE [23], which is a simple variant of gradient clip-\nping.",
                "We also compare with Co-teaching[9], which is the representative work of sample selection, and PHuber-CE [23], which is a simple variant of gradient clip-",
                "As shown in Table 4, our method works better than Co-teaching and PHuber-CE."
            ],
            "citingPaper": {
                "paperId": "d784142c033f783b86f52849339f33aff9d8084d",
                "externalIds": {
                    "DBLP": "conf/iccv/ZhouLWZJJ21",
                    "ArXiv": "2108.00192",
                    "DOI": "10.1109/ICCV48922.2021.00014",
                    "CorpusId": 236772536
                },
                "corpusId": 236772536,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/d784142c033f783b86f52849339f33aff9d8084d",
                "title": "Learning with Noisy Labels via Sparse Regularization",
                "abstract": "Learning with noisy labels is an important and challenging task for training accurate deep neural networks. Some commonly-used loss functions, such as Cross Entropy (CE), suffer from severe overfitting to noisy labels. Robust loss functions that satisfy the symmetric condition were tailored to remedy this problem, which however encounter the underfitting effect. In this paper, we theoretically prove that any loss can be made robust to noisy labels by restricting the network output to the set of permutations over a fixed vector. When the fixed vector is one-hot, we only need to constrain the output to be one-hot, which however produces zero gradients almost everywhere and thus makes gradient-based optimization difficult. In this work, we introduce the sparse regularization strategy to approximate the one-hot constraint, which is composed of network output sharpening operation that enforces the output distribution of a net-work to be sharp and the \u2113p-norm (p \u2264 1) regularization that promotes the network output to be sparse. This simple approach guarantees the robustness of arbitrary loss functions while not hindering the fitting ability. Experimental results demonstrate that our method can significantly improve the performance of commonly-used loss functions in the presence of noisy labels and class imbalance, and out-perform the state-of-the-art methods. The code is available at https://github.com/hitcszx/lnl_sr.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109520799",
                        "name": "Xiong Zhou"
                    },
                    {
                        "authorId": "2108681776",
                        "name": "Xianming Liu"
                    },
                    {
                        "authorId": "2109501904",
                        "name": "Chenyang Wang"
                    },
                    {
                        "authorId": "2431195",
                        "name": "Deming Zhai"
                    },
                    {
                        "authorId": "2141510194",
                        "name": "Junjun Jiang"
                    },
                    {
                        "authorId": "7807689",
                        "name": "Xiangyang Ji"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Recent studies demonstrate that gradient clipping can be applied for robustness to model update poisoning attacks [38] and label noise [39]."
            ],
            "citingPaper": {
                "paperId": "5f509611696295a7f45c07670721ce6966e24bee",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-14956",
                    "ArXiv": "2106.14956",
                    "DOI": "10.1109/TSP.2022.3185885",
                    "CorpusId": 235670178
                },
                "corpusId": 235670178,
                "publicationVenue": {
                    "id": "1f6f3f05-6a23-42f0-8d31-98ab8089c1f2",
                    "name": "IEEE Transactions on Signal Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Signal Process"
                    ],
                    "issn": "1053-587X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=78",
                    "alternate_urls": [
                        "http://www.signalprocessingsociety.org/publications/periodicals/tsp/",
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=78"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5f509611696295a7f45c07670721ce6966e24bee",
                "title": "Robust Distributed Optimization With Randomly Corrupted Gradients",
                "abstract": "In this paper, we propose a first-order distributed optimization algorithm that is provably robust to Byzantine failures\u2013arbitrary and potentially adversarial behavior, where all the participating agents are prone to failure. We model each agent\u2019s state over time as a two-state Markov chain that indicates Byzantine or trustworthy behaviors at different time instants. We set no restrictions on the maximum number of Byzantine agents at any given time. We design our method based on three layers of defense: 1) temporal robust aggregation, 2) spatial robust aggregation, and 3) gradient normalization. We study two settings for stochastic optimization, namely Sample Average Approximation and Stochastic Approximation. We provide convergence guarantees of our method for strongly convex and smooth non-convex cost functions.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "150048016",
                        "name": "Berkay Turan"
                    },
                    {
                        "authorId": "32030988",
                        "name": "C\u00e9sar A. Uribe"
                    },
                    {
                        "authorId": "2627442",
                        "name": "Hoi-To Wai"
                    },
                    {
                        "authorId": "1799995",
                        "name": "M. Alizadeh"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "3) PHuber-CE [41], which uses a composite loss-based gradient clipping, a variation of standard gradient clipping for label noise robustness.",
                "As the setting in F-correction, we first train a standard network to estimate the transition matrix Q. 3) PHuber-CE [41], which uses a composite loss-based gradient clipping, a variation of standard gradient clipping for label noise robustness.",
                "5) Some method apply regularization techniques to improve generalization under the settings of label noise [10, 23, 66], like gradient clipping [41], label smoothing [36, 57], temporal ensembling [28] and virtual adversarial training [42]."
            ],
            "citingPaper": {
                "paperId": "39ccbe81127e44bf3275b94d8b2311367d5c9548",
                "externalIds": {
                    "DBLP": "conf/nips/WeiTXA21",
                    "ArXiv": "2106.10891",
                    "CorpusId": 235490581
                },
                "corpusId": 235490581,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/39ccbe81127e44bf3275b94d8b2311367d5c9548",
                "title": "Open-set Label Noise Can Improve Robustness Against Inherent Label Noise",
                "abstract": "Learning with noisy labels is a practically challenging problem in weakly supervised learning. In the existing literature, open-set noises are always considered to be poisonous for generalization, similar to closed-set noises. In this paper, we empirically show that open-set noisy labels can be non-toxic and even benefit the robustness against inherent noisy labels. Inspired by the observations, we propose a simple yet effective regularization by introducing Open-set samples with Dynamic Noisy Labels (ODNL) into training. With ODNL, the extra capacity of the neural network can be largely consumed in a way that does not interfere with learning patterns from clean data. Through the lens of SGD noise, we show that the noises induced by our method are random-direction, conflict-free and biased, which may help the model converge to a flat minimum with superior stability and enforce the model to produce conservative predictions on Out-of-Distribution instances. Extensive experimental results on benchmark datasets with various types of noisy labels demonstrate that the proposed method not only enhances the performance of many existing robust algorithms but also achieves significant improvement on Out-of-Distribution detection tasks even in the label noise setting.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2115312735",
                        "name": "Hongxin Wei"
                    },
                    {
                        "authorId": "3023914",
                        "name": "Lue Tao"
                    },
                    {
                        "authorId": "1381430534",
                        "name": "Renchunzi Xie"
                    },
                    {
                        "authorId": "2057964623",
                        "name": "Bo An"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Successful recent approaches include correcting the loss for class or label noise, such as [32, 39, 56] (and references therein).",
                "The approaches in [2, 4, 6, 13, 31, 32, 36, 39, 53, 60, 61, 62] share a higher-level technical commonality: they alter the loss via its surrogate."
            ],
            "citingPaper": {
                "paperId": "d6d644cf70e9175a1fc991276eb6c4601cc618cc",
                "externalIds": {
                    "DBLP": "conf/icml/SypherdNS22",
                    "ArXiv": "2106.09920",
                    "CorpusId": 235485480
                },
                "corpusId": 235485480,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/d6d644cf70e9175a1fc991276eb6c4601cc618cc",
                "title": "Being Properly Improper",
                "abstract": "Properness for supervised losses stipulates that the loss function shapes the learning algorithm towards the true posterior of the data generating distribution. Unfortunately, data in modern machine learning can be corrupted or twisted in many ways. Hence, optimizing a proper loss function on twisted data could perilously lead the learning algorithm towards the twisted posterior, rather than to the desired clean posterior. Many papers cope with specific twists (e.g., label/feature/adversarial noise), but there is a growing need for a uni-fied and actionable understanding atop properness. Our chief theoretical contribution is a generalization of the properness framework with a notion called twist-properness , which delineates loss functions with the ability to \u201cuntwist\u201d the twisted posterior into the clean posterior. No-tably, we show that a nontrivial extension of a loss function called \u03b1 -loss, which was first introduced in information theory, is twist-proper. We study the twist-proper \u03b1 -loss under a novel boosting algorithm, called P IL B OOST , and provide formal and experimental results for this algorithm. Our overarching practical conclusion is that the twist-proper \u03b1 -loss outperforms the proper log -loss on several variants of twisted data.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1718786",
                        "name": "R. Nock"
                    },
                    {
                        "authorId": "72454076",
                        "name": "Tyler Sypherd"
                    },
                    {
                        "authorId": "144711127",
                        "name": "L. Sankar"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "the APL losses is approximated to that of the Bayes classifier (learned using supervised data) [43, 44, 45, 46].",
                "Table 1: Bounds of multi-class losses, including the mean absolute error (MAE) loss, the mean square error (MSE) loss, the reverse cross entropy (RCE) loss [67], the generalized cross entropy (GCE) loss, the partially Huberised cross entropy (PCE) loss [46], the categorical cross entropy (CCE) loss, and the focal loss (FL) [68].",
                "Constructing robust losses from the perspective of the objective function is a powerful means in weakly supervised learning [43, 44, 46]."
            ],
            "citingPaper": {
                "paperId": "aa5dd26a54758db0b0f83c1932f3d6778a37488f",
                "externalIds": {
                    "ArXiv": "2106.06152",
                    "DBLP": "journals/corr/abs-2106-06152",
                    "DOI": "10.1109/TPAMI.2023.3275249",
                    "CorpusId": 235417144,
                    "PubMed": "37167048"
                },
                "corpusId": 235417144,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/aa5dd26a54758db0b0f83c1932f3d6778a37488f",
                "title": "On the Robustness of Average Losses for Partial-Label Learning",
                "abstract": "Partial-label learning\u00a0(PLL) utilizes instances with PLs, where a PL includes several candidate labels but only one is the true label (TL). In PLL, identification-based strategy\u00a0(IBS) purifies each PL on the fly to select the (most likely) TL for training; average-based strategy\u00a0(ABS) treats all candidate labels equally for training and let trained models be able to predict TL. Although PLL research has focused on IBS for better performance, ABS is also worthy of study since modern IBS behaves like ABS in the beginning of training to prepare for PL purification and TL selection. In this paper, we analyze why ABS was unsatisfactory and propose how to improve it. Theoretically, we propose two problem settings of PLL and prove that average PL losses\u00a0(APLLs) with bounded multi-class losses are always robust, while APLLs with unbounded losses may be non-robust, which is the first robustness analysis for PLL. Experimentally, we have two promising findings: ABS using bounded losses can match/exceed state-of-the-art performance of IBS using unbounded losses; after using robust APLLs to warm start, IBS can further improve upon itself. Our work draws attention to ABS research, which can in turn boost IBS and push forward the whole PLL.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "144798906",
                        "name": "Jiaqi Lv"
                    },
                    {
                        "authorId": "2117930471",
                        "name": "Lei Feng"
                    },
                    {
                        "authorId": "49235356",
                        "name": "Miao Xu"
                    },
                    {
                        "authorId": "2057964623",
                        "name": "Bo An"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    },
                    {
                        "authorId": "1735299",
                        "name": "Xin Geng"
                    },
                    {
                        "authorId": "67154907",
                        "name": "Masashi Sugiyama"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "To achieve this we focus on gradient clipping methods (Pascanu et al., 2013; Gehring et al., 2017; Menon et al., 2020; Mai and Johansson, 2021; Zhang et al., 2020a,b).",
                "To achieve this we focus on gradient clipping methods [31, 11, 24, 23, 41, 42].",
                "[24] Aditya Krishna Menon, Ankit Singh Rawat, Sashank J Reddi, and Sanjiv Kumar."
            ],
            "citingPaper": {
                "paperId": "8738d9226e80c40bb325b245b697299fe79394a3",
                "externalIds": {
                    "ArXiv": "2106.05958",
                    "DBLP": "journals/corr/abs-2106-05958",
                    "CorpusId": 235390662
                },
                "corpusId": 235390662,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8738d9226e80c40bb325b245b697299fe79394a3",
                "title": "Near-Optimal High Probability Complexity Bounds for Non-Smooth Stochastic Optimization with Heavy-Tailed Noise",
                "abstract": "Stochastic first-order methods are standard for training large-scale machine learning models. Random behavior may cause a particular run of an algorithm to result in a highly suboptimal objective value, whereas theoretical guarantees are usually proved for the expectation of the objective value. Thus, it is essential to theoretically guarantee that algorithms provide small objective residual with high probability. Existing methods for non-smooth stochastic convex optimization have complexity bounds with the dependence on the confidence level that is either negative-power or logarithmic but under an additional assumption of sub-Gaussian (light-tailed) noise distribution that may not hold in practice. In our paper, we resolve this issue and derive the first high-probability convergence results with logarithmic dependence on the confidence level for non-smooth convex stochastic optimization problems with non-sub-Gaussian (heavy-tailed) noise. To derive our results, we propose novel stepsize rules for two stochastic methods with gradient clipping. Moreover, our analysis works for generalized smooth objectives with H\u00f6lder-continuous gradients, and for both methods, we provide an extension for strongly convex problems. Finally, our results imply that the first (accelerated) method we consider also has optimal iteration and oracle complexity in all the regimes, and the second one is optimal in the non-smooth setting.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "144044688",
                        "name": "Eduard A. Gorbunov"
                    },
                    {
                        "authorId": "2065834337",
                        "name": "Marina Danilova"
                    },
                    {
                        "authorId": "1753624473",
                        "name": "Innokentiy Shibaev"
                    },
                    {
                        "authorId": "2960542",
                        "name": "P. Dvurechensky"
                    },
                    {
                        "authorId": "2663409",
                        "name": "A. Gasnikov"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "This approach has been pursued in a large body of work (Long & Servedio, 2008; Wang et al., 2019a; Liu & Guo, 2020; Lyu & Tsang, 2020; Menon et al., 2020; Feng et al., 2020) that embraces new losses, especially symmetric loss functions and their variants (Manwani & Sastry, 2013; van Rooyen et al.,\u2026",
                "This approach has been pursued in a large body of work (Long & Servedio, 2008; Wang et al., 2019a; Liu & Guo, 2020; Lyu & Tsang, 2020; Menon et al., 2020; Feng et al., 2020) that embraces new losses, especially symmetric loss functions and their variants (Manwani & Sastry, 2013; van Rooyen et al."
            ],
            "citingPaper": {
                "paperId": "9549b8784c0a664fd406e8178d300308b2b17ea7",
                "externalIds": {
                    "ArXiv": "2106.03110",
                    "DBLP": "journals/corr/abs-2106-03110",
                    "CorpusId": 235358312
                },
                "corpusId": 235358312,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/9549b8784c0a664fd406e8178d300308b2b17ea7",
                "title": "Asymmetric Loss Functions for Learning with Noisy Labels",
                "abstract": "Robust loss functions are essential for training deep neural networks with better generalization power in the presence of noisy labels. Symmetric loss functions are confirmed to be robust to label noise. However, the symmetric condition is overly restrictive. In this work, we propose a new class of loss functions, namely \\textit{asymmetric loss functions}, which are robust to learning with noisy labels for various types of noise. We investigate general theoretical properties of asymmetric loss functions, including classification calibration, excess risk bound, and noise tolerance. Meanwhile, we introduce the asymmetry ratio to measure the asymmetry of a loss function. The empirical results show that a higher ratio would provide better noise tolerance. Moreover, we modify several commonly-used loss functions and establish the necessary and sufficient conditions for them to be asymmetric. Experimental results on benchmark datasets demonstrate that asymmetric loss functions can outperform state-of-the-art methods. The code is available at \\href{https://github.com/hitcszx/ALFs}{https://github.com/hitcszx/ALFs}",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109520799",
                        "name": "Xiong Zhou"
                    },
                    {
                        "authorId": "2108681776",
                        "name": "Xianming Liu"
                    },
                    {
                        "authorId": "1708439",
                        "name": "Junjun Jiang"
                    },
                    {
                        "authorId": "2109103156",
                        "name": "Xin Gao"
                    },
                    {
                        "authorId": "7807689",
                        "name": "Xiangyang Ji"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Therefore, it is of great importance to achieve robust training against noisy labels [10, 9, 18, 39, 26]."
            ],
            "citingPaper": {
                "paperId": "b69e662169630957dd3698da0d80c0675020a443",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-00455",
                    "ArXiv": "2106.00455",
                    "CorpusId": 235265884
                },
                "corpusId": 235265884,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b69e662169630957dd3698da0d80c0675020a443",
                "title": "Instance Correction for Learning with Open-set Noisy Labels",
                "abstract": "The problem of open-set noisy labels denotes that part of training data have a different label space that does not contain the true class. Lots of approaches, e.g., loss correction and label correction, cannot handle such open-set noisy labels well, since they need training data and test data to share the same label space, which does not hold for learning with open-set noisy labels. The state-of-the-art methods thus employ the sample selection approach to handle open-set noisy labels, which tries to select clean data from noisy data for network parameters updates. The discarded data are seen to be mislabeled and do not participate in training. Such an approach is intuitive and reasonable at first glance. However, a natural question could be raised\"can such data only be discarded during training?\". In this paper, we show that the answer is no. Specifically, we discuss that the instances of discarded data could consist of some meaningful information for generalization. For this reason, we do not abandon such data, but use instance correction to modify the instances of the discarded data, which makes the predictions for the discarded data consistent with given labels. Instance correction are performed by targeted adversarial attacks. The corrected data are then exploited for training to help generalization. In addition to the analytical results, a series of empirical evidences are provided to justify our claims.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2077454998",
                        "name": "Xiaobo Xia"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    },
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "29393235",
                        "name": "Mingming Gong"
                    },
                    {
                        "authorId": "2117884081",
                        "name": "Jun Yu"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    },
                    {
                        "authorId": "67154907",
                        "name": "Masashi Sugiyama"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Class-conditional label noise Label noise is commonly treated as a class-conditional phenomenon, where the noisy labels are treated strictly as a function of the true label [54, 57, 72, 98, 33, 102, 51, 67, 58, 5, 11, 4, 3, 94, 100, 90, 104, 93]."
            ],
            "citingPaper": {
                "paperId": "3df83528144af411090b6cb4ed8cb48c10b1c4b5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2105-14083",
                    "ArXiv": "2105.14083",
                    "CorpusId": 235254694
                },
                "corpusId": 235254694,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3df83528144af411090b6cb4ed8cb48c10b1c4b5",
                "title": "Rethinking Noisy Label Models: Labeler-Dependent Noise with Adversarial Awareness",
                "abstract": "Most studies on learning from noisy labels rely on unrealistic models of i.i.d. label noise, such as class-conditional transition matrices. More recent work on instance-dependent noise models are more realistic, but assume a single generative process for label noise across the entire dataset. We propose a more principled model of label noise that generalizes instance-dependent noise to multiple labelers, based on the observation that modern datasets are typically annotated using distributed crowdsourcing methods. Under our labeler-dependent model, label noise manifests itself under two modalities: natural error of good-faith labelers, and adversarial labels provided by malicious actors. We present two adversarial attack vectors that more accurately reflect the label noise that may be encountered in real-world settings, and demonstrate that under our multimodal noisy labels model, state-of-the-art approaches for learning from noisy labels are defeated by adversarial label attacks. Finally, we propose a multi-stage, labeler-aware, model-agnostic framework that reliably filters noisy labels by leveraging knowledge about which data partitions were labeled by which labeler, and show that our proposed framework remains robust even in the presence of extreme adversarial label noise.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "40495705",
                        "name": "Glenn Dawson"
                    },
                    {
                        "authorId": "1780024",
                        "name": "R. Polikar"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "7361fb6993f06ef5bff34e234cf06fe9f2b1bb00",
                "externalIds": {
                    "ArXiv": "2105.13003",
                    "DBLP": "journals/corr/abs-2105-13003",
                    "DOI": "10.24963/ijcai.2022/348",
                    "CorpusId": 235212247
                },
                "corpusId": 235212247,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/7361fb6993f06ef5bff34e234cf06fe9f2b1bb00",
                "title": "Rethinking InfoNCE: How Many Negative Samples Do You Need?",
                "abstract": "InfoNCE is a widely used contrastive training loss. It aims to estimate the mutual information between a pair of variables by discriminating between each positive pair and its associated K negative pairs. It is proved that when the sample labels are clean, the lower bound of mutual information estimation is tighter when more negative samples are incorporated, which usually yields better model performance. However, in practice the labels often contain noise, and incorporating too many noisy negative samples into model training may be suboptimal. In this paper, we study how many negative samples are optimal for InfoNCE in different scenarios via a semi-quantitative theoretical framework. More specifically, we first propose a probabilistic model to analyze the influence of the negative sampling ratio K on training sample informativeness. Then, we design a training effectiveness function to measure the overall influence of training samples based on their informativeness. We estimate the optimal negative sampling ratio using the K value that maximizes the training effectiveness function. Based on our framework, we further propose an adaptive negative sampling method that can dynamically adjust the negative sampling ratio to improve InfoNCE-based model training. Extensive experiments in three different tasks show our framework can accurately predict the optimal negative sampling ratio, and various models can benefit from our adaptive negative sampling method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118839668",
                        "name": "Chuhan Wu"
                    },
                    {
                        "authorId": "2397264",
                        "name": "Fangzhao Wu"
                    },
                    {
                        "authorId": "1731776",
                        "name": "Yongfeng Huang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "1713c7932d374359724579c5777c4eb6d84909d3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-15055",
                    "ArXiv": "2103.15055",
                    "CorpusId": 232404537
                },
                "corpusId": 232404537,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1713c7932d374359724579c5777c4eb6d84909d3",
                "title": "Friends and Foes in Learning from Noisy Labels",
                "abstract": "Learning from examples with noisy labels has attracted increasing attention recently. But, this paper will show that the commonly used CIFAR-based datasets and the accuracy evaluation metric used in the literature are both inappropriate in this context. An alternative valid evaluation metric and new datasets are proposed in this paper to promote proper research and evaluation in this area. Then, friends and foes are identified from existing methods as technical components that are either beneficial or detrimental to deep learning from noisy labeled examples, respectively, and this paper improves and combines technical components from the friends category, including self-supervised learning, new warmup strategy, instance filtering and label correction. The resulting F&F method significantly outperforms existing methods on the proposed nCIFAR datasets and the real-world Clothing1M dataset.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2110191943",
                        "name": "Yifan Zhou"
                    },
                    {
                        "authorId": "48471328",
                        "name": "Yifan Ge"
                    },
                    {
                        "authorId": "1808816",
                        "name": "Jianxin Wu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "\u2026Mirzasoleiman et al., 2020, Wu et al., 2020, Chen et al., 2021] that selects training examples dynamically during training; training techniques [Menon et al., 2020, Liu et al., 2020] that are designed to increase robustness and avoid memorization of noisy labels; learning with rejection or\u2026"
            ],
            "citingPaper": {
                "paperId": "7cae037e059caf0d9a521593c45785d236756110",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-13569",
                    "ArXiv": "2103.13569",
                    "CorpusId": 232352896
                },
                "corpusId": 232352896,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7cae037e059caf0d9a521593c45785d236756110",
                "title": "Approximating Instance-Dependent Noise via Instance-Confidence Embedding",
                "abstract": "Label noise in multiclass classification is a major obstacle to the deployment of learning systems. However, unlike the widely used class-conditional noise (CCN) assumption that the noisy label is independent of the input feature given the true label, label noise in real-world datasets can be aleatory and heavily dependent on individual instances. In this work, we investigate the instance-dependent noise (IDN) model and propose an efficient approximation of IDN to capture the instance-specific label corruption. Concretely, noting the fact that most columns of the IDN transition matrix have only limited influence on the class-posterior estimation, we propose a variational approximation that uses a single-scalar confidence parameter. To cope with the situation where the mapping from the instance to its confidence value could vary significantly for two adjacent instances, we suggest using instance embedding that assigns a trainable parameter to each instance. The resulting instance-confidence embedding (ICE) method not only performs well under label noise but also can effectively detect ambiguous or mislabeled instances. We validate its utility on various image and text classification tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2108288126",
                        "name": "Yivan Zhang"
                    },
                    {
                        "authorId": "67154907",
                        "name": "Masashi Sugiyama"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Furthermore, many existing approaches are exclusively designed for classification problems (e.g., Malach & ShalevShwartz (2017); Reed et al. (2014); Menon et al. (2019); Zheng et al. (2020)); extending them to solving regression problems is not straightforward."
            ],
            "citingPaper": {
                "paperId": "54038835a02ccb0d8db27c6d13d279c1008c71fa",
                "externalIds": {
                    "DBLP": "conf/icml/LiuSWTZ21",
                    "ArXiv": "2102.06735",
                    "CorpusId": 231924588,
                    "PubMed": "35502317"
                },
                "corpusId": 231924588,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/54038835a02ccb0d8db27c6d13d279c1008c71fa",
                "title": "Learning Deep Neural Networks under Agnostic Corrupted Supervision",
                "abstract": "Training deep neural models in the presence of corrupted supervision is challenging as the corrupted data points may significantly impact the generalization performance. To alleviate this problem, we present an efficient robust algorithm that achieves strong guarantees without any assumption on the type of corruption, and provides a unified framework for both classification and regression problems. Unlike many existing approaches that quantify the quality of the data points (e.g., based on their individual loss values), and filter them accordingly, the proposed algorithm focuses on controlling the collective impact of data points on the average gradient. Even when a corrupted data point failed to be excluded by our algorithm, the data point will have very limited impact on the overall loss, as compared with state-of-the-art filtering methods based on loss values. Extensive experiments on multiple benchmark datasets have demonstrated the robustness of our algorithm under different types of corruptions.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "144281102",
                        "name": "Boyang Liu"
                    },
                    {
                        "authorId": "49632897",
                        "name": "Mengying Sun"
                    },
                    {
                        "authorId": "2119265388",
                        "name": "Ding Wang"
                    },
                    {
                        "authorId": "39900740",
                        "name": "P. Tan"
                    },
                    {
                        "authorId": "145487992",
                        "name": "Jiayu Zhou"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "2a067a78c83655b2f18561508f1a5f4054a6075f",
                "externalIds": {
                    "ArXiv": "2102.06062",
                    "DBLP": "conf/nips/GhaziGKMZ21",
                    "CorpusId": 231879976
                },
                "corpusId": 231879976,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2a067a78c83655b2f18561508f1a5f4054a6075f",
                "title": "Deep Learning with Label Differential Privacy",
                "abstract": "The Randomized Response (RR) algorithm is a classical technique to improve robustness in survey aggregation, and has been widely adopted in applications with differential privacy guarantees. We propose a novel algorithm, Randomized Response with Prior (RRWithPrior), which can provide more accurate results while maintaining the same level of privacy guaranteed by RR. We then apply RRWithPrior to learn neural networks with label differential privacy (LabelDP), and show that when only the label needs to be protected, the model performance can be significantly improved over the previous state-of-the-art private baselines. Moreover, we study different ways to obtain priors, which when used with RRWithPrior can additionally improve the model performance, further reducing the accuracy gap between private and non-private models. We complement the empirical results with theoretical analysis showing that LabelDP is provably easier than protecting both the inputs and labels.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2529354",
                        "name": "Badih Ghazi"
                    },
                    {
                        "authorId": "3348246",
                        "name": "Noah Golowich"
                    },
                    {
                        "authorId": "2109226273",
                        "name": "Ravi Kumar"
                    },
                    {
                        "authorId": "3022753",
                        "name": "Pasin Manurangsi"
                    },
                    {
                        "authorId": "151505981",
                        "name": "Chiyuan Zhang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Robust loss function: The literature has also observed the proposal of robust loss functions that perform well with dealing outlier noisy examples (Zhang & Sabuncu, 2018; Menon et al., 2019; Charoenphakdee et al., 2019; Wang et al., 2019)."
            ],
            "citingPaper": {
                "paperId": "f9b43f61504b20ad499e2af2fe7256034c7f5038",
                "externalIds": {
                    "ArXiv": "2102.05336",
                    "DBLP": "conf/icml/Liu21",
                    "CorpusId": 235667999
                },
                "corpusId": 235667999,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/f9b43f61504b20ad499e2af2fe7256034c7f5038",
                "title": "Understanding Instance-Level Label Noise: Disparate Impacts and Treatments",
                "abstract": "This paper aims to provide understandings for the effect of an over-parameterized model, e.g. a deep neural network, memorizing instance-dependent noisy labels. We first quantify the harms caused by memorizing noisy instances, and show the disparate impacts of noisy labels for sample instances with different representation frequencies. We then analyze how several popular solutions for learning with noisy labels mitigate this harm at the instance level. Our analysis reveals that existing approaches lead to disparate treatments when handling noisy instances. While higher-frequency instances often enjoy a high probability of an improvement by applying these solutions, lower-frequency instances do not. Our analysis reveals new understandings for when these approaches work, and provides theoretical justifications for previously reported empirical observations. This observation requires us to rethink the distribution of label noise across instances and calls for different treatments for instances in different regimes.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152799147",
                        "name": "Yang Liu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "e40f743e1dc087c717d6c3417f512665359171ab",
                "externalIds": {
                    "MAG": "3120475762",
                    "DBLP": "journals/corr/abs-2101-01178",
                    "ArXiv": "2101.01178",
                    "DOI": "10.5281/zenodo.4399748",
                    "CorpusId": 231581592
                },
                "corpusId": 231581592,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e40f743e1dc087c717d6c3417f512665359171ab",
                "title": "Advances in Electron Microscopy with Deep Learning",
                "abstract": "This doctoral thesis covers some of my advances in electron microscopy with deep learning. Highlights include a comprehensive review of deep learning in electron microscopy; large new electron microscopy datasets for machine learning, dataset search engines based on variational autoencoders, and automatic data clustering by t-distributed stochastic neighbour embedding; adaptive learning rate clipping to stabilize learning; generative adversarial networks for compressed sensing with spiral, uniformly spaced and other fixed sparse scan paths; recurrent neural networks trained to piecewise adapt sparse scan paths to specimens by reinforcement learning; improving signal-to-noise; and conditional generative adversarial networks for exit wavefunction reconstruction from single transmission electron micrographs. This thesis adds to my publications by presenting their relationships, reflections, and holistic conclusions. This version of my thesis is typeset for online dissemination to improve readability, whereas the thesis submitted to the University of Warwick in support of my application for the degree of Doctor of Philosophy in Physics is typeset for physical printing and binding.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51149606",
                        "name": "Jeffrey M. Ede"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Proposed methods range from robust loss functions [18], [19], [20], [21], or noise modeling [22], [23], [24], to sample selection [25], [26], [27], or re-weighting samples [28], [29].",
                "Regularization techniques [30], [31], [21] have also been shown to reduce the effect of label noise.",
                "We experiment with the partially Huberized cross-entropy loss [21], a more robust loss function, and the mixup regularization [35].",
                "In our work, we experiment with the partially Huberized cross-entropy loss [21] and the mixup regularization [35] to deal with the inherent noise of pseudo-labels."
            ],
            "citingPaper": {
                "paperId": "028080312edffd7946672130b75a8e5591c74aee",
                "externalIds": {
                    "DBLP": "conf/icra/JiaSHL21",
                    "MAG": "3110792502",
                    "ArXiv": "2012.08890",
                    "DOI": "10.1109/ICRA48506.2021.9561699",
                    "CorpusId": 229223806
                },
                "corpusId": 229223806,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/028080312edffd7946672130b75a8e5591c74aee",
                "title": "Self-Supervised Person Detection in 2D Range Data using a Calibrated Camera",
                "abstract": "Deep learning is the essential building block of state-of-the-art person detectors in 2D range data. However, only a few annotated datasets are available for training and testing these deep networks, potentially limiting their performance when deployed in new environments or with different LiDAR models. We propose a method, which uses bounding boxes from an image-based detector (e.g. Faster R-CNN) on a calibrated camera to automatically generate training labels (called pseudo-labels) for 2D LiDAR-based person detectors. Through experiments on the JackRabbot dataset with two detector models, DROW3 and DR-SPAAM, we show that self-supervised detectors, trained or fine-tuned with pseudolabels, outperform detectors trained only on a different dataset. Combined with robust training techniques, the self-supervised detectors reach a performance close to the ones trained using manual annotations of the target dataset. Our method is an effective way to improve person detectors during deployment without any additional labeling effort, and we release our source code to support relevant robotic applications.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2052778496",
                        "name": "Dan Jia"
                    },
                    {
                        "authorId": "2037857620",
                        "name": "Mats Steinweg"
                    },
                    {
                        "authorId": "36665147",
                        "name": "Alexander Hermans"
                    },
                    {
                        "authorId": "1789756",
                        "name": "B. Leibe"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Most existing works, for their theoretical analysis or noise synthesizing in experiments, follow the class-conditional noise (CCN) assumption (Scott, Blanchard, and Handy 2013; Zhang and Sabuncu 2018; Menon et al. 2020; Ma et al. 2020), where the label noise is independent of its input features conditional on the latent true label.",
                "\u2026analysis or noise synthesizing in experiments, follow the class-conditional noise (CCN) assumption (Scott, Blanchard, and Handy 2013; Zhang and Sabuncu 2018; Menon et al. 2020; Ma et al. 2020), where the label noise is independent of its input features conditional on the latent true label.",
                "\u2026as clearly stated in theoretical analysis (Blum and Mitchell 1998; Yan et al. 2017; Patrini et al. 2016; Zhang and Sabuncu 2018; Xu et al. 2019; Menon et al. 2020; Ma et al. 2020) or inexplicitly used in experiments for synthetizing noisy labels (Han et al. 2018b; Yu et al. 2019; Arazo et al.\u2026",
                "The CCN assumption is commonly used in previous works, as clearly stated in theoretical analysis (Blum and Mitchell 1998; Yan et al. 2017; Patrini et al. 2016; Zhang and Sabuncu 2018; Xu et al. 2019; Menon et al. 2020; Ma et al. 2020) or inexplicitly used in experiments for synthetizing noisy labels (Han et al."
            ],
            "citingPaper": {
                "paperId": "4945fb6bc967179b8d9a19e1b2f87a62720d79c7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2012-05458",
                    "ArXiv": "2012.05458",
                    "MAG": "3112685016",
                    "DOI": "10.1609/aaai.v35i13.17363",
                    "CorpusId": 228083495
                },
                "corpusId": 228083495,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/4945fb6bc967179b8d9a19e1b2f87a62720d79c7",
                "title": "Beyond Class-Conditional Assumption: A Primary Attempt to Combat Instance-Dependent Label Noise",
                "abstract": "Supervised learning under label noise has seen numerous advances recently, while existing theoretical findings and empirical results broadly build up on the class-conditional noise (CCN) assumption that the noise is independent of input features given the true label. In this work, we present a theoretical hypothesis testing and prove that noise in real-world dataset is unlikely to be CCN, which confirms that label noise should depend on the instance and justifies the urgent need to go beyond the CCN assumption.The theoretical results motivate us to study the more general and practical-relevant instance-dependent noise (IDN). To stimulate the development of theory and methodology on IDN, we formalize an algorithm to generate controllable IDN and present both theoretical and empirical evidence to show that IDN is semantically meaningful and challenging. As a primary attempt to combat IDN, we present a tiny algorithm termed self-evolution average label (SEAL), which not only stands out under IDN with various noise fractions, but also improves the generalization on real-world noise benchmark Clothing1M. Our code is released. Notably, our theoretical analysis in Section 2 provides rigorous motivations for studying IDN, which is an important topic that deserves more research attention in future.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2158171944",
                        "name": "Pengfei Chen"
                    },
                    {
                        "authorId": null,
                        "name": "Junjie Ye"
                    },
                    {
                        "authorId": "2653181",
                        "name": "Guangyong Chen"
                    },
                    {
                        "authorId": "1601191498",
                        "name": "Jingwei Zhao"
                    },
                    {
                        "authorId": "1714602",
                        "name": "P. Heng"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "One typical idea is to reduce the influence of noisy samples with carefully designed losses [35, 1, 52, 40, 44, 25, 14, 6] or regularization terms [20, 28, 23]."
            ],
            "citingPaper": {
                "paperId": "c388ec40b382ca85370dd758d28207542a971fd8",
                "externalIds": {
                    "MAG": "3102571367",
                    "DBLP": "conf/nips/WuZ0M020",
                    "ArXiv": "2012.04835",
                    "CorpusId": 227276541
                },
                "corpusId": 227276541,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/c388ec40b382ca85370dd758d28207542a971fd8",
                "title": "A Topological Filter for Learning with Label Noise",
                "abstract": "Noisy labels can impair the performance of deep neural networks. To tackle this problem, in this paper, we propose a new method for filtering label noise. Unlike most existing methods relying on the posterior probability of a noisy classifier, we focus on the much richer spatial behavior of data in the latent representational space. By leveraging the high-order topological information of data, we are able to collect most of the clean data and train a high-quality model. Theoretically we prove that this topological approach is guaranteed to collect the clean data with high probability. Empirical results show that our method outperforms the state-of-the-arts and is robust to a broad spectrum of noise types and levels.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2498892",
                        "name": "Pengxiang Wu"
                    },
                    {
                        "authorId": "48161623",
                        "name": "Songzhu Zheng"
                    },
                    {
                        "authorId": "2512248",
                        "name": "Mayank Goswami"
                    },
                    {
                        "authorId": "1711560",
                        "name": "Dimitris N. Metaxas"
                    },
                    {
                        "authorId": "2145762465",
                        "name": "Chao Chen"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "This is because the commonly used cross-entropy loss is known to be highly overconfident [27, 40].",
                "As the commonly used cross-entropy loss is known to be highly overconfident [27, 40], LossNet tends to produce polarized results, and high weights could be assigned to some noisy data."
            ],
            "citingPaper": {
                "paperId": "a298fd2bbad144a84adec7c2d4644764ad5f20a3",
                "externalIds": {
                    "ArXiv": "2012.05273",
                    "DBLP": "journals/corr/abs-2012-05273",
                    "MAG": "3112642831",
                    "CorpusId": 228083649
                },
                "corpusId": 228083649,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a298fd2bbad144a84adec7c2d4644764ad5f20a3",
                "title": "MetaInfoNet: Learning Task-Guided Information for Sample Reweighting",
                "abstract": "Deep neural networks have been shown to easily overfit to biased training data with label noise or class imbalance. Meta-learning algorithms are commonly designed to alleviate this issue in the form of sample reweighting, by learning a meta weighting network that takes training losses as inputs to generate sample weights. In this paper, we advocate that choosing proper inputs for the meta weighting network is crucial for desired sample weights in a specific task, while training loss is not always the correct answer. In view of this, we propose a novel meta-learning algorithm, MetaInfoNet, which automatically learns effective representations as inputs for the meta weighting network by emphasizing task-related information with an information bottleneck strategy. Extensive experimental results on benchmark datasets with label noise or class imbalance validate that MetaInfoNet is superior to many state-of-the-art methods.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2115312735",
                        "name": "Hongxin Wei"
                    },
                    {
                        "authorId": "2117930471",
                        "name": "Lei Feng"
                    },
                    {
                        "authorId": "103856029",
                        "name": "R. Wang"
                    },
                    {
                        "authorId": "143706343",
                        "name": "Bo An"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "99d86a078e6aacffa39489af93051c27f8432f10",
                "externalIds": {
                    "DBLP": "journals/pami/XiaHWDLML23",
                    "ArXiv": "2012.00932",
                    "MAG": "3110483780",
                    "DOI": "10.1109/TPAMI.2022.3180545",
                    "CorpusId": 227247878,
                    "PubMed": "35675234"
                },
                "corpusId": 227247878,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/99d86a078e6aacffa39489af93051c27f8432f10",
                "title": "Extended <inline-formula><tex-math notation=\"LaTeX\">$T$</tex-math><alternatives><mml:math><mml:mi>T</mml:mi></mml:math><inline-graphic xlink:href=\"xia-ieq1-3180545.gif\"/></alternatives></inline-formula>: Learning With Mixed Closed-Set and Open-Set Noisy Labels",
                "abstract": "The <italic>noise transition matrix</italic> <inline-formula><tex-math notation=\"LaTeX\">$T$</tex-math><alternatives><mml:math><mml:mi>T</mml:mi></mml:math><inline-graphic xlink:href=\"xia-ieq2-3180545.gif\"/></alternatives></inline-formula>, reflecting the probabilities that true labels flip into noisy ones, is of vital importance to model label noise and build statistically consistent classifiers. The traditional transition matrix is limited to model <italic>closed-set</italic> label noise, where noisy training data have true class labels <italic>within</italic> the noisy label set. It is unfitted to employ such a transition matrix to model <italic>open-set</italic> label noise, where some true class labels are <italic>outside</italic> the noisy label set. Therefore, when considering a more realistic situation, i.e., both closed-set and open-set label noises occur, prior works will give <italic>unbelievable</italic> solutions. Besides, the traditional transition matrix is mostly limited to model instance-independent label noise, which may not perform well in practice. In this paper, we focus on learning with the mixed closed-set and open-set noisy labels. We address the aforementioned issues by extending the traditional transition matrix to be able to model mixed label noise, and further to the cluster-dependent transition matrix to better combat the instance-dependent label noise in real-world applications. We term the proposed transition matrix as the cluster-dependent extended transition matrix. An unbiased estimator (i.e., extended <inline-formula><tex-math notation=\"LaTeX\">$T$</tex-math><alternatives><mml:math><mml:mi>T</mml:mi></mml:math><inline-graphic xlink:href=\"xia-ieq3-3180545.gif\"/></alternatives></inline-formula>-estimator) has been designed to estimate the cluster-dependent extended transition matrix by only exploiting the noisy data. Comprehensive experiments validate that our method can better cope with realistic label noise, following its more robust performance than the prior state-of-the-art label-noise learning methods.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2077454998",
                        "name": "Xiaobo Xia"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    },
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "2156503263",
                        "name": "Nannan Wang"
                    },
                    {
                        "authorId": "3234063",
                        "name": "Jiankang Deng"
                    },
                    {
                        "authorId": "2109018731",
                        "name": "Jiatong Li"
                    },
                    {
                        "authorId": "39704049",
                        "name": "Yinian Mao"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", sample selection [21, 29, 35, 51, 60, 67], label correction [22, 54, 56, 62, 66], and robustifying loss functions [8, 14, 32, 39, 42, 55, 71].",
                "Many approaches are proposed to modify or redesign them [18, 40, 42, 45, 69, 71]."
            ],
            "citingPaper": {
                "paperId": "e9d373a3b2b3a86c3666ace0e4b471b967e45fa3",
                "externalIds": {
                    "MAG": "3100689571",
                    "DBLP": "journals/corr/abs-2011-08145",
                    "CorpusId": 226965174
                },
                "corpusId": 226965174,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e9d373a3b2b3a86c3666ace0e4b471b967e45fa3",
                "title": "Decoupling Representation and Classifier for Noisy Label Learning",
                "abstract": "Since convolutional neural networks (ConvNets) can easily memorize noisy labels, which are ubiquitous in visual classification tasks, it has been a great challenge to train ConvNets against them robustly. Various solutions, e.g., sample selection, label correction, and robustifying loss functions, have been proposed for this challenge, and most of them stick to the end-to-end training of the representation (feature extractor) and classifier. In this paper, by a deep rethinking and careful re-examining on learning behaviors of the representation and classifier, we discover that the representation is much more fragile in the presence of noisy labels than the classifier. Thus, we are motivated to design a new method, i.e., REED, to leverage above discoveries to learn from noisy labels robustly. The proposed method contains three stages, i.e., obtaining the representation by self-supervised learning without any labels, transferring the noisy label learning problem into a semisupervised one by the classifier directly and reliably trained with noisy labels, and joint semi-supervised retraining of both the representation and classifier. Extensive experiments are performed on both synthetic and real benchmark datasets. Results demonstrate that the proposed method can beat the state-of-the-art ones by a large margin, especially under high noise level.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2178835859",
                        "name": "Hui Zhang"
                    },
                    {
                        "authorId": "3259992",
                        "name": "Quanming Yao"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "[35] mitigated the effects of label noise from an optimization lens, which naturally introduces the partially Huberised loss.",
                "[35] leverage gradient clipping to design a new loss.",
                "Their designs are based on different principles, such as gradient clipping [35] and curriculum learning [89].",
                "From the perspective of objective function, the focus is to derive the statistical consistency guarantees for robust  \u0303\u0300 [5], [35], [64]."
            ],
            "citingPaper": {
                "paperId": "8fdda881582d515315fed22d26a9793ce9862224",
                "externalIds": {
                    "MAG": "3103846556",
                    "DBLP": "journals/corr/abs-2011-04406",
                    "ArXiv": "2011.04406",
                    "CorpusId": 226282258
                },
                "corpusId": 226282258,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8fdda881582d515315fed22d26a9793ce9862224",
                "title": "A Survey of Label-noise Representation Learning: Past, Present and Future",
                "abstract": "Classical machine learning implicitly assumes that labels of the training data are sampled from a clean distribution, which can be too restrictive for real-world scenarios. However, statistical learning-based methods may not train deep learning models robustly with these noisy labels. Therefore, it is urgent to design Label-Noise Representation Learning (LNRL) methods for robustly training deep models with noisy labels. To fully understand LNRL, we conduct a survey study. We first clarify a formal definition for LNRL from the perspective of machine learning. Then, via the lens of learning theory and empirical study, we figure out why noisy labels affect deep models' performance. Based on the theoretical guidance, we categorize different LNRL methods into three directions. Under this unified taxonomy, we provide a thorough discussion of the pros and cons of different categories. More importantly, we summarize the essential components of robust LNRL, which can spark new directions. Lastly, we propose possible research directions within LNRL, such as new datasets, instance-dependent LNRL, and adversarial LNRL. Finally, we envision potential directions beyond LNRL, such as learning with feature-noise, preference-noise, domain-noise, similarity-noise, graph-noise, and demonstration-noise.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "3259992",
                        "name": "Quanming Yao"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    },
                    {
                        "authorId": "1807998",
                        "name": "I. Tsang"
                    },
                    {
                        "authorId": "145193332",
                        "name": "J. Kwok"
                    },
                    {
                        "authorId": "67154907",
                        "name": "Masashi Sugiyama"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[28] propose the partially Huberised cross entropy loss"
            ],
            "citingPaper": {
                "paperId": "0facaa62bd79007fff3ca4fcd22054f12b9e05d2",
                "externalIds": {
                    "MAG": "3095175122",
                    "DBLP": "conf/wacv/VoigtlaenderLYJ21",
                    "ArXiv": "2011.01142",
                    "DOI": "10.1109/WACV48630.2021.00310",
                    "CorpusId": 226236822
                },
                "corpusId": 226236822,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/0facaa62bd79007fff3ca4fcd22054f12b9e05d2",
                "title": "Reducing the Annotation Effort for Video Object Segmentation Datasets",
                "abstract": "For further progress in video object segmentation (VOS), larger, more diverse, and more challenging datasets will be necessary. However, densely labeling every frame with pixel masks does not scale to large datasets. We use a deep convolutional network to automatically create pseudo-labels on a pixel level from much cheaper bounding box annotations and investigate how far such pseudo-labels can carry us for training state-of-the-art VOS approaches. A very encouraging result of our study is that adding a manually annotated mask in only a single video frame for each object is sufficient to generate pseudo-labels which can be used to train a VOS method to reach almost the same performance level as when training with fully segmented videos. We use this workflow to create pixel pseudo-labels for the training set of the challenging tracking dataset TAO, and we manually annotate a subset of the validation set. Together, we obtain the new TAO-VOS benchmark, which we make publicly available at www.vision.rwth-aachen.de/page/taovos. While the performance of state-of-the-art methods on existing datasets starts to saturate, TAO-VOS remains very challenging for current algorithms and reveals their shortcomings.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2767859",
                        "name": "P. Voigtlaender"
                    },
                    {
                        "authorId": "79744009",
                        "name": "Lishu Luo"
                    },
                    {
                        "authorId": "2117729099",
                        "name": "C. Yuan"
                    },
                    {
                        "authorId": "2117937336",
                        "name": "Yong Jiang"
                    },
                    {
                        "authorId": "1789756",
                        "name": "B. Leibe"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "500ac8d556a9d283af7feea9da59f85d39272d21",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2010-02519",
                    "ArXiv": "2010.02519",
                    "MAG": "3101450190",
                    "CorpusId": 222140873
                },
                "corpusId": 222140873,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/500ac8d556a9d283af7feea9da59f85d39272d21",
                "title": "Improved Analysis of Clipping Algorithms for Non-convex Optimization",
                "abstract": "Gradient clipping is commonly used in training deep neural networks partly due to its practicability in relieving the exploding gradient problem. Recently, \\citet{zhang2019gradient} show that clipped (stochastic) Gradient Descent (GD) converges faster than vanilla GD/SGD via introducing a new assumption called $(L_0, L_1)$-smoothness, which characterizes the violent fluctuation of gradients typically encountered in deep neural networks. However, their iteration complexities on the problem-dependent parameters are rather pessimistic, and theoretical justification of clipping combined with other crucial techniques, e.g. momentum acceleration, are still lacking. In this paper, we bridge the gap by presenting a general framework to study the clipping algorithms, which also takes momentum methods into consideration. We provide convergence analysis of the framework in both deterministic and stochastic setting, and demonstrate the tightness of our results by comparing them with existing lower bounds. Our results imply that the efficiency of clipping methods will not degenerate even in highly non-smooth regions of the landscape. Experiments confirm the superiority of clipping-based methods in deep learning tasks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1988294358",
                        "name": "Bohang Zhang"
                    },
                    {
                        "authorId": "1988350912",
                        "name": "Jikai Jin"
                    },
                    {
                        "authorId": "47967033",
                        "name": "Cong Fang"
                    },
                    {
                        "authorId": "24952249",
                        "name": "Liwei Wang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "b00e89b4ede90904704dff6b64eed34384dfc083",
                "externalIds": {
                    "MAG": "3084979415",
                    "ArXiv": "2009.08328",
                    "DBLP": "journals/corr/abs-2009-08328",
                    "DOI": "10.1088/2632-2153/abd614",
                    "CorpusId": 221761447
                },
                "corpusId": 221761447,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b00e89b4ede90904704dff6b64eed34384dfc083",
                "title": "Deep learning in electron microscopy",
                "abstract": "Deep learning is transforming most areas of science and technology, including electron microscopy. This review paper offers a practical perspective aimed at developers with limited familiarity. For context, we review popular applications of deep learning in electron microscopy. Following, we discuss hardware and software needed to get started with deep learning and interface with electron microscopes. We then review neural network components, popular architectures, and their optimization. Finally, we discuss future directions of deep learning in electron microscopy.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "51149606",
                        "name": "Jeffrey M. Ede"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Though clipping the training gradient does not tighten the PAC-Bayes bound, Menon et al. (2020) prove that gradient clipping can accelerate training convergence when optimizing deep neural networks."
            ],
            "citingPaper": {
                "paperId": "bad3c8246aa2403fcb02d5825065f651368b203e",
                "externalIds": {
                    "MAG": "3049161099",
                    "DBLP": "journals/corr/abs-2008-06431",
                    "ArXiv": "2008.06431",
                    "CorpusId": 221136025
                },
                "corpusId": 221136025,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/bad3c8246aa2403fcb02d5825065f651368b203e",
                "title": "Efficient hyperparameter optimization by way of PAC-Bayes bound minimization",
                "abstract": "Identifying optimal values for a high-dimensional set of hyperparameters is a problem that has received growing attention given its importance to large-scale machine learning applications such as neural architecture search. Recently developed optimization methods can be used to select thousands or even millions of hyperparameters. Such methods often yield overfit models, however, leading to poor performance on unseen data. We argue that this overfitting results from using the standard hyperparameter optimization objective function. Here we present an alternative objective that is equivalent to a Probably Approximately Correct-Bayes (PAC-Bayes) bound on the expected out-of-sample error. We then devise an efficient gradient-based algorithm to minimize this objective; the proposed method has asymptotic space and time complexity equal to or better than other gradient-based hyperparameter optimization methods. We show that this new method significantly reduces out-of-sample error when applied to hyperparameter optimization problems known to be prone to overfitting.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1879342053",
                        "name": "John J. Cherian"
                    },
                    {
                        "authorId": "3121615",
                        "name": "Andrew G. Taube"
                    },
                    {
                        "authorId": "144431879",
                        "name": "R. McGibbon"
                    },
                    {
                        "authorId": "2897184",
                        "name": "Panagiotis Angelikopoulos"
                    },
                    {
                        "authorId": "38023684",
                        "name": "Guy Blanc"
                    },
                    {
                        "authorId": "11227436",
                        "name": "M. Snarski"
                    },
                    {
                        "authorId": "2061464149",
                        "name": "D. D. Richman"
                    },
                    {
                        "authorId": "2666962",
                        "name": "J. L. Klepeis"
                    },
                    {
                        "authorId": "2142424128",
                        "name": "D. Shaw"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Examples include semi-supervised learning [7, 4, 59, 64, 63, 47, 54, 5, 40], multi-instance learning [1, 79], positive-unlabeled learning [14, 15, 58, 30, 22, 9], complementary-label learning [33, 73, 34, 69, 11], noisy-label learning [56, 52, 62, 28, 72, 53, 45, 65, 70, 26, 66], positive-confidence learning [35], similar-unlabeled learning [2], and unlabeled-unlabeled learning [43, 44].",
                "[53] A."
            ],
            "citingPaper": {
                "paperId": "2a4e0101ad605a775f28ee66d7397cc2e57bf66b",
                "externalIds": {
                    "MAG": "3101114756",
                    "ArXiv": "2007.08929",
                    "DBLP": "journals/corr/abs-2007-08929",
                    "CorpusId": 220633053
                },
                "corpusId": 220633053,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2a4e0101ad605a775f28ee66d7397cc2e57bf66b",
                "title": "Provably Consistent Partial-Label Learning",
                "abstract": "Partial-label learning (PLL) is a multi-class classification problem, where each training example is associated with a set of candidate labels. Even though many practical PLL methods have been proposed in the last two decades, there lacks a theoretical understanding of the consistency of those methods-none of the PLL methods hitherto possesses a generation process of candidate label sets, and then it is still unclear why such a method works on a specific dataset and when it may fail given a different dataset. In this paper, we propose the first generation model of candidate label sets, and develop two novel PLL methods that are guaranteed to be provably consistent, i.e., one is risk-consistent and the other is classifier-consistent. Our methods are advantageous, since they are compatible with any deep network or stochastic optimizer. Furthermore, thanks to the generation model, we would be able to answer the two questions above by testing if the generation model matches given candidate label sets. Experiments on benchmark and real-world datasets validate the effectiveness of the proposed generation model and two PLL methods.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "47010134",
                        "name": "Lei Feng"
                    },
                    {
                        "authorId": "144798906",
                        "name": "Jiaqi Lv"
                    },
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "49235356",
                        "name": "Miao Xu"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    },
                    {
                        "authorId": "1735299",
                        "name": "Xin Geng"
                    },
                    {
                        "authorId": "2057964623",
                        "name": "Bo An"
                    },
                    {
                        "authorId": "67154907",
                        "name": "Masashi Sugiyama"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "(\u00a7 II IB ) Explicit Regularization Bilevel Learning [87] \u00a9 \u00a9 \u00a9 5 4 4 Official (TensorFlow)9 Annotator Confusion [86] \u00a9 5 \u00a9 \u00a9 4 4 Official (TensorFlow)10 Pre-training [88] \u00a9 5 \u00a9 \u00a9 4 4 Official (PyTorch)11 PHuber [89] \u00a9 \u00a9 \u00a9 \u00a9 4 4 Unofficial (PyTorch)12 Robust Early-learning [90] \u00a9 \u00a9 \u00a9 \u00a9 4 4 Official (PyTorch)13 ODLN [91] \u00a9 \u00a9 \u00a9 \u00a9 4 4 Official (PyTorch)14",
                "PHuber [89] proposes a composite loss-based gradient clipping, which is a variation of standard gradient clipping for label noise robustness."
            ],
            "citingPaper": {
                "paperId": "5ffe9b1d8219438f0343995ad3ea1a888e3d9f8e",
                "externalIds": {
                    "ArXiv": "2007.08199",
                    "DBLP": "journals/corr/abs-2007-08199",
                    "MAG": "3042609801",
                    "DOI": "10.1109/TNNLS.2022.3152527",
                    "CorpusId": 220546541,
                    "PubMed": "35254993"
                },
                "corpusId": 220546541,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5ffe9b1d8219438f0343995ad3ea1a888e3d9f8e",
                "title": "Learning from Noisy Labels with Deep Neural Networks: A Survey",
                "abstract": "Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "22656934",
                        "name": "Hwanjun Song"
                    },
                    {
                        "authorId": "2116505638",
                        "name": "Minseok Kim"
                    },
                    {
                        "authorId": "2122896649",
                        "name": "Dongmin Park"
                    },
                    {
                        "authorId": "2143422191",
                        "name": "Jae-Gil Lee"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", 2012; Zhang & Sabuncu, 2018) or gradient clipping (Menon et al., 2020).",
                "Losses can also be modified to address outliers by favoring small losses (Yu et al., 2012; Zhang & Sabuncu, 2018) or gradient clipping (Menon et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "1f6de95137e96872274eedae1beb1bd55f03c57a",
                "externalIds": {
                    "ArXiv": "2007.01162",
                    "MAG": "3040657859",
                    "DBLP": "journals/corr/abs-2007-01162",
                    "CorpusId": 220302148
                },
                "corpusId": 220302148,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/1f6de95137e96872274eedae1beb1bd55f03c57a",
                "title": "Tilted Empirical Risk Minimization",
                "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2118910109",
                        "name": "Tian Li"
                    },
                    {
                        "authorId": "1791052",
                        "name": "Ahmad Beirami"
                    },
                    {
                        "authorId": "2095979",
                        "name": "Maziar Sanjabi"
                    },
                    {
                        "authorId": "145260024",
                        "name": "Virginia Smith"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                ", 2020), which employs a joint loss function to select small-loss samples; PHuber-CE (Menon et al., 2020), which introduces gra-",
                "\u2026conduct experiments on Co-teaching (Han et al., 2018b), which is a representative algorithm of selecting reliable samples for training; JoCoR (Wei et al., 2020), which employs a joint loss function to select small-loss samples; PHuber-CE (Menon et al., 2020), which introduces gra-\nTable 2.",
                "Besides, we ex-\nternally conduct experiments on Co-teaching (Han et al., 2018b), which is a representative algorithm of selecting reliable samples for training; JoCoR (Wei et al., 2020), which employs a joint loss function to select small-loss samples; PHuber-CE (Menon et al., 2020), which introduces gra-\nTable 2.",
                "6\nCo-teaching 55.32\u00b10.28 51.09\u00b11.06 47.07\u00b10.83 55.29\u00b10.41 53.08\u00b10.26 45.63\u00b10.75 JoCor 52.21\u00b10.70 49.84\u00b10.92 48.83\u00b10.43 55.58\u00b10.27 49.35\u00b10.62 46.21\u00b10.73\nPHuber-CE 55.73\u00b10.38 54.33\u00b10.92 45.05\u00b10.49 56.76\u00b10.26 51.15\u00b10.65 41.59\u00b11.05 APL 56.91\u00b10.21 53.12\u00b11.21 43.60\u00b11.28 56.11\u00b10.23 50.93\u00b11.05 43.60\u00b11.28 S2E 57.93\u00b10.37 47.16\u00b11.32 28.53\u00b15.04 54.89\u00b11.92 50.42\u00b11.71 30.67\u00b13.12\nRevision 58.06\u00b10.19 52.30\u00b11.73 46.84\u00b11.09 56.41\u00b10.77 53.44\u00b10.83 43.77\u00b11.08\nReweight 53.34\u00b11.08 50.15\u00b11.33 44.73\u00b10.79 53.37\u00b10.66 49.82\u00b10.44 39.46\u00b11.27 Forward 57.30\u00b10.32 53.94\u00b10.42 46.91\u00b11.48 53.58\u00b10.54 49.90\u00b11.44 42.55\u00b13.81\nR-Class2Simi 58.67\u00b10.38 56.59\u00b10.74 50.48\u00b10.97 58.44\u00b10.66 55.03\u00b11.55 47.75\u00b12.17 F-Class2Simi 58.27\u00b10.47 56.70\u00b11.13 50.18\u00b10.89 58.46\u00b10.68 54.92\u00b11.66 46.07\u00b13.54\ndient clipping to mitigate the effects of noise; APL (Ma et al., 2020), which applies simple normalization on loss functions and makes them robust to noisy labels; S2E (Yao et al., 2020a), which properly controls the sample selection process so that deep networks can benefit from the memorization effect."
            ],
            "citingPaper": {
                "paperId": "e6d244f375cd72571d8c63a11a2b216734061c59",
                "externalIds": {
                    "DBLP": "conf/icml/WuXL0GWL021",
                    "ArXiv": "2006.07831",
                    "CorpusId": 235458469
                },
                "corpusId": 235458469,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/e6d244f375cd72571d8c63a11a2b216734061c59",
                "title": "Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels",
                "abstract": "Learning with noisy labels has attracted a lot of attention in recent years, where the mainstream approaches are in pointwise manners. Meanwhile, pairwise manners have shown great potential in supervised metric learning and unsupervised contrastive learning. Thus, a natural question is raised: does learning in a pairwise manner mitigate label noise? To give an affirmative answer, in this paper, we propose a framework called Class2Simi: it transforms data points with noisy class labels to data pairs with noisy similarity labels, where a similarity label denotes whether a pair shares the class label or not. Through this transformation, the reduction of the noise rate is theoretically guaranteed, and hence it is in principle easier to handle noisy similarity labels. Amazingly, DNNs that predict the clean class labels can be trained from noisy data pairs if they are first pretrained from noisy data points. Class2Simi is computationally efficient because not only this transformation is on-the-fly in mini-batches, but also it just changes loss computation on top of model prediction into a pairwise manner. Its effectiveness is verified by extensive experiments.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "4206933",
                        "name": "Songhua Wu"
                    },
                    {
                        "authorId": "2077454998",
                        "name": "Xiaobo Xia"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    },
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "29393235",
                        "name": "Mingming Gong"
                    },
                    {
                        "authorId": "2156503263",
                        "name": "Nannan Wang"
                    },
                    {
                        "authorId": "1410056390",
                        "name": "Haifeng Liu"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "The obtained method is known in literature as clipped-SGD (see [17, 21, 43, 44, 57, 70, 71] and references therein)."
            ],
            "citingPaper": {
                "paperId": "4cd92a56dca741190e453b4229eb9851abf6944c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2005-10785",
                    "MAG": "3026800838",
                    "ArXiv": "2005.10785",
                    "CorpusId": 218763151
                },
                "corpusId": 218763151,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/4cd92a56dca741190e453b4229eb9851abf6944c",
                "title": "Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping",
                "abstract": "In this paper, we propose a new accelerated stochastic first-order method called clipped-SSTM for smooth convex stochastic optimization with heavy-tailed distributed noise in stochastic gradients and derive the first high-probability complexity bounds for this method closing the gap in the theory of stochastic optimization with heavy-tailed noise. Our method is based on a special variant of accelerated Stochastic Gradient Descent (SGD) and clipping of stochastic gradients. We extend our method to the strongly convex case and prove new complexity bounds that outperform state-of-the-art results in this case. Finally, we extend our proof technique and derive the first non-trivial high-probability complexity bounds for SGD with clipping without light-tails assumption on the noise.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "144044688",
                        "name": "Eduard A. Gorbunov"
                    },
                    {
                        "authorId": "2065834337",
                        "name": "Marina Danilova"
                    },
                    {
                        "authorId": "2663409",
                        "name": "A. Gasnikov"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Indeed, label smoothing is conspicuously absent in most treatments of the noisy label problem (Patrini et al., 2016; Han et al., 2018b; Charoenphakdee et al., 2019; Thulasidasan et al., 2019; Amid et al., 2019; Menon et al., 2020).",
                "Further expanding such study, as done for gradient clipping (Menon et al., 2020), is also of interest."
            ],
            "citingPaper": {
                "paperId": "82c77a88969ac0e3a4e55c9a7dc5ced4afee0225",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2003-02819",
                    "ArXiv": "2003.02819",
                    "MAG": "3034432520",
                    "CorpusId": 212414865
                },
                "corpusId": 212414865,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/82c77a88969ac0e3a4e55c9a7dc5ced4afee0225",
                "title": "Does label smoothing mitigate label noise?",
                "abstract": "Label smoothing is commonly used in training deep learning models, wherein one-hot training labels are mixed with uniform label vectors. Empirically, smoothing has been shown to improve both predictive performance and model calibration. In this paper, we study whether label smoothing is also effective as a means of coping with label noise. While label smoothing apparently amplifies this problem --- being equivalent to injecting symmetric noise to the labels --- we show how it relates to a general family of loss-correction techniques from the label noise literature. Building on this connection, we show that label smoothing is competitive with loss-correction under label noise. Further, we show that when distilling models from noisy data, label smoothing of the teacher is beneficial; this is in contrast to recent findings for noise-free problems, and sheds further light on settings where label smoothing is beneficial.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2744849",
                        "name": "M. Lukasik"
                    },
                    {
                        "authorId": "1798880",
                        "name": "Srinadh Bhojanapalli"
                    },
                    {
                        "authorId": "2844480",
                        "name": "A. Menon"
                    },
                    {
                        "authorId": "49596260",
                        "name": "Surinder Kumar"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Another approach restricts information in gradients by clipping them (Menon et al., 2020) .",
                "Another approach\nrestricts information in gradients by clipping them (Menon et al., 2020) ."
            ],
            "citingPaper": {
                "paperId": "560c7437538dbadbb1e3e27e309945f2befd521f",
                "externalIds": {
                    "ArXiv": "2002.07933",
                    "DBLP": "conf/icml/HarutyunyanRSG20",
                    "MAG": "3035343530",
                    "CorpusId": 211171359
                },
                "corpusId": 211171359,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/560c7437538dbadbb1e3e27e309945f2befd521f",
                "title": "Improving Generalization by Controlling Label-Noise Information in Neural Network Weights",
                "abstract": "In the presence of noisy or incorrect labels, neural networks have the undesirable tendency to memorize information about the noise. Standard regularization techniques such as dropout, weight decay or data augmentation sometimes help, but do not prevent this behavior. If one considers neural network weights as random variables that depend on the data and stochasticity of training, the amount of memorized information can be quantified with the Shannon mutual information between weights and the vector of all training labels given inputs, $I(w : \\mathbf{y} \\mid \\mathbf{x})$. We show that for any training algorithm, low values of this term correspond to reduction in memorization of label-noise and better generalization bounds. To obtain these low values, we propose training algorithms that employ an auxiliary network that predicts gradients in the final layers of a classifier without accessing labels. We illustrate the effectiveness of our approach on versions of MNIST, CIFAR-10, and CIFAR-100 corrupted with various noise models, and on a large-scale dataset Clothing1M that has noisy labels.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "144787340",
                        "name": "Hrayr Harutyunyan"
                    },
                    {
                        "authorId": "3422961",
                        "name": "Kyle Reing"
                    },
                    {
                        "authorId": "1719898",
                        "name": "G. V. Steeg"
                    },
                    {
                        "authorId": "143728483",
                        "name": "A. Galstyan"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "e8f42e5ebbdcb187bef3774e9786326227332abb",
                "externalIds": {
                    "ACL": "2023.clasp-1.14",
                    "CorpusId": 261211338
                },
                "corpusId": 261211338,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e8f42e5ebbdcb187bef3774e9786326227332abb",
                "title": "UseClean: learning from complex noisy labels in named entity recognition",
                "abstract": "We investigate and refine denoising methods for NER task on data that potentially contains extremely noisy labels from multi-sources. In this paper, we first summarized all possible noise types and noise generation schemes, based on which we built a thorough evaluation system. We then pinpoint the bottleneck of current state-of-art denoising methods using our evaluation system. Correspondingly, we propose several refinements, including using a two-stage framework to avoid error accumulation; a novel confidence score utilizing minimal clean supervision to increase predictive power; an automatic cutoff fitting to save extensive hyper-parameter tuning; a warm started weighted partial CRF to better learn on the noisy tokens. Additionally, we propose to use adaptive sampling to further boost the performance in long-tailed entity settings. Our method improves F1 score by on average at least 5 10% over current state-of-art across extensive experiments.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "9509390",
                        "name": "Jinjin Tian"
                    },
                    {
                        "authorId": "1423651904",
                        "name": "Kun Zhou"
                    },
                    {
                        "authorId": "50469060",
                        "name": "Mei Wang"
                    },
                    {
                        "authorId": "49889909",
                        "name": "Yu Zhang"
                    },
                    {
                        "authorId": "2052408469",
                        "name": "Benjamin Yao"
                    },
                    {
                        "authorId": "8015600",
                        "name": "Xiaohu Liu"
                    },
                    {
                        "authorId": "1941997",
                        "name": "Chenlei Guo"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "c9a91230a7059860dfe95371bcf0ac72f4f3d060",
                "externalIds": {
                    "CorpusId": 261497471
                },
                "corpusId": 261497471,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c9a91230a7059860dfe95371bcf0ac72f4f3d060",
                "title": "Decision Layer: Enhancing Multi-model, Multi Timescale Decisions on the Fly with Online Feedback",
                "abstract": "Rogue actors employ sophisticated automation techniques to mimic human browsing/click patterns and generate invalid (i.e., fraudulent or robotic) traffic on retail marketplaces to artificially inflate their key performance metrics at the expense of their legitimate competitors. To maintain a clean and fair advertising system, it is essential to identify and mitigate ad traffic that is invalid, i.e., fraudulent or coerced or unintended, driven by bad actors and ensure that advertisers do not get charged for invalid traffic (IVT). One major challenge for advertising systems is the absence of complete ground truth fraud labels, even in limited amounts, which makes it challenging to build one single overarching model for comprehensive IVT detection. This generally results in a suite of models, each trying to identify some specific bot modus operandi. While this approach has been beneficial to offer more robust protection to advertisers by catching a variety of bots, it also piled up potentially millions of dollars of lost revenue opportunities, with each algorithm contributing incrementally to false positive detection (i.e., incorrect removal of valid traffic). Hence, we propose to build a \u201cmodel over models\u201d that learns to maintain true IVT coverage of ad fraud detection system while simultaneously lowering the cost of false positives. In this paper, we present a few variations for the new system, trained with incomplete labels that are either high quality but delayed in availability or low quality but available faster. Our proposed online algorithm combines the best of both worlds. It continuously adapts to not only reduce false positive cost by a massive 37% (owing to strong delayed labels), but also to rapidly mitigate revenue loss spikes (owing to weak fast labels) associated with occasional IVT detection system failure scenarios. To this end, we show that the online algorithm has sub-linear regret.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2237567221",
                        "name": "Meet Gandhi"
                    },
                    {
                        "authorId": "89091368",
                        "name": "Agniva Som"
                    },
                    {
                        "authorId": "2237560999",
                        "name": "Suraj Satishkumar Sheth"
                    },
                    {
                        "authorId": "2237607368",
                        "name": "Amrita Singh"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "(4) PHuber-CE [36], a loss variant of gradient clipping for learning with noisy labels.",
                "For PHuber-CE,\nwe set \u03c4 = 10 for CIFAR-10 and \u03c4 = 30 for CIFAR-100 and WebVision.",
                "They instead proposed a noise-robust variant, composite loss-based gradient clipping and the resulting partially Huberised loss (PHuber-CE).",
                "The results in Section 4 have shown that LogitClip not only outperforms but also enhances the performance of PHuber-CE loss.",
                "Indeed, recent work [36] has shown that gradient clipping alone does not endow label noise robustness to neural networks.",
                "Partial Huberised Cross Entropy (PHuber-CE) [36] enhances the noise robustness of CE with a loss variant of gradient clipping.",
                "More importantly, we show that LogitClip can boost the performance of a wide range of popular robust loss functions, including MAE [12], PHuber-CE [36], SCE [49], GCE [62], Taylor-CE [11], NCE [34], AEL, AUL [64], Cores [8], and Active Passive losses [34]."
            ],
            "citingPaper": {
                "paperId": "9502c57d93075da44c708328706ab62dc77e361f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-04055",
                    "DOI": "10.48550/arXiv.2212.04055",
                    "CorpusId": 254409038
                },
                "corpusId": 254409038,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/9502c57d93075da44c708328706ab62dc77e361f",
                "title": "Logit Clipping for Robust Learning against Label Noise",
                "abstract": "In the presence of noisy labels, designing robust loss functions is critical for securing the generalization performance of deep neural networks. Cross Entropy (CE) loss has been shown to be not robust to noisy labels due to its unboundedness . To alleviate this issue, existing works typically design specialized robust losses with the symmetric condition, which usually lead to the under\ufb01tting issue. In this paper, our key idea is to induce a loss bound at the logit level, thus universally enhancing the noise robustness of existing losses. Speci\ufb01cally, we propose logit clipping ( LogitClip ), which clamps the norm of the logit vector to ensure that it is upper bounded by a constant. In this manner, CE loss equipped with our LogitClip method is e\ufb00ectively bounded, mitigating the over\ufb01tting to examples with noisy labels. Moreover, we present theoretical analyses to certify the noise-tolerant ability of LogitClip. Extensive experiments show that LogitClip not only signi\ufb01cantly improves the noise robustness of CE loss, but also broadly enhances the generalization performance of popular robust losses.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115312735",
                        "name": "Hongxin Wei"
                    },
                    {
                        "authorId": "8841273",
                        "name": "Huiping Zhuang"
                    },
                    {
                        "authorId": "1381430534",
                        "name": "Renchunzi Xie"
                    },
                    {
                        "authorId": "47010134",
                        "name": "Lei Feng"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    },
                    {
                        "authorId": "2057964623",
                        "name": "Bo An"
                    },
                    {
                        "authorId": "1527103472",
                        "name": "Yixuan Li"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "(7)\nHence,\nE [ e2i ] = (\u03c3tf ) 2\n12 \u2225\u2225\u2225\u2225 \u2207\u03b8if S \u2225\u2225\u2225\u2225 2\n2\n,E [eiej ]= (\u03c3tf ) 2\n12 (\u2207\u03b8if S )T \u2207\u03b8jf S (8)\nPerspective 1: Menon et al. (2019) propose not overly trusting any single sample to help mitigate the label noise effect."
            ],
            "citingPaper": {
                "paperId": "a34473d8b505e6714bab4a8e92bd05f46223f2d7",
                "externalIds": {
                    "ACL": "2022.emnlp-main.515",
                    "DBLP": "conf/emnlp/WuDTZ0022",
                    "DOI": "10.18653/v1/2022.emnlp-main.515",
                    "CorpusId": 256461354
                },
                "corpusId": 256461354,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/a34473d8b505e6714bab4a8e92bd05f46223f2d7",
                "title": "STGN: an Implicit Regularization Method for Learning with Noisy Labels in Natural Language Processing",
                "abstract": "Noisy labels are ubiquitous in natural language processing (NLP) tasks. Existing work, namely learning with noisy labels in NLP, is often limited to dedicated tasks or specific training procedures, making it hard to be widely used. To address this issue, SGD noise has been explored to provide a more general way to alleviate the effect of noisy labels by involving benign noise in the process of stochastic gradient descent. However, previous studies exert identical perturbation for all samples, which may cause overfitting on incorrect ones or optimizing correct ones inadequately. To facilitate this, we propose a novel stochastic tailor-made gradient noise (STGN), mitigating the effect of inherent label noise by introducing tailor-made benign noise for each sample. Specifically, we investigate multiple principles to precisely and stably discriminate correct samples from incorrect ones and thus apply different intensities of perturbation to them. A detailed theoretical analysis shows that STGN has good properties, beneficial for model generalization. Experiments on three different NLP tasks demonstrate the effectiveness and versatility of STGN. Also, STGN can boost existing robust training methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2182653324",
                        "name": "Tingting Wu"
                    },
                    {
                        "authorId": "2117434160",
                        "name": "Xiao Ding"
                    },
                    {
                        "authorId": "2203912523",
                        "name": "Minji Tang"
                    },
                    {
                        "authorId": "40479003",
                        "name": "Hao Zhang"
                    },
                    {
                        "authorId": "152277111",
                        "name": "Bing Qin"
                    },
                    {
                        "authorId": "2140034231",
                        "name": "Ting Liu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                ", 2014), temporal ensembling (Laine & Aila, 2017), gradient clipping (Pascanu et al., 2012; Zhang et al., 2019; Menon et al., 2020) and label smoothing (Szegedy et al.",
                "Moreover, preventing overconfidence can mitigate overfitting on noisy labels (Menon et al., 2020; Lukasik et al., 2020).",
                "On CIFAR-10 and CIFAR-100, we compare with the following baselines: 1) standard crossentropy (CE) loss, 2) Generalized Cross-Entropy (GCE) (Zhang & Sabuncu, 2018) loss, 3) CoTeaching (Han et al., 2018b) that uses co-training and sample selection, 4) PHuber-CE (Menon et al., 2020) that uses gradient clipping and 5) label-smoothing (LS) Lukasik et al. (2020) that clips the label to be less confident before training.",
                "6) Chen et al. (2019b); Menon et al. (2020); Hu et al. (2020); Harutyunyan et al. (2020); Lukasik et al. (2020) apply regularization techniques to improve generalization under label noise, including explicit regularizations such as manifold regularization (Belkin et al., 2006) and virtual\u2026",
                "\u2026and virtual adversarial training (Miyato et al., 2018), and implicit regularizations such as dropout (Srivastava et al., 2014), temporal ensembling (Laine & Aila, 2017), gradient clipping (Pascanu et al., 2012; Zhang et al., 2019; Menon et al., 2020) and label smoothing (Szegedy et al., 2016).",
                ", 2018b) that uses co-training and sample selection, 4) PHuber-CE (Menon et al., 2020) that uses gradient clipping and 5) label-smoothing (LS) Lukasik et al.",
                "\u2026Cross-Entropy (GCE) (Zhang & Sabuncu, 2018) loss, 3) CoTeaching (Han et al., 2018b) that uses co-training and sample selection, 4) PHuber-CE (Menon et al., 2020) that uses gradient clipping and 5) label-smoothing (LS) Lukasik et al. (2020) that clips the label to be less confident before\u2026",
                "\u2022 PHuber-CE (Menon et al., 2020).",
                "The original paper (Menon et al., 2020) uses \u03c4 = 2 on CIFAR-10 and \u03c4 = 10 on CIFAR-100, but the default setting does not work well in our experiments."
            ],
            "citingPaper": {
                "paperId": "29891cba979efd7a5a332f2210a3a9aa5192a805",
                "externalIds": {
                    "DBLP": "conf/iclr/ChenCYZH21",
                    "CorpusId": 235614316
                },
                "corpusId": 235614316,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/29891cba979efd7a5a332f2210a3a9aa5192a805",
                "title": "Noise against noise: stochastic label noise helps combat inherent label noise",
                "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect, previously studied in optimization by analyzing the dynamics of parameter updates. In this paper, we are interested in learning with noisy labels, where we have a collection of samples with potential mislabeling. We show that a previously rarely discussed SGD noise, induced by stochastic label noise (SLN), mitigates the effects of inherent label noise. In contrast, the common SGD noise directly applied to model parameters does not. We formalize the differences and connections of SGD noise variants, showing that SLN induces SGD noise dependent on the sharpness of output landscape and the con\ufb01dence of output probability, which may help escape from sharp minima and prevent overcon\ufb01dence. SLN not only improves generalization in its simplest form but also boosts popular robust training methods, including sample selection and label correction. Speci\ufb01cally, we present an enhanced algorithm by applying SLN to label correction. Our code is released 1 .",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2158171944",
                        "name": "Pengfei Chen"
                    },
                    {
                        "authorId": "2653181",
                        "name": "Guangyong Chen"
                    },
                    {
                        "authorId": null,
                        "name": "Junjie Ye"
                    },
                    {
                        "authorId": "1601191498",
                        "name": "Jingwei Zhao"
                    },
                    {
                        "authorId": "1714602",
                        "name": "P. Heng"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "As an optimization method, we used Adam [49] with an initial learning rate of 0.001, linearly decreasing to zero from 80 epochs to 200 epochs, a momentum of 0.9, and a batch size of 128.",
                "As an optimization method, we used Adam [49] with an initial learning rate of 0."
            ],
            "citingPaper": {
                "paperId": "cdc9a763b951f9edb2ba490b9ae92d1a922e3c0f",
                "externalIds": {
                    "DBLP": "journals/access/TakedaYM21",
                    "DOI": "10.1109/ACCESS.2021.3119582",
                    "CorpusId": 240002445
                },
                "corpusId": 240002445,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/cdc9a763b951f9edb2ba490b9ae92d1a922e3c0f",
                "title": "Training Robust Deep Neural Networks on Noisy Labels Using Adaptive Sample Selection with Disagreement",
                "abstract": "Learning with noisy labels is one of the most practical but challenging tasks in deep learning. One promising way to treat noisy labels is to use the small-loss trick based on the memorization effect, that is, clean and noisy samples are identified by observing the network\u2019s loss during training. Co-teaching+ is a state-of-the-art method that simultaneously trains two networks with small-loss selection using the \u201cupdate by disagreement\u201d strategy; however, it suffers from the problem that the selected samples tend to become noisy as the number of iterations increases. This phenomenon means that clean small-loss samples will be biased toward agreement data, which is the set of samples for which the two networks have the same prediction. This paper proposes an adaptive sample selection method to train deep neural networks robustly and prevent noise contamination in the disagreement strategy. Specifically, the proposed method calculates the threshold of the small-loss criterion by considering the loss distribution of the whole batch at each iteration. Then, the network is backpropagated by extracting samples below this threshold from the disagreement data. Combining the disagreement and agreement data of the two networks can suppress the degradation of the true-label rate of training data in a mini batch. Experiments were conducted using five commonly used benchmarks, MNIST, CIFAR-10, CIFAR-100, NEWS, and T-ImageNet to verify the robustness of the proposed method to noisy labels. The results show the proposed method improves generalization performance in an image classification task with simulated noise rates of up to 50%.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2052440651",
                        "name": "Hiroshi Takeda"
                    },
                    {
                        "authorId": "20173740",
                        "name": "Soh Yoshida"
                    },
                    {
                        "authorId": "144096118",
                        "name": "M. Muneyasu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Label smoothing has demonstrated its benefits in improving learning representation M\u00fcller et al. (2019). A recent paper Lukasik et al.",
                "Robust loss function: The literature has also observed the proposal of robust loss functions that perform well with dealing outlier noisy examples Zhang & Sabuncu (2018); Amid et al. (2019); Menon et al. (2019); Charoenphakdee et al. (2019); Wang et al. (2019)."
            ],
            "citingPaper": {
                "paperId": "16b5267a51cd6355e27d9bd4f4947391b828cde7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-05336",
                    "CorpusId": 231861406
                },
                "corpusId": 231861406,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/16b5267a51cd6355e27d9bd4f4947391b828cde7",
                "title": "The importance of understanding instance-level noisy labels",
                "abstract": "This paper aims to provide understandings for the effect of an over-parameterized model, e.g. a deep neural network, memorizing instance-dependent noisy labels. We first quantify the harms caused by memorizing noisy instances from different spectra of the sample distribution. We then analyze how several popular solutions for learning with noisy labels mitigate this harm at the instance-level. Our analysis reveals new understandings for when these approaches work, and provides theoretical justifications for previously reported empirical observations. A key aspect of the analysis is its focus on each training instance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152799147",
                        "name": "Yang Liu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "For more information on Huberised losses, we kindly refer to the original paper (Menon et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "2b558dcd85c86113fbe6781bbc8f5d758cee2b95",
                "externalIds": {
                    "CorpusId": 235409670
                },
                "corpusId": 235409670,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2b558dcd85c86113fbe6781bbc8f5d758cee2b95",
                "title": "[Re] Can gradient clipping mitigate label noise?",
                "abstract": "All the experiments described in the paper were fully re-implemented using NumPy, SciPy and PyTorch. The experiments on synthetic data were run on a CPU, while the deep learning experiments were run using a Nvidia RTX 2080 Ti GPU. Running the experimentationnecessary to gain some insight on someof the network architectures used and reproducing the real-world experiments required over 550 GPU hours.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2111623708",
                        "name": "David Mizrahi"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Successful recent approaches include correcting the loss for class or label noise, such as [32, 39, 56] (and references therein).",
                "The approaches in [2, 4, 6, 13, 31, 32, 36, 39, 53, 60, 61, 62] share a higher-level technical commonality: they alter the loss via its surrogate."
            ],
            "citingPaper": {
                "paperId": "2bb5bbb38cf43481d5bfb570b06102b7f5da9a80",
                "externalIds": {
                    "CorpusId": 235632839
                },
                "corpusId": 235632839,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2bb5bbb38cf43481d5bfb570b06102b7f5da9a80",
                "title": "L G ] 1 8 Ju n 20 21 Being Properly Improper",
                "abstract": "In today\u2019s ML, data can be twisted (changed) in various ways, either for bad or good intent. Such twisted data challenges the founding theory of properness for supervised losses which form the basis for many popular losses for class probability estimation. Unfortunately, at its core, properness ensures that the optimal models also learn the twist. In this paper, we analyse such class probability-based losses when they are stripped off the mandatory properness; we define twist-proper losses as losses formally able to retrieve the optimum (untwisted) estimate off the twists, and show that a natural extension of a half-century old loss introduced by S. Arimoto is twist proper. We then turn to a theory that has provided some of the best off-the-shelf algorithms for proper losses, boosting. Boosting can require access to the derivative of the convex conjugate of a loss to compute examples weights. Such a function can be hard to get, for computational or mathematical reasons; this turns out to be the case for Arimoto\u2019s loss. We bypass this difficulty by inverting the problem as follows: suppose a blueprint boosting algorithm is implemented with a general weight update function. What are the losses for which boosting-compliant minimisation happens? Our answer comes as a general boosting algorithm which meets the optimal boosting dependence on the number of calls to the weak learner; when applied to Arimoto\u2019s loss, it leads to a simple optimisation algorithm whose performances are showcased on several domains and twists.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1718786",
                        "name": "R. Nock"
                    },
                    {
                        "authorId": "72454076",
                        "name": "Tyler Sypherd"
                    },
                    {
                        "authorId": "144711127",
                        "name": "L. Sankar"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "d04310656f74ee4829dea6ee501cfb0f191cde3b",
                "externalIds": {
                    "CorpusId": 259839728
                },
                "corpusId": 259839728,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d04310656f74ee4829dea6ee501cfb0f191cde3b",
                "title": "U NDERSTANDING S HARPNESS -A WARE M INIMIZATION",
                "abstract": "Sharpness-Aware Minimization (SAM) is a recent training method that relies on worst-case weight perturbations. SAM significantly improves generalization in various settings, however, existing justifications for its success do not seem conclusive. First, we analyze the implicit bias of SAM over diagonal linear networks, and prove that it always chooses a solution that enjoys better generalisation properties than standard gradient descent. We also provide a convergence proof of SAM for non-convex objectives when used with stochastic gradients and empirically discuss the convergence and generalization behavior of SAM for deep networks. Next, we discuss why SAM can be helpful in the noisy label setting where we first show that it can help to improve generalization even for linear classifiers. Then we discuss a gradient reweighting interpretation of SAM and show a further beneficial effect of combining SAM with a robust loss. Finally, we draw parallels between overfitting observed in learning with noisy labels and in adversarial training where SAM also improves generalization. This connection suggests that, more generally, techniques from the noisy label literature can be useful to improve robust generalization.",
                "year": 2021,
                "authors": []
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "\u2022 Partially Huberised Cross Entropy (PHuber-CE) (Menon et al., 2020):\nLPHuber-CEpfpxq, yq \u201c \" \u00b4 log p\u03b8py|xq, if p\u03b8py|xq \u011b 1\u03c4 , \u00b4\u03c4p\u03b8py|xq ` log \u03c4 ` 1, else,\nwhere \u03c4 \u0105 0 is a user-defined hyper-parameter.",
                "We set \u03c4 \u201c 10, because it works well in Menon et al. (2020).",
                "We also use an unbounded loss CCE and four bounded losses MAE, MSE, GCE (Zhang & Sabuncu, 2018), and PHuberCE (Menon et al., 2020) in our empirical estimator Eq.",
                "\u2022 Partially Huberised Cross Entropy (PHuber-CE) (Menon et al., 2020):"
            ],
            "citingPaper": {
                "paperId": "b7d2055781cdfb210540cedba020f3cbfcf323fc",
                "externalIds": {
                    "MAG": "2998301463",
                    "DBLP": "conf/icml/FengK000S20",
                    "ArXiv": "1912.12927",
                    "CorpusId": 209515346
                },
                "corpusId": 209515346,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b7d2055781cdfb210540cedba020f3cbfcf323fc",
                "title": "Learning with Multiple Complementary Labels",
                "abstract": "A complementary label (CL) simply indicates an incorrect class of an example, but learning with CLs results in multi-class classifiers that can predict the correct class. Unfortunately, the problem setting only allows a single CL for each example, which notably limits its potential since our labelers may easily identify multiple CLs (MCLs) to one example. In this paper, we propose a novel problem setting to allow MCLs for each example and two ways for learning with MCLs. In the first way, we design two wrappers that decompose MCLs into many single CLs, so that we could use any method for learning with CLs. However, the supervision information that MCLs hold is conceptually diluted after decomposition. Thus, in the second way, we derive an unbiased risk estimator; minimizing it processes each set of MCLs as a whole and possesses an estimation error bound. We further improve the second way into minimizing properly chosen upper bounds. Experiments show that the former way works well for learning with MCLs but the latter is even better.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2117930471",
                        "name": "Lei Feng"
                    },
                    {
                        "authorId": "68973934",
                        "name": "Takuo Kaneko"
                    },
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "47537639",
                        "name": "Gang Niu"
                    },
                    {
                        "authorId": "143706343",
                        "name": "Bo An"
                    },
                    {
                        "authorId": "67154907",
                        "name": "Masashi Sugiyama"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "f98c62212916d49c849e259c3a495fd4705398a6",
                "externalIds": {
                    "MAG": "3047604421",
                    "CorpusId": 219571071
                },
                "corpusId": 219571071,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f98c62212916d49c849e259c3a495fd4705398a6",
                "title": "Label Noise Reduction Without Assumptions",
                "abstract": "We propose an algorithm for training neural networks in noisy label scenarios that up-weighs per-example gradients that are more similar to other gradients in the same minibatch. Our approach makes no assumptions about the amount or type of label noise, does not use a held-out validation set of clean examples, makes relatively few computations, and only modi\ufb01es the minibatch gradient aggregation module in a typical neural network training work\ufb02ow. For CIFAR-10 classi\ufb01cation with varying levels of label noise, our method suc-cessfully up-weighs clean examples and de-prioritizes noisy examples, showing consistent improvement over a vanilla training baseline. Our results open the door to potential future work involving per-example gradient comparisons.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "144026731",
                        "name": "Jason Wei"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Common strategies include loss correction and reweighting (Patrini et al., 2016; Zhang & Sabuncu, 2018; Menon et al., 2020), label refurbishment (Reed et al., 2014; Song et al., 2019), abstention (Thulasidasan et al., 2019), and relying on carefully constructed trusted subsets of human-verified\u2026",
                "Common strategies include loss correction and reweighting (Patrini et al., 2016; Zhang & Sabuncu, 2018; Menon et al., 2020), label refurbishment (Reed et al."
            ],
            "citingPaper": {
                "paperId": "28f0a2defdf3fb8f7be31929691e120613c03dee",
                "externalIds": {
                    "CorpusId": 236907864
                },
                "corpusId": 236907864,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/28f0a2defdf3fb8f7be31929691e120613c03dee",
                "title": "ROBUST TEMPORAL ENSEMBLING",
                "abstract": "Successful training of deep neural networks with noisy labels is an essential capability as most real-world datasets contain some amount of mislabeled data. Left unmitigated, label noise can sharply degrade typical supervised learning approaches. In this paper, we present robust temporal ensembling (RTE), a simple supervised learning approach which combines robust task loss, temporal pseudolabeling, and a ensemble consistency regularization term to achieve noise-robust learning. We demonstrate that RTE achieves state-of-the-art performance across the CIFAR-10, CIFAR-100, and ImageNet datasets, while forgoing the recent trend of label filtering/fixing. In particular, RTE achieves 93.64% accuracy on CIFAR-10 and 66.43% accuracy on CIFAR-100 under 80% label corruption, and achieves 74.79% accuracy on ImageNet under 40% corruption. These are substantial gains over previous state-of-the-art accuracies of 86.6%, 60.2%, and 71.31%, respectively, achieved using three distinct methods. Finally, we show that RTE retains competitive corruption robustness to unforeseen input noise using CIFAR10-C, obtaining a mean corruption error (mCE) of 13.50% even in the presence of an 80% noise ratio, versus 26.9% mCE with standard methods on clean data.",
                "year": 2020,
                "authors": []
            }
        }
    ]
}