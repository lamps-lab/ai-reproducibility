text,target_M6_predict,target_predict_M6_label
"Moreover, enforcing strict consistency for exponential family models p and q, is a severe restriction, leading to a joint m, which collapses to an EF-Harmonium (Shekhovtsov et al., 2022).",1,neutral
"However, in practice, determining such a form is often infeasible [41].",1,neutral
"The ELBO optimization is a well known method which was deeply investigated, and is applicable in many models, mainly in VAE [8].",1,neutral
Minimizing the KL divergence is equivalent to maximizing the Evidence Lower Bound (ELBO) [8].,1,neutral
"Most of the insightful points focus on more complex target posterior distributions, leading to an increase in the complexity of the model and the computational burden of model training [27].",1,neutral
"Unfortunately, VAE's generation process needs to make assumptions about the distribution space of latent variables, which will cause the approximation error [24-27].",1,neutral
"(Shekhovtsov et al., 2022) demonstrated the relationship between model consistency and posterior collapse and suggested that a proper choice of data processing or architecture may alleviate collapse.",1,neutral
"For VAEs there are several lines of work in this respect which investigate ELBO optimization (Hoffman and Johnson, 2016; Mescheder et al., 2017; Dai et al., 2018; Lucas et al., 2019; Shekhovtsov et al., 2022).",1,neutral
"It has been shown that flexible and invertible transformation g(Â·) can overcome this issue [41, 7].",1,neutral
"If the decoder and encoder are from an exponential family, the simple affine mapping is enough to ensure the encoder and decoder consistency for any exponential distribution [41] and ELBO maximization forces themodel to be simple.",1,neutral
"Other notable VAE analysis work pointed out by reviewers includes (Damm et al., 2023; Shekhovtsov et al., 2022; Zietlow et al., 2021).",2,positive
"Unfortunately, it also causes the approximation error of VAE since the generation process needs to make assumptions about the distribution space of latent variables [24],[25],[26],[27].",1,neutral
"Most of the highlights focus on more complex target posterior distributions, leading to an increase in the complexity of the model and the computational burden of model training [27].",1,neutral
