text,target_M6_predict,target_predict_M6_label
"In the works of [8, 20, 27, 36, 38, 46], a table is depicted as a grid of regions.",1,neutral
"For instance, region-based methods [8, 20, 36, 38, 46] employ a split model to divide input table images into a grid of regions, and a merge model to combine over-split spanning cells.",1,neutral
"TabStructNet [36] combines table element detection and vertex relationship prediction into a single network, providing an end-to-end solution.",2,positive
"[16, 25, 35, 36, 47] represent tables by a group of cells.",1,neutral
"Note that, there are fundamental differences between the representation in [8, 20, 36, 38, 46] and ours despite the representation is also termed as ""grid"".",1,neutral
"Several studies have proposed detectors for detecting cells or their contents [28,31,30,49].",1,neutral
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",0,negative
Raja et al.[34]6 2020 TabStruct Net ECCV SciTSR UNLV X X NR,2,positive
TabStruct-Net [7] proposed an end-to-end network to detect cells and predict cell relations jointly.,2,positive
"Some recent works [7, 8, 12] have proposed a modified TEDS metric named TEDS-Struct to evaluate table structure recognition accuracy only by ignoring OCR errors.",1,neutral
"To bypass this problem, the second group of methods [7, 8, 12, 45, 46] detects the bounding boxes of table cells directly and uses different methods to group them into rows and columns.",1,neutral
"Also based on DGCNN, TabStructNet [36] is proposed for end-to-end training cell detection and structure recognition in a joint manner.",2,positive
"With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",1,neutral
"Similar to [36], we randomly extract 80% of the data for training and others for testing.",2,positive
"the filed, which can be mainly categorized into boundary extraction-based methods [38, 31, 15, 41, 25] and element relationship-based methods [23, 4, 34, 36] according to the component type leveraged.",2,positive
"The first group are the single component-based methods, which rely on either boundary extraction [15, 25, 31, 38, 41] or element relationship [4, 23, 34, 36].",1,neutral
"To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in",1,neutral
"In recent years, inspired by the success of deep learning in various tasks, especially object detection and semantic segmentation, many deep learning-based methods (Raja et al., 2020; Schreiber et al., 2017) have been presented to recognize table structures.",1,neutral
"Sachin et al. (Raja et al., 2020) presented a table structure recognizer named TabStruct-Net that combines cell detection and interaction modules to localize the cells and predicts their row and column associations with other detected cells.",2,positive
"(Raja et al., 2020) presented a table structure recognizer named TabStruct-Net that combines cell detection and interaction modules to localize the cells and predicts their row and column associations with other detected cells.",2,positive
"(Raja et al., 2020; Schreiber et al., 2017) have been presented to recognize table structures.",1,neutral
21 PubTabNet TabStructNet [37] SciTSR 90.,2,positive
TableStructNet [37] and FLAG-NET [24] both utilized Mask R-CNN [13] network to obtain the region of cells and cell visual features.,1,neutral
"To eliminate this assumption, another group of methods [25, 24] proposed to detect the bounding boxes of table cells directly.",1,neutral
"Due to the rapid development of deep learning in documents, many deep learning-based TSR approaches [37, 3, 35, 25] have been presented.",1,neutral
"Following this work, there are models devoted to improving the relationship classification by using elaborated neural networks and adding multi-modal features (Qasim, Mahmood, and Shafait 2019; Raja, Mondal, and Jawahar 2020, 2022; Liu et al. 2021, 2022).",2,positive
"It should be noted that ICDAR-2013 provides no training data, so we extend it to the partial version for cross validation following previous works (Raja, Mondal, and Jawahar 2020; Liu et al. 2022, 2021).",0,negative
"Then we compare LORE with models mining the adjacency of cells by relation-based metrics: TabStrNet (Raja, Mondal, and Jawahar 2020), LGPMA (Qiao et al. 2021), TOD (Raja, Mondal, and Jawahar 2022), FLAGNet (Liu et al. 2021) and NCGM (Liu et al. 2022).",2,positive
"We also report the performance of cell spatial location prediction, using the F-1 score under the IoU threshold of 0.5, following recent works (Raja, Mondal, and Jawahar 2020; Xue et al. 2021).",2,positive
"56 million, while the method in reference [22] uses the Resnet101 [10] network, and the parameter amount reaches 44.",2,positive
"Several deep learning-based methods and datasets from the literature (TabStructNet [17], TableNet [14], CDeCNet [1], UNLV [19], DeepDeSRT [18], TableBank [11], PubTabNet [23], ICDAR 2013 Table Competition [9], DeepFigures [20], PubLayNet [24]) explore solutions to table detection and table structure recognition tasks.",2,positive
GTE [39] PubTabNet-train PubTabNet-test 93.,0,negative
S Raja [116] describes a method for recognizing table structure that combines cell detection and interaction modules to locate the cells and forecast their relationships with other detected cells in terms of row and column.,1,neutral
S Raja [116] Mask R-CNN + ResNet-101 based Net 1) An additional alignment loss is suggested for precise cell detection.,1,neutral
S Raja [121] suggests a novel object-detection-based deep model that is tailored for quick optimization and captures the natural alignments of cells inside tables.,1,neutral
com/doc-analysis/TableBank S Raja S Raja [116] TabStructNet 2020 tensorflow https://github.,2,positive
S Raja[116] ICDAR2013 Object Detection Methods Precision 92.,1,neutral
"[12] proposed to use deep learning [13], [14] to identify the structure information of the table and extract the structure of the table through the text box in the cell, but this method has limitations in dealing with some complex cells.",1,neutral
[21] usedMask R-CNNwith ResNet-101 as a backbone network.,2,positive
"[33], approaches table structure detection as a relationship problem between the row and column of the detected cell.",1,neutral
"Some recent works [(Raja, Mondal, and Jawahar 2020), (Qiao et al. 2021), (Zheng et al. 2021)] have proposed a modified TEDS metric named TEDS-Struct to
evaluate table structure recognition accuracy only by ignoring OCR errors.",2,positive
"According to the underlying alignment information in the table, [38, 46, 47] aim to obtain more accurate aligned cells which can be effectively used to infer the final structure.",1,neutral
"2% among all published methods for this widely studied dataset, TabStruct-Net [18] has low TEDs because it cannot handle the problem of unlined tables.",2,positive
TabStruct-Net [18] first detects individual cells and then links them to get table structure by graphs.,1,neutral
"As the table shows, the TRUST achieves the best Structure TEDs 97.1% and TEDs 96.2% among all published methods for this widely studied dataset, TabStruct-Net [18] has low TEDs because it cannot handle the problem of unlined tables.",2,positive
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc.",2,positive
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc. Unlike many state-of-the-art methods that perform evaluations only at TEDs, our method also test the Structure TEDs on PubTabNet.",2,positive
"Table detection [25,26], structure recognition [20,24] and extraction [9,30] in DLA gathered some special attention in recent years due to the high variability of layouts that make the both necessary to be solved and challenging to be tackled.",1,neutral
"Although the mentioned methods made progress toward understanding complex structured tables, several assumptions were made, such as that accurate word bounding boxes were available and that accurate document text could be used as additional inputs [66].",1,neutral
"Certain relational understanding tasks already play the important role in building electronic archives and developing office automation, which include table structure recognition [24,25,27,31,33],",1,neutral
"Now mainstream relational understanding tasks like table structure recognition [24, 25, 27, 31, 33], key information extraction [16, 17, 46] and reading order detection [37] are born with entitylevel.",1,neutral
"Some recent works [8, 22, 23] have proposed a modified TEDS metric, denoted as TEDS-Struct, to evaluate table structure recognition accuracy only by ignoring OCR errors.",1,neutral
"To eliminate this assumption, another group of methods [8, 22, 23] proposed to detect the bounding boxes of",1,neutral
[22] introduced a novel loss function that modeled the inherent alignment of cells in the cell detection,1,neutral
"Net [22] and LGPMA [23], typically use CNNbased object detection or segmentation models like Mask R-CNN to detect table cells first, then adopt some cell grouping/clustering algorithms to predict row/column relationships between the detected cells.",1,neutral
"Notably, the experimental results of Tabby, GraphTSR, DeepDeSRT on the ICDAR2013, SciTSR and SciTSR-COMP dataset come from the study [3], and the results of TableStrucNet and Split+Heur are from study [22].",2,positive
TableStrucNet [22] considers two experiment settings in their work.,1,neutral
"Document Intelligence can be considered as an umbrella term covering problems of Key Information Extraction [10,54], Table Detection [41,38] and Structure Recognition [39,55], Document Layout Segmentation [5,4] Document Layout Generation [6,36,3,48], Document Visual Question Answering [51,50,32], Document Image Enhancement [49,22,47] which involves the understanding of visually rich semantic information and structure of different layout entities of a whole page.",1,neutral
"We use four existing recognizers —ocr [26], equation descriptor [19], table recognizer [23], and figure classifier [12] to recognize content from the segmented regions.",2,positive
We use TabStruct-Net [23] to recognize the physical structure of the table and then Tesseract [26] to recognize content.,2,positive
"The success of DL has marked the revisiting of table structure parsing by [7], which inspired follow-up research [27, 1, 6, 2, 28, 29, 30, 19, 31, 18, 32, 17].",1,neutral
"In some best performing frameworks [17, 18, 19], they all jointly optimize the structure detection and entity relations in the structure, as in DocParser.",1,neutral
"We see from the previous works, the most effective methods [17, 18, 19] always jointly optimize the cell locations and cell relationships.",1,neutral
"In order to visualize predicted structures, we have drawn blue cell boxes that belong to the same column and row to the selected red cells as [25].",1,neutral
[25] also attempted to remove heuristics.,0,negative
"TabStructNet [25] detected cell-level bounding boxes, not content-level bounding boxes.",2,positive
"of parameters CascadeTabNet [23] 82,852,033 TabStructNet [25] 68,636,098 SPLERGE [32] 255,862 Ours 1,120,692",0,negative
"Some authors attempted to replace the heuristics with machinelearning methods [24, 25].",1,neutral
"8 Examples of qualitative results on complex tables, the colored regions are the recognized cell regions: Table structure recognition results of (a) CascadeTabNet  [23], (b) TabStructNet  [25], (c) SPLERGE [32], and (d) the proposed method",1,neutral
"We compare the performance of our method with three coventional methods: CascadeTabNet [23], TabStructNet [25], and SPLERGE [32].",2,positive
"Results of CascadeTabNet [23], TabStructNet [25], SPLERGE [32], and the proposed method, from top to bottom 5844 Multimedia Tools and Applications (2022) 81:5827–5848",2,positive
"(a) Result from CascadeTabNet [23], (b) TabStructNet [25] with ground truth table locations, (c) SPLERGE [32] with ground truth table locations, and (d) result from the proposed method 5845 Multimedia Tools and Applications (2022) 81:5827–5848",2,positive
"Therefore, recent methods [2, 30, 34] attempt to attack the problem via constructing visual cues of table elements as graphs and applying the deep graph model, such as Graph Convolutional Networks (GCN) [15] to reason their relationships.",1,neutral
"Compared with “DGCNN”, although “Transformer” can deploy the global information of nodes, it ignores the directed edge effects between nodes.",2,positive
"With the development of deep learning, table structure recognition methods have recently advanced substantially on performance, which can be classified into three categories: boundary extractionbased [13, 22, 27, 35, 40], generative model-based [18, 46], and graph-based [2, 20, 30, 34] methods.",1,neutral
"For comparison, we also visualize
the multi-head self-attention maps from the last blocks of “Transformer-Mixed” [42] and KNN (K = 5) selection heatmaps of all layers in DGCNN [30], where a lighter color indicates a closer relationship.",1,neutral
The method [30] introduces DGCNN to predict the relationship between words represented by the appearance and geometry features.,1,neutral
"For “DGCNN”, it only aggregates information from top K similar nodes of each node instead of all ones.",1,neutral
"Although many previous algorithms [2,13,18,20,22,30,31,34,35,40,45,46] have achieved impressive progress in the community, TSR is still a challenging task due to two factors of complicated tables.",1,neutral
"To compare in a unified protocol, we follow two different experimental setups in [34]: (a) SetupA where only table image is taken as input without additional information and (b) Setup-B where table image along with additional features such as cell/text segment bounding boxes and text contents.",2,positive
"Also based on DGCNN, TabStruct-Net [34] proposes an end-to-end network training cell detection and structure recognition networks in a joint manner.",2,positive
"It should be noted that there is no training set in ICDAR-2013 and UNLV datasets, so we extend the two datasets to the partial versions, which is similar to TabStruct-Net [34].",2,positive
"Table structure recognition (TSR) aims to recognize the table internal structure to the machine readable data mainly presented in two formats: logical structure [18, 46] and physical structure [2, 13, 20, 22, 27, 30, 31, 34, 35, 40, 45].",1,neutral
"The KNN results of DGCNN show that the feature aggregation of one node only pays attention to the top K similar features of other nodes instead of all the nodes, and relies on the choice of K.",1,neutral
"In the similar spirit with works [30, 34], we adopt the following asymmetric edge function hΘ(xi,xj) = xi∥(xi − xj) to combine graph edge features to each node, which can be denoted as HΘ ∈ R ·(N−1)/2)×d .",1,neutral
"To introduce richer table information, several methods [20, 30, 34] con-",1,neutral
"Besides, the DGCNN-based methods apply CNN to perform local context aggregation.",1,neutral
"In previous works using DGCNN [30, 34], only local context of each node is selected by k-Nearest Neighbors algorithm (KNN) to be aggregated into node feature.",1,neutral
"3 compares the effectiveness of various extractors, including DGCNN [30] and Transformer [42], with ECE in our method.",2,positive
"Contrarily, the TabStruct-Net [24] does not make any such assumptions and produces adjacency relations and cell locality information as the output.",1,neutral
• Introduce channel attention [19] for table object detection and define two additional regularizers — continuity and overlapping loss between every pair of cells in addition to the alignment loss from [24].,1,neutral
"Our formulation uses rectilinear adjacencies instead of row/column adjacencies [22, 24].",2,positive
"Table structure recognition generates a machine-interpretable output for a given table image, which encodes its layout according to a pre-defined standard [30, 17, 20, 42, 4, 39, 24].",1,neutral
"Not taking them into account might lead to false negatives and, in-turn, incorrect structure [24].",1,neutral
"Recently, many researchers have opted for a graph-based formulation of the problem as a graph is inherently an ideal data structure to model associations between entities [22, 4, 24].",1,neutral
"We further observe that empty cells account for an average of 12.3% across UNLV and ICDAR-2013 datasets, where our method outperforms TabStruct-Net by 4.2% F1 score.",0,negative
"Inspired by human cognition, we say that table cells, in addition to completely encapsulating their content, should adhere to alignment [24], continuity and non-overlapping constraints, which in-turn makes it easier to locate table columns and rows as independent objects.",1,neutral
"In order to compare our method against others on TUCD dataset, we develop our implementation of DeepDeSRT [26], and use open source implementations of DGCNN (TIES) [22], SPLERGE [30], and TabStruct-Net [24].",2,positive
"Cognitive methods in this space broadly classified into five categories — image-to-sequence models [17, 2, 14], segmentation networks [26, 18, 20, 23], graph formulations [22, 4, 24], conditional generative adversarial networks [16] and a recent multi-modal method by [40].",1,neutral
Raja [24] proposed a first end-to-end object detection and graph based model for collective cells detection and structure recognition.,1,neutral
"To detect table cells, we propose TOD-Net, where we augment the cell detection network of TabStruct-Net [24] with additional loss components to further improve the table object performance (rows/columns/cells) detection.",2,positive
"4(c) shows our method can well handle the table including non-gridded cells, which may cause the “cell boundary ambiguity” problem to the cell detection-based methods [29, 31, 43].",2,positive
"Furthermore, some methods [2, 19, 28, 31] attempt to construct the graphs of elements to reason the relationships.",1,neutral
"Different from previousworks [29, 31, 43], we adopt word bounding boxes rather than cells as table elements to avoid cell boundary ambiguity issue.",1,neutral
"Similar to previous works [28, 31] using DGCNN, only k nearest neighbours of each node are selected by k-Nearest Neighbors algorithm (KNN) to construct the local context which is applied by the CNN to aggregate the edge information into node feature Di ∈ RN× d h for i-th head.",1,neutral
inference speed than the method [31] greedily employing large number of proposals with redundancy to model their relationships.,1,neutral
"To overcome this issue, Raja et al. [31] propose TabStruct-Net, which predicts the aligned cell regions and the localized cell relations in a joint manner.",1,neutral
"[31] propose TabStruct-Net, which predicts the aligned cell regions and the localized cell relations in a joint manner.",1,neutral
"For the relational reasoning aspect, recent mainstream algorithms [2, 19, 28, 31] construct table elements as contextual graphs and apply the graph-based aggregator, such as Graph Convolutional Networks (GCN) [14], to reason their relationships.",1,neutral
"To solve this problem, we randomly extract 80% of the data for training and others for testing, which is similar to [31].",2,positive
"While on both ICDAR-2019 and UNLV, the F1 score of our approach can overtake that of TabStruct-Net as much as 4%.",0,negative
"Although methods [29, 31, 43] achieve performance improvement by directly predicting cell boxes, they may suffer from “cell boundary ambiguity” problem, especially on those blank or non-gridded cell cases.",1,neutral
"In addition, our model is only trained on the training set of SciTSR for a fair comparison with TabStruct-Net [31].",2,positive
"Compared with the strong baseline TabStruct-Net [31] greedily exploiting large numbers of proposals (round 2,000), our proposed FLAG-Net can achieve marginally better performance with less parameters and computational consumption, which thanks to the proposal filtering mechanism in our method.",2,positive
"For a more practical requirement of parsing table structures from images taken by hand-held cameras in the wild, the existing state-of-the-art approaches [13, 14, 11, 16, 9, 23] are prone to fail as the commonly-used assumption of tabular images no longer holds.",1,neutral
"However, these methods mainly focuses on the well-conditioned document images, where the tables [16, 23, 12, 9, 23, 14] are well-aligned to the image axes.",1,neutral
"For instance, the non-rigid image deformation and complicated image background presented in natural images will challenge existing approaches [14] for document images on detecting and grouping the tabular cells.",1,neutral
"…for tabular data, as corrupt cell detection is actually a fundamental task in table structure decomposition pipelines such as (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicted row/column separators or cell boundaries can lead to corrupted cell text.",1,neutral
"…of corrupt cell detection, which again is practically useful as a postprocessing step after table structure decomposition (Tensmeyer et al., 2019; Raja et al., 2020) because mistakes in predicting row/column/cell boundaries (sometimes compounded by OCR errors) can lead to inaccurate extraction.",1,neutral
"While this objective was originally motivated as enabling more efficient training compared to BERT’s masked language modeling objective, it is especially suited for tabular data, as corrupt cell detection is actually a fundamental task in table structure decomposition pipelines such as (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicted row/column separators or cell boundaries can lead to corrupted cell text.",1,neutral
"We emphasize that this pretraining objective is a fundamental task in table structure decomposition pipelines (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicting row/column separators or cell boundaries leads to corrupted cell text.",1,neutral
"We first examine how TaBERT performs on TABBIE’s pretraining task of corrupt cell detection, which again is practically useful as a postprocessing step after table structure decomposition (Tensmeyer et al., 2019; Raja et al., 2020) because mistakes in predicting row/column/cell boundaries (sometimes compounded by OCR errors) can lead to inaccurate extraction.",2,positive
works (trained on ImageNet [20] or COCO [43]) on the problem of table detection and table structure recognition in document images [44]–[53].,1,neutral
[53] introduced a table structure recognition method that directly regresses the cellular boundaries.,1,neutral
"The random splits are performed ten rounds for computing averaged performance, which is similar to TabStruct-Net [14].",2,positive
"Compared with TabStructNet [14], NCGM can achieve better performance with less parameters and similar computational budgets.",2,positive
"In particular, note that TabStruct-Net [14] and FLAG-Net [10] are only tested for structure recognition, so we do not count the parameters and operations of cell detection for a fair comparison.",1,neutral
"Bottom-up methods [5,26,27,40] first detect cells or text segments using detection models or OCR engines, then analyze the relations between neighbouring cells using GNN or LSTM.",1,neutral
TabStruct-Net [27] extract cell regions in object detection manner and they can only predict rectangular cell bounding boxes.,1,neutral
