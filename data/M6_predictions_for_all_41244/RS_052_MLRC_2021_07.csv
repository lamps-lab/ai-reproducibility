text,target_M6_predict,target_predict_M6_label
"Although DCL does not use any external data, DCL achieved higher accuracy than SKS. 5) We further analyze the impact of the sequence between the two stages.",2,positive
"Compared with the best-performed baseline model SKS, DCL is superior in terms of both metrics.",2,positive
This is because SKS used an external sentiment dataset to enhance the performance.,2,positive
[7] proposed the sentiment knowledge sharing (SKS) model integrated with an insulting word list and multi-task learning to detect hate speech.,1,neutral
"Although achieving promising performance in this task, the SKS model holds a strong assumption that insulting and negative emotions can distinguish between hate speech and non-hate speech.",1,neutral
[7] proposed the sentiment knowledge sharing (SKS) model combined,1,neutral
Zhou et al. [7] proposed the sentiment knowledge sharing (SKS) model integrated with an insulting word list and multi-task learning to detect hate speech.,1,neutral
"Therefore, the SKS model with an insulting word list of hate speech achieved limited performance by overly focusing on the token-level emotional semantics.",1,neutral
"We used the different F1 score metrics on two datasets following existing studies, such as the SOTA baseline model SKS [7] for fair comparisons.",2,positive
"For the DV dataset, we adopt the mean accuracy and the weighted F1 after five-fold cross-validation, and save the parameters corresponding to the optimal model, which follows the settings in previous work [7].",2,positive
SKS: It was proposed by Zhou et al. [7].,2,positive
[7] proposed the sentiment knowledge sharing (SKS) model combined with a negative word list and multi-task learning for hate speech detection.,1,neutral
"The increasing social issue caused by online hate speech has attracted considerable attention of researchers in the natural language processing (NLP) field, seeking efficient and appropriate solutions to detecting online hate speech [3], [4], [5], [6], [7].",1,neutral
"Furthermore, SKS, benefiting from its sentiment knowledge-sharing mechanism and multi-task learning, achieved the best performance among all the baselines.",2,positive
"4) On the DV dataset, DCL achieved the best performance by accuracy, and better performance by weighted-F1 than all the baseline models except SKS.",0,negative
"[25] work, authors developed a multitasking framework utilizing sentiment knowledge for hate speech detection based on multi-head attention and category information of hate words.",1,neutral
"Various studies in social sciences and psychology verify the existence of several cues that can aid in detecting hate [35,10,19,5,45] such as the haterâ€™s prior history, the conversational thread, overall sentiment, and aggression in the text.",1,neutral
[32] incorporated sentiment knowledge into a hate speech detection task by employing a multi-task learning framework.,1,neutral
"Recently, most researchers have utilized methods of deep learning based on the pretrained language model to tackle this problem (Mou et al., 2020; Cao and Lee, 2020; Tekiroglu et al., 2020; Mathew et al., 2021; Zhou et al., 2021a).",1,neutral
"Inspired by Zhou et al. (2021a), we design a toxic embedding to introduce lexical knowledge.",2,positive
"(Mou et al., 2020; Cao and Lee, 2020; Tekiroglu et al., 2020; Founta et al., 2018; Zhou et al., 2021a; Mathew et al., 2021; Caselli et al., 2020; Hanu and Unitary team, 2020).",2,positive
"The training data with these markers is often labeled as toxic language, leading to spurious associations in the models (Zhou et al., 2021b).",0,negative
[63] Applies attention based neural networks and word embedding feature extraction methods for classification.,1,neutral
(3) The multi-task learning framework SKS performs well on both datasets.,2,positive
11https://github.com/dadangewp/HurtBERT 12https://github.com/1783696285/SKS,2,positive
"2) Baselines: We compare our framework with five categories of baselines: feature-based models (SVM), neural text classification models (LSTM+ATT, CNN+GRU, BiGRU+Capsule, Transformer), pre-trained language model (Bert, HurtBert), Graph Neural Network (DepGCN), and multi-task model (SKS) for abusive language detection.",2,positive
"[34] constructs a largescale abusive language dataset, on which [45] applies GPT-2 to detect abusive language.",1,neutral
Sentiment Knowledge Sharing (SKS) [45] is a multitask abusive language detection framework based on sentiment knowledge sharing.,2,positive
"(4) Our model achieves better performance than the stateof-the-art SKS. Specifically, the accuracy and F1-macro are increased by nearly 2% on SemEval, while the accuracy is improved by about 1% on OLID.",2,positive
"(5) Compared with other pre-trained language models (Bert, HurtBert) and multi-task learning model (SKS), we can also observe that our framework w/ BERT is significantly more robust as shown in Figure 3(a) and Figure 3(b).",2,positive
"Furthermore, our framework does not require any extra knowledge, while SKS requires human-annotated sentiment classification datasets 13.",0,negative
[45] proposes an abusive language detection framework based on external emotional knowledge sharing and combines the characteristics of different feature extraction units to detect abusive language.,1,neutral
"Multi-task learning (MTL) can simultaneously learn multiple related tasks and share knowledge in one framework [23], [45].",1,neutral
"The hate speech detection framework proposed by [29] based on sentiment knowledge sharing (SKS), which includes multiple feature extraction units and a controlled attention mechanism for feature fusion.",2,positive
"Negative sentiment is a salient toxicity feature, which has been used in designing feature-based and neural toxicity detection systems (Fortuna and Nunes, 2018; Zhou et al., 2021; Chiril et al., 2022), and highly",1,neutral
"Negative sentiment is a salient toxicity feature, which has been used in designing feature-based and neural toxicity detection systems (Fortuna and Nunes, 2018; Zhou et al., 2021; Chiril et al., 2022), and highly correlates with toxic language when targeted at demographic groups.",1,neutral
[5] proposes Sentiment Knowledge Sharing that parallel trains Hate Speech Task and Sentiment Task to improve model generalization.,1,neutral
Zhou et al. (2021) integrate features from external resources to support the model performance.,2,positive
"In [9], the authors designed a deep learning model fusing affective features with other features for hate speech detection.",1,neutral
Zhou et al. (2021) integrate features from external resources to support the model performance.,2,positive
