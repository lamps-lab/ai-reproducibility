text,target_M6_predict,target_predict_M6_label
"Some of the DG methods proposed over the past ten years include domain alignment [16], meta-learning [10], style transfer [28], and regularization methods [14].",2,positive
"We further perform a user study [1, 2, 4, 35, 45, 50, 54] to investigate user preference over different stylization results.",2,positive
Recent works [40] show that semantic information can be reflected via the order of pixels according to their gray value.,1,neutral
"Specifically, we
re-implement the TENT [34], BIN [19], DSU [20], Frequency Amplitude Normalization (AmpNorm) [36,37], SAN [35] and EFDMix [40].",2,positive
"re-implement the TENT [34], BIN [19], DSU [20], Frequency Amplitude Normalization (AmpNorm) [36,37], SAN [35] and EFDMix [40].",2,positive
"Inspired by recent studies [5,7,14,22,27,42], we believe that by introducing a suitable normalization strategy, it is possible to effectively balance the training stability and image generation quality of GANs.",2,positive
EFDMix [5] achieves precise feature distribution matching in the feature space using higher-order statistics and augments the training data with style transfer techniques to mitigate overfitting to the source domain.,2,positive
"Following the methodology described in [5], we employ the OSNet architecture as the backbone for our experiments.",2,positive
"Due to the inherent distribution disparities between multiple source domains and the target domain, domain generalization [1, 2, 5, 6] has emerged as a prominent research area.",1,neutral
"We compare our method with several SOTA methods, including feature-level perturbation methods such as [5, 44, 45, 46, 47, 48], as well as image-level perturbation methods like [2, 8, 13, 26, 25, 49, 50, 51].",2,positive
"To mitigate the impact of domain shift, a multitude of domain generalization techniques have emerged [5, 6].",1,neutral
"ERM 71.8 76.1 44.6 36.0 57.1 MixStyle [44] 73.2 74.8 46.0 40.6 58.6 EFDMix [5] 75.3 77.4 48.0 44.2 61.2 ASA [52] 77.3 78.8 50.3 61.8 67.0 Pro-RandConv [53] - - - - 73.3 CPerb (ours) 85.1 86.1 66.6 72.6 77.6
observations can be made from this figure.",0,negative
"Each column denotes a distinct domain, with the first column representing the source domain and the remaining three columns representing the target domains.
when using Market1501 as the source domain and GRID as the target domain, where the CPerb framework achieves a significant 3.8% improvement in mean average precision (mAP) compared to the EFDMix [5].",2,positive
8% improvement in mean average precision (mAP) compared to the EFDMix [5].,2,positive
"In the texture transformation comparison, 76.9% of users prefer the results of SAdaIN over AdaIN, 71.2% prefer the results of SLST results over LST, and 64.1% prefer the results of SEFDM results over EFDM.",2,positive
"We extend this approach to various methods such as AdaIN [13], linear style transfer (LST) [21] and EFDM [44].",1,neutral
"6 shows the results of the style transfer algorithms (e.g., AdaIN, LST, and EFDM), after utilizing the modules of semantic transfer.",1,neutral
"Similarly, semantic EFDM (SEFDM) is defined as SE (VS , VT , Useg) = ∑5 i=1 SE i ( V iS , V i T , U i seg ) :
SLi =
{ EHM ( V iS , V i T ) U iseg, if i 6= 5,
V 5S , if i = 5, (7)
To increase the diversity of the texture, we also design a switch gate (SG) to stochastically exchange the part source feature V iS and the part target feature V i T in both the Eqs.",2,positive
"2D style transfer has been extensively explored with many proposed methods such asAdaIN [13], LST [21], Adaattn[25], InST [40], and EFDM [45].",1,neutral
"It consisted of three main components: a comparison of shape transformation (five questions about NC, DSN, KPD, NT and ours), a comparison of texture transformation (five questions about AdaIN and ours, five questions about LST and ours, five questions about EFDM and ours), and a judgement of realism (five T/F questions).",2,positive
"Decoder is identical to the decoder of AdaIN [13] , LST [21] and EFDM [44] for our SAdaIN, SLST and SEFDM, respectively.",2,positive
"To show the transfer capacity of our method for 3D bird creation, we compare with four shape deformation methods (i.e., NC [37], DSN [34], KPD [17] and NT [15]) and three texture style transformation methods (i.e., AdaIN [13], LST [21] and EFDM [44]).",2,positive
"We extend AdaIN [13], LST [21], and EFDM [44] into SAdaIN, SLST, and SEFDM respectively on the UV maps for the texture transfer.",2,positive
"Third, we introduce a semantic UV texture transfer that exploits switched gates to respectively control whether the part textural transfer or not using AdaIN [13], LST [21] and EFDM [44].",2,positive
"• We present a semantic UV transfer method to utilize switched gates to respectively control whether the part textural transfer or not by using AdaIN [13], LST [21], and EFDM [44], and employing semantic UV segmentation for the texture style transfer.",2,positive
[12] propose a method called Exact Feature Distribution Matching (EFDM) that matches the empirical cumulative distribution functions of image features.,1,neutral
"In this paper, we propose a novel method for data augmentation in domain generalization, which differs from existing methods that perform augmentation at the image or feature level [9], [7], [12] to directly enrich image style information.",2,positive
"We compare our NormAUG method with several augmentation-based methods, including EFDMix [12], FACT [9], RSC [13], and STNP [16].",2,positive
"In this study, we alleviate domain discrepancy by first introducing unsupervised stain augmentation using our proposed RestainNet [14] to introduce domain specific samples in an unsuperivsed learning manner and then applying EFDMix [15] to enhance the cross-domain feature representation.",2,positive
"…feature clustering ResNet38 (ImageNet Pretrained) Imbalanced Training Samples RestainNet (Zhao et al., 2022)
Shared Weights
Domain 1 Domain 2 Domain � Unsupervised Stain Augmentation (UnSA)
Input Image
ResNet38 with EFDMix
(Zhang et al., 2022)
Training Samples (1st Sampler)
Parent
Children
1.",2,positive
"Loss Functions
Training Phase
…
Image Features
Mitosis Detection Pipeline
Test Phase
ResNet38 with EFDMix
(Zhang et al., 2022)
…
Positive samples Negative samples
Feature Representation
Positive samples Negative samples
Feature Representation (Parent)
Positive samples Negative samples
Feature…",2,positive
"…Classes:
：Dropped negative samples ：Selected negative samples
Positive sample (Yellow boundary)
Negative sample (Red boundary)
ResNet38 with EFDMix
(Zhang et al., 2022)
Hematoxylin Channel
Potential Nuclei
Input Image
Training Samples (2nd Sampler)
Hematoxylin Channel Potential Nuclei
Focal…",1,neutral
"To tolerance the color variance across different institutions, we propose stain enhancement (SE) to augment the domain-relevant data by our previously proposed RestainNet [14] and enhance the cross-domain feature representation by EFDMix [15].",2,positive
"Inspired by a style transfer method that augments cross-style features by mixing feature distributions, we apply an EFDMix [15] method to augment the feature representation of different stain styles.",2,positive
"Domain generalization (DG) Existing literature on DG strongly relies on supervised knowledge from source domain data, regardless of whether it originates from a single domain [39] or multiple domains [10,43,46,47], which may not be realistic in continually changing scenarios, as knowledge comes in a sequential manner.",1,neutral
"AdaIN had a significant influence on subsequent research in style transfer, leading to the proposal of various general style transfer methods [9-16].",1,neutral
"Recently, there has been increasing attention on the feature augmentation method that employs style representation [11], [12].",1,neutral
"Under the domain-invariant assumptions, there are many lines of research: contrastive learning [7], factor disentanglement [10], meta-learning [8], style augmentation in feature space [11], [12].",1,neutral
[12] further expanded upon this research with the proposal,2,positive
"Data-based methods augment training data to prevent overfitting [51, 50, 62, 59, 6, 32, 7, 53, 54].",1,neutral
", 2022) and EFDMix (Zhang et al., 2022) have been also proposed.",2,positive
", 2022), EFDMix (Zhang et al., 2022), that also work in the style space as ours.",2,positive
", 2017) that the domain characteristic of data has a strong correlation with the feature statistics (or style statistics) of the early layers of CNNs, the authors of (Zhou et al., 2021; Li et al., 2022; Zhang et al., 2022; Kang et al., 2022) proposed to generate new style statistics during training via style augmentation.",2,positive
"Based on EFDM, the authors of (Zhang et al., 2022) also propose EFDMix, which replaces the concept of AdaIN in MixStyle with EFDM, in a channel-wise manner as follows: EFDMix(x)τi = λxτi + (1− λ)yκi .",2,positive
"As in the setup of (Zhang et al., 2022), we adopt Market1501 (Zheng et al., 2015) and GRID (Loy et al., 2009) datasets, and train the model in one dataset and test on the other one.",2,positive
"Our work is built upon the official setup of EFDMix (Zhang et al., 2022).",2,positive
"Recently, various style augmentation methods such as MixStyle (Zhou et al., 2021), DSU (Li et al., 2022), Style Neophile (Kang et al., 2022) and EFDMix (Zhang et al., 2022) have been also proposed.",2,positive
"Other setups are exactly the same as in MixStyle (Zhou et al., 2021), DSU (Li et al., 2022) and EFDMix (Zhang et al., 2022) when implementing each module; each module is activated with probability 0.5.",2,positive
"This parameter also appears in MixStyle (Zhou et al., 2021) and EFDMix (Zhang et al., 2022), and we set τ = 0.1 for all experiments as in these prior works.",2,positive
"The term f(s)− ⟨f(s)⟩ is introduced to facilitate backpropagation of sample s as in (Zhang et al., 2022).",1,neutral
"The authors of (Zhang et al., 2022) proposed EFDM to replace AdaIN in (3).",2,positive
"Following the setups in (Zhou et al., 2021; Li et al., 2022; Zhang et al., 2022), we adopt ResNet-18 pre-trained on ImageNet as a backbone, where the results with ResNet50 are reported in Appendix.",2,positive
"As in the setup of (Zhang et al., 2022), we adopt Market1501 (Zheng et al.",2,positive
"…characteristic of data has a strong correlation with the feature statistics (or style statistics) of the early layers of CNNs, the authors of (Zhou et al., 2021; Li et al., 2022; Zhang et al., 2022; Kang et al., 2022) proposed to generate new style statistics during training via style augmentation.",2,positive
", 2021) and EFDMix (Zhang et al., 2022), and we set τ = 0.",1,neutral
"First, we consider the state-of-the-art style augmentation schemes, MixStyle (Zhou et al., 2021), DSU (Li et al., 2022), EFDMix (Zhang et al., 2022), that also work in the style space as ours.",2,positive
"In this section, we provide a qualitative comparison of our proposed method with the three selected baseline methods: EFDM (Example-based Feature-driven Diffusion Model), CMD (In the light of feature distributions), and DSTN (Domain-Aware Universal Style Transfer).",2,positive
"[30], proposed a novel approach for arbitrary style transfer that matches the distributions of features between the content and style images.",1,neutral
"Compared to EFDM, our method better preserves the content components of the content image, ensuring that the fine-grained details and structural information are maintained throughout the style transfer process.",2,positive
"3 shows the various content and style images (columns 1,2 respectively), our approach (column 3), CMD (column 4), EFDM (column 5) and DSTN (column 6).",0,negative
(a) Content (b) Style (c) DEPM (Ours) (d) CMD [13] (e) EFDM [30] (f) DSTN [8],1,neutral
"By contrast, the perturbation can be performed in the feature space [25,9,22].",1,neutral
"Subsequently, more research efforts have been devoted to designing the search space that covers a larger area in the feature-style space [9,22].",1,neutral
"We used the same segmentation network and loss function to compare our TriD with seven DG methods, including (1) DCAC: dynamic structure [7], (2) SAN-SAW: based on normalization and whitening [16], (3) RandConv: input-space domain randomization [21], (4-6) MixStyle, EFDM, DSU: feature-space domain randomization [25,22,9] and (7) MaxStyle: adversarial noise [3].",2,positive
"domain tasks [15, 43, 42, 5], which involves training a robust model capable of generalizing well to any unseen domains.",1,neutral
"To address the diversity of training samples, some augmentation schemes have been proposed to enrich training data [15, 43].",1,neutral
"For example, compared with recent methods such as EFDMix [43] and XDED [19], using PBN can increase their performance by +2.9% (57.3 vs. 54.4) and +2.3% (68.8 vs. 66.5), respectively, demonstrating the effectiveness of our proposed PBN.",2,positive
We employ OSNet [46] as the backbone and follow the experiment protocol of [43].,2,positive
"For example, when integrating our PBN into EFDMix [43], it can still increase +2.",1,neutral
"Implementation Details: For the PACS dataset, we follow the same setting as in [19, 43], where we use ResNet-18 as the backbone.",2,positive
"We compare our method with several state-of-the-art (SOTA) methods, including RSC [15], ADA [34], MEADA [44], EFDMix [43] and XDED [19], and integrate our PBN into these methods by replacing BN of the backbone.",2,positive
"For example, when integrating our PBN into EFDMix [43], it can still increase +2.8% (64.0 vs. 61.2).",2,positive
"For example, compared with recent methods such as EFDMix [43] and XDED [19], using PBN can increase their performance by +2.",1,neutral
"Moreover, some multi-source domain generalization methods, such as Exact Feature Distribution Matching [43] and Cross-Domain Ensemble Distillation [19], can also be applied to the single-domain task.",1,neutral
"To solve this problem, researchers have proposed two solutions, namely domain adaptation [21, 25, 28, 31] and domain generalization [3, 16, 38, 40].",1,neutral
"The results indicate that improvement of the proposed AGFA over the existing DG methods is even more pronounced: averaged accuracies higher than the best prior method EFDMIX (Zhang et al., 2022) by about 10% for ResNet-18 and by about 7% for ResNet-50.",0,negative
"Compared to the recent approaches MixStyle (Zhou et al., 2021b) and EFDMix (Zhang et al., 2022), our approach AGFA again shows higher performance even with the smaller ResNet-18 backbone.",2,positive
"Inspired by this observation, researchers have proposed to perform feature statistics perturbation to introduce style-augmented samples (Nuriel, Benaim, and Wolf 2021; Zhou et al. 2021c; Zhang et al. 2022; Li et al. 2022; Chen et al. 2022; Zhong et al. 2022).",1,neutral
"Our method adopts the data augmentation strategy, more specifically, feature-based augmentation (Nuriel, Benaim, and Wolf 2021; Zhou et al. 2021c; Li et al. 2022; Zhang et al. 2022).",2,positive
"We closely follow (Zhou et al. 2021c; Zhang et al. 2022) to perform the cross-domain instance retrieval task on person re-identification (re-ID) datasets of Market1501 (Zheng et al. 2015) and Duke (Ristani et al. 2016; Zheng, Zheng, and Yang 2017).",2,positive
"More importantly, our AdvStyle significantly outperforms other style augmentation competitors (Zhou et al. 2021c; Li et al. 2022; Zhang et al. 2022), validating the effectiveness of expanding the style space via adversarial training.",2,positive
"Recently, performing style augmentation in feature space by conducting feature statistics perturbation has attracted increasing attention due to its simplicity and efficacy (Nuriel, Benaim, and Wolf 2021; Zhou et al. 2021c; Zhang et al. 2022; Li et al. 2022).",1,neutral
"Compared to the common augmentation strategies (Zhong et al.; Ghiasi, Lin, and Le 2018), the style augmentation methods (Zhou et al. 2021c; Li et al. 2022; Zhang et al. 2022) present clear advantages.",2,positive
"Different from most data augmentation methods that introduce augmented samples in the image space (Zhang et al. 2020; Luo et al. 2020), we generate augmented samples in the feature space, which is more computationally efficient.",1,neutral
"Besides the first and second order statistics used in (Nuriel, Benaim, and Wolf 2021; Zhou et al. 2021c), Zhang et al. (Zhang et al. 2022) implicitly considered high-order statistics for more effective statistics perturbation.",1,neutral
"The adversarial training strategy was later adopted to align feature distributions in domain adaptation (Ganin and Lempitsky 2015; Ganin et al. 2016; Long et al. 2018), generative photo-realistic super-resolution (Ledig et al. 2017; Wang et al. 2018), data augmentation (Zhang et al. 2020; Volpi et al. 2018a; Luo et al. 2020), and so on.",2,positive
"Based on such observation, researchers started to introduce style/distribution augmented training samples by feature statistics perturbation into DG model training (Nuriel, Benaim, and Wolf 2021; Zhou et al. 2021c; Li et al. 2022; Zhang et al. 2022).",2,positive
"Particularly, we perform existing style augmentation-based DG methods (Nuriel, Benaim, and Wolf 2021; Zhou et al. 2021c; Li et al. 2022; Zhang et al. 2022) under the same setting for fair comparison.",2,positive
"By expanding the training data with these style-augmented samples, improved generalization performance of DNN models has been observed (Nuriel, Benaim, and Wolf 2021; Zhou et al. 2021c; Zhang et al. 2022; Li et al. 2022).",2,positive
"Our method also outperforms the recent work (Zhang et al. 2022) that explores broader style spaces by utilizing high-order batch statistics, revealing the advantage of exploring style spaces beyond batch statistics.",2,positive
"…DG works are typically based on accurate supervision knowledge of the source domain data, whether it is drawn from a single domain (Wang et al., 2021d; Li et al., 2021) or multiple domains (Yao et al., 2022; Zhang et al., 2022), which may not be achievable in continually changing scenarios.",2,positive
"RaTP is compared with a comprehensive set of state-of-the-art works from Continual DA [CoTTA (Wang et al., 2022), AuCID (Rostami, 2021)], Source-Free DA [SHOT (Liang et al., 2020), GSFDA (Yang et al., 2021), BMD (Qu et al., 2022)], Test-Time/Online DA [Tent (Wang et al., 2020), T3A (Iwasawa & Matsuo, 2021)], Single DG [L2D (Wang et al., 2021d), PDEN (Li et al., 2021)], Unified DA&DG [SNR (Jin et al., 2021)], and Multiple DG [PCL (Yao et al., 2022), EFDM (Zhang et al., 2022)].",2,positive
"For Single DG [L2D (Wang et al., 2021d), PDEN (Li et al., 2021)] and Multiple DG [PCL (Yao et al., 2022), EFDM (Zhang et al., 2022)], we use SHOT (Liang et al., 2020) to assign pseudo labels for the optimization on target domains.",2,positive
"…GSFDA (Yang et al., 2021), BMD (Qu et al., 2022)], Test-Time/Online DA [Tent (Wang et al., 2020), T3A (Iwasawa & Matsuo, 2021)], Single DG [L2D (Wang et al., 2021d), PDEN (Li et al., 2021)], Unified DA&DG [SNR (Jin et al., 2021)], and Multiple DG [PCL (Yao et al., 2022), EFDM (Zhang et al., 2022)].",2,positive
"In EFDM, we use samples from current domain as the content images and randomly select images in the replay memory as the style images.",2,positive
"According to the composition of the given source domain, DG can be divided into two types, Single Source (Wang et al., 2021d; Li et al., 2021) and Multi-Source (Yao et al., 2022; Zhang et al., 2022).",2,positive
", 2021) or multiple domains (Yao et al., 2022; Zhang et al., 2022), which may not be achievable in continually changing scenarios.",0,negative
EFDM [22] implicitly performs the exact histogram matching on features to achieve style transfer.,1,neutral
"Some recent methods [7], [21], [22] utilize feature statistics to tackle the domain generalization problem.",1,neutral
"Several image classification works [13,35,45,48,56] have proposed strategies to improve the performance on unseen domains while training on a single source domain.",1,neutral
"While this has been well studied for image classification [13, 35, 45, 48, 56], it remains a nascent topic in object detection.",1,neutral
"In particular, [35,45,48] introduce data augmentation strategies where diverse input images are generated via adversarial training; [13, 56] propose normalization techniques to adapt the feature distribution to unseen domains.",1,neutral
Input Reference Ours (α = 0) Ours (α = 1) AdaIN [5] WCT [8] LinearWCT [7] ArtFlow [1] EFDM [16] StyleSwap [2] Avatar-Net [13] SANet [11] AdaAttN [10] StyTR2 [3] Figure A.,2,positive
Input Reference Ours (α = 0) Ours (α = 1) AdaIN [5] WCT [8] LinearWCT [7] ArtFlow [1] EFDM [16] StyleSwap [2] Avatar-Net [13] SANet [11] AdaAttN [10] StyTR2 [3] Figure E.,2,positive
Input Reference Ours (α = 0) Ours (α = 1) AdaIN [5] WCT [8] LinearWCT [7] ArtFlow [1] EFDM [16] StyleSwap [2] Avatar-Net [13] SANet [11] AdaAttN [10] StyTR2 [3] Figure B.,2,positive
"5 [16] Yabin Zhang, Minghan Li, Ruihuang Li, Kui Jia, and Lei Zhang.",0,negative
Input Reference Ours (α = 0) Ours (α = 1) AdaIN [5] WCT [8] LinearWCT [7] ArtFlow [1] EFDM [16] StyleSwap [2] Avatar-Net [13] SANet [11] AdaAttN [10] StyTR2 [3],2,positive
9% [43] proposes to perform exact feature distribution matching in the image feature space and achieve one classification performance of 83.,2,positive
"As shown in Table 1, the LCT module outperformed the method without jump connection and the EFDM method with a higher SSIM score, which proved the effectiveness of the LCT module.",2,positive
"Table 1: Quantitative comparison between LCT and other methods
LCT EFDM Without skip
0.612 0.255 0.578
Figure 3: The effectiveness of GLFA
Figure 4: The effectiveness of LCT
As shown in Figure 3, without the constraint of WCE, the local information of the style image cannot match the local information of the content image well.",0,negative
"On the other hand, to prove the effectiveness of the LCT transform module, this article compares it with EFDM [36], a method that matches higher-order statistics of images.",1,neutral
"As shown in Figure 4, in the third and fourth columns of the first row, in the EFDM method, clouds in the sky show inconsistent stylization and inaccurate feature extraction ability (the lights of the building windows blur).",0,negative
"In addition, the overall color of the style achieved by the EFDM method also differs from the original style image.",0,negative
"Holistic feature distribution matching [13, 24, 17, 47] and locality-aware feature matching [32, 12, 29, 46, 27] are two categories of existing approaches.",1,neutral
"In order to break through the theoretical and practical limitations of first-order and second-order statistics, high-order statistics are introduced in [17] and [47] to perform more exact distribution matching.",1,neutral
"Arbitrary style transfer [4, 13, 24, 32, 12, 22, 29, 42, 46, 19, 15, 7, 17, 27, 1, 40, 5, 6, 47, 48] has received increasing attention recently, depending on its advantage of using a single feed-forward neural model to transfer the style of an arbitrary image.",1,neutral
"There have been notable improvements in feature transformation modules [13, 32, 12, 29, 46, 7, 27, 17, 47], novel architectures [24, 31, 1, 40, 6], and practical objectives [19, 5, 48].",1,neutral
"̃? with 𝑆𝐷𝑤 using recently proposed work by Zhang [37] to get𝑇 (𝑒 𝑓 𝑑𝑚)
𝐷𝑤 (?",1,neutral
higher order moments of ?̃? with SDw using recently proposed work by Zhang [37] to getT (e f dm) Dw (?̃?).,1,neutral
"Among data augmentation methods, our method is related to MixStyle [71] and EFDMix [65] due to the use of style transfer (i.e., the AdaIN algorithm [15]) to create novel data samples.",2,positive
"Among data augmentation methods, our method is related to MixStyle [71] and EFDMix [65] due to the use of style transfer (i.",2,positive
"These methods have demonstrated their ability to not only transfer artistic styles but also effectively capture the semantic content of images [15, 58, 65], which we propose that they hold promise for fulfilling the front-door requirements.",1,neutral
"In addition, both MixStyle and EFDMix rely on statistical predictions, which are sensitive to domain shift [1, 32].",2,positive
"A commonly used invariance hypothesis is the texture shift hypothesis: a lot of domain shifts are primarily textures shifts, and using style transfer based data augmentation will improve the generalization, whether it is explicitly by training a model on stylized images [38, 19] or implicitly in the internal representation of the network [43, 27].",1,neutral
"While all the existing methods improve upon the standard training procedure (ERM) on PACS, only EFDM, spectral decoupling [28], and our method yield better results on Office-Home.",2,positive
"If the methods did not have quantitative hyper-parameters, such as EFDM [43] with the
choice of mixing-layers depths, we used the ones proposed for the PACS experiments.",1,neutral
"This would explain why test-time batch normalization yield an large improvement on the PACS benchmark, as the simple use of test-time statistics, that encode textures [3], is enough to significantly bridge the domain gap and why the methods reaching the highest results [43, 27, 38] in the usual setting (without test-time batch normalization) are all style transfer based methods.",1,neutral
"As a result, a number of methods study single-source domain generalization [38, 31, 44, 43, 27].",1,neutral
"If the methods did not have quantitative hyper-parameters, such as EFDM [43] with the choice of mixing-layers depths, we used the ones proposed for the PACS experiments.",1,neutral
"Used alongside test-time batch normalization, our method reaches a performance similar to that of EFDM [43] on the PACS datasets, but exceeds it on the Office-Home datasets.",2,positive
"We compare our approach with the standard training procedure (expected risk minimization, ERM), with several methods designed for single-source domain generalization [38, 43, 27, 36, 44, 31], with a method designed to reduce the shortcut learning phenomenon in deep networks [28] and a multi-source domain generalization algorithm that does not explicitly require several training domains [17].",2,positive
"See the results of RSC [18], MixStyle [59] and EFDMix [51] in Figure 1a.",0,negative
"Data augmentation methods aim to diversify the training data, which is often achieved by learning a generative model [57, 58] or mixing data at the input [43,44] or feature-level [51,59].",1,neutral
"In most cases, the two feature-based data augmentation methods, i.e., MixStyle and EFDMix, achieve better performance than RSC, a regularization method that mutes the most predictive subsets of neurons during training.",1,neutral
"For example, MixStyle and EFDMix can improve upon ERM when using MobileNetV3-Small but their performance plunges below ERM’s when using two much smaller architectures specifically designed for MCUs.",2,positive
"We choose top-performing DG methods that do not need domain labels to compare: ERM, RSC [18], MixStyle [59], and EFDMix [51].",2,positive
"Although dating from 2015, VGG-19 is still the go-to architecture for applications involving Gram matrices such as image style transfer (Zhang et al., 2022; Höllein et al., 2022; Xie et al., 2022).",2,positive
"Similarly, EFDM (Zhang et al. 2022) proposes to match the empirical Cumulative Distribution Functions (eCDFs) of image features, mapping the representation from unseen domains to the specific feature space.",1,neutral
"In domain generalization, EFDMix [11] applies the EHM method to gain an exact match of the eCDF by performing ranked matching in the image feature space.",1,neutral
"(2) We adopt the EFDMix (Exact Feature Distribution Mixing) method [11] to generate two different enhancements by implicitly using higher order statistics to produce more diverse feature enhancements, which is the first application of EFDMix to vehicle re-identification so far.",2,positive
"We show the overall framework of the proposed network in section A; in section B we introduce the IBN-Net; in section C we describe the EFDMix method [11]; finally, in section D we describe the SE and CA attention mechanisms; and in section F we introduce the loss function used.",2,positive
"EFDM(x, y) ∶ oτi = xτi + yki − 〈xτi〉 (4) where〈xτi〉represents the stop-gradient operation [11].",1,neutral
"To overcome the problem of cross-domain performance degradation in vehicle reidentification, this paper introduces a new method EFDMix[11] that performs Exact Feature Distribution Matching (EFDM) based on the empirical Cumulative Distribution Function (eCDF) of exact matching image features.",1,neutral
"On the other hand, existing DG methods, which mainly span domain invariant feature learning [16,34,35,41,42,69], gradient based meta-learning [9, 30, 31], and augmentation based generalization [50, 58], are devoted to learn semantic representations in virtue of one-vs-one consistency constraints.",1,neutral
"Used alongside test-time batch normalization, our method reaches a performance similar to that of EFDM [44] on the PACS datasets but exceeds it on the Ofﬁce-Home datasets.",2,positive
"Used alongside test-time batch normalization, our method reaches a performance similar to that of EFDM [44] on the PACS datasets but exceeds it on the Office-Home datasets.",2,positive
"It can be done explicitly by training a model on stylized images [38, 20] or implicitly in the internal representation of the network [44, 28].",1,neutral
"We compare our approach with the standard training procedure (expected risk minimization, abbreviated ERM), with several methods designed for single-source domain generalization [38, 44, 28, 36, 45, 32], with Spectral Decoupling [29], a method designed to reduce the shortcutlearning phenomenon in deep networks, and with RSC [18], and InfoDrop [32], that are domain generalization algorithms which do not explicitly require several training domains.",2,positive
"While all the existing methods improve upon the standard training procedure (ERM) on PACS, only EFDM, spectral decoupling [29], and our method yield better results on Ofﬁce-Home.",2,positive
"It would also explain why the methods reaching the highest results [44, 28, 38] in the usual setting (without test-time batch normalization) are all style-transfer-based methods.",1,neutral
"As a result, some works study single-source domain generalization [38, 32, 45, 44, 28].",1,neutral
"In particular, MixStyle [25] generates novel domains by mixing implicit style information and demonstrates outstanding performances and EFDMix [27] provides more diverse feature augmentations by measuring accurate feature distributions.",2,positive
"The purpose of data augmentation in DG is to enlarge the source domain distribution into a wider span [5], [8], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], which can improve the robustness of the models to novel domains.",2,positive
"A recent data augmentation method, MixStyle [25], pAdaIN [24] and EFDMix [27], achieve significant improvement over the other baselines.",2,positive
"Note that, the purpose of data augmentation techniques, MixStyle [25], pAdaIN [24] and EFDMix [27], are to diversify the source domain as aforementioned.",2,positive
"Very recently, the generation-based approaches to define novel domains by synthesizing new images in the embedding space have been proposed [8], [23], [25], [27].",1,neutral
"…such problems are found in numerous applications, including molecular docking (Gainza et al., 2020), image-based rendering (Fachada et al., 2021) , 3D reconstruction (Zhao et al., 2022), generative models (Dai & Hang, 2021) and style transfer (Zhang et al., 2022), in addition to countless others.",1,neutral
", 2022), generative models (Dai & Hang, 2021) and style transfer (Zhang et al., 2022), in addition to countless others.",2,positive
"Among data augmentation methods, our method is related to MixStyle [65] and EFDMix [59] due to the use of style transfer [13] to create novel data samples.",2,positive
"In addition, both MixStyle and EFDMix rely on statistical prediction, which we believe, to be sensitive to domain shift [1, 28].",2,positive
