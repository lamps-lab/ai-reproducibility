text,target_M6_predict,target_predict_M6_label
"samples into splits with disjoint compositional structures [23, 52].",1,neutral
"[52] Peter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova.",0,negative
"As the posed question does not follow the identical distribution of the training dataset adopted by the semantic parsing model (Shaw et al., 2021; Yin et al., 2021), it is falsely parsed with the Or operator, which should be an And operator, causing the structure error of the KB query.",2,positive
"For database schema serialization, previous PLM-basedworks [17, 29, 36, 37] directly concatenate the table/column names and require the model to output these names to form an SQL query.",1,neutral
SMBOP introduces a semi-autoregressive bottom-upNL2SQLmodel as an alternative approach to top-down autoregressive model.,2,positive
Type Perturbation # Test SMBOP [34] T5-3B LK [37] Picard [36] RESDSQL [17] ChatGPT ChatGPT + ZeroNL2SQL,2,positive
"The first type is the SOTA PLM-based models fine-tuned on the Spider training set, including SMBOP [34], T5-3B LK [37], Picard [36] and RESDSQL [17].",2,positive
"For example, on the DBcontent-equivalence test set, the EX accuracy of SMBOP [37] is only 37.2%, which is much worse than its average performance.",1,neutral
"For example, on the DBcontent-equivalence test set, the EX accuracy of SMBOP [37] is only 37.",1,neutral
"Previous methods [17, 29, 36, 37] cannot guarantee this when test environment changes.",1,neutral
"To support Text-to-SQL, similar to [24, 26], we fine-tune the model in an end-to-end manner.",2,positive
"Different from the previous methods with task-specific design, PLM-based methods [24, 26] can be applied to different text-to-SQL datasets without specific modifications to the base PLMs.",1,neutral
"Specifically, Picard [24] and [26] also achieve good performance in the few-shot scenario using general PLMs (e.",1,neutral
"Transformer-based encoder-decoder models have been widely used to support Text-to-SQL, and representative models include NQG-T5 [26], PICARD [24], UnifiedSKG [34], etc.",1,neutral
"These benchmarks contain not only synthetic evaluations deliberately designed for diverse categories of systematic generalization but also non-synthetic ones additionally requiring capabilities of neural models in handling natural language variations (Shaw et al., 2021).",1,neutral
"(2) Because finding the most probable string t2 from pθ(t2|t1) is NP-hard (Sima’an, 1996; Lyngsø and Pedersen, 2002), we follow Kim (2021) to use a decoding strategy with heavy sampling.",1,neutral
", 2021b) and NLP fields (Shaw et al., 2021; Furrer et al., 2020), but it’s under-explored in dialogue, and also, we argue that data-level explicit dividing is simple and more interpretable than that of implicit representation-level dividing.",1,neutral
"…disenchanted representation effectively improves the zero-shot generalization in the CV (Chen et al., 2021; Ye et al., 2021b) and NLP fields (Shaw et al., 2021; Furrer et al., 2020), but it’s under-explored in dialogue, and also, we argue that data-level explicit dividing is simple and more…",2,positive
Shaw et al. (2021) define the atom and compound for SQL statements and propose the TMCD split to repartition the dataset.,2,positive
Shaw et al. (2021) define the atom and compound for SQL statements and prop se the TMCD split to repartition the dataset.,2,positive
"From another point of view, our compositional generalization scenario could also be viewed as a special case of TMCD split (Shaw et al., 2021), where the SQL templates and modification templates could be seen as atoms and their combination results are the compounds.",2,positive
"…architectures for this task (Yu et al., 2018a; Zhang et al., 2019; Wang et al., 2020; Lin et al., 2020), there has been a trend of directly fine-tuning pre-trained sequenceto-sequence models as semantic parsers (Shaw et al., 2021; Scholak et al., 2021; Xie et al., 2022; Qi et al., 2022).",2,positive
", 2020) have now been more and more widely adopted for semantic parsing due to their promising performance and straightforward architectures (Shaw et al., 2021; Scholak et al., 2021; Yin et al., 2021; Qi et al., 2022; Xie et al., 2022; Qiu et al., 2021).",2,positive
", 2020), there has been a trend of directly fine-tuning pre-trained sequenceto-sequence models as semantic parsers (Shaw et al., 2021; Scholak et al., 2021; Xie et al., 2022; Qi et al., 2022).",1,neutral
"…models (LMs)2 such as T5 (Raffel et al., 2020) have now been more and more widely adopted for semantic parsing due to their promising performance and straightforward architectures (Shaw et al., 2021; Scholak et al., 2021; Yin et al., 2021; Qi et al., 2022; Xie et al., 2022; Qiu et al., 2021).",2,positive
"However, recent work revealed that these LMs still struggle to generalize on outof-distribution (OOD) samples (Lake and Baroni, 2018; Keysers et al., 2019; Shaw et al., 2021; Qiu et al., 2022b).",2,positive
"Strong priors in the form of specialized model architectures (Shaw et al., 2021; Herzig and Berant, 2021; Wang et al., 2021) are either too expensive or not applicable across domains.",2,positive
"The state table is passed into the dialogue context by simple “linearisation” (Suhr et al., 2020; Scholak et al., 2021; Shaw et al., 2021): the rows are converted to",2,positive
"The state table is passed into the dialogue context by simple “linearisation” (Suhr et al., 2020; Scholak et al., 2021; Shaw et al., 2021): the rows are converted to slot-value tuples, cast to a string using the template {slot} = {value}, and concatenated together using ; as a separator.2 During…",2,positive
"To develop a text-to-SQL parser, a prevalent approach is to collect labeled data and train a model via supervised learning (Shaw et al., 2021; Scholak et al., 2021).",1,neutral
"Alternatively, other studies (Guo et al., 2019; Lin et al., 2020; Shaw et al., 2020) have converted table schemas into a sequence to effectively leverage pretrained language models,",1,neutral
"Alternatively, other studies (Guo et al., 2019; Lin et al., 2020; Shaw et al., 2020) have converted table schemas into a sequence to effectively leverage pretrained language models,
such as BERT (Devlin et al., 2018) and T5 (Raffel et al., 2020).",1,neutral
"question-specific table content by identifying the relevant table content mentioned in the question through string matching (Lin et al., 2020; Shaw et al., 2020; Wang et al., 2019).",0,negative
"To incorporate table content into neural models, prior work with supervised models provides question-specific table content by identifying the relevant table content mentioned in the question through string matching (Lin et al., 2020; Shaw et al., 2020; Wang et al., 2019).",1,neutral
"By fine-tuning generic neural models on these benchmarks, much work reported that these models exhibit poor compositional generalization (Furrer et al., 2020; Shaw et al., 2021; Bogin et al., 2022).",2,positive
"Many approaches were proposed to enhance the CG on general-purpose models (Andreas, 2020; Akyürek et al., 2020; Guo et al., 2021; Oren et al., 2021; Shaw et al., 2021; Zhu et al., 2021) or design task-specific methods (Liu et al.",2,positive
"Moreover, some work has suggested that the challenge of compositional generalization under fine-tuning lies in unobserved structures (Keysers et al., 2019; Shaw et al., 2021; Bogin et al., 2022).",1,neutral
"3 In-Context Learning vs Fine-Tuning Compositional generalization under the fine-tuning paradigm has been widely studied (Furrer et al., 2020; Shaw et al., 2021; Bogin et al., 2022), while there is little observation under in-context learning.",1,neutral
"Many approaches were proposed to enhance the CG on general-purpose models (Andreas, 2020; Akyürek et al., 2020; Guo et al., 2021; Oren et al., 2021; Shaw et al., 2021; Zhu et al., 2021) or design task-specific methods (Liu et al., 2020; Herzig
6The term “fictional words” means that these words are…",2,positive
"Compositional generalization under the fine-tuning paradigm has been widely studied (Furrer et al., 2020; Shaw et al., 2021; Bogin et al., 2022), while there is little observation under in-context learning.",1,neutral
"approaches for compositional generalization (Shaw et al., 2021).",1,neutral
"Task-specific representations and encoding schemes are very common with state-of-the-art approaches for compositional generalization (Shaw et al., 2021).",1,neutral
"To improve compositionality of LMs, previous works propose to parameterize grammatical rules (Kim, 2021; Shaw et al., 2021) but show that those hybrid models are inefficient and usually underperform neural counterparts.",1,neutral
", [15, 22, 31, 63]), prompt engineering with pre-trained language models such as Codex and GPT-4 [45, 46], and fine-tuned large language models [51, 54].",1,neutral
"These methods have achieved success when trained and tested on a specifc dataset or domain [2, 7, 8, 10, 18, 21, 22, 25].",1,neutral
"With the recent advances in pre-trained language models (PLMs), many existing works formulate the Text-to-SQL task as a semantic parsing problem and use a sequence-tosequence (seq2seq) model to solve it (Scholak, Schucher, and Bahdanau 2021; Shi et al. 2021; Shaw et al. 2021).",1,neutral
"Following Shaw et al. (2021); Scholak, Schucher, and Bahdanau (2021), we treat Text-to-SQL as a translation task, which can be solved by an encoder-decoder transformer model.",2,positive
"However, even the T5-3B model only achieves about 70% accuracy (Shaw et al. 2021; Scholak, Schucher, and Bahdanau 2021).",2,positive
"An example compositionality metric for semantic parsing is maximum compound divergence (Keysers et al., 2019; Shaw et al., 2021), that minimises train-test differences in word distributions while maximising the differences in compound usage.",1,neutral
"However, these models often generalize poorly to out-of-distribution (OOD) and tail examples (Cheng et al., 2019; Shaw et al., 2021; Kim, 2021; Lin et al., 2022), while grammar or rule-based parser work relatively robustly across different linguistic phenomena and language domains (Cao et al.,…",1,neutral
"However, these models often generalize poorly to out-of-distribution (OOD) and tail examples (Cheng et al., 2019; Shaw et al., 2021; Kim, 2021; Lin et al., 2022), while grammar or rule-based parser work relatively robustly across different linguistic phenomena and language domains (Cao et al.",1,neutral
"The baseline models also include a similar practice with (Shaw et al., 2021) and (Hoang et al., 2021).",2,positive
"This has motivated the work in neuralsymbolic parsing where symbolic approaches are imported as inductive bias (Shaw et al., 2021; Kim, 2021; Cheng et al., 2019; Cole et al., 2021).",1,neutral
"(5) T5-3B LK (Shaw et al., 2021): A T5-3B model with an entity linking between question and DB content.",2,positive
Compositional generalization benchmarks such as SCAN and COGS are often used to evaluate pretrained models.,1,neutral
"…(typically, “language modeling”) such as T5 (Raffel et al., 2020), mT5 (Xue et al., 2021), CodeT5 (Wang et al., 2021) and pretrained convolutional sequence-to-sequence (seq2seq) networks achieve high generalization accuracy on SCAN and COGS (Shaw et al., 2021; Tay et al., 2021; Orhan, 2021).",2,positive
"…impact the interpretation of a large body of existing work in this domain that uses pretrained models (Furrer et al., 2020; Tay et al., 2021; Shaw et al., 2021; Orhan, 2021; Qiu et al., 2021; Zhu et al., 2021; Herzig et al., 2021; Qiu et al., 2022; Zheng and Lapata, 2022; Drozdov et al.,…",2,positive
"Among such work, some report that models pretrained on context reconstruction (typically, “language modeling”) such as T5 (Raffel et al., 2020), mT5 (Xue et al., 2021), CodeT5 (Wang et al., 2021) and pretrained convolutional sequence-to-sequence (seq2seq) networks achieve high generalization accuracy on SCAN and COGS (Shaw et al., 2021; Tay et al., 2021; Orhan, 2021).",1,neutral
", 2021) and pretrained convolutional sequence-to-sequence (seq2seq) networks achieve high generalization accuracy on SCAN and COGS (Shaw et al., 2021; Tay et al., 2021; Orhan, 2021).",2,positive
"Despite strong performance of pre-trained language models (LMs) across many tasks, they have been shown to struggle in a compositional generalization setting (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021), when tested on their ability to process and generate novel combinations of previously observed elements.",1,neutral
"…pre-trained language models (LMs) across many tasks, they have been shown to struggle in a compositional generalization setting (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021), when tested on their ability to process and generate novel combinations of previously observed elements.",1,neutral
"We use the standard (i.i.d.) and compositional splits created by Shaw et al. (2021): (1) template split, where target programs are anonymized into templates and then the templates are randomly split between training and test sets (Finegan-Dollak et al., 2018); (2) TMCD split, which makes the…",2,positive
"Other benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2021) focus on naturally occurring examples but create train-test splits based on the properties of their formal meaning representations (e.",1,neutral
", 2020), architecture improvements (Dessì and Baroni, 2019; Gordon et al., 2020; Oren et al., 2020; Zheng and Lapata, 2021; Herzig et al., 2021; Shaw et al., 2021), task decomposition (Liu et al.",2,positive
"…al., 2020), architecture improvements (Dessì and Baroni, 2019; Gordon et al., 2020; Oren et al., 2020; Zheng and Lapata, 2021; Herzig et al., 2021; Shaw et al., 2021), task decomposition (Liu et al., 2020, 2021), semi-supervised learning (Guo et al., 2021), multi-task learning (Jiang and Bansal,…",2,positive
The Semantic Parsing approach also addresses part of the problem (Shaw et al. 2021).,1,neutral
GeoQuery (Shaw et al. 2021) is a non-synthetic dataset with pairs of questions and meaning representations annotated by humans.,1,neutral
", 2020), but they still fail on tasks that require compositional generalization (Shaw et al., 2021; Furrer et al., 2020).",1,neutral
"Big language models have impressive performance on many language understanding tasks (Devlin et al., 2019; Raffel et al., 2020; Chowdhery et al., 2022; Lewis et al., 2020), but they still fail on tasks that require compositional generalization (Shaw et al., 2021; Furrer et al., 2020).",1,neutral
", 2020) architectures, both of which have frequently been applied to semantic parsing benchmarks (Shaw et al., 2021; Scholak et al., 2021; Desai and Aly, 2021; Banerjee et al., 2022).",2,positive
"Shaw et al. (2020) first shows that the pre-trained Seq2Seq model (Raffel et al., 2020) with 3 Billion parameters achieves competitive performance on the Spider dataset.",2,positive
"Further works have explored both problems—multi-hop reasoning and compositional generalization—through the lens of semantic parsing (Wolfson et al., 2020; Shaw et al., 2021).",1,neutral
"Recent work in compositionality in NLP has been mostly limited to semantic parsing and multihop reasoning for the purpose of Q&A (Shaw et al.,
2021; Wolfson et al., 2020; Min et al., 2019).",1,neutral
Many recent works in the Q&A literature have strived to study compositionality on either a question or system level.,1,neutral
"Shaw et al. (2021) also address the challenge of natural language variation in compositional generalization, but they experiment on semantic parsing, where the knowledge is highly consistent and can be inducted with grammar rules.",1,neutral
We take the serialization scheme mentioned in [45] and enable database content by appending database values to the column names [15].,2,positive
"Following Shaw et al. (2021), we benchmark the competitive T5-base model (Raffel et al., 2020) on all splits of the SPIDER dataset.",2,positive
"Other approaches create dataset splits that test for specific skills, such as length generalization (Lake and Baroni, 2018) and compositional generalization (Shaw et al., 2021), but they only apply to a narrow subset of tasks.",1,neutral
"For SPIDER, we follow Shaw et al. (2021) and tune the learning rate, batch size and maximum training steps for a T5-base model (Raffel et al., 2020) on a random split of the SPIDER dataset.",2,positive
"Other approaches create dataset splits that test for specific skills, such as length generalization (Lake and Baroni, 2018) and compositional generalization (Shaw et al., 2021), ar X iv :2 21 0.",1,neutral
"…of programming languages makes semantic parsing, the task of translating a natural language utterance into a logical program, a good testbed for evaluating compositional generalization (Lake and Baroni, 2018; Kim and Linzen, 2020; Hupkes et al., 2020; Key-
sers et al., 2020; Shaw et al., 2021).",1,neutral
"Shaw et al. (2021), one of the alternative splits that we compare against, use a subset of 4000 examples from the 7000 training examples.",1,neutral
We follow Shaw et al. (2021) and swap examples between the train and evaluation sets such that every logical program atom in the evaluation set appears at least once in the train set.,1,neutral
"Following Shaw et al. (2021), we report atom and compound divergences of the various splits in Table 13 of Appendix A.4.",2,positive
"The deterministic grammar of programming languages makes semantic parsing, the task of translating a natural language utterance into a logical program, a good testbed for evaluating compositional generalization (Lake and Baroni, 2018; Kim and Linzen, 2020; Hupkes et al., 2020; Keysers et al., 2020; Shaw et al., 2021).",1,neutral
"Recently, Shaw et al. (2021); Scholak et al. (2021) successfully applied T5 for the text-to-SQL task.",2,positive
"Correspondence to: ramild.yar@gmail.com
Shaw et al. (2021) continued the study in the multidatabase setting and showed that the compositional generalization was hard to achieve, and even to measure it, one should be very careful with splits.",1,neutral
"These pre-trained decoders, like the one of T5, can also be successfully applied to the text-to-SQL task (Shaw et al., 2021).",1,neutral
"Structured knowledge grounding tasks mainly adopt semantic parsing since symbolic languages like SQL, SPARQL can be executed on them (Berant et al., 2013; Liang et al., 2017; Yin & Neubig, 2017; Zhong et al., 2018; Yu et al., 2018; Shaw et al., 2021; Scholak et al., 2021).",1,neutral
Shaw et al. (2021) heuristically induce a QCFG and create an ensemble of a QCFG-based parser and a seq2seq model.,1,neutral
", 2019), semantic parsing (e.g. Finegan-Dollak et al., 2018; Keysers et al., 2019; Kim and Linzen, 2020; Shaw et al., 2021) or other kinds of generation tasks (e.",1,neutral
"…2016), machine translation (e.g. Dankers et al., 2022; Liu et al., 2021b; Raunak et al., 2019), semantic parsing (e.g. Finegan-Dollak et al., 2018; Keysers et al., 2019; Kim and Linzen, 2020; Shaw et al., 2021) or other kinds of generation tasks (e.g. Hupkes et al., 2020; Lake and Baroni, 2018).",1,neutral
"However, SCAN is an artificial task built upon a synthetic language with a tiny vocabulary and is generated from a small set of grammar rules, and it is unclear whether strong results transfer to more realistic tasks that are based on a larger vocabulary and more complicated grammars (Furrer et al., 2020).",1,neutral
"Similarly to symbolic grammar learning techniques on SCAN, these approaches achieve impressive performance on several benchmarks, and represent the previous state of the art on CFQ (Keysers et al., 2020) and COGS (Kim & Linzen, 2020).",2,positive
"Since SCAN commands are generated by a simple grammar of only 20 rules, this decomposition task can be performed using a prompt consisting of only 8 decomposition exemplars.",1,neutral
"C L
] 3
0 Se
p 20
22
We evaluate our approach on two realistic benchmarks that, like SCAN, are designed to measure compositional generalization: CFQ (Keysers et al., 2020) and COGS (Kim & Linzen, 2020).",2,positive
"Indeed, while decomposing SCAN commands is similar to decomposing mathematical expressions with standard arithmetic operations, decomposing sentences corresponding to more realistic subsets of natural language essentially becomes a problem of syntactic parsing.",1,neutral
"As an illustration, consider the application of least-to-most prompting to SCAN.",1,neutral
"A number of approaches have been proposed to improve compositional generalization on SCAN (Lake & Baroni, 2018; Loula et al., 2018), including specialized design of neural model architectures (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021; Russin et al., 2019; Li et al., 2019; Gordon et al., 2020; Herzig & Berant, 2021) and training algorithms (Lake, 2019; Kim, 2021), training data augmentation (Andreas, 2020; Akyürek et al., 2021), and prompting (Zhou et al., 2022).",2,positive
"In particular, recent work (Zhou et al., 2022) found that least-to-most prompting shows a lot of potential for adapting LLMs for compositional generalization, achieving 99.7% accuracy on SCAN, a commonly used compositional generalization benchmark.",2,positive
"As for CFQ and SCAN, the training data for COGS contains multiple systematic gaps that can only be addressed by compositional generalization; these include new combinations of familiar syntactic structures and familiar structures.",1,neutral
"Roughly, the decomposition of a SCAN statement resembles that of a mathematical expression with standard arithmetic operations.",1,neutral
"Even more general purpose methods that rely on data augmentation are limited in the class of data it can support (Shaw et al., 2021; Qiu et al., 2022a).",1,neutral
"Compared to SCAN, CFQ is based on a much larger vocabulary as well as more complex linguistic structures produced by a unification-based grammar (Shieber, 2003).",1,neutral
"Recent work has achieved perfect generalization accuracy on SCAN by inferring grammar rules in symbolic form (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021).",1,neutral
"While 100% accuracy has been accomplished on SCAN (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021), good performance on SCAN does not necessarily transfer to more challenging compositional generalization problems (Furrer et al.",1,neutral
"Notably, although least-to-most prompting has achieved 99.7% accuracy on SCAN (Zhou et al., 2022), prior attempts on prompting for semantic parsing still demonstrate limited compositional generalization performance (Qiu et al., 2022b).",1,neutral
"…problem that attracts attention across fields, including vision (Johnson et al., 2017; Bahdanau et al., 2019; Ruis et al., 2020; Nikolaus et al., 2019) and language domains (Lake & Baroni, 2018; Keysers et al., 2020; Kim & Linzen, 2020; Shaw et al., 2021; Yin et al., 2021; Gan et al., 2022).",1,neutral
"…2018; Loula et al., 2018), including specialized design of neural model architectures (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021; Russin et al., 2019; Li et al., 2019; Gordon et al., 2020; Herzig & Berant, 2021) and training algorithms (Lake, 2019; Kim, 2021),…",2,positive
"As an illustration of the context-free nature of SCAN, consider the expression “walk twice”, which always translates to “WALK WALK”.",1,neutral
"While the performance of least-to-most prompting on SCAN is impressive, it is not clear whether and how the same technique can be applied to compositional generalization problems that are based on a more realistic subset of natural language.",1,neutral
"As discussed in Section 2.3, decomposition is more challenging for realistic tasks such as CFQ and COGS than for artificial tasks like SCAN.",1,neutral
"Single Prompt Insufficient to Represent Full Label Space In the case of SCAN, the knowledge needed to translate a command into a sequence of actions is small enough that it can be captured with about a dozen examples.",1,neutral
", 2018), including specialized design of neural model architectures (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021; Russin et al., 2019; Li et al., 2019; Gordon et al., 2020; Herzig & Berant, 2021) and training algorithms (Lake, 2019; Kim, 2021), training data augmentation (Andreas, 2020; Akyürek et al.",2,positive
"While 100% accuracy has been accomplished on SCAN (Chen et al., 2020; Nye et al., 2020; Liu et al., 2020; Shaw et al., 2021), good performance on SCAN does not necessarily transfer to more challenging compositional generalization problems (Furrer et al., 2020).",2,positive
"Natural Language is Challenging to Decompose SCAN commands are constructed from eight distinct symbols with a fixed precedence (“left”, “right”, “twice”, “thrice”, “opposite”, “around”, “and”, and “after”).",1,neutral
"In practice, the decomposition for SCAN can be predicted by a language model using a simple prompt.",1,neutral
"SCAN (Lake & Baroni, 2018; Loula et al., 2018) is one of the earliest benchmarks that shows neural sequence models cannot systematically generalize to novel combinations of the primitive items of the language.",1,neutral
"Also, decomposing a problem is more difficult than with SCAN, exacerbated by constituents that cannot be translated independent of their context.",1,neutral
"Most recently, Zhou et al. (2022) demonstrate that SCAN can be solved by least-to-most prompting, which leverages a pretrained large language model (LLM) and a prompt consisting of only 14 exemplars, which is less than 0.1% of the training data used by previous approaches.",2,positive
"Shaw et al. (2021) already reported that T5-Base model struggles in most splitting strategies, particularly when using length-based split and TMCD split; we reproduce those results in Table 1 in rows T5-Base and T5-3B.",1,neutral
"Shaw et al. (2021)
propose Spider-SSP, a dataset that can be used to measure the compositional generalization of SQL generation methods.",1,neutral
", 2019), Spider-SSP (Shaw et al., 2021), and CoSQL (Yu et al.",2,positive
"Thus, in order to properly evaluate and compare methods’ performance, multiple benchmark datasets have been proposed, namely Spider (Raffel et al., 2019), Spider-SSP (Shaw et al., 2021), and CoSQL (Yu et al., 2019).",2,positive
"We evaluate T5QL on three benchmark datasets: Spider (Raffel et al., 2019), Spider-SSP (Shaw et al., 2021), and CoSQL (Yu et al., 2019).",2,positive
"To the best of our knowledge, Shaw et al. (2021) were the first to propose a method that uses an LLM, namely T5, and evaluate it on Spider.",2,positive
"Thus, we evaluate two different models: T5-Base, which is similar to the model evaluated by Shaw et al. (2021), and T5QL-Base wo/ CD which is T5QL without the constrained decoding component (and without the ranker).",2,positive
"Following previous implementation5, α in DBCA is set as 0.1 and 0.5 for DBCAa and DBCAc, respectively.",2,positive
"Different datasets have therefore been introduced to support the compositional generalization research on Language-driven Navigation [28], [29], Question Answering [6], [30], [31], Emergent Languages [32] and text2SQL [33].",1,neutral
"I, existing work [5], [6] has proposed their method based on distribution-based compositional assessment (DBCA) to create compositional splits for KBQA",2,positive
"Next, DBCAa is derived from the frequency of cluster indexes after traversing the expression tree.",1,neutral
The detailed algorithm could be found in original work [5].,1,neutral
"The compositional data sets all have high DBCAc but low DBCAa, which indicates the datasets indeed follow our expected objective of maximizing the compound divergence with great control of small constituent divergence.",2,positive
"C L
] 3
S ep
2 02
2
on the one hand, we adopt a data splitting method, which is built upon DBCA [5] and holds the objective of maximizing the compositional gap with control of constituent difference between training and test.",2,positive
"Therefore, it is reasonable for us to split MWPs data and obtain the compositional data sets with DBCAc performing as the measurement criteria.
b) Effect of Different Composition Types: SD dataset that we introduced in Sec.",2,positive
"We choose k value from range {5, 10, 20} based on the highest DBCAc it could achieve after splitting.",2,positive
built upon DBCA [5] and holds the objective of maximizing the compositional gap with control of constituent difference between training and test.,2,positive
"Like many other tasks such as Question Answering [5], [6], MWP solving methods are expected to exhibit Compositional Generalization, an important capability to handle novel compositions of known components after learning the “rules of composition” from the training data.",1,neutral
"In more detail, they obtain atom and compound distributions based on their frequencies, and then compute Atom Divergence DBCAa and Compound Divergence DBCAc, respectively.",1,neutral
"I, existing work [5], [6] has proposed their method based on distribution-based compositional assessment (DBCA) to create compositional splits for KBQA task, which could be summarized as follows:
• Each data is represented using a graph, where the nodes are considered as Atoms and the rule applications on the graph are treated as Compounds.",2,positive
"As we can see, the performance of MathEN on both Math23K and MAWPS datasets decreases dramatically with the increase of compound divergence DBCAc.",2,positive
"To obtain DBCAc, we exhaustively search sub-expression trees in a complete expression tree.",1,neutral
"• A distribution-based compositional assessment [6] is utilized to measure the divergence: DBCA(Dp,Dq) = 1−Cα(P‖Q), where Cα(P‖Q) = ∑ i p α i q 1−α i ∈ [0, 1] is
the Chernoff coefficient [34], P and Q are distributions deriving from training and test sets, respectively.",1,neutral
"• Starting from a data pool D, they apply a greedy algorithm to assign each data to form Dp and Dq , the objective of which is to maximize DBCAc with the control of an upper bound of DBCAa.",1,neutral
"There are also several works [46, 66, 67] which neglect the SQL grammar during the decoding process, by leveraging the powerful large scale pre-trained language model like T5 [68] finetuned on the text-to-SQL training set for SQL query generation.",1,neutral
"Architectures and training methods that target this specific problem are often developed based on synthetic tasks whose creation rules are known (Das et al., 1992; Li et al., 2019b; Russin et al., 2019; Andreas, 2020; Liu et al., 2020a; Chen et al., 2020; Herzig and Berant, 2021; Shaw et al., 2021; Zhu et al., 2021).",1,neutral
"…methods that target this specific problem are often developed based on synthetic tasks whose creation rules are known (Das et al., 1992; Li et al., 2019b; Russin et al., 2019; Andreas, 2020; Liu et al., 2020a; Chen et al., 2020; Herzig and Berant, 2021; Shaw et al., 2021; Zhu et al., 2021).",1,neutral
"Other splitting methods also exist to help different research topics (Shaw et al., 2021; Chang et al., 2020).",1,neutral
"Shaw et al. (2021) use a hybrid model which firstly uses a high precision grammar-based approach (NQG) to generate SQL queries, then uses T5 (Raffel et al., 2019) as a back-up if NQG fails.",2,positive
"We report results on the standard data split as well as three compositional splits based on those introduced in Shaw et al. (2021): (1) the template split, where abstract output templates in training and test data are disjoint (Finegan-Dollak et al., 2018); (2) the TMCD split, which makes the…",2,positive
"Despite their strong performance on many tasks, pre-trained language models1 (LMs) such as T5 (Raffel et al., 2020) have been shown to struggle on compositional generalization (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021).",1,neutral
"…flat or negative scaling curves when fine-tuning LMs except on the CFQ dataset, suggesting scaling with full finetuning is unlikely to be an effective solution for compositional generalization in semantic parsing as observed in Shaw et al. (2021), Herzig et al. (2021), and Furrer et al. (2020).",1,neutral
", 2021), ensemble models (Shaw et al., 2021), different Transformer variations (Csordás et al.",1,neutral
"Full fine-tuning of model parameters is a standard approach for applying LMs to end tasks, and T5 performance with fine-tuning has been measured for compositional generalization up to the scale of 11 billion parameters (Shaw et al., 2021; Furrer et al., 2020).",2,positive
", 2020) have been shown to struggle on compositional generalization (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021).",1,neutral
"We define compounds as combinations of parent and child symbols in the output, similarly to Shaw et al. (2021).",1,neutral
"…2020; Chen et al., 2020; Zheng and Lapata, 2021; Oren et al., 2020; Herzig and Berant, 2021; Ruiz et al., 2021; Wang et al., 2021), ensemble models (Shaw et al., 2021), different Transformer variations (Csordás et al., 2021; Ontanón et al., 2021), intermediate representations (Herzig et al., 2021;…",2,positive
"In the prompt constructed to solve SCAN, we actually used both natural language and Python notation.",2,positive
The full prompt contexts for SCAN are shown in Appendix B.1.,0,negative
The 14 command-mapping demonstration examples are supposed to be able to fully cover the semantics of SCAN commands.,2,positive
"One contains 8 command-reduction examples to demonstrate how to reduce a long command to a list of short commands (see some of them in Table 6), and the other contains 14 command-mapping examples to demonstrate how
4See the “length train-test split” section in https://github.com/brendenlake/SCAN.",2,positive
In this section we present the prompt contexts used for the SCAN benchmark in Section 3.2.,2,positive
"The two benchmarks considered in this paper, SCAN (Lake & Baroni, 2018) and DROP (Dua et al., 2019), have often been tackled by neural-symbolic methods (Andor et al., 2019; Chen et al., 2019, 2020; Nye et al., 2020; Shaw et al., 2021; Kim, 2021).",1,neutral
"SCAN (Lake & Baroni, 2018) is probably the most popular benchmark for evaluating compositional generalization.",1,neutral
", 2019), have often been tackled by neural-symbolic methods (Andor et al., 2019; Chen et al., 2019, 2020; Nye et al., 2020; Shaw et al., 2021; Kim, 2021).",1,neutral
"We show here that SCAN can essentially be solved using least-to-most prompting with 14 examples, compared to those neural-symbolic methods where the full training set is used.",1,neutral
"Many specialized neural-symbolic models have been proposed to solve SCAN (Chen et al., 2020; Nye et al., 2020; Shaw et al., 2021; Kim, 2021).",1,neutral
", 2020) and natural benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2020), researchers have been studying systematic generalization of existing semantic parsing methods as well as proposing new approaches such as",1,neutral
"Using synthetic (Bahdanau et al., 2019; Kim and Linzen, 2020a; Keysers et al., 2020) and natural benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2020), researchers have been studying systematic generalization of existing semantic parsing methods as well as proposing new approaches such as…",1,neutral
We align most of the hyperparameter settings with Shaw et al. (2021) to provide a fair comparison.,2,positive
We mostly follow Shaw et al. (2021) and Scholak et al. (2021) to serialize the inputs.,2,positive
"Recent attempts by Shaw et al. (2021) show that directly fine-tuning a T5 model (Raffel et al., 2020) on this task without presenting any relational structures could achieve satisfying results.",1,neutral
"Recently, Shaw et al. (2021) showed that finetuning a pre-trained T5-3B model could yield results competitive to the then-state-of-the-art.",2,positive
", 2022), T5 (Shaw et al., 2021) and PICARD (Scholak et al.",1,neutral
"Experiments with111 RATSQL+GAP (Shi et al., 2021) show that our112 Spider-CG is more challenging than the existing113 TMCD split (Shaw et al., 2021).114 To improve the generalization performance of115
text-to-SQL models, we modify several previous 116 state-of-the-art models so that they can be…",2,positive
"Ensuring a 049 reasonable data split may also lead to a reduction in 050 dataset size: e.g., the training set drops from 7000 051 to 3282 in the Spider TCMD split (Yu et al., 2018b; 052 Shaw et al., 2021).",0,negative
"On the other hand, Shaw et al. (2021) in- 559 troduces TMCD splits for studying compositional 560 generalization in semantic parsing, where they aim 561 to maximize the divergence of SQL compounds 562 between the training and test sets.",1,neutral
"For non-KG semantic parsing, PLMs have been evaluated recently with a focus on compositional generalisation [30].",1,neutral
"Subsequent work has yielded a number of studies that attempt to identify properties of datasets (Keysers et al., 2020; Shaw et al., 2021) and instances (Bogin et al., 2022; Tamari et al., 2021) that make generalization hard and use these properties to construct hard generalization splits.",1,neutral
"Subsequent work has yielded a number of studies that attempt to identify properties of datasets (Keysers et al., 2020; Shaw et al., 2021)",1,neutral
"For instance, it has been applied to the text-to-SQL generation problem [15, 43], where the output is a code to be executed.",1,neutral
"…based on a fine-grained schema of generalization patterns like this work (Bahdanau et al., 2019; Keysers et al., 2020; Kim & Linzen, 2020), or by repartitioning existing datasets with i.i.d. samples into splits with disjoint compositional structures (Finegan-Dollak et al., 2018; Shaw et al., 2021).",2,positive
"samples into splits with disjoint compositional structures (Finegan-Dollak et al., 2018; Shaw et al., 2021).",1,neutral
"Non-invasive Approaches T5-Base (Shaw et al., 2021) 57.",1,neutral
"We compare GPT-3 and Codex against methods from Shaw et al. (2021) using the T5 encoder-decoder
1See Appendix A.2 for a discussion on parameter counts.
ar X
iv :2
20 4.",2,positive
"A clear trend in this area is to finetune models pretrained on natural language; notably, performance significantly improves as larger pretrained models are used (Shaw et al., 2021; Scholak et al., 2021).",1,neutral
"Recent work has introduced several compositional data augmentation schemes: rule-based procedures or learned models that synthesize artificial training examples to promote generalization (Andreas, 2020; Shaw et al., 2021; Akyürek et al., 2021; Zhang et al., 2022, inter alia).",2,positive
"Data Augmentation Data augmentation approaches are widely used across machine learning application domains featuring known invariances of the data distribution (Japkowicz et al., 2000; Jia and Liang, 2016; Shaw et al., 2021).",1,neutral
"While previous works also cast SKG tasks into the textto-text format (Hosseini-Asl et al., 2020; Shaw et al., 2021; Liu et al., 2021), their independent choices of pretrained language models (PLMs), input-output formats, and frameworks make our unification non-trivial.",2,positive
"However, since MCD and TMCD were designed to generate compositional splits, they were not tested on whether they predict difficulty of other splits, such as the template split.",1,neutral
"Similarly to TMCD, we define atoms and compounds over the program tree T , over the graph defined in §4.1.",1,neutral
"As discussed (§4.4), Maximum Compound Divergence (MCD) and its variation TMCD, are recently proposed metrics for estimating the difficulty of a test set, while we measure difficulty at the in-
stance level.",1,neutral
"Measuring compositional difficulty The most closely related methods to our work are MCD and its variation TMCD (Keysers et al., 2020; Shaw et al., 2021), designed to create compositional splits.",2,positive
"In addition, while in TMCD the difficulty is over an entire test set, we predict the difficulty of specific instances.",1,neutral
"In MCD, it is created from the tree of derivation rules that generates the program, and in TMCD from the program parse tree, similar to our approach.",2,positive
"We measure compound divergence of the distributions of compounds and atoms on the program graph, following Keysers et al. (2020) and Shaw et al. (2021).",2,positive
"TMCD The MCD and TMCD methods (Keysers et al., 2020; Shaw et al., 2021) have been used to create compositional splits, by maximizing compound divergence across the training and test splits.",1,neutral
"While the two
methods are not directly comparable, since we focus on instance-level generalization, we extend our approach for computing the easiness of a split and compare to TMCD in §5.",2,positive
"For TMCD, we compute the compound divergence of each split (high compound divergence indicates a more difficult split, or lower easiness) following Shaw et al. (2021), see details in App.",1,neutral
"Instancelevel analysis can better characterize the challenges of compositional generalization, and as we show in §5.2 it is a better predictor of difficulty compared to TMCD even at the split level.",2,positive
"Automatic methods include splitting examples by output length (Lake and Baroni, 2018), by anonymizing programs (Finegan-Dollak et al., 2018), and by maximizing divergence between distribution across the training and test set (Keysers et al., 2020; Shaw et al., 2021).",1,neutral
", 2020) and COGS (Kim and Linzen, 2020) have been created, and several approaches achieve good performance on these tasks, the out-of-distribution generalization ability of state-of-the-art models on real-world, nonsynthetic tasks is still far from sufficient (Shaw et al., 2021; Yin et al., 2021).",2,positive
18We do not show LeAR results for SCAN and GeoQuery as Liu et al. (2021) did not report results for SCAN and reported GeoQuery results using a different template split and a different evaluation metric.,0,negative
"GeoQuery We use the same variant of FunQL (Kate et al., 2005) as Shaw et al. (2021), with entities replaced with placeholder values.",2,positive
"However, these models often perform poorly on out-of-distribution compositional generalization tasks (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021).
ar X
iv :2
11 2.",1,neutral
"19Some of our results for NQG-T5 are different than those reported in Shaw et al. (2021) as we average over 3 new GeoQuery template and TMCD splits, as described in §4.1.",0,negative
"In contrast, specialized architectures with discrete latent structure (Chen et al., 2020; Liu et al., 2020; Nye et al., 2020; Herzig and Berant, 2021; Shaw et al., 2021) have made strides in compositional generalization, but without task-specific engineering or ensembling, the gains have been limited to synthetic semantic parsing tasks.",1,neutral
"CSL and NQG of Shaw et al. (2021) vary across several dimensions, as the two systems use different grammar induction algorithms and different model parameterizations.",1,neutral
"For the TMCD splits, we changed the atom constraint slightly, based on the error analysis in Shaw et al. (2021) which found that a disproportionate amount of the errors on the TMCD test set were in cases where an “atom” was seen in only a single context during training.",2,positive
T5 Fine-Tuning We started with the same configuration for fine-tuning T5 as Shaw et al. (2021).,2,positive
"For SCAN, NQG-T5 (Shaw et al., 2021) is one of several specialized models that achieves 100% accuracy across multiple splits (Chen et al., 2020; Liu et al., 2020; Nye et al., 2020; Herzig and Berant, 2021).",2,positive
"…contrast, specialized architectures with discrete latent structure (Chen et al., 2020; Liu et al., 2020; Nye et al., 2020; Herzig and Berant, 2021; Shaw et al., 2021) have made strides in compositional generalization, but without task-specific engineering or ensembling, the gains have been…",2,positive
"…2021; Ruiz et al., 2021; Wang et al., 2021a), different Transformer variations (Csordás et al., 2021; Ontanón et al., 2021), ensemble models (Shaw et al., 2021), intermediate representations (Herzig et al., 2021), meta-learning (Lake, 2019; Conklin et al., 2021; Zhu et al., 2021), and…",2,positive
"…(x ∈ XCSL) to x /∈ XCSL.
Comparison with NQG We cannot compare using CSL for data augmentation directly with using its closely related predecessor NQG (Shaw et al., 2021) for data augmentation, as NQG is a discriminative parsing model and not a probabilistic generative model that enables sampling…",1,neutral
"Comparison with NQG We cannot compare using CSL for data augmentation directly with using its closely related predecessor NQG (Shaw et al., 2021) for data augmentation, as NQG is a discriminative parsing model and not a probabilistic generative model that enables sampling new examples.",2,positive
", 2021), ensemble models (Shaw et al., 2021), intermediate representations (Herzig et al.",1,neutral
"We report results on the standard data split as well as three compositional splits based on those introduced in Shaw et al. (2021): the template split (where abstract output templates in training and test data are disjoint (Finegan-Dollak et al., 2018)), the TMCD split (an extension of MCD for…",2,positive
"For SCAN, NQG-T5 (Shaw et al., 2021) is one of several specialized models that achieves 100% accuracy across multiple splits (Chen et al.",1,neutral
Using CSL for data augmentation outperforms using GECA on SCAN and GeoQuery.,2,positive
"Our method for inducing a QCFG is based on that of Shaw et al. (2021), but with several modifications, which improve the computational scalability of the algorithm as well as the precision and coverage of the induced grammar.",2,positive
"However, these models often perform poorly on out-of-distribution compositional generalization tasks (Lake and Baroni, 2018; Furrer et al., 2020; Shaw et al., 2021).",1,neutral
"CSL builds on the NQG model of Shaw et al. (2021), a discriminative parsing model over an induced QCFG backbone, which Shaw et al. (2021) proposed to ensemble with T5.",2,positive
"CSL builds on the NQG model of Shaw et al. (2021), with several key differences discussed in the following sections:
• Unlike NQG, which is discriminative, CSL is a generative model that admits efficient sampling from the joint distribution p(x, y).",2,positive
"Prior work found T5-Base to perform best on the compositional splits of SCAN and GeoQuery (Furrer et al., 2020; Shaw et al., 2021).",2,positive
"…rules in §3.
be quasi-synchronous (Smith and Eisner, 2006) because we allow a one-to-many alignment between non-terminals.6 Unlike the formalism of Shaw et al. (2021), which limited rules to contain ≤ 2 nonterminals, in the current work the maximal number of non-terminals is a configurable…",1,neutral
"We generate new length, template, and TMCD splits following the methodology of Shaw et al. (2021), so that we could evaluate our method on dev sets, which the original splits did not include.",2,positive
"…2020) and COGS (Kim and Linzen, 2020) have been created, and several approaches achieve good performance on these tasks, the out-of-distribution generalization ability of state-of-the-art models on real-world, nonsynthetic tasks is still far from sufficient (Shaw et al., 2021; Yin et al., 2021).",2,positive
"…and θ given D would be to find the MAP estimate based on some prior, p(G, θ), that encourages compositionality:
argmax G,θ p(G, θ)× ∏ 〈x,y〉∈D pG,θ(x, y) (5)
However, since optimizing G and θ jointly is computationally challenging, we adopt a two-stage process similar to that of Shaw et al. (2021).",1,neutral
"Namely, it has been shown to perform competitively on different text-to-SQL datasets, regardless of their SQL conventions (Shaw et al., 2021; Herzig et al., 2021).",2,positive
"Following past work (Shaw et al., 2021; Herzig et al., 2021), we fine-tune T5 to map text to SQL.",2,positive
"Recently, there has been a growing interest in compositional generalization in the NLIs to other formal representations [3, 13, 15, 17, 19, 21, 26] which enables these systems to systematically compose complex examples after being exposed to simple components during training.",1,neutral
[26] both evaluated their models on a subset of GeoQuery dataset splits and achieved strong performance.,2,positive
"specialized architecture models [3, 19, 21, 26] which learn and incorporate grammar or structure to tackle compositional generalization challenges.",1,neutral
"[26] highlighted in their work that evaluating NLIs on a diverse set of benchmarks is important and the performance on synthetic datasets [15, 17] is not well-correlated with performance on nonsynthetic tasks with natural language variation.",1,neutral
The only method with perfect scores on all SCAN split which doesn’t require task specific resources is NQG-T5 [26].,1,neutral
[26] leveraged the GeoQuery dataset [32] to evaluate the compositional generalization on a non-synthetic dataset.,1,neutral
"While these models fail in Length splits for both SCAN and Okapi datasets, several models with specialized architectures [19, 26] have been proposed for SCAN dataset which achieve 100% accuracy on Length and MCD splits.",1,neutral
We use the MCD split generated for SCAN from Keysers et al. (2020) and the Target Maximum Compound Divergence (TMCD) splits generated for GeoQuery from Shaw et al. (2021).,2,positive
"We use the same pre-processing as in Shaw et al. (2021), replacing entity mentions with placeholders in the Functional Query Language (FunQL; Kate et al. 2005) output representations.",2,positive
"For GEO cd, our approach beats the state-of-the-art, established by a hybrid neurosymbolic model (Shaw et al., 2021); for GEO len, we substantially improved over the baselines.",2,positive
"In particular, pre-finetuning on SCAN cd leads to an accuracy of 57.8% on GEO TMCD2, surpassing — with a neural-only approach — the previous state-of-the-art of 56.6%, which was established by NQG-T5, a hybrid model that combines a grammar-based approach with T5 (Shaw et al., 2021).",2,positive
"The state-of-the-art results on this task is 52.2% from the NQG-T5 model (Shaw et al., 2021).",0,negative
We adopt the length and TMCD splits from Shaw et al. (2021).,2,positive
"6%, which was established by NQG-T5, a hybrid model that combines a grammar-based approach with T5 (Shaw et al., 2021).",2,positive
"…NLP. Specifically, recent work has proposed new or
modified model architectures (Li et al., 2019; Russin et al., 2019; Gordon et al., 2020; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020b; Zheng & Lapata, 2020; Oren et al., 2020; Herzig & Berant, 2020; Shaw et al., 2021; Yin et al., 2021).",2,positive
"Recent work has spotlighted significant shortcomings of neural network approaches to NLP in coping with compositional generalization (CG) (Lake & Baroni, 2018; Finegan-Dollak et al., 2018; Keysers et al., 2020; Kim & Linzen, 2020; Shaw et al., 2021).",1,neutral
"Recently, it has been shown that T5 can be successfully fine-tuned on a large-scale text-to-sql dataset (Shaw et al., 2021; Scholak et al., 2021).",2,positive
", 2020) and natural benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2020), researchers have been studying systematic generalization of existing semantic parsing methods as well as proposing new approaches such as",1,neutral
"Using synthetic (Bahdanau et al., 2019; Kim and Linzen, 2020a; Keysers et al., 2020) and natural benchmarks (Finegan-Dollak et al., 2018; Shaw et al., 2020), researchers have been studying systematic generalization of existing semantic parsing methods as well as proposing new approaches such as…",1,neutral
"These predicates correspond to the “compounds” defined in (Keysers et al., 2020; Shaw et al., 2020), and the objective is to maximize the divergence between compound distribution of the evaluation data to the training data.",2,positive
"To generate evaluations of compositional generalization, we use a method similar to that of Shaw et al. (2020) and Keysers et al. (2020) which maximizes compound divergence between the distribution of compounds in the evaluation set and in the training set.",2,positive
"We validate the generalization capability of COMPOSER by designing an evaluation procedure for a more challenging compositional generalization task that uses test examples with maximum compound divergence (MCD) to the training data (Shaw et al., 2020; Keysers et al., 2020).",2,positive
"As mentioned in the main text, we generate compositional generalization (CG) splits with 1,000 images and 5,000 text queries, maximizing the Compound Divergence (MCD) as Shaw et al. (2020)3, to assess models’ capability in generalizing to the data with different predicate distribution.",2,positive
"Following Shaw et al. (2021); Hazoom et al. (2021), we use T5 as our baseline model.",2,positive
"Similar to Shaw et al. (2021), we identify examples from training set databases that contain more than 50 examples to ensure sufficient coverage over table and column names in the training data.",2,positive
"Following Shaw et al. (2021), we adopt a setting similar to an alternative setting called the example split in the original dataset (Yu et al., 2018) where the databases are shared between train and test examples.",2,positive
"However, the follow-up studies from Deng et al. (2021); Gan et al. (2021); Suhr et al. (2020); Shaw et al. (2021); Oren et al. (2020); Keysers et al. (2020)
1Our dataset is available at https://github.com/ygan/SpiderDK.
show that the generalization performance is much worse in more challenging…",2,positive
We use the same serialization scheme used by Shaw et al. (2021).,2,positive
"We are encouraged by results by Shaw et al. (2021), who showed that a pre-trained T5-Base or T5-3B model can not only learn the text-toSQL task, but also generalize to unseen databases, and even that T5-3B can be competitive with the then-state-of-the-art (Choi et al., 2021; Wang et al., 2020)—all…",2,positive
Our reproductions of Shaw et al. (2021)’s results with T5 cannot compete with the current state of the art on Spider.,0,negative
"…model architectures (Li et al., 2019; Gordon et al., 2020; Guo et al., 2020b; Oren et al., 2020; Zheng and Lapata, 2020; Herzig and Berant, 2021; Shaw et al., 2020), pre-trained language models (Furrer et al., 2020), intermediate representations (Herzig et al., 2021), and meta learning (Lake,…",2,positive
"Recently, Keysers et al. (2020) and Shaw et al. (2020) used the notion of sub-structures, to construct a compositional test set.",1,neutral
"There has since been a large body of work on compositional sequence-tosequence learning through various approaches including modifications to existing architectures [70, 94, 44, 17, 26], grammars and neuro-symbolic models [86, 98, 85, 19, 76], meta-learning [67, 25], and data augmentation [6, 49, 50, 4].",1,neutral
Our approach is closely related to NQG-T5 [98] which uses a rules-based approach to induce a non-probabilistic QCFG and then backs off to a flexible sequence-to-sequence model during prediction if the grammar cannot parse the input sequence.,2,positive
"In fact, the existing SCAN-inspired solutions have limited performance gains on other datasets (Furrer et al., 2020; Shaw et al., 2020).",2,positive
"Although some related work managed to improve compositional generalization on general semantic parsing tasks [113], [114], there is few work investigating this topic on complex KBQA task.",1,neutral
"Such studies typically focus on either MT (Lake and Baroni, 2018; Raunak et al., 2019; Li et al., 2021) or semantic parsing (Finegan-Dollak et al., 2018; Keysers et al., 2019; Kim and Linzen, 2020; Shaw et al., 2021).",1,neutral
"[10] claim that the SCAN benchmark does not correlate well with non-synthetic data, and argue that most research on compositional generalization focuses on specialized architectures that introduce strong compositional biases.",1,neutral
", 2020), language modeling (Andreas, 2020; Shaw et al., 2020), and text generation (Feng et al.",1,neutral
"Thus, following Shaw et al. (2020), we use a general-purpose pretrained sequence-to-sequence model, T5 (Raffel et al., 2020), which was shown to be competitive with Spider’s state-of-the-art models.",2,positive
"Neural semantic parsing is more promising for coverage but is still brittle in real-world applications where queries can involve novel compositions of learned patterns (Finegan-Dollak et al., 2018; Shaw et al., 2020).",1,neutral
"Grammars have proven essential in statistical semantic parsing in the pre-neural era [51, 57], and have gained renewed interest now as a means of achieving systematic generalization [18, 41].",1,neutral
"Thus, our model bridges the gap between conventional seq2seq models and specialized state-of-the-art grammar-based models [18, 41].",2,positive
"6 We use the varaible-free form, as opposed to other alternatives such lambda calculus, for two reasons: 1) variable-free programs have been commonly used in systematic generalization settings [18, 41], probably it is easier to construct generalization splits using this form; 2) the variable-free form is more suitable for modeling alignments since variables in programs usually make alignments hard to define.",1,neutral
"Pre-trained encoder-decoder transformer models such as BART (Lewis et al., 2020a) and T5 (Raffel et al., 2020) have enjoyed dramatic success on semantic parsing (Lin et al., 2018; Hwang et al., 2019; Shaw et al., 2020; Suhr et al., 2020).",2,positive
", 2020) have enjoyed dramatic success on semantic parsing (Lin et al., 2018; Hwang et al., 2019; Shaw et al., 2020; Suhr et al., 2020).",1,neutral
"performance in general remains a significant challenge (Shaw et al., 2020; Furrer et al., 2020).",2,positive
", 2020; Herzig and Berant, 2020), hybrid models (Shaw et al., 2020), meta-learning (Lake, 2019), and compositional data augmentation (Andreas, 2020).",2,positive
"…(Li et al., 2019; Russin et al., 2019; Gordon et al., 2020; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020; Zheng and Lapata, 2020; Oren et al., 2020; Herzig and Berant, 2020), hybrid models (Shaw et al., 2020), meta-learning (Lake, 2019), and compositional data augmentation (Andreas, 2020).",2,positive
"For both our T5 baseline and LIRd+RIR, further increasing model capacity beyond T5-base does not give further improvements, which is consistent with previous work on similar tasks with small train set sizes (Shaw et al., 2020; Furrer et al., 2020).",0,negative
"…Chen et al., 2020, inter alia) and general-purpose pre-trained seq2seq models such as T5 (Raffel et al., 2020) have shown improvements on some evaluations of compositional generalization, but strong performance in general remains a significant challenge (Shaw et al., 2020; Furrer et al., 2020).",2,positive
"our T5 baseline and LIRd+RIR, further increasing model capacity beyond T5-base does not give further improvements, which is consistent with previous work on similar tasks with small train set sizes (Shaw et al., 2020; Furrer et al., 2020).",0,negative
", 2019c) can significantly boost parsing accuracy by enhancing generalization over natural language variations and capturing long-term dependencies (Shaw et al., 2020).",2,positive
"Finally, concurrently to us, Shaw et al. (2020) induced a synchronous grammar over program and utterance pairs and used it to introduce a compositional bias, showing certain improvements over compositional splits.",1,neutral
"Following previous works, we conduct the “productivity” experiment (Lake and Baroni, 2018; Shaw et al., 2021), which focuses on generalization to longer sequences or to greater compositional depths than have been seen in training (for example, from a length 4 program to a length 5 program).",2,positive
"…2020; Oren et al., 2020; Akyurek and Andreas, 2021; Chaabouni et al., 2021), meta-learning (Lake, 2019; Conklin et al., 2021), grammar (Kim, 2021; Shaw et al., 2021), neuro-symbolic models (Chen et al., 2020; Liu et al., 2020; Nye et al., 2020), data augmentation (Andreas, 2020; Akyürek et al.,…",2,positive
", 2021), grammar (Kim, 2021; Shaw et al., 2021), neuro-symbolic models (Chen et al.",1,neutral
"To support Text-to-SQL, similar to [24, 26], we fine-tune the model in an end-to-end manner.",2,positive
"Different from the previous methods with task-specific design, PLM-based methods [24, 26] can be applied to different text-to-SQL datasets without specific modifications to the base PLMs.",1,neutral
"Specifically, Picard [24] and [26] also achieve good performance in the few-shot scenario using general PLMs (e.",1,neutral
"Transformer-based encoder-decoder models have been widely used to support Text-to-SQL, and representative models include NQG-T5 [26], PICARD [24], UnifiedSKG [34], etc.",1,neutral
"With the recent advances in pre-trained language models (PLMs), many existing works formulate the Text-to-SQL task as a semantic parsing problem and use a sequence-tosequence (seq2seq) model to solve it (Scholak, Schucher, and Bahdanau 2021; Shi et al. 2021; Shaw et al. 2021).",1,neutral
"Following Shaw et al. (2021); Scholak, Schucher, and Bahdanau (2021), we treat Text-to-SQL as a translation task, which can be solved by an encoder-decoder transformer model.",2,positive
"However, even the T5-3B model only achieves about 70% accuracy (Shaw et al. 2021; Scholak, Schucher, and Bahdanau 2021).",2,positive
"Although it is easier to define these distributions for synthetic data, as in the CFQ dataset described by Keysers, it can also be applied to natural data, for example in semantic parsing (Shaw et al., 2021).",1,neutral
"On the other hand, humans and classical AI algorithms (grammar and search-based systems) are not troubled by compositional tasks [6, 7].",1,neutral
"The existing work surrounding compositional generalization includes a variety of approaches including data augmentation [9, 10, 11], Syntactic Attention [12], compositional parsers [6, 13], intermediate representations [14, 15] and structure annotations [7].",1,neutral
"Compositional Generalization has attracted increasing attention with dedicated datasets (Lake and Baroni, 2018; Keysers et al., 2020a; Kim and Linzen, 2020; Li et al., 2021; Shaw et al., 2021; Dankers et al., 2022).",2,positive
"This model has been shown to have a strong performance on a variety of NLP tasks ranging from classification to generation problems [23, 29, 48].",1,neutral
"…been created automatically from existing semantic parsing datasets by splitting by output length (Lake and Baroni, 2018), holding out program templates (Finegan-Dollak et al., 2018), and by maximizing compound divergence between the training and test sets (Keysers et al., 2020; Shaw et al., 2021).",2,positive
"Our work, especially that on sampling diverse test sets, is also related to work on creating compositional splits from existing datasets (Keysers et al., 2020; Shaw et al., 2021; Bogin et al., 2022) and reducing biases in datasets via adversarial filtering or other means (Bras et al.",2,positive
"…that on sampling diverse test sets, is also related to work on creating compositional splits from existing datasets (Keysers et al., 2020; Shaw et al., 2021; Bogin et al., 2022) and reducing biases in datasets via adversarial filtering or other means (Bras et al.,
2020; Sakaguchi et al.,…",1,neutral
", 2018), and by maximizing compound divergence between the training and test sets (Keysers et al., 2020; Shaw et al., 2021).",2,positive
"…based on a fine-grained schema of generalization patterns like this work (Bahdanau et al., 2019; Keysers et al., 2020; Kim & Linzen, 2020), or by repartitioning existing datasets with i.i.d. samples into splits with disjoint compositional structures (Finegan-Dollak et al., 2018; Shaw et al., 2021).",2,positive
"samples into splits with disjoint compositional structures (Finegan-Dollak et al., 2018; Shaw et al., 2021).",1,neutral
"Both approaches have generally shown that compositional generalization remains an important challenge (e.g., Shaw et al., 2021).",1,neutral
"This points to a fundamental tension between broad-coverage semantic parsing on natural text and the ability to generalize compositionally from structurally limited synthetic training sets (see also Shaw et al., 2021).",1,neutral
"For instance, Shaw et al. (2021) describe a synchronous grammar induction approach that achieves perfect accuracy on SCAN (Lake and Baroni, 2018), but has very low accuracy on corpora of naturally occurring text such as GeoQuery (Zelle and Mooney, 1996) and Spider (Yu et al., 2018).",1,neutral
"…in547 joint neural models of text and images.548
Data Augmentation Data augmentation ap- 549 proaches are widely used across machine learn- 550 ing application domains featuring known invari- 551 ances of the data distribution (Japkowicz et al., 552 2000; Jia and Liang, 2016; Shaw et al., 2020).",2,positive
"Following past work [23, 48] we use T5-large as our NL-to-SQL model.",2,positive
"As our NLIDB of choice, we follow past work [23, 48] and fine-tune the state-of-the-art T5 language model [40] on mapping NL-to-SQL.",2,positive
"Recent approaches have heavily relied on specialized architectures [19, 48, 58] combined with pre-trained language models [14, 33, 40].",1,neutral
"Specifically, we use theT5-large model [40] as it has been previously shown to perform competitively with state-of-the-art methods [11, 48].",2,positive
"sented with novel user utterances (Suhr et al., 2020; Radhakrishnan et al., 2020; Shaw et al., 2021), databases (Suhr et al.",2,positive
"…show that the models tend to fail on challenging cases that involve novel user expression (Suhr et al., 2020) and SQL structures (Suhr et al., 2020; Shaw et al., 2021), our diagnosis exposes more robustness issues in their surface form understanding (even with seemingly simple inputs), and…",2,positive
", 2020) and SQL structures (Suhr et al., 2020; Shaw et al., 2021), our diagnosis exposes more robustness issues in their surface form understanding (even with seemingly simple inputs), and highlights the importance of addressing such issues in the modeling foundation (Bommasani et al.",2,positive
"…when pre-
˚Work done during an internship at Salesforce Research.
sented with novel user utterances (Suhr et al., 2020; Radhakrishnan et al., 2020; Shaw et al., 2021), databases (Suhr et al., 2020) and SQL query structures (Finegan-Dollak et al., 2018; Suhr et al., 2020; Shaw et al., 2021).",2,positive
"[16] Peter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova.",0,negative
"However, their applicability to other datasets remains limited [15, 16].",0,negative
