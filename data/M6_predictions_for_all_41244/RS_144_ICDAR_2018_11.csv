text,target_M6_predict,target_predict_M6_label
"[2, 17, 18, 21, 22, 34, 43] extract table elements (cells or text lines) first, then employ a graph network to learn the relation of the extracted table elements.",1,neutral
"tional architecture, like graph network [Xue et al., 2021] or rule-based post-processing strategies [Qiao et al.",1,neutral
"Additionally, graph convolutional networks [4] are used to parse table structures.",1,neutral
"Graph Neural Network (GNN) based methods [3,6,17,18], as the name suggests, represent tables as graph structures.",1,neutral
"On the other hand, the problem of table structure recognition (TSR) is a lot more challenging and remains a very active area of research, in which many novel machine learning algorithms are being explored [3,4,5,9,11,12,13,14,17,18,21,22].",1,neutral
[27] [28] [29] [30] share the identical GNN structure.,1,neutral
The code of one paper (TGRNet; [35]) was executable after we contacted the original authors.,0,negative
[16]7 2021 Multi-Type -TD-TSR KI ICDAR 2019 ICDAR 2019 Track-B2 X X R Xue et al.[35]8 2021 TGRNet ICCV TableGraph ICDAR 2019 X X R,0,negative
TGRNet [9] designed a network to jointly predict the spatial locations and spanning information of table cells.,2,positive
"First, we compare LORE with models which directly predict logical locations including Res2TIM (Xue, Li, and Tao 2019) and TGRNet (Xue et al. 2021).",2,positive
We tune the model provided by Xue et al. (2021) on WTW dataset to make a thorough comparison.,2,positive
"The baseline meth-
ods can only produce passable results on relatively simple benchmarks of digital-born table images from scientific articles, i.e., TableGraph-24K.",1,neutral
"Xue et al. (2021) propose to perform ordinal classification of logical indices on each detected cell for TSR, which is close to our approach.",2,positive
"Since the markup language has plenty of control sequences formatting styles, they can be viewed as noise in labels and impede model training (Xue et al. 2021).",1,neutral
"C V
] 7
M ar
2 02
cal locations of table cells (Xue et al. 2021).",1,neutral
"…(Göbel et al. 2013), SciTSR-comp (Chi et al. 2019), PubTabNet (Zhong, ShafieiBavani, and Jimeno Yepes 2020),
TableBank (Li et al. 2020) and TableGraph-24K (Xue et al. 2021), as well as tables from scanned documents and photos, i.e., ICDAR-2019 (Gao et al. 2019) and WTW (Long et al. 2021).",2,positive
"2017) in LORE to avoid making additional assumptions about the distribution of table structure, rather than graph neural networks employed by previous methods (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021), which will be further discussed in experiments.",2,positive
"In experiment 2a, we replace the self-attention encoder with a graph-attention encoder similar to graph-based TSR models (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021) with an equal amount of parameters with LORE.",2,positive
"We evaluate LORE on a wide range of benchmarks, including tables in digital-born documents, i.e., ICDAR-2013 (Göbel et al. 2013), SciTSR-comp (Chi et al. 2019), PubTabNet (Zhong, ShafieiBavani, and Jimeno Yepes 2020),
TableBank (Li et al. 2020) and TableGraph-24K (Xue et al. 2021), as well as tables from scanned documents and photos, i.e., ICDAR-2019 (Gao et al. 2019) and WTW (Long et al. 2021).",2,positive
"In this section, we conduct comprehensive experiments to research and answer two key questions: 1) Is the proposed LORE able to effectively predict the logical locations of table cells from input images? 2) Does the LORE framework, modeling TSR as logical location regression, overcome the limitations and cover the abilities of other paradigms? For the first question, we compare LORE with baselines directly predicting logical locations (Xue, Li, and Tao 2019; Xue et al. 2021).",2,positive
"We also report the performance of cell spatial location prediction, using the F-1 score under the IoU threshold of 0.5, following recent works (Raja, Mondal, and Jawahar 2020; Xue et al. 2021).",2,positive
"2020) and TableGraph-24K (Xue et al. 2021), as well as tables from scanned documents and photos, i.",2,positive
"For the first question, we compare LORE with baselines directly predicting logical locations (Xue, Li, and Tao 2019; Xue et al. 2021).",2,positive
"…mechanism (Vaswani et al. 2017) in LORE to avoid making additional assumptions about the distribution of table structure, rather than graph neural networks employed by previous methods (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021), which will be further discussed in experiments.",2,positive
"The #1 instance indicates the cell annotation object located by polygon [[19,202], [92,204], [391,212], [391,227], [168,221], [18,217]], in the tenth row and the first column of table 1 (group id=1), spanning three columns, with the text content ""预计费用总额"".",1,neutral
"Reference [9] proposed a table graph reconstruction network for table structure recognition (TGRNet), which uses ResNet50 [10] to extract the rows and columns of the table image and the features of the original image for fusion, predicting the spatial coordinates, and used the graph convolutional networks (GCN) [11] to predict the logical coordinates.",2,positive
"[34, 37, 45, 66] treat these cells as nodes in a graph and train another Graph Neural Network (GNN) to predict the relations.",1,neutral
"have emerged as a powerful tool to tackle the problems of Key Information Extraction (KIE) [6,35], Document Layout Analysis (DLA) which includes wellstudied sub-tasks like table detection [25,26], table structure recognition [20,34] and table extraction [9], Visual Question Answering (VQA) [18,17], synthetic document generation [4] and so on.",1,neutral
TGRNet [50] designed a network to jointly predict the spatial locations and spanning information of table cells.,2,positive
"We take deep-learning-based GAN, CFM, TGRNet, and Faster RCNN, SSD as baselines.",2,positive
"Deep learning-based algorithms such as OSTU + MSVM-rbf (Multi-class Support Vector Machine) [13], GAN [14], CFM [15], TGRNet [16] have achieved good results.",1,neutral
"[16] Xue, Wenyuan, et al. ""TGRNet: A Table Graph Reconstruction Network for Table Structure
Recognition.""",1,neutral
"To obtain the table-structure, one creates an initial graph, where each of the text-cells becomes a node in the graph similar to [33, 34, 2].",1,neutral
"The success of DL has marked the revisiting of table structure parsing by [7], which inspired follow-up research [27, 1, 6, 2, 28, 29, 30, 19, 31, 18, 32, 17].",1,neutral
"[29] proposed TGRNet as an effective end-to-end trainable table graph construction network, which encodes a table by combining the cell location detection and cell relation prediction.",2,positive
[16] proposed TGRNet that jointly predicts the cell spatial location and logical location for the downstream table parsing task.,2,positive
"To answer questions over unstructured table images, both computer vision (CV) and natural language processing (NLP) methods are required [4, 10, 16, 17].",1,neutral
", SQA [5] and WikiSQL [18]) following the way in [16].",1,neutral
"For the table structure recognition, each of the text cells is represented as a vertex in the graph (Xue et al., 2019, 2021; Chi et al., 2019a).",1,neutral
