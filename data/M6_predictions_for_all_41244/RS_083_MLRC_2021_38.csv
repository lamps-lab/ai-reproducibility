text,target_M6_predict,target_predict_M6_label
"At last, we mention NGAR [74] and GEN [85] as works that can predict the graph topology alongside node-level signals.",1,neutral
"DCRNN [71] 2018 ICLR M-S D-C Spatial GNN T-R No R SP STGCN [58] 2018 IJCAI M-S D-F Spectral GNN T-C No R SP ST-MetaNet [73] 2019 KDD M-S D-F Spatial GNN T-R No R SP, PC NGAR [74] 2019 IEEE IJCNN S-S D-F Spatial GNN T-R No R ASTGCN [75] 2019 AAAI M-S D-F Spectral GNN T-H No R SP, PC ST-MGCN [46] 2019 AAAI S-S D-F Spectral GNN T-R No R - SP, PC, PS Graph WaveNet [76] 2019 IJCAI M-S D-F Spatial GNN T-C No O S SP MRA-BGCN [77] 2020 AAAI M-S D-C Spatial GNN T-R No R SP MTGNN [53] 2020 KDD S-S, M-S D-F Spatial GNN T-C No NR S STGNN* [78] 2020 WWW M-S D-C Spatial GNN T-H No R SP GMAN [79] 2020 AAAI M-S D-C Spatial GNN T-A No R SP SLCNN [80] 2020 AAAI M-S D-F Hybrid T-C No NR S STSGCN [81] 2020 AAAI M-S D-C Spatial GNN T No R PC StemGNN [54] 2020 NeurIPS M-S D-F Spectral GNN F-C No NR S AGCRN [82] 2020 NeurIPS M-S D-C Spatial GNN T-R No NR S LSGCN [83] 2020 IJCAI M-S D-F Spectral GNN T-C No R SP STAR [84] 2020 ECCV M-S D-F Spatial GNN T-A No R PC GTS [56] 2021 ICLR M-S D-C Spatial GNN T-R No NR S GEN [85] 2021 ICLR S-S D-F Spatial GNN T-R No R Z-GCNETs [86] 2021 ICML M-S D-C Spatial GNN T-C No NR S STGODE [70] 2021 KDD M-S C-F Spatial GNN T-C No R SP, PS STFGNN [49] 2021 AAAI M-S D-F Spatial GNN T-C No R SP, PS DSTAGNN [87] 2022 ICML M-S D-F Spectral GNN T-H No R - PC, PS TPGNN [88] 2022 NeurIPS S-S, M-S D-F Spatial GNN T-A No NR D MTGODE [23] 2022 IEEE TKDE S-S, M-S C-C Spatial GNN T-C No NR S STG-NCDE [89] 2022 AAAI M-S C-C Spatial GNN T-C Yes NR S STEP [90] 2022 KDD M-S D-F Spatial GNN T-A No NR S Chauhan et al.",0,negative
"cessing point clouds by Graph Neural Networks (GNNs) [34], [35], [36], [37], [38], [39], which can be considered an extension of PointNet.",1,neutral
"There are several research that conduct a more general study in which a full graph (nodes, edges, and attributes) is predicted [37], [38].",1,neutral
"While previously mentioned approaches focus on multivariate time series prediction, other methods aim at predicting changes in graph topology (Zambon et al., 2019; Paassen et al., 2020).",1,neutral
"While previously mentioned approaches focus on multivariate time series prediction, other methods aim at predicting changes in graph topology (Zambon et al., 2019; Paassen et al., 2020).",1,neutral
"While the above approaches focus on multivariate time series prediction and use the graph structure only as a representational tool, other methods aim at predicting changes in the graph topology [Zambon et al., 2019, Paassen et al., 2020].",1,neutral
"While some recent approaches are more flexible in both respects [27, 32], it remains a hard problem to accurately characterize the distribution of large graphs.",1,neutral
"Second, decoders that generate graphs by a sequence of edits [27, 29, 30, 31], e.",1,neutral
"Theory of deep learning for graphs: While theoretical studies have found crucial relations between the Weisfeiler-Lehman test and the graph edit distance [8, 10, 27], it is still not fully clear how these connections relate to learning.",1,neutral
"For example, users enter or leave social networks and change their connections over time [27].",1,neutral
"Conversely, graph edit networks only use embedding information at time t but can predict changes in the node set via node deletions or insertions [27].",1,neutral
"However, in many applications we need to decode graphs from vectors, such as in molecule design [24, 25, 26] or when performing time series prediction [27].",1,neutral
"Promising results have been achieved for chemical molecules [24, 25, 26] and computer programs [40, 27].",1,neutral
"Some recent approaches offer a compromise by first determining the nodes of a graph in a sequential fashion and, afterwards, all edges are generated in a single step [27, 32].",1,neutral
