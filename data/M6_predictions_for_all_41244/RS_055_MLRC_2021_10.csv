text,target_M6_predict,target_predict_M6_label
"Surpassing GANs in image generation quality [41; 100] and exhibiting good mode coverage, they are becoming a popular choice for high-fidelity image generation and restoration tasks.",1,neutral
"Different from the Medical Image Analysis area, GAN-based GDA networks are still the main methods in Agricultural Image Analysis as even the emergence of GANs in this area can be dated to recent years[211].",1,neutral
"For a visual perspective on GAN’s intricate structure, one may refer to the top section of Figure 2.",1,neutral
"Takezaki, Kishida et al.[254] get the classification accuracy for heart sound improved by 1% with Synthetic Spectrogram-based GANs(SSG).",0,negative
"Unlike conventional approaches, GANs are designed to generate samples directly from the desired data distribution, bypassing the need to explicitly model the underlying probability density function.",1,neutral
"Nevertheless, VAEs tend to generate samples of lower visual quality compared to GANs.",1,neutral
• Generative Adversarial Networks: GANs are known for rapidly producing high-quality samples.,1,neutral
"Lu, Chen et al. reviewed the application of GANs in agriculture in September 2022.",2,positive
"Salvador, Javier et al. apply evolutionary conditional GANs to generate grape berry cluster images.",1,neutral
"Furthermore, [107] tapped into the potential of GANs to create synthetic data augmentations for medical images, exemplifying the versatility of generative models in diverse imaging contexts.",1,neutral
"Diffusion models achieved the best trade-off between sample fidelity and diversity and obtained the highest Fréchet Inception Distance, compared to GANs[232].",1,neutral
"However, the types of GANs used are similar and the tasks are narrow, though it seems that GANs have achieved success in many precise tasks.",1,neutral
GANs generate high-quality samples across the use of discriminators.,1,neutral
"Esteban et al. adopted recurrent conditional GANs for the generation of realvalued medical time series data, underscoring the significance of generative models in healthcare applications [106].",1,neutral
"From the conventional VAEs[16; 17; 18; 19; 20; 21] and GANs[22; 23; 24; 25; 26; 27; 28; 29; 30] to the burgeoning GPT-based[31; 32; 33; 34; 35; 36; 37; 38; 39; 40] and diffusionbased innovations[41; 42; 43; 44; 45; 46; 47], we elucidate their mechanisms, pros, cons, and use-case scenarios.",2,positive
"While GANSpace was shown to extract interpretable controls for image generation, similar PCA-based techniques are also used in the audio domain to identify the most informative parts of the latent space, without necessarily providing interpretability [10].",1,neutral
"In other words, GANSpace enabled to reduce dimensionality of our trained WaveGAN from a 10-to a three-dimensional latent space, while preserving 75% of its learned representation. that continuously changing one latent parameter triggers a continuous morphing between generated breathing waveforms.",1,neutral
"GANSpace enables to reduce dimensionality of a latent space by applying principal component analysis (PCA) at one given network layer of a GAN, then using the first few components as latent parameters for generation.",1,neutral
"Technically speaking, we implemented and applied the GANSpace algorithm at each of the five layers of our trained WaveGAN.",2,positive
The first and fourth authors first searched to reduce dimensionality of our deep generative model by implementing GANSpace [27].,1,neutral
"After training, dimensionality of latent spaces can be reduced using generic algorithms such as principal component analysis [10, 27].",1,neutral
"On the left panel, we put three sliders which we respectively connected to the three latent parameters computed with GANSpace.",1,neutral
"Following that, a large number of works [6], [8], [26], [27], [28], [29], [30], [31], [32] have shown that the latent spaces of GANs contain rich semantic knowledge of image attributes and can be used to edit images via arithmetic of attribute vectors in latent spaces.",1,neutral
"More recently, the authors of GANSpace [31] conducted unsupervised Principal Component Analysis (PCA) on the latent space, and then applied principal directions to achieve interpretable control over the output images.",2,positive
"Following infoGAN, many attempts have been made to facilitate the discovery of semantically meaningful traversal directions through regularization [33, 42, 89, 34, 100, 66, 77, 90, 98, 84, 99, 78, 62].",1,neutral
"On the other hand, other methods [10, 11, 15, 23, 42] resort to latent space manipulation [9, 34].",1,neutral
"By properly exploiting their latent structure, prior works succeeded in image editing [33, 79, 80, 81, 82, 83, 84], semantic control [55, 56, 85], disentangled control direction discovery [86, 87, 88, 89], etc.",1,neutral
"1 [10] Erik Härkönen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris.",0,negative
"Latent Space Manipulation GANs allow the generation of images that are controlled by semantic directions [19, 14, 17, 25, 23, 10].",1,neutral
The identification of latent directions based on the principal component analysis (PCA) was proposed in [10].,2,positive
"In particular, in the work [10] authors proposed estimating the subspaces that are invariant under random-walk diffusion for identification.",1,neutral
"Additional qualitative comparisons for editing We conducted additional comparative experiments of the proposed WRanGAN approach and the PTI inversion method for the StyleGAN 2 model in two domains: the FFHQ domain, with semantic directions corresponding to binary image attributes [23], and the LSUN Church domain, with the first 4 vectors obtained by PCA approach [10].",2,positive
"Moreover, several works [19, 14, 17, 25, 23, 10] have demonstrated that GANs possess a wide range of interpretable semantics, providing the basis for image editing.",1,neutral
"2014) have led to a wide range of applications, including image manipulation (Voynov and Babenko 2020; Shen et al. 2020; Härkönen et al. 2020), domain translation (Isola et al.",1,neutral
"Algorithms in the image domain [9], [10], statistically",1,neutral
"In computer vision, algorithms such as [9], [10], [48], [49], [50], [51] leverage StyleGANs ability to disentangle the latent space to find directional vectors for editing semantics",1,neutral
"Exploring meaningful directions in the latent space: The methods proposed in [12, 16, 17] aim to discover directions in the latent representations such that moving on these directions yields humanly interpretable image transformations such as a change in aging, gender, hairstyle, lighting and etc.",1,neutral
"GANSpace [3] and InterFaceGAN [4], etc.",1,neutral
"where − →n denotes the semantic direction acquired by arbitrary semantic editing techniques [23, 24, 5, 42, 41].",1,neutral
"It is evidenced that the latent space of a well-trained GAN is semantically organized, and shifting the latent code along with a specific direction results in the manipulation of a corresponding attribute [23, 24, 5, 19, 45, 32].",1,neutral
"There have also been many efforts to manipulate latent codes for spatial editing [2, 13, 17, 18, 22, 35, 45, 46, 48, 49, 55], such as object movement, rotation, and zooming.",1,neutral
"Different methods have been developed, including PCA analysis to extract important latent directions [28], semantic analysis to control various attributes [29], and composing a new latent vector to control multiple attributes [30].",1,neutral
"Many works have chosen to extend StyleGAN2 including [28, 48, 50, 52] thus allowing many possible applications including image editing with SeFa [50].",1,neutral
"Numerous works have explored this disentanglement latent space to identify semantic directions in a supervised [4, 14, 36], unsupervised [15, 37, 41] or self-supervised [19, 32] manner.",1,neutral
"GANSpace [24] uses principal component analysis (PCA) in the feature space to identify the important latent directions, which represent the interpretable variations.",1,neutral
"2020], or in an unsupervised manner [Härkönen et al. 2020; Shen and Zhou 2021; Voynov and Babenko 2020].",1,neutral
"Recent works [Härkönen et al. 2020; Shen et al. 2020] have demonstrated that StyleGAN learns disentangled attributes, making it possible to find directions in its latent space to generate images that possess such desired attributes.",1,neutral
"Recent works [Härkönen et al. 2020; Shen et al. 2020] have demonstrated that StyleGAN learns disentangled attributes, making it possible to ind directions in its latent space to generate images that possess such desired attributes.",1,neutral
"Such a direction can be found by either using explicit supervision of image attribute annotations [Abdal et al. 2021; Shen et al. 2020; Wu et al. 2020], or in an unsupervised manner [Härkönen et al. 2020; Shen and Zhou 2021; Voynov and Babenko 2020].",1,neutral
"Recently, lots of methods explore disentangling the latent space to achieve image editing by moving the latent code in the identified interpretable directions [7, 3, 22, 49, 18, 58, 71, 50, 19, 43, 56, 59, 57, 32, 57, 33, 62, 23, 46, 9, 55, 53].",1,neutral
"Previous latent semantics discovery approaches [15, 58, 18, 49, 50] consider the GAN manipulation as edit(G(z))=G(z + αn) where G(·) represents the generator, z∈R denotes the latent code of dimension d, n∈R is the identified semantically meaningful direction, and α represents the perturbation strength.",1,neutral
GANSpace [14] and SeFa [35] find editing directions from the principal components of the latent space.,1,neutral
"Unsupervised methods [2,14,35,40] are to discover the interpretable directions using PCA [14,35] or texts [2].",1,neutral
"Previous literature [2, 14, 34, 35, 41] usually edits the facial attribute ai by linear interpolation in the latent space with certain editing directions nai ∈ R(512), which can be formulated as follows:",1,neutral
"In this paper, we study an adaptive nonlinear transformation rather than linear interpolation in [2,14,25,34,35,40,41], and investigate a density regularization to encourage indistribution latent transformation.",1,neutral
"nai can be learned by training a hyperplane/fully-connected layers in the latent space [34, 41], or discovered from the principal components [14, 35] and text information [2].",1,neutral
"Differently, the unsupervised methods [1,2,9,14,20,35,37] do not need the valuable annotated data.",0,negative
"In particular, the pre-trained StyleGAN generator presents a meaningful intermediate latent space, traversing on which the faces can be semantically manipulated [2, 3, 14, 34, 35, 38, 40, 41].",1,neutral
"tions in the latent space of GANs [23], [24].",1,neutral
One line of works find semantic controls in the generator’s latent space which enable controlled synthesis and image editing pipelines [Abdal et al. 2020; Härkönen et al. 2020; Patashnik et al. 2021; Shen et al. 2020; Shen and Zhou 2020; Voynov and Babenko 2020].,2,positive
GANSpace [11] utilized Principal Component Analysis (PCA) applied on the feature space of pretrained GANs to create interpretable controls for image synthesis.,2,positive
"Similar to GANSpace [11], InterFaceGAN [25] proposed a framework for semantic face editing.",2,positive
"However, these approaches, GANSpace [11] and InterFaceGAN [25], mainly relied on human labels or attribute classifiers for visual attribute manipulation without any restriction on identity information.",1,neutral
"After that, many StyleGAN-based methods have been proposed for controllable face generation [9]–[11].",1,neutral
Our method can be adapted to use other editing methods like InterfaceGAN [40] and GANSpace [20].,2,positive
"Finally, we can edit an inverted image by manipulating the latent code, which can be described as:
I′edit = G(w + + ∆w+; θp), (4)
where ∆w+ could be any editing directions from InterfaceGAN [40] or GANSpace [20].",2,positive
where ∆w could be any editing directions from InterfaceGAN [40] or GANSpace [20].,1,neutral
"In recent years, style-based generator [19, 20] emerged as a powerful image synthesis model, and a plethora of recent works [1, 2, 18, 37, 42, 45] tend to explore the rich interpretable semantics inside the latent space of fixed GAN models.",1,neutral
GANSpace [18] carries out Principal Component Analysis (PCA) in the latent space of generative networks and explores interpretable controls in an unsupervised manner.,2,positive
"Unsupervised methods [Cherepkov et al. 2021; Härkönen et al. 2020; Shen and Zhou 2021; Voynov
and Babenko 2020; Wei et al. 2021] find the interpretable direction without using annotated samples, e.g., by a PCA decomposition on the network weights or on the latent codes.",1,neutral
"Compared with the other emergent generative models, GANs have the advantages of rapid inference [29], generating fixed objects [29, 56] and controllable latent distribution [33, 34, 32, 3, 21, 64].",1,neutral
"Some methods mitigate this problem by finding latent semantic vectors existing in pre-trained generators [8], [9], [10], [11].",1,neutral
"[10], [11], [50], [51], [52], [53], [54].",1,neutral
"Recently, many StyleGAN variants [Abdal et al. 2021; Gal et al. 2022; Härkönen et al. 2020; Patashnik et al. 2021; Shoshan et al. 2021; Tov et al. 2021; Wang et al. 2021a, 2022; Wu et al. 2021] have been introduced to address this problem.",1,neutral
"Built on the success of StyleGAN, a large number of methods [Abdal et al. 2021; Gal et al. 2022; Härkönen et al. 2020; Patashnik et al. 2021; Shoshan et al. 2021; Tov et al. 2021; Wang et al. 2021a, 2022; Wu et al. 2021] use it as a prior for semantic face editing and other image enhancement tasks,…",2,positive
"GANSpace [Härkönen et al. 2020] attempts to analyze the GAN space by identifying latent directions based on principal component analysis (PCA), applied either in latent space or feature space.",1,neutral
"Built on the success of StyleGAN, a large number of methods [Abdal et al. 2021; Gal et al. 2022; Härkönen et al. 2020; Patashnik et al. 2021; Shoshan et al. 2021; Tov et al. 2021; Wang et al. 2021a, 2022; Wu et al. 2021] use it as a prior for semantic face editing and other image enhancement tasks, such as inpainting and super-resolution.",2,positive
"Can we construct computer vision systems that may likewise understand, recombine, and imagine the visual world? Most existing work in concept discovery focus on discovering latent vectors or directions representing individual concepts [15, 24, 18, 44, 55], but require supervised data labeling each concept.",1,neutral
"Existing works in concept discovery in computer vision typically focus on discovering a latent space to manipulate images [15, 24, 18, 44, 55, 42] but require supervised data to specify each concept.",1,neutral
"Specifically, previous methods mainly used pre-trained GAN models to enable image manipulation [8, 9].",1,neutral
"Our StyleIPSB outperforms Ganspace [13], which is also a basis constructed in W+ space using unsupervised learning.",2,positive
We compare our method with GANSpace [13] and InterfaceGAN [34] in the editing of facial expression.,2,positive
"To facilitate attribute manipulation in an unsupervised manner, GANSpace [13] and SeFa [36] perform decomposition to find primary directions
in the latent space and explore the interpretable directions among the primary directions.",1,neutral
"To facilitate attribute manipulation in an unsupervised manner, GANSpace [13] and SeFa [36] perform decomposition to find primary directions",1,neutral
"We compare our method with InterFaceGAN [34], GANSpace [13], GIF [12] and SeFa [36].",2,positive
"StyleGAN-based image editing requires either an encoder trained to map a given image to the latent space [2, 35], or specifying latent update direction which requires explicit ground-truth annotations [1, 16, 52, 57].",1,neutral
[52] searched for attribute development’s potential path by performing principal component analysis operations between attributes and latent code.,2,positive
"To discover semantically meaningful latent directions without supervision, an effective approach was to perform principal component analysis on the latent vectors of the training images [13, 14].",1,neutral
"Recent works [15,37,43] have discovered that the latent space of StyleGAN possesses semantic disentanglement properties, enabling a variety of image editing operations via latent transformations.",1,neutral
Figure 3 shows editing results with GANSpace [6].,0,negative
"The combination of GAN inversion [1–3, 5, 7, 14, 15, 25, 28, 29] and latent space editing [6, 16, 18] enables us to edit a wide range of image attributes such as aging, expression, and light condition, by applying editing operations [6, 16, 18] to inverted latent codes.",1,neutral
"Image synthesis has recently made significant advancements [1, 12, 22, 26, 39, 2, 11, 32].",1,neutral
"For example, unsupervised approaches [18,19,20,21,22,23,24,25] attempt to find interpretable directions in a latent space using, e.",1,neutral
"Specifically, we focused on a state-of-the-art (SOTA) unsupervised method - GANSpace (Härkönen et al., 2020), which utilizes Principal Component Analysis (PCA) (Pearson, 1901) to find orthogonal directions along which new semantic axes can be located.",2,positive
"Specifically, we focused on a state-of-the-art (SOTA) unsupervised method - GANSpace (Härkönen et al., 2020), which utilizes Principal Component Analysis (PCA) (Pearson, 1901) to find orthogonal directions along which new semantic axes can be located.",2,positive
"4 RESULTS AND DISCUSSION The examples of manipulations obtained by GANSpace (Härkönen et al., 2020) are shown in Fig.",1,neutral
"The examples of manipulations obtained by GANSpace (Härkönen et al., 2020) are shown in Fig.",1,neutral
"For StyleGAN2, as was done by Härkönen et al. (2020) we applied GANSpace in W latent space.",2,positive
"In this work, we evaluated the transformations obtained by GANSpace (Härkönen et al., 2020) for both StyleGAN2 (Karras et al., 2020) and GAN from Liu et al. (2021) both visually and quantitatively.",2,positive
"3 METHODS In this work, we evaluated the transformations obtained by GANSpace (Härkönen et al., 2020) for both StyleGAN2 (Karras et al.",1,neutral
"[19] Erik Härkönen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris.",0,negative
"We take inspiration from the related line of work that finds so-called ‘interpretable directions’ in latent space [18, 19] that capture high-level semantic attributes–however, we learn subspaces that capture variation uniquely present amongst representations of words of particular parts of speech.",1,neutral
"Other methods [24, 41, 44, 46] adopt principal component analysis or contrastive learning to explore unique editing directions in an unsupervised manner.",1,neutral
Other approaches compute the important semantic directions in the latent space in an unsupervised manner [Härkönen et al. 2020; Shen and Zhou 2020; Zhu et al. 2023].,1,neutral
"Note that in contrast to the original GANSpace algorithm [22], we do not apply PCA in the W-space.",1,neutral
"To this end, explore latent directions in an unsupervised way like [22], as we do not have additional supervision from synthetic data like [21] or attribute classifier networks like [24].",1,neutral
Our work belongs to the last category (unsupervised latent exploration) and is based on GANSpace [22].,2,positive
"For this, we first show the directions obtained by GANSpace [22] applied to StyleGAN2.",1,neutral
"In Figure 5, we also explore applying GANSpace in the W+-space of Urban-StyleGAN and in the S-space of different layers.",2,positive
"Applying GANSpace in
the W+-space of the class ’car’ gives only one meaningful direction of control (increasing car number and size on both sides).",1,neutral
"Note that in contrast to the original GANSpace algorithm [22], we do not apply PCA in the W+-space.",1,neutral
"This is a fairly new area, and relevant to this line of work may be semantic adversarial approaches [8, 12, 17] which rely on generative models in order to generate adversarial examples, and [6] where interpretable controls are discovered for generative models.",1,neutral
"Style-based generators [16, 17, 15] demonstrate the power of their semantic latent spaces, namely W , in image generation, image editing [11, 30], and video generation [33].",1,neutral
"We compute the style codes by simply adding these two different codes based on the linearity [11, 30] of the latent space W+.",1,neutral
"Furthermore, thanks to the continuous and linear nature of the latent space [16, 11, 30], we linearly manipulate the style codes using the audio input to generate lip-synced video frames.",1,neutral
"Second, the style codes form the continuous and linear [16, 11, 30] latent spaces, which enables us to design a high-level visual transformation, such as natural motion, only with a linear transformation of latent code [37].",1,neutral
"Various GAN-based editing methods rely on traversing the latent space to generate meaningful edits, highlighting the importance of the GAN inversion approach for achieving desired manipulations [66, 10, 29, 39, 14, 18, 53, 46, 47, 38, 20, 52, 48].",1,neutral
"Several works have found that the latent spaces of StyleGAN are remarkably linear [18, 31, 17, 39], disentangling attributes such as facial expression, hair color, and pose.",1,neutral
"Most straightforwardly, an early set of these approaches aimed to identify fixed linear directions in latent space and evolve samples along the discovered directions to create trajectories (Härkönen et al., 2020; Voynov & Babenko, 2020; Shen & Zhou, 2021).",1,neutral
"Most straightforwardly, an early set of these approaches aimed to identify fixed linear directions in latent space and evolve samples along the discovered directions to create trajectories (Härkönen et al., 2020; Voynov & Babenko, 2020; Shen & Zhou, 2021).",1,neutral
"By contrast, unsupervised methods discover interpretable directions without any prior knowledge (Härkönen et al., 2020; Kwon et al., 2023; Choi et al., 2022; Karmali et al., 2022; Spingarn-Eliezer et al., 2021; Ren et al., 2022; Oldfield et al., 2023).",1,neutral
"By contrast, unsupervised methods discover interpretable directions without any prior knowledge (Härkönen et al., 2020; Kwon et al., 2023; Choi et al., 2022; Karmali et al., 2022; Spingarn-Eliezer et al., 2021; Ren et al., 2022; Oldfield et al., 2023).",1,neutral
"Such directions can also be identified in an unsupervised fashion, using the PCA decomposition of the latent space [12], or the SVD of the first subsequent linear layer [37].",1,neutral
"When the latent space is disentangled as in StyleGAN [17,18], linear control is possible by carefully identifying and combining the latent directions of each attribute [12,36,37,50].",1,neutral
[11] proposed GANspace which performed PCA on early feature layers.,2,positive
"Various works explored learning based [37, 54, 56], optimization based [1, 2, 14, 55], or hybrid [4, 60] approaches for GAN inversion, aiming to encode an image to the latent space of GANs.",1,neutral
Härkönen et al. [11] proposed GANspace which performed PCA on early feature layers.,1,neutral
"Despite the various work studying the latent space of GANs, the latent space of diffusion models lack semantic meaning and cannot be easily applied for semantic manipulation.",1,neutral
"The StyleGAN [16] generator maps the random noise vector to a semantically meaningful latent space, inspiring various follow-up works exploring the controllability and interpretability of the latent space of GANs [14, 16, 27, 34, 38, 51, 55].",1,neutral
"There have been various works on learning visual representations and manipulating the latent space of GANs [11,44,45].",1,neutral
", 1) unsupervised methods that explore the semantics of generator to discover distinguishable directions [45, 49, 11] and 2) Supervised methods that use attribute labels to find meaningful latent path [44, 43, 60, 1].",1,neutral
[6] have already demonstrated that PCA applied in feature space can produce interpretable controls for image synthesis.,1,neutral
"Existing studies showed that linear perturbations along principal components of ∇wg enable semantic editing, and such perturbation directions are often applicable over w ∼ pw (Härkönen et al., 2020; Zhu et al., 2021).",1,neutral
Härkönen et al. (2020) apply principal component analysis on pw distribution and found semantically meaningful editing directions.,1,neutral
"Existing studies on semantic editing showed that Rdw consists of linear semantic dimensions (Härkönen et al., 2020; Zhu et al., 2021).",1,neutral
"Indeed, instead of local analysis on the Jacobian, (Härkönen et al., 2020) showed that principal component analysis directly on pw also reveals semantic dimensions.",1,neutral
"For example, StyleGAN-based approaches [1, 31, 19, 32, 20, 33, 28, 2, 10] edit the attributes of an image, such as smile and age, by obtaining an editing direction in the latent space.",1,neutral
"Follow-up works enable controllability by either adding conditioning input along with the sampled vectors as input (named ”Conditional GAN”) [35, 65] or manipulating the sampled vectors [82, 28, 105].",1,neutral
"[39] for GANs [34] and has found application beyond that [94, 21], to our knowledge its use for the purpose of identifying a basis for exposure minimization is novel.",2,positive
"As a result, StyleGANs are being extensively used in various applications like face-editing [11, 42], video generation [47, 53], face reenactment [3], etc.",1,neutral
", so that user controls such as knobs and sliders have one primary (perceptual or semantic) effect [17, 18, 5].",1,neutral
"…al., 2021), which is able to infer the implicit cause-effect relationships between attributes using causal reasoning (Schölkopf et al., 2021), and DisCo (Härkönen et al., 2020), that uses a contrastive learning approach to discover disentangled directions and learn disentangled representations.",1,neutral
"Examples of controllable generative models are CAGE (Mao et al., 2021), which is able to infer the implicit cause-effect relationships between attributes using causal reasoning (Schölkopf et al., 2021), and DisCo (Härkönen et al., 2020), that uses a contrastive learning approach to discover disentangled directions and learn disentangled representations.",1,neutral
", 2021), and DisCo (Härkönen et al., 2020), that uses a contrastive learning approach to discover disentangled directions and learn disentangled representations.",1,neutral
"Following GANSpace [20], we empirically set the first 8 layers of latents as pose latents (denoted as w), the remaining 8 layers of latents as shape and appearance latents.",1,neutral
GANSpace [20] found that different layers in w∗ control different image attributes.,1,neutral
"Interpreting the latent representation of GANs [20, 32] has benefited a body of work disentangling various factors of generated objects in a 3D-controllable manner, e.",1,neutral
We draw aspiration from GANSpace [20] and SeFa [32] to disentangle StyleGAN2.,2,positive
"Pose Difference Range (FFHQ-P) [0,15) [15,30) [30,45) [45,60) [60,75) [75,90)",1,neutral
"• Pose Misalignment: When the yaw difference is between [15-30) or [30-45), a single checkmark or double checkmarks are used, respectively in Table 1.",0,negative
"Since the well-designed StyleGAN [25] contains a semantically rich latent space, a commonly-used approach [43, 15, 44] is to explore and find “walking” directions that control a specific attribute of interest.",1,neutral
"The pioneering work StyleCLIP [18] adds a vector to the original image representation in the StyleGAN feature space, which is known to be well disentangled [3,7,26,30].",1,neutral
"While researchers have found ways to make sense of latent space’s underlying properties in generative models [4, 8], its hidden layers are not a part of the interaction in co-creation [7].",1,neutral
"Some of these techniques allow a user to edit a set of visual attributes found through unsupervised learning [13, 33], while others leverage supervised learning or pre-trained classifiers",1,neutral
"This provides the potential for the proposed framework to control a generative model’s output using implicit feedback from users, rather than requiring them to explicitly quantify their preferences [13, 33, 1, 22, 34].",1,neutral
"To expand their capabilities, there is substantial interest in improving the controllability of these models, providing the end user the ability to modify the continuous attributes of output images [13, 33, 1, 22, 34].",2,positive
"Unsupervised methods [18], [19], [20], [21], [22] adopt",1,neutral
"Unsupervised approaches [18], [19], [20], [21], [22] typically use classical unsupervised machine learning techniques, e.",1,neutral
"Unsupervised approaches [18], [19], [20] are inappropriate for this task as they focus on discovering interpretable latent semantics, instead of solving for the latent direction for the target attribute.",1,neutral
"In the latent space W defined asw ∈W,Gmapping(z) = w, significant semantic directions have already been found [16], [17].",1,neutral
"Unsupervised techniques attempt to find interesting edits without labeled data [22, 24, 41, 49].",1,neutral
"[27, 50, 28, 8, 68, 81, 63, 24, 17] There have been a number of works that renovate GANs focusing on styles.",1,neutral
"As demonstrated in [20, 29, 1, 56], StyleGAN2 can disentangle viewpoints in the early layers.",1,neutral
"GANs are known to encode the semantics of the training data in their latent space [1, 2, 3].",1,neutral
"Simply translating a latent code in a given direction can lead to the variation of a semantic attribute in the corresponding generated image [1, 2, 3, 12].",1,neutral
"Latent semantic directions can be extracted from the latent space without supervision by performing PCA [2] or by singular value decomposition on the weights of the pretrained GAN [3, 12].",1,neutral
"In the context of GANs [10], it was shown that the principal components of a collection of randomly sampled latent codes results in semantically interpretable editing direction.",1,neutral
[10] found interpretable control directions in pretrained GANs by applying principal components of latent codes to appropriate layers of the generator.,1,neutral
"While there has been extensive research on finding disentangled editing directions in the latent space of unconditional GANs [1, 33, 10, 6, 35, 38, 24], comparatively little work has been done on this topic for unconditional DDMs.",1,neutral
"Semantic editing has been widely explored in GANs [33, 10, 6, 35, 38, 20, 24, 39, 43].",1,neutral
"…explored the use of instance-specific augmentations obtained via GAN inversion (Xia et al., 2022; Huh et al., 2020; Zhu et al., 2016), which map original images into latent vectors that can be subsequently transformed to generate augmented images (Jahanian et al., 2020; Härkönen et al., 2020).",1,neutral
", 2016), which map original images into latent vectors that can be subsequently transformed to generate augmented images (Jahanian et al., 2020; Härkönen et al., 2020).",1,neutral
"For text-guided image synthesis using GANs, text was usually used as condition.",1,neutral
"With image-caption data pairs, GANs were trained to generate samples by utilizing attention mechanisms or contrastive approaches [21, 22].",1,neutral
"Early works on image manipulation utilized GANs [18, 5, 19].",1,neutral
"tions by principal component analysis [10], low-rank factorization [41] and closed-form factorization [28].",1,neutral
"This means that the StyleGAN editing vectors found in previous studies [26, 10, 28] can be directly applied to StyleGANEX for normal FoV face editing, e.",1,neutral
"Building upon StyleGAN, researchers have developed a range of face manipulation models [1, 23, 29, 26, 10, 28, 41, 37].",1,neutral
"Unsupervised methods for finding interpretable axes in the generator have also been proposed (Härkönen et al. 2020; Voynov and Babenko 2020; Tzelepis, Tzimiropoulos, and Patras 2021; Shen and Zhou 2021; Wang and Ponce 2021).",2,positive
"As first demonstrated by StyleCLIP [34], the requirements for large amounts of annotated data [25] and manual efforts [14, 44] were considerably alleviated.",0,negative
Desirable changes to attributes of interest were previously brought out by discovering the relevant channels [44] and curating principal components [14] either through manual inspection or otherwise driven by data-hungry attribute predictors.,0,negative
"Notably, StyleGAN-family models [32,34] have shown impressive ability in image synthesis tasks for single-category domains [1, 25, 49, 70, 84].",1,neutral
"Though these techniques achieve impressive results for translation, they suffer the same limitations as GANs such as mode coverage and difficulty in training.",1,neutral
"Improving editability and controllability in various other forms of generative models (e.g., GANs [14, 15, 50], VAE [2, 27] and Flow-based Models [10, 11]) has been one of the most prominent research topics in the past few years.",1,neutral
"To overcome the limitations, we use similar techniques and build on top of diffusion models, that has shown to have better mode coverage and higher quality generations [9] compared to GANs.",2,positive
"GANs such as StyleGAN-v2 [22] have been shown to inherently learn smooth and regular latent spaces [15,50] that enable meaningful edits and manipulations on a real or generated image.",1,neutral
", GANs [14, 15, 50], VAE [2, 27] and Flow-based Models [10, 11]) has been one of the most prominent research topics in the past few years.",1,neutral
DDGAN [51] combined the best of GANs and diffusion models to retain the mode coverage and quality of diffusion models while making it faster like GANs.,2,positive
"Inspired by DiffAE [40] and similar approaches in GANs [29], we introduce a content encoder Ec( · ;ψ) and a style encoderEs( · ;φ) in our framework as shown in Fig.",2,positive
"An alternative to using the inherent latent space of GANs for manipulation is to learn multiple external disentangled latent spaces to condition the generation [21, 29, 32, 39].",1,neutral
We apply PCA on the style and content latent spaces and identify meaningful attribute specific manipulation directions similar to [15] as shown in Fig.,2,positive
"However, the extent of controllability and editability with diffusion models is underexplored relative to GANs.",1,neutral
"Additionally, the learned latent spaces are observed to have desirable properties similar to GANs.",1,neutral
", 2019), unsupervised (Shen & Zhou, 2021; Wang & Ponce, 2021; Härkönen et al., 2020; Voynov & Babenko, 2020), or text-guided methods (Global Mapper & GlobalDirection1 of StyleCLIP (Patashnik et al.",2,positive
"The difference is that unlike GlobalDirection which relies on a single channel manipulation, Multi2One encode change of image caused by image-agnostic direction found by unsupervised methods (Härkönen et al., 2020; Shen & Zhou, 2021).",2,positive
"1(a), we can observe that applying the 70-th GANspace direction manipulates the source image to become a man with wide smile, showing that pre-trained StyleGAN itself is capable of such manipulation.",1,neutral
"Finally, we compute the similarity score for 30 instances of source images and 1024 directions from SeFa and GANspace whose average is reported in Tab.",2,positive
"To avoid this unrealistic assumption, we substitute ŝt with the known directions α ∈ Rn derived from unsupervised methods (Härkönen et al., 2020; Shen & Zhou, 2021).",1,neutral
"The dictionary learning process of Multi2One employs the directions α ∈ Rn from unsupervised methods (Shen & Zhou, 2021; Härkönen et al., 2020).",2,positive
"1 to show that GlobalDirection (Patashnik et al., 2021) cannot effectively recover the directions found by unsupervised methods (Härkönen et al., 2020; Shen & Zhou, 2021).",2,positive
"(4) by using all 512 directions found by GANspace and directions with top 80 eigenvalues out of 512 from SeFa4 (Härkönen et al., 2020; Shen & Zhou, 2021).",2,positive
"We emphasize that despite the dictionary of our method is learned from the known directions in unsupervised approaches (Shen & Zhou, 2021; Härkönen et al., 2020), the manipulation results show that our learned dictionary could adapt to previously unseen combination of semantics such as red hair,…",2,positive
", 2021) cannot effectively recover the directions found by unsupervised methods (Härkönen et al., 2020; Shen & Zhou, 2021).",0,negative
"On the other hand, GANspace (Härkönen et al., 2020) relies on the randomly sampled latent codes in W and 2",1,neutral
"First, we show that many edits using unsupervised methods (Härkönen et al., 2020; Shen & Zhou, 2021) cannot be recovered by GlobalDirection.",2,positive
"…contrary to this common belief on text-guidance, the standard method (Patashnik et al., 2021) for text-based StyleGAN manipulation surprisingly fails to even find the manipulation directions that are known to be found in unsupervised approaches (Härkönen et al., 2020; Shen & Zhou, 2021) (see Fig.",1,neutral
"We use unsupervised directions from SeFa and GANspace, both of which are found in intermediate space W limiting the maximum number of directions to 512, which is the dimension of the intermediate latent space.",1,neutral
"To avoid this unrealistic assumption, we substitute ŝt with the known directions α ∈ R derived from unsupervised methods (Härkönen et al., 2020; Shen & Zhou, 2021).",1,neutral
"…fast inference and is applicable to any images once found using supervised (Jahanian et al., 2019), unsupervised (Shen & Zhou, 2021; Wang & Ponce, 2021; Härkönen et al., 2020; Voynov & Babenko, 2020), or text-guided methods (Global Mapper & GlobalDirection1 of StyleCLIP (Patashnik et al., 2021)).",2,positive
"On the other hand, GANspace (Härkönen et al., 2020) relies on the randomly sampled latent codes in W and
the eigenvectors from the latent codes proved to be global directions that share an image-agnostic modification ability.",1,neutral
"Therefore, we conduct an ablation study on the effect of using unsupervised directions by comparing the two cases where directions α come from supervised method (Shen et al., 2020) and unsupervised methods (Shen & Zhou, 2021; Härkönen et al., 2020).",2,positive
"We emphasize that despite the dictionary of our method is learned from the known directions in unsupervised approaches (Shen & Zhou, 2021; Härkönen et al., 2020), the manipulation results show that our learned dictionary could adapt to previously unseen combination of semantics such as red hair, pale skin, and big eyes to represent ‘Little Mermaid’ and unnatural smiles with red lipstick and pale face to represent ‘Joker smile’.",2,positive
", 2021) for text-based StyleGAN manipulation surprisingly fails to even find the manipulation directions that are known to be found in unsupervised approaches (Härkönen et al., 2020; Shen & Zhou, 2021) (see Fig.",1,neutral
"It follows the course of generative adversarial networks: extending per-sample editing directions (Ramesh et al., 2018; Patashnik et al., 2021; Abdal et al., 2021; Shen & Zhou, 2021) to global editing directions (Härkönen et al., 2020; Shen & Zhou, 2021; Yüksel et al., 2021).",2,positive
"As we introduce the first unsupervised editing in DMs, we compare our method with GANSpace (Härkönen et al., 2020) considering the mapping from X to H instead of Z to W in GANs.",2,positive
"Since unsupervised editing is not available for DMs, we consider GANSpace for image editing.",2,positive
", 2021; Shen & Zhou, 2021) to global editing directions (Härkönen et al., 2020; Shen & Zhou, 2021; Yüksel et al., 2021).",2,positive
"In addition to what § 4.5 provides, the editing direction, extracted by the GANSpace, primarily alters colors in images.",2,positive
"As we introduce the first unsupervised editing in DMs, we compare our method with GANSpace (Härkönen et al., 2020) considering the mapping from X to H instead of Z to W in GANs.",2,positive
Appendix C describes more details for GANSpace.,0,negative
We use 1k random images with DDIM generative process for GANSpace.,2,positive
", 2021) have been developed, as well as global manipulation techniques such as (Härkönen et al., 2020; Shen & Zhou, 2021; Yüksel et al., 2021).",2,positive
Note that the GANSpace method is obtaining directions inW thus we used GANSpace to add directions directly toH.,1,neutral
"For example, local latent space manipulation techniques such as (Ramesh et al., 2018; Patashnik et al., 2021; Abdal et al., 2021) have been developed, as well as global manipulation techniques such as (Härkönen et al., 2020; Shen & Zhou, 2021; Yüksel et al., 2021).",1,neutral
"There are numerous strategies that can be used to build GAN-based FG models, more details can be found Kammoun et al. (2022)Wang et al. (2022)Ning et al. (2020). In Kammoun et al.",2,positive
"There are numerous strategies that can be used to build GAN-based FG models, more details can be found Kammoun et al. (2022)Wang et al. (2022)Ning et al. (2020). In Kammoun et al. (2022), models are organized in three main types: Conditional, Controllable, and Progressive. Uncontrolled approaches have shown the best performance due to the big amount of unannotated data available. One of the most important families of GAN models is the StyleGAN family Karras et al. (2019). StyleGAN2Karras et al. (2020), a SOTA model in facial generation which applies effective strategies to improve the model performance such as: generator normalization, revisiting progressive growing and regularizing the generator.",2,positive
"There are numerous strategies that can be used to build GAN-based FG models, more details can be found Kammoun et al. (2022)Wang et al. (2022)Ning et al.",2,positive
"There are numerous strategies that can be used to build GAN-based FG models, more details can be found Kammoun et al. (2022)Wang et al.",1,neutral
"There are numerous strategies that can be used to build GAN-based FG models, more details can be found Kammoun et al. (2022)Wang et al. (2022)Ning et al. (2020). In Kammoun et al. (2022), models are organized in three main types: Conditional, Controllable, and Progressive. Uncontrolled approaches have shown the best performance due to the big amount of unannotated data available. One of the most important families of GAN models is the StyleGAN family Karras et al. (2019). StyleGAN2Karras et al.",2,positive
"There are numerous strategies that can be used to build GAN-based FG models, more details can be found Kammoun et al. (2022)Wang et al. (2022)Ning et al. (2020). In Kammoun et al. (2022), models are organized in three main types: Conditional, Controllable, and Progressive.",2,positive
"Further investigation into the latent space structure has been performed by applying unsupervised methods, such as Principal Component Analysis (PCA) [18] or eigenvalue decomposition [43], or by using semantic labels [42,2].",1,neutral
6: Editing quality on LSUN Church using GANSpace [18],2,positive
"For these datasets, the editing directions were taken from GANSpace [18].",0,negative
The unsupervised path aims to unveil the domain’s structure by applying PCA [18] or eigenvalue decomposition [43].,1,neutral
7: Editing quality on the Stanford Cars using GANSpace [18],1,neutral
"2 Semantic-based Editing Except for the parsing-based and appearance-based editing methods, our fine-tuned anime generator also supports the latent semantic editing [Härkönen et al. 2020; Shen et al. 2020; Shen and Zhou 2021].",2,positive
"We also compare with some other SOTA methods in the experiments, i.e., StyleRig [7], InterfaceGAN [8], GANSpace [9], StyleFlow [10].",2,positive
"The comparisons of the multi-view editing effects, using StyleRig [7], InterfaceGAN [8], GANSpace [9], StyleFlow [10] and ours.",2,positive
", StyleRig [7], InterfaceGAN [8], GANSpace [9], StyleFlow [10].",2,positive
GANSpace is unable to discover the editing direction for a specific semantic attribute.,1,neutral
GANSpace [6] analyses the latent space W by PCA and identifies semantic editing directions manually.,2,positive
"For unsupervised approaches, GANSpace[6] adopts PCA to analyse meaningful editing directions in the latent spaceW.",2,positive
"Semantic editing using latent spaces has employed supervised [2, 33, 47] and unsupervised approaches [13, 29, 39].",1,neutral
"through latent space edits proposed by [13, 33].",1,neutral
"Latent Space Manipulation of StyleGAN: Since the proposal of StyleGAN, there has been a plethora of research on the semantic interpretability of the intermediate latent spaces [13, 33, 34, 47].",1,neutral
"Considering the latent space manipulations in [2, 13, 28, 47] it is evident that the latent space of a pre-trained StyleGAN has implicit 3D information embedded within it.",1,neutral
"StyleGAN’s [22] ability to produce high-resolution (1024(2)) photo-realistic faces, richness and semantic interpretability of its latent spaces [13, 28, 33, 47], and the improvements in inversion techniques contributed to improved re-enactment generations [19, 28, 49].",2,positive
"applied to the source image (see [13,33]) could be generated as shown in Fig.",1,neutral
", beard, age, make-up) accommodating latent manipulation techniques such as [13, 33].",1,neutral
"Thanks to inversion, StyleGAN has found use in many image editing [23, 43, 51] and restoration [13–15, 39, 40] tasks.",1,neutral
"StyleGANs [26–29] have achieved high-quality photorealistic 2D image generation and have been successfully applied to various image editing applications [18, 24, 40, 45].",1,neutral
"With our GAN inversion, we can modify the latent code to perform high-quality semantic image editing [18, 24, 40, 45] or video editing [53, 58, 60].",2,positive
"By changing the latent code, one can achieve many creative semantic editing effects [18, 24, 40, 45] for images.",1,neutral
"2022], and utilize latent edit directions [Abdal et al. 2022; Härkönen et al. 2020; Patashnik et al. 2021; Shen et al. 2020].",2,positive
[47] applied Principal Component Analysis on the latent space and proposed to control the semantics by layer-wise perturbation along the principal directions.,1,neutral
"Early unsupervised methods (Shen and Zhou 2021; Härkönen et al. 2020) apply Principal Component Analysis (PCA) on latent space or model weights, and interpretable control can be performed by layer-wise perturbation along the principal directions.",1,neutral
"Early unsupervised methods (Shen and Zhou 2021; Härkönen et al. 2020) apply Principal Component Analysis (PCA) on latent space or model weights, and interpretable control can be performed by layer-wise perturbation along the principal directions.",1,neutral
"…(Wu, Lischinski, and Shechtman 2021). winit can be semantically manipulated by a pre-trained style editing models (Shen and Zhou 2021; Härkönen et al. 2020; Shen et al. 2020; Patashnik et al. 2021; Wang, Yu, and Fritz 2021; Li et al. 2021; et al. 2021a; Ling et al. 2021; Shi et al.…",2,positive
"winit can be semantically manipulated by a pre-trained style editing models (Shen and Zhou 2021; Härkönen et al. 2020; Shen et al. 2020; Patashnik et al. 2021; Wang, Yu, and Fritz 2021; Li et al. 2021; et al. 2021a; Ling et al. 2021; Shi et al. 2022; Chong, Lee, and Forsyth 2021; Hou et al. 2022).",2,positive
", 2020), GANspace (GS) (Härkönen et al., 2020), LatentDiscovery (LD) (Voynov & Babenko, 2020) and DisCo (Ren et al.",2,positive
"The GAN-based baselines include InfoGAN-CR (Lin et al., 2020), GANspace (GS) (Härkönen et al., 2020), LatentDiscovery (LD) (Voynov & Babenko, 2020) and DisCo (Ren et al., 2021).",2,positive
"Without label annotation, other methods explore the latent space by unsupervised [13, 29, 32, 33] or self-supervised ways [15, 24] to find more semantic directions way.",1,neutral
"StyleGAN (Karras et al., 2019; 2020; 2021) in particular has a thoroughly studied latent space, which allows principled control of generated images (Bermano et al., 2022; Härkönen et al., 2020; Shen et al., 2020; Abdal et al., 2021; Kafri et al., 2022).",2,positive
", 2019; 2020; 2021) in particular has a thoroughly studied latent space, which allows principled control of generated images (Bermano et al., 2022; Härkönen et al., 2020; Shen et al., 2020; Abdal et al., 2021; Kafri et al., 2022).",2,positive
"Although they provide some control over the camera poses [36, 37, 15, 38], they lack explicit 3D understanding of the scenes.",0,negative
"For a certain attribute, they search for a certain direction in the latent space, and then alter the target attribute via moving the latent code z along the searched direction [6], [9], [10], [11], [12].",1,neutral
"However, the existing methods [6], [8], [9], [10], [11], [12] mostly require additional information like extra annotation or human selection.",0,negative
"Some recent works [8], [10], [12] identify the essential directions in the latent space via the techniques like",1,neutral
"Some recent works [8], [10], [12], [25] search for steerable directions using techniques like Principal Component Analysis (PCA) in an unsupervised manner.",1,neutral
", 2021], GANspace [Härkönen et al., 2020], InterfaceGAN [Shen et al.",1,neutral
"Recent works such as Styleflow [Abdal et al., 2021], GANspace [Härkönen et al., 2020], InterfaceGAN [Shen et al., 2020], and StyleSpace [Wu et al., 2021] presented techniques to discover the concepts encoded in the GAN latent.",2,positive
Editing with pretrained GANs (StyleGAN inversionbased models).,2,positive
"When encoders are forced to encode images into GAN’s natural latent distribution, the results suffer from the lack of faithful reconstruction.",1,neutral
"Embedding images in GAN’s space and exploring interpretable directions in latent codes have emerged as important research endeavors on the fixed pretrained GANs [9], [27], [28], [30], [35].",1,neutral
"There have been various architectures [3], [31] and objectives proposed to project an image to GAN’s embedding.",2,positive
"These directions are explored in supervised [27], and unsupervised ways [9], [28], [30], [35], and many directions are found for face editing, e.",1,neutral
Facial attribute editing is also shown to be possible with pretrained GANs.,1,neutral
"To edit a facial attribute of an input image, one needs to project the image to a latent code in GANs’ latent space [1] such that the generator reconstructs the input image from the latent code.",1,neutral
"Facial attribute editing task has been a popular topic among the image translation tasks, and significant improvements have been achieved with generative adversarial networks (GANs) [4], [5], [20], [26], [36], [40].",1,neutral
"We
3 also show this behavior in the Results section 4.3 when comparing our method with state-of-the-art editing with pretrained GANs methods.",2,positive
"For example, with the GANSpace method [9], editing di-",1,neutral
Those methods that employ pre-trained StyleGANs rely on StyleGAN’s semantically rich feature organizations.,1,neutral
"That is if the image is faithfully reconstructed, it may not lie in the true distribution of GANs latent space, and therefore, the directions do not work as expected, which prevents editing the image.",1,neutral
"The disentangled latent space learned by StyleGAN has been shown to exhibit semantic properties conducive to semantic image editing [1, 3, 16, 22, 36, 44, 51, 56, 62].",1,neutral
"Since our 3D domain adaptation is designed to preserve the properties of W and S spaces, we can perform semantic edits via InterFaceGAN [51], GANSpace [22], StyleSpace [62] etc.",2,positive
"Since our 3D domain adaptation is designed to preserve the properties of W and S spaces, we can perform semantic edits via InterFaceGAN [53], GANSpace [23], StyleSpace [63] etc., and geometric edits using TPS (Sec.",2,positive
"Such solutions typically first embed the given input image into the latent space of a pretrained GAN model through a process referred to as GAN inversion [20], and then perform text– conditioned manipulations in the latent space that eventually lead to semantically meaningful changes in the corresponding output images [19], [21], [22], [23].",1,neutral
"We run extensive experiments with directions explored with InterfaceGAN [30], GANSpace [15], StyleClip [26], and GradCtrl [7] methods.",2,positive
"Many methods have been proposed for finding latent directions to edit images [15, 30, 31, 33, 37].",1,neutral
"For this purpose, different GAN inversion methods are proposed, aiming to project real images to pretrained GAN latent space [15, 30, 31, 33, 37].",1,neutral
"These directions are explored both in supervised [3, 30] and unsupervised ways [15, 31, 33, 37] resulting in exploration of attribute manipulations beyond the predefined attributes of labeled datasets.",1,neutral
"For each method, the first column shows inversion, and the second shows InterfaceGAN [30] and GANSpace [15] edits.",1,neutral
"Note that prior works that manipulate one feature at a time in latent space [1, 9, 31, 36, 40, 43] are not applicable in our context.",1,neutral
"Other works use pre-trained image generators such as StyleGAN [16, 17] to achieve high naturalness, but often only focus on the manipulation of attributes in the facial images [9, 31, 36, 43]; not de-identification.",1,neutral
"Identity disentanglement in latent space has not been addressed by prior work and is not possible with existing methods [9, 31, 43].",1,neutral
"Prior work has shown how such disentanglement can be leveraged to manipulate selected facial features [9, 31, 36, 43].",1,neutral
The gender is corrected in the third row by using global direction of GANSpace (only for faces with incorrect gender).,1,neutral
"In the context of non-identity related features, prior research [9, 43] has found that more fine-grained control of facial features is possible when manipulating individual channels.",1,neutral
"To show this, note that there exist many tools for controlling non-identity related attributes, including StyleSpace [43], GANSpace [9], InterfaceGAN [36], StyleCLIP [31].",1,neutral
"Also, we have compared our method with state-of-the-art methods [36, 4, 5, 24] on face attribute manipulation [17, 25].",2,positive
"8) with offthe-shelf GAN manipulation approaches [30, 25, 17].",1,neutral
"In contrast to the previous, supervised method, GANSpace [81] describes an unsupervised approach for discovering semantic directions.",1,neutral
"In contrast to the previous, supervised method, GANSpace [72] describes an unsupervised approach for discovering semantic directions.",1,neutral
To achieve a more disentangled editing it was proposed to orthogonalize a discovered set of semantic Figure 15: Moving along the 10th principal component in 7-8 layers changes hair color [72].,1,neutral
"Inspired by the potential of StyleGAN, several image editing methods based on StyleGAN have been proposed [11, 23, 27].",1,neutral
"The rapid development of Generative Adversarial Networks (GANs) in image generation and synthesis tasks [9, 13–16] has led to the appearance of image editing methods [11, 23, 26, 27, 30].",1,neutral
"For example, GANSpace [11] finds the directions which enable to edit a particular attribute by Principal Component Analysis (PCA) of latent codes.",1,neutral
GANSpace (NeurIPS’ 2020) [11] gets the directions that can edit image attributes by PCA.,2,positive
"For unsupervised approaches, GANSpace [11] finds editable directions for some attributes by performing PCA of latent codes.",1,neutral
"There are several image editing methods based on the disentangled latent space of StyleGAN [3, 11, 23, 25, 27, 28].",1,neutral
"Among GAN-based image editing methods, it has been reported that recently proposed StyleGAN [15] has a disentanglement latent space, and it can edit a particular attribute of the synthesized image by moving the latent code along the certain direction in the latent space [11].",1,neutral
"For StyleNeRF and EG3D, we apply 2D editing method [7] on the frontal image and get an inverted latent code.",2,positive
"We can apply any existing latent code editing methods [7, 21] on the frontal latent code w̄ to get wstyle.",2,positive
"Method 360◦ Editing w/o 3D Auxiliary data Real image Editing 3D Consistent Real-time Editing 2D GANs [7, 10, 21] 7 3 3 7 3 3D-aware [1, 2, 6, 16] 7 3 7 3 7 NeRF editing [12, 31] 3 7 7 3 7 Ours 3 3 3 3 3",1,neutral
"To ensure the high-fidelity, we restrict the camera pose range to lie in StyleGAN’s training pose distribution [1,16,26].",2,positive
"Using existing latent space manipulation techniques, 2D GANs [7,10,21] can produce stylized images from multiple camera poses.",1,neutral
"Recent works [7, 21] found that the pre-trained StyleGAN has a well-behaved latent space, which involves interpretable styles such as pose, !! !"" D A ! .",1,neutral
"Furthermore, when we vary the pose, the baselines degrade quickly: GANSpace incurs obvious background; InterFaceGAN has a large shift; EG3D obtains blurry results.",2,positive
"Previous 2D GAN manipulation works [7, 30, 32] show that the latent space of pre-trained GANs can be decomposed to control the image",1,neutral
"However, since the training dataset cannot cover a diverse and continuous range of viewing directions, both the supervised [11, 21, 23, 29] and unsupervised [7, 22, 30, 32] manipulation methods struggle to make accurate and outof-domain control of viewing directions.",0,negative
"For GANSpace and InterFaceGAN, we use their own stylization
method for editing.",2,positive
w/o Editing w Editing ID↑ PSNR↑ SSIM↑ LPIPS↓ APS↑ Pose ↓ GANSpace [7] 44.,1,neutral
"For 2D manipulation baselines, we choose GANSpace [7] and InterFaceGAN [21], both of which are able to control the pose direction.",2,positive
"To realize this, we restrict the pose range to StyleGAN’s training pose domain and align the images on FaceScape.",2,positive
"Previous 2D GAN manipulation works [7, 30, 32] show that the latent space of pre-trained GANs can be decomposed to control the image
1Code and dataset will be released.
generation process for attribute editing.",2,positive
"In particular, with the improvement of analysis and manipulation techniques for recent Generative Adversarial Network (GAN) models [8, 12, 21, 27, 28], we simply can do this task by manipulating a given image’s latent feature.",1,neutral
"Additionally, some recent research [52, 120] manipulated two or more face attributes and controlled the variation intensity via interpreting the separation boundaries between different facial styles.",1,neutral
"Our experiments show that latent directions found by prior methods adapted to SIS [10, 29] lead to weaker class edits, comparable to random directions (see Sec.",1,neutral
"GANSpace [10] performed PCA on the intermediate generator features, discovering useful directions in the latent space resulting from layerwise perturbations along the principal directions.",1,neutral
"As the dependence on supervision limits the practical use of these methods, [10, 29, 30, 35, 36, 41] investigated unsupervised discovery of GAN controls.",1,neutral
"Prior GAN control methods were mostly evaluated by subjective visual inspection [10, 29, 41].",0,negative
"Ctrl-SIS is compared against the two related latent discovery methods GANSpace [10] and SeFa [29], using the authors’ code 2.",2,positive
"On the other hand, prior work has extensively studied the latent space of unconditional GANs [8, 10, 25, 29, 35, 41], finding interpretable latent directions which activate distinctive factors of variations in the generation process in an unsupervised fashion, without exploiting reference images.",1,neutral
"Following GANSpaceStyleGAN2 [10] and SeFA-StyleGAN2 [29], we train all latent direction methods on features extracted from the normalization layers of each ResNet block in the generator.",2,positive
"GANSpace [20] applies PCA over latent codes to obtain semantically meaningful edits, such as zoom, rotation, hair color, and gender.",1,neutral
Härkönen et al.25 summarized the previous work and realized unsupervised latent space.,1,neutral
Härkönen et al.(25) summarized the previous work and realized unsupervised latent space.,1,neutral
Even unsupervised methods like [Härkönen et al. 2020] rely on intuition about semantics to demonstrate meaningful edit directions.,1,neutral
"0730-0301/2022/12-ART269 $15.00 https://doi.org/10.1145/3550454.3555472
Additional Key Words and Phrases: GANs, example-based media, digital brushes
ACM Reference Format: Maria Shugrina, Chin-Ying Li, and Sanja Fidler.",0,negative
"…many methods allow control and exploration of high-level attributes by leveraging the latent space [Abdal et al. 2020, 2021a,c; Alaluf et al. 2021; Härkönen et al. 2020; Kim et al. 2021; Richardson et al. 2021; Tov et al. 2021], or by modifying GAN architectures with built-in control using…",2,positive
"Generative Adversarial Networks (GANs) [Goodfellow et al. 2014] continue to show impressive results in image generation [Brock et al. 2018; Karras et al. 2021, 2019, 2020b], including scenarios with limited data [Karras et al. 2020a].",2,positive
Generative Adversarial Networks (GANs) [Goodfellow et al. 2014] have shown a remarkable range of applications by approximating a continuous distribution of natural images from unlabeled data.,1,neutral
"Many methods have been developed for semantic editing of images using GANs [Härkönen et al. 2020; Ling et al. 2021; Shen et al. 2020; Zhu et al. 2021] for domains such as human faces and cars, where semantics have a well-defined meaning.",1,neutral
"For example, many methods allow control and exploration of high-level attributes by leveraging the latent space [Abdal et al. 2020, 2021a,c; Alaluf et al. 2021; Härkönen et al. 2020; Kim et al. 2021; Richardson et al. 2021; Tov et al. 2021], or by modifying GAN architectures with built-in control using available labels [Choi et al.",1,neutral
A wide range of approaches for manipulating images using GANs have been developed.,1,neutral
"We follow the same methodology and instead apply deep convolutional GANs to model a distribution of interactive drawing tools, showing a range of novel and expressive applications in control and discovery of digital brushes.",2,positive
"Like other GANs, our model is challenging to evaluate.",2,positive
…an age code explicitly or by traversing the latent space along a linear or non-linear path (a “semantic dimension”) as steered by a pre-trained age classifier [Abdal et al. 2021; Alaluf et al. 2021; Antipov et al. 2017; Härkönen et al. 2020; Or-El et al. 2020; Shen et al. 2020; Yang et al. 2021].,1,neutral
"We thus seek to achieve this goal using photorealisc synthetic faces, taking inspiration in recent work that leverages semantic manipulations within the latent space of powerful neural face models pre-trained on thousands of real faces [Abdal et al. 2021; Alaluf et al. 2021; Härkönen et al. 2020; Shen et al. 2020].",2,positive
"…this goal using photorealisc synthetic faces, taking inspiration in recent work that leverages semantic manipulations within the latent space of powerful neural face models pre-trained on thousands of real faces [Abdal et al. 2021; Alaluf et al. 2021; Härkönen et al. 2020; Shen et al. 2020].",2,positive
"Leveraging the semantics learned by the neural model, this body of research work seeks to re-age a face, represented as a particular latent point, either by interpolating an age code explicitly or by traversing the latent space along a linear or non-linear path (a “semantic dimension”) as steered by a pre-trained age classifier [Abdal et al. 2021; Alaluf et al. 2021; Antipov et al. 2017; Härkönen et al. 2020; Or-El et al. 2020; Shen et al. 2020; Yang et al. 2021].",1,neutral
The parameter space of the model is then traversed along highly elaborate “semantic dimensions” to provide realistic edits such as re-aging [Abdal et al. 2021; Alaluf et al. 2021; Härkönen et al. 2020; Shen et al. 2020].,2,positive
[10] proposes to identify important latent directions based on the Principal Components Analysis (PCA) of the latent space vectors.,1,neutral
"But different from [10], the PCA components are computed from the weight parameters rather that the sampled vectors.",1,neutral
"For instance, PCA is applied in the latent space to create interpretable controls for synthesizing images [8, 26].",1,neutral
"Others [7,8,26,35,52] try to find semantic directions in an unsupervised manner.",1,neutral
"Broadly speaking, we can divide image editing with GANs into two subgroups: (i) Unconditional GAN-based methods [16, 54], which find editing vectors using unsupervised learning methods like PCA [16] or activation maps [54].",1,neutral
"With the advent of models based on StyleGAN [24], there has been a plethora of work focusing on controllable manipulation of the latent code for the task of image editing [9, 16, 48].",1,neutral
"On the other hand, methods like [9, 16, 47, 53, 54] use unsupervised approaches for finding editing directions.",1,neutral
Two popular editing methods are selected for semantic editing: GANSpace [7] and InterfaceGAN [6] to manipulate inverted images.,1,neutral
"[7] utilize typical unsupervised learning strategies, i.",1,neutral
"Some works try to discover interpretable directions in the GAN latent space in an unsupervised manner [17, 39, 46].",1,neutral
"Several works [17, 38] empirically showed thatW supports linear latent code manipulation as they were able to find semantic directions inW corresponding to meaningful disentangled attributes such as color change, zoom, pose, gender, etc.",1,neutral
GANSpace [13] proposes a technique to analyze GANs and create interpretable controls in terms of latent directions based on a Principal Component Analysis (PCA).,2,positive
"(E.g- Curved backrest and Stuffed seat in GANSpace adds changes legs, Connected armrest in GANSpace adds changes to seat, Removing armrest in Closed-form adds changes to backrest, etc.) Although GANSpace has been more successful than Closed-form in identifying directions for common semantics like swivel legs, specific semantics like cantilever legs were not present/clearly distinguishable among directions yielded by either GANSpace or Closed-form.",1,neutral
"Fig.4 shows results of part level semantic manipulation using 3DLatNav, GANSpace [13] and Closed-form [42].",1,neutral
"As shown in Table 2, 3DLatNav outperforms both GANSpace and Closed-form in restricting the semantic changes to a required part, confirming its superior performance in disentangling part-level semantic controls.",2,positive
"3DLatNav consistently outperforms the previous other latent disentanglement and navigation approaches [13,42] in most semantic manipulations.",1,neutral
"4 shows results of part level semantic manipulation using 3DLatNav, GANSpace [13] and Closed-form [42].",1,neutral
Comparison of part-level object manipulation results of 3DLatNav with unsupervised latent disentanglement methods; Closed-form [42] and GANSpace [13].,1,neutral
"Once the image has been inverted, edits can be made in the latent space to re-create the adjusted image [1] [9] [19] [25].",1,neutral
"Recall that prior works such as [5, 21] explored similar properties in GAN latent spaces, but their domain of study was restricted to well-aligned data such as faces or churches.",1,neutral
"Some methods [2,18,39,41] also leverage disentangled properties in the latent space to enable 3D controls.",1,neutral
", W space) [18, 20, 38, 41] or extended latent space (i.",1,neutral
"Control in Image Synthesis Methods In GANSpace: Discovering Interpretable GAN Controls [2], Härkönen et al. propose a method for analyzing the latent space in GANbased methods.",1,neutral
"Control in Image Synthesis Methods In GANSpace: Discovering Interpretable GAN Controls [2], Härkönen et al.",1,neutral
"Meanwhile, the success of the StyleGAN series [24, 25, 26, 27] on generation tasks has established a robust baseline for many downstream tasks such as style transfer [1, 16, 39], GAN-inverse [37], latent space editing [17, 45, 49], and inpainting [63].",2,positive
"GANs synthesize not only realistic images but also steerable ones towards specific content or styles [22, 54, 50, 33, 59, 55, 32].",1,neutral
"This understanding is also evidenced by image editing works [22, 54, 50, 55, 32] which show that interfering with low-resolution feature maps leads to a structural and high-level change of an image, and altering high-resolution feature maps only induces subtle appearance changes.",1,neutral
"Recent methods (Goetschalckx et al., 2019; Shen et al., 2020; Karras et al., 2019; Plumerault et al., 2020; Jahanian et al., 2020; Voynov & Babenko, 2020; Spingarn-Eliezer et al., 2021; Härkönen et al., 2020) show that certain factors such as object shape and position in the images synthesized by generative adversarial networks (GANs) (Goodfellow et al.",1,neutral
"…2019; Shen et al., 2020; Karras et al., 2019; Plumerault et al., 2020; Jahanian et al., 2020; Voynov & Babenko, 2020; Spingarn-Eliezer et al., 2021; Härkönen et al., 2020) show that certain factors such as object shape and position in the images synthesized by generative adversarial networks…",1,neutral
"Another line of works (Voynov and Babenko 2020; Härkönen et al. 2020; Shen and Zhou 2021; SpingarnEliezer, Banner, and Michaeli 2021; Ramesh, Choi, and LeCun 2018; Zhu et al. 2021; Esser, Rombach, and Ommer 2020; Choi et al. 2022) search latent directions without external human supervision.",2,positive
"Another line of works (Voynov and Babenko 2020; Härkönen et al. 2020; Shen and Zhou 2021; SpingarnEliezer, Banner, and Michaeli 2021; Ramesh, Choi, and LeCun 2018; Zhu et al. 2021; Esser, Rombach, and Ommer 2020; Choi et al. 2022) search latent directions without external human supervision.",2,positive
"This method is getting popular recently and both unsupervised methods [43, 17, 36] and supervised methods [19, 35, 52] are heavily explored.",1,neutral
"Recent works [43, 17, 36] show that postprocessing can be applied to find disentangled latent directions in a pretrained GAN space.",1,neutral
", StyleGAN) and the semantic control they exhibit [10, 16, 17, 18].",1,neutral
"For example, GANSpace [11] is an approach that applies PCA on the latent space, and uses the dominant eigenvectors for the image manipulation.",1,neutral
The authors showed that SeFa enables more disentangled manipulation and is thus better for controlling a single semantic attribute compared to GANSpace.,2,positive
"Next, Shen et al. [32] proposed the closed-form factorization (SeFa), which is similar to GANSpace but the PCA was applied on the weight matrices of the afne transformation.",1,neutral
[27] (Apr 2020) create interpretable controls for image synthesis by identifying important latent directions based on PCA applied in the latent or feature space.,2,positive
"Unsupervised Manner Some methods [27, 123] aim to discover interpretable directions in the latent space in an unsupervised manner, i.",1,neutral
"InterFaceGAN [97] CVPR 2020 Face N/A ✗ ✓ synthetic image & label GANSpace [27] NeurIPS 2020 Face, ImageNet N/A ✗ ✓ Unsup.",2,positive
CONFIG [51] GANSpace [27]) InterFaceGAN [97]) NGP [16] SeFa [98],1,neutral
"WarpedGANSpace [175] ICCV 2021 Linear Interpolation ZSN , ZPG, ZBig , Z 1024× 1024 TARR, L1-normalized Correlation of Attribute Distributions GANSpace [176] NeurIPS 2020 Linear Interpolation ZBig , W 1024× 1024 -",1,neutral
"On the other hand, GANSpace [176] models interpretable traversal directions as the principal components of feature tensors in the W space, which capture the major semantic variations of training data (i.",1,neutral
WarpedGANSpace [175] adopts a framework similar to UDID with nZ estimated by a set of Radial basis functions (RBFs).,2,positive
"On the other hand, GANSpace [176] models interpretable traversal directions as the principal components of feature tensors in the W space, which capture the major semantic variations of training data (i.e., facial attributes) and can be solved by Principal Components Analysis.",1,neutral
"The recent success of style-based GANs [28]–[30] in synthesizing HR images and learning disentangled semantic representations has enabled FAM based on latent space navigation [33], [86], [176].",1,neutral
"Method Name Publication Navigation Type Latent Space Resolution Quantitative Metrics StyleGAN2Distillation [167] ECCV 2020 Linear Interpolation W , W+ 1024× 1024 FID, US
StyleSpaceAnalysis [92] CVPR 2021 Linear Interpolation S 1024× 1024 FID, TARR, DCI [168], Attribute Dependency (AD) InterFaceGAN [33] CVPR 2020 Linear Interpolation ZPG, Z, W 1024× 1024 Correlation of Attribute Distributions
ACU [169] ACM MM 2021 Linear Interpolation S 1024× 1024 FID, AD [92], Success Rate of Local Editing, Region Purity AdvStyle [83] CVPR 2021 Linear Interpolation W 1024× 1024 Correlation of Attribute Distributions
EditGAN [170] NeurIPS 2021 Linear Interpolation W+ 1024× 1024 FID, KID, TARR, CSIM EnjoyEditingGAN [171] ICLR 2021 Linear Interpolation ZPG, W 1024× 1024 NAPR, CSIM, US Latent-Transformer [40] ICCV 2021 Linear Interpolation W+ 1024× 1024 The Relation between NAPR/CSIM and Attribute Change Style-Transformer [172] CVPR 2022 Linear Interpolation W+ 1024× 1024 FID, LPIPS, AD [92], SWD [173], Cost Analysis
UDID [174] ICML 2020 Linear Interpolation ZSN , ZPG, ZBig 1024× 1024 TARR, US WarpedGANSpace [175] ICCV 2021 Linear Interpolation ZSN , ZPG, ZBig , Z 1024× 1024 TARR, L1-normalized Correlation of Attribute Distributions
GANSpace [176] NeurIPS 2020 Linear Interpolation ZBig , W 1024× 1024 - SeFa [86] CVPR 2021 Linear Interpolation ZPG, ZBig , Z 1024× 1024 FID, US, Attribute Re-scoring Analysis
LowRankGAN [177] NeurIPS 2021 Linear Interpolation ZBig , Z 1024× 1024 FID, Masked L2 Error of Pixel Value, US, SWD [173] LatentCLR [178] ICCV 2021 Linear Interpolation ZBig , Z 512× 512 US, Attribute Re-scoring Analysis NeuralODE [179] ICCV 2021 Non-linear Traversal W 256× 256 US, Control-Disentanglement Curve
SGF [180] CVPR 2021 Non-linear Traversal ZPG, W -",0,negative
"Meanwhile, generative adversarial network Goodfellow et al. (2020) address their latent space for image editing (Ling et al. (2021), Härkönen et al. (2020), Chefer et al. (2021), Shen et al. (2020),
Yüksel et al. (2021), Patashnik et al. (2021), Gal et al. (2021), Dai et al. (2019), Xu et al.…",2,positive
"Recently, [3], [4] show that the latent space of GAN has rich semantic information and that image manipulation is possible by modifying these latent code w.",1,neutral
"[9] Erik Härkönen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris.",0,negative
"1 Introduction Contemporary generative adversarial networks (GANs) [8, 14, 15, 13, 3] show remarkable performance in modeling image distributions and have applications in a wide range of computer vision tasks (image enhancement [18, 42], editing [9, 31], image-to-image translation [12, 46, 47], etc.",1,neutral
SeFa [14] or GANSpace [15] uncover relevant directions in the latent space of pre-trained StyleGAN that affect the semantic properties of the decoded image in an unsupervised manner.,1,neutral
"Specifically, investigations [3, 4, 18, 40, 45] predict the meaningful offsets or directions in the latent space given image annotations as supervision, while studies [16, 41, 48, 49] disentangle the latent space in an unsupervised manner to find the semantic directions.",1,neutral
"According to these PCA results on vector-based texture codes and shape codes, our TSD-GAN clearly exhibits the capability of controlling the useful directions of textures and shapes, suggesting the potential to assist designers to accomplish “intelligent” designs to some extent.",2,positive
"Then, each PCA result on the texture code of a fashion item is formulated as
pt = G (Tt (xt + ϱ × tk ) ,Ts (xs )) , (15) where ϱ ∈ Ω and ϱ×tk denotes moving along the component tk in the ϱ edit direction.",1,neutral
"Here, sk (k ∈ [1, 5]) denotes the five principal shape components decomposed by PCA; and each PCA result on the shape code of
ACM Trans.",1,neutral
"For texture codes, we use PCA important directions in the latent space.",1,neutral
"Likewise, for shape codes, we also use PCA to learn the first five critical directions in the latent space.",1,neutral
Figure 9 illustrates certain samples generated by PCA.,1,neutral
"In line with this, we use principal component analysis (PCA) [13] to calculate the vector-based texture and shape in the orthogonal direction in order to obtain texture and shape principal components.",1,neutral
"Here, tk (k ∈ [1, 5]) denotes the five principal texture components decomposed by PCA; Ω = [−1, 1] indicates the edit directions of the texture codes.",1,neutral
"In line with this, we use principal component analysis (PCA) [13] to calculate the vector-based texture and shape in the orthogonal direction to obtain texture and shape principal components.",1,neutral
Figure 10 illustrates some samples by utilizing the PCA.,1,neutral
We employ GANSpace [17] method to quantitatively evaluate the manipulation capability of the acquired latent code.,2,positive
"In this work, we leverage GANSpace [17], which performs principal component analysis in the latent space, to demonstrate latent-based manipulation of 3D shape.",2,positive
We perform various edits [17] over latent codes and camera pose acquired by each method.,2,positive
"Thus, other researchers resorted to using an unsupervised approach [17] or contrastive learning based methods [48, 35] to find meaningful directions.",1,neutral
Fréchet basis is compared with GANSpace [12] and SeFa [35] because these two methods are also unsupervised global basis (Sec 2).,1,neutral
"Among them, one approach is to find meaningful latent perturbations that induce the disentangled semantic variation on generated images [7, 12, 33, 35].",1,neutral
", Global directions in StyleCLIP [29], GANSpace [12], and SeFa [35].",1,neutral
"For a fair comparison, we took the annotated basis in GANSpace [12] and compared those with Fréchet basis onW-space of three StyleGAN models.",2,positive
GANSpace [12] suggested the principal components of latent space obtained by performing PCA as global meaningful perturbations.,1,neutral
"Following the experiments in [6], we assessed the global-basis-compatibility by the FID [13] Gap between Local Basis and GANSpace [12] under the same perturbation intensity.",2,positive
"In this work, we focus on the global methods [12, 35].",1,neutral
"We ran this basis refinement on the subspace generated by the existing global methods, GANSpace [12] and SeFa [35].",2,positive
"These methods free users from drawing on face masks and shows superiority over other latent space manipulation methods [17, 21, 35, 47] in component transfer and disentangled attribute manipulation.",1,neutral
GANSpace [17] carries out Principal Component Analysis (PCA) in the latent space of generative networks and explores interpretable controls in an unsupervised manner.,2,positive
GANSpace [16] adopts PCA to find facial semantic representation in the latent space of the GANmodel.,1,neutral
"Recently, learning facial semantics via manipulating latent code in the latent space has achieved great success in high-fidelity face image synthesis [16, 41, 43].",1,neutral
[16] adopt PCA to find the principle face attribute representation in the latent space of GAN model.,1,neutral
GANSpace [20] identify important manipulation vectors as the principal components (PCA),1,neutral
[2] identified important latent directions based on Principal Component Analysis (PCA) and showed a large number of interpretable controls can be defined by layer-wise perturbation along the principal directions.,1,neutral
"Other works show that it is possible to find meaningful directions in latent space in an unsupervised way [20, 21, 49].",1,neutral
"In the image domain, it has been demonstrated that augmentations in an embedded space learned via a GAN [8, 26, 30] or an encoder-decoder model [12] can be used to improve classification performance.",1,neutral
"For example, GAN-based editing methods invert an image to the latent space [1, 9, 14, 99, 121, 138], and edit the inverted image by modifying the latent code [49, 68, 72, 89, 109, 137].",1,neutral
We now show that images inverted with top-ranked models can be further edited using existing GAN-based image editing techniques such as GANSpace [49].,2,positive
"We use the model ranked first by our image-based model retrieval algorithm for inverting the real image, and then we perform editing using GANspace [49].",2,positive
"There are multiple methods [9, 14, 17, 24, 36, 44, 45, 54, 57, 63] to manipulate the latent code, most of them are based on algebraic operations on the latent code.",1,neutral
"One major example of deepfakes is face manipulation with GANs, which has been an emerging topic in very recent years [9, 10, 12, 14, 17, 24, 36, 38, 44, 45, 47, 49, 54, 56, 57, 63].",1,neutral
"The second step is latent code manipulation [9, 14, 17, 24, 36, 44, 45, 54, 57, 63]",1,neutral
"generative factors of GANs, the research community focuses on discovering interpretable and controllable directions in the latent space of pre-trained generators [6]–[9], [17], [24], [28].",1,neutral
"Moreover, GANSpace [17] performs Principal Components Analysis (PCA) on deep features at the early layers of the generator and finds directions in the latent space that best map to those deep PCA vectors, arriving at a set of non-orthogonal directions in the latent space.",1,neutral
"space and the underlying generative factors of GANs, the research community has recently directed its efforts towards discovering interpretable/disentangled directions in the latent space of pre-trained generators [6]–[9], [17]; that is, latent directions travelling across which gives rise to generations where only a single (or a very few) generative factors are",1,neutral
[17] or on certain pre-trained detectors [8].,0,negative
"lability of such methods is very limited, introducing severe changes in the identity characteristics, and their evaluation relies either on laborious manual annotation [7], [17] or on certain pre-trained detectors [8].",0,negative
"Other methods use latent space exploration thanks to backpropagation or principal component analysis [25, 26] and allow precise control of the generation based on the study of the GAN representation.",1,neutral
", 2020) and analyzing(Härkönen et al., 2020) in synthetic latent space.",1,neutral
"Others find meaningful directions in an unsupervised (Härkönen et al., 2020; Shen & Zhou, 2021; Voynov & Babenko, 2020; Wang & Ponce, 2021) or self-supervised(Jahanian et al.",1,neutral
"Instead, GANspace (Härkönen
et al. 2020) performs PCA on the latent space and discover editable and controllable semantic directions directly.",2,positive
"Besides image editing [Härkönen et al. 2020; Jiang et al. 2021; Shen et al. 2020; Shen and Zhou 2021], StyleGAN has also gained attention in video editing.",2,positive
"However, finding decoupled editing directions for different facial expressions is laborious and difficult because these expressions are found to couple with other attributes such as poses in the latent space of StyleGAN due to the bias of the training data [12], [31], [32].",1,neutral
"Previous works have studied these challenges separately, and typical methods include editing of “style” codes [22, 66, 30] and explicit conditions [41, 67].",1,neutral
"Generative Adversarial Networks (GANs) [9] have brought revolutionary changes for image processing field, ranging from image synthesis [6, 29], image editing [10, 18], and even some downstream applications like classification and regression [27].",1,neutral
"Unsupervised methods [10, 22, 24] find meaningful latent directions which make interpretable and distinguishable changes to the image.",1,neutral
"In recent years, with the expressive power of StyleGAN, many researches utilize StyleGAN latent spaces for semantic image manipulation [2, 10, 21, 22, 24].",1,neutral
"While aforementioned 2D GANs [15], [17], [22], [23] allow explicit head pose control to some extent, they fail to guarantee appearance consistency, leading to inconsistent identity or facial attributes when viewed from vastly different angles.",1,neutral
"correlates with the manipulated attribute [12], [13], [14], [15], [16], [16], [17], [18].",1,neutral
"Some works have studied the latent space of StyleGAN [1, 9, 22, 24] and discovered meaningful semantics for manipulating images.",1,neutral
"Modern GANs [8,31,33] are capable of producing high quality images and are increasingly leveraged for image manipulation tasks [26,1].",1,neutral
"Recent works [21,29] further studied the interpolation directions by learning a linear binary classifier, and illustrated the effects of linearly interpolating different channels in a supervised or unsupervised manner [10,28].",1,neutral
"For example, is there a correspondence between interpolation directions in the latent space and visual factors in the generated images? If yes, how can we generate images in a controllable way? Furthermore, are different interpolation directions independent of each other? If not, is it possible to disentangle them in an interpretable fashion? To answer the above important but challenging questions, existing works have studied the learned latent space by identifying and linearly interpolating along directions that correspond to certain semantic factors in the generated images [10,18,21,24,28].",1,neutral
"Another line of works aim to identify semantic controls in a self-supervised or unsupervised manner [6,10,25].",1,neutral
"For example, to modify the color of a car, existing approaches need to learn all the pairwise connections among different colors, which is nontrivial [10,28].",1,neutral
"We compare our method with the related works [10,21,28] by measuring the accuracy and the level of attribute entanglement.",2,positive
"Many attempts have been made to understand and visualize the latent representations of GANs [1,2,10,18,21,24,28,29].",1,neutral
"For example, GANSpace [10] identifies important latent directions by applying principal component analysis (PCA) to vectors in GAN latent space or feature space.",1,neutral
"Furthermore, these models have been shown to contain high-level semantics in their latent space mappings, allowing powerful post-hoc image editing operations, such as changing the appearance and expression of a generated person [1, 56, 22].",1,neutral
The former learns to discover interpretable directions in latent space by leveraging Principal Component Analysis (PCA) [Härkönen et al. 2020] (e.,1,neutral
"In order to compute the PCA of the style codes, GANSpace samples multiple random vectors (i.e., 𝑧 space) and computes the corresponding style codes (i.e., W space).",1,neutral
"Regarding the unsupervised methods, most of them search the interpretable directions using PCA [Härkönen et al. 2020], or introducing orthogonalization [He et al. 2021; Voynov and Babenko 2020] in the latent space.",1,neutral
"The former learns to discover interpretable directions in latent space by leveraging Principal Component Analysis (PCA) [Härkönen et al. 2020] (e.g., using closed-form factorization [Shen and Zhou 2021]) by utilizing a learnable orthogonal matrix [He et al. 2021; Voynov and Babenko 2020] or by…",1,neutral
GANSpace [Härkönen et al. 2020] shows that PCA in the latent space of StyleGAN can find important interpretable directions that can be utilized to control image generation.,1,neutral
"Regarding the unsupervised methods, most of them search the interpretable directions using PCA [Härkönen et al. 2020], or introducing orthogonalization [He et al.",1,neutral
"The former learns to discover interpretable directions in latent space by leveraging Principal Component Analysis (PCA) [Härkönen et al. 2020] (e.g., using closed-form factorization [Shen and Zhou 2021]) by utilizing a learnable orthogonal matrix [He et al. 2021; Voynov and Babenko 2020] or by applying the regularization losses [Peebles et al. 2020; Wei et al. 2021].",1,neutral
"A partition of these methods leverages the naturally disentangled latent space of pre-trained GAN models to develop latent manipulations that allow for specific semantic operations [10,34].",1,neutral
"For the unsupervised approach [CDH*16; VB20; Här*20; SZ21; HKS21; YSEY21; ZFS*21], for example, GANSpace [Här*20] discovered that moving a latent code toward principal directions in a latent space leads to interpretable control.",1,neutral
"GAN images by manipulating latent codes, latent space exploration techniques have been actively studied [VB20; SGTZ20; JCI20; Här*20; YCW*21; SZ21; YSEY21; AZMW21].",1,neutral
"While latent space exploration has been attempted [17, 1, 41], it requires a lot of human labor to discover meaningful directions, and the editings could still be entangled.",0,negative
"While latent space exploration [17, 43, 41] has proved to be effective, it requires extensive human labors to obtain meaningful control for generation.",2,positive
"Exploiting such benefits, some recent works [30,11] focus on the linearity and the interpretability of the pretrained latent space of StyleGAN.",1,neutral
"Recently, some works [14,24,27,31] have been conducted to find these meaningful directions.",1,neutral
"Much like other GAN-inversion and latent space manipulation methods [3,4,13,28,29,39], accurate real-image editing with paint2pix is highly dependent on the ability of used encoder architecture to invert the original real image into StyleGAN [18] latent space.",1,neutral
"Whereas studies in [17, 63, 64] find directions in an unsupervised manner, requiring manual identification of the determined directions later and [55] using a closed-form factorization algorithm for identifying top semantic latent directions by directly decomposing the pre-trained weights.",1,neutral
"By leveraging the disentangling properties of the latent space as shown in [68, 54, 17, 8, 61, 51], extensive image manipulations could be performed.",1,neutral
"For example, GANSpace [10] and InterfaceGAN [23] modify facial attributes via manipulation in the latent space of StyleGAN [15].",1,neutral
"With the understanding of the latent space in GANs, recent approaches based on latent space manipulation [10,23,26] have shown promising results in image editing.",1,neutral
"Although, multiple works [1,23,44,47,56] are built upon this property to generate desired image transformations, there is no established metric to evaluate the extent of this linear correlation in the latent space.",1,neutral
"Several methods [23,47,48] propose ways to find attribute-specific directions in W+ latent space.",1,neutral
"Latent space of pretrained StyleGAN models is highly structured [47] and is popularly used to perform realistic image edits in the generated images [1, 4, 23, 47, 48, 56, 60].",1,neutral
"of popular attributes {gender, smile, age, hair, bangs, beard} [23, 47, 48].",0,negative
"Several unsupervised approaches opted to bypass that limitation [18, 51] albeit still partially entailing model training and data sampling; nevertheless, later, purely unsupervised approaches were proposed",1,neutral
"PCAGAN[9] utilizes principal component analysis (PCA)[10] to determine the main semantic direction of controllable editing in the latent space of GAN, but the editing result depends on the number of sampling points in the latent space.",1,neutral
2 shows the obvious entanglement between pose and coat color attribute in the generated image of cat when edited by PCAGAN method.,1,neutral
"The proposed method is compared with two state-of-the art unsupervised editing methods, SefaGAN and PCAGAN.",2,positive
"For example, Ganspace [7] used Principal Component Analysis (PCA) to identify important latent directions and create interpretable controls for image attributes, such as viewpoint, aging, lighting, and time of day.",1,neutral
"Image editing is a task that modifies a target attribution of a given image while preserving other details [28,7,15,21,20,33,26,22].",1,neutral
"To unsupervisedly discover meaningful latent directions of a pretrained GAN model, GANSpace [19] and SeFa [10] use Principal Component Analysis (PCA) to analyse the latent space.",1,neutral
"And π -GAN [Chan et al. 2021] also learns a multi-identity NeRF model using network layers that are modulated by a noise vector, in StyleGAN fashion [Karras et al. 2019].",1,neutral
"StyleGAN and its derivatives [Karras et al. 2021, 2019, 2020] are popular and powerful full-head models that generate synthetic images with a large variety of facial identities and photorealistic appearance.",2,positive
"While it is possible to separate some semantic components of these models for edits [Abdal et al. 2020; Härkönen et al. 2020; Shen et al. 2020], the results are typically limited to nearly frontal portraits and lack precise consistency in 3D geometry and appearance when rendering from multiple…",1,neutral
"A larger training dataset should also allow for semantic control to be “discovered” by traversing the latent space using facial attribute classifiers, as done for StyleGAN [Härkönen et al. 2020; Shen et al. 2020].",2,positive
"We adopt hierarchical fitting similar to that used with StyleGAN [Abdal et al. 2019]: we first fit an id code to initialize idw and idc, which are then optimized further in their own subspaces.",2,positive
"In fact, even powerful StyleGAN models that are trained on thousands of identities cannot represent identity features that are unique to an arbitrary person not seen during training.",1,neutral
"Data-driven photorealistic face modeling has been a topic of recent research, which has led to very powerful generative models like the StyleGAN variants [Karras et al. 2019].",1,neutral
Others have proposed ways to identify such semantic directions in an entirely unsupervised manner [Härkönen et al. 2020; Shen and Zhou 2020] or in a zero-shot manner by leveraging models [Radford et al. 2021] that jointly encode image and text [Patashnik et al. 2021].,1,neutral
The unprecedented ability of StyleGAN to encode semantic properties within its latent space has spawned an impressive array of image manipulation methods [Härkönen et al. 2020; Patashnik et al. 2021; Shen et al. 2020; Shen and Zhou 2020;Wu et al. 2021a].,2,positive
2021] or even in an unsupervised fashion [Härkönen et al. 2020; Shen and Zhou 2020].,1,neutral
"Such directions can be found with weak supervision [Shen et al. 2020], in a zero-shot manner [Patashnik et al. 2021] or even in an unsupervised fashion [Härkönen et al. 2020; Shen and Zhou 2020].",1,neutral
Others have proposed ways to identify such semantic directions in an entirely unsupervised manner [Härkönen et al. 2020; Shen and Zhou 2020] or in a zero-shot manner by leveraging models [Radford et al.,1,neutral
"Using ideas introduced in [Härkönen et al. 2020] and [Shoshan et al. 2021], the hidden space is disentangled by using a 2 layer feed forward neural network with ReLU activations.",1,neutral
Using ideas introduced in [Härkönen et al. 2020] and [Shoshan et al.,1,neutral
"Generative adversarial networks(GANs) have achieved promising results in various computer vision tasks including image [27–29] or video generation [53, 59, 60, 65], translation [7,20,31,34,73], manipulation [3,15,22,30,36,50], and cross-domain translation [18, 35] for the past several years.",1,neutral
"Unlike the previous methods [55,19,56] that allows implicit pose control, we make StyleGAN enable explicit control over pose.",1,neutral
"Of course, the discovery using SURF-GAN is one of many applicable approaches and we can also utilize the existing semantic analysis methods [55,19,56] because our model is flexibly compatible with well-studied StyleGAN-based techniques.",2,positive
"Recent works [55,19,3,45,56,67,48] have demonstrated semantic manipulation, especially for facial attributes, by analyzing the manifold and finding meaningful direction or mapping.",1,neutral
"In GANSpace [13], a PCA is performed on latent codes to obtain the directions of maximum variations followed bymanual filtering of directions.",1,neutral
"to estimate a linear direction of variation that controls any given attribute [13, 22, 27, 28] in a disentangled manner.",1,neutral
"We compare FLAME quantitatively and quantitatively with three recent face editing methods - InterFaceGAN [27], GANSpace [13] and StyleFlow [3].",2,positive
"proaches: InterfaceGAN [27], GANSpace [13], StyleFlow [3]",2,positive
"Multiple works [3, 7, 9, 13, 27, 31] perform fine-grained image editing by leveraging the rich structure present in the latent space of a pre-trainedGAN.",1,neutral
"This is not uncommon practice to alter only few layers for editing of any given attribute and all the state-of-the-art methods follow this approach [3, 13, 39].",1,neutral
Our method performs at par with the best performing GANSpace [13] method on both CS and ED metrics.,2,positive
"Some works [13, 22, 27, 28] estimate global linear edit directions to model the latent transformation.",1,neutral
Methods such as InterFaceGAN [27] and GANSpace [13] demonstrate the existence of directions in latent space that controls the extent of attributes in the generated image.,1,neutral
"Prior works [3, 4, 13, 27, 30, 33, 35, 39] estimate linear or non-linear paths in the latent space, achieving realistic attribute editing in StyleGAN generated images.",1,neutral
"The 2D GAN manifolds appear to learn 3D geometrical properties implicitly, where recent GAN interpretation methods [14, 51] have shown that manipulating the latent code of the pre-trained GAN models can produce images of the same object under different viewpoints.",1,neutral
"Another line of works, such as InterFaceGAN [50], SeFa [51], GANSpace [14], discover the latent semantic directions of a pre-trained GAN model that can manipulate object rotation unaware of its underlying 3D model.",1,neutral
"Although GAN interpretation methods have shown that manipulating the latent code of StyleGAN produces multi-view images of the same object [14, 51], no studies have quantitatively evaluated the unreliable/inconsistent object shape",1,neutral
"Such latent codes have been shown to learn various disentangled semantics [14,51].",1,neutral
"The widespread use of GANs as opposed to other generative models in the interpretability is done due to the availability of an disentangled latent space [18, 49], which is a property we utilize in our work.",1,neutral
"2 Discovery of Interpretable Directions in Latent Spaces Several unsupervised methods to find interpretable directions in GAN latent spaces have been proposed [8, 24, 26].",1,neutral
"Recently, several unsupervised methods for discovering interpretable directions in GAN latent spaces were proposed [8, 24, 26].",1,neutral
"The FFHQ dataset was first employed to evaluate StyleGAN, which performs unsupervised separation of high-level attributes of face images [283].",1,neutral
"CelebA contains 10,177 number of identities, 202,599 number of face images, and 5 landmark locations along with 40 binary attributes annotations per image.",0,negative
[156] leverages a PCA to decompose the latent space learned by models to factorize controllable latent directions.,1,neutral
"Borrowing the FFHQ dataset, we evaluate the human face editing task for image synthesis by collecting and summarizing results from Abdal et al. [213] in Table 6.",2,positive
"Datasets that have been employed for image editing cover a wide range of types of image, including digit image such as MNIST [6, 96, 113, 122, 130] and The Street View House Numbers (SVHN) [96, 147], and human character, such as CelebA [6, 121, 121, 132, 133, 156], Flickr-Faces-HQ (FFHQ) [120, 156], Helen [132], Labeled Faces in theWild (LFW) [113] and Sprites [130], shape images such as dSprites [153, 154], 3D shapes [154] and ShapeNet [104], fashion image such as DeepFashion [170], animals such as Caltech-UCSD Birds 200 [113] and general scenes such as ImageNet [122, 133, 147, 155] and LSUN [133, 147].",1,neutral
"CelebFaces Attributes Dataset (CelebA) is a large-scale face dataset with more than 200,000 celebrity images [282].",2,positive
[20] show that using principal component analysis can identify meaningful semantic directions in an unsupervised manner.,1,neutral
"One is StyleGAN’s native latent space W [3, 20, 23, 43, 47], where the style code is a 512dimensional vector, and the other is an extended latent space W+ [1, 2, 41, 49, 62], where the style code consists of 18 different 512dimensional vectors.",1,neutral
"Numerous methods have been proposed to find semantically meaningful directions in the latent space of GANs, where semantic directions can be determined through fully-supervised approaches [3, 17, 43, 50, 57, 65], self-supervised approaches [23, 39, 46, 47], or unsupervised approaches [11, 20, 29, 44, 51, 52, 54].",1,neutral
[11] perform PCA on the sampled data to find primary directions in the latent space.,1,neutral
GANSpace [8] detects interpretable controls based on Principal Components Analysis (PCA).,2,positive
"In recent GANs studies [26, 39, 66, 92], the additional mapping network has proven to provide more disentangled semantics for the generator than directly using input codes.",1,neutral
"Several studies explored disentanglement in the latent space of GANs in an unsupervised manner [25,23,9,28,32].",1,neutral
"In [9], the authors found that the principle components of features on pretrained GANs represent high-level semantic concepts.",1,neutral
GANSpace [16] adopts PCA to find facial semantic representation in the latent space of the GANmodel.,1,neutral
"Recently, learning facial semantics via manipulating latent code in the latent space has achieved great success in high-fidelity face image synthesis [16, 41, 43].",1,neutral
[16] adopt PCA to find the principle face attribute representation in the latent space of GAN model.,1,neutral
"For postprocessing, we applied PCA to 1,024 randomly-sampled latent codes to obtain bases W.",1,neutral
InterFaceGAN [29] can control the pose and expression of faces by finding semantic boundaries via the training of a linear SVM. Shen et al. and Härkönen et al. found interpretable paths in a latent space through closed-form analysis [30] and principal components analysis (PCA) [12].,1,neutral
"Inspired by GANSpace [12], we solve this problem by restricting the latent code exploration to certain principal directions.",1,neutral
found interpretable paths in a latent space through closed-form analysis [30] and principal components analysis (PCA) [12].,1,neutral
"These works show that images can be
mapped to the GANs latent space and edits can be achieved by manipulations in the latent space.",1,neutral
"Exploring these interpretable directions in latent codes has emerged as an important research endeavor on the fixed pretrained GANs [28,31,11,29,36].",1,neutral
"There has been a significant progress in image-to-image translation methods [15,26,39,8,23,41,22,25] especially for facial attribute editing [7,27,37,42,21] powered with generative adversarial networks (GANs).",1,neutral
"These directions are explored in supervised [28] and unsupervised ways [31,11,29,36].",1,neutral
"In another line of research, it is shown that GANs that are trained to synthesize faces can also be used for face attribute manipulations [17,5,18].",1,neutral
"However, it is shown that one can embed existing images into the GAN’s embedding space [1] and further one can find latent directions to edit those images [28,31,11,29,36].",1,neutral
"Realistic semantic image edits can be made by steering latents in optimized directions [7, 12, 19], or by finding and activating neurons that encode semantic concepts [2].",1,neutral
"• Relevance feedback:We implement relevance feedback by combining unsupervised interpretable controls based on principal component analysis (PCA) [6] with Thompson sampling, a Bayesian contextual bandit algorithm based on probability matching [3].",2,positive
"Interpretable controls have been created using supervised [20] and unsupervised [6] learning, as well as methods where users draw directly on to an image [24], or combine features from multiple images to achieve the desired output [18].",1,neutral
"In particular, we obtain the controls from the pre-trained sourcemodels using the latent discovery method GANSpace [Härkönen et al. 2020].",2,positive
"In particular, we obtain the controls from the pre-trained source models using the latent discovery method GANSpace [26].",2,positive
", deform a cat ear into a curly shape) compared to using latent directions [26].",1,neutral
We can also apply GANSpace edits [26] to our models to change the object attributes such as poses or colors.,2,positive
"Second, we observe that it is easier to introduce out-of-thedistribution geometric changes (e.g., deform a cat ear into a curly shape) compared to using latent directions [Härkönen et al. 2020].",1,neutral
We use the GANSpace approach [Härkönen et al. 2020] to discover interpretable directions in the intermediate latent spacew .,2,positive
We use the GANSpace approach [Härkönen et al. 2020] to discover interpretable directions in the intermediate latent space𝒘 .,2,positive
", 2020], discovering interpretability [Härkönen et al., 2020], and fine-tuning [Mo et al.",1,neutral
"Several works (Radford, Metz, and Chintala 2016; Chen et al. 2016; Härkönen et al. 2020; Shen and Zhou 2021; Voynov and Babenko 2020; Wu, Lischinski, and Shechtman 2021) focused on disentangling the attributes of the generated images.",2,positive
"Several works (Radford, Metz, and Chintala 2016; Chen et al. 2016; Härkönen et al. 2020; Shen and Zhou 2021; Voynov and Babenko 2020; Wu, Lischinski, and Shechtman 2021) focused on disentangling the attributes of the generated images.",2,positive
"On the other hand, some recent works [25, 41, 48] try to identify the manipulation directions in an unsupervised way by leveraging eigenvector decomposition.",1,neutral
[33] found the latent direction of attributes in the latent space based on principal component analysis.,1,neutral
"While other generative models with explicit modulation of resolution hierarchies have shown properties of disentanglement [35, 36, 22, 21], note that our method was not designed to exhibit this sort of behaviour, and instead seems to be an emergent feature.",1,neutral
"Targeting at finding semantic directions in the latent space of a pretrained generator, in-domain editing [51,22,52,60,63,37,44,3,5,59,4,50] manipulates the attributes of the object, but keeps the same style.",1,neutral
"We refer to an in-domain editing [51,22,52,60] as the editing that only manipulates the latent code, given a fixed pretrained generator.",2,positive
"For image-level editing applications, several approaches [22,51,52] find specific semantic directions in the latent space, e.",1,neutral
"In our work, we use a similar method to GANSpace [14], which applies PCA to latent vectors sampled",2,positive
"Our direction finding method is inspired by GANSpace [14], which applies Principal Component Analysis (PCA) [41] to a set of randomly sampled latent vectors from the intermediate layers of BigGAN [4] and StyleGAN [19] models to find meaningful directions and perform controlled im-",2,positive
"Unsupervised latent space manipulation methods find meaningful directions in latent space in an unsupervised manner [14, 17, 34, 42].",1,neutral
"1 Introduction Generative Adversarial Networks (GANs) [8] have achieved significant advancement over the past several years, enabling many computer vision tasks such as image manipulation [17, 12, 28, 9, 2], domain translation [11, 34, 6, 7, 20, 18], and image or video generation [19, 21, 15, 16, 13, 14, 29, 32, 30, 31].",1,neutral
"[12], [31], [32], [33], [34], [35] 2D L.",1,neutral
"Instead of training a conditional generative model, the other line of works [12], [31], [32], [33], [34], [35] manages to explore the latent space of pretrained generative models, which can randomly generate high-fidelity images of a specific category, to find directions",1,neutral
"While the disentangled style-space of StyleGANs [20–22] allows for control over the viewpoint of the generated images to some extent [13, 26, 42, 51], gaining precise 3D-consistent control is still non-trivial due to its lack of physical interpretation and operation in 2D.",1,neutral
"Some approaches use fundamental techniques such as projection [48], PCA [17], and orthogonal regularization [26], while others use self-supervised techniques to learn interpretable representations [36].",1,neutral
", [34, 11]) or by incorporating pre-trained detectors [32].",1,neutral
", ProgGAN [14], and StyleGAN2 [15]) and compare with GANSpace [11], WGS [32], and StyleCLIP [23].",1,neutral
"Exploring the latent space of a pre-trained GAN in an interpretable manner has typically been approached by the research community by discovering a set of linear [34, 11] or non-linear [32] latent paths, in an unsupervised or (semi)supervised manner, and then trying to label them based either on laborious manual annotation (e.",1,neutral
"In this section, we first compare the proposed method, which discovers non-linear paths in the GAN’s latent space and may adopt non-linear or linear paths in the text space, with GANSpace [11] and WGS [32], which discover linear or non-linear paths, respectively, in the GAN latent space in an unsupervised manner.",1,neutral
"Exploring the latent space of a pre-trained GAN in an interpretable manner has drawn significant attention from the research community during the recent years [11, 34, 31, 22, 32, 9, 29, 24, 12, 1, 35, 30].",1,neutral
", [34, 11]) or by incorporating pre-trained detectors (e.",1,neutral
", by preserving certain attributes such as hair style and facial expressions) and far less artifacts, without the need of labeling them using manual annotation [11] or certain pretrained detectors [32].",0,negative
Figure 9: Comparison of the proposed method with GANSpace [11] and WGS [32].,2,positive
ID (↑) Age (↓) Gender (↓) Skin (↓) Hair (↓) Beard (↓) GANSpace [11] .,0,negative
"GANSpace [11] performs PCA on deep features at the early layers of the generator and finds directions in the latent space that best map to those deep PCA vectors, arriving at a set of non-orthogonal directions in the latent space.",1,neutral
"The general idea of optimizing latent representations or parameters of an image generator using a separately trained classifier has been widely used as a powerful framework for generating, editing and recovering images (Dhariwal & Nichol, 2021; Abdal et al., 2019; Härkönen et al., 2020).",1,neutral
"The general idea of optimizing latent representations or parameters of an image generator using a separately trained classifier has been widely used as a powerful framework for generating, editing and recovering images (Dhariwal & Nichol, 2021; Abdal et al., 2019; Härkönen et al., 2020).",1,neutral
"Controllable GAN Generation Increasingly powerful image GAN models have sparked interest in steerable image generation methods that synthesize an image by guiding the generator towards some objective: GAN output can be steered by directly guiding generation towards target images [12]; or by optimizing loss of a classifier [8, 23]; or PCA, clustering or other methods can also be used to directly identify meaningful representation subspaces for manipulating a GAN [3, 11, 24].",1,neutral
"The state-of-theart DALL-E [21] uses CLIP; and CLIP has also been combined with StyleGAN [2, 14, 19], BigGAN [18], and VQGAN [4–6].",1,neutral
"Figure 1 presents samples of generated images: the first row shows images generated with the original VQGAN+CLIP setting, capturing the visual concepts of the target prompts, and in cases of “peas”, “time”, “focus”, and “police” also showing the letters of the words.",1,neutral
"We use an open-
source implementation from [5] of a VQGAN generation model [6] which steers the image generation based on a text prompt.",2,positive
"In case of nonsense strings, the VQGAN+CLIP method is more likely to produce image text, possibly because nonsense string text prompts do not have a visual meaning associated with them.",1,neutral
"Like these methods, we investigate the ability of CLIP to steer VQGAN, however instead of generating individual images, we ask whether the broad ability of CLIP to read and draw visual words can be controlled.",2,positive
"We generate 1000 images conditioned on real English words from our validation set, and 1000 images conditioned on nonsense strings from the validation text string set using VQGAN+CLIP and both of our projection models.",2,positive
"Alternative methods have involved specially designing the GAN architecture to facilitate modification [24, 39], while others involve utilizing various mathematical techniques such as principal component analysis [16] to identify important dimensions within the latent space or even building customized models that can learn to manipulate the latent space, such as in [41].",1,neutral
"Unsupervised approaches typically involve identifying components within the latent GAN space [7, 16].",1,neutral
"Recent work has demonstrated that Generative Adversarial Networks (GANs) [15] encode human-interpretable representations of semantic concepts [14, 42, 16, 7, 41], which partially explains their performance in semantic editing tasks.",1,neutral
"Due to their high performance in modeling highly complex features, the most popular techniques involve various approaches built on generative neural networks [28, 2, 11, 42, 41, 27, 32, 16, 7], although other neural architectures [4, 29] have also shown promise.",1,neutral
"Moreover, GANs like StyleGAN [28, 29] have been shown to form a semantic understanding of the modeled images in their features [3, 4, 15, 22, 25, 35, 56, 61, 63, 68, 73], which has been leveraged in diverse applications, including image editing [10, 20, 31, 32, 37, 60, 76], inverse rendering [71], style transfer [1, 30], image-to-image translation [8,9,23,51], and semi-supervised learning [35,68,73].",1,neutral
We use GANSpace [21] and StyleCLIP [40] for finding an editing direction δw in the W latent space.,2,positive
"After inversion, we can edit the inverted code by traversing semantically meaningful directions computed using supervised [9, 25, 47] or unsupervised approaches [17, 21, 41, 48, 52].",1,neutral
We use GANSpace [21] and StyleCLIP [40] for finding an editing direction δw+ in the W+ latent space.,2,positive
"The paths can also be learned by Principal Component Analysis or self-supervised approaches without annotation [15, 16].",1,neutral
The latent space distiller [34] is used to achieve attribute disentanglement and GANSpace [11] performs PCA on the sampled data to find primary directions in the latent space.,1,neutral
"[8, 26, 28] attempt to identify useful directions in an unsupervised manner.",1,neutral
"Alternative methods [8, 9, 25, 28, 35] find meaningful latent directions using unsupervised approaches.",1,neutral
"However, whilst several methods identify ways of manipulating the latent space of GANs to bring about global semantic changes–either in a supervised [16, 44, 48, 47] or unsupervised [53, 49, 20, 52, 42] manner–many of them struggle to apply local changes to regions of interest in the image.",1,neutral
"A popular line of GAN-based image editing research concerns itself with learning so-called “interpretable directions” in the generator’s latent space [20, 49, 48, 53, 52, 57, 21, 18, 19].",1,neutral
"Understanding the representations induced by these networks for interpretation [3, 47, 57] and control [48, 47, 49, 20, 53, 15, 52, 63, 55, 1] has subsequently received much attention.",1,neutral
"Developing a better understanding of the way in which high-level concepts are represented and composed to form synthetic images is important for a number of downstream tasks such as generative model interpretability [47, 3, 57] and image editing [20, 49, 48, 53, 52, 2].",1,neutral
"For the StyleGAN architecutre, InterFaceGAN [Shen et al. 2020], GANSpace [Härkönen et al. 2020], StyleFlow [Abdal et al. 2021b], and StyleRig [Tewari et al. 2020a] propose linear and non-linear edits of the underlying𝑊 and𝑊 + spaces.",2,positive
"2020], GANSpace [Härkönen et al. 2020], StyleFlow [Abdal et al.",2,positive
Note that this method is widely used by Gan-based image editing methods like InterfaceGAN [Shen et al. 2020] and GANSpace [Härkönen et al. 2020].,1,neutral
"On the other hand, the global methods search layer-wise perturbation directions that perform the same semantic manipulation on the entire latent space [14, 35, 37].",1,neutral
We chose GANSpace [14] as a global basis because of its broad applicability.,2,positive
The global basis proposed in GANSpace is PCA components of latent variable samples.,2,positive
"The results provide an explanation for the superior disentanglement of W-space observed in many literatures [14, 21], and suggest that the layers 6, 7 can serve as a similar-or-better alternative.",1,neutral
We chose the Fréchet Inception Distance (FID) [15] gap between Local Basis and GANSpace as a measure of global-basis-compatibility.,2,positive
"Local Basis Several previous works suggested unsupervised methods to find semantic-factorizing directions based on the geometry of the target latent space in a pre-trained GAN model [8, 14].",1,neutral
GANSpace [14] showed that the principal components obtained by PCA can serve as globally meaningful traversal directions.,1,neutral
"Here, global basis refers to the sample-independent semantically meaningful perturbations on a latent space [8], for example, GANSpace [14] and SeFa [35].",1,neutral
FID gap represents the difference between FID score of Local Basis [8] and the global basis [14].,1,neutral
"FID is measured for 50k samples of perturbed images along the 1st component of Local Basis and GANSpace, respectively.",2,positive
"On the other hand, unsupervised methods [20,39] were proposed to find semantic direction without using attribute classifier.",1,neutral
"The typical knowledge, like the expression, age, or gender of facial images, may only contain information of low dimensions (Penev & Sirovich, 2000; Härkönen et al., 2020; Shen et al., 2020).",1,neutral
"The typical knowledge, like the expression, age, or gender of facial images, may only contain information of low dimensions (Penev & Sirovich, 2000; Härkönen et al., 2020; Shen et al., 2020).",1,neutral
"For pre-trained GAN-based baselines, we adopt GANspace (GS) [20], LatentDiscovery (LD) [39], ClosedForm (CF) [37], DeepSpectral (DS) [26] and DisCo [36].",2,positive
We compared the rotation and smile directions found by our approach to those previously found by InterFaceGAN [33] and GANSpace [17].,2,positive
Visual comparison of editing a randomly sampled latent code in the smiling directions found in GANSpace [17] and InterFaceGAN [33] with the happiness direction found in this work.,1,neutral
GANSpace [17] finds interpretable directions in an unsupervised fashion with PCA while manual examination of the found directions is required.,0,negative
"Comparison of rotations produced by GANSpace [17] (top 2 rows), InterFaceGAN [33] (third row) and our approach (bottom).",1,neutral
The quality of the edits performed with these directions is on par with the corresponding edits using GANSpace [17] and InterFaceGAN [33].,2,positive
"To perform rotations with GANSpace [17], we initially used the 2nd principal component applied to the first three style vectors.",1,neutral
Qualitative comparison of the found rotation direction with the equivalent edits from InterFaceGAN [33] and GANSpace [17] applied on the FEI face database [36].,2,positive
"Hence, our approach is still compatible with unsupervised editing techniques such as GANSpace [22] (fig.",2,positive
"Although several methods [10, 23, 24] have shown the successful pose control by discovering a direction related to pose in the latent space of StyleGAN, they haven’t found accurate mapping for frontalizing an arbitrary image in an unsupervised manner.",1,neutral
"Several techniques of StyleGAN latent manipulation [10, 23, 24] have been combined with GAN inversion [2, 22] for real image editing.",1,neutral
"Directions of variation naturally emerge in the latent space and can be discovered when guided by geometry/color changes [31], language or attributes [59, 63, 75, 2, 88], cognitive signals [17], or in an unsupervised manner [21, 76, 61].",1,neutral
"In global manipulation works, interpolations in the latent space are located which correspond to edits over the entire image, either via visual attribute classifiers [10, 33, 57, 71], unsupervised disentanglement [26, 47, 56, 63, 67], or via image-text similarity [3, 11, 22, 40, 46, 55, 68].",1,neutral
"Many studies have utilized pre-trained StyleGAN [9, 10] in various fields, such as image encoding [20, 25, 28], discovering latent semantics [4, 21, 23], image editing [1, 22] and transfer learning [7, 16, 17].",1,neutral
"On the other hand, the unsupervised approach (Shen & Zhou, 2021; Härkönen et al., 2020) explores the principal components of the sampled latent codes and observes if these codes correspond to semantically meaningful editing directions.",1,neutral
"Smile Age Gender Glass InterfaceGAN 0.0515 0.1294 0.1225 0.0916 GANspace 0.1081 0.0975 0.0507 0.1420 Ours 0.0047 0.0660 0.0491 0.0279
Identity-agnostic Analysis It is essential to preserve the identity in face editing.",0,negative
"We consider the following two methods: InterfaceGAN (Shen et al., 2020b) and GANspace (Härkönen et al., 2020).",2,positive
"InterfaceGAN is a supervised disentangle method obtaining edit directions from trained SVMs, while GANspace is an unsupervised disentangle method that discovers edit directions from the principal components of sampled latent codes.",1,neutral
[19] presented GANSpace which collected a set of latent codes and conducted PCA [9] on them to obtain principal components as primary directions in the latent space.,2,positive
"Note that unsupervised methods (e.g., GANSpace, SeFa) might fail to edit unnatural attributes (i.e., glass) due to the lack of supervision from attribute labels.",1,neutral
"Both supervised [24,3,14] and unsupervised [12,27,25] approaches are employed to search for meaningful editing directions.",1,neutral
", GANSpace[12], and SeFa [25]) on the estimated latent codes from both encoders.",2,positive
"We show comparison with different editing methods including InterfaceGAN [24], AdvStyle [30], GANSpace[12], and SeFa [25].",2,positive
"For instance, GANSpace [12] and SeFa [25] adopt principal components analysis (PCA) and eigenvector decomposition to search for editing directions respectively.",1,neutral
"As for image manipulation, studies explore the capability of attribute disentanglement in the latent space with supervised [2, 33, 79] and unsupervised [29, 80, 87, 94] networks.",1,neutral
"Work in this field has focused on uncovering semantic directions, either in a supervised [22, 31, 52] or unsupervised way [29], or on spatially editing images using GANs [76, 7, 44, 9].",1,neutral
"Our framework is motivated by the following observation [1, 13] – objects generated by BigGAN, despite originating from different domains, share high content correspondences when generated from the same latent code.",2,positive
"Most commonly, recent works perform a latent space traversal of the GAN’s learned manifold for controlling a speciic attribute of interest such as age, gender, and expression [Abdal et al. 2020b; Goetschalckx et al. 2019; Härkönen et al. 2020; Jahanian et al. 2020; Shen et al. 2020; Shen and Zhou 2020; Voynov and Babenko 2020; Wu et al. 2020].",1,neutral
"For example, as shall be shown, pairing StyleFusion with GANSpace [Härkönen et al. 2020] or StyleCLIP [Patashnik et al.",1,neutral
"2020], GANSpace [Härkönen et al. 2020], and StyleCLIP [Patashnik et al.",2,positive
"For example, as shall be shown, pairing StyleFusion with GANSpace [Härkönen et al. 2020] or StyleCLIP [Patashnik et al. 2021] leverages their diverse manipulations while ensuring that the resulting edits alter only the desired semantic regions.",2,positive
"…traversal of the GAN’s learned manifold for controlling a specific attribute of interest such as age, gender, and expression [Abdal et al. 2020b; Goetschalckx et al. 2019; Härkönen et al. 2020; Jahanian et al. 2020; Shen et al. 2020; Shen and Zhou 2020; Voynov and Babenko 2020; Wu et al. 2020].",1,neutral
"For InterFaceGAN and GANSpace we use their official implementation and latent directions, while for StyleCLIP we adapt the official implementation to train a latent mapper which manipulates only the desired image region.",2,positive
"In Figure 14 we show the advantage of using StyleFusion’s disentangled representation when editing images using three latent traversal editing methods: InterFaceGAN [Shen et al. 2020], GANSpace [Härkönen et al. 2020], and StyleCLIP [Patashnik et al. 2021].",2,positive
"We then manipulate the resulting code to obtain the edited representation wedit (e.g., via a traversal along a latent path learned by InterFaceGAN or GANSpace).",2,positive
"Previous works aiming at finding semantic directions can typically be divided into the supervised ones [12, 32], the self-supervised ones [19, 35], and the unsupervised ones [15, 34].",1,neutral
"Next, the resulting latent code can be semantically edited using a wide range of methods [2, 21, 36, 43, 49].",1,neutral
"Studies show that disentanglement of semantic attributes can be achieved by carefully searching for latent directions learned by GANs [12,41,50], but all attributes being factorized have to be identified by humans.",1,neutral
"Recent studies [12, 41, 50] show that rich semantically meaningful directions (e.",1,neutral
"Research such as [20, 31] explore the latent-space of StyleGAN to identify the interpretable semantic directions that control attributes such as aging, smile, gender, pose, etc.",1,neutral
"…has been studied extensively and enabled image editing using linear and non-linear latent space arithmetic [Abdal et al. 2019, 2020, 2021; Härkönen et al. 2020; Pumarola et al. 2019; Roich et al. 2021; Shen et al. 2020; Tov et al. 2021; Zhu et al. 2020]; local, semantically-aware edits…",2,positive
"…on generative adversarial network (GAN) inversion manipulate the latent space of a pre-trained 2D GAN [Choi et al. 2020; Karras et al. 2018, 2021, 2019, 2020;Wang et al. 2018] to adjust expression, pose, lighting, or other attributes [Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020a,b].",1,neutral
"While StyleFlow or other latent space interpolation techniques [Härkönen et al. 2020; Shen et al. 2020] can be used with 2D GANs to control pose via conditional attributes, the results are limited in pose range and suffer from view inconsistencies and changes to the subject likeness during pose…",1,neutral
"These limitations could be alleviated by using PCA-based editing techniques [Härkönen et al. 2020] to synthesize blinking textures, more sophisticated face tracking models, or improving the GAN training procedure to disentangle the subject expression, allowing explicit control similar to what is…",1,neutral
"Moreover, IA-FaceS can find interesting directions at the component level by implementing PCA in the latent space of a specific component, providing users more accurate editing of components and creating more facial expressions.",2,positive
"There are also investigations on finding disentangled directions in GAN’s latent space, including supervised methods [1, 17, 49, 50] and unsupervised methods [6, 8, 10, 18].",1,neutral
"Although some attributes can be edited individually [1, 6, 8, 15, 16], the whole-face single-embedding manner limits the flexibility of editing facial components.",1,neutral
"Here, we can find many interesting fine-grained directions for component editing by applying PCA [6] to the latent space of each component.",1,neutral
"The first stream usually leverages the captured semantics in GAN’s latent space after the generator is trained [1, 6, 29].",1,neutral
) We further apply unsupervised methods [6] to find interpretable directions in the latent space of each component.,1,neutral
"Existing studies on GAN interpretation have affirmed that, pre-trained GAN models own great potential in a range of downstream applications, such as object classification [9, 45], semantic segmentation [49], video generation [23], and image editing [4, 11, 13, 20, 28, 31, 38, 39, 42, 46, 50].",1,neutral
"Compared with prior works which present manipulation results on generated images of BigGAN via manipulating attribute vectors in the latent space [13, 20, 52, 56], our method demonstrates that simply altering only one feature channel could achieve this.",2,positive
"Some attempts are made to also analyze class conditional models [13,20,45,52,56], but they still target the latent space, leaving it unclear how the generator leverages the categorical information.",1,neutral
"component of the latent space [31], or to find a latent space that can edit a meaningful area of generated images by additionally using label information [32] or semantic map [33].",1,neutral
"Some of these works aim to discover specific directions such as expression or gender using supervision [24], while others propose unsupervised approaches to identify semantically meaningful directions [8, 31].",1,neutral
"We used the official implementations for both methods2 and obtained the top 10 principal components for Ganspace
2http://github.com/harskish/ganspace, http:// github.com/genforce/sefa
and the top 10 eigenvectors for SeFa methods using the default parameters.",2,positive
"ture of the latent space of StyleGAN2 in a more principled way [8, 24].",1,neutral
"As can be seen from Figure 6, our method yields more disentangled and diverse directions compared to Ganspace and SeFa.",2,positive
"For example, while both Ganspace and SeFA change semantics in the input, such as gender, age, eyeglasses, while also changing other semantics such as background, position, highlight at the same time.",1,neutral
"Comparison of the top 10 directions for Ganspace [8], SeFa [25] and our method.",2,positive
"We conduct several qualitative experiments to demonstrate the effectiveness of the submodular framework and compare our method to supervised [34] and unsupervised methods [8, 25].",2,positive
Ganspace [8] uses principal component analysis (PCA) [33] on randomly,1,neutral
"On the other hand, unsupervised methods such as [8, 31] find a certain number of directions, but the user has to manually explore what these directions are capable of.",1,neutral
"Recent research has shown that the latent space of GANs contains semantically meaningful directions that can be used for editing images in a variety of ways [8, 9, 31].",1,neutral
Ganspace applies PCA to randomly sampled w vectors of StyleGAN2 and uses the resulting principal components as directions.,1,neutral
"Ganspace [8] uses principal component analysis (PCA) [33] on randomly
sampled latent vectors from the intermediate layers of BigGAN and StyleGAN2 and treats the generated principal components as latent directions.",1,neutral
"Next, we compare our results with the state-of-theart unsupervised methods Ganspace [8] and SeFa [25].",2,positive
identified important latent directions based on PCA applied either in latent space or feature space.(27) They showed that important directions in GAN latent spaces can be found by applying PCA in latent space for StyleGAN2 and layer‐ wise decomposition of PCA edit directions leads to many interpretable controls.,1,neutral
"The meaningful dimensions can be identified by using segmentation-based networks [5], linear subspace models [12], Principal Components Analysis in the activation space [17], or carefully designed disentanglement constraints [28, 33, 38].",1,neutral
GANSpace [11] and Sefa [30] adopt PCA to find the principal directions in W space.,1,neutral
"Despite of the great efforts, inverting [1, 2, 28, 31, 40] or editing [3, 11, 29, 30, 35] images for StyleGAN is still challenging due to following reasons.",0,negative
"For cars, we use the directions provided in GANSpace [11] for editing.",2,positive
"For car domain, we apply GANSpace [11] to find the semantic directions.",1,neutral
"the pretrained and fixed StyleGAN for downstream tasks becomes a hot research topic, especially in the editing task of image-to-image (I2I) translation [3, 11, 29, 30, 35, 36].",1,neutral
"Traditional approaches [11,29,35] assume the linear separations in the latent space for a binary attribute, so inverted code from different images are edited by the same direction.",1,neutral
"limited to the semantics identified in the latent space via a pre-trained classifier [1,41,57] or through a semi-automatic manner [22, 48].",1,neutral
"Through specific latent-space manipulation, high-level attributes such as age or gender can be identified and edited in a realistic manner [1,22,41,57].",1,neutral
"Other methods [22,48] operate without a pre-trained classifier and find the transformations in an unsupervised manner, requiring a manual labelling process to interpret and annotate the “discovered” transformations.",1,neutral
"The manipulations are achieved by latent space analysis [27], [28], utilizing pre-trained classifiers [29], [30], controlling a 3D morphable model [31], etc.",1,neutral
"In addition, we mathematically show that Semantic Factorization (SeFa) [6], GANSpace [7] and regular PCA [11] typically achieve almost the identical results when sampling enough data for GANSpace.",1,neutral
"Study on the Latent Space of a GAN Recent studies [8, 7, 6] on a GAN reveal that a latent space possess a range of semantically-understandable information (e.",1,neutral
"Recent works [6, 7, 8] reveal that there exists a wide range of meaningful semantic factors in the latent space of a GAN, such as facial attributes and head poses for face synthesis [8] and layout for scene generation [9].",1,neutral
"Figure 9: Visualization of individual components within the latent codes, for (1) SeFa [6], (2) GANSpace [7] and (3) regular PCA.",1,neutral
"Based on recent studies [6, 7], we assume that the pre-trained weights of a conditional text-toimage GAN architecture contain a set of useful directions.",1,neutral
"9 plots the latent-code manipulation results of SeFa [6], GANSpace [7] and regular PCA on the CUB bird and COCO data sets.",2,positive
"The scalar parameter for GANSpace [7] is set to 20 on the CUB bird data set and 9 on the COCO data set, respectively.",1,neutral
"Analyzing the correspondences between SeFa, GANSpace and PCA We attempt to discuss the relationship between SeFa [6] and GANSpace [7], since they both introduce an algorithmically simple but surprisingly effective technique to derive semantically-understandable directions.",2,positive
"[7] designed a novel pipeline named GANSpace, which performed PCA [11] on a series of collected latent vectors and employed obtained principal components as the meaningful directions in the latent space.",1,neutral
"Since different hyperplanes for different facial attributes in StyleGAN latent space (Shen et al., 2020; Härkönen et al., 2020) can be found, our method can be used to modify the memorability of the images conditionally.",2,positive
"Since different hyperplanes for different facial attributes in StyleGAN latent space (Shen et al., 2020; Härkönen et al., 2020) can be found, our method can be used to modify the memorability of the images conditionally.",2,positive
"2020], most recent works are completely unsupervised [Gal et al. 2021; Härkönen et al. 2020; Patashnik et al. 2021; Shen and Zhou 2020; Voynov and Babenko 2020; Wang and Ponce 2021; Wu et al. 2020; Xia et al. 2021], potentially enabling the semantic editing of any domain, even for real images [Roich et al.",2,positive
"Moreover, with respect to natural scene objects, the generated images can be edited by enabling the interpretation of the GANs’ latent space [34], [37], [38].",1,neutral
"Most prior arts, however, target at finding global attributes [15, 35, 40, 45] such that altering the latent code with these attributes will manipulate the output image as a whole.",1,neutral
"To interpret the latent space learned by GANs, many attempts have been made, including both supervised ones [20, 35, 45] and unsupervised ones [15, 36, 40].",1,neutral
"Unsupervised methods [12, 35, 44] learn the control by analyzing the statistics or the model weights.",1,neutral
"StyleGAN and others investigate how to enhance desirable properties in GAN latent spaces to influence the characteristics of generated images selectively (Karras et al., 2019, 2020; Härkönen et al., 2020).",1,neutral
"StyleGAN and others investigate how to enhance desirable properties in GAN latent spaces to influence the characteristics of generated images selectively (Karras et al., 2019, 2020; Härkönen et al., 2020).",1,neutral
"GANSpace [12]) proposes to apply principal component analysis (PCA, [35]) to randomly select the latent vectors of the intermediate layers of the BigGAN and StyleGAN models.",1,neutral
"For instance, GANSpace [22] proposes applying principal component analysis (PCA) [57] on a set of randomly sampled latent vectors extracted from the intermediate layers of BigGAN and StyleGAN.",1,neutral
"Since there are no existing approaches for this task, we propose a simple PCA-based baseline inspired by GANSpace [22].",2,positive
"Latent-Space Editing The unprecedented ability of StyleGAN to encode semantic properties within its latent space has spawned an impressive array of image manipulation methods [16, 24, 32, 33, 40].",1,neutral
"Others have proposed ways to identify such semantic directions in an entirely unsupervised manner [16, 33] or in a zero-shot manner by leveraging models [26] that jointly encode image and text [24].",1,neutral
"Given an input latent code w, let us consider that we have a latent code w̃ corresponding to a desired editing, where w̃ is obtained from a latent space editing method [16, 33, 34].",1,neutral
"Recent studies [16, 33, 34, 43] have shown that it is possible to control semantic attributes of synthetic images by manipulating the latent space of a pre-trained GAN, however an efficient encoding method, necessary for real images, still remains an open problem, especially in the case of these editing tasks.",1,neutral
"These techniques include unsupervised exploration [38], learning linear SVM models [33], principle component analysis on the latent codes [16], and k-means clustering of the activation features [10].",1,neutral
"see [12, 24, 30] and Figure 2), including work on co-creativity and computational creativity (e.",1,neutral
"However, there are techniques to facilitate the learning or extraction of disentangled dimensions [4, 12, 29], such that each one represents a (more) interpretable feature.",1,neutral
"[12]), (2) the impact of varying inputs and hyperparameters (e.",1,neutral
"[4]) or “discover” meaningful concepts in a model: For our study, we used the GANSpace approach [12] to automatically select the dimensions from StyleGAN to be controlled via sliders in our study (Section 4.",2,positive
"Currently, there is no guidance on the number of control dimensions to use in various settings, with numbers reported in related work ranging from 5 to 80 dimensions [12, 22, 30].",1,neutral
"Beyond allowing for entering text labels [12, 30], our insights motivate exploring concepts from infovis and information retrieval (e.",2,positive
"As a new way to handle this, researchers have worked on methods to explore and evaluate generative models via interaction [12, 30].",1,neutral
"Principal Component Analysis, PCA, on StyleGAN ’s w vectors, see [12] for details): Concretely, for a task with N sliders, we use this to extract the N top dimensions as ranked by PCA.",1,neutral
"Such UIs have been used to enable interaction for model exploration and evaluation [12, 22, 30].",1,neutral
Figure 2: Examples of the many slider and image grid UIs used in related work to interact with generative image models: (a) UI for editing face photos with the “Smart Portrait Filters” in Adobe’s Photoshop [33]; (b) UI used in the GANSpace paper [12] (sliders manipulate latent dimensions discovered via PCA); (c) UI used in the “Swapping Autoencoders” paper [22] (thumbnail grid; sliders on thumbnails change strength of the corresponding texture edits); (d) Automatically created image gallery for interactive GAN exploration (image grid without sliders) [43]; (e) slider UI used in a user study to evaluatemodel interpretability by interactive reconstruction [30].,1,neutral
We then apply different manipulation directions obtained by GANspace [20] and StyleMC [31].,1,neutral
"They achieve high image fidelity [27, 28], fine-grained semantic control [20, 36, 61], and recently alias-free generation enabling realistic animation [26].",2,positive
inversion and edits the image with a direction discovered by GANspace [20].,1,neutral
"StyleGAN2 [36] features several semantically-rich latent spaces, which have been heavily studied and exploited in the context of image manipulation [4, 15, 26, 60, 61, 65] and image inversion [1,2,10,25,51,85].",1,neutral
"Latent GAN space: There is a plethora of works that investigate the existence of interpretable directions in the GAN’s latent space [13,23,26,34,35,38,39,46].",1,neutral
"This is in contrast to past traversal studies [4, 13, 15, 27, 30] that found global linear directions to suffice for simple scalar attributes.",1,neutral
"Most propose finding global linear directions correlated with scalar attributes of interest [4, 11, 13, 27, 30, 37, 41].",1,neutral
"Latent spaces of deep generative networks like generative adversarial networks (GANs) [12,16,17,28] and variational autoencoders (VAEs) [18] are known to organize semantic attributes into disentangled subspaces without supervision [13, 15, 28, 36, 38].",1,neutral
GANSpace [11] applies Principal Component Analysis (PCA) either in the latent space or feature space to identify useful control directions.,1,neutral
"This property has derived an active research area on exploring interpretable latent subspaces (also referred as latent controls) to modify visual attributes in synthesized images [1, 5, 11, 23, 27, 28, 40, 44].",1,neutral
"Unsupervised methods discover meaningful latent codes or directions by analyzing the space distribution under certain constraints [5, 11, 12, 27, 32, 44].",1,neutral
"[28] use PCA to identify important latent space directions in order to modify the lightning, aging, and viewpoint of",1,neutral
"On this basis, various works (Gu et al., 2020; Härkönen et al., 2020; Richardson et al., 2020; Zhu et al., 2020) explore in detail the StyleGAN potential vector space: some (Shen and Zhou, 2020; Shen et al.",2,positive
") (Härkönen et al., 2020; Shen and Zhou, 2020; Shen et al., 2020), establishing relationship between 3D semantic parameters and genuine facial expressions (Tewari et al.",1,neutral
"2020a,b], such as attribute labels, to unsupervised and zero-shot approaches [Gal et al. 2021; Härkönen et al. 2020; Patashnik et al. 2021; Shen and Zhou 2020; Voynov and Babenko 2020; Wang and Ponce 2021; Xia et al. 2021a].",2,positive
"Such interpretable directions can found in both supervised [1, 20] and unsupervised [4, 8, 9, 18, 21, 24, 26] way.",1,neutral
"Recent methods [4, 8, 18] find such directions with the aid of multimodal representation of CLIP.",1,neutral
"In this section, we qualitatively compare our approach with three state-of-the-art methods for face editing: InterFaceGAN [23], GANSpace [6], and StyleFlow [1].",2,positive
"We find that our generation time is somewhat longer than the InterFaceGAN and GANSpace approaches, but more than four times faster than StyleFlow.",2,positive
"IG, SF, GS, and L2L refer to InterFaceGAN, StyleFlow, GANSpace and our proposed method.",2,positive
"[6] introduced GANSpace, an unsupervised method that uses principal component analysis to find directions for edits.",1,neutral
"For GANSpace, we used components provided by Härkönen [6] that best match these attributes.",2,positive
"In this case, the GANSpace and InterFaceGAN approaches changed the eyebrows, illumination as well as the background of the figure.",1,neutral
"For GANSpace, we used components provided by Härkönen [6] that best match these attributes.",2,positive
"In addition, GANSpace also significantly changed the background of the edited image.",0,negative
"1StyleFlow: https://github.com/RameenAbdal/StyleFlow, GANSpace: https://github.com/harskish/ganspace , InterFaceGAN: https://github.com/a312863063/generators-with-stylegan2
Figure 4 (top left) compares the approaches in adjusting the Age attribute.",2,positive
"In this example, both StyleFlow and GANSpace added glasses to the face when the baldness attribute was moved in the negative direction, while InterfaceGAN radically changed the hair color.",1,neutral
"After finding these directions, GANSpace requires the user to observe the outputs and manually select meaningful directions based on the target attribute.",1,neutral
"A further technique that conserves the initial attributes of the image is to apply the changed latent vector only to some attribute dependent “style” layers of the generator - for instance to layer 6 and 7 of a StyleGAN for “age” [1, 6].",1,neutral
"Consequently, pre-trained unconditional GANs have been incorporated as a building block in many image editing and manipulation tasks, enabling high flexibility while ensuring high quality performances [7, 11, 24, 9, 23, 28].",1,neutral
"A recent line of works [11, 24, 9] extend this to reveal steering directions corresponding to semantically meaningful image transformations in BigGAN’s latent space.",1,neutral
"This can be done by operating directly on the latent codes [17,18] or by analysing the activation space of latent codes to discover interpretable directions of manipulation in latent space [19].",1,neutral
We compare against GANSpace [10] and SeFA [35] by identifying the attributes above in their basis of interpretable directions.,1,neutral
[19] also sought to utilize the GAN latent space for image synthesis with specific properties.,1,neutral
[10] observed that applying PCA on the latent space of Style-GAN and BigGAN retrieves humaninterpretable directions.,1,neutral
"[27] and [22] attempts to learn directions that are easily distinguishable while [25], [26] and [10] finds directions of maximum variance.",1,neutral
"[27] performs unsupervised learning to identify distinguishable directions while [10], [26] and [25] obtains directions analytically.",1,neutral
Analyses for latent space of the generator were also performed to manipulate the semantic of the generation (Peebles et al. 2020; Härkönen et al. 2020).,1,neutral
Analyses for latent space of the generator were also performed to manipulate the semantic of the generation (Peebles et al. 2020; Härkönen et al. 2020).,1,neutral
GANSpace [10] proposes to apply Principal Component Analysis (PCA) [33] to randomly sampled latent vectors of the intermediate layers of BigGAN and StyleGAN models.,1,neutral
"Most of this work discovers domain-independent and interpretable directions such as zoom-in, rotation, and translation [21, 10, 30], while other frameworks propose to find a set of domain-specific directions such as hair color or gender on face images [25] or cognitive features [8].",1,neutral
"Most previous works find that the style space [23, 49, 51, 59, 60], a feature layer after the first 8-layer MLP of the StyleGAN generator, reveals fascinating semantic controlling over synthesis images.",1,neutral
"This can be achieved with unsupervised and self-supervised methods [38,41,47,66], or an auxiliary signal [30, 56].",1,neutral
"Many disentanglement methods assume all images or image attributes can be combined (“mixed-n-matched”) with all others [30, 38, 41, 47, 56, 59, 65, 66].",1,neutral
"InterfaceGAN [39] finds linear directions to edit latent codes in a supervised manner, while GANSpace [21] extracts unsupervised linear directions for editing using PCA in the W space.",1,neutral
"We use the Zero-Shot scores to compare three sets of images; (a) the positive images in X+ as a baseline, (b) the results of applying an edit using our approach in StyleGAN W+ space, and (c) the result of a GANSpace edit that was labeled with the same attribute by [21].",2,positive
Image editing frameworks in the StyleGAN domain [Abdal et al. 2021b; Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020a] analyze the latent space to identify linear and non-linear paths for semantic editing.,1,neutral
"2020] finds linear directions to edit latent codes in a supervised manner, while GANSpace [Härkönen et al. 2020] extracts unsupervised linear directions for editing using PCA in theW space.",1,neutral
"Alternatively, GANSpace [Härkönen et al. 2020] finds latent space manipulations in an unsupervised manner but then the directions themselves are manually labeled and curated in a post process.",1,neutral
We identify GANSpace [21] as the closest (unsupervised) method to compare with.,1,neutral
Note that the “Gender/Male” direction has a higher accuracy score for GANSpace but comparison with the Table 1 in the main paper indicates that the edit might retain some features or changes the attribute minimally which is not desirable.,0,negative
Note that in GANSpace the labels are assigned manually and all directions are curated.,1,neutral
We identify GANSpace [Härkönen et al. 2020] as the closest (unsupervised) method to compare with.,2,positive
"domain, various works [Bau et al. 2018, 2019; Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020a; Wang et al. 2021] explore latent spaces to enable high quality image editing applications.",2,positive
"2020b,a] and semantic control [Abdal et al. 2021b; Härkönen et al. 2020; Shen et al. 2020] together has enabled semantic editing of existing photographs.",2,positive
"We use the Zero-Shot scores to compare three sets of images; (a) the positive images in X+ as a baseline, (b) the results of applying an edit using our approach in StyleGANW + space, and (c) the result of a GANSpace edit that was labeled with the same attribute by [Härkönen et al. 2020].",2,positive
"Instead, we parameterize c as a linear combination of the top-N principal directions ofW space [28, 74]:",1,neutral
"ral network in the latent space of StyleGAN, one could control the global attributes [4, 26, 59, 60] or 3D structure [64] of the generated images.",1,neutral
"For example, InterFaceGAN [59], GANSpace [26] and StyleFlow [4] trains a attribute model in the StyleGAN latent space to control binary attributes.",1,neutral
"Direct manipulations of latent representations inside generative models have been used to create human-understandable changes in synthesized images [Bau et al., 2019, Jahanian et al., 2019, Goetschalckx et al., 2019, Shen et al., 2020, Härkönen et al., 2020, Wu et al., 2020].",1,neutral
"Varying Textures, Backgrounds and More As shown in [14, 29], it is hard to control texture and background in standard GANs.",1,neutral
[14] applied principal component analysis to the GAN space to create interpretable controls for image synthesis.,1,neutral
"For a certain attribute, they search for a certain direction in the latent space, and then alter the target attribute via moving the latent code z along the searched direction [3,4,8,10,11].",1,neutral
"As a result, other studies [16, 40, 46, 47] propose unsupervised approaches to accomplish the same aim without the need for manual annotations.",1,neutral
"Several studies [7, 16, 40, 41, 50] have been conducted to examine the latent spaces learned by GANs,",1,neutral
"Editing directions on human facial domain are obtained from InterFaceGAN [41], while those for church domain are from GANSpace [16].",2,positive
"Using the pre-trained model, several works discover directions in the latent space that correspond to spatial or semantic changes [Härkönen et al. 2020; Jahanian et al. 2020; Peebles et al. 2020; Shen and Zhou 2021; Shoshan et al. 2021].",1,neutral
"We perform various edits [24, 48, 56] over latent codes obtained by each inversion method.",1,neutral
"Thanks to their semantically rich latent representations, many works have utilized these models to facilitate diverse and expressive editing through latent space manipulations [4, 6, 9, 12, 24, 38, 44, 48, 56].",1,neutral
"These range from full-supervision in the form of semantic labels [3, 16, 19, 56] and facial priors [59,60] to unsupervised approaches [24,57,63,64].",1,neutral
GANSpace [6] and StyleSpace [16] allow image manipulation with interpretable controls from a pre-trained GAN generator.,1,neutral
"Besides producing impressive image samples, GANs [15] have been shown to learn meaningful latent spaces [27] with extensive studies on multiple derived spaces [24, 57] and various knobs and controls for conditional human face generation [21, 37, 55].",1,neutral
", on images [1, 37] and on unsupervisedly discovered directions in the latent space [12, 38, 43, 44].",1,neutral
"Recently, growing numbers of works focus on latent space image manipulation [12,13,37,41,45,48] because of the remarkable large scale GANs like StyleGAN [15, 16], which can generate high-resolution images with well disentangled latent space.",1,neutral
"Disentangled image manipulation [1,8,10,12,21,23,37, 38, 43, 44] aiming at changing the desired attributes of the image while keeping the others unchanged, has long been studied for its research significance and application value.",1,neutral
"Despite the convenience of directly using the pre-trained GANs to generate images, all these methods need human annotations [1, 12, 37, 38, 43, 44].",1,neutral
"The latent space Ω can be any of Z,W,W+,S for StyleGAN generator as in [16], and Z,Z+ for BigGAN generator as in [10].",1,neutral
"Several recent works control the semantics of the GANgenerated image by tweaking the latent code to perform global [9, 10, 11, 12, 13, 14] or localized [7, 15, 16, 17] editing.",1,neutral
"GAN-based Image Editing Algorithms Supervision A B C D E F G [10, 11, 12] Unsupervised 3 3 3 3 3 7 7",1,neutral
"Some works use an unsupervised approach to discover meaningful latent space directions, and then manually attribute a semantic to each of the found directions [10, 11, 12, 19].",1,neutral
"Meanwhile, we allow layer-wise (both coarse and fine-grained) semantic editing similar to [10] for both style-based GANs and BigGAN.",2,positive
We see qualitatively in our GANSpace comparison in Fig.,2,positive
"1 Mapping edits to latent space To use these directions found in the activation space to edit the original latent code, we transform this edit tensor back to the original latent space [12].",1,neutral
"The PCA-based method of GANSpace [12] finds interpretable directions in the traditional architectures by first vectorising these tensors vec(Zm) and then learning a PCA basis U that admits the following decomposition
vec(Zm) = UU>vec(Zm) (1) = vec(Zm)×1 UU>.",1,neutral
"In Section 3.3, we introduce the proposed multilinear approach (formulating GANSpace as a special case), and finally in Section 3.4 we detail how we use these learnt directions to modify the latent code.",2,positive
"In this vein, recent methods use auxiliary networks to search for ‘diverse’ image transformations [34, 36], decompose the weights defining the mapping between layers [30], or decompose the intermediate generator’s representations directly [12].",1,neutral
The PCA-based method of GANSpace [12] finds interpretable directions in the traditional architectures by first vectorising these tensors vec(Zm) and then learning a PCA basis U that admits the following decomposition vec(Zm) = UUvec(Zm) (1) = vec(Zm)×1 UU>.,1,neutral
"Since these works, a host of methods have been proposed to explore the latent structure in these generators by imposing structure at training-time [4, 24] or more recently in the pre-trained generators themselves [1, 12, 31, 32, 34, 36].",1,neutral
We show how the linear approach of [12] can be framed as a special case.,1,neutral
From this it is clear that the GANSpace [12] approach as we formulate it using the mode-1 product in Eq.,1,neutral
To further shed light on the connection between our formulation and the linear approach of GANSpace in Eq.,2,positive
"However, of the approaches that decompose the intermediate features directly (such as [12]), a linear decomposition is applied–where we argue a multilinear one can be more suitable in providing an ability to locate different categories of transformation.",1,neutral
"A user can transform the generated outputs by tweaking the latent code [15, 20, 32, 33].",1,neutral
"Moreover, several recent studies have utilized unsupervised methods to obtain semantic directions [15,33,43].",1,neutral
"Likewise, while there is some evidence for property disentanglement within their latent space to independent axes of variation at the global scale [28, 36, 64, 71], most existing GANs fail to provide controllability at the level of the individual object or local region.",1,neutral
There is a growing number of studies investigating interpretable directions to manipulate the latent space of a GAN to synthesize images (Goetschalckx et al. 2019; Shen et al. 2019; Härkönen et al. 2020).,1,neutral
"Inspired by the latent space manipulation technique proposed by (Härkönen et al. 2020), important latent directions are identified by applying PCA to the latent representations of the patients.",1,neutral
There is a growing number of studies investigating interpretable directions to manipulate the latent space of a GAN to synthesize images (Goetschalckx et al. 2019; Shen et al. 2019; Härkönen et al. 2020).,1,neutral
"Inspired by the latent space manipulation technique proposed by (Härkönen et al. 2020), important latent directions are identified by applying PCA to the latent representations of the patients.",1,neutral
Principal Component Analysis (PCA) can also be applied to data points sampled from a latent space to find relevant directions (Härkönen et al. 2020).,1,neutral
Principal Component Analysis (PCA) can also be applied to data points sampled from a latent space to find relevant directions (Härkönen et al. 2020).,1,neutral
"Such an explicit model has the potential of making many subsequent tasks easier and better: better control of feature sampling for decoding and synthesis [70], designing more robust generators and classifiers for noise and corruptions based on the low-dimensional structures identified, or even extending to the settings of incremental and online learning [71,72].",1,neutral
Additional unsupervised approaches for finding semantic directions in StyleGAN include Principal Component Analysis (PCA) on sampled latent codes [15] and the closed-form factorization suggested by [25].,1,neutral
11: To find the optimal interpolation strength α for rotation transfer for InterFaceGAN [24] and GANSpace [15] we compare the images generated by shifting the latent code corresponding to an image from the one rotation towards the other and compare the result with the ground truth.,1,neutral
"Finally, we compare τGAN to InterFaceGAN [24] and GANSpace [15] for the application of semantic face editing by using rotation transfer as one example.",1,neutral
"(i) One line of work relies on the careful dissection of the GAN’s latent space, aiming to find interpretable and disentangled latent variables, which can be leveraged for image editing, in a fully unsupervised manner [47, 24, 25, 12, 13, 14, 48, 49, 26, 27, 50, 51].",1,neutral
"much attention as a promising tool for efficient image editing, as it was found that latent space manipulations often lead to interpretable and predictable changes in output [47, 24, 48, 49, 26, 27, 50].",1,neutral
"Other approaches carefully analyze and dissect GANs’ latent spaces, finding disentangled latent variables suitable for editing [24, 25, 12, 13, 14, 26, 27], or control the GANs’ network parameters [25, 28, 16].",1,neutral
"In another line of work, the 3D scene information is extracted from 2D GANs such as StyleGAN2 to manipulate 2D images in 3D (Shen and Zhou 2020; Härkönen et al. 2020) and recover explicit 3D shapes from images (Pan et al. 2020; Zhang et al. 2020).",2,positive
"In another line of work, the 3D scene information is extracted from 2D GANs such as StyleGAN2 to manipulate 2D images in 3D (Shen and Zhou 2020; Härkönen et al. 2020) and recover explicit 3D shapes from images (Pan et al.",1,neutral
"position, scale) [4, 3, 15], memorability [16] to facial attributes [5, 17, 2, 9, 15, 6, 8].",1,neutral
"Some works attempt to find semantic directions with self-supervised learning [9], unsupervised approaches in latent space such as PCA [2], or by leveraging the internal representation of GANs to derive closed-form solutions [8, 15].",1,neutral
"In particular, some methods find linear directions that can be interpreted as variations of some semantic attributes across the latent space [2, 3, 4, 5, 6, 7, 8, 9].",1,neutral
"For example, GANSpace [2] applies PCA in theW space and the authors are able to assign semantic interpretations to the resulting directions (orthogonal by definition).",1,neutral
"show that principal component analysis (PCA) can be used to create interpretable GAN controls to alter, for example, the gender, age or pose of a generated face [15].",1,neutral
"[15], where interpretable directions in latent space are found using PCA.",1,neutral
create controls by sampling Z space and performing PCA on an intermediate representation of the GAN (W space in StyleGAN or feature space in BigGAN) [15].,1,neutral
"For example, DCGAN uses convolutions in both the generator and discriminator [34], PCGAN progressively grows its architecture, and therefore the resolution of images, during training [21] and BigGAN introduced the “truncation trick”, where images are generated by sampling from a truncated normal distribution [6].",1,neutral
Härkönen et al. create controls by sampling Z space and performing PCA on an intermediate representation of the GAN (W space in StyleGAN or feature space in BigGAN) [15].,1,neutral
"Additivity in the space of StyleGAN was demonstrated in [7, 8, 9], for linearly interpolating between different images along semantic directions as well as for the manipulation of semantic attributes ([10] for example).",1,neutral
"Image Manipulation Our work is also related to recent image manipulation works based on a pretrained generator or CLIP [18, 19, 9, 10].",1,neutral
"Many recent works have proposed methods to interpret the semantics encoded in that space and its extensions and apply them to image editing (Jahanian et al., 2019; Shen et al., 2020a; Härkönen et al., 2020; Tewari et al., 2020; Abdal et al., 2020; Wu et al., 2020; Patashnik et al., 2021).",1,neutral
"Many recent works have proposed methods to interpret the semantics encoded in that space and its extensions and apply them to image editing (Jahanian et al., 2019; Shen et al., 2020a; Härkönen et al., 2020; Tewari et al., 2020; Abdal et al., 2020; Wu et al., 2020; Patashnik et al., 2021).",1,neutral
"Recent works have attempted to overcome these issues by first training an unconditional generator, and then converting it to a conditional model with a small cost [26, 20, 1, 42].",1,neutral
"Some works explore linear manipulations of latent code [26, 20, 46], while others consider more complicated nonlinear manipulations [37, 16, 1, 42].",1,neutral
"Previous methods alleviate this problem by finding the latent semantic vectors existing in pre-trained 2D GAN models [22, 26, 52, 53].",1,neutral
"Many approaches (Jahanian, Chai, and Isola 2019; Yang, Shen, and Zhou 2021; Shen et al. 2020; Balakrishnan et al. 2020; Härkönen et al. 2020) exploit the inherent disentanglement properties of GAN latent space to control the generated images.",1,neutral
"Many approaches (Jahanian, Chai, and Isola 2019; Yang, Shen, and Zhou 2021; Shen et al. 2020; Balakrishnan et al. 2020; Härkönen et al. 2020) exploit the inherent disentanglement properties of GAN latent space to control the generated images.",1,neutral
"Some methods (Härkönen et al., 2020; Tewari et al., 2020a; Shen et al., 2020; Abdal et al., 2020; Tewari et al., 2020b; Leimkühler & Drettakis, 2021; Shoshan et al., 2021) leverage disentangled properties in the latent space to enable explicit controls, most of which focus on faces.",1,neutral
"Some methods (Härkönen et al., 2020; Tewari et al., 2020a; Shen et al., 2020; Abdal et al., 2020; Tewari et al., 2020b; Leimkühler & Drettakis, 2021; Shoshan et al., 2021) leverage disentangled properties in the latent space to enable explicit controls, most of which focus on faces.",1,neutral
"Similarly, generative models can be used to create novel views of images [37, 39, 57] by manipulating them in latent space.",1,neutral
"Previous works [10, 25, 26] can identify a semantically meaningful direction vector in the W or Z space that can manipulates target attribute of r .",1,neutral
"Some previous works [9, 10, 14, 32] Poster Session 1 MM ’21, October 20–24, 2021, Virtual Event, China",0,negative
"The unsupervised approaches [6, 10, 21, 31] aim to discover as many directions as possible using unsupervised techniques.",1,neutral
GANSpace [10] adopts PCA in latent space and identifies important latent directions.,1,neutral
"Note that, our proposed method can perform various local attribute editing tasks, which is much more than previous methods [10, 25, 26, 33].",2,positive
"GANSpace [16] and SeFa [43] use unsupervised learning to achieve face attribute disentanglement, while StyleFlow [3] uses supervised learning to disentangle face attributes.",1,neutral
"In this section, we compare our methods against five concurrent works: Sefa [43], GANSpace [16], Image2StyleGAN [2], InterfaceGAN [42] and StyleFlow [3].",2,positive
The other methods such as SeFa [43] and GANSpace [16] are trained in unsupervised ways.,1,neutral
"Some approaches [2, 3, 16, 43, 44] have tried to extract semantic information from trained GANs [23, 24] and have shown promising performance on image editing.",1,neutral
"On the other hand, unsupervised methods for image editing based on a pretrained GAN [16, 43] have also been proposed recently.",1,neutral
[15] applied principal component analysis over the intermediate features of random samples to determine the principal latent directions.,1,neutral
"In [15, 37], important latent directions are determined by performing principal component analysis and matrix factorization on the features and weights of an intermediate layer, respectively.",1,neutral
"Z latent space[7, 11, 21, 23] and W+ latent space[3, 10, 29] are the most used optimization latent space in GAN inversion methods at present.",1,neutral
"On the other hand, GANSpace (Härkönen et al., 2020) extracts unsupervised linear directions for editing using PCA in the W space.",1,neutral
"In the StyleGAN domain, recent works (Härkönen et al., 2020; Shen et al., 2020; Tewari et al., 2020a; Abdal et al., 2021b) extract meaningful linear and non-linear paths in the latent space.",1,neutral
"In the StyleGAN domain, recent works (Härkönen et al., 2020; Shen et al., 2020; Tewari et al., 2020a; Abdal et al., 2021b) extract meaningful linear and non-linear paths in the latent space.",1,neutral
"Some notable works in this domain (Bau et al., 2018; 2019; Härkönen et al., 2020; Shen et al., 2020; Tewari et al., 2020a) have led to many GAN-based image editing applications.",1,neutral
"On the other hand, GANSpace (Härkönen et al., 2020) extracts unsupervised linear directions for editing using PCA in the W space.",1,neutral
"Some notable works in this domain (Bau et al., 2018; 2019; Härkönen et al., 2020; Shen et al., 2020; Tewari et al., 2020a) have led to many GAN-based image editing applications.",1,neutral
"In computer vision, discovering latent space manipulations for image style transfer has recently become a topic of increased interest, in both supervised (Jahanian et al., 2020; Zhuang et al., 2021) and unsupervised ways (Härkönen et al., 2020; Voynov and Babenko, 2020).",1,neutral
"Controllable generative models have also been developed for images (Härkönen et al., 2020; Esser et al., 2019; Singh et al., 2019; Lample et al., 2017; Karras et al., 2020; Brock et al., 2019; Collins et al., 2020; Shen et al., 2020; Esser et al., 2020; Goetschalckx et al., 2019; Pavllo et al., 2020; Zhang et al., 2018; Chan et al., 2021; Kwon & Ye, 2021; Kazemi et al., 2019), which control the object class, pose, lighting, etc.",1,neutral
"Controllable generative models have also been developed for images (Härkönen et al., 2020; Esser et al., 2019; Singh et al., 2019; Lample et al., 2017; Karras et al., 2020; Brock et al., 2019; Collins et al., 2020; Shen et al., 2020; Esser et al., 2020; Goetschalckx et al., 2019; Pavllo et al.,…",1,neutral
"Another approach, [14], demonstrates that interpretable directions often correspond to the principal components of the activations from hidden layers of generator networks.",1,neutral
"Moreover, since the GAN latent spaces are known to possess semantically meaningful vector space arithmetic, a plethora of recent works explore these spaces to discover the interpretable directions [27, 29, 11, 16, 26, 31, 14, 25].",1,neutral
"Finally, a bunch of recent methods [31, 14, 25] identify interpretable directions without any form of (self-)supervision.",1,neutral
"ing the structure of GAN’s latent space [28, 30, 18, 33, 7, 37, 1, 34, 35, 9, 14, 32, 26, 11].",1,neutral
", [11]) or relies on laborious human labeling [34].",0,negative
GANSpace [11] is trained in an unsupervised manner in order to discover meaningful directions by using PCA on deep features of the generator.,2,positive
"Finally, let us note that in contrast to the global linear directions discovered by [34, 11], in our case the directions along each warping are different for different latent codes.",1,neutral
"More specifically, for a given method that discovers a set of paths, that is, linear in the cases of [34, 11] or non-linear in our case, in the latent space of a pretrained GAN, we generate an image sequence for each path, starting from a random latent code and “walking” towards the positive and the negative ways of the path for a certain amount of steps.",1,neutral
"Figure 8: Automatically discovered non-linear (ours – first row) and linear (Voynov and Babenko [34] – second row, GANSpace [11] – third row) interpretable paths in ProgGAN’s [17] latent space.",1,neutral
"We compare with the corresponding linear directions obtained by [34, 11] and we note that our method both leads to greater variation in the respective generative factors (e.",1,neutral
"GANSpace [11] performs PCA on deep features at the early layers of the generator and finds directions in the latent space that best map to those deep PCA vectors, arriving at a set of nonorthogonal directions in the latent space.",1,neutral
", SN-GAN [25], BigGAN [3], ProgGAN [17], and StyleGAN2 [19]) and compare our non-linear paths to linear ones [34, 11], both qualitatively and quantitatively.",1,neutral
"Finally, our method is closely related to those of [34, 11], since we are also learning a set of interpretable paths in an unsupervised and model-agnostic manner.",1,neutral
"[21] identify important latent directions based on Principal Component Analysis (PCA) to control properties such as lighting, facial attributes, and landscape attributes.",1,neutral
"2020), GANSpace (Härkönen et al. 2020) and SeFa (Shen and Zhou 2020).",2,positive
"Specifically, GANSpace (Härkönen et al. 2020) identifies latent directions based on applied PCA either in latent space or feature space, and interpretable controls can be defined by layer-wise perturbation along the principal directions.",1,neutral
"Methods of this stream (Shen et al. 2020; Härkönen et al. 2020; Shen and Zhou 2020; Hou et al. 2020; Tewari et al. 2020; Abdal et al. 2020; Wang, Yu, and Fritz 2021; Xia et al. 2021; Roich et al. 2021; Alaluf, Patashnik, and CohenOr 2021b; Ren et al. 2021; Lang et al. 2021; Wu, Lischinski, and Shechtman 2021; Patashnik et al. 2021) attempt to achieve controlled image synthesis by exploring the semantics in the latent space of well-trained GANs.",2,positive
"1 below, where the x is the scale parameter customed by user [3]:",1,neutral
"Specially, by utilizing the principal component analysis (PCA) on the intermediate latent space W of StyleGAN2 model [3], this paper achieved high-level properties control of generated building facade images.",2,positive
"In addition, the features of latent space they have brings the possibility to achieve further model explanation and semantic edition of generated images [3, 11].",1,neutral
"Introduce GANSpace and image embedding method to visualize the correlation between the generated building façade images and their corresponding latent vectors, which achieved unsupervised classification and high-level properties control of both generated and novel images.",1,neutral
"In this paper, by training the state-of-the-art GAN based image generation model, StyleGAN2 [2], with high-resolution building façade image dataset, and exploring its latent space by applying PCA and GANSpace analysis, we could overcome above challenges in different extend [3].",2,positive
Above hypothesis has been proved by the research GANSpace [3].,1,neutral
"The manipulations can correspond to linear [Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020a] or non-linear [Abdal et al. 2021; B R et al. 2021] paths in latent space, while disentangled controls can be jointly trained with the generator [Deng et al. 2020].",1,neutral
"Combined with recent methods to project a real photo to such a latent code [Abdal et al. 2019; Tewari et al. 2020b] they also allow semantic image editing, e.g., controlling facial expression or relighting [Abdal et al. 2021; Deng et al. 2020; Härkönen et al. 2020].",2,positive
The manipulations can correspond to linear [Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020a] or non-linear [Abdal et al.,1,neutral
", controlling facial expression or relighting [Abdal et al. 2021; Deng et al. 2020; Härkönen et al. 2020].",1,neutral
GANSpace explores latent directions using PCA and manually identifies the attributes corresponding to each direction.,2,positive
"The 2nd column is the result of GANSpace, where the attributes are not well disentangled.",1,neutral
"(2) We realize controllable and disentangled facial attribute manipulations without any manual intervention, contrary to previous approaches [5, 6].",1,neutral
"Other approaches have attempted to imitate or directly carry out Principal Component Analysis (PCA) in the latent space of generative networks [6, 19].",1,neutral
We compare our manipulation results with two recent state-of-the-art methods: GANSpace [6] and InterFaceGAN [5].,2,positive
"Current approaches assume that a linear interpolation of latent codes lead to smooth variations of a visual attribute [5, 6].",1,neutral
"In each subfigure, from left to right are the original image, the manipulation result of GANSpace [6], that of InterFaceGAN [5] and ours.",2,positive
Competitive approaches to StyleGAN appear in (Gao et al. 2021; Tewari et al. 2020; Härkönen et al. 2020; Nitzan et al. 2020).,2,positive
Competitive approaches to StyleGAN appear in (Gao et al. 2021; Tewari et al. 2020; Härkönen et al. 2020; Nitzan et al. 2020).,2,positive
GANspace [13] performed PCA on early feature layers.,1,neutral
"For attribute
editing, we adopt InterfaceGAN [30] for face images and GANSpace [13] for car images.",2,positive
"editing, we adopt InterfaceGAN [30] for face images and GANSpace [13] for car images.",2,positive
"Using the pre-trained model, several works discover directions in the latent space that correspond to spatial or semantic changes [Härkönen et al. 2020; Jahanian et al. 2020; Peebles et al. 2020; Shen and Zhou 2021; Shoshan et al. 2021].",1,neutral
"Supervised methods find directions to edit the attributes of interest using attribute labels [40, 41, 59], while unsupervised methods exploit semantics learned by the pretrained GAN to discover the most important and distinguishable directions [45, 11, 42].",1,neutral
"While some approaches [40, 41, 45, 42, 11] could perform continuous editing to some extent by shifting the latent code of a pretrained GAN [17, 19, 16, 3], they typically make two assumptions: 1) the attribute change is achieved by traversing along a straight line in the latent space; 2) different identities share the same latent directions.",1,neutral
"But different from [8], the PCA components are computed from the weight parameters rather that the sampled vectors.",1,neutral
[8] proposes to identify important latent directions based on the Principal Components Analysis (PCA) of the latent space vectors.,1,neutral
[14] applied Principal Component Analysis to the GAN input space.,1,neutral
"Finally, interpretable directions can be discovered on w via supervised methods [21], [28], which also can be discovered in unsupervised methods [29], [30], i.",1,neutral
[10] identify semantic directions by applying the principal component analysis (PCA) on sampled latent codes.,1,neutral
"Recently, it has been shown that rich semantic information is encoded in the intermediate features and the latent space of GANs, and furthermore, that images can be effectively edited in a semantically meaningful way by modifying features or latent code [21, 4, 26, 23, 10].",1,neutral
"StyleGAN also possesses several desirable properties including projection (also known as GAN inversion) whereby the latent code of an existing image can be recovered [1, 21]; style-mixing whereby portions of the latent codes from different images can be mixed; and controlled synthesis by perturbing latent codes in important directions like the network weights’ eigenvectors to obtain semantically meaningful changes in the output [13, 25].",1,neutral
"Recent work has analyzed the GAN latent space and network weights [13, 25].",1,neutral
"Thanks to the interpretable controls of GANs, our method could also attain controllable and smooth transitions by walking through GAN latent space.",2,positive
"When we remove the pretrained GANs, our method degrades to a common automatic colorization method without guidance.",0,negative
"Generative priors of pretrained GANs [3, 26, 27, 28] is previously exploited by GAN inversion [1, 13, 38, 41, 62, 63], which aims to find the closest latent codes given an input image.",1,neutral
"On the other hand, our method inherits the merits of interpretable controls of GANs [20, 24, 46, 49] and could attain controllable and smooth transitions by walking through GAN latent space.",2,positive
The prior features from pretrained GANs probably misalign with the input images.,0,negative
Our method also inherits the merit of interpretable controls of GANs and could attain controllable and smooth transitions by walking through GAN latent space.,2,positive
One could easily realize diverse colorization by simply adjusting the latent codes or conditions in GANs.,1,neutral
"In this work, we have developed a framework to produce vivid and diverse colorization results by leveraging generative color priors encapsulated in pretrained GANs.",2,positive
There are several representative attempts aiming to gain more flexible and specific control upon the generation process by identifying editable latent or feature directions: some [11] performed Principal Components Analysis to the latent space or feature space for direction identification; Alharbi et al.,1,neutral
[13] performed PCA on the sampled data to find the important and meaningful directions in the style space of StyleGAN.,1,neutral
"Several unsupervised methods have been suggested for discovering interpretable directions in the latent space of a pre-trained GAN [2,13,37,38,41].",1,neutral
[7] perform PCA on the sampled data to find primary directions in the latent space.,1,neutral
"[12] manipulate semantic attributes of images by analyzing latent space of pre-trained generative models, while Huh et al.",1,neutral
"Generative models, such as generative adversarial networks (GAN) [3, 10, 19], normalizing flows [21], and variational autoencoders [42], have shown remarkable quality in image generation, and have been applied to numerous purposes such as image-to-image translation [7, 11, 31, 32, 35, 47] and image editing [1, 12, 36].",1,neutral
"Specifically, by projecting given images into the latent vectors [1, 2, 4, 49, 57] and manipulating them [6, 11, 12, 26, 36], images are easily edited.",1,neutral
"Furthermore, we showed the image can be further edited using GANSpace [22] (d).",1,neutral
"To investigate this, we apply the latent discovery method GANSpace [22] to the original models.",2,positive
GANSpace [9] discusses the use of PCA (Principle Component Analysis) to GAN (Generative Adversarial Network) to create inter-,1,neutral
"Such a latent space is conductive for tasks such as image editing and image-to-image translation [3, 13, 30, 33, 36].",1,neutral
"These range from image enhancement [18,50], editing [13,36] and recently even discriminative tasks such as classification and regression [27, 48].",1,neutral
"By traversing this intermediate latent space, W , or by mixing different w codes across different network layers, prior work demonstrated fine-grained control over semantic properties in generated images [2, 13, 30, 36].",1,neutral
", 2020), and discovering meaningful latent directions (Shen et al., 2020; Goetschalckx et al., 2019; Jahanian et al., 2020; Härkönen et al., 2020).",1,neutral
"…designing better encoders (Richardson et al., 2021; Tov et al., 2021), modeling image corruption and transformations (Anirudh et al., 2020; Huh et al., 2020), and discovering meaningful latent directions (Shen et al., 2020; Goetschalckx et al., 2019; Jahanian et al., 2020; Härkönen et al., 2020).",2,positive
"These normal vectors are commonly referred to as linear editing directions and many previous works proposed methods to identify them [20, 37, 45, 46].",1,neutral
"Many recent works have proposed methods to interpret the semantics encoded in this latent space and apply them to image editing [2, 20, 37, 45, 50, 57, 62].",1,neutral
"The other part of the hybrid architecture, GANSpace, presents a method for finding significant latent space directions in a trained GAN model (Härkönen et al., 2020).",2,positive
"However, prior works either operate at the scene level [Granskog et al. 2020; Härkönen et al. 2020; Kulkarni et al. 2015; Nie et al. 2020], or rely on learned representations of standard graphics primitives, e.g. voxel grids [NguyenPhuoc et al. 2019, 2020, 2018; Olszewski et al. 2019; Rematas and…",2,positive
GANSpace [Härkönen et al. 2020] explores the linearity of the GAN space and its latent directions based on Principal Component Analysis.,1,neutral
"General decompositions such as PCA analysis could then be considered (Härkönen et al., 2020).",1,neutral
"General decompositions such as PCA analysis could then be considered (Härkönen et al., 2020).",1,neutral
"We achieve this by making use of the advantageous properties of StyleGAN’sW+ space, that have been used for face editing before [9, 25, 26]: Our main assumption is that given a point inW+, the directions into which one would need to shift this point in order to change the identity of the actor that it depicts are mostly orthogonal to those directions that would change the pose/expression/articulation of the actor.",2,positive
"For example, GANSpace [13] requires manually choosing layer subsets; AttGAN [14] and InterFaceGAN [31] requires attribute labels, StyleRig [36] requires a 3D face model.",1,neutral
GANSpace [13] uses PCA to identify meaningful latent directions.,1,neutral
"While other work based on StyleGAN, including EIS [10, 13], focus on manipulating generated images, we focus on the more relevant problem of manipulating real images.",1,neutral
"As an alternative, unsupervised discovery of latent directions in a pretrained GAN [13, 31, 39] allows for finding meaningful latent representations in a computationally efficient way.",1,neutral
"Unlike methods that manipulate the latent space via vector arithmetic [13, 16, 31, 32, 39], EIS formulates the semantic editing problem as copying style coefficients σ of StyleGAN [18] from a reference image to a source image, i.",1,neutral
"While several ways of controlling the generative process have been found [8, 28, 10, 41, 24, 2, 7, 46, 6], the foundations of the synthesis process remain only partially understood.",1,neutral
"From the 3rd column in each subfigure, from left to right are the manipulation result of GANSpace [18], that of InterFaceGAN [34] and ours.",1,neutral
We compare our results with two state-of-the-art methods: InterFaceGAN [34] and GANSpace [18].,2,positive
"GANSpace [18] performed PCA in the latent space of generative networks, explored the principal directions and discovered interpretable controls.",1,neutral
These properties alleviate us to search for directions in the latent space as in [22] or to directly hardcode conditional features in the architecture as in [23].,1,neutral
"In Fig 5, we compare the semantic factorizations of Local Basis and GANSpace [15] for the particular semantics discovered by GANSpace.",1,neutral
"By contrast, the global methods, such as GANSpace [15] and SeFa [16], propose a global direction for the particular semantics (e.",1,neutral
"GANSpace [15] finds a global basis for W in StyleGAN using a PCA, enabling a fast image manipulation.",1,neutral
"(b) Comparison of Latent Traversal Methods (Global methods: GANSpace [15] and SeFa [16], Local methods: Ramesh et al.",1,neutral
We compare the semantic-factorizing directions of GANSpace provided by the authors [15] with Local Basis of the highest cosine similarity.,1,neutral
"In Fig 3, the traversal image of Local Basis is compared with those of the global methods (GANSpace [15] and SeFa [16]) under the strong perturbation intensity of 12 along the 1st and 2nd direction of each method.",1,neutral
We use the popular GANSpace [14] and InterfaceGAN [34] methods for latent-based editing.,2,positive
"We use the popular GANSpace [Härkönen et al. 2020] and InterfaceGAN [Shen et al. 2020] methods for latent-based editing. hese approaches are orthogonal to ours, as they require the use of an inversion algorithm to edit real images.",2,positive
[14] identify latent directions based on Principal Component Analysis (PCA).,1,neutral
"Using this property, many methods demonstrate realistic editing abilities over StylGAN’s latent space [3, 7, 14, 27, 34, 36, 42], such as changing facial orientations, expressions, or age, by traversing the learned manifold.",1,neutral
"Using this property, many methods demonstrate realistic editing abilities over StyleGAN’s latent space [Abdal et al. 2021; Collins et al. 2020; Härkönen et al. 2020; Patashnik et al. 2021; Shen et al. 2020; Tewari et al. 2020a; Wu et al. 2021], such as changing facial orientations, expressions, or…",2,positive
"Some using fullsupervision in the form of semantic labels [10, 11, 34], others [15, 30, 35] find meaningful directions in a selfsupervised fashion, and finally recent works present unsupervised methods to achieve the same goal [14, 39, 40], requiring no manual annotations.",1,neutral
"Interestingly, generative models can also create multiple views of an image: by steering in their latent spaces they can achieve camera and color transformations [30] and more [24, 65].",1,neutral
"7, both GANSpace and SeFa have some degree of influence on the other region when editing a specific region.",1,neutral
Methods FID↓ SWD↓ User Study GANSpace [15] 7.,1,neutral
"C V
] 3
0 N
ov 2
beyond well-defined annotations) and proposed to find steerable directions of the latent space in an unsupervised manner, such as using Principal Component Analysis (PCA) [15].",1,neutral
", unable to identify semantics beyond well-defined annotations) and proposed to find steerable directions of the latent space in an unsupervised manner, such as using Principal Component Analysis (PCA) [15].",1,neutral
"For example, when adding the smile, the identity of GANSpace is changed as well as hairstyle.",1,neutral
"And then, we project the principal vectors into the null space of PCA.",1,neutral
"Prior work [33, 28, 15] has pointed out that the above pipeline could be limited by the labeling step (e.",1,neutral
"We compare our method with GANSpace [15] and SeFa [28] on StyleGAN2, which are the two state-of-the-art unsupervised approaches to image editing.",2,positive
"Rigorously, simply conducting PCA onM in Eq.4 in the main paper does not possess a null space since all the eigenvalues are not equal to zeros.",1,neutral
LowRankGAN (Ours) Figure 7: Comparison on image local editing with GANSpace [15] and SeFa [28].,2,positive
", supervised [13, 30, 18, 24] and unsupervised [33, 15, 28, 31].",0,negative
"We find the most relevant vectors that can control the smile and hair in GANSpace and SeFa, according to their papers.",2,positive
"And the new problem can be categorized to Robust PCA, which is formulated as follows: Problem 1.",1,neutral
This implies that the null space of PCA does not contain any components that could affect the region of the eyes.,1,neutral
"When changing the hair color, GANSpace just has little activation on this attribute, while SeFa has an obvious change in the background.",1,neutral
"To be specific, the attribute vectors that could edit the regions of eyes vanishes after projecting them to the null space of PCA.",1,neutral
Classical PCA seeks the best rank-r estimate of L0 [36] via Singular Value Decomposition (SVD).,1,neutral
"Table 1: Quantitative comparison results on (a) the effect of using null space projection, and (b) the image quality from various image editing approaches [15, 28].",1,neutral
"Previous works [15, 28, 24, 33] could edit some attributes in a specific region but without any control on the rest region, which actually results in a global change on the image when editing the region of interest.",1,neutral
"On the other hand, unsupervised approaches try to discover steerable latent dimensions by statistically analyzing the latent space [15], maximizing the mutual information between the latent space and the image space [33], or exploring model parameters [28, 31].",1,neutral
"Semantic editing is the ability to perform image editing operations on images by manipulating their latent space [11, 34, 39].",1,neutral
"Images can be interpolated and transformed using semantic vectors in the embedding space [11, 34], effectively using it as a strong regularizer.",1,neutral
"For instance, GANspace [Härkönen et al. 2020] is able to extract linear directions from the StyleGAN latent space (W space) in an unsupervised fashion using Principal Component Analysis (PCA).",1,neutral
We further compare with an unsupervised method [15] in Fig.,1,neutral
"Each person was randomly assigned 18 groups of data and asked to choose all of the results they are satisfied with according to three criteria: the result looks natural, the primal attribute is
1For InterfaceGAN, GANSpace and our method, we firstly embed the given images into the W+ latent space of StyleGAN using [Abdal et al., 2019] and then edit them.
well changed, and condition attribute is well preserved.",0,negative
"Another set of works [Shen et al., 2020; Voynov and Babenko, 2020; Shen and Zhou, 2020; Plumerault et al., 2020; Härkönen et al., 2020; Goetschalckx et al., 2019] propose to edit face attribute by moving the latent code along a specific semantic direction in the latent space of well-trained…",2,positive
"We compare our IALS method with several state-of-the-art face attribute editing method proposed recently, including InterfaceGAN [Shen et al., 2020], GANSpace [Härkönen et al., 2020], and STGAN [Liu et al., 2019].",2,positive
Both InterfaceGAN and GANSpace are methods based on GAN latent space search.,2,positive
"Another set of works [Shen et al., 2020; Voynov and Babenko, 2020; Shen and Zhou, 2020; Plumerault et al., 2020; Härkönen et al., 2020; Goetschalckx et al., 2019] propose to edit face attribute by moving the latent code along a specific semantic direction in the latent space of well-trained unconditional GAN model [Karras et al.",2,positive
"[Härkönen et al., 2020] sample a collection of latent codes and perform PCA on them to find principle semantic directions.",1,neutral
", 2020], GANSpace [Härkönen et al., 2020], and STGAN [Liu et al.",1,neutral
"InterfaceGAN is a supervised semantic direction search method as mentioned in the previous section, while GANSpace is an unsupervised one which performs PCA on the sampled latent codes to find principle semantic directions in the latent space.",1,neutral
"Another set of works [Shen et al., 2020; Voynov and Babenko, 2020; Shen and Zhou, 2020; Plumerault et al., 2020; Härkönen et al., 2020; Goetschalckx et al., 2019] propose to edit face attribute by moving the latent code along a specific semantic direction in the latent space of well-trained unconditional GAN model [Karras et al., 2018; Karras et al., 2019; Karras et al., 2020; Goodfellow et al., 2014].",2,positive
"On the other hand, the condition attributes (i.e. eyeglasses) are changed by GANSpace and InterfaceGAN.",1,neutral
"Härkönen et al. [Härkönen et al., 2020] sample a collection of latent codes and perform PCA on them to find principle semantic directions.",1,neutral
"7 show that our method obtained the highest average satisfactory rate (69.66% for ours vs. 62.06% for InterfaceGAN, 35.44% for GANSpace and 6.48% for STGAN).",0,negative
"This motivates several works [Shen et al., 2020; Voynov and Babenko, 2020; Shen and Zhou, 2020; Härkönen et al., 2020] to edit face attribute by reusing the knowledge learned by GAN models.",2,positive
"This motivates several works [Shen et al., 2020; Voynov and Babenko, 2020; Shen and Zhou, 2020; Härkönen et al., 2020] to edit face attribute by reusing the knowledge learned by GAN models.",2,positive
InterfaceGAN and GANSpace only use attribute-level direction while ignoring the instance information when facial editing.,1,neutral
"We assign the directions found by GANSpace to interpretable meanings following [Shen and Zhou, 2020].",2,positive
", [Abdal et al. 2020; Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020]) have tried to analyze and disentangle the latent code of some pretrained GAN space [Karras et al.",1,neutral
"Many other works (e.g., [Abdal et al. 2020; Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020]) have tried to analyze and disentangle the latent code of some pretrained GAN space [Karras et al. 2019] also with labeled data of specific attributes.",1,neutral
"As for the nonlinear mapping network, it comprises repeated downsampling, convolution, batchnorm, and leakyReLU layers until the feature map can be pooled as a vector, i.e., l ∈ R1×512.",1,neutral
"As for the latent space, early methods perform image inversion into W ∈ R1×512 [42, 19, 17], while later works [1, 2, 11, 10] extend the latent space to W ∈ R18×512, which proves to have better reconstruction results.",1,neutral
"Secondly, to modify face representations and resolve the problem of previous latent code manipulation methods [43, 17, 48, 51, 50, 7, 37, 3] that only one attribute can be modified once a time, a novel swapping module, Face Transfer Module (FTM), is proposed to control multiple attributes synchronously without explicit feature disentanglement.",1,neutral
"Finally, the transferred latent code ls2t ∈ Ls2t can be predicted as
ls2t = σ(ω)l̂ high t + (1− σ(ω))l̂highs (3)
where ω ∈ R1×512 is a trainable weight vector, and σ stands for the sigmoid activation.",1,neutral
"As for the latent space, early methods perform image inversion into W ∈ R1×512 [42, 19, 17], while later works [1, 2, 11, 10] extend the latent space to W+ ∈ R18×512, which proves to have better reconstruction results.",1,neutral
"Previous methods [17, 51, 37, 43] have found good controllability of StyleGAN based on the assumption that semantic directions in StyleGAN latent space are linear.",1,neutral
Layerwise manipulation of the GANs are then performed to produce edits in the input image that are interpretable in terms of chosen semantic features [16].,1,neutral
The principal components of activation tensors on the first few layers of the generator represent important factors of variation ([16]).,1,neutral
"Recent research [3, 10, 13, 18, 30, 35] has proposed a number of techniques for interactive GAN image generation, which all could",1,neutral
"Techniques for interactive GAN image generation [3, 10, 13, 18, 30, 35] enable manual creation of specifc images, but not sampling of diverse, high-quality images from a GAN.",1,neutral
"Such algorithmic approaches [13, 18] often search specifc parts of latent space of a GAN using limited number",1,neutral
"Recent studies have shown that GANs naturally learn to encode rich semantics within the latent space, thus changing the latent code leads to manipulating the corresponding attributes of the output images [22, 42, 17, 15, 43, 3, 50, 5].",1,neutral
"Alternatively, we also experiment with sampling according to principal directions; these directions were found to correspond well with interpretable controls in GANspace [21].",1,neutral
"eral interesting properties to emerge, where the generator learns meaningful variations in data without requiring an explicit training objective to do so [21, 53, 12].",1,neutral
"Previous work [1] finds that the intermediate w space is better able to represent images than the original code z, while moving in this space offers controllable and interesting effects [21].",1,neutral
"One set of approaches aims to uncover primary directions of variation in an intermediate latent space [21, 53, 12], while another enforces distinctness of optimized directions during training [58].",1,neutral
"Neural networks improve the fidelity and realism of generative models [14, 28] but limit control and interpretability [5, 6, 8, 16].",1,neutral
Principal component analysis (PCA) has been one of the effective tools for visualizing and analyzing embedded feature distribution (Härkönen et al. 2020).,1,neutral
Principal component analysis (PCA) has been one of the effective tools for visualizing and analyzing embedded feature distribution (Härkönen et al. 2020).,1,neutral
"The above methods try to learn a GAN generator with explicit interpretable representations; in contrast, another class of methods, post-processing methods, try to reveal the interpretable factors from a well-trained GAN generator [9, 3, 35, 39, 32, 12, 38, 36].",1,neutral
"According to this property, one can identify semantic attributes from different layers of a well-trained generator by performing post-processing algorithms [3, 12, 36, 39], and then can manipulate these attributes on the synthesized images.",1,neutral
"[12] apply PCA to the feature space of the early layers, and the resulting principal components represent interpretable variations.",1,neutral
"Without introducing external supervision, several methods search interpretable factors in self-supervised [32] or unsupervised [12, 36] manners.",1,neutral
"Among these methods, [3, 35, 39, 12, 36] carefully investigate the semantics represented in different generator layers.",1,neutral
"To overcome this limitation, some recent works [Härkönen et al. 2020; Shen et al. 2020; Shen and Zhou 2020] focus on the manipulation of the underlying learned latent space, using the vector arithmetic property observed in [Mikolov et al.",1,neutral
Comparisons with Latent Space Manipulation Methods: We then compare our method with GANSpace and InterFaceGAN that perform semantic image control via latent space manipulation in Fig.,2,positive
"TABLE 2 User Study Results
Method shape exp. illum. pose
GANSpace 10.57 0.86 13.71 0.57 First Order - 4.29 - 2.86 InterFaceGAN - 2.86 - 2.00 MLS 0.57 0.57 - -",0,negative
Comparison results with GAN latent space manipulation methods: GANSpace (GANS.) and InterFaceGAN (Interface.).,1,neutral
"Since GANSpace is an unsupervised method without explicit supervision of the semantic attributes, it is difficult to locate the corresponding latent variable for a given attribute.",1,neutral
"In contrast, the noteworthy work GANSpace [Härkönen et al. 2020] can identify important latent directions for different attributes in an unsupervised fashion.",1,neutral
"Compared to GANSpace, InterFaceGAN allows explicit controls with supervision,
Fig.",2,positive
"2019b] or latent space[Härkönen et al. 2020; Shen et al. 2020]), regarding both quality and controllability.",2,positive
"In contrast, the noteworthy work GANSpace [15] can identify important latent directions for different attributes in an unsupervised fashion.",1,neutral
"To demonstrate our advantages in cross-domain face manipulation, we conduct comparisons with different types of representative baselines, including 2D warping based methods:Moving-Least-Squares (MLS) deformation [13] and First Order motion model [14], latent space manipulation based methods: GANSpace [15] and InterFaceGAN [16], and 3DMM guided methods: StyleRig [9] and PIE [10].",2,positive
"2019b], latent space manipulation based methods: GANSpace [Härkönen et al. 2020] and InterFaceGAN [Shen et al.",1,neutral
We compare the proposed method SGF with two stateof-the-art latent space manipulation methods: InterfaceGAN [31] † and GANSpace [11] .,2,positive
"On the other hand, unsupervised methods directly find semantically meaningful directions by PCA [11] or self-supervised learning [32].",1,neutral
"Existing methods can be categorized into two classes: supervised methods [31, 26, 8] and unsupervised methods [11, 32].",1,neutral
"To be specific, InterFaceGAN [31] and GANSpace [11] find meaningful directions in latent space, and vary latent codes along these directions to adjust the attributes of images.",1,neutral
"To control the GAN synthesis process, some works explore the semantic editing of latent codes by finding semantic directions on their latent space in a supervised [3] or unsupervised [39], [40] manner.",1,neutral
"entangling the latent space and adding more and more control [20, 11, 8, 27, 28, 29, 9, 13].",1,neutral
"[32] takes an unsupervised approach with a trainable reconstructor network and direction matrix which find directions that are easily distinguishable, and [13, 30] learn interpretable directions by performing principle component analysis (PCA) on samples in the latent space or on the learned weights that map the latent vector to the first convolutional layers.",1,neutral
"The direction is suggested for change of gender [18], yet the full-size model also changes the age significantly along the direction.",0,negative
"Generative adversarial networks (GANs) [16] are the leading model for several crucial computer vision tasks like image generation [7, 30] and image editing [3, 4, 18, 47].",1,neutral
GANSpace Editing.,2,positive
"We further demonstrate the benefit of our content-aware compressed StyleGAN2 for editing tasks of style mixing, latent space image morphing, and a recent proposed tech-
nique, GANSpace [18].",2,positive
We further deploy our compressed 1024px model for GANSpace [18] editing.,2,positive
"We further deploy our compressed
1024px model for GANSpace [18] editing.",2,positive
"6, where we use the same latent code as in the original paper [18] and traverse it in the direction of the first principal component, u0.",2,positive
"On the other end of the supervision spectrum, several methods [16, 41, 42] find directions in a completely unsupervised manner.",1,neutral
", StyleGAN [24, 25, 23], effectively encode semantic information in their latent spaces [16, 36, 21].",1,neutral
"To this end, we perform latent space manipulations [16, 36, 37] on the inverted latent codes to see if the embeddings are semantically meaningful.",1,neutral
"For performing the edits in the human facial domain we use InterFaceGAN [36], for the cars domain we use GANSpace [16], and for the horse domain we use SeFa [37].",2,positive
We believe that the closest methods to our work are Ganspace [7] and SeFa [22] methods which we extensively compare in Section 4.,2,positive
"(b) A comparison of rotate, zoom and background change directions between our method and Ganspace [7].",2,positive
Ganspace [7] is a sampling-based unsupervised method that randomly samples latent vectors from the intermediate layers of BigGAN and StyleGAN models.,1,neutral
Q4: How successful are the obtained directions comparing to other methods? We visually compare† the directions obtained by our method with Ganspace[7] using Husky class.,2,positive
"As explained in Section 3, contrary to [7], our learning method can optionally consider only the effects of a selected subset of layers while finding directions.",2,positive
"Similar to [7, 22, 26], we limit ourselves to the unsupervised setting, where we aim to identify such edit directions without any external supervision utilized in works such as [4, 21, 8].",1,neutral
"Utilizing Layer-wise Styles: The layer-wise structure of StyleGAN2 and BigGAN models can be used for finegrained editing, as pointed out by [7] where different semantics are controlled with different layer groups.",2,positive
"Recently, several approaches are proposed to explore the structure of latent space in GANs in a more principled way [21, 7, 26, 8].",1,neutral
"We also compare our method to state-of-the-art unsupervised methods [7, 22]*, and run several qualitative and quantitative experiments to demonstrate the effectiveness of our approach.",2,positive
Figure 4: (a) Comparison of manipulation results on FFHQ dataset with Ganspace [7] and SeFa [22] methods.,1,neutral
"Layered GANs Generative adversarial networks (GANs) [18] have been proposed and improved towards highly photorealistic image synthesis [26, 7, 27] and explored for disentangling factors of variation towards controllable generation [17, 46, 26, 41, 23, 49, 48, 22], efficient representation learning [12], and saving of human annotations [55, 54].",1,neutral
many 1D inputs for a high D latent space) [22] vs.,1,neutral
"More recent work analyse the latent space of trained GANs by exploiting human-provided supervision [18, 51, 29] or selfsupervision [43, 26, 57], and mathematically analysing layer weights [54] or features [25], leading to discovery of substantial interpretable directions.",1,neutral
"Inspired by recent work on interpretable directions in GAN latent space [51, 26, 25, 57], we adopt the linear walk as the representation of T Z and model it with neural network Φ as T Z z = z+Φ( ), where Φ is implemented with Multiple Layer Perceptron (MLP) and jointly trained with G.",2,positive
", by modifying the training objective [7, 55] or network architecture [28, 29], or discovering factors of variation in latent spaces of pre-trained generative models [1, 12, 16, 19, 25, 60, 73].",1,neutral
"Besides increasing the size of the dataset, recent methods to explore the model’s latent space such as GANSpace [27] could be experimented with to achieve this, on top of fine-tuning or extending the base architecture.",2,positive
"In contrast to other style code based editing methods [31, 12, 6], our diagonal attention maps are shown to have a clear and intuitive relationship to different spatial regions.",2,positive
"We attempt to interpret the latent space of the model trained to synthesize all classes (setting B), following [13].",1,neutral
"While state-of-the-art editing frameworks [3, 37, 18] achieve high quality fine grained edits using supervised and unsupervised approaches, background/ foreground aware embeddings and edits still pose a challenge.",1,neutral
"Some recent works in this domain [5, 6, 16, 18, 49, 3, 36, 2, 37] study the structure of the activation and latent space.",1,neutral
"While originally conjectured that GANs are merely great at memorizing the training data, recent work in GAN-based image editing [18, 3, 36, 42] demonstrates that GANs learn non-trivial semantic information about a class of objects, e.",1,neutral
"There have been also many attempts to manipulate inverted codes in disentangled latent spaces [7, 15, 27, 28, 12].",1,neutral
"So recent work has developed unsupervised methods for identifying disentangled interpretable directions in these interior latents [17, 47].",1,neutral
"While there are several other approaches which demonstrate transformations of StyleGAN latent vectors for semantic manipulation [Collins et al. 2020; Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020a], these methods focus on StyleGAN generated images, and do not produce high-quality and high-resolution results for real existing",1,neutral
"While there are several other approaches which demonstrate transformations of StyleGAN latent vectors for semantic manipulation [Collins et al. 2020; Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020a], these methods focus on StyleGAN generated images, and do not
produce high-quality and…",1,neutral
"Several methods [65, 24] have been proposed to discover such latent directions that control certain aspects of the input (e.",1,neutral
"Several methods have been proposed, including choosing better or multiple layers to project and edit [1, 2, 19], fine-tuning network weights for each image [5], modeling image corruption and transformations [4, 35], and discovering meaningful latent directions [65, 16, 38, 24].",1,neutral
", add smiling to a portrait) by tweaking the latent code [61, 38, 42, 24, 65].",1,neutral
"Similarly, generative models can be used to create novel views of images (Plumerault et al., 2020; Jahanian et al., 2019; Härkönen et al., 2020) by manipulating them in latent space.",1,neutral
"Similarly, generative models can be used to create novel views of images (Plumerault et al., 2020; Jahanian et al., 2019; Härkönen et al., 2020) by manipulating them in latent space.",1,neutral
"Härkönen et al. (2020) search for important and meaningful directions by performing PCA in the style space of StyleGAN (Karras et al., 2019; 2020).",2,positive
"For discovering-based methods, we consider serveral recent methods: GANspace (GS) (Härkönen et al., 2020), LatentDiscovery (LD) (Voynov & Babenko, 2020), ClosedForm (CF) (Shen & Zhou, 2021) and DeepSpectral (DS) (Khrulkov et al., 2021).",2,positive
"For discovering-based methods, we consider serveral recent methods: GANspace (GS) (Härkönen et al., 2020), LatentDiscovery (LD) (Voynov & Babenko, 2020), ClosedForm (CF) (Shen & Zhou, 2021) and DeepSpectral (DS) (Khrulkov et al.",2,positive
"Recent works (Shen & Zhou, 2021; Khrulkov et al., 2021; Karras et al., 2019; Härkönen et al., 2020; Voynov & Babenko, 2020) show that, for GANs purely trained for image generation, traversing along different directions in the latent space causes different variations of the generated image.",1,neutral
"Such learned latent spaces can contain subspaces with geometric properties, like viewpoint changes (Härkönen et al., 2020).",1,neutral
"Our study is partially inspired by a very recent line of works on controllable generation (Voynov & Babenko, 2020; Shen & Zhou, 2020; Härkönen et al., 2020; Peebles et al., 2020), which explore the latent spaces of pretrained GANs and identify the latent directions useful for image editing.",2,positive
"Our study is partially inspired by a very recent line of works on controllable generation (Voynov & Babenko, 2020; Shen & Zhou, 2020; Härkönen et al., 2020; Peebles et al., 2020), which explore the latent spaces of pretrained GANs and identify the latent directions useful for image editing.",2,positive
"The discovery of directions that allow for interesting image manipulations is a nontrivial task, which, however, can be performed in an unsupervised manner surprisingly efficiently (Voynov & Babenko, 2020; Shen & Zhou, 2020;
Härkönen et al., 2020; Peebles et al., 2020).",1,neutral
"We consider several recently proposed methods: ClosedForm (Shen & Zhou, 2020), GANspace (Härkönen et al., 2020), LatentDiscovery (Voynov & Babenko, 2020).",2,positive
"We consider several recently proposed methods: ClosedForm (Shen & Zhou, 2020), GANspace (Härkönen et al., 2020), LatentDiscovery (Voynov & Babenko, 2020).",2,positive
GANspace (GS).,1,neutral
"To this end, we follow our inversion method with several existing editing techniques: StyleFlow [3], InterFaceGAN [34], GANSpace [14], and SeFa [35].",2,positive
"To this end, we follow our inversion with several existing editing techniques: StyleFlow [Abdal et al. 2020b], InterFaceGAN [Shen et al. 2020], GANSpace [Härkönen et al. 2020], and SeFa [Shen and Zhou 2020].",2,positive
"For cars, we use directions obtained by GANSpace [14]; for faces we use StyleFlow [3]; and for horses, cats, and churches we use SeFa [35].",1,neutral
"Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020a; Wu et al. 2020], which allow one to perform extensive image manipulations by leveraging a pretrained StyleGAN.",1,neutral
"In Figure 1, we show inversions obtained by our encoder in multiple domains, followed by several manipulations performed using various editing methods [Abdal et al. 2020b; Härkönen et al. 2020; Shen and Zhou 2020].",2,positive
"For performing editing on the inversions, we use editing directions obtained by GANSpace [Härkönen et al. 2020].",2,positive
"Finally, several methods [14, 38, 39] find latent directions in an unsupervised manner and require manual annotations to determine the semantic meaning of each direction post hoc.",1,neutral
"Finally, several methods [Härkönen et al. 2020; Voynov and Babenko 2020; Wang and Ponce 2021] find latent directions in an unsupervised manner and require manual annotations to determine the semantic meaning of each direction post hoc.",1,neutral
"Furthermore, numerous works have demonstrated thatW has intriguing disentangled properties [7, 14, 34, 37, 40], which allow one to perform extensive image manipulations by leveraging a pretrained StyleGAN.",1,neutral
"For performing editing on the inversions, we use editing directions obtained by GANSpace [14].",1,neutral
"In Figure 1, we show inversions obtained by our encoder in multiple domains, followed by several manipulations performed using various editing methods [3, 14, 34, 35].",1,neutral
"For cars, we use directions obtained by GANSpace [Härkönen et al. 2020]; for faces we use StyleFlow [Abdal et al. 2020b]; and for horses, cats, and churches we use SeFa [Shen and Zhou 2020].",2,positive
"Other work considered unsupervised methods (Härkönen et al., 2020; Voynov & Babenko, 2020) to discover interpretable latent space directions.",1,neutral
"These global directions
are commonly used (Härkönen et al., 2020; Jahanian et al., 2019; Shen et al., 2019; Viazovetskyi et al., 2020).",1,neutral
"Other work considered unsupervised methods (Härkönen et al., 2020; Voynov & Babenko, 2020) to discover interpretable latent space directions.",1,neutral
"Unsupervised latent-space editing methods (Härkönen et al., 2020; Voynov & Babenko, 2020) are often less effective at providing semantically meaningful directions and all too often change image identity during an edit.",1,neutral
"Unsupervised latent-space editing methods (Härkönen et al., 2020; Voynov & Babenko, 2020) are often less effective at providing semantically meaningful directions and all too often change image identity during an edit.",1,neutral
"…evaluate the proposed approach on two types of datasets: (i) face datasets – FFHQ (Karras et al., 2019a), CelebA (Liu et al., 2018) and CelebA-HQ (Karras et al., 2017), commonly used in prior work (Härkönen et al., 2020; Karras et al., 2017; 2019a;b; Shen et al., 2019;
Viazovetskyi et al., 2020).",2,positive
", 2017a) and discovering semantically meaningful directions in a GAN latent space (Härkönen et al., 2020; Jahanian et al., 2019; Plumerault et al., 2020; Shen et al., 2019; Voynov & Babenko, 2020).",1,neutral
"…2018; 2020; Isola et al., 2017; Lee et al., 2020; Wang et al., 2018; Wu et al., 2019; Zhu et al., 2017a) and discovering semantically meaningful directions in a GAN latent space (Härkönen et al., 2020; Jahanian et al., 2019; Plumerault et al., 2020; Shen et al., 2019; Voynov & Babenko, 2020).",1,neutral
"methods [89], [124], [127], [128] aim to discover interpretable",1,neutral
[128] create interpretable controls for image,1,neutral
"Relative control over image generation: A widely studied approach for controlling the generated images of GANs is by exploiting the inherent disentanglement properties of their latent space [26, 53, 22, 44, 7].",1,neutral
[22] use principal component analysis (PCA) in latent space to identify directions that correspond to image attributes.,1,neutral
"GANSpace [16] considers unsupervised identification of interpretable controls over image synthesis, showing that semantically meaningful directions can be found by applying PCA in the latent space of StyleGAN.",1,neutral
"Different from previous works [42, 21, 16, 43] that adopt linear editing in latent space with a predefined editing direction, our method seeks to control face attributes via a non-linear editing conditioned on the starting latent code.",2,positive
We also test the gender change direction of GANSpace (See Table 3).,2,positive
"For the pose change experiments, we use the right-left
pose edit from GANSpace.",2,positive
"Unlike reconstruction, the editing quality of an embedding has not been studied, because competitive editing frameworks just became available very recently [22, 11, 25, 3].",1,neutral
"Specifically, for a latent code in the GANSpace coordinate system, we can set the coordinate corresponding to pose to five different values: -2σ, -σ, 0, σ, and +2σ, where σ is the eigenvalue for the direction.",1,neutral
"For its simplicity and interpretability, we choose GANSpace [11] as our main evaluation method for editing quality.",2,positive
"Most recently, the work of Härkönen et al. (2020) studied unsupervised discovery of meaningful directions by using PCA on deep features of the generator.",1,neutral
"Other works have recently presented unsupervised techniques for exposing meaningful directions (Voynov & Babenko, 2020; Härkönen et al., 2020; Peebles et al., 2020).",1,neutral
"It is known that the earlier scales in such models are responsible for generating the global composition of the image, while the deeper scales are responsible for more local attributes (Karras et al., 2019a; Yang et al., 2019; Härkönen et al., 2020).",1,neutral
"Other works have recently presented unsupervised techniques for exposing meaningful directions (Voynov & Babenko, 2020; Härkönen et al., 2020; Peebles et al., 2020).",1,neutral
"Our approach is seemingly similar to GANspace (Härkönen et al., 2020), which computes PCA of activations within the network.",2,positive
"It is known that the earlier scales in such models are responsible for generating the global composition of the image, while the deeper scales are responsible for more local attributes (Karras et al., 2019a; Yang et al., 2019; Härkönen et al., 2020).",1,neutral
"Our approach is seemingly similar to GANspace (Härkönen et al., 2020), which computes PCA of activations within the network.",2,positive
Some studies have attempted to identity semantically meaningful directions by self-supervised learning [29] or PCA on latent spaces [15].,1,neutral
"Finally, a bunch of recent methods [29, 10, 24] identify interpretable directions without any form of supervision.",1,neutral
"Another approach, [10], demonstrates that interpretable directions often correspond to the principal components of the activations from the first layer of the generator network.",1,neutral
"encode human-interpretable concepts [26, 28, 7, 14, 25, 29, 10, 24, 30], which makes GANs the dominant paradigm for controllable generation.",1,neutral
"Note that the problem statement above resembles the established problem of learning the interpretable latent controls addressed in [28, 14, 29, 10, 30].",1,neutral
"Since the seminal paper [26], which has demonstrated the semantic arithmetic of latent vectors in GANs, plenty of methods to discover interpretable directions in the GAN latent spaces have been developed [26, 28, 7, 14, 25, 29, 10, 24, 30].",1,neutral
"In this section we compare the ability of our approach to achieve disentangled manipulation of visual attributes to that of two state-of-the-art methods, specifically GANSpace [12] and InterFaceGAN [29].",2,positive
"However, current methods require either a pretrained classifier [10, 28, 29, 34], a large set of paired examples [15], or manual examination of many candidate control directions [12], which limits the versatility of these approaches.",1,neutral
[12] detect interpretable controls based on PCA applied either to the latent space of StyleGAN [17] or to the feature space of BigGAN [6].,1,neutral
"In contrast, GANSpace [12] identifies manipulation controls via a manual examination of a large number of different manipulation directions, which typically involve all of the channels of one or several layers.",1,neutral
"Comparing manipulations performed in StyleSpace to those in W and W+ spaces [12, 29], shows that our controls exhibit significantly lower AD.",1,neutral
"GANSpace manipulations also exhibit some entanglement (Lipstick affects face lightness, Gray hair ages the rest of the face).",1,neutral
"Figure 8 plots the mean-AD of the three methods (GANSpace, InterFaceGAN, and ours) for a range of maniplations of the Gender, Gray hair, and Lipstick attributes.",1,neutral
GANs [21] are arguably widely used generative model.,1,neutral
"During the past few years, GANs’ performance has been remarkably improved and achieved to produce photo-realistic quality images.",2,positive
"In particular, as demonstrated in the paper [28], the latent space of StyleGANs trained with FFHQ is well-defined and linearly separable.",1,neutral
Training details for GANs.,0,negative
"In response, we design a pipeline that combines GANs, the GAN manipulation techniques, and 3D reconstruction networks.",2,positive
"Another research direction [46, 24, 54] towards the facial attribute control is to directly manipulate a latent vector on top of the pre-trained latent space.",1,neutral
GAN models have been previously verified to enable manipulation of an attribute of an output image while maintaining the identity of the individual by navigating the GANs’ latent space.,1,neutral
"Once the disentangling capability of the GANs’ latent space is improved, we believe our pipeline can be enhanced as well.",2,positive
"Facial attribute manipulation on 2D image has drawn significant attention in various computer vision and graphics research, such as GANs [46, 24, 54] and image translation [57, 13, 23, 12] due to its practical necessity and broad applicability.",1,neutral
One feasible solution against this seemingly insurmountable obstacle is to make use of Generative Adversarial Networks (GANs).,1,neutral
"Briefly, StyleRig [51] introduced additional networks trained to map the 3D parametric space into the well-trained latent space of GANs.",1,neutral
The core idea of GANs is to train a generator in a way that its output distribution matches the data distribution.,1,neutral
"Related works of GANs and 3D Morphable Model (3DMM) are described in subsection 2.1, 2.2.",1,neutral
"Boosted by the enhanced power of GANs, facial attribute manipulation on 2D image has been widely explored.",1,neutral
"They either modify the training objective [9, 40, 71] or network architecture [39], or investigate latent spaces of well-engineered and pre-trained generative models [1, 16, 23, 27, 34, 78, 96].",1,neutral
"Unsupervised approaches [9, 11, 22, 26] use classical unsupervised machine learning techniques, e.",1,neutral
"Unsupervised approaches [9, 11, 22, 26] are inappropriate for this task as they focus on discovering interpretable latent semantics, instead of solving for the latent direction for the target attribute.",1,neutral
"ies [5, 9, 11, 21, 22, 25, 26], would inevitably cause spatial entanglement.",1,neutral
"In this paper, 12 attributes directions are considered for the qualitative experiment, which is a large extension comparing to previous studies [11, 21, 22, 26].",1,neutral
"Unsupervised approaches [9, 11, 22, 26] adopt classical unsupervised machine learning techniques, e.",1,neutral
"This document is structured as follows: In Section II the GAN framework, some relevant variations and a literature review in image generating GANs are presented along with (a) StarGAN [12] (b) GANSpace [22] (c) StyleGAN-v2 [9]",2,positive
GANSpace v2 [22] 2020 Parameter/Secondary Image EM-GP Image-to-Image yes,2,positive
"principal directions variation [14] in the latent/feature space or proposing a structured noise injection method, where the input noises are injected to GANs for controlling specific parts of the generated images [15].",1,neutral
", 2019), GANSpace (Härkönen et al., 2020), and SeFa (Shen & Zhou, 2020).",2,positive
"We compare our method with other unsupervised methods that also achieve face rotation with GANs, including HoloGAN (Nguyen-Phuoc et al., 2019), GANSpace (Härkönen et al., 2020), and SeFa (Shen & Zhou, 2020).",2,positive
"↓ HoloGAN 47.38 69.24 GANSpace 41.17 58.93 SeFa 41.79 60.73 Ours (3D) 28.93 43.02 Ours (GAN) 39.85 57.21
Identity-preserving Face Rotation.",0,negative
"We compare with HoloGAN, GANSpace, and SeFa.",2,positive
"In contrast, SeFa (Shen & Zhou, 2020) and GANSpace (Härkönen et al., 2020) discover meaningful latent directions without supervision, where some of them is coupled with content pose.",1,neutral
"In contrast, SeFa (Shen & Zhou, 2020) and GANSpace (Härkönen et al., 2020) discover meaningful latent directions without supervision, where some of them is coupled with content pose.",1,neutral
"Shen et al. (2020) aims to find the latent space vectors that correspond to meaningful edits, while Härkönen et al. (2020) exploits PCA to disentangle the latent space.",1,neutral
"[26] demonstrate the use of Principal Components Analysis (PCA) in the activation space of specific layers, allowing high-level control over image attributes without any supervision.",1,neutral
"The work most closely related to ours is GANSpace (Härkönen et al., 2020) for image synthesis editing.",2,positive
GANSpace applies PCA within the latent feature space of a pretrained GAN to discover semantically-interpretable directions for image editing in the latent space.,2,positive
"Performing SVD on the weight space enables two critical differences between our work and Härkönen et al. (2020): (i) we edit the entire output distribution rather than one image, and (ii) rather than manual editing, we adapt to a new domain.",2,positive
"Training a standard GAN and retrospectively discovering semantically meaningful axes of variation in the latent space [25, 10].",1,neutral
Most approaches linearly change the StyleGAN latent codes for editing [HÃďrkÃűnen et al. 2020; Shen et al. 2020; Tewari et al. 2020].,1,neutral
"Some of the most recent methods perform face manipulation by generating the entire head [65], [66].",1,neutral
"Unlike the previous methods (Abdal et al. 2019; Härkönen et al. 2020; Shen et al. 2019) the semantic edits performed on the latent vectors w forces the resultant vector to remain in the distribution of W space (p(w)). is enables us to do stable sequential edits which, to the best of our…",2,positive
Unlike the previous methods (Abdal et al. 2019; Härkönen et al. 2020; Shen et al. 2019) the semantic edits performed on the latent vectors w forces the resultant vector to remain in the distribution of W space (p(w)).,1,neutral
(iii) GANSpace (Härkönen et al. 2020): We used the code provided by the authors and use the version using layer subsets.,2,positive
"Nevertheless, we believe it will be useful for the reader to judge our work in competition with these recent papers (Härkönen et al. 2020; Nitzan et al. 2020; Tewari et al. 2020a), because they provide beer results than other work.",0,negative
"We would like to reiterate that the three competing methods were only available on arXiv at the time of submission and were independently developed (GANSpace (Härkönen et al. 2020), StyleRig (Tewari et al. 2020a), InterfaceGAN (Shen et al. 2019)).",2,positive
"Here we relied on a simple PCA approach for creating a reduced basis of the generative space, but there are other promising approaches in the literature that could also be applied to this task (e.g., [27, 28]).",1,neutral
"We tested an alternative aggregation approach, where we summarized the five responses for each item with a KDE (Gaussian kernel, standard deviation of 0.5 in units of PCA standard deviations), and took the mode of the resulting distribution (Exp. 4c, Fig.",2,positive
"As would be expected, the version of PCA with components 71–80 performs poorly; in practice, these components contribute very little perceptually speaking (see also [25]).",2,positive
"We used the top 10 PCA components to parameterize our stimulus space, allowing these components to vary up to two standard deviations from the mean, and fixing the input latent code (z in the original papers) to the mean to control variability.",2,positive
"0
25
50
75
100
Training Random Random PCA GSP Dataset
C om
po si
tio n
%
Perceived gender Female Male Other
Figure S25: Perceived gender for faces from different stages of the modeling pipeline, as collected in Exp. 4g.
41
0 10
20
30
40
Training Random Random PCA GSP Dataset
P er
ce iv
ed a
ge
Perceived gender Female Male
Figure S26: Perceived age split by gender for faces from different stages of the modeling pipeline, as collected in Exp. 4g.",0,negative
"Training Random Random PCA GSP Training Random Random PCA GSP
Training Random Random PCA GSP 0
25
50
75
100
0
25
50
75
100
Dataset
P er
ce nt
Y es
Perceived gender Female Male
Figure S27: Evaluations of ethnicity, smiling, hats, formal clothes, and glasses, for faces from different stages of the modeling pipeline, split by gender (Exp. 4g).",0,negative
"The results suggest an early advantage for the original PCA technique; however, the discrepancy with sparse PCA and ICA is small, and seems to disappear after more iterations.",1,neutral
"Figure S23: Final samples from the first four male and female chains in the dating preferences experiment (Exp. 4j).
to a certain amount through the modeling pipeline, even before the PCA process; it seems as if the model is capturing this association and stereotyping it to a certain degree.",0,negative
"On this basis, there is little evidence to dismiss any one of PCA, sparse PCA, or ICA.",0,negative
"Following [50], we apply this approach to the generative adversarial network ‘StyleGAN’ [51, 52], pretrained on the FFHQ dataset of faces from Flickr [51], and applying PCA to the intermediate latent code (termed w in the original papers).",2,positive
"In addition to the original PCA, we tested sparse PCA using a sparsity parameter of 1.0 (see the alpha parameter of SparsePCA from the scikit-learn package) and independent component analysis (ICA).",2,positive
We also tested the effect of retaining dimensions 71–80 instead of dimensions 1–10 of the PCA solution.,1,neutral
"71−80)
Sparse PCA
ICA
Figure S24: Validation results for Exp. 4e (exploring different basis construction methods), as collected in Exp. 4f.",0,negative
"S28, which shows that perceived intelligence is indeed associated
40
2.5
3.0
3.5
0 10 20 30 Iteration
R at
in g
Original PCA
PCA (dims.",0,negative
"The important prerequisite is finding a relatively low-dimensional basis for the network for GSP to parameterize; fortunately, it seems that relatively simple techniques such as PCA can sometimes suffice for this task [50].",1,neutral
"State-of-the-art image synthesis models typically still have high-dimensional parameter spaces, but here we build on recent work showing that the latent space of these models can be effectively navigated using principal component analysis (PCA) [50].",1,neutral
"Recently, numerous methods have shown competence in controlling StyleGAN’s latent space and performing meaningful manipulations in W [17, 35, 36, 13].",1,neutral
[13] find useful paths in an unsupervised manner by using the principal component axes of an intermediate activation space.,1,neutral
"which is commonly used in the existing approaches [7, 24, 27, 26, 10].",1,neutral
GANSpace [10] proposes to perform PCA on a collection of sampled data to find principal directions in the latent space.,2,positive
"More concretely, prior work [7, 24, 27, 26, 10] proposed to use a certain direction n ∈ R in the latent space to represent a semantic concept.",1,neutral
"However, they still require model training [26] and data sampling [10].",2,positive
"We compare our method with some unsupervised alternatives, including the sampling-based method [10] and the learning-based method [5].",2,positive
"In this part, we compare SeFa with GANSpace on the StyleGAN model trained on FF-HQ dataset [17].",2,positive
SeFa and GANSpace show close FID score since this is mostly determined by the generator itself as well as the manipulation model in Eq.,2,positive
[10] perform PCA on the sampled data to find primary directions in the latent space.,1,neutral
Qualitative comparison between (a) GANSpace [10] and (b) SeFa.,1,neutral
"Some very recent studies explore the unsupervised discovery of interpretable GAN semantics [26, 10], but they also require model training [26] or data sampling [10].",1,neutral
Quantitative comparison with GANSpace [10].,1,neutral
But SeFa outperforms GANSpace on attribute re-scoring and user study.,2,positive
"(Härkönen et al. 2020) showed that PCA directions of style latent vectors in StyleGAN (Karras, Laine, and Aila 2019) contain intuitive interpolation directions such as rotation.",1,neutral
"Like GANSpace [19], the user is provided with knobs to adjust the gain for each manipulation vector.",1,neutral
"StyleGAN latent codes exhibit disentangled properties, which enables extensive manipulation of images when using a trained StyleGAN model [15], [16], [17], [18], [19].",1,neutral
"For example, GANSpace [16] applies PCA to the latent space or feature space of a decoder to modify global attributes like the make of a car, background, or age.",1,neutral
"These often take the form of finding ways of navigating the latent space [23], or finding component vectors that represent key semantic properties [12, 27, 29], or trying to map out the latent space to find interpolations that map to semantic properties [15].",1,neutral
[23] find useful paths in a completely unsupervised manner.,1,neutral
"As many works [51, 29, 64, 23] have shown, the latent space of GANs is well-behaved and allows great controlled editing opportunities.",1,neutral
"As many works [Härkönen et al. 2020; Jahanian et al. 2019; Shen et al. 2019; Zhu et al. 2020] have shown, the latent space of GANs is well-behaved and allows great controlled editing opportunities.",2,positive
"manipulation [15], [39], [40], [41], [42], [43], but is restricted to synthetic images of the GAN itself or real images of limited complexity, e.",1,neutral
", 2021) and control (Shen & Zhou, 2021; Härkönen et al., 2020; Voynov & Babenko, 2020; Georgopoulos et al., 2021; Tzelepis et al., 2021; Zhu et al., 2021a; Bounareli et al., 2022; Wu et al., 2021; Abdal et al., 2021) has subsequently received much attention.",2,positive
"Eyes Nose Open mouth Smile GANSpace (Härkönen et al., 2020) 2.",1,neutral
"…and qualitative results for the baseline methods, we use the following directions annotated from the pre-trained models by the authors, where available:
• GANSpace (Härkönen et al., 2020): we use the following author-annotated directions: Eye_Openness, Nose_length, Screaming, and Smile.",2,positive
"For both the quantitative and qualitative results for the baseline methods, we use the following directions annotated from the pre-trained models by the authors, where available:
• GANSpace (Härkönen et al., 2020): we use the following author-annotated directions: Eye_Openness, Nose_length, Screaming, and Smile.",2,positive
"…tasks such as generative
∗Corresponding author: j.a.oldfield@qmul.ac.uk
model interpretability (Shen et al., 2020a; Bau et al., 2019; Yang et al., 2021) and image editing (Härkönen et al., 2020; Shen & Zhou, 2021; Shen et al., 2020c; Voynov & Babenko, 2020; Tzelepis et al., 2021; Bau et al., 2020).",2,positive
"…a supervised (Goetschalckx et al., 2019; Plumerault et al., 2020; Shen et al., 2020c;a) or unsupervised (Voynov & Babenko, 2020; Shen & Zhou, 2021; Härkönen et al., 2020; Tzelepis et al., 2021; Oldfield et al., 2021) manner–many of them struggle to apply local changes to regions of interest in…",2,positive
"A popular line of GAN-based image editing research concerns itself with learning so-called “interpretable directions” in the generator’s latent space (Härkönen et al., 2020; Shen & Zhou, 2021; Shen et al., 2020c; Voynov & Babenko, 2020; Tzelepis et al., 2021; Yang et al., 2021; He et al., 2021; Haas et al., 2021; 2022).",2,positive
"A popular line of GAN-based image editing research concerns itself with learning so-called “interpretable directions” in the generator’s latent space (Härkönen et al., 2020; Shen & Zhou, 2021; Shen et al., 2020c; Voynov & Babenko, 2020; Tzelepis et al., 2021; Yang et al., 2021; He et al., 2021;…",2,positive
"…induced by these networks for interpretation (Bau et al., 2019; Shen et al., 2020a; Yang et al., 2021) and control (Shen & Zhou, 2021; Härkönen et al., 2020; Voynov & Babenko, 2020; Georgopoulos et al., 2021; Tzelepis et al., 2021; Zhu et al., 2021a; Bounareli et al., 2022; Wu et…",2,positive
", 2020c;a) or unsupervised (Voynov & Babenko, 2020; Shen & Zhou, 2021; Härkönen et al., 2020; Tzelepis et al., 2021; Oldfield et al., 2021) manner–many of them struggle to apply local changes to regions of interest in the image.",0,negative
"directions in the latent space [26], [27].",1,neutral
"Instead, we parameterize c as a linear combination of the top-N principal directions of W space [189,190]:",1,neutral
"Notably, there have been previous studies in understanding latent semantic transitions for natural images (Shen & Zhou, 2021; Härkönen et al., 2020; Patashnik et al., 2021; Wu et al., 2021).",1,neutral
"For example, Härkönen et al. (2020) proposed to edit fake images by adding weighted eigenvectors to its latent representations.",1,neutral
"Notably, there have been previous studies in understanding latent semantic transitions for natural images (Shen & Zhou, 2021; Härkönen et al., 2020; Patashnik et al., 2021; Wu et al., 2021).",1,neutral
"related to the latent space unsupervisedly [30], [31].",1,neutral
"We speculate from an empirical perspective that the success of editing an opened mouth and the failure of editing eyebrows/nose shape may both ascribe to the entangled nature of the StyleGAN latent space, as prior arts [1, 10, 9, 26] have already managed to change the mouth openness via StyleGAN latent manipulation but none (to our knowledge) have succeeded in editing eyebrows/nose in the same way.",2,positive
GANSpace [29] and SeFa [53] identified important directions in the GAN latent space in an unsupervised manner; the discovered directions often correspond to meaningful semantic edits.,1,neutral
"These methods seek to find the semantically meaningful path in the latent space in either a supervised [11], [12], [14], [60], [61] or unsupervised manner [62], [63], then mov-",1,neutral
"On input, GANSliders [22] and GANSpace [40] support goal-driven input customization for GANs through visual feedforward sliders and semantic controls, respectively.",2,positive
We derive disentanglement of latent space in Style-GAN2 [6] from GANSpace [5].,1,neutral
We derive disentanglement of latent space in StyleGAN2 [6] from GANSpace [5].,1,neutral
"[29]), and it might be useful to develop similar methods for this approach.",1,neutral
"Our current work seeks to design GANspire using a specific method, called diffractive [10], which enables to include joint art and health perspectives in deep learning and interaction prototyping.",2,positive
"We proposed to call GANspire this deep learning tool, which enables to generate expressive breathing waveforms for art and health applications (see workflow in Figure 1).",2,positive
"Ethical Implications
The breathing waveform dataset scraped for training GANspire was fully anonymised.",0,negative
We used TouchDesigner to map pressure waveform values generated by GANspire to that of the mechanical ventilator.,2,positive
"We implemented GANspace, a technique for analysing and defining interpretable controls for image GANs [12], within our trained GAN.",2,positive
"We eventually applied GANspire to create a soft inflatable object, whose inflatings and deflatings would be controlled by our generative model.",2,positive
"Current work explores other creative applications of GANspire to control temporal evolution of other media, such as sound or image, i.e., making them “breathe”, as well as other shapes, materials, and actuators to fabricate a more advanced version of our soft breathing object.",2,positive
"One of the final aims of our work would be to use GANspire to control our soft breathing object in clinical settings, typically, observing how expressive breathings could produce empathic interactions between humans and the behavioural object, potentially appeasing the minds of patients suffering from chronic respiratory diseases [15].",2,positive
"We hope to attend this year’s workshop to discuss such socio-cultural issues with practitioners from the field of machine learning for creativity and design, along with artistic, design, and technical aspects of our ongoing work with GANspire.",2,positive
"Additional quantitative results In addition to the experimental evaluation in the main paper, we provide accuracy for the synthesis of specific hair tone using PGAN 1: [2]: 91%, [5]: 97%, Ours: 99%.",2,positive
We set α := 1.0 for GANSpace to generate the edited latent codes in the target attribute.,2,positive
GANSpace We train GANSpace [2] on the pre-trained ProgressiveGAN that is used for the other methods.,2,positive
"Recent advances in GAN inversion techniques [1,5,6,30] enable manipulation of real-world images [2,3,4,20,31,41].",1,neutral
"[20] suggest a PCA-based approach applied onto the latent space of StyleGAN [22] to identify key control directions for semantic edits such as aging, lighting, etc.",1,neutral
We use GANSpace [21] and StyleCLIP [40] for finding an editing direction δw in the W latent space.,2,positive
"After inversion, we can edit the inverted code by traversing semantically meaningful directions computed using supervised [9, 25, 47] or unsupervised approaches [17,21,41,48,52].",1,neutral
We use GANSpace [21] and StyleCLIP [40] for finding an editing direction δw+ in the W+ latent space.,2,positive
"The rotation and smile directions are obtained from InterFaceGAN [9], whereas other directions are borrowed from GANSpace [3].",1,neutral
"The smile direction is obtained from InterFaceGAN [9], whereas other directions are borrowed from GANSpace [3].",1,neutral
The editing directions are obtained from GANSpace [3].,1,neutral
", 2020], discovering interpretability [Härkönen et al., 2020], and fine-tuning [Mo et al.",1,neutral
"Examples include improving fairness [Tan et al., 2020, Karakas et al., 2022], rule rewriting [Bau et al., 2020], discovering interpretability [Härkönen et al., 2020], and fine-tuning [Mo et al., 2020, Li et al., 2020, Zhao et al., 2020].",2,positive
"[11] performed unsupervised learning, mainly PCA, on the latent space in StyleGAN as well as feature layers in BigGAN to find the directions of some editable features.",2,positive
"Finally, Härkönen et al. (2020) shows that keeping principal components from a PCA in the intermediate latent space of StyleGAN captures most variance of the model, which implies that GANs compress the high-dimensional latent space.",1,neutral
"While aforementioned 2D GANs [15], [17], [22], [23] allow explicit head pose control to some extent, they fail to guarantee appearance consistency, leading to inconsistent identity or facial attributes when viewed from vastly different angles.",1,neutral
"correlates with the manipulated attribute [12], [13], [14], [15], [16], [16], [17], [18].",1,neutral
"Recent works on image manipulation show that visual attributes can be controlled for more complex images [16, 18, 15, 17] and that generative models can be applied to larger datasets such as ImageNet [27].",1,neutral
"The latent space can also be used as a way to control the generation process, for instance to edit images [15, 16, 17].",1,neutral
"DE-AC52-07NA27344, Lawrence Livermore National Security, LLC.and was supported by the LLNLLDRD Program under Project No. 21-ERD-012.
of image synthesis and manipulation tasks (Karras et al., 2019; Härkönen et al., 2020; Brock et al., 2019; Song et al., 2021).",2,positive
"A desired property of any GAN inversion algorithm is that the latent codes can be semantically manipulated for downstream applications such as style transfer and attribute discovery (Voynov & Babenko, 2020; Härkönen et al., 2020; Plumerault et al., 2020; Jahanian et al., 2019; Wang et al., 2021).",1,neutral
"of image synthesis and manipulation tasks (Karras et al., 2019; Härkönen et al., 2020; Brock et al., 2019; Song et al., 2021).",1,neutral
"For manipulating facial semantics, most works focus on changing the attributes [36, 32, 14].",1,neutral
"Despite there are many methods aiming to find out these relations [8,15], most of them are too costly to be a practical option.",1,neutral
"These techniques include unsupervised exploration [39], learning linear SVM models [34], principle component analysis on the latent codes [17], and k-means clustering of the activation features [10].",1,neutral
"Recent studies [34,17,44,35] have shown that it is possible to control semantic attributes of synthetic images by manipulating the latent space of a pre-trained GAN.",1,neutral
"Given a latent code w, let us consider that we have a modified latent code w̃ = w+∆w corresponding to a desired editing, obtained from a latent space editing method [34,17,35].",1,neutral
"This is in contrast to past traversal studies [4, 14, 16, 28, 31] that found global linear directions to suffice for simple scalar attributes.",1,neutral
"Latent spaces of deep generative networks like generative adversarial networks (GANs) [13, 17, 18, 29] and variational autoencoders (VAEs) [19] are known to organize semantic attributes into disentangled subspaces without supervision [14, 16, 29, 37, 39].",1,neutral
"Most propose finding global linear directions correlated with scalar attributes of interest [4, 14, 12, 28, 31, 38, 43].",1,neutral
"Related to StyleGAN, the editing frameworks [16,33,35,4] analyze the linear and non-linear nature of the underlying W and W+ spaces.",1,neutral
"By identifying the principal components of the latent space, GANSpace [8] identifies important factors of variation.",1,neutral
"Existing methods for semantic control discovery include large amounts of annotated data, manual examination[10, 30, 36], or pre-trained classifiers[30].",1,neutral
"The superior properties of W space have attracted a host of researchers to develop advanced GAN inversion techniques[1, 2, 10, 29, 33, 34, 39]",1,neutral
"Also, we have compared our method with state-of-the-art methods [2, 3, 21, 33] on face attribute manipulation [15, 22].",2,positive
"9) with off-the-shelf GAN manipulation approaches [15, 22, 27].",1,neutral
"In recent years many works have proposed to utilize such appealing properties of the StyleGAN latent spaces for image editing tasks [1, 12, 15, 27, 33, 35, 41].",1,neutral
"In particular, the state-of-theart StyleGAN models [17–19] have many practical applications such as image enhancement [6, 22, 39, 44], image editing [1, 12, 15, 27, 33, 35, 41], image-to-image translation [9, 14, 29, 34] thanks to their high-quality image generation and their latent representation that has rich semantics and disentangled controls for localized meaningful image manipulations.",1,neutral
"2 [12] Erik Härkönen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris.",0,negative
"A key technique for using pretrained generative models to produce interested images is latent space navigation [32, 33, 80, 81, 46, 82, 83], which manipulates images by discovering interpretable directions in the latent space.",1,neutral
"…generation is to identify directions of variation in the latent space for each meta-attribute and
manipulate the latent code for an input image along these directions to achieve the desired control, e.g., Shen et al. (2020); Härkönen et al. (2020); Voynov & Babenko (2020); Khrulkov et al. (2021).",2,positive
"Finally, additional GANspace [4] editing results can be found in Fig.",1,neutral
"In the future, it would be interesting to similarly expose a subset of the parameters, along with relevant value ranges, ideally with semantic attributes similar to latent spaces for portrait editing with StyleGAN [Abdal et al. 2021; Härkönen et al. 2020].",2,positive
11 contains additional HyperStyle editing results on the cars domain obtained with GANSpace [6].,1,neutral
10 provides additional editing comparisons on the cars domain obtained with GANSpace [6].,2,positive
0 Model Source License StyleGAN2 [11] Nvidia Source Code License-NC pSp [20] MIT License e4e [26] MIT License ReStyle [1] MIT License PTI [21] MIT License IDInvert [30] MIT License InterFaceGAN [24] MIT License StyleCLIP [18] MIT License GANSpace [6] Apache 2.,2,positive
"Recent studies have demonstrated that the features of StyleGAN2 have abundant information on facial attributes such as postures and expressions [13, 36, 37].",1,neutral
"There have been abundant works to exploit the pre-trained StyleGAN for various tasks, including image manipulation [41, 13, 37, 35], 3D reconstruction [30], image segmentation [22, 2], and semantic matching [31].",1,neutral
The synthetic thermal database was built using GANSpace to manipulate the intermediate latent space w of StyleGAN2 and obtain images with different characteristics.,2,positive
"Figure 10 shows some examples of directions in the latent space obtained with GANSpace, representing images generated with different characteristics.",1,neutral
"In this work, we used GANSpace [17], which allows us to discover",1,neutral
GANSpace uses the StyleGAN w space (intermediate latent space) to identify directions in the latent space using PCA.,1,neutral
"The database must have variability in the images; therefore, it is proposed to explore the intermediate latent space w of StyleGAN2 using the GANSpace algorithm [17], which allows manipulation of the semantics of the thermal image generated in a way that is not supervised by using principal component analysis (PCA).",2,positive
"rithm [17], which allows manipulation of the semantics of the thermal image generated in a way that is not supervised by using principal component analysis (PCA).",1,neutral
"Available: http://arxiv.org/abs/1912.04958 [17] E. Härkönen, A. Hertzmann, J. Lehtinen, and S. Paris, ‘‘GANSpace: Discovering interpretable GAN controls,’’ 2020, arXiv:2004.02546.",2,positive
"In this work, we used GANSpace [17], which allows us to discover
80518 VOLUME 9, 2021
interpretable editions in an unsupervised way via the use of PCA.",2,positive
"Inspired by work on latent-space manipulation [4, 16, 30, 31, 41], we also link the latent space with the image space, but here with the explicit goal to supervise our loss.",2,positive
Edits are made using GANSpace.,2,positive
"Here, the editing method is to male with GANSpace.",1,neutral
"We evaluate our projection on four well-known editing methods: InterfaceGAN [30], GANSpace [16], StyleFlow [4] and random interpolation between latent vectors [19].",2,positive
"InterfaceGAN StyleFlow GANSpace Interpolations realism t realism t realism realism
Im2StyleGAN++ 0.973 0.096 0.929 0.211 0.960 1.00 w/o MAGEC loss 0.994 0.097 0.976 0.148 0.985 1.03 Full Method 0.998 0.122 0.982 0.202 0.984 1.04
Table 2: Realism scores and “improved target” scores of random image edits.",0,negative
"Figure 1: From left to right: original image, projection in latent space using MAGEC loss, various edits (GANSpace, InterfaceGAN and StyleFlow respectively).",2,positive
"Importantly, notice how our method gives better scores for an editing method not utilized to supervise the loss (GANSpace), suggesting that the latent vector doesn’t overfit to one editing method, but is encouraged to become “in-domain”.",2,positive
"Each edit operation consisted in changing one of 10 possible facial attributes to a random new value, using either [16] or [4].",1,neutral
"GANSpace [16] doesn’t use an auxiliary classifier, but instead performs PCA analysis on the latent space.",1,neutral
"From the 3rd column in each subfigure, from left to right are the manipulation result of GANSpace [18], that of InterFaceGAN [35] and ours.",1,neutral
"We project the real images of FFHQ to the latent spaceW+ of StyleGAN using the pretrained encoder [34], and manipulate the latent codes using each method with the suggested magnitude of edits (3 for InterFaceGAN, specified range based on attributes for GANSpace and 1 for our method).",2,positive
We compare our results with two state-of-the-art methods: InterFaceGAN [35] and GANSpace [18].,2,positive
"We compare our method quantitatively with GANSpace and InterFaceGAN using three metrics: target attribute change rate, attribute preservation rate and identity preservation score.",2,positive
"GANSpace [18] performed PCA in the latent space of generative networks, explored the principal directions and discovered interpretable controls.",1,neutral
"For example, when changing ‘gender’, both GANSpace and InterFaceGAN modify the hairstyle, and when changing ‘age’, GANSpace adds eyeglasses and InterFaceGAN affects smile.",1,neutral
The official implementation of GANSpace on StyleGAN2 is available.,2,positive
The directions of GANSpace are discovered from PCA so that they may control several attributes simultaneously.,1,neutral
…either by directly learning a disentangled mapping of an attribute of interest [Nitzan et al. 2020] or by a latent space traversal [Abdal et al. 2020b; Denton et al. 2019; Goetschalckx et al. 2019; Härkönen et al. 2020; Shen et al. 2020; Shen and Zhou 2020; Voynov and Babenko 2020; Wu et al. 2020].,1,neutral
"Recently, many works have explored performing semantically meaningful manipulations in the latent space of a well-trained GAN generator, either by directly learning a disentangled mapping of an attribute of interest [53] or by a latent space traversal [13, 23, 28, 29, 60, 61, 66, 68].",1,neutral
"Other works [13, 29, 48, 60, 68] have approached the age transformation task by exploring the semantics of the latent space of a well-trained GAN, such as StyleGAN [38, 39], and perform a latent space traversal to obtain the desired transformed image.",1,neutral
"Other works [Abdal et al. 2020b; Härkönen et al. 2020; Liu et al. 2020; Shen et al. 2020; Wu et al. 2020] have approached the age transformation task by exploring the semantics of the latent space of a well-trained GAN, such as StyleGAN [Karras et al. 2019, 2020], and perform a latent space…",2,positive
"Härkönen et al. (2020) searches for important and meaningful directions by performing PCA in the style space of StyleGAN (Karras et al., 2019; 2020).",2,positive
"For GANbased methods that extract disentangled representations from pretrained GANs, we consider serveral recent methods: GANspace (GS) (Härkönen et al., 2020), LatentDiscovery (LD) (Voynov & Babenko, 2020), ClosedForm (CF) (Shen & Zhou, 2020) and DeepSpectral (DS) (Khrulkov et al., 2021).",2,positive
"For GANbased methods that extract disentangled representations from pretrained GANs, we consider serveral recent methods: GANspace (GS) (Härkönen et al., 2020), LatentDiscovery (LD) (Voynov & Babenko, 2020), ClosedForm (CF) (Shen & Zhou, 2020) and DeepSpectral (DS) (Khrulkov et al.",2,positive
"These non-disentangled GAN-based methods discover semantically meaningful directions in the style space of StyleGAN (Karras et al., 2019; 2020) by analysing the distribution of the first-layer outputs (Härkönen et al., 2020) or layer weights (Shen & Zhou, 2020; Khrulkov et al., 2021).",1,neutral
", 2019; 2020) by analysing the distribution of the first-layer outputs (Härkönen et al., 2020) or layer weights (Shen & Zhou, 2020; Khrulkov et al.",2,positive
"Manipulation by perturbing the stRGB channels in early resolution layers (0,1,2), middle layers (3,4,5) and late layers (6,7,8).",1,neutral
"receding hairline (5,414,1) (6,322,2) (6,497,3) (6,504,8) hair style mouth smiling (6,501,1) size of face or eye lipstick (15,45,1) gender, face expression beard sideburns (12,237,2) other type of beard, gender goatee (9,421,1) other type of beard, gender chin double chin (9,132,1) size of neck, wrinkle ear earrings (entangled with gender) (8,81,1) gender, face shape eye glasses (3,288,1) (2,175,3) (3,120,4) (2,97,6) gender, wrinkle and beard",0,negative
"hair black hair (12,479,1) different hair color, lighting blond hair (12,479,1) (12,266,3) gender, other hair color and style gray hair (11,286,1) glasses, gender, wrinkle and beard wavy hair (6,500,1) (8,128,2) (5,92,3) (6,394,7) (6,323,28) hair style, gender",0,negative
"bangs (3,259,1) (6,285,2) (5,414,3) (6,128,4) (9,295,8) (6,322,9) (6,487,11) (6,504,14) hair style",0,negative
"For 40 CelebA attributes, we first remove inactivated (9), ambiguous (2) or neutral (3) attributes.",1,neutral
"As shown in Figure 10, manipulating the early (coarse) resolutions (0,1,2) mainly affects the center of the target object (better visible in faces than in cars), manipulating the middle resolutions (3,4,5) typically affects the entire target object, and manipulating the late (fine) resolution layers (6,7,8) affects the entire image.",1,neutral
"In the main text, we define three methods for perturbations in the latent code of a GAN: 1) adding isotropic Gaussian noise, 2) moving along principle component axes [2], and 3) style-mixing the optimized latent code with a random latent code.",1,neutral
"Several methods have been proposed in this direction, including fine-tuning network weights for each image [7, 38, 46], choosing better or multiple layers to project and edit [1, 2, 19, 60], designing better encoders [45, 57], modeling image corruption and transformations [5, 24], and discovering meaningful latent directions [49, 16, 27, 21].",1,neutral
"Several methods have been proposed in this direction, including fine-tuning network weights for each image [7, 38, 46], choosing better or multiple layers to project and edit [1, 2, 19, 60], designing better encoders [45, 57], modeling image corruption and transformations [5, 24], and discovering meaningful latent directions [49, 16, 27, 21].",1,neutral
"We will observe result quality and then explore semantic editing capabilities using [7], which should be exactly what is shown in GANSpace [14].",2,positive
"A novel camera manifold formulation together with a multi-view embedding strategy [5, 6] for the first time allows GAN-generated images to be used in virtual environments and enables new applications like generative stereoscopic image synthesis, while preserving semantic editing capabilities, such as changes of lighting or facial expression [7, 8, 9].",1,neutral
", [Abdal et al. 2020; Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020]) have tried to analyze and disentangle the latent code of some pretrained GAN space [Karras et al.",1,neutral
"Many other works (e.g., [Abdal et al. 2020; Härkönen et al. 2020; Shen et al. 2020; Tewari et al. 2020]) have tried to analyze and disentangle the latent code of some pretrained GAN space [Karras et al. 2019] also with labeled data of specific attributes.",1,neutral
"Similar to Figure 9 in the main text, we show additional results of applying GANSpace [3] edits to our customized models, horse rider (top) and gabled church (bottom).",0,negative
The geometric head motion was generated as a random latent space walk along hand-picked directions from GANSpace [10] and SeFa [22].,1,neutral
"Following [11], principal axes of p(w) are identified with PCA.",1,neutral
"Next, we describe the unsupervised attribute discovery problem for a single generative model formulated in [7], which we extend to multiple models subsequently.",1,neutral
"Many existing unsupervised GAN attribute discovery works [7, 21] rely on closed-form optimization to extract attribute directions, thereby requiring a post-hoc attribute alignment step.",1,neutral
"With the development of high quality generative models [6, 13, 11], this goal can be achieved using unsupervised attribute discovery methods [7, 21, 23], which show latent spaces learn the underlying attribute structure of the data.",1,neutral
"For example, for the ffhq manifold, we use the first two PCA components identified by GANSpace, which correspond to head pose and gender, as visible in figure 4.",1,neutral
"Specifically we use GANSpace [10] to find interpretable semantic directions in the W space of StyleGAN2 [16], using PCA.",2,positive
"This can be done by operating directly on the latent codes [15, 16] or by analysing the activation space of latent codes to discover interpretable directions of manipulation in latent space [17].",1,neutral
"This phenomenon has been observed in the previous work, where principal components from StyleGAN have resulted in the entanglement of facial attributes like gender and head rotation [13].",1,neutral
We also plot the FID values for one of the directions discovered with the GANSpace [4] approach in the latent space.,1,neutral
"In order to define consistent and semantically meaningful latent factors, we follow GANSpace [4] and perform PCA analysis on the W space of StyleGAN2.",2,positive
"More recently, approaches have been found that allow the unsupervised identification of meaningful hyper-directions in GAN latent spaces, with an approach called GANspace [15] currently providing the most efficient method4.",1,neutral
"In a second step, we then analyze the most salient hyper-directions in the learned latent space with the help of the GANspace method.",1,neutral
"Importantly, GANspace is
4In July 2020, another, conceptually different, approach was published [28] that shows even more promising results.",2,positive
We have also suggested to explore generative adversarial networks as a potential generative approach in digital art history and have documented a proof-of-concept approach utilizing StyleGAN and the GANspace algorithm to identify meaningful directions in the latent spaces of two GANs trained on art historical corpora.,2,positive
Active research on disentangled representation learning has recently proposed interpretable controls for global image manipulation (Härkönen et al. 2020).,1,neutral
Active research on disentangled representation learning has recently proposed interpretable controls for global image manipulation (Härkönen et al. 2020).,1,neutral
", 2020), and discovering meaningful latent directions (Shen et al., 2020; Goetschalckx et al., 2019; Jahanian et al., 2020; Härkönen et al., 2020).",1,neutral
"…designing better encoders (Richardson et al., 2021; Tov et al., 2021), modeling image corruption and transformations (Anirudh et al., 2020; Huh et al., 2020), and discovering meaningful latent directions (Shen et al., 2020; Goetschalckx et al., 2019; Jahanian et al., 2020; Härkönen et al., 2020).",2,positive
