text,target_M6_predict,target_predict_M6_label
", Xiang’s [48] and Lee’s [49] algorithms can be utilized to encrypt the CNN",2,positive
"On the other hand, even if our model and transmitted images can be intercepted by attackers, we can encrypt the CNN model and secret information by encryption algorithms, e.g., Xiang’s [48] and Lee’s [49] algorithms can be utilized to encrypt the CNN models, and the AES and DES algorithms can be used to encrypt secret information, to further improve the security.",2,positive
"The concept of instance encoding is widespread under many different names: learnable encryption (Huang et al., 2020; Yala et al., 2021; Xiao & Devadas, 2021; Xiang et al., 2020), split learning (Vepakomma et al.",1,neutral
"Alternatively, Yala et al. (2021); Xiao & Devadas (2021); Xiang et al. (2020) proposed to use a secret encoder network for private training, whose privacy guarantee relies on the secrecy of the encoder network.",2,positive
"…of instance encoding is widespread under many different names: learnable encryption (Huang et al., 2020; Yala et al., 2021; Xiao & Devadas, 2021; Xiang et al., 2020), split learning (Vepakomma et al., 2018; Poirot et al., 2019), split inference (Kang et al., 2017; Dong et al., 2022), and…",1,neutral
"…al., 2016; Arjovsky et al., 2016; Trabelsi et al., 2018; Wang et al., 2020; Trouillon et al., 2016), complex-valued NNs also contribute to faster learning (Arjovsky et al., 2016; Danihelka et al., 2016) and increased model robustness (Danihelka et al., 2016; Yeats et al., 2021; Xiang et al., 2020).",1,neutral
"…capacity (Wisdom et al., 2016; Arjovsky et al., 2016; Trabelsi et al., 2018; Wang et al., 2020; Trouillon et al., 2016), faster learning speed (Arjovsky et al., 2016; Danihelka et al., 2016), and increased model robustness (Danihelka et al., 2016; Yeats et al., 2021; Xiang et al., 2020).",1,neutral
", 2016), and increased model robustness (Danihelka et al., 2016; Yeats et al., 2021; Xiang et al., 2020).",2,positive
"Complexvalued NNs have also been used in privacy detection (Xiang et al., 2020) and knowledge graph completion (Trouillon et al., 2016; Trouillon & Nickel, 2017).",1,neutral
", 2016) and increased model robustness (Danihelka et al., 2016; Yeats et al., 2021; Xiang et al., 2020).",2,positive
"Complex-valued neural networks (NNs) have been long studied (Georgiou & Koutsougeras, 1992; Nitta, 2002; Hirose, 2011; Trabelsi et al., 2018; Xiang et al., 2020; Yang et al., 2020) with various NN building blocks including RNN (Wisdom et al., 2016), CNN (Guberman, 2016) and Transformers (Yang et…",1,neutral
"Complexvalued NNs have also been used in privacy detection (Xiang et al., 2020) and knowledge graph completion (Trouillon et al.",1,neutral
"Complex values have been used in various NNs across domains (Arjovsky et al., 2016; Danihelka et al., 2016; Wisdom et al., 2016; Trouillon et al., 2016; Hirose, 2011; Trabelsi et al., 2018; Xiang et al., 2020; Yang et al., 2020; Guberman, 2016; Wang et al., 2019).",1,neutral
"Complex-valued neural networks (NNs) have been long studied (Georgiou & Koutsougeras, 1992; Nitta, 2002; Hirose, 2011; Trabelsi et al., 2018; Xiang et al., 2020; Yang et al., 2020) with various NN building blocks including RNN (Wisdom et al.",1,neutral
The attacker merely accesses the smashed data [11].,0,negative
"Most of the existing works have been devoted to privacypreserving inference [10], [11] rather than split learning, as inference only requires the features transmitted in the one-time forward propagation is privacy-preserving, while it is much more difficult to protect the training data in multiple rounds of forward and backward propagations.",1,neutral
An inversion attack can be launched to infer private information from smashed data [11].,1,neutral
"Differential privacy and other transform-based approaches applied to the training inputs [13], [14], or intermediate features [10], [11], usually sacrifice significant accuracy performance to achieve the privacy guarantee.",1,neutral
"In addition, some schemes [4, 16, 41, 49] employ several technologies, such as adversarial learning, domain-transformation, and encryption, to achieve privacy-preserving inference.",1,neutral
"All prior works that aimed to quantify or improve the privacy of the split layer activation failed to meet one or both of the above criteria [1, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].",0,negative
"There are growing concerns over the interpretability of NLP models, especially when language models are being rapidly applied on various critical fields (Lipton, 2016; Du et al., 2019; Xiang et al., 2019; Miller, 2019; Sun et al., 2021).",1,neutral
"Xiang et al. [27] proposed a complexvalued network, CVDNN, which concealed the input data into a randomized phase.",1,neutral
"TABLE I PRIVATE DEEP LEARNING SOLUTIONS Inference privacy Training privacy Intrusive GHOST, ARDEN [23] With SDP and DPFE [24], CVDNN [27] federate learning [7]–[11],",2,positive
"[27] proposed a complexvalued network, CVDNN, which concealed the input data into a randomized phase.",1,neutral
"Consequently, several works have used split learning for inference to build defense [7, 45, 50, 57, 61, 69, 70, 74, 84, 87] and attack mechanisms [32, 53, 64].",1,neutral
"TargetingG1, researchers proposed to use encryption for privacy protection [4, 6, 33].",1,neutral
"Several works [4, 6, 33] propose to use encryption to protect the user privacy and thus defend against the direct attacks.",1,neutral
"First, comparingwith the data encryption [4, 6, 33], distillation [21, 22], and adversarial training [8, 14, 26] approaches, Fake Gradient reduces huge protection overhead by eliminating the need of re-training.",2,positive
"In [33], the proposed approach transforms the real-valued features into complex-valued ones, in which the input is hidden in a randomized phase of the transformed features.",1,neutral
"The forth baseline was the (Xiang et al., 2019), which was constructed using the same division of modules of the QNN.",2,positive
"(Xiang et al., 2019) used complex-valued neural networks to protect privacy.",1,neutral
The paper by Xiang et al. (2020) looks at the privacy problems that are associated with running data processing operations on the cloud.,2,positive
"This report investigates the reproducibility of the paper ‘Interpretable Complex-Valued Neural Networks For Privacy Protection’ by Xiang et al. (2020). The paper proposes a new method of creating complex-valued DNNs, for which the privacy of the model is better protected against potential attackers while the performance of the models is largely preserved.",2,positive
"…and Reinier Bekkenutte (13438557)
Reproducibility Summary
Scope of Reproducibility
In this reproducibility report, the following two main claims of Xiang et al. (2020)’s paper are tested:
• The performance of a Deep Neural Network (DNN) is largely preserved when comparing DNNs with complex…",2,positive
"Scope of Reproducibility In this reproducibility report, the following two main claims of Xiang et al. (2020)’s paper are tested:",0,negative
This report investigates the reproducibility of the paper ‘Interpretable Complex-Valued Neural Networks For Privacy Protection’ by Xiang et al. (2020).,2,positive
"The paper by Xiang et al. (2020) proposes a new model architecture that encrypts the data in complex-valued and rotated features, to prevent an attacker from inferring or reconstructing privacy sensitive information.",2,positive
[29] conceal intermediate features by rotating the features in a complex space.,1,neutral
"To a certain extent, it also reduces the amount of data that can be processed, which is more effective than DPI in terms of protecting personal privacy [6, 7] and consuming computing resources.",1,neutral
"Other studies [7,13] monitor each inserted flow entry and check whether it has any negative impact on the data plane.",0,negative
"Specifically, FortNOX [13] can detect flow conflicts and VeriFlow [7] verifies network invariants upon forwarding state changes.",1,neutral
"Some studies [7,13] monitor each inserted flow entry and check whether it has any negative impact on the data plane, but they are unable to identify the threats which are caused by a set of flow entries.",0,negative
"Therefore, how to effectively use a large amount of existing knowledge and historical accumulation in the field of cybersecurity to achieve the specification and integration of security data, to continuously store and update malicious traffic information under massively connected terminals, has become a critical issue to be solved urgently [7].",2,positive
"Moreover, previous research on link-separation multipath selection schemes [5,7,17] did not solve the Head of Line (HOL) blocking problem due to the fact that different routing paths had varied latency, resulting in out-of-order arrival of packets at the same destination node [12].",1,neutral
"RBAC supports generally accepted security principles: minimum privilege principle, separation of responsibility principle and data abstraction principle [7].",2,positive
"Eventually, if the controller cannot provide normal services, the entire network will be greatly affected or even paralyzed [7].",0,negative
"In our previous research work [7], we present a differential constellation shifting (DCS) aided RF watermark scheme to improve reliability performance while providing secure transmissions.",2,positive
Exll [6] and C2TCP [7] are proposed to achieve low latency in cellular networks.,2,positive
"[40] put real number features in complex numbers to hide through rotation, and use GAN model to generate confusion samples to achieve k-anonymity.",1,neutral
