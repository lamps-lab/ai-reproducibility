text,target_M6_predict,target_predict_M6_label
"Transfer learning has emerged as a crucial paradigm within machine learning due to its ability to use knowledge extracted from one domain (source) to enhance learning in a different, typically related domain (target) [30, 43, 49, 38, 6].",1,neutral
"We leave it to future work to further study this behavior and the relationship between the FT loss surface and OOD generalization (Shwartz-Ziv et al., 2022; Juneja et al., 2023).",2,positive
"…the performance of supervised baselines on many downstream tasks [Larsson et al., 2016, Bachman et al., 2019, Gidaris et al., 2018, 2021, Misra and van der Maaten, 2019, Grill et al., 2020, Shwartz-Ziv et al., 2022b, Chen et al., 2020b, He et al., 2020, Zbontar et al., 2021, Chen and He, 2021].",2,positive
"However, understanding the learned representations and their underlying mechanisms remains a persistent challenge due to the complexity of the models and the lack of labeled training data [Shwartz-Ziv et al., 2022a].",2,positive
"More recently, Shwartz-Ziv et al. (2022) proposes to approximate the prior using SGD trajectory as in SWAG (Maddox et al., 2019) for transfer learning.",2,positive
"Notably, Shwartz-Ziv et al. (2022) use transfer learning to specify informative BNN priors, considering SimCLR
pre-training as a special case.",1,neutral
"For instance, employing SWAG inference to learn θs (Maddox et al., 2019) would an yield approach similar to Pre-train Your Loss (Shwartz-Ziv et al., 2022).",1,neutral
"These pre-trained representations are then used as a feature extractor for downstream supervised tasks such as image classification, object detection, and transfer learning (Caron et al., 2021; Chen et al., 2020; Misra and Maaten, 2020; Shwartz-Ziv et al., 2022).",1,neutral
[46] use a low-rank estimate of the curvature around an optimum of a pre-training task to regularise subsequent supervised learning.,1,neutral
Shwartz-Ziv et al. (2022) use a low-rank estimate of the curvature around an optimum of a pre-training task to regularise subsequent supervised learning.,1,neutral
"in [40], that the model pre-trained with the high-resolution dataset can provide the desirable initialization of the network for a downstream task i.",1,neutral
