text,target_M6_predict,target_predict_M6_label
"Many great efforts have been made in this field, including a few specific image datasets (Lake et al., 2019; Bertinetto et al., 2019; Triantafillou et al., 2019; Wah et al., 2011) (such as Omniglot, CIFAR-FS, CUB, and mini-ImageNet) and various approaches.",2,positive
"shot learning methods [37], [38] use a meta-learning strategy, which extracts transferable knowledge from a set of tasks",1,neutral
"One approach is to use meta-learning to learn how to learn new tasks from few examples [34, 43, 25, 49].",1,neutral
"We investigate the effect of label noise on two representative datasets, CifarFS [2] and Omniglot [10], in a (5, 5)-FSL setting with a query set of 15 samples per class.",2,positive
", miniImageNet [7], CIFAR-FS [36] and MURA [37], are conducted.",2,positive
CIFAR-FS is also a well-known few-shot classiﬁcation database [36].,2,positive
"To assess the performance of the proposed model by comparison with other methods in terms of inference accuracy, validations on three databases, i.e., miniImageNet [7], CIFAR-FS [36] and MURA [37], are conducted.",2,positive
"It should be noted that on the miniImageNet database, the best performance is achieved with L ¼ 2 , while on CIFAR-FS, it is better when L is 4.",2,positive
"Speciﬁcally, MURA is a medical imaging database in e-healthcare and another two databases are more generic. miniImageNet and CIFAR-FS contain a wide variety of images with more complex backgrounds, which can help us more effectively examine the generalization ability of our proposed model under different e-healthcare scenarios.",2,positive
CIFAR-FS is also a well-known few-shot classification database [36].,2,positive
"We adhere to the widely used splitting protocol proposed in (Bertinetto et al. 2019; Oreshkin, López, and Lacoste 2018; Ravi and Larochelle 2017) to ensure fair comparisons with baselines.",2,positive
"Few-shot Learning Setting: We employ four prominent few-shot image classification benchmarks for our evaluations: CIFAR-FS (Bertinetto et al. 2019), FC100 (Oreshkin, López, and Lacoste 2018), miniImageNet (Vinyals et al.",2,positive
32% in Top-1 accuracy on the CIFAR-FS (Bertinetto et al. 2019) dataset compared to the BEiT-3 baseline.,0,negative
"Few-shot Learning Setting: We employ four prominent few-shot image classification benchmarks for our evaluations: CIFAR-FS (Bertinetto et al. 2019), FC100 (Oreshkin, López, and Lacoste 2018), miniImageNet (Vinyals et al. 2016), and tieredImageNet (Ren et al. 2018).",2,positive
We utilized the BEiT-3 backbone in all experiments and reported our findings on the CIFAR-FS dataset.,2,positive
"Specifically, we observe a boost of up to 3.32% in Top-1 accuracy on the CIFAR-FS (Bertinetto et al. 2019) dataset compared to the BEiT-3 baseline.",2,positive
"Method Omniglot miniImageNet CIFAR-FS (5,1) (5,5) (20,1) (5,1) (5,5) (20,1) (5,1) (5,5) (20,1)
Train from scratch 50.29 72.82 26.20 24.20 38.84 16.29 31.12 44.89 20.32",0,negative
"We evaluate BMSSL on three standard few-shot benchmarks of unsupervised meta-learning: Omniglot [30], miniImageNet [52], and CIFAR-FS [6].",2,positive
"Nevertheless, having a closed-form expression for Ab enables us to exploit a meta-learning scheme like [57] to formulate a zero-shot prediction loss to learn them jointly with the rest of the parameters.",1,neutral
"[4] Luca Bertinetto, Joao F Henriques, Philip Torr, and Andrea Vedaldi.",0,negative
", meta-learning [4, 29], hyperparameter optimization [12, 3], reinforcement learning [59, 54] and neural architecture search [35, 8].",1,neutral
model uses a differentiable ridge regression (RR) layer in the inner loop to learn task-specific features [28].,1,neutral
", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al. (2017); Blanchet et al. (2017); Lin et al.",2,positive
", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al.",1,neutral
", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al. (2017); Blanchet et al.",2,positive
", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate.",2,positive
", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al.",2,positive
", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al. (2017); Blanchet et al. (2017); Lin et al. (2020); Devraj & Chen (2019); Hu et al.",2,positive
", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions.",2,positive
", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al.",2,positive
"…tool to study many machine learning applications such as hyperparameter optimization (Franceschi et al., 2018; Shaban et al., 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et…",2,positive
", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al. (2017); Blanchet et al. (2017); Lin et al. (2020); Devraj & Chen (2019); Hu et al. (2019). A SCO reformulation has also been used to solve nonconvex distributionally robust optimization (DRO) Rahimian & Mehrotra (2019); Qian et al.",2,positive
"Following [61], it is split into 64, 20 and 16 classes for training, validation and testing, respectively.",0,negative
"In other words, while FR is part of the whole network, its weights ΘR are obtained by a direct least-squares type of solutions instead of by gradient descent, which has been used as a paradigm in [Bertinetto et al., 2018] for adaptation.",1,neutral
"[2020] use an attention mechanism based on word statistics that is trained on meta tasks to aggregate pre-trained embeddings for direct classification using a ridge regressor [Bertinetto et al., 2019] instead of predicting softmax parameters.",1,neutral
"Next, we evaluate these two selection methods along with random selection by ap-
plying them using the three representative networks in implementation settings, namely, P > M > F (Mini-I), RFS (S.S.), and R2-D2 (S.S.).",2,positive
"To begin with, as indicated by the bold numbers, six out of the nine networks (RFS, Baseline, Baseline++, R2-D2, e3bm, SSL) performed better when trained with Snapshot Serengeti than when trained with mini-ImageNet.",0,negative
"(a) Baseline (b) Baseline++ (c) e3bm
(d) P > M > F (e) ProtoNet (f) R2-D2
(g) RFS (h) RENet (i) SSL
Figure A1.",1,neutral
"We have selected nine FSL networks: ProtoNet [13], RFS [14], Baseline and Baseline++ [15], R2-D2 [34], e3bm [17], RENet [35], SSL-FEW-SHOT [36], and P > M > F [37].",2,positive
"Baseline [15], RFS [14], and R2-D2 [34] all use a form of linear classifier for their decision rule, while RENet uses a novel cross-correlational attention (CCA) module and e3bm [17] uses a more complex ensemble of classifiers.",1,neutral
"We conduct the same implementation test for the three representative networks (P > M > F (Mini-I), RFS (S.S.), R2-D2 (S.S.)), and the resulting comparisons are shown in Figure 7.",2,positive
"(a) Baseline (b) Baseline++ (c) e3bm
(d) P > M > F (e) ProtoNet (f) R2-D2
(g) RFS (h) RENet (i) SSL Figure A2.",1,neutral
"The effect is not significant with R2-D2, and in the case of P > M > F it actually degrades the performance slightly.",1,neutral
The comparative evaluation results on MiniImageNet and Cifar-FS have been presented in Figure 5.,2,positive
"On Cifar-FS and CUB-100-2011, PEMnE-BMS* is instead the best transductive approach.",2,positive
"We report the evaluation results on the MiniImageNet and Cifar-FS workloads; the results on other workloads are similar, thus omitted here.",0,negative
"All the images are of the size of 84×84; • Cifar-FS[47]: it contains totally 100 classes, each of which contains 600 images with the size of 32×32.",1,neutral
The evaluation results on MiniImagenet and Cifar-FS have been presented in Table 4.,0,negative
"All the images are of the size of 84×84;
• Cifar-FS[47]: it contains totally 100 classes, each of which contains 600 images with the size of 32×32.",1,neutral
"Metric-based models tend to achieve better results on tieredImageNet and CIFAR-FS with high-diversity task samplers, while they perform better on Omniglot with the Uniform Sampler.",2,positive
"CIFAR-FS [6] comprises 100 classes with 600 images per class, split the same as miniImageNet.",2,positive
"For instance, [61] and [62] perform a closed-form or convex optimization on top of meta-learned features.",1,neutral
"Following the recent work of [46], we use the same training/validation/testing splits consisting of 64/16/20 classes respectively.",2,positive
"Implementation Details We study the classic FSL methods ProtoNet (Snell et al., 2017), MAML (Finn et al., 2017), R2D2 (Bertinetto et al., 2019), and Baseline(++) (Chen et al., 2019), using the implementations provided by the LibFewShot1.",2,positive
", 2017), R2D2 (Bertinetto et al., 2019), and Baseline(++) (Chen et al.",1,neutral
"Recent algorithmic advances in this field have driven successful applications in areas such as meta-learning [3, 16, 24], reinforcement learning [21, 30, 46] and hyperparameter optimization [13, 20, 44].",1,neutral
"The experiments are conducted on three widely used fewshot learning benchmarks, including miniImageNet (Vinyals et al. 2016), CUB (Wah et al. 2011), and CIFARFS (Bertinetto et al. 2019). miniImageNet is a mini-version
of the ImageNet dataset (Russakovsky et al. 2015).",2,positive
"• CAVDO stands for combining Cifar-fs (Bertinetto et al., 2019), FGVCAircraft (Maji et al., 2013), VGGFlower (Nilsback & Zisserman, 2006), DescribableTextures (Cimpoi et al., 2013), Omniglot (Lake et al., 2015).",2,positive
"• MICOVA stands for combining MiniImagenet (Vinyals et al., 2017), Cifar-fs (Bertinetto et al., 2019), Omniglot (Lake et al., 2015), VGGFlower (Nilsback & Zisserman, 2006), FGVCAircraft (Maji et al., 2013).",2,positive
"• CAVDO stands for combining Cifar-fs (Bertinetto et al., 2019), FGVCAircraft (Maji et al.",2,positive
"• CADO stands for combining Cifar-fs (Bertinetto et al., 2019), FGVCAircraft (Maji et al.",2,positive
"• CADO stands for combining Cifar-fs (Bertinetto et al., 2019), FGVCAircraft (Maji et al., 2013), Delaunay (Gontier et al., 2022), and Omniglot (Lake et al., 2015).",2,positive
", 2017), Cifar-fs (Bertinetto et al., 2019), Omniglot (Lake et al.",2,positive
"• MICOD stands for combining MiniImagenet (Vinyals et al., 2017), Cifar-fs (Bertinetto et al., 2019), Omniglot (Lake et al., 2015), and Delaunay (Gontier et al., 2022).",2,positive
"CIFAR-FS MiniImagenet FC100
5w1s 5w5s 5w1s 5w5s 5w1s 5w5s
Matching Networks(CNN-4-64) - - 43.5 55.3 - - MAML(CNN-4-64) - - 48.7 63.1 - -
ProtoNet (CNN-4-64) 55.5 72.0 49.4 68.2 37.5 51.4 MetaOpt-SVM (ResNet12) 72.0 84.2 62.6 78.6 49.8 67.2 Meta-Baseline (ResNet12) - - 68.6 83.7 - - EASY 3xResNet12(ResNet12) 75.24 89.0 71.75 87.15 48.0 64.7
Baseline++ (WRN-28-10) 67.5 80.1 57.5 73.0 - - S2M2R(WRN-28-10) 74.8 87.5 64.9 83.2 - -
AMDIM (AmdimNet) - - 76.8 91.0 - -
HCTransformers(ViT-S) 79.9 90.5 74.7 89.2 48.3 66.4 P>M>F (IN1K, Sup., RN50)† 76.73 87.60 85.74 94.33 58.91 75.14
P>M>F (IN1K, Sup., Swin-S)† 84.61 92.62 95.83 98.20 70.92 83.98
OURS(1N1K, Sup., RN50) 78.32 89.13 86.68 96.31 60.74 78.54 OURS(1N1K, Sup., Swin-S) 86.52 93.64 96.44 98.82 72.81 85.22
Fig.",0,negative
"We evaluate our proposed method on three standard within-
domain benchmarks: MiniImagenet [11], CIFAR-FS [1], and
FC100 [8].",2,positive
"We evaluate our proposed method on three standard withindomain benchmarks: MiniImagenet [11], CIFAR-FS [1], and FC100 [8].",2,positive
"There are six methods based on meta-learning, named MAML [23], Versa [24], R2D2 [25], MTL [26], Leo [27],
and ANIL [28].",1,neutral
The R2D2 [25] proposed used the main adaptation mechanism which based on some fast convergent methods for few-shot learning.,1,neutral
"There are six methods based on meta-learning, named MAML [23], Versa [24], R2D2 [25], MTL [26], Leo [27],",1,neutral
A similar model was introduced in [2] but mainly repurposed for classification.,0,negative
"NAO consistently outperforms all few-shot methods on CUB [63] and miniImageNet [62], and reaches comparable results to SeedSelect [49] on CIFARFS [8].",2,positive
"Tables 3a and 3b compare NAO with SoTA approaches on few-shot classification benchmarks: CUB, miniImageNet, and CIFAR-FS.",2,positive
(3) CIFAR-FS [8]: Created from CIFAR-100 [31] by using the sampling criteria as miniImageNet.,2,positive
"1) More meta-learning instances: We first supplement the results of FoMAML and ProtoNet with a Conv-4 backbone on the mini-ImageNet dataset in Table VI, and then integrate MGAug into more meta-baselines, including Reptile [58], CAVIA [59], MAML [35], R2-D2 [38], and MetaOptNet [39].",2,positive
"This paper focuses on these two meta-learning branches, but our MGAug can also be used for other branches and methods [10] derived from this two-loop framework, such as R2-D2 [38] and MetaOptNet [39].",2,positive
"In the main text, we show examples where the estimand is a given coefficient of a linear regression model (implemented by differentiating through a least-squares solution), and in the Appendix we show results for bounding the coefficient of a logistic regression (implemented via differentiating through an iteratively reweighted least squares solver [31]).",1,neutral
"In particular, our method is similar to [33] which employ KRR on top of a meta-learned feature map but they do not focus on instances that are sets.",1,neutral
"Before CLIP emerged, Jeong et al. [20] addressed the few-shot OOD detection, using only a few ID training data for OOD detection, but their experiments have only been done on small data sets (e.g., Omniglot [25], CIFAR-FS [3]), showing the limitations of the performances of few-shot learning methods without CLIP.",2,positive
", Omniglot [25], CIFAR-FS [3]), showing the limitations of the performances of few-shot learning methods without CLIP.",1,neutral
"tion networks [17], R2D2 [62], SNAIL [63], AdaResNet [64], and RFS [21].",2,positive
"The contrasted
ones include MAML [56], Matching networks [12], IMP [18], Prototypical networks [7], TAML [57], SAML [19], GCR [58], KTN (Visual) [59], PARN [60], Dynamic few-shot [61], Relation networks [17], R2D2 [62], SNAIL [63], AdaResNet [64], and RFS [21].",2,positive
"10 Effective for Other FSL Classifiers?: In Table V, we additional select three FSL classifiers, including logistic regression [9], ridge regression [57], and SVM [67], to analyze the effectiveness of the proposed fusion strategy.",2,positive
"HERE, “CC”, “LR”, “RR”, AND “SVM” DENOTES THE COSINE [11], LOGISTIC REGRESSION [9], RIDGE REGRESSION [57], AND SVM [67] CLASSIFIERS, RESPECTIVELY",1,neutral
"Following [57], we split it into 64 classes for training, 16 classes for validation, and 20 classes for test, respectively.",0,negative
The CIFAR-FS [40] contains 32 × 32 images from CIFAR-100 [41] that are divided into 100 classes and each class contains 600 images.,1,neutral
"We use miniImageNet [4], tiered-ImageNet [45] and CIFAR-FS [40] as the datasets in our experiments.",2,positive
• CIFAR100 Few-Shots (CIFAR-FS) [33] is randomly split from CIFAR-100 [34] dataset.,2,positive
"The study evaluated the effectiveness of the bias prediction network across multiple benchmark datasets, including miniImageNet, CIFAR-FS, FC-100, and Adience , employing five-way one-shot and five-way five-shot learning settings.",2,positive
"We evaluate our BiDfMKD framework on the meta-testing subsets of CIFARFS (Bertinetto et al., 2018), MiniImageNet (Vinyals et al.",2,positive
"Datasets for Meta Testing
CIFAR-FS (Bertinetto et al., 2018), MiniImageNet (Vinyals et al., 2016) are commonly used in meta-learning, consisting of 100 classes with 600 images per class.",2,positive
"We evaluate our BiDfMKD framework on the meta-testing subsets of CIFARFS (Bertinetto et al., 2018), MiniImageNet (Vinyals et al., 2016), and CUB-200-2011 (CUB) (Wah et al., 2011).",2,positive
"For benchmarks of three scenarios on CIFARFS, MiniImageNet and CUB, our framework achieves significant performance gains in the range of 8.09% to 21.46%.",2,positive
CIFAR-FS (CIFAR100 few-shots) [63] is randomly sampled from CIFAR-100 [64] in the same way that miniImageNet has been generated.,2,positive
"Datasets: We validate our framework on the following datasets, i.e., miniImageNet[13], CUB-200-2001[14], and CIFAR-FS[15].",2,positive
"Moreover, our network is better for both coarse-grained classification[13, 15] and fine-grained classification[14].",2,positive
"Restrictions apply.
we also used the CIFAR-FS datasets, a variant of the CIFAR100 datasets.",2,positive
", miniImageNet[13], CUB-200-2001[14], and CIFAR-FS[15].",2,positive
"As expected, the imbalance is severe; yet such condition is rare in computer vision scenarios, especially in metalearning settings—typical FSL datasets like Omniglot [39], miniImageNet [40] and CIFAR-FS [41] have all ρ=1.",1,neutral
"Here, Ours, DR-CFS, DR-ML, and Meta-CI perform meta-learning; DR-ML and Meta-CI employ model-agnostic meta-learning [11], Ours and DR-CFS are founded on the model choice that yields closed-form solvers for task adaptation [5, 35].",1,neutral
We formulate outcome model μa and pseudo outcome model τ using task-shared encoders with the task-specific last linear layer [5]:,2,positive
"This advantage is crucial in meta-learning because the recent studies show that the closed-form solvers for task adaptation can greatly improve the classification and regression performances [35, 5].",1,neutral
"Whereas there are several closed-form solvers in the field of meta-learning [35, 5, 26, 16], none of them can be directly applied to training the models in meta-learners, which are founded on the two-stage-based estimation, where the outputs of one regression model are used for training another regression model.",1,neutral
"(13, 14), which can be O(N s3 a ) and O(N ) using the Woodbury formula [5].",1,neutral
"Researchers explore meta-learning to find well-initialized models suitable for adaptation [5,31,66], or compensate for the data insufficiency in few-shot settings by data augmentation [3, 40].",1,neutral
"Another model with an embedded differentiable iterative solver is introduced by (Bertinetto et al., 2019).",1,neutral
"In addition to comparing with ProtoNet [18] and R2D2 [109] on their original small backbones, we also compare with
both methods with larger convolutional backbones, i.e., ResNet-12.",2,positive
"Interestingly, ProtoNet and R2D2 both show competitive results, and especially R2D2 already performs better than MetaOptNet on CIFAR-FS.",2,positive
"We consider four typical meta-learning methods: MAML [17], ProtoNet [18], R2D2 [109], and MetaOptNet [119] with SOTA performance.",2,positive
"In addition to comparing with ProtoNet [18] and R2D2 [109] on their original small backbones, we also compare with both methods with larger convolutional backbones, i.",1,neutral
"Then, DAC-MR can still consistently provide improvements to both (enhanced) baselines with an obvious gap, which yields at least 1.5% and 2.4% 1-shot accuracy improvement for ProtoNet and R2D2, respectively.",2,positive
"An elegant property of DDRR methods is that they naturally address regression tasks, although they have been repurposed for classification [6] by conducting MSE-loss regression to a target 1-hot vector.",1,neutral
"Further, we calibrate the prediction for binary cross entropy loss with a learnable scale and bias following [6].",1,neutral
"DDRR Deep differentiable ridge-regression has been considered for few-shot recognition [6], tracking [82], and other tasks.",1,neutral
"when encountering adversarial samples, AQ focuses only on the case when the query sample is attacked, this paper aims to improve R2D2’s performance under adversarial attacks [9].",2,positive
"Meta-learning methods based on optimization aim to find a set of initialization parameters which can quickly adapt to the basic model, including MAML [3] , LEO [4], R2D2 [9], MetaOptNet [14] and a series of methods.",2,positive
"In this section, we verify the performance of DeR2D2 on two benchmark datasets: MiniImageNet [10] and CIFAR-FS [9].",2,positive
"Pioneer works [24], [25] have shown their effectiveness by using a closed-form solution for prototypical reprojection, which performs the conventional Ridge regression:",1,neutral
"This new learning space ensures a differentiable closedform solution with ridge regression [24], [25] to reduce the",1,neutral
"distance measurements [17], [18], [24], [25], [35], [36].",1,neutral
"This is the case in applications where the data is scarce, for example in rare animal species [1].",1,neutral
"Optimization-based methods focus on learning a robust model initialization, through gradientbased solutions [9, 27], closed-form solutions [1] or an LSTM [31].",1,neutral
"First, for semantic data augmentation, where we reach SoTA for both few-shot classification and long-tail learning on miniImageNet [63], CUB [64], CIFAR-FS [4], ImageNet-LT [39] and iNaturalist [62].",2,positive
"Tables 1a and 1b compare SeedSelect with SoTA approaches for few-shot classification and semantic data augmentation, for CUB, miniImageNet, and CIFAR-FS.",2,positive
(3) CIFAR-FS [4]: Obtained from CIFAR-100 dataset [33] using the same criteria used for sampling miniImageNet.,2,positive
"2021), ridge/logistic regression (Chen et al. 2019; Bertinetto et al. 2019; Tian et al. 2020), and graph neural networks (Satorras and Estrach 2018; Tang et al.",1,neutral
2016) with the same architecture as previous works (Bertinetto et al. 2019; Ye et al. 2020) is used as the feature extractor fθ of our model.,2,positive
"Some of the other notable approaches include learning to generate synthetic data for novel classes [23, 33, 68], using better feature representations [1, 2, 19, 28, 41, 63, 67] or utilizing differentiable convex solvers [3, 34].",1,neutral
CIFAR-FS is the subsets of CIFAR100 [17].,1,neutral
We use the source code of FEAT and SnaTCHer-F from github to do the experiment on the CIFAR-FS.,2,positive
"We use miniImageNet [37], tieredImageNet [24] and CIFAR-FS [4] to evaluate the performance of the model.",2,positive
"However, scaling&&shift and full-tuning both do not
get consistent improvements on five benchmarks against directly test without meta-training, even having a large margin on CIFAR-FS.",0,negative
"Although typically input image size of few-shot setting is smaller than that in large-scaled pretraining, e.g. 84 for miniImageNet and 32 for CIFAR-FS, the emphasis of our pipeline is not to make comparisons with other few-shot algorithms but to explore how to better leveraging pretrained models against full-tuning.",2,positive
"We use five frequently-used datasets to evaluate our pipeline: miniImageNet[9], CUB[25], CIFAR-FS[23], clipart[24] and sketch[24].",2,positive
2 has 0.3M parameters updated that is 78 times as that of VPT-SHALLOW with 10 tokens but the latter gets obviously better performance except on 1 shot tasks of CIFAR-FS.,2,positive
3 VPT-DEEP is compared with VPT-SHALLOW and VPT-ADD on CIFAR-FS.,2,positive
"We use five frequently-used datasets to evaluate our pipeline: miniImageNet[9], CUB[25], CIFAR-FS[23], clipart[24] and sketch[24]. miniImageNet is from ImageNet-1K[19] and is the most common benchmark of few-shot learning.",2,positive
"CIFAR-FS has the same structure as miniImageNet which has 64 classes of 100 as training split, 16 classes as validation split and 20 classes as test split.",2,positive
", 2019) and meta-learning (Bertinetto et al., 2018; Finn, 2018; Finn et al., 2018)), RNN training (Merity et al.",2,positive
"…baselines
In Table 14, we further compare our method on meta learning benchmarks, namely Mini Imagenet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019) with different approaches in the literature based on meta learning (Snell et al., 2017; Oreshkin et al., 2018; Dhillon et…",2,positive
"Comparison with metalearning baselines
In Table 14, we further compare our method on meta learning benchmarks, namely Mini Imagenet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019) with different approaches in the literature based on meta learning (Snell et al., 2017; Oreshkin et al., 2018; Dhillon et al., 2020; Lachapelle et al., 2022a).",2,positive
"Other approaches that leverage a meta-learning objective for multi-task learning have been formulated (Dhillon et al., 2020; Snell et al., 2017; Lee et al., 2019; Bertinetto et al., 2019).",1,neutral
"We report results on the following FSL benchmark datasets: miniImageNet [54], tieredImageNet [39], CIFARFS [8], and FC100 [33].",2,positive
"We report results on the following FSL benchmark datasets: miniImageNet [54], tieredImageNet [39], CIFARFS [8], and FC100 [33].
miniImageNet incorporates 100 randomly sampled categories from ImageNet and 600 images per category.",2,positive
"The Cars [30] dataset consists of 16,185 images of 196 classes of cars; it is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in 50-50.",0,negative
"The mini-ImageNet is used for the meta-train task, and the tiered-ImageNet [52], CUB-200-2011 [58], Cars [11] datasets are used for the metatest task.",2,positive
", miniImageNet [1], tieredImageNet [30] and CIFAR-FS [31], utilizing Pytorch on NVIDIA Geforce RTX 3090 with 24G VRAM.",2,positive
"Assuming that M tasks are fed to the model at an episodic training, the corresponding loss function is CIFAR-FS is a subset of the CIFAR-100 dataset with 100 different classes and 600 color images in every class.",1,neutral
"We analyze the computational complexity and conduct the ﬁve-way ﬁve-shot streaming tasks on miniImageNet, tieredImageNet, and CIFAR-FS.",2,positive
"[90] introduced a new idea about the existing learning the optimizer methods, that is using a non-deep machine learning algorithm to adapt new tasks from few samples.",1,neutral
", 2018), CIFARFS (Bertinetto et al., 2018), focus on the meta-learning N-way K-shot setting, but this setting is less applicable to transfer learning models (Dumoulin et al.",1,neutral
"Traditional few-shot learning benchmarks, i.e. miniImageNet (Cai et al., 2018), CIFARFS (Bertinetto et al., 2018), focus on the meta-learning N-way K-shot setting, but this setting is less applicable to transfer learning models (Dumoulin et al., 2021) and was demonstrated not challenging enough for…",2,positive
"Traditional few-shot learning benchmarks, i.e. miniImageNet (Cai et al., 2018), CIFARFS (Bertinetto et al., 2018), focus on the meta-learning N-way K-shot setting, but this setting is less applicable to transfer learning models (Dumoulin et al., 2021) and was demonstrated not challenging enough for large pretrained models (Dhillon et al., 2019).",2,positive
"the MAML-based methods on miniImageNet [7], tieredImageNet [53] and CIFAR-FS [54], which are public benchmarks",2,positive
"on 3 popular few-shot benchmarks: miniImageNet [7], tieredImageNet [53] and CIFAR-FS [54], where for each experiment, tasks are drawn from only one underlying distribution.",2,positive
"For task-homogeneous setting, we conduct experiments on 3 popular few-shot benchmarks: miniImageNet [7], tieredImageNet [53] and CIFAR-FS [54], where for each experiment, tasks are drawn from only one underlying distribution.",2,positive
"The number of metaupdate iterations is set to be 60,000 for Mixture-of-Datasets and miniImageNet, 80,000 for tieredImageNet and Meta-Dataset, and 40,000 for CIFAR-FS.",2,positive
"5) Results on Public Benchmarks: Task-Homogeneous Benchmarks We further conduct experiments to compare the MAML-based methods on miniImageNet [7], tieredImageNet [53] and CIFAR-FS [54], which are public benchmarks following task-homogeneous setting.",2,positive
"Meta-Album will further challenge the research community by being considerably larger and by mixing tasks from multiple domains, in [2-20]-way [1-20]-shot settings.",2,positive
CIFAR-FS [2] and FC100 [45] are remodeled from CIFAR-100 [30] for few-shot settings.,0,negative
"Meta-Album allows us to choose N ∈ [2, 20] and k ∈ [1, 20].",1,neutral
"3) Datasets: CIFAR-FS [64] is a few-shot dataset created by dividing the 100 classes of CIFAR-100 into 64 base classes, 16 validation classes, and 20 novel test classes.",2,positive
"The last column denotes the OOD noise from CIFAR-FS dataset.
is from miniImageNet.",2,positive
CIFAR-FS+miniImagenet in the second column represents that OOD noise is a sample from miniImageNet while replacing the sample in CIFAR-FS.,2,positive
"In experiments, we adopt four standard few-shot classification datasets, including CIFAR-FS [64], FC-100 [65], miniImagenet [19] and tieredImagenet [63].",2,positive
The evaluations are conducted on 5-way 5-shot open-world settings on the CIFAR-FS dataset.,0,negative
"However, Omniglot is not a challenging image dataset and models can easily get near-perfect performance (Mishra et al., 2018; Miconi et al., 2018); therefore, recent works tend to choose MiniImageNet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019) instead.",2,positive
"Here we consider the sequential version of 5-way one-shot image classification on MiniImageNet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019).",2,positive
"In the experiment, we compare our algorithm with the optimization in MetaOptNet on datasets CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, Rodríguez López, and Lacoste 2018), which are widely used for few-shot learning.",2,positive
The comparison to previous work on CIFAR-FS and FC100 in the aspect of prediction accuracy is shown in Table 1.,2,positive
"However, its optimization does not explicitly consider the
0 500 1000 1500 2000 2500 3000 3500 Running time /s
0.4
0.6
0.8
1.0
1.2
1.4
Tr ai
ni ng
lo ss
Dataset: CIFAR-FS (5-way 5-shot) GAM MetaOptNet
500 1000 1500 2000 2500 3000 3500 Running time /s
0.76
0.78
0.80
0.82
0.84
Te st
a cc
ur ac
y
Dataset: CIFAR-FS (5-way 5-shot) GAM MetaOptNet
0 200 400 600 800 1000 Running time /s
0.6
0.8
1.0
1.2
1.4
Tr ai
ni ng
lo ss
Dataset: FC100 (5-way 5-shot) GAM MetaOptNet
0 200 400 600 800 1000 Running time /s
0.49
0.50
0.51
0.52
0.53
0.54
0.55
0.56
Te st
a cc
ur ac
y
Dataset: FC100 (5-way 5-shot) GAM MetaOptNet
Figure 7: Comparison of MetaOptNet and gradient approximation method (GAM).",0,negative
"For both CIFAR-FS and FC100 datasets, our method converges faster than the optimization in MetaOptNet in terms of the training loss and test accuracy, and achieves a higher final test accuracy.",2,positive
"Other approaches are essentially model based (Santoro et al., 2016; Bertinetto et al., 2018; Ravi & Larochelle, 2016; Munkhdalai & Yu, 2017) and metric space based (Koch et al.",1,neutral
"Other approaches are essentially model based (Santoro et al., 2016; Bertinetto et al., 2018; Ravi & Larochelle, 2016; Munkhdalai & Yu, 2017) and metric space based (Koch et al., 2015; Vinyals et al., 2016; Snell et al., 2017; Sung et al., 2018).",1,neutral
"CIFAR-FS [4], a variant of Ci-
far100 [24], contains 64, 16, and 20 categories for training, validation, and test, respectively.",2,positive
"CIFAR-FS [4], a variant of Cifar100 [24], contains 64, 16, and 20 categories for training, validation, and test, respectively.",2,positive
We used two popular few-shot benchmark CIFAR-FS [4] and MiniImageNet [24] for comparison with other few-shot methods.,2,positive
7 shows the results of the two image models on CIFAR-FS.,2,positive
"To validate this, we computed the average CoS between GT anchors and the output visual features of the two models trained on CIFAR-FS in Tab.",2,positive
"• ProtoNet [6] is one of the most iconic and well-recognized few-shot learning structures; • Baseline and Baseline++ are proposed in [16] and are reported to be effective at cross-domain few-shot learning cases; • RFS [9] discarded the commonly used episodic training scheme in few-shot learning and achieved good results; • R2-D2 [8] is the representative of meta-learning, where fewshot learning is only one of many potential applications of the network.",2,positive
"As can be seen, four out of five networks (RFS, Baseline, Baseline++, R2-D2) performed better when trained with Snapshot Serengeti than when trained with mini-ImageNet.",2,positive
"Hence, meta-learning networks such as [7] and [8] are also used for few-shot learning tasks.",1,neutral
"When trained with mini-ImageNet, R2-D2 obtained best overall performance, and RFS is a close second.",0,negative
"In addition, DSMNet outperforms or matches the previous state-ofthe-art models on miniImagenet, CUB-200, Stanford-Dogs, and CIFAR-FS datasets.",2,positive
"To evaluate the performance of DSMNet on fine-grained datasets, we conducted experiments on CUB-200, StanfordDogs, and CIFAR-FS datasets.",2,positive
All images in CIFAR-FS have the same resolution of 32 × 32.,1,neutral
"Under the 5-way 1-shot setting, our DSMNet achieves competitive results on CIFAR-FS dataset, whereas the results on the Stanford Dogs dataset are somewhat less satisfactory, which can be attributed to two possible reasons.",0,negative
"As shown in Tables 4 and 5, under the 5-way 5-shot setting, our DSMNet achieves the highest results on both Stanford Dogs
and CIFAR-FS datasets.",0,negative
"In this experiment, we select four benchmark datasets including miniImagenet [18], and three fine-grained datasets that are Caltech-UCSD Birds-200-2011 (CUB200) [51], Stanford-Dogs [52], and CIFAR100 few-shots (CIFAR-FS) [53].",2,positive
CIFAR-FS: This dataset [53] is sampled from CIFAR100 dataset [55].,2,positive
"To investigate the effects of different backbones on DSMNet, we used ResNet10 [65], ResNet12 [47], ResNet18 [65], ResNet34 [65], and WRN-28-10 [66] as embedding module respectively, and conducted experiments on miniImagenet, CUB-200, Stanford-Dogs, and CIFAR-FS datasets.",2,positive
"To verify the effectiveness of the adaptation strategy, we conducted two sets of experiments on miniImagenet, CUB200, Stanford-Dogs, and CIFAR-FS datasets.",2,positive
"We show some of the representative images from miniImagenet, CUB-200, Stanford-Dogs, and CIFAR-FS in Fig.",2,positive
"Optimization-based methods (Bertinetto et al. 2019)(Finn, Abbeel, and Levine 2017)(Ravi and Larochelle 2017) usually train a meta learner over auxiliary dataset to learn a general initialization model, which can fine-tune and adapt to new tasks very soon.",1,neutral
Way 1-Shot accuracy of different P on validation set of miniImageNet and CIFAR-FS.,2,positive
"MiniImageNet and tieredImageNet are derivatives of ImageNet dataset [36], CIFAR-FS is derived from CIFAR-100 dataset [20,43].",2,positive
"We conduct our experiments on 4 widely used FSL benchmarks, i.e., miniImageNet [44], tieredImageNet [34], CIFAR-FS [4], and CUB [45].",2,positive
Way 1-Shot results when setting different weight coefficients λ on the validation set of miniImageNet and CIFAR-FS.,1,neutral
", miniImageNet [44], tieredImageNet [34], CIFAR-FS [4], and CUB [45].",2,positive
"In addition, as shown in Tab.6, our method also gets competitive results on CIFAR-FS.",0,negative
"As for benchmarks without semantic knowledge annotations (e.g., class-aware attributes annotations) such as miniImageNet, tieredImageNet, and CIFAR-FS, previous works always leverage pretrained Word2Vec models such as GloVe [29] as the semantic source.",2,positive
And R2-D2 [4] learns the feature extractor that adapts well to closed-formed linear classifiers.,1,neutral
"The adaptation of the entire network makes it hard to be scaled to large networks, and many recent efforts focus on adapting the last classification layer only [12, 4], while assuming a universal feature extractor that is shared across all tasks.",1,neutral
Table 3 displays the results on CIFAR-FS.,0,negative
"Datasets The experiments are conducted on three few-shot learning benchmarks, including miniImageNet [6], CUB-200-2011 [31], and CIFAR-FS [32].",2,positive
"The experiments are conducted on three few-shot learning benchmarks, including miniImageNet [6], CUB-200-2011 [31], and CIFAR-FS [32]. miniImageNet is a mini-version of the ImageNet dataset [33], which contains 100 classes with 600 images per class, and the image size is 84 × 84 × 3. miniImageNet is divided into 64 base classes, 16 validation classes,
and 20 novel classes in all experiments.",2,positive
%) on CIFAR-FS with 95% confidence intervals.,0,negative
"All tables show that our framework achieves the best performance for 1-shot and 5-shot compared with the other state-of-the-art on miniImageNet, CUB-200-2011, and CIFAR-FS.",2,positive
"Extensive experiments are conducted on the miniImageNet, CUB-200-2011, and CIFAR-FS.",2,positive
"CIFAR-FS is created by randomly splitting 100 classes of CIFAR-100 [34] into 64 base classes, 16 validation classes, and 20 novel classes.",2,positive
"Method CIFAR-FS
5-way-1-shot 5-way-5-shot
Optimization-based ICML17’ MAML [4] 58.9± 1.9 71.5± 1.0 ICLR19’ R2D2 [32] 65.4± 0.2 79.4± 0.2 CVPR19’ MetaOptNet [46] 72.8± 0.7 85.0± 0.5
Metric-based
NIPS17’ ProtoNet [14] 55.5± 0.7 72.0± 0.6 CVPR18’ RelationNet [40] 55.0± 1.0 69.3± 0.8 AAAI22’ AAP2S [42] 73.12± 0.22 85.69± 0.16 CVPR19’ Shot-Free [47] 69.15 84.70
Fine-tuning-based ICLR19’ Baseline++ [15] 67.50± 0.64 80.08± 0.32
Ours PSDC 74.66 ± 0.21 86.37 ± 0.15",0,negative
"We evaluate our approach using four datasets: (i) Mini-ImageNet (Vinyals et al., 2016), (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al., 2018), (iv) and EMNIST (balanced) (Cohen et al., 2017).",2,positive
"This occurred around iteration 16,000 for CIFAR-FS and around iteration 20,000 for Mini-ImageNet, slightly after the first learning rate decay (at 15,000 and 18,000 steps, respectively).",2,positive
"CIFAR-FS consists of a random split of the CIFAR-100 classes into 64 meta-train classes, 14 meta-validation classes, and 20 meta-test classes.",2,positive
"CIFAR-FS and FC-100 are both derived from the CIFAR-100 dataset (Krizhevsky, 2012).",2,positive
"To demonstrate this, we compared the 1- and 5-shot performance of our approach to several other few-shot learning algorithms on the Mini-ImageNet, CIFAR-FS, and FC-100 datasets, as summarized in Table 1.",2,positive
", 2016), (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al.",1,neutral
"Therefore, we empirically investigated the dynamics of mini 6=j∈[l] ‖µf (S̃i)−µf (S̃j)‖ during training in our standard setting (WRN-28-4 with the default hyperparameters, see Section 2) on CIFAR-FS, considering a varying number source classes (l ∈ {5, 10, 20, 30, 40, 50, 60}) and learning rates (η ∈ {2−2i−2}4i=1).",2,positive
"Additionally, [17] showed that meta fine-tuning the entire representation model using MetaOptNet [31] or R2D2 [4] lead to worse performance compared to standard meta-learning, negating the advantages of pre-training completely.",2,positive
"Similarly, while RFS and R2D2 both learn a fixed representation and only adapt the classifier based on each task, RFS’s pre-trained representation clearly outperforms R2D2’s meta-learned representation.",1,neutral
"Our proposed method is most closely related to meta-representation learning [4, 15, 32, 48], which parametrizes the base learner as A(θ,D) = w(gθ(D))gθ(·), separating it into parts of a global feature extractor gθ : X → Rm and a task-adaptive classifier w : D → {f : Rm → Y} resulting in the optimization problem",1,neutral
"The task-adaptive classifier w(·) may take various forms, including nearest neighbor [59], ridge regression classifier [4], embedding adaptation with transformer models [73], and Wasserstein distance metric [74].",1,neutral
"R2D2 [4], ProtoNet [42]) learn classifiers by minimizing some loss over support sets, losing out on the access to the contextual information provided by global labels.",1,neutral
"1-shot 5-shot
ProtoNet 47.8± 0.5 66.8± 0.5 MatchNet 65.6± 0.2 78.7± 0.2 R2D2 75.1± 0.3 86.4± 0.2 DeepEMD 51.3± 0.5 65.6± 0.8 FEAT 77.6± 0.6 87.3± 0.4 FRN 81.9± 0.4 91.0± 0.2 MeLa 84.8± 0.3 92.9± 0.2
Oracle 84.4± 0.3 93.1± 0.2
further improved, since the pre-trained representation is not explicitly optimized for handling novel classes.",0,negative
"In contrast, unconditional approaches (e.g. R2D2 [4], ProtoNet [42]) learn classifiers by minimizing some loss over support sets, losing out on the access to the contextual information provided by global labels.",1,neutral
"[67] Luca Bertinetto, Joao F Henriques, Philip Torr, and Andrea Vedaldi.",0,negative
"And we compare the proposed CPBO with baseline algorithms MAML [64], iMAML [63], and ANIL [65] on Omniglot [66] and CIFAR-FS [67] datasets.",2,positive
"The way MLPs transform data in Transformers diverges from the standard meta-learning approach, where a task-shared input embedding network is optimized by backpropagation-through-training to improve the learning performance of a task-specific readout (e.g., Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019).",1,neutral
"…data in Transformers diverges from the standard meta-learning approach, where a task-shared input embedding network is optimized by backpropagation-through-training to improve the learning performance of a task-specific readout (e.g., Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019).",1,neutral
"DiffAlign has outperformed state-of-the-art approaches on standard few-show classification benchmarks, such as FC100, CIFAR-FS, miniImageNet, tieredImageNet, in both 5- shot and 1-shot setups.",2,positive
"Ablation on losses
Losses FC-100 CIFAR-FS miniImageNet
5w1s 5w5s 5w1s 5w5s 5w1s 5w5s Lnovel 48.1 ± 0.8 65.0 ± 0.7 77.6 ± 1.0 89.71 ± 0.6 66.85 ± 0.76 84.50 ± 0.53 Lnovel + Lsyn 67.33 ± 0.7 73.11 ± 0.7 86.33 ± 0.8 90.87 ± 0.5 80.92 ± 0.7 85.05 ± 0.48 Lnovel + Lsyn + Lbase 69.18 ± 0.7 75.99 ± 0.7 88.9 ± 0.8 91.83 ± 0.5 82.16 ± 0.7 87.88 ± 0.5 Lnovel + Lsyn + Lbase + LMMD 69.37 ± 0.7 76.12 ± 0.7 88.99 ± 0.8 91.96 ± 0.5 82.81 ± 0.8 88.63 ± 0.3
Figure 3.",0,negative
"Comparisons on CIFAR-FS, FC-100, miniImageNet, and tieredImageNet in both 5-way 1-shot and 5-way 5-shot settings are provided in Table.",0,negative
"CIFAR-FS is also obtained from CIFAR-100, containing 64 classes for meta-training, 16 classes for metavalidation and 20 classes for meta-testing. miniImageNet is derived from ImageNet with images downsampled to a resolution of 84× 84 pixels.",2,positive
"We experiment on the four common few-shot benchmarks : FC-100 [33], CIFAR-FS [5], miniImageNet [51] and tieredImageNet [39].",2,positive
"• We validate our approach on standard few-shot benchmarks: CIFAR-FS, FC-100, miniImageNet, and tieredImageNet and achieve state-of-the-art performance in both 5-shot and 1-shot setups.",2,positive
"IV, we show the classification accuracies on popular datasets including miniImageNet, tieredImageNet, CIFAR-FS and CUB-2002011 datasets.",2,positive
4) CIFAR-FS: CIFAR-FS a subset of CIFAR-100 [24] for few-shot classification.,0,negative
"In this section, we show the results on four standard few-shot learning benchmarks: miniImageNet [13], tieredImageNet [18], CUB-200-2011 [21] and CIFAR-FS [22].",2,positive
"In our paper, we propose to employ meta-learning [4, 9, 26] to learn a parameter initialization.",2,positive
"For the experiment, we simulated federated meta-learning using data from three popular datasets, including Omniglot [13], CIFARFS [4], and Mini-ImageNet [25].",2,positive
"Meta-learning [4, 9, 26] learns common knowledge across a large number of tasks which is an optimized starting point for various new tasks as it can fast adapt to unseen tasks.",1,neutral
"The second method is optimizationbased approach [37]–[40], which uses base categories to learn a good feature space as initialization.",1,neutral
"For fair comparison, we follow previous works (Vinyals et al. 2016; Ren et al. 2018; Bertinetto et al. 2018) to split these datasets into training, validation and testing subsets, respectively.",2,positive
"On the CIFAR-FS, where images have a very low resolution, RankDNN with the IE backbone surpasses its baseline, which is also the recent best, by 1.14% and 0.90% under 5-way-1-shot and 5-way-5shot settings, respectively (Table 3).",2,positive
"We use four popular benchmark datasets in our experiments: miniImageNet(Vinyals et al. 2016), tieredImageNet (Ren et al. 2018), Caltech-UCSD Birds-200-2011 (CUB)(Chen et al. 2019b), and CIFAR-FS(Bertinetto et al. 2018).",2,positive
"We build on the ProtoNet [26] and the R2D2 [96] methods, and evaluate on FC100 [58] and CIFAR-
FS [96] datasets.",2,positive
"R2D2 [96] methods, and evaluate on FC100 [58] and CIFARFS [96] datasets.",2,positive
", miniImageNet [23], CIFAR-FS [24], and Omniglot [25].",1,neutral
"Extensive experiments on miniImageNet [23], CIFAR-FS [24], and Omniglot [25] demonstrate that our method performs favourably against previous robust MAML methods considering both clean accuracy and robustness.",2,positive
", miniImageNet [23], CIFAR-FS [24], and Omniglot [25], demonstrate that our method performs favourably against previous robust MAML methods",2,positive
"The bi-level formulation Problem (6) is closely related to metric-based meta-learning methods (Snell et al., 2017; Bertinetto et al., 2019), where a shared representation fθ̂ is learned across all tasks via simple task-specific predictors, such as linear classifiers.",1,neutral
"The experiments are implemented on CIFAR-FS, FC-100, mini-ImageNet and tiered-ImageNet datasets with Conv-4 backbone.",2,positive
"We first implement the proposed IMC hybrid model on mini-ImageNet to compare with the state-of-the-art works including MatchingNet [39], ProtoNet [32], LSTM [28], MAML [7],
RelationNet [33], R2-D2 [2] and LMPNet [9] etc.",2,positive
"Besides, we implement the proposed method in other common FSL datasets including CIFAR-FS, FC100 and tiered-ImageNet.",2,positive
"RelationNet [33], R2-D2 [2] and LMPNet [9] etc.",1,neutral
"CIFAR-FS Constructed from CIFAR-100 [15], CIFAR-FS [2] is a common few-shot learning dataset that contains 100 classes and 60,000 images.",2,positive
"We report the experiments on CIFAR-FS, FC100, mini-ImageNet and tiered-ImageNet datasets in 5-way 5-shot and 5-way 1-shot settings respectively.",2,positive
"For example, L2 normalization brings +6.76% improvements in 1-shot setting and + 1.75% in 5-shot setting on CIFAR-FS dataset.",2,positive
"According to FSL criteria, CIFAR-FS randomly samples 64, 16 and 20 classes for the training, validation and testing sets respectively from CIFAR-100 and each class has 600 images with the size of 32 × 32.",0,negative
"From the results, we can find that, compared with the reproduced ProtoNet, our proposed method has better performance on CIFAR-FS with +14.08% and + 6.97% performance improvements on 1-
ProtoNet* 46.32 ± 0.82 70.43 ± 0.73 36.83 ± 0.74 50.92 ± 0.71 43.13 ± 0.83 65.88 ± 0.76 OM 52.97 ± 0.86 74.44 ± 0.70 38.33 ± 0.71 52.43 ± 0.72 46.24 ± 0.89 67.13 ± 0.74 OC 59.68 ± 0.85 75.65 ± 0.68 38.78 ± 0.70 50.16 ± 0.70 53.79 ± 0.91 70.05 ± 0.75 IMC (Ours) 60.40 ± 0.86 77.40 ± 0.68 39.41 ± 0.74 53.50 ± 0.72 51.55 ± 0.90 69.96 ± 0.74
The best performances are highlighted
shot and 5-shot settings respectively.",0,negative
"In order to validate the efficacy of our method, we conduct experiments on single-domain, cross-domain and unsupervised FSL with a wide range of benchmark datasets including miniImageNet, tieredImageNet, CIFAR-FS and CUB.",2,positive
"The utility of our method is demonstrated on the state-of-the-art results consistently achieved on several benchmarks includingminiImageNet, tieredImageNet, CIFAR-FS, CUB, Cars, Places and Plantae, in all settings of single-domain, cross-domain and unsupervised FSL.",2,positive
"These categories are further broken into 608 categories, where 351 categories are used for training, 97 for validation and 160 for testing. iii) CIFAR-FS [72] divides CIFAR-100 into 64 meta-train categories, 16 meta-val categories and 20 meta-test categories. iv) CUB [73], a bird dataset with 200 total categories and 6033 total images.",0,negative
"For miniImageNet and CIFAR-FS, the initial learning rate is set as 0.15 and 0.05 for
tieredImageNet.",2,positive
"TABLE 6 Ablation Study of CGR and Hardness-Aware PatchMix on tieredImageNet and CIFAR-FS
Model tieredImageNet CIFAR-FS
1-shot 5-shot 1-shot 5-shot
w/o 72.28 86.24 76.57 88.15 vanilla 72.13 86.71 76.42 88.21 Softmax 72.54 86.78 77.06 87.27 CGR 73.48 87.35 77.87 88.94 vanilla 72.56 86.39 76.97 87.83 w/o H 72.78 86.67 77.02 88.10 local 72.81 86.81 77.30 88.52 global 73.48 87.35 77.87 88.94
Authorized licensed use limited to the terms of the applicable license agreement with IEEE.",0,negative
"iii) CIFAR-FS [72] divides CIFAR-100 into 64 meta-train categories, 16 meta-val categories and 20 meta-test categories.",0,negative
"This result, together with the comparison between baseline and PatchMix on CIFAR-FS in Fig.",2,positive
"(3) Our final choice of gumbel-softmax benefits the model with 0.53% and 0.52% higher accuracies on 1-shot and 5-shot tasks onminiImageNet, and consistent improvement on CIFAR-FS and tieredImageNet.",2,positive
"We adopt three datasets including miniImageNet, tieredImageNet and CIFAR-FS in the single domain setting, where the model is trained on the metatrain set of each dataset and tested on the corresponding meta-test set.",2,positive
"On tieredImageNet and CIFAR-FS the results are nearly consistent with those on miniImageNet (e.g., our model leads by 2.47% and 1.69% in 1-shot and 5-shot on CIFARFS).",2,positive
"To verify the effectiveness of the proposed method, the CIFAR-FS dataset [17] is used to evaluate the performance of the proposed method.",2,positive
"The
vanilla network achieves decent 1-SHOT and 5-SHOT clean accuracies on the CIFAR-FS dataset, however, it’s extremely vulnerable to adversarial perturbations.",2,positive
"Apart from [n/2,2], we took [n-1, 2] as rrange, and performed experiments on the CIFAR-FS dataset with rrange equals to [31,2].",2,positive
"Recently, the few-shot-learning community has shifted its attention to metalearning, which attempts to ‘learn’ the ‘learning-algorithm’ itself over a distribution of tasks, such that it can quickly adapt to novel tasks using finetuning [9, 15, 27, 11].",1,neutral
(in main draft) where the the radius corresponding to highest weight (peak radius rp) is at n/2 (16 in the case of CIFAR-FS dataset).,2,positive
"This is especially important as selecting a fixed radius (for e.g. r = 2) might work well for certain dataset (for instance CIFAR-FS) but can yield suboptimal performance on others
(for e.g. Mini-ImageNet).",1,neutral
We perform experiments on CIFAR-FS dataset and fix the number of classes i.e. k as 5 and query set size as 75 (15 query samples per class).,2,positive
"Specifically, we repeat our experiments using WRN-28-10 (Wide Resnet with width 28 and depth 10) [34] and conv (64)×4 (CNN with 4 layers and 64k channels in the kth layer) [14] on CIFAR-FS [27] for both 1-shot and 5-shot settings and report their results in Table II.",2,positive
"We demonstrate the effectiveness of our technique by performing experiments on two benchmarks datasets in few-shot-learning, specifically, CIFAR-FS [27] and MiniImageNet [14].",2,positive
"On CIFAR-FS dataset, our method yields significant improvement of ≈ 11 − 29% on clean data and ≈ 28−35% on adversarial data for 1-shot while ≈ 8−32% on clean data and ≈ 31− 40% on adversarial data for 5-shot settings), over existing state-of-the-art methods.",0,negative
In Table VII we vary the quantity of the query set from 5 samples per class (i.e. query set size = 25) to 25 samples per class (i.e. query set size = 125) on CIFAR-FS for 5- way 1-shot setting.,2,positive
", t as 98 and 90 for CIFAR-FS and Mini-ImageNet, respectively.",1,neutral
"(3) It can be seen from the second row in Table 5 that on the one hand supervised contrastive loss has little effect on the improvement of classification performance on CIFAR-FS and MiniImageNet datasets, where the reason is that there are 64 categories in both CIFAR-FS and MiniImageNet datasets and the number of positive and negative sample pairs in the training process are not enough, resulting in the molecular terms of supervised contrast loss function almost be zero.",1,neutral
EQ-TARGET;temp:intralink-;e003;116;169 rgminθ;φLbþrðDbaseÞ þ RðθÞ þ RðφÞ; (3),2,positive
"The second few-shot learning dataset was CIFAR-FS [17], containing 60,000 images collected from CIFAR100.",2,positive
"The same formulation applies to optimization-based [10], [36], metricbased [41], and fusion-based [1], [23], [47] algorithms, as shown in Figures 3a, 3b and 3c, respectively.",1,neutral
"output the parameters of a neural network specialized for target tasks [31], [39]; 2) metric-learning for similarity-based learning-to-learn in a highly efficient manner [41]; 3) the highly successful gradient-based ML paradigm [10], [36]; 4) data fusion approaches [1], [23], [37], [47] that “guide” the learning on the query set through the support features; and",1,neutral
"ML: optimization- [10], [25], [33], [36], metric- [13], [41], [49] and fusion-based [1], [23], [37] strategies.",1,neutral
"Following the schema presented in Figure 4c, a whole family of fusion-based meta-learners can be implemented, including methods traditionally proposed for classification, such as MetaOptNet [23] and R2D2 [1].",2,positive
"In this tutorial we introduced a novel taxonomy for categorizing ML algorithms for few-shot image classification [1], [10], [23], [25], [33], [36], [41], [47] and FSWS segmentation [12], [12], [37], [49].",2,positive
"Different from classical constrained optimization, bilevel optimization restricts certain variables to be the minimizer of the lower level function, which is more applicable in modern machine learning problems like meta learning (Snell et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019) and hyperparameter optimization (Pedregosa, 2016; Franceschi et al.",1,neutral
", 2020), meta learning (Snell et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020), hyperparameter optimization (Pedregosa, 2016; Franceschi et al.",1,neutral
"…certain variables
to be the minimizer of the lower level function, which is more applicable in modern machine learning problems like meta learning (Snell et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019) and hyperparameter optimization (Pedregosa, 2016; Franceschi et al., 2018).",1,neutral
"…(Chen et al., 2021) to modern machine learning problems such as reinforcement learning (Hong et al., 2020), meta learning (Snell et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020), hyperparameter optimization (Pedregosa, 2016; Franceschi et al., 2018), etc.…",1,neutral
"…and (3) bi-level optimization where the outer level optimizes the hyperparameters and the inner level optimizes the model parameters given the hyperparameters (Finn et al., 2017; Finn, 2018; Bertinetto et al., 2018; Lee et al., 2019; Zintgraf et al., 2019; Li et al., 2017; Zhou et al., 2018).",1,neutral
", 2017), and (3) bi-level optimization where the outer level optimizes the hyperparameters and the inner level optimizes the model parameters given the hyperparameters (Finn et al., 2017; Finn, 2018; Bertinetto et al., 2018; Lee et al., 2019; Zintgraf et al., 2019; Li et al., 2017; Zhou et al., 2018).",1,neutral
"Few-Shot learning (FSL) Existing FSL approaches can be categorized into metric-learning methods that learn an embedding space to compare query and support samples [24, 34, 45, 54], meta-learning approaches that adapt a base learner to new classes [7, 15, 21, 26, 28, 39, 43], or a combination of both [52].",1,neutral
"We validate our model on 6 benchmark few-shot datasets: CIFAR-FS (Bertinetto et al., 2019), Mini-ImageNet (Russakovsky et al., 2015), Tiered-ImageNet (Russakovsky et al., 2015), Cars, CUB and VGG-Flower, for few-shot classification and 3 additional benchmark standard image classification datasets:…",2,positive
"For meta-training, we use CIFAR-FS (Bertinetto et al., 2019) and Mini-ImageNet (Russakovsky et al., 2015).",2,positive
"ANIL [32], R2D2 [31] and MTL [17] are obtained from the work [27] which implemented open-sourced codes using the original paper settings.",2,positive
"From Table VI, we can observe that FSL methods, including ProtoNet, R2D2, MTL, and Ours, acquire significant performance promotion with larger image size.",2,positive
"In addition, the evaluation results of Versa [30], ANIL [32], R2D2 [31] and MTL [17] are obtained from the work [27] which implemented open-sourced codes using the original paper settings.",0,negative
"In line with recent meta-learning strategies (e.g. Bertinetto et al., 2019; Raghu et al., 2020), we keep ψ fixed during our method’s first stage while only adapting the classifier φ to learn from data streams.",2,positive
[4] noted that updating only the parameters sensitive to specific classes for few-shot classification task leads to a,1,neutral
We sample B base classes from CIFAR-FS to build the base dataset.,2,positive
"Free-lunch did not share the features on tieredImageNet and CIFAR-FS, thus we have taken the pre-trained WRN28+RTloss backbone of Mangla et al. [39] to extract the features, where we use this same backbone to implement Free-lunch with its official code and we have explored and selected an appropriate w for Free-lunch.",2,positive
"Here, the number B of base classes of miniImageNet, CIFAR-FS, CUB, and tieredImageNet is 64, 64, 100, and 351, respectively.",1,neutral
"We design two cross-domain scenarios: miniImageNet → CUB, CIFAR-FS → CUB, where CUB is the target domain while both miniImageNet and CIFAR-FS are the source domains.",2,positive
"10, we consider in-domain setting (CUB, top) and cross-domain setting (CIFAR-FS → CUB, bottom), both of which adopt same 5way1shot novel task from CUB.",1,neutral
"The CIFAR-FS dataset is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100 [38].",2,positive
"B.6 Learned transport plan based on low-level OT
Taking the 5way1shot task on CIFAR-FS as an example, we further explore the per-example weights learned by our low-level OT.",2,positive
"Datasets We evaluate our proposed method on several standard few-shot classification datasets with different levels of granularity, including miniImageNet [33], tieredImageNet [34], CUB [35], and CIFAR-FS [36].",2,positive
"Here, miniImageNet, tieredImageNet, and CIFAR-FS have a broad range of classes including various animals and objects while CUB is a more fine-grained dataset that includes various species of birds.",2,positive
"Moreover, H-OT under the CIFAR-FS→ CUB (blue bar in the 3rd column) scenario still outperforms Free-Lunch under CUB (orange bar in the 1st column).",1,neutral
"B.1 Summary of the test results
To explore how our proposed model improves its baseline (Free-Lunch), we perform the experiments on 10,000 tasks from CIFAR-FS dataset using these two distribution calibration models, where the statistics about the classification results are shown in Fig.",2,positive
"We now conduct experiments on the most common setting in few-shot classification, 1-shot and 5-shot classification, where the results of different models on miniImageNet, tieredImagenet, CUB and CIFAR-FS are shown in Tables 1 and 2.",2,positive
"We use the same hyperparameter value for all datasets except for λ. Specifically, the number of generated features is 750, the in Sinkhorn algorithm is 0.01, the α in (10) is 0.21; and λ is 0.5, 1, 1 and 0.8 for miniImageNet, tieredImageNet, CUB, and CIFAR-FS, respectively, selected by a grid search using the validation set.",2,positive
"8, we visualize the adaptive cost learned from low-level OT and the transport plan learned from the high-level OT given the adaptive cost on CIFAR-FS for 5way1shot task.",2,positive
"2, we now compare the performance of the hybrid fine-tuning strategy (HFT-Last1/HFT-All) with that of the traditional finetuning strategy (FT-Last1/FT-All) under different pretraining methods including RFS-simple [29], SKD-GEN0 [41], and R2D2 [42].",2,positive
"Based on the hands-on hybrid fine-tuning strategy obtained in Section 4.2, we now compare the performance of the hybrid fine-tuning strategy (HFT-Last1/HFT-All) with that of the traditional finetuning strategy (FT-Last1/FT-All) under different pretraining methods including RFS-simple [29], SKD-GEN0 [41], and R2D2 [42].",2,positive
"Few-shot learning is cast to optimization-based (Antoniou et al., 2018, Bertinetto et al., 2019, Finn et al., 2017, Flennerhag et al., 2020, Lee and Choi, 2018, Nichol et al., 2018, Park and Oliva, 2019, Ravi and Larochelle, 2017, Rusu et al., 2019) or metric-based (Koch et al., 2015, Oreshkin et…",1,neutral
"…in machine learning such as hyper-parameter optimization (Franceschi et al., 2018; Lorraine & Duvenaud, 2018; Okuno et al., 2021), meta learning (Bertinetto et al., 2018; Rajeswaran et al., 2019; Soh et al., 2020) and reinforcement learning (Yang et al., 2018; Tschiatschek et al., 2019).",1,neutral
"…bilevel optimization is a widely confronted problem in machine learning with various applications such as meta-learning (Finn et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019), hyper-parameter optimization (Franceschi et al., 2018; Shaban et al., 2019; Baydin et al., 2017;…",1,neutral
"CIFAR-FS is a variant of CIFAR-100 [13] with low resolution, which has 100 classes and each of them has 600 samples of 32 × 32 size.",2,positive
"We conduct experiments on four widely-used few-shot learning benchmark datasets for general object recognition and fine-grained classification, including miniImageNet [25], tieredImageNet [26], CIFAR-FS [2] and CUB [34].",2,positive
"• We conduct comprehensive experiments on four few-shot benchmark datasets, i.e., miniImageNet, tieredImageNet, CIFAR-FS and CUB, for demonstrating our superiority over state-of-the-art FSL and SSFSL methods.",2,positive
"RR (Bertinetto et al., 2019) adopts ridge regression (RR) for classification.",1,neutral
"To solve the problem of lack of large-scale labeled data, many researchers have proposed effective few-shot learning methods, including optimization-based [9-11], meta-learning-based [12-15], and metric-based learning [16-21] methods.",1,neutral
"[28] Luca Bertinetto, João F Henriques, Philip HS Torr, and Andrea Vedaldi.",0,negative
"However, works that integrate algorithmic inductive biases—for example by exploiting gradient descent [24, 25], metric learning [26, 27], convex optimization [28, 29], exact or approximate Bayesian inference [30– 32], changepoint detection [33, 34], and other algorithmic primitives—have been highly successful when applied to few-shot learning.",1,neutral
The second design is a ridge-regression predictor with differentiable closed-form solvers [6].,1,neutral
"To avoid expensive training from scratch or fine-tuning over the support set per task, we employ ridge regression that admits a closed form solution [6] that can be computed directly in the inner loop of meta-learning.",1,neutral
"In Table 6 below we report the accuracy of our proposed method on all benchmarks, note that for FC100 and CIFAR-FS we believe to be among the first to conduct experiments in the unbalanced setting.",2,positive
"In Appendix we also show the performance of our proposed method on other benchmarks such as FC100 (Oreshkin et al., 2018) and CIFAR-FS (Bertinetto et al., 2019).",2,positive
"In this section we further conduct experiments on two other well-known Few-Shot datasets: 1) FC100 (https://github.com/ElementAI/TADAM) is a recent split dataset based on CIFAR-100 (Krizhevsky et al., 2009) that contains 60 base classes for training, 20 classes for validation and 20 novel classes for evaluation, each class is composed of 600 images of size 32x32 pixels; 2) CIFAR-FS (https://github.com/bertinetto/r2d2) is also sampled from CIFAR-100 and shares the same quantity of classes in the base-validation-novel splits as for mini-Imagenet.",2,positive
"For tiered-Imagenet we set Tkm, Tvb and smax to be 10, 100, 2 in the balanced setting, 100, 100, 1 in the unbalanced setting; for CUB we set them to be 10, 5, 5 in both balanced and unbalanced settings; and for FC100 and CIFAR-FS we set the hyperparameters to be the same as mini-Imagenet.",2,positive
In Appendix we also show the performance of our proposed method on other well-known Few-Shot benchmarks such as FC100 [30] and CIFAR-FS [4].,2,positive
The CIFAR-FS dataset [2] contains 100 classes with 600 images per class.,2,positive
"Thus, ""DS+R2D2"" performs better on Huffpost than ""BERT+R2D2"", but worse on Banking77 and Clinc150.",2,positive
"The base learner used by Ridge Regression Differentiable Discriminator (R2D2) (Bertinetto et al., 2019) is ridge regression based on linear regression model.",1,neutral
"For the sake of fairness, the classifiers of these two algorithms use R2D2, so we constructed a comparison item with BERT as encoder.",1,neutral
"For the CIFAR-FS dataset, our method outperforms the sub-optimal method by 0.4% on 1-shot and 0.5% on 5- shot.",2,positive
Our method also consistently outperforms the other state-of-the-arts methods under both 1-shot and 5-shot settings on the CIFAR-FS and FC100 datasets.,2,positive
"To evaluate the effectiveness of the ICRL-Net, we conducted extensive experiments on four publicly available and widely used few-shot visual recognition benchmarks, i.e., miniImageNet, tieredImageNet, CIFAR-FS, and FC100 datasets.",2,positive
"We conducted extensive experiments on four popular fewshot benchmarks: miniImageNet [21], tieredImageNet [31], CIFAR-FS [32], and FC100 [33] datasets.",2,positive
2) Performance on CIFAR-FS and FC100: Experimental results on CIFAR-FS and FC100 are shown in Table II.,0,negative
"We conduct extensive experiments on four commonly adopted few-shot benchmarks: miniImageNet, tieredImageNet, CIFAR-FS, and FC100 datasets.",2,positive
"Similar to the CIFAR-FS dataset,
every class has 600 images of size 32 × 32.",2,positive
"3) CIFAR-FS: The CIFAR-FS dataset [32] is a recently proposed few-shot visual recognition benchmark, consisting of all 100 classes from CIFAR-100 [71].",2,positive
"Two common datasets are used: the CIFAR-FS (Bertinetto et al., 2019) and Mini-ImageNet (Vinyals et al.",2,positive
"Notes: This table shows the performance of three state-of-the-art few-shot classifiers applied to the CIFAR-FS (Bertinetto et al., 2019) and Mini-ImageNet (Vinyals et al.",0,negative
"Two common datasets are used: the CIFAR-FS (Bertinetto et al., 2019) and Mini-ImageNet (Vinyals et al., 2016).",2,positive
"To simulate realistic evolving semi-supervised task distributions, we construct a new large-scale dataset and collect 6 datasets, including CIFARFS [12], AIRCRAFT [38], CUB [67], Miniimagenet [56], Butterfly [16] and Plantae [28].",2,positive
"To simulate the task distribution shift in SETS, we construct a dataset by composing 6 datasets, including CIFARFS [12], AIRCRAFT [38], CUB [67], Miniimagenet [56], Butterfly [16] and Plantae [28].",2,positive
"To investigate the sensitivity of baselines and our method to dataset order, we also performed comparisons on two other dataset sequences, including (i) Butterfly, CUB, CIFARFS, Plantae, MiniImagenet, Aircraft and (ii) CUB, CIFARFS, Plantae, MiniImagenet, Butterfly, Aircraft.",2,positive
"Category shift exists in datasets while the categories are disjoint between training and testing sets, such as miniImagenet (Vinyals et al. 2016) and CIFAR-FS (Bertinetto et al. 2018).",2,positive
"We evaluate our proposed method on four standard benchmarks: miniImagenet (Vinyals et al. 2016), Tiered-ImageNet (Ren et al. 2018), CIFAR-FS (Bertinetto et al. 2018), and CUB-200-2011 (Wah et al. 2011). miniImagenet contains 100 randomly chosen classes from
Algorithm 2: Evaluate the CSCA module…",2,positive
"2018), CIFAR-FS (Bertinetto et al. 2018), and CUB-200-2011 (Wah et al.",2,positive
"Typical self-supervised methods design pretext tasks to provide automated supervision, where both the inputs and labels are derived from an unlabeled dataset [29, 30, 31].",1,neutral
", the finetuning function) can be solved by a few gradient steps, the firstorder Taylor expansion, or other closed-form approximation [3].",1,neutral
"We compared the results against those of various networks for few-shot recognition, including ProtoNet [42], R2D2 [45], and BaseLine [46].",2,positive
"Performance Comparison of Different FSL Networks
To validate the effectiveness of RelationNet, the four experimental validation results of ProtoNet, R2D2, BaseLine, and RelationNet were compared.",2,positive
"scale to large datasets, the efficient gradient descent methods provide a promising solution to the complicated bi-level optimization problem and thus are widely adopted in many deep learning research work to optimize hyperparameters in the single-task formulation [Bertinetto et al. 2019; Y. Chen et al. 2019; Hu et al. 2019; H. Liu et al. 2019; Ma et al. 2020; Rendle 2012] or extract meta knowledge in the multi-task formulation [Andrychowicz et al.",1,neutral
[Bertinetto et al. 2019] propose ridge regression as part of its internal model for closed-form solutions.,1,neutral
"…optimization problem and thus are widely adopted in much deep learning research work to optimize hyperparameters in the single-task formulation (Bertinetto et al., 2019; Hu et al., 2019; Liu et al., 2019; Rendle, 2012; Chen et al., 2019; Ma et al., 2020; Zhang et al., 2023; Li et al., 2022) or…",1,neutral
Bertinetto et al. (2019) propose ridge regression as part of its internal model for closed-form solutions.,1,neutral
"The second is the optimized-based approach [24,6,44,30,43,2,31,68], which rapidly updates models through meta-learning the optimization procedures from a few samples.",1,neutral
"B.2 Details of Datasets
We evaluated our method on five benchmark datasets to demonstrate its robustness: miniImagenet[35], tieredImagenet[26], CIFAR-FS[2], FC100[22], and CUB[36].",2,positive
"Existing research work [11, 34, 24, 2] has empirically shown that debiasing the model by input data or learned representation can significantly improve the action recognition performance.",1,neutral
"For example, 0.43% vs 0.98%, 0.71% vs 1.9% on CUB-200-2001 and 1.72% vs 2.40% on CIFAR-FS.",0,negative
"For DeepEMD, we do more experiments on CIFAR-FS[2], FC100[22] and CUB[36].",2,positive
"We evaluated our method on five benchmark datasets to demonstrate its robustness: miniImagenet[35], tieredImagenet[26], CIFAR-FS[2], FC100[22], and CUB[36].",2,positive
"We report the accuracy and ECE on CIFAR-FS, FC100 and CUB-200-2011.",2,positive
Dataset derived from CIFAR100[15]: CIFAR-FS[2] contains 100 classes.,2,positive
"Table 5: Few-shot classification accuracy and 95% confidence interval on CIFAR-FS, FC100 and CUB-200-2011 datasets.",0,negative
"Algorithm Backbone CIFAR-FS,5-way FC100,5-way CUB-200-2011,5-way1-shot 5-shot 1-shot 5-shot 1-shot 5-shot Rethink-Distill[34] ResNet-12 73.90±0.80 86.90±0.50 44.6±0.7 60.9±0.6 – –
BML[44] ResNet-12 73.04±0.47 88.04±0.33 45.00±0.41 63.03±0.41 76.21±0.63 90.45±0.36 DeepEMD[42] ResNet-12 73.80±0.29 86.76±0.62 45.17±0.26 60.91±0.75 75.81±0.29 88.35±0.55 DeepEMD+BEL(ours) ResNet-12 73.96±0.29 86.92±0.62 45.10±0.26 61.07±0.74 75.75±0.29 88.56±0.54
Table 6: Few-shot classification expected calibration error(ECE)%↓ on CIFAR-FS, FC100 and CUB-200-2011 datasets.",0,negative
"Ridge Regression Meta-Learner (Bertinetto et al., 2018) (RRML) develops the closed-form solution based on ridge regression to acquire the class vector.",2,positive
"The combinations with PN and RRML, respectively, improve the performance of its original counterpart.",2,positive
"We incorporate them into the RRML (Bertinetto et al., 2018) to build a more effective metalearning system.",2,positive
"Notably, the method obtains better generalization ability in various meta-learning frameworks, and DS+RRML achieves the best performance in (Bao et al., 2019).",2,positive
"They can be roughly categorized into two groups: (1) Optimization-based methods advocate learning a suitable initialization of model parameters from base classes and transferring these parameters to novel classes in a few gradient steps [33,48,3,10,29].",1,neutral
The train/val/test classes are same to miniImageNet [3].,0,negative
"As mentioned in (Bertinetto et al., 2019), the Woodbury formulation,
W ∗ = ZT (ZZT + λI)−1Y
is used to alleviate the problem, leading to an O(d3) complexity, where d is the hidden size hyperparameter, fixed to some value (see Appendix H).",1,neutral
"This transforms the inner loop optimization problem into a simple ridge regression problem for the case of mean squared error loss, having a simple analytic solution to replace the otherwise complicated nonlinear optimization problem (Bertinetto et al., 2019).",1,neutral
"As mentioned in (Bertinetto et al., 2019), the Woodbury formulation, W ∗ = Z (ZZ + λI)−1Y is used to alleviate the problem, leading to an O(d(3)) complexity, where d is the hidden size hyperparameter, fixed to some value (see Appendix H).",1,neutral
"We also specify an efficient instantiation of the meta-optimization procedure via a closed-form ridge regressor (Bertinetto et al., 2019).",1,neutral
"Bilevel optimization has proven to be a major tool for solving machine learning problems that possess a nested structure such as hyper-parameter optimization [17], meta-learning [6], reinforcement learning [23, 33], or dictionary learning [38].",1,neutral
"[6] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi.",0,negative
"[10] Luca Bertinetto, Joao F Henriques, Philip Torr, and Andrea Vedaldi.",0,negative
"1 Introduction Bilevel optimization is rapidly evolving due to its wide array of applications in modern machine learning (ML) problems including meta-learning [25, 10], hyperparameter optimization [28, 24], neural network architecture search [56, 8], and reinforcement learning [45, 81].",1,neutral
• R2D25 [3]: an efficient meta-learning model with closedform solvers based on ridge regression.,1,neutral
"a few labeled samples [2, 3, 12, 13], we employ episodic training to",1,neutral
"ridge regression and support vector machine, were successfully integrated into CNNs [55], [56] and have shown great potential in solving the challenging few-shot learning problem.",1,neutral
"The CIFAR-FS dataset (Bertinetto et al., 2019) and the FC100 dataset (Oreshkin et al., 2018) are generated from the CIFAR100 dataset based on different selection criteria.",2,positive
"The CIFAR-FS dataset (Bertinetto et al., 2019) and the FC100 dataset (Oreshkin et al.",2,positive
"CIFAR-FS includes 100 classes that are divided into 64 base, 16 validation, and 20 novel classes.",2,positive
"For our proposed CAMtrast, we train 30 epochs (t = 30) for warmup on miniImageNet and CIFAR-FS, and 50 epochs (t = 50) on tieredImageNet.",2,positive
"For the latter, the tieredImageNet and CIFAR-FS (Bertinetto et al. 2018) are used.",2,positive
"Cross-domain few-shot recognition: To further evaluate the transfer performance in a more realistic scenario, we also conduct few-shot experiments with domain shifts between tieredImageNet and CIFAR-FS.",2,positive
"The models are pretrained on either tieredImageNet’s or CIFAR-FS’s base classes and
evaluated on the other’s novel classes.",2,positive
"[5]) and K-Nearest Neighbor (KNN, K-Nearest Neighbor) to conduct our comparison experiments.",1,neutral
"It has been found to provide favorable solutions in a variety of problems, such as meta learning and hyperparameter optimization (Franceschi et al., 2018; Snell et al., 2017; Bertinetto et al., 2018), composition optimization (Wang and Liu, 2016b), two-player games (Von Stackelberg and Von, 1952), reinforcement learning and imitation learning (Arora et al.",1,neutral
", 2020; Tu, 2021), and more recently in machine learning problems (Franceschi et al., 2018; Snell et al., 2017; Bertinetto et al., 2018; Wang and Liu, 2016b).",1,neutral
"We exploit CaSE as building block of a hybrid training protocol called UpperCaSE which is based on the idea of adjusting the body of the network in a single forward pass over the context, and reserving the use of expensive fine-tuning routines for the linear head, similarly to methods like MetaOptNet (Lee et al., 2019), R2D2 (Bertinetto et al., 2018), and ANIL (Raghu et al., 2019).",2,positive
"Another possible solution is the use of an alternating-optimization scheme, similar to the one proposed in a number of recent methods such as MetaOptNet (Lee et al., 2019), R2D2 (Bertinetto et al., 2018), and ANIL (Raghu et al., 2019).",2,positive
", 2019), R2D2 (Bertinetto et al., 2018), and ANIL (Raghu et al.",1,neutral
"…is based on the idea of adjusting the body of the network in a single forward pass over the context, and reserving the use of expensive fine-tuning routines for the linear head, similarly to methods like MetaOptNet (Lee et al., 2019), R2D2 (Bertinetto et al., 2018), and ANIL (Raghu et al., 2019).",2,positive
"The closed form inner optimization for meta-learning has been successfully used in various methods [3, 14, 37, 11, 12].",1,neutral
"MetaOptNet [14] and [28,3] reset the inner optimization by dividing the model into feature extractor and head classifier and apply on complex base learner like ResNet-12 without overfitting.",2,positive
"Copyright 2023 by the author(s).
of problems has attracted great attention due to their applications in hyper-parameter optimization (Franceschi et al., 2018; Shaban et al., 2019), meta-learning (Rajeswaran et al., 2019; Bertinetto et al., 2019), and reinforcement learning (Hong et al., 2020).",2,positive
"Conventional benchmarks of FSL only consider category shift, i.e. the categories are disjoint for training and testing, such as miniImageNet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019).",2,positive
CIFAR-FS.,2,positive
"The CIFAR-FS dataset (Bertinetto et al., 2019) contains essentially the data from the CIFAR100 (Krizhevsky et al., 2009) dataset and splits the 100 categories of 600 images each into 64 training, 16 validation and 20 test classes.",2,positive
"The CIFAR-FS dataset (Bertinetto et al., 2019) contains essentially the data from the CIFAR100 (Krizhevsky et al.",2,positive
", 2018), CIFAR-FS (Bertinetto et al., 2019) and FC100 (Oreshkin et al.",2,positive
"Evaluations are conducted on all five popular FSL datasets: CUB-200-2011 (Wah et al., 2011), miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFAR-FS (Bertinetto et al., 2019) and FC100 (Oreshkin et al., 2018).",2,positive
"Reported are the mean and 95% confidence interval on the unseen test sets of CIFAR-FS [4] and FC-100 [33], using the established evaluation protocols.",0,negative
"We evaluate our method FewTURE using two different Transformer backbones and compare our results against the current state of the art in Table 1 for the miniImageNet and tieredImageNet, and in Table 2 for the CIFAR-FS and FC100 datasets.",2,positive
CIFAR-FS.,2,positive
"The CIFAR-FS dataset [1] contains the 100 categories with 600 images per category from the CIFAR100 [8] dataset which are split into 64 training, 16 validation and 20 test classes.",0,negative
"We train and evaluate our methods using four popular few-shot classification benchmarks, namely miniImageNet [48], tieredImageNet [37], CIFAR-FS [4] and FC-100 [34].",2,positive
"We train and evaluate our methods using four popular few-shot classification benchmarks, namely miniImageNet [48], tieredImageNet [36], CIFAR-FS [4] and FC-100 [33].",2,positive
"These include meta-learning (Franceschi et al., 2018; Bertinetto et al., 2019), hyperparameter optimisation (Feurer & Hutter, 2019; Shaban et al.",1,neutral
"These include meta-learning (Franceschi et al., 2018; Bertinetto et al., 2019), hyperparameter optimisation (Feurer & Hutter, 2019; Shaban et al., 2019), and reinforcement learning (Konda & Tsitsiklis, 2003; Khodadadian et al., 2021).",1,neutral
"1 Introduction Bilevel optimization provides a framework for solving problems arising from meta learning [33, 2, 29], hyperparameter optimization [26, 8], reinforcement learning[12], etc.",1,neutral
"[2] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi.",0,negative
"It aims at minimizing an objective in the upper level under a constraint given by another optimization problem in the lower level, and has been studied intensively in recent years [8, 2, 9, 13, 12, 5].",1,neutral
"Due to its great success in solving problems in meta learning [33, 2, 29] and hyperparameter optimization [26, 8], there is a flurry of work proposing and analyzing bilevel optimization algorithms.",1,neutral
"This case study demonstrates the capability of our tool in boosting performance on a natural image dataset, CIFAR-FS [53].",2,positive
"CIFAR-FS has 12,000 images of 20 unseen classes.",2,positive
"We evaluated the learner and shot selection algorithms with four widely used datasets: mini-ImageNet [50], tieredImageNet [51], MNIST [52], and CIFAR-FS [53].",2,positive
"To demonstrate the generalization of our approach to new tasks, we used the MNIST and CIFAR-FS datasets because there are no base learners pre-trained on them.",2,positive
"For MNIST and CIFAR-FS, we used all the unseen classes (10 and 20, respectively) in the tasks.",1,neutral
", 2018), GNN (Garcia & Bruna, 2017), R2-D2 (Bertinetto et al., 2018), CC+rot (Gidaris et al.",1,neutral
"Regarding baselines, we use the MAML (Finn et al., 2017), Matching Nets (Vinyals et al., 2016), Meta-SGD (Li et al., 2017), MAML++ (Antoniou et al., 2019), Meta-Curvature (MC) (Park & Oliva, 2019), Meta Networks (Munkhdalai & Yu, 2017), Neural Statistician (Edwards & Storkey, 2017), and Memory Mod (Kaiser et al., 2017), Relation Network (Sung et al., 2018), GNN (Garcia & Bruna, 2017), R2-D2 (Bertinetto et al., 2018), CC+rot (Gidaris et al., 2019).",2,positive
"…Meta-Curvature (MC) (Park & Oliva, 2019), Meta Networks (Munkhdalai & Yu, 2017), Neural Statistician (Edwards & Storkey, 2017), and Memory Mod (Kaiser et al., 2017), Relation Network (Sung et al., 2018), GNN (Garcia & Bruna, 2017), R2-D2 (Bertinetto et al., 2018), CC+rot (Gidaris et al., 2019).",1,neutral
"Many prior works have proposed different solutions for the aforementioned meta-overfitting problem, such as using dropout (Bertinetto et al., 2018; Lee et al., 2020), and modifying the loss function (Jamal & Qi, 2019) etc.",1,neutral
"(Bertinetto et al., 2018) find that regularization such as dropout can alleviate meta-overfitting and (Yin et al.",1,neutral
"(Bertinetto et al., 2018) find that regularization such as dropout can alleviate meta-overfitting and (Yin et al., 2019) propose metaregularization on weights; (Rajendran et al., 2020) introduce an information-theoretic framework of meta-augmentation to make meta-learner generalize to new tasks;…",1,neutral
"The results of CIFAR-FS with new baseline ECM (Ravichandran et al., 2019) and PROTO Nets (Snell et al., 2017) are shown in Table 2.",2,positive
"Many prior works have proposed different solutions for the aforementioned meta-overfitting problem (Zintgraf et al., 2019), such as using dropout (Bertinetto et al., 2018; Lee et al., 2020), and modifying the loss function (Jamal & Qi, 2019) etc.",1,neutral
"We verify the effectiveness of Eigen-Reptile alleviate overfitting sampling noise on two clean few-shot classification datasets Mini-Imagenet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2018).",2,positive
"Similarly, for CIFAR-fs, more than 5× reduction in FLOPs is achieved while improving the accuracy by more than 2%.",1,neutral
"The efficacy of our method is validated on CIFAR-fs [1] and mini-ImageNet [28] datasets, and we have observed that our approach can provide improvements in model accuracy of up to 2% on standard meta-learning benchmark, while reducing the model size by more than 75%.",2,positive
"This translates to 15504 test tasks for both CIFAR-fs and mini-ImageNet (C = 20, N = 5).",2,positive
"Learning task-specific compressed metamodels
We discuss here the results of task-specific pruning obtained using METADOCK on standard 4-Conv models with 64 and 128 channels for CIFAR-fs 5-way 1-shot and 5-way 5-shot settings.",2,positive
"The former attains an average meta-test accuracy score of 70.15% on CIFARfs 5-way 1-shot (Table 3), while the latter scores 67.25%, thus increasing the performance by an absolute margin of 2.9%.",0,negative
We study the performance of METADOCK on standard 4-conv models trained on mini-ImageNet [28] and CIFARfs [1] datasets for several different choices of pruning budget.,2,positive
"Figure 4 shows parameters vs. accuracy plot for CIFAR-fs and mini-ImageNet datasets on 5-way, 5-shot setting with 4-Conv-128 model.",0,negative
"The results for continuous scheme as well as our approach on CIFAR-fs, 5-way, 5-shot are shown in Table 1.",2,positive
"After a threshold parameter count, performance starts to drop for both CIFAR-fs and mini-ImageNet but the extent of compression achieved before that point is already significant.",2,positive
"Similarly, Figure 5 shows FLOPs vs. accuracy plot for CIFAR-fs and mini-ImageNet dataset on 5-way, 5-shot setting with 4-Conv-128 model.",0,negative
"Similar to CIFAR-fs, performance gains of up to 2% in accuracy are observed for this dataset as well.",2,positive
"Furthermore, our method also outperforms all previous works by at least 8.6% on PGD adversarial examples for 1-shot classification on CIFAR-FS with ResNet12.",0,negative
We present our experimental results on two standard benchmarks: miniImageNet [30] in Table 1 and CIFARFS [1] in Table 2.,2,positive
"To fully evaluate the effectiveness of our methods, we conduct extensive experiments on two standard few-shot classification benchmarks: miniImageNet [30] and CIFARFS [1].",2,positive
The cross-domain transfer experiment is implemented between miniImageNet [30] and CIFAR-FS [1] bilaterally as shown as Table 5.,2,positive
"CIFAR-FS [1] has the same dataset splitting of 64, 16, 20 classes for training, validation and testing respectively.",2,positive
"To comprehensively evaluate our methods, we adopt the widely-used few-shot benchmark datasets miniImageNet [30] and CIFAR-FS [1].",2,positive
"regression [3,38] is used as a classifier and trained on the support set, and the regularized squared loss is minimized by Equation (12):",1,neutral
"We construct a large-scale benchmark and collect 10 datasets with varying degree of similarity and difficulty, with default domain arrival order of Quickdraw [31], AIRCRAFT [45], CUB [77], Miniimagenet [70], Omniglot [35], Plantae [28], Electronic from Logo-2K+ [73], CIFARFS [10], Fungi [62], Necessities from Logo-2K+ [73].",2,positive
"We use the following small-scale datasets for meta-learning with MLPs: Omniglot [26, 52], CIFARFS [7], VGG-Flower [37, 27] and Aircraft [33, 27].",2,positive
"Some works focused on the role of label122 and attribute semantics as additional information to facilitate few-shot learning [10, 60, 80].123
All the above discussed few-shot methods focused on the standard setting where the base classes124 and novel classes are from the same domain, and are evaluated on natural images using the current125 standard benchmarks for few-shot classification: Omniglot [36], CUB [75], miniImageNet [74],126 tieredImageNet [55] and CIFAR-FS [3].",1,neutral
"All the above discussed few-shot methods focused on the standard setting where the base classes and novel classes are from the same domain, and are evaluated on natural images using the current standard benchmarks for few-shot classification: Omniglot [40], CUB [79], miniImageNet [78], tieredImageNet [59] and CIFAR-FS [5].",2,positive
"Bilevel optimization has attracted significant attention recently due to its popularity in a variety of machine learning applications including meta-learning [9, 1, 34, 17], hyperparameter optimization [9, 35, 5], reinforcement learning [22, 15], and signal processing [23, 7].",1,neutral
"Four benchmark datasets are used to evaluate the model performance (miniImageNet [4], CUB-200-2011 [17], tieredImageNet [18] and CIFAR-FS [19]).",2,positive
"Benchmarks The most simple few-shot classification benchmarks are built respectively on the basic image recognition dataset CIFAR100 [3] and Omniglot [14], which is a dataset of handwritten characters.",2,positive
"…can be the weights of a neural network that acts as a feature extractor that will help a task-specific classifier or regressor parameterized by the base parameters to solve the task at hand (Raghu, Raghu, Bengio, & Vinyals, 2020; Lee, Maji, Ravichandran, & Soatto, 2019; Bertinetto et al., 2019).",1,neutral
"task-shared outer parameters can be the weights of a neural network that acts as a feature extractor that will help a task-specific classifier or regressor parameterized by the base parameters to solve the task at hand (Raghu, Raghu, Bengio, & Vinyals, 2020; Lee, Maji, Ravichandran, & Soatto, 2019; Bertinetto et al., 2019).",1,neutral
"Instead, many machine learning tasks – such as adversarial learning, meta learning (Franceschi et al., 2018; Bertinetto et al., 2018), hyperparameter optimization (Franceschi et al., 2018; Feurer & Hutter, 2019), reinforcement/imitation learning (Arora et al., 2020; Hong et al., 2020), and neural…",1,neutral
"Instead, many machine learning tasks – such as adversarial learning, meta learning (Franceschi et al., 2018; Bertinetto et al., 2018), hyperparameter optimization (Franceschi et al.",1,neutral
"In this paper, we take inspiration from the in-context [11] few-shot learning technique instead of more involved few-shot learning approaches based on metric learning [24, 103, 112, 117] or meta-learning [6, 7, 27, 31, 91, 155].",2,positive
"We examined the 5-way (5 classes) 1-shot task of CIFAR-FS, which is a kind of standard task in one-shot classification.",2,positive
"Also, for transfer learning, we used CIFAR-FS (Bertinetto et al. 2018) with Torchmeta (Deleu et al.",2,positive
"Also, for transfer learning, we used CIFAR-FS (Bertinetto et al. 2018) with Torchmeta (Deleu et al. 2019).",2,positive
"We conduct few-shot classification experiments on four widely used few-shot image recognition benchmarks: miniImageNet [53], tieredImageNet [54], CIFAR-FS [37], and FC100 [24].",2,positive
"For example, MAML-type algorithms assume φτ is one or a few gradient steps away from θ [5], [16]–[18], while other meta-learning approaches assume that φτ and θ share the parameters in the feature extractor and only differ in the top layer [6], [37], [38].",1,neutral
"Meanwhile, R2-D2 [37] and MetaOptNet [38] reduce the dimensionality of trainable model parameters by freezing feature extraction layers during inner loop optimization.",2,positive
Note that the proposed method is fundamentally different from R2-D2 and MetaOptNet because our method requires neither episodic meta-learning nor bi-level optimization.,2,positive
"We first evaluate the impact of pre-training regime (including algorithm and dataset), as well as neural architecture on FSL benchmarks Meta-Dataset [61] (train on 8 datasets), miniImageNet [62], and CIFAR-FS [8].",2,positive
"CIFAR-FS [8] is created by dividing the original CIFAR-100 into 64 training, 16 validation and 20 testing classes.",2,positive
"For miniImageNet and CIFAR-FS, the convention is to evaluate 5-way-1-shot (5w1s) and 5-way-5-shot episodes, and the size of the query set for each episode is fixed to 15× 5.",2,positive
"The results for single-domain miniImageNet and CIFAR-FS are summarized in Table 4,
while the results for cross-domain datasets Meta-Dataset and Broader Study CDFSL are shown in Table 5 and 6 respectively.",0,negative
"7.3.2 Meta-Ridge Regression (MRR) Our next baseline comes from the meta-learning work reviewed in Section 2.3 by Harrison et al. (2018b,a), Bertinetto et al. (2019), Lee et al. (2019), and O’Connell et al. (2021), wherein ridge regression is used as a base-learner to meta-learn parametric features…",2,positive
Boffi et al. (2020) discuss the case where V̄ is a Lyapunov function in the sense of Lyapunov’s direct method (Lyapunov 1892) with x∗(t) ≡ 0.,1,neutral
"(2018b,a), Bertinetto et al. (2019), Lee et al. (2019), and O’Connell et al. (2021), wherein ridge regression is used as a base-learner to meta-learn parametric features y(x;φ). That is, for a given trajectory Tj , these works assume the last layer Â should be the best fit in a regression sense, as a function of the parametric features y(x;φ), to some subset of points in Tj . The feature parameters φ are then trained to minimize this regression fit. This approach, which we term Meta-Ridge Regression (MRR), contrasts with our thesis that φ should be trained for the endmost purpose of improving control performance, rather than regression performance. We now specify how to implement MRR using the meta-learning language from Section 4. Our implementation is a generalization* of the approach taken by O’Connell et al. (2021) to any nonlinear control-affine dynamical system (17), which can be slightly extended using (19) to include all fully-actuated Lagrangian systems.",2,positive
"(2018b,a), Bertinetto et al. (2019), Lee et al. (2019), and O’Connell et al. (2021), wherein ridge regression is used as a base-learner to meta-learn parametric features y(x;φ).",1,neutral
"Bertinetto et al. (2019) and Lee et al. (2019) back-propagate through closed-form ridge regression solutions for few-shot learning, with a maximum likelihood meta-objective.",1,neutral
Bertinetto et al. (2019) and Lee et al. (2019) instead study when the base-learner can be expressed as a convex program with a differentiable closedform solution.,1,neutral
Bertinetto et al. (2019) and Lee et al. (2019) instead study when the base-learner can be expressed as a convex program with a differentiable closed-form solution.,1,neutral
"[8] and MetaOptNet [23] presented closed form solutions and differentiable solvers for task-dependent Ridge Regression, Logistic Regression (LR), and Support Vector Machines (SVMs).",1,neutral
", 2018), R2-D2 (Bertinetto et al., 2019), and BOIL (Oh et al.",1,neutral
"…of IBP with other few-shot learners: As contending meta-learning algorithms, we choose the vanilla MAML along with notable meta-learners such as Meta-SGD (Li et al., 2017), Reptile (Nichol et al., 2018), LLAMA (Grant et al., 2018), R2-D2 (Bertinetto et al., 2019), and BOIL (Oh et al., 2021).",2,positive
"Comparison of IBP with other few-shot learners: As contending meta-learning algorithms, we choose the vanilla MAML along with notable meta-learners such as Meta-SGD (Li et al., 2017), Reptile (Nichol et al., 2018), LLAMA (Grant et al., 2018), R2-D2 (Bertinetto et al., 2019), and BOIL (Oh et al., 2021).",2,positive
For the experiments we have used the novel CIFARFS [8] dataset.,2,positive
"In [8] it has been suggested to split 100 classes into train, validation and test sets.",0,negative
Accuracies and timings for our MAML implementation on CIFAR-FS are presented in Table 1.,2,positive
The testing results will be shown on a publicly available few-shot learning dataset CIFAR-FS [8].,0,negative
The exact classes that go into each split are important and are defined in [8].,1,neutral
"Instead, we consistently use meta-batch size of 4 as it leads to slightly better performance on CIFAR-FS [8] dataset during our experiments.",2,positive
We have taken the CIFAR-FS dataset for our experiments as it hasn’t been analyzed by the MAML authors and is also faster to compute than miniImageNet.,2,positive
"…with hallucinating more samples(Hariharan and Girshick 2017; Wang et al. 2018), optimization with ridge regression or support vector machine (Bertinetto et al. 2018; Lee et al. 2019), using graph neural networks (Garcia and Bruna 2017; Kim et al. 2019), self/semi-supervised learning (Ren et…",1,neutral
"2018), optimization with ridge regression or support vector machine (Bertinetto et al. 2018; Lee et al. 2019), using graph neural networks (Garcia and Bruna 2017; Kim et al.",1,neutral
"For MiniImagenet (Table 1) we report on both versions “SOTp” and “SOTt” over a range of backbone architectures, while for the smaller datasets CIFAR-FS and CUB (Table 2) we focus on the ‘drop-in’ version “SOTp” and only the strongest wrn-28-10 architecture.",2,positive
Table 2: Few-Shot Classification (FSC) accuracy on CIFAR-FS [1] and CUB [40].,0,negative
"Our main experiment is a comprehensive evaluation on the standard few-shot classification benchmarks MiniImagenet [39], CIFAR-FS [1], and CUB [40], with detailed results in Tables 1 and 2.",2,positive
The CIFAR-FS [1] dataset includes 100 classes with 600 images of size 32 × 32 per-class.,2,positive
"Results on the mini-ImageNet, tiered-ImageNet, CUB, and CIFAR-FS datasets are shown in Tables 1, 2, 3, and 4, respectively.",2,positive
"‘Others’ means some other backbones that are larger than ResNet12, such as ResNet18 [1], [23], [24], [59], [78], [79], ResNet34 [80], and ResNet50 [81].
the mini-ImageNet (in Table 1) and CIFAR-FS (in Table 4) datasets, our method improves upon the model-based method METAVRF [33] by 5:1% and 5%, using ConvNet as the backbone.",2,positive
"Similarly, experimental results on the tiered-ImageNet (in Table 2), CUB (in Table 3), and CIFAR-FS (in Table 4) datasets further suggest our superiority.",2,positive
"On the CIFAR-FS dataset, our method outperforms compared methods by more than 8% and 5% in the 1-shot and 5-shot tasks.",2,positive
"We used the mini-ImageNet [59], tiered-ImageNet [64], CUB [65], and CIFAR-FS [66] datasets for few-shot classification.",2,positive
"Thus, we choose m ¼ 16 in the classification tasks for the miniImageNet, tiered-ImageNet, CUB, and CIFAR-FS dataset.",2,positive
"Comparisons With the State-of-the-Art Few-Shot Classification Methods on the CIFAR-FS Dataset
Backbone Method Category 1-shot 5-way 5-shot 5-way
ConvNet
METAVRF [33] Model 63:10 0:70 76:50 0:90 MAML [1] Optim 56:50 1:90 70:50 0:90
FOMAML [1] Optim 55:60 1:88 69:52 0:91 Reptile [71] Optim 57:50 0:45 71:88 0:42 Lazy-Reptile [35] Optim 59:36 1:44 74:90 1:28 Ours Optim 65:43 0:90 81:50 1:08
ResNet12
Shot-Free [68] Metric 69.20 84.70 TEWAM [29] Metric 70.40 81.30 ProtoNet [23] Metric 72:20 0:70 83:50 0:50 MetaOptNet [75] Metric 72:60 0:70 84:30 0:50 RENet [26] Metric 74:51 0:46 86:60 0:32 DSN [30] Metric 75:60 0:90 86:20 0:60
MCGN [85] Metric 76:45 0:99 88:42 0:23 RFS [86] Metric 73:90 0:80 86:90 0:50 Rizve et al. [87] Metric 77:87 0:85 89:74 0:57 MABAS [88] Aug 73:51 0:92 85:49 0:68
Ours Optim 86:40 0:80 94:87 0:50
‘Aug’ means the data augmentation technique for few-shot learning.
while our method uses a product manifold neural network, and learns a curvature generation scheme and a curvature updating scheme.",0,negative
CIFAR-FS is a dataset derived from CIFAR-100 [67].,2,positive
"Our proposed method could likely be extended to Relation Networks [22], MetaOptNet [15], or R2D2 [3], with a decoder network to visualize embeddings.",2,positive
The CIFAR-FS dataset [3] is a recent few-shot image classification benchmark consisting of all 100 classes from CIFAR-100 [14].,2,positive
"From Figure 9, we can see that on the MiniImagenet dataset and the CIFAR-FS dataset, the classification accuracy of the WPGN is higher than that of the DPGN on the three tasks.",2,positive
The results of the ablation experiment on the CUB-200-2011 and CIFAR-FS datasets under 5-way-1 shot tasks are shown in Table 9.,0,negative
"This data can be found here: CUB-200-2011: https://resolver.caltech.edu/CaltechAUTHORS:20111026-120541847, MiniImagenet: https://www.image-net.org/, CIFAR-FS: DOI: 10.1109/IROS45743.",2,positive
7 k 200 100/50/50 [33] 84 × 84 CIFAR-FS 60 k 100 64/16/20 [4] 32 × 32,0,negative
"We selected three types of standard datasets in FSL: MiniImageNet [9], CUB-2002011 [32] and CIFAR-FS [4].",2,positive
Meta-learning with differentiable closed-form solvers [4] uses simpler differentiable regression methods that have closed-form solutions to replace the original learning algorithms (e.,1,neutral
The accuracy of the CIFAR-FS dataset was lower than that of the MiniImagenet dataset because its background had a much smaller impact on the classification accuracy.,0,negative
"…and popular optimization framework that covers a variety of emerging machine learning applications, e.g., metalearning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyperparameter
optimization (Franceschi et al., 2018; Shaban et al., 2019;…",2,positive
"Meta-learning is closely related to representation learning, although the assumption is not the same [Denevi et al., 2019; Finn et al., 2019; Khodak et al., 2019; Lee et al., 2019; Bertinetto et al., 2018].",1,neutral
"Note that it is difficult to present a fair and direct comparison between the conventional FS-C and our few-shot classification task since FS-C is always evaluated on single-label classification benchmarks [2,32,57,74,76], whereas our task is evaluated on multi-label benchmarks [13,36], which are irreducible to a single-label one in general.",2,positive
"Following the split in [2], we used 64 classes to construct the base set, 16 and 20 for validation and novel set.",2,positive
"For this purpose, we employ the miniImageNet [8, 36], tieredImageNet [38], CIFAR-FS [5], and CUB-2002011 [49] datasets.",2,positive
"On the other hand, while our approach does not report the best result on CUB-200, we are on par with the best method FRN and produce the best performance on CIFAR-FS (≈ 5%).",0,negative
"For this purpose, we employ the miniImageNet [8, 36], tieredImageNet [38], CIFAR-FS [5], and CUB-2002011 [49] datasets.
miniImageNet consists of a subset of 100 object classes from ImageNet [8] with 600 images per class.",2,positive
"In this work, we leverage the tools of NTK from [26, 37] to analyze MAML in the few-shot learning setting, and our analysis can be easily generalized to other variants of MAML such as [9, 50, 51].",2,positive
",miniImageNet [50], tieredImageNet [39] and CIFAR-FS [3] whose details are deferred to the supplement.",0,negative
"Here we compare SUN with state-of-the-arts (SoTAs), including CNN based methods and ViT based one, on miniImageNet [50], tieredImageNet [39] and CIFAR-FS [3].",2,positive
"Without introducing extremely complex few-shot learning methods like [54,21], our SUN achieves comparable performance with SoTA on miniImageNet [50], and sets new SoTAs on tieredImageNet [39] and CIFAR-FS [3].",2,positive
"We evaluate the proposed method on three benchmark datasets, which are mini -ImageNet [33], CUB-200-2011 (CUB) [34] and CIFAR-FS [4].",2,positive
"CIFAR-FS is produced by arbitrarily dividing CIFAR-100 [19] into 64 base, 16 validation and 20 novel classes.",2,positive
"Another line of work [29,30,33,4,17] leverages the characteristics of different distance metrics to classify unknown samples by comparing with embeddings or their variants (e.",1,neutral
"We evaluate the proposed method on three benchmark datasets, which are mini -ImageNet [33], CUB-200-2011 (CUB) [34] and CIFAR-FS [4]. mini -ImageNet consists of 100 categories randomly selected from the ImageNet dataset [27] with each category containing 600 images sized 84×84.",2,positive
%) worse on CIFAR-FS.,0,negative
"CIFAR‐FS The full name of CIFAR-FS is CIFAR100 Few-Shots, which is the same as Fewshot-CIFAR100 from the CIFAR100 dataset and was first proposed by [51].",2,positive
"Following [5], we split the data set into 64 classes for training, 16 classes for validation, and 20 classes for test, respectively.",2,positive
"This yields the exact meta-gradients in constant memory, without any assumption on the optimality of the inner optimization problem, which is necessary when using the normal equations (Bertinetto et al., 2018), or to apply implicit differentiation (Rajeswaran et al., 2019).",1,neutral
"This yields the exact meta-gradients in constant memory, without any assumption on the optimality of the inner optimization problem, which is necessary when using the normal equations (Bertinetto et al., 2018), or to apply implicit differentiation (Rajeswaran et al.",1,neutral
"With its shared embedding network across tasks, COMLN is also connected to metric-based meta-learning methods (Vinyals et al., 2016; Snell et al., 2017; Sung et al., 2018; Bertinetto et al., 2018; Lee et al., 2019).",2,positive
"Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al.",1,neutral
"Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al. (2018); Shaban et al.",2,positive
"Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al. (2018); Shaban et al. (2019), actors and critics in reinforcement learning Konda & Tsitsiklis (2000); Hong et al. (2020), and model architectures and weights in neural architecture search Liu et al.",2,positive
"Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al.",2,positive
"Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al.…",2,positive
"Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al. (2018); Shaban et al. (2019), actors and critics in reinforcement learning Konda & Tsitsiklis (2000); Hong et al. (2020), and model architectures and weights in neural architecture search Liu et al. (2018). Mathematically, bilevel optimization captures intrinsic hierarchical structures in those machine learning models, and can be formulated into the following two-level problem:",1,neutral
"Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al. (2018); Shaban et al. (2019), actors and critics in reinforcement learning Konda & Tsitsiklis (2000); Hong et al.",1,neutral
"Because training models that can perform well in FSL tasks is difficult, meta-learning frameworks such as those of [2] were developed to transfer knowledge from the meta-training stage to the meta-testing stage.",1,neutral
Authors in [2] developed a deep neural network augmented with conventional learning components.,1,neutral
"Unlike the metric-based approach, recent optimization-based modeling approaches estimate parameters using a parameterized predictor together with a feature-extractor [2, 11].",1,neutral
"Following in the footsteps of [2], the authors of “MetaOptNetSVM” [11] used a support-vector machine instead of ridge regression for meta-learning.",1,neutral
"We train MetaOptNet-SVM (Lee et al., 2019) for benchmark datasets CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al., 2018) in 1-, 5-, and 10-shot settings.",2,positive
"On the other hand, CIFAR-FS train and test tasks are more similar, as indicated by the high accuracy, and thus are harder to distinguish; the correlation is worse for all dataset distances.",1,neutral
"FC100 is a more challenging variant of CIFAR-FS that was created to reduce similarity between train and test tasks (Oreshkin et al., 2018).",2,positive
"Both CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al., 2018) are few-shot learning benchmarks derived from the CIFAR-100 dataset (Krizhevsky et al., 2009).",2,positive
"CIFAR-FS partitions the classes randomly, while FC100 utilizes the class similarity information (100 classes are grouped into 20 superclasses in CIFAR-100) to reduce the semantic overlap between train and
test classes.",2,positive
", 2019) for benchmark datasets CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al.",2,positive
CIFAR FS [1] is a subset of CIFAR 100 [19] dataset which was generated in the same way as miniImageNet and contains 37800 images of 64 categories in the train set and 11400 images of 20 categories in the test set.,2,positive
", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods.",2,positive
"MetaOptNet [Lee et al., 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model.",2,positive
", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods. 10. HyperTransformer [Zhmoginov et al., 2022] study amortized models based on transformers [Vaswani et al., 2017] and show applications to few-shot classification. 11. Metz et al. [2021] study and emphasize the difficulty of optimizing objectivebased loss with just gradient information due to natural chaotic-based failure models of the amortization model.",2,positive
", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use.",2,positive
", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods. 10. HyperTransformer [Zhmoginov et al., 2022] study amortized models based on transformers [Vaswani et al., 2017] and show applications to few-shot classification. 11. Metz et al. [2021] study and emphasize the difficulty of optimizing objectivebased loss with just gradient information due to natural chaotic-based failure models of the amortization model. They focus on iterated dynamical systems and study where chaotic losses arise in physics and meta-learning. They identify the spectrum of the Jacobian as one source of these issues and give suggestions for remedying these undesirable behaviors to have learning systems that are well-behaved and stable. 12. Metz et al. [2019b] learn optimizers for robust classification tasks. They find that optimizers can uncover ways of quickly finding robust parameterizations that generalize to settings beyond the corruptions used during training. 13. Metz et al. [2019a] study semi-amortized optimization of convolutional architectures and identify and focus on key issues of 1) biased gradients from truncated BPTT and 2) exploding gradient norms from unrolling for many timesteps. They overcome both of these issues by optimizing the smoothed loss in eq. (2.14) with a variant of the gradient estimator proposed in Parmas et al. [2018] for reinforcement learning.",2,positive
", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods. 10. HyperTransformer [Zhmoginov et al., 2022] study amortized models based on transformers [Vaswani et al., 2017] and show applications to few-shot classification. 11. Metz et al. [2021] study and emphasize the difficulty of optimizing objectivebased loss with just gradient information due to natural chaotic-based failure models of the amortization model. They focus on iterated dynamical systems and study where chaotic losses arise in physics and meta-learning. They identify the spectrum of the Jacobian as one source of these issues and give suggestions for remedying these undesirable behaviors to have learning systems that are well-behaved and stable. 12. Metz et al. [2019b] learn optimizers for robust classification tasks. They find that optimizers can uncover ways of quickly finding robust parameterizations that generalize to settings beyond the corruptions used during training. 13. Metz et al. [2019a] study semi-amortized optimization of convolutional architectures and identify and focus on key issues of 1) biased gradients from truncated BPTT and 2) exploding gradient norms from unrolling for many timesteps.",2,positive
", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model.",1,neutral
", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods. 10. HyperTransformer [Zhmoginov et al., 2022] study amortized models based on transformers [Vaswani et al., 2017] and show applications to few-shot classification. 11. Metz et al. [2021] study and emphasize the difficulty of optimizing objectivebased loss with just gradient information due to natural chaotic-based failure models of the amortization model. They focus on iterated dynamical systems and study where chaotic losses arise in physics and meta-learning. They identify the spectrum of the Jacobian as one source of these issues and give suggestions for remedying these undesirable behaviors to have learning systems that are well-behaved and stable. 12. Metz et al. [2019b] learn optimizers for robust classification tasks.",2,positive
"ANIL and related GBML methods (Lee et al., 2019; Bertinetto et al., 2019) restrict Eq.",1,neutral
"3) We conduct extensive experiments on miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), and CIFAR-FS (Bertinetto et al., 2018) datasets where the unlabeled set has in-distribution and out-of-distribution (OOD) classes.",2,positive
"We conduct experiments on three datasets: miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), and CIFAR-FS (Bertinetto et al., 2018).",2,positive
"3, and CIFAR-FS in Tab.",1,neutral
", 2018), and CIFAR-FS (Bertinetto et al., 2018) datasets where the unlabeled set has in-distribution and out-of-distribution (OOD) classes.",1,neutral
"CIFAR-FS contains 60,000 images of size 32×32×3 from 100 classes.",2,positive
3 Relation network[33] CVPR 18 InceptionV2 No / 50.,0,negative
11 Relation net (T)[33] CVPR18 Conv4 No 15 50.,0,negative
CIFAR-FS [130] is randomly sampled from CIFAR100 by using the same criteria with which miniImageNet has been generated.,2,positive
"Image Datasets without Auxiliary Knowledge for zero-shot learning, as CIFAR-FS, FC100, or domain generalization, as Office-31, Office-Home, and VisDA2017.",2,positive
CIFAR-FS [10]: CIFAR-FS is randomly sampled from CIFAR-100 [75].,1,neutral
"We have many choices, such as logistic regression (Kleinbaum et al. 2002), kernel-based nonlinear model (Liu 2003) and differentiable closed-form solvers (Bertinetto et al. 2018).",1,neutral
"2002), kernel-based nonlinear model (Liu 2003) and differentiable closed-form solvers (Bertinetto et al. 2018).",1,neutral
(Lee et al. 2019; Bertinetto et al. 2018) argue that (Bengio 2000; Baydin and Pearlmutter 2014) it is too costly and adopt algorithms with closed-form solutions in the lower-level optimization.,1,neutral
"We evaluate the performance of the proposed method using standardized few-shot classification datasets: miniImageNet [1], CUB [19] and CIFAR-FS [20].",2,positive
"The CIFAR-FS dataset is called the CIFAR100 Few-Shots dataset, which is derived from the CIFAR 100 dataset.",2,positive
"On the basis of transfer learning and metalearning [1], Timothy Hospedales [24] proposed small sample learning [14] to apply to limited labeled data.",1,neutral
"We consider four different datasets: (i) Mini-ImageNet (Vinyals et al., 2016); (ii) CIFAR-FS (Bertinetto et al., 2019); (iii) FC-100 (Oreshkin et al., 2018); and (iv) EMNIST (balanced) (Cohen et al., 2017).",2,positive
"Throughout the experiments, we consider four different datasets: (i) MiniImageNet (Vinyals et al., 2016) and (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al., 2018) and EMNIST (balanced) (Cohen et al., 2017).",2,positive
", 2016) and (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al.",1,neutral
", 2016); (ii) CIFAR-FS (Bertinetto et al., 2019); (iii) FC-100 (Oreshkin et al.",1,neutral
"We report few-shot classification within domain by using Conv-4, WRN-28-10, ResNet-12 and ResNet-18 in Table 16.",0,negative
"For the within-domain experiments, we use two backbones: Conv-4 and ResNet-12.",2,positive
"The results using ResNet-12 are reported in Table 5, the results using Conv-4 are reported in the appendix B.5.",0,negative
"We also provide results for few-shot within domain using a ResNet-12 backbone under data augmentation in the meta-training stage following (Zhang et al., 2021).",2,positive
"Following the prior works, we configure the ResNet-12 backbone as 4 residual blocks.",2,positive
"To gain better performance, ResNet-12 (Bertinetto et al., 2019; Gidaris & Komodakis, 2018; Yoon et al., 2018) is also widely reported for few-shot classification.",0,negative
"However, the typical metatesting stage just adapts the last classification head with the frozen backbone, which is commonly a fully connected (FC) layer [6].",0,negative
"In CIFAR-FS and FC100 5-shot, the average improvement are 0.8% and 3.2% respectively.",0,negative
"2018), CIFAR-FS (Bertinetto et al. 2019), and FC100 (Oreshkin, López, and Lacoste 2018).",2,positive
"We evaluate our method on four widely used few-shot recognition benchmarks: miniImageNet (Vinyals et al. 2016), tieredImageNet (Ren et al. 2018), CIFAR-FS (Bertinetto et al. 2019), and FC100 (Oreshkin, López, and Lacoste 2018).",2,positive
"On CIFAR-FS, the improvements over SKD-GEN1 (our implementation) for 1-shot and 5-shot are 0.7% and 0.9%, respectively.",2,positive
"With the combination of distillation loss on the soft-labeled base dataset, our method (Soft LabelHalluc + finetuning) eliminates the overfitting problem yielding 5-shot gains of 5.57%, 3.8% and 5.3% on miniImageNet, CIFAR-FS, and FC100, respec-
tively, over finetuning with the episode examples only.",0,negative
"The use of soft labels over hard labels contributes 5-shot classification gains of 4.92% in miniImageNet, 4.2% in CIFAR-FS, and 4.8% in FC100.",0,negative
"Though using the arcMax alone yieds an improvement of 1.18% over finetune in miniImageNet, we find that combining arcMax with centroid alignment leads to inferior results in our experimental setup based on ResNet-12 and SGD. AssoAlign with softMax and centroid alignment outperforms finetune by 3.44%, 1.9% and 2.7%, whereas our method outperforms AssoAlign by 2.13%, 1.9% and 3.6% in miniImageNet, CIFAR-FS and FC100 respectively.",2,positive
"2011), CIFAR-FS (Bertinetto et al. 2018) and Fewshot-CIFAR100 (FC100) (Oreshkin, López, and Lacoste 2018).",2,positive
"…evaluate our approach across five standard benchmarks, i.e., mini-ImageNet (Ravi and Larochelle 2016), tiered-ImageNet (Ren et al. 2018), Caltech-UCSD Birds-200-2011 (CUB) (Wah et al. 2011), CIFAR-FS (Bertinetto et al. 2018) and Fewshot-CIFAR100 (FC100) (Oreshkin, López, and Lacoste 2018).",2,positive
"Both CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, López, and Lacoste 2018) are modified from the CIFAR-100 dataset containing 100 classes, with 600 samples per class.",2,positive
"Both CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, López, and Lacoste 2018) are modified from the CIFAR-100 dataset containing 100 classes, with 600 samples per class.",2,positive
"We carry out experiments on five benchmark datasets, including mini-ImageNet [56], tiered-ImageNet [54], CIFARFS [57], FC100 [25], and CUB [58].",2,positive
"We carry out experiments on five benchmark datasets, including mini-ImageNet [56], tiered-ImageNet [54], CIFAR-
FS [57], FC100 [25], and CUB [58].",2,positive
"We follow the split introduced in [57] to divide CIFAR-FS into 64 classes as base set, 16 classes as validation set, 20 classes as novel set, and divide FC100 into 60 classes as base set, 20 classes as validation set, 20 classes as novel set.",2,positive
"Indeed, many machine learning applications can be reduced to (1) including hyper-parameter optimization (Feurer and Hutter, 2019), meta-learning (Bertinetto et al., 2018), reinforcement learning (Hong et al.",1,neutral
"Indeed, many machine learning applications can be reduced to (1) including hyper-parameter optimization (Feurer and Hutter, 2019), meta-learning (Bertinetto et al., 2018), reinforcement learning (Hong et al., 2020b; Liu et al., 2021) or dictionary learning (Mairal et al., 2011; Lecouat et al.,…",1,neutral
", miniImageNet [54], tieredImageNet [40], CIFAR-FS [3], and CUB [55].",2,positive
"Results on CIFAR-FS are shown in Table 4, where our method also gets competitive results.",0,negative
"We perform experiments on four widely used FSL benchmarks to verify the effectiveness of the proposed method, i.e., miniImageNet [54], tieredImageNet [40], CIFAR-FS [3], and CUB [55]. miniImageNet and tieredImageNet are both derivatives of ImageNet dataset [41], CIFAR-FS is derived from CIFAR-100 dataset [19,52].",2,positive
"By comparing the performance of with semantic (the first row) and without semantic (the second row which is our baseline [11] under our framework), we can infer that the semantic knowledge can significantly improve performance (i.e., the performance improvement is 6%, 4% and 8% on miniImageNet, tieredImageNet, and CIFAR-FS respectively).",2,positive
"Aside from the original application in few-shot image classification [7], differentiable closed-form solvers have been used for other few-shot problems like visual tracking [47], video object segmentation [24], spoken intent recognition [27] and spatial regression [17], while we are not aware of any application in forecasting.",1,neutral
"Typical meta-learning methods usually parameterize a learnable function as the meta learner, which can generate the parameters or statistics [20, 18, 21] for base learners.",1,neutral
"The first class of methodologies include optimization-based meta-learners, like model-agnostic meta-learner [11], gradient unrolling [12], closed-form solvers [13], and convex learners [14].",1,neutral
", nonparametric nearest neighbors [28, 29, 30, 31, 32]; (2) black-box methods that train feed-forward or recurrent neural networks (RNNs) to take the hyperparameters and task dataset as the input and predict the optimal model parameters or parameter updating rules [33, 34, 35, 36, 37, 38, 39, 40, 41]; and (3) optimization-based methods that conduct a bi-level optimization, where the inner level is to estimate the model parameters given the hyperparameters and the outer level is to optimize the hyperparameters via a meta-loss [42, 43, 44, 45, 46, 47, 48, 49].",1,neutral
"In this section, we compare our proposed SDNN approach against contemporary methods on miniImageNet, CIFAR-FS and tieredImageNet.",2,positive
"We perform all our main experiments on three standard datasets used for few shot learning: miniImageNet [40], tieredImageNet [27], and CIFAR-FS [2]. miniImageNet consists of 100 classes randomly picked from the ImageNet dataset [28] with 600 images of size 84×84 pixels per class.",2,positive
"• We demonstrate the effectiveness of SDNNs on the miniImageNet, tiered-ImageNet, CIFAR-FS, and ActEV Surprise Activities datasets.",2,positive
"For two of the experiments in the original paper (the “Gaussian SDNN + BF3S” experiment performed on the CIFAR-FS and tieredImageNet dataset in Table 1 of the original paper) our SDNN implementation only applied noise and auxiliary losses to the last two blocks of the network, as opposed to the three used in every other experiment.",2,positive
"An unmodified version of our method also perform favorably against many prior methods, even achieving state-of-the-art performance on the “CIFAR-FS” dataset without modification.",2,positive
"We perform all our main experiments on three standard datasets used for few shot learning: miniImageNet [40], tieredImageNet [27], and CIFAR-FS [2].",2,positive
"In this section we study the performance range of meta-learners trained with a variety of algorithms: MAML [10], Meta-Curvature (MC) [32], Prototypical networks [38], R2D2 [4], and MetaOptNet with Ridge and SVM heads [21].",2,positive
"We execute algorithm 1 to find the worst-case 5-way 10-shot support examples on CIFAR-FS and FC100 datasets for R2D2, ResNet-Ridge, and the ResNet-SVM algorithms.",2,positive
"R2D2 [4] casts classification as a multi-target ridge-regression problem and utilizes the corresponding closed-form solution as a(θ,A).",1,neutral
"D Improving support data robustness with adversarial training
In Table 6, we show the projected embeddings for the R2D2, MetaOptNet-Ridge, and the MetaOptNetSVM algorithms on the training and the test dataset, when trained in a standard manner vs when trained adversarially.",2,positive
"We also see no differences between meta-learners adapting end-to-end, i.e. MAML and MC, and those adapting only the last linear classification layer, i.e. R2D2 and MetaOptNet.",2,positive
"0 1 2 3 4 5 6 7 8 9 10 Iterations
30
40
50
60
70
80
90
Ac cu
ra cy
R2D2 ResNet-Ridge ResNet-SVM
(a) Worst-case accuracy over 10 iterations of algorithm 1 for different algorithms and on the CIFAR-FS dataset.",1,neutral
"For ProtoNet and R2D2 experiments, we use the same architectures as are used in the original papers.",2,positive
"The corresponding run times for a single iteration for R2D2 method on FC100 are approximately 1 minute for 1-shot setting, approximately 6 minutes for 5-shot setting, and approximately 20 minutes for 10-shot setting.",0,negative
"0 1 2 3 4 5 6 7 8 9 10 Iterations
10
20
30
40
50
60
Ac cu
ra cy
R2D2 ResNet-Ridge ResNet-SVM
(b) Worst-case accuracy over 10 iterations of Algorithm 1 for different algorithms and on the FC100 dataset.",1,neutral
"CIFAR-FS [4] is a dataset of 60000 32×32 RGB images from CIFAR-100 partitioned into 64, 16 and 20 classes for training, validation and testing, respectively.",2,positive
"The R2D2 feature extractor is a combination of 4 convolutional layers with [96, 192, 384, 512] filters.",2,positive
The CIFAR-FS and FC100 datasets are derived from CIFAR-100 dataset having 100 classes with each class consisting of 600 images of size 32 × 32.,2,positive
"We conducted experiments on four datasets – CIFAR-FS [8], FC100 [13], miniImageNet [6] and tieredImageNet [32].",2,positive
"On CIFAR-FS, we have improved on original methods up to 2.0%, with the largest improvement by 2-way MAML MTM SPSA-Track.",2,positive
R2D2 [8] and MetaOptNet [2] improved accuracy by using Ridge Regression and SVM as classifiers.,2,positive
"In the CIFAR-FS dataset classes are randomly divided into groups of 64, 16 and 20 for training, validation, and testing, respectively, while in the FC100 datasets 20 superclasses of CIFAR-100 are split into groups of 12, 4 and 4.",0,negative
", 2017) aim to learn transferable deep representations which can adapt to unseen classes without any additional fine-tuning; (c) Optimization based methods (Finn et al., 2017; Lee et al., 2019; Bertinetto et al., 2018) learn a good pre-training initialization for effective transfer to unseen tasks with only a few optimization steps.",2,positive
"In addition, we use MetaOptNet (Lee et al., 2019) and R2D2 (Bertinetto et al., 2018) as representative algorithms from the optimization based meta-learning methods.",2,positive
"…representations which can adapt to unseen classes without any additional fine-tuning; (c) Optimization based methods (Finn et al., 2017; Lee et al., 2019; Bertinetto et al., 2018) learn a good pre-training initialization for effective transfer to unseen tasks with only a few optimization steps.",1,neutral
"The CIFAR-FS dataset (Bertinetto et al., 2018) is curated from CIFAR-100 and comprises of 100 classes in total with each class consisting of 600 images.",2,positive
", 2019), and R2D2 (Bertinetto et al., 2018) primarily focus on improving prediction performance on average across multiple episodes.",2,positive
"Existing state-of-the-art meta-learners (Finn et al., 2017; Lee et al., 2019; Snell et al., 2017; Bertinetto et al., 2018) primarily focus on optimizing for the average loss across multiple training episodes or tasks.",2,positive
"In this paper, we study this issue and investigate how existing state-of-the-art meta-learners (Snell et al., 2017; Bertinetto et al., 2018; Lee et al., 2019) perform on episodes of varying hardness.",2,positive
"Existing meta-learners such as prototypical networks (Snell et al., 2017), MAML (Finn et al., 2017), MetaOptNet (Lee et al., 2019), and R2D2 (Bertinetto et al., 2018) primarily focus on improving prediction performance on average across multiple episodes.",2,positive
"Different meta-learners have different types of fine-tuning procedures and we direct the readers to (Finn et al., 2017; Snell et al., 2017; Bertinetto et al., 2018)",1,neutral
"We use three standard few-shot classification datasets for our experiments : (i) CIFARFS (Bertinetto et al., 2018); (ii) mini-ImageNet (Vinyals et al.",2,positive
"Different meta-learners have different types of fine-tuning procedures and we direct the readers to (Finn et al., 2017; Snell et al., 2017; Bertinetto et al., 2018)
for more information on the characteristics ofA.",2,positive
"We use three standard few-shot classification datasets for our experiments : (i) CIFARFS (Bertinetto et al., 2018); (ii) mini-ImageNet (Vinyals et al., 2016) and (iii) tieredImageNet (Ren et al., 2018).",2,positive
", 2019) and R2D2 (Bertinetto et al., 2018) as representative algorithms from the optimization based meta-learning methods.",1,neutral
"Similar to [41, 17, 12], Figure 6: Accuracy results for training and validation on R2-D2 base-learner [8] with a DBT-regularized ResNet-12 backbone on the CIFAR-FS dataset.",2,positive
"To start with, we used the R2-D2 base learner [8] and the CIFAR-FS database to evaluate the augmentation performance on support, query and task augmentations as shown in Table 1.",2,positive
"We used the R2-D2 base leaner [8], the ”ResNet12” and ”64-64-64-64” backbone for different few-shot learning modes used in our work.",2,positive
"In this branch, optimization based methods [3, 1, 2, 10, 11, 12] train a well-initialized optimizer so that it quickly adapts to unseen classes with a few epochs of training.",1,neutral
"This section focuses on comparing and evaluating the proposed method with several state-of-the-art approaches on several benchmark few-shot learning datasets, such as mini-ImageNet[5], tiered-ImageNet[4], CIFAR-FS[12], and CUB[24].",2,positive
"In the 5-way 1-shot setting, tiered-Imagenet and CIFAR-FS are improved by at least 1.59% and 1.5%, respectively.",0,negative
"Table II and Table III show the accuracy of LDAnet in tiered-Imagenet and CIFAR-FS, respectively.",2,positive
"In the 5- way 5-shot setting, tiered-Imagenet and CIFAR-FS increased by at least 0.99% and 1% respectively.",0,negative
CIFAR-FS is the subsets of the CIFAR-100 dataset and consists of 100 classes.,2,positive
"We divide the 100 category into meta-training set, metavalidation set, and meta-test set according to [12], with categories of 64, 16, and 20, respectively.",2,positive
"We divide the 200 category into base set, validation set, and novel set according to [12], with categories of 100, 50, and 50, respectively.",2,positive
"We comprehensively evaluate our proposed method on three challenging benchmark datasets, including miniImageNet, CIFAR-FS and FC100.",2,positive
CIFAR-FS and FC100 are both derived from the standard CIFAR-100 dataset [22].,2,positive
"To further illustrate the effectiveness of our method, we also conducted extensive experiments on CIFAR derivatives (CIFAR-FS and FC100).",2,positive
"CIFAR-FS contains a random split of 100 classes into 64 training classes, 16 validation classes and 20 testing classes, while FC100 splits classes based on the super-classes.",0,negative
"Tables 1, 2 and 3 tabulate the few-shot classification performances of different methods on miniImageNet, CIFAR-FS and FC100 datasets respectively.",0,negative
"Extensive experimental results on miniImageNet, CIFAR-FS and FC100 datasets demonstrate the effectiveness of our proposed approach, which can achieve consistent performance gains across different benchmark methods.",2,positive
"On CIFAR-FS dataset, our method achieves accuracy of 76.68% and 87.49% in 1-shot and 5-shot scenarios, respectively.",2,positive
"In this section, we conduct experiments on three widely used few-shot learning benchmarks: miniImageNet [42], CIFAR-FS [2], FC100 [32].",2,positive
", 2017), and (3) optimization-based methods that conduct a bi-level optimization, where the inner level is to estimate the model parameters given the hyperparameters (in each task) and the outer level is to optimize the hyperparameters via a meta-loss (Finn et al., 2017; Finn, 2018; Bertinetto et al., 2018; Lee et al., 2019; Zintgraf et al., 2019; Li et al., 2017; Finn et al., 2018; Zhou et al., 2018; Harrison et al., 2018).",1,neutral
"…the model parameters given the hyperparameters (in each task) and the outer level is to optimize the hyperparameters via a meta-loss (Finn et al., 2017; Finn, 2018; Bertinetto et al., 2018; Zintgraf et al., 2019; Li et al., 2017;
Finn et al., 2018; Zhou et al., 2018; Harrison et al., 2018).",1,neutral
"They can also be extended to other applications such as regression and image classification by changing the architecture and training objective [9], [69], [70], [71].",1,neutral
"Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning [4, 12, 49, 24, 36], hyperparamater optimization [12, 51], neural architecture search [35, 58], signal processing [10], etc.",1,neutral
"CIFAR-FS The CIFAR-FS dataset [34] is a recently proposed fewshot image classification benchmark, consisting of all 100 classes from CIFAR-100 [35].",2,positive
"[34] Luca Bertinetto, João Henriques, Philip H.",0,negative
"For the cosine classifier experiments, we trained over 1.92, 1.92, and 3.36 million classifiers for mini-ImageNet, CIFAR-FS, and tiered-ImageNet datasets, respectively.",2,positive
"CIFAR-FS is a random split of CIFAR-100 (Krizhevsky and Hinton, 2009) with images of size 32× 32 into 64, 16, and 20 classes for base, validation, and novel sets, respectively.",2,positive
"E.1 ADDITIONAL LOGISTIC CLASSIFIER EXPERIMENTS
The experiments of Figure 2 were repeated to perform 16-way classification using a logistic classifier on tiered-ImageNet and CIFAR-FS in Figure A13.",1,neutral
"The improvement almost falls within (0.1%-0.5%), (0-0.1%), and (0-0.2%), for mini-ImageNet, CIFAR-FS, and tiered-ImageNet, respectively.",2,positive
", 2016), CIFAR-FS (Bertinetto et al., 2019), tiered-ImageNet (Ren et al.",2,positive
"Datasets: We perform experiments on four widely-used and publicly available benchmarks: miniImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), tiered-ImageNet (Ren et al., 2018), and CUB (Wah et al., 2011).",2,positive
"Before After Improvement Before After Improvement
5-way 10-way
1-shot 74.96 75.03 ± 0.19 0.07 ± 0.01 61.46 61.49 ± 0.13 0.03 ± 0.00 5-shot 87.43 87.48 ± 0.13 0.06 ± 0.00 77.73 77.83 ± 0.10 0.10 ± 0.00
10-shot 89.83 89.88 ± 0.11 0.05 ± 0.00 81.52 81.64 ± 0.09 0.11 ± 0.00 15-way 20-way
1-shot 53.45 53.47 ± 0.10 0.02 ± 0.00 47.78 47.79 ± 0.07 0.01 ± 0.00 5-shot 70.70 70.99 ± 0.07 0.28 ± 0.00 65.26 65.60 ± 0.03 0.34 ± 0.00
10-shot 75.37 75.71 ± 0.06 0.34 ± 0.00 70.57 70.99 ± 0.02 0.42 ± 0.00
Table A6: The Firth bias reduction improvements on the CIFAR-FS dataset shown in Figure 4 in the main paper.",0,negative
"We trained Firth penalized and non-penalized cosine classifiers on the mini-ImageNet, tiered-ImageNet, and CIFAR-FS datasets.",2,positive
"The CIFAR-FS dataset (Bertinetto et al., 2018) is derived from the original CIFAR-100 dataset (Krizhevsky et al.",2,positive
"Next, we compare our proposed few-shot approach with other state-of-the-art methods on CIFAR-FS and FC-100 datasets.",2,positive
"(13)
A.2 EXPERIMENTS ON CIFAR-FS AND FC-100
Here, we conduct the experiments on the CIFAR-FS and the FC-100 datasets.",2,positive
"The pre-trained model, by itself, outperforms several meta-learning approaches in numerous FSL datasets (e.g., miniImageNet, tieredImageNet, CIFAR-FS, etc.).",2,positive
"Experimental results on miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFARFS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al., 2018) datasets are provided demonstrating the efficacy of the proposed approach compared to other state-of-the-art few-shot learning…",2,positive
"In this section, we present our experimental results in various few-shot learning benchmarks, including miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFAR-FS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al., 2018) 3.",2,positive
"Experimental results on miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFARFS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al., 2018) datasets are provided demonstrating the efficacy of the proposed approach compared to other state-of-the-art few-shot learning methods.",2,positive
", 2018), CIFAR-FS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al.",1,neutral
", 2018), CIFARFS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al.",1,neutral
"The CIFAR-FS dataset (Bertinetto et al., 2018) is derived from the original CIFAR-100 dataset (Krizhevsky et al., 2009) by splitting 100 classes into 64 training classes, 16 validation classes, and 20 testing classes.",2,positive
"3Due to page limits, we discuss the experiments on CIFAR-FS and FC-100 in the appendix.
encoder fθ of the Whole-Classification network, and use it to compute the TAS in the task affinity phase.",2,positive
"Here, we fist present the proof of the Theorem 1, and then we provide more experimental results on CIFAR-FS and FC-100 datasets.",2,positive
"Meanwhile, optimization-based approaches employ bi-level optimization to learn the learning procedures, such as initialization and weight updates, that will be used to adapt to new tasks with few examples [2, 4, 5, 10, 21, 26, 38].",1,neutral
"Several works attempted to overcome the difficulty either by attempting to find a better initialization [5, 13, 11, 15, 45, 49] or a better fast adaptation process (inner-loop update rule) [2, 7, 20, 21, 34].",1,neutral
"There has been recent studies on improving the overall performance either by enhancing the learning scheme of initialization [5, 15, 34, 43, 45] or improving gradient-based fine-tuning process [2, 4, 21, 38].",1,neutral
"We compare our method with state-of-the-art FSL methods in the inductive and transductive settings on the miniImageNet, tiered-ImageNet, CUB, and CIFAR-FS datasets, where 1-shot/5-shot 5-way classification were implemented
and query sets had 15 samples per class.",2,positive
"We conducted experiments on four popular datasets: mini-ImageNet [50], tiered-ImageNet [40], CUB [51], and CIFAR-FS [4].",2,positive
"We used BigResNet12 on tiered-ImageNet and CIFAR-FS, and ConvNet on the CUB dataset.",2,positive
The results on Omniglot and CIFAR-FS are reported in Table 3.,0,negative
"Some recent studies along this line include Matching Networks [49], which employs the cosine similarity, Prototypical Networks [43], which uses the Euclidean distance to compute the similarity, Relation Network [44], which uses a relation module as the similarity function, ridge regression [6], and graph neural networks [39].",1,neutral
"We experiment with four datasets for few-shot learning: Omniglot [24], MiniImageNet [50], TieredImageNet [37], and CIFAR-FS [6].",2,positive
"Given that high-dimensional features have better modeling capacity but are computationally expensive to work with, each meta-learning task is then formulated as a convex optimization problem and solved in its low-dimensional dual space [9, 34].",1,neutral
"Another popular approach [2, 39, 34, 4, 6] is to develop a meta-learner to optimize key hyper-parameters (e.",1,neutral
"Baselines FPAIT [11] directly leverages MAML [13] to deal with few-shot VQA and IC tasks; Prototypical Net [42], Relation Net [44], R2D2 [6], and DN4 [28] focus on few-shot classification.",2,positive
", Euclidean distance) or directly learn the metric [49, 56, 3, 40, 16, 58].",1,neutral
"Recent efforts on reducing the impact of DSP are generally based on designing a more robust and adaptive FEM to generate better features, such as introducing meta-learning strategy [10] [2]; self-supervised learning strategy [23] [30]; knowledge distillation strategy [38] [29].",1,neutral
"(2) Meta feature (Meta-Fea), the FEM introduces the meta-learning strategy to the network, just like [2].",2,positive
"(3)Weevaluate the proposedmethod on four benchmark datasets (mini-ImageNet, tiered-ImageNet, CIFAR-FS, FC100) and achieve significant improvements of 2.1%-7.8% compared with other stateof-the-art methods.",2,positive
"(2)Metric learning based methods, focusing on looking for ideal distance metrics to strengthen model’s robustness, including ProtoNet [36], MetaOpt [2], TADAM [25] 𝑒𝑡 𝑎𝑙 .",1,neutral
"MHFC has significant improvements of at least 7.7%, 10.0%, 6.8% and 4.7% on miniImageNet, tiered-ImageNet, CIFAR-FS, FC100 datasets.",2,positive
",M θ , where h = [1, 2] denotes the hth head.",1,neutral
"Both CIFAR-FS and FC100 are the subsets of CIFAR-100 dataset [14], and consist of 100 classes.",2,positive
"And on the 5-way 5-shot case, the MHFC also exceeds others at least 3.0%,
2.8%, 4.8% and 6.9% on mini-ImageNet, tiered-ImageNet, CIFAR-FS, FC100 datasets.",0,negative
"(2)Metric learning based methods, focusing on looking for ideal distance metrics to strengthen model’s robustness, including ProtoNet [36], MetaOpt [2], TADAM [25] et al .",1,neutral
"MHFC is a simple non-parametric model that can directly fuse multi-head features extracted from the existing FEMs, such as ICI-Net [47], MetaOpt-Net [2].",2,positive
"We follow the split introduced in [2] to divide CIFAR-FS into 64 classes as base set, 16 classes as validation set, 20 classes as novel set, and divide FC100 into 60 classes as base set, 20 classes as validation set, 20 classes as novel set.",2,positive
"We carry out experiments on five benchmark datasets, including mini-ImageNet [43], tiered-ImageNet [28], CIFAR-FS [2], FC100 [25], and CUB [44].",2,positive
"More recently, differentiable solvers have also been adopted for meta-learning [4, 25] as well.",1,neutral
"Images Classes Split miniImageNet [39] 60,000 100 64/16/20 tieredImageNet [31] 779,165 608 351/97/160 CIFAR-FS [3] 60,000 100 60/16/20 CUB-200-2011 [40] 11,788 200 100/50/50",0,negative
"We validate our BML on four commonly used benchmarks, including miniImageNet [39], tieredImageNet [31], CIFAR-FS [3] and CUB-200-2011 (CUB) [40].",2,positive
"As for CIFAR-FS, we surpass all competitors and reach a new SoTA, including LR+ICI [41] which is based on the transductive strategy.",2,positive
"Some of model-based meta-algorithms avoid innertask training by learning a meta amortization network G parameterized by ψ to generate task-specific parameters φTi using the support set as inputs (Gordon et al., 2018b,a), i.e.,
φTi = Gψ ( fθ(DtrTi) ) .",1,neutral
"…with closed-form solvers can be applied as the inner-task algorithm, such as nearest neighbor classification (Snell et al., 2017), ridge regression (Bertinetto et al., 2019), SVM (Lee et al., 2019) or gradient descent with a learned initialization (Finn et al., 2017), which significantly limits…",1,neutral
"Several meta-algorithms adopt a simple algorithm with convex objective function as inner-task algorithm such that the taskspecific parameters φTi have a closed-form solution (Bertinetto et al., 2019; Lee et al., 2019).",1,neutral
"(5)
Then, the gradients of θ include a second-order gradient of θ, because ∇θφTi = I − ∇2θ (∑ (xj ,yj)∈DtrTi l ( fθ(xj), yj )) .",1,neutral
"For example, (Bertinetto et al., 2019) uses ridge regression as inner-task algorithm, and the closed-form solution is
φTi = (Xθ TXθ + λI) −1Xθ TY.",1,neutral
"Similarly, over the embedding space, meta-algorithms with closedform solutions apply simple inner-task algorithms with a closed-form solution such as ridge regression (Bertinetto et al., 2019) or SVM (Lee et al.",1,neutral
"Next, meta-update is performed by aggregating the predictions of all the predictors on the query set to obtain final predictions and then using the final predictions to update the shared meta-parameters θ. Formally, the meta-training procedure of A2M is formulated as follows,
Inner-task adaptation: Fix θ, for e ∈ {1, 2, . . . , E}, φeTi = arg minxφe Ti L(DtrTi ; θ, xφeTi ), Meta-update: Fix {φeTi} E e=1, θ = θ − lθ∇θL(DtsTi ; θ, {φ e Ti} E e=1).",2,positive
", 2017), ridge regression (Bertinetto et al., 2019), SVM (Lee et al.",1,neutral
"2, during inner-task adaptation, we train a bag of diverse algorithms {Ae}Ee=1 separately with the embedded support set and obtain E predictors, i.e., {Ae(DtrTi ; θ)} E e=1.",1,neutral
"The iteration scheme is formulated as follows:
Inner-task adaptation: Fix θ, φTi = arg minxφTi L(DtrTi ; θ, xφTi ), (9) Meta-update: Fix φTi , θ = θ − lθ∇θL(DtsTi ; θ, φTi), (10)
where θ refers to the meta-parameters, i.e., the global parameters shared by all the tasks, and φTi refers to the task-specific parameters, i.e., the local parameters which are different among the tasks.",1,neutral
"For example, (Bertinetto et al., 2019) uses ridge regression as inner-task algorithm, and the closed-form solution is",1,neutral
"For prototypical networks (Snell et al., 2017), the task-specific parameters are the mean vectors of same-class support samples, which can be computed as
φTi = { 1
N ∑ (xj ,yj)∈DtrTi ,yj=k fθ(xj)}Kk=1.",1,neutral
"(8)
For brevity, Xθ = {fθ(xj)}mj=1 and Y = {yj}mj=1, where (xj , yj) ∈ DtrTi (Bertinetto et al., 2019).",1,neutral
"During inner-task adaptation, the inner-task algorithm A runs through the support set DtrTi and outputs a predictor gφTi parameterized by taskspecific parameters φTi .",2,positive
"For example, the taskspecific parameters of a typical gradient-based meta-algotithm, MAML (Finn et al., 2017) φTi is
φTi = θ − lφTi∇θL(D tr Ti ; θ) = θ −∇θ ( ∑ (xj ,yj)∈DtrTi l ( fθ(xj), yj )) .",1,neutral
"Hence, the inner-task algorithm A should be solved analytically, i.e., φTi should be an analytical expression of θ,
φTi = s(DtrTi , θ).",1,neutral
"2, the three algorithms are trained over the embedded support set independently, i.e,:
A1: φ1Ti ={ck} K k=1 = {
1
N ∑ zj∈DtrTi ,yj=k fθ′(xj)}Kk=1,
A2:φ2Ti =φ− lφ∇φ[ 1
m ∑ zj∈DtrTi − log ( egφ(fθ′ (xj))[yj ]∑ k′ e gφ(fθ′ (xj))[k ′] ) ],
A3: φ3Ti =φ 3 Ti − lφ3Ti ∇φ3Ti [
1
m ∑ zj∈DtrTi − log  egφ3Ti (fθ′ (xj))[yj ]∑ k′ e g φ3 Ti (fθ′ (xj))[k ′] ], (13) where A1, A2 and A3 denote the mean-centroid classification algorithm, the initializationbased algorithm and the two-layer MLP, respectively.",1,neutral
"Similarly, over the embedding space, meta-algorithms with closedform solutions apply simple inner-task algorithms with a closed-form solution such as ridge regression (Bertinetto et al., 2019) or SVM (Lee et al., 2019).",1,neutral
"During meta-training, given a set of training tasks {Ti ∼ p(τ)}ni=1, the meta-algorithm observes the meta-samples D = {DTi = (DtrTi ,D ts Ti )}ni=1, where DtrTi is the training (support) set of task Ti and D ts Ti
is the test (query) set of Ti.",1,neutral
"For brevity, Xθ = {fθ(xj)}j=1 and Y = {yj}j=1, where (xj , yj) ∈ Dtr Ti (Bertinetto et al., 2019).",1,neutral
"We randomly construct a training batch of size 128 for the ImageNet family [57, 75] and 64 for CUB [76] & CIFAR-FS [3] to compute Lanchor.",2,positive
"The hyperparameter λ is set to 0.25, 0.5, 1.5 for ImageNet derivatives, CIFAR-FS, CUB, respectively. γ is set to 2 for CUB and 5 otherwise.",1,neutral
"For evaluation, we use four standard benchmarks for few-shot classification: miniImageNet, tieredImageNet, CUB-200-2011, and CIFAR-FS. miniImageNet [75] is a subset of ImageNet [60] consisting of 60,000 images uniformly distributed over 100 object classes.",2,positive
"Our model uses a smaller backbone than that of several methods [17, 41, 53, 61] yet sets a new state of the art in both 5-way 1- shot and 5-shot settings on miniImageNet, CUB-200-2011, and CIFAR-FS datasets while being comparable to DeepEMD [87] on tieredImageNet.",2,positive
"Following the recent work of [3], we use the same train/validation/test splits consisting of 64/16/20 object classes, respectively.",2,positive
CIFAR-FS [3] is built upon CIFAR-100 [29] dataset.,2,positive
"We focus on a broad class of methods that we call meta-representation learning [1, 6, 10, 15], which is remarkably effective in practice and closely related to feature pre-training.",2,positive
"In [1], the ridge regression estimator is chosen as the base learner Alg(θ,D) = w(ψθ(D))",1,neutral
"where X([1,2,3,4]) t is a simplified denotation of search features from different backbone layers (layer 1 to 4).",1,neutral
"In [27], the closed-form ridge regression [3] is introduced to solve the VOS problem, it online optimizes a parameter matrix that maps features to segmentation masks.",1,neutral
"The steepest descent method is applied to iteratively minimize the squared error instead of the direct closed-form solution [3], as the latter requires time-consuming matrix inversion operations which are harmful to the running speed.",1,neutral
"Optimization-based methods [2, 6, 21] leverage a meta learner over the auxiliary dataset to learn a general initialization model.",1,neutral
"We further assess our method on two relatively less acknowledged datasets that are derived from CIFAR [42], namely, FC100 (Fewshot-CIFAR100) [18] and CIFAR-FS (CIFAR100 few-shots) [43].",2,positive
"Metric-based methods learn a shared feature extractor which is used to compute the distance between samples in embedding space [53, 3, 44, 30].",1,neutral
"Three standard few-shot classification datasets (CIFAR-FS [Bertinetto et al., 2019], CUB-200 [Wah et al., 2011], mini-ImageNet [Vinyals et al., 2016]) are selected to compare the performance of our approach with previous fewshot learning methods.",2,positive
"Three standard few-shot classification datasets (CIFAR-FS [Bertinetto et al., 2019], CUB-200 [Wah et al.",0,negative
"Common approaches include back-propagation through the sequence of gradient updates for a set of parameters, as in MAML [9], or back-propagation through the fixed point of a convex optimization algorithm [4], [19], [27], [34].",1,neutral
"CIFAR-FS [6] is created by dividing CIFAR-100 into 64 training, 16 validation and 20 testing classes; images are of size 32 × 32.",2,positive
A complete run of Conv-4-64 on CIFAR-FS and WRN-28-10 on MiniImageNet takes less than 2 hours and 5 hours respectively.,0,negative
"For few-shot classification, experiments are performed on CIFAR-FS and MiniImageNet whereas for continual learning, experiments are performed on Omniglot, CIFAR-100 and MiniImageNet.",2,positive
"In order to explore the role of each module, ablation experiments were performed on miniImageNet, CIFARFS, and CUB to investigate the following three components: ResNet-12, simple linear operation, and local cross-channel interaction.",2,positive
"In this section, experiments were performed on four traditional datasets including miniImageNet, CIFARFS, FC100, tieredImageNet, and CUB datasets to verify the effect of the acceleration strategy.",2,positive
"Four image datasets including miniImageNet [13], CIFARFS [26], FC100 [27], and tieredImageNet [28] are used to validate the performance of BAL-Reptile on traditional image classification, where both CIFAR-FS and FC100 are derived from CIFAR-100.",2,positive
"Because our method uses multi-task training, the batchsize is set to 2 for training ProNet, RelationNet, ANIL, R2D2, and MetaOpt.",2,positive
"R2D2 [4] and MetaOpt [18] adopt ridge regression or support vector machine [7] as the task-specific learner for each learning task, respectively.",1,neutral
"As shown in Table 3, pre-training the feature encoder substantially improves the performance of ProNet and R2D2 on four unseen benchmarks.",2,positive
"As for gradient-based method, ANIL, R2D2 [4], and MetaOptNet [18] are chosen.",1,neutral
"R2D2 [4] and MetaOpt [18] adopt ridge regression or support vector machine [7] as the task-specific learner for each learning task,
respectively.",1,neutral
R2-D2 [22] and MetaOptNet [23] adopt linear models as the classifier due to their computational efficiency.,2,positive
"Experimental results show that the proposed SEEN method achieves state-of-the-art few-shot classification performance on benchmark datasets, including mini-ImageNet, tiered-ImageNet, and CIFAR-FS.",2,positive
"mini-ImageNet [8] 100 60, 000 84× 84 tiered-ImageNet [40] 608 779, 165 84× 84 CIFAR-FS [22] 100 60, 000 32× 32 CUB [41] 200 11, 788 224× 224",1,neutral
"The metric-based methods include MatchingNet [8], ProtoNet [6], RelationNet [7], TADAM [20], R2-D2 [22], Prototype Classifier, and MetaOptNet [23].",2,positive
"Four benchmark datasets are used, including the mini-ImageNet and tiered-ImageNet from ILSVRC-2012 [44], CIFAR-FS from CIFAR-100, and CUB [41].",2,positive
CIFAR-FS [22] is a recent benchmark for few-shot classification.,2,positive
"[49] and R2D2 [2] by about 4% and 8%, respectively.",1,neutral
", miniImagenet [43] and CIFAR-FS [2], which firmly validates the effectiveness of our method.",2,positive
"Following [2, 39, 46], we respectively use ConvNet4 [43] and ResNet-12 [14] to implement the meta-learner.",2,positive
7 n/a n/a R2D2 [2] ICLR’ 19 ConvNet-4 51.,1,neutral
miniImagenet [43] and CIFAR-FS [2] are the most commonly used FSL datasets.,2,positive
", 2017), ridge regression classifier (Bertinetto et al., 2019) and SVM classifier (Lee et al.",1,neutral
"2 Experiments on CIFAR derivatives The CIFAR-FS dataset (Bertinetto et al., 2019) is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100.",2,positive
"Experiments of few-shot learning are based on four popular benchmark datasets: miniImageNet [4], tiered-ImageNet [24], CIFAR-FS [25], and FC100 [10].",2,positive
"Experimental results on ImageNet derivatives (mini-ImageNet and tiered-ImageNet) are reported in Table 1, and results on CIFAR derivatives (CIFAR-FS and FC100) are reported in Table 2.",2,positive
"Although few methods adapt to support instances by solving convex optimization problems for fast and effective adaptation [3, 26], they consider classification tasks.",1,neutral
"These methods require higher-order derivatives and to retain all optimization path of the iterative adaptation to backpropagate through the path, which imposes considerable computational and memory burdens [3].",1,neutral
"In this framework, fast adaptation to support instances is essential since the result of the adaptation is required to train the model in each iteration of training [3, 34].",2,positive
"Meta-learning methods have been recently attracting a lot of attention [8, 41, 9, 34, 3, 16].",1,neutral
"miniImageNet [10] 64 38,400 16 9,600 20 12,000 tieredImageNet [26] 351 448,695 97 124,261 160 206,209 CUB [29] 100 5,891 50 2,932 50 2,965 CIFAR-FS [27] 64 38,400 16 9,600 20 12,000 FC-100 [28] 60 36,000 20 12,000 20 12,000",0,negative
"The classes in CIFAR-FS are randomly split into 64/16/20 for metatraining/validation/testing, while FC-100 takes the split of 60/20/20 classes following the super-classes.",0,negative
CIFAR-FS [27] and FC-100 [28] are two variants of the CIFAR-100 dataset [103] for fewshot learning but with different partitions.,1,neutral
"For CIFAR-FS and FC-100, we enlarge the images to 50 by 50.",2,positive
"We validate LASTSHOT in combination with representative FSL methods [13], [23], [24], [25] on multiple benchmarks, including miniImageNet [10], tieredImageNet [26], CIFARFS [27], FC-100 [28], and CUB [29].",2,positive
"Last but not the least, comparing to Model Regression [16] and RFS [34], in which the former only uses the target classifier to guide the few-shot learner in the last fullyconnected layer while the latter uses distillation to strengthen the pre-trained features, our LASTSHOT outperforms them on miniImageNet, CUB, and CIFAR-FS, and performs on par with them on other datasets.",2,positive
"Way 5-Shot tasks on miniImageNet (Table 2), tieredImageNet (Table 3), CUB (Table 4), CIFAR-FS (Table 5), and FC-100 (Table 5).",2,positive
"We evaluate our approach LASTSHOT using multiple benchmark datasets, including miniImageNet [10], tieredImageNet [26], CUB [29], CIFAR-FS [27], and FC100 [28].",2,positive
"Furthermore, the EFIL assumption is empirically reasonable, since previous works (Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020) yield comparable performance while leaving the encoder untouched during the inner loop.",2,positive
"Similar ideas of freezing feature extractors during the inner loop have also been explored (Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020), and have been held as an assumption in theoretical works (Du et al., 2021; Tripuraneni et al., 2020; Chua et al., 2021).",1,neutral
"Similar ideas of freezing feature extractors during the inner loop have also been explored (Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020), and have been held as an assumption in theoretical works (Du et al.",1,neutral
"The inner algorithm from Equation (4), that uses ‖ · ‖F regularization, has been used in empirical work, for ` being the logistic and squared error losses in Bertinetto et al. (2019) and the margin loss in Lee et al. (2019); also used in theoretical work (Saunshi et al., 2020).",1,neutral
"Their proposed representation learning algorithm ANIL and other methods (Lee et al., 2019; Bertinetto et al., 2019) show that representation learning performs comparably to gradient-based methods on many benchmarks.",1,neutral
"These two features, few‐shot learning and rapid adaptation, make meta‐ learning to be on the spot of recent works, surpassing the previous literature by a considerable margin [32, 36, 37].",1,neutral
"DATASET METHODS PROTONET R2D2 METAOPTNETAccnat Accadv TIME Accnat Accadv TIME Accnat Accadv TIME
CIFAR-FS
AT (5WAY-1SHOT) 42.67 % (0.65",0,negative
"DATASET METHODS PROTONET R2D2 METAOPTNETAccnat Accadv TIME Accnat Accadv TIME Accnat Accadv TIME
CIFAR-FS
AT (5WAY-1SHOT) 38.11 % (0.62",0,negative
"10.3H
We follow the experimental setting of AQ in (Goldblum et al., 2020), training the state-of-the-art metalearning models including PROTONET (Snell et al., 2017a), R2D2 (Bertinetto et al., 2018a) , and MetaOptNet ( ResNet12 as backbone (He et al., 2016)).",2,positive
"We adopt models including PROTONET (Snell et al., 2017b), R2D2 (Bertinetto et al., 2018b), and MetaOptNet (Lee et al., 2019) and dataset including MiniImageNet (Vinyals et al., 2016), TieredImageNet (Ren et al., 2018), CIFARFS (Bertinetto et al., 2018b), and FC100 (Oreshkin et al., 2018).",2,positive
Extended experiments results on R2D2 and MetaOptNet versus PGD attack at different attack steps,1,neutral
3 (See Appendix A.4 for R2D2 and MetaOptNet ).,1,neutral
"DATASET METHODS PROTONET R2D2 METAOPTNET
Accnat Accadv TIME Accnat Accadv TIME Accnat Accadv TIME
TIEREDIMAGENET
AT (5WAY-1SHOT) 30.88 % (0.52",0,negative
"As CIFAR-FS is a small dataset, we follow [3,23] to consider 5way 1-shot and 5-way 5-shot.",2,positive
"Besides, CIFAR-FS is a subset of CIFAR-100, containing images of 32× 32 [3].",1,neutral
"We conduct experiments on a set of widely used benchmarks for few-shot image classification: mini-ImageNet, tieredImageNet, CIFAR-FS and FC100.",2,positive
"• CIFAR-FS (Bertinetto et al., 2019): It contains 60,000 colored images of 32x32 pixels, with 100 classes (each with 600 images) split into 64 training classes, 16 validation classes and 20 test classes.",2,positive
"Note that the two ImageNet derivatives (i.e., mini-ImageNet of 7.2 GB and tiered-ImageNet of 29 GB) are much bigger than that of the two CIFAR-100 derivatives (i.e., CIFAR-FS of 336 MB and FC100 of 336 MB).",2,positive
"As a comparison, another line of GBML algorithms uses the explicit `2 regularization in the inner loop instead (Rajeswaran et al., 2019; Lee et al., 2019b; Bertinetto et al., 2019; Zhou et al., 2019b; Goldblum et al., 2020).",1,neutral
"[10] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi.",0,negative
"This includes updates in closed form [2], iterative updates according to the gradient descent [10, 74, 44] and learnable iterative updates, such as LSTM [50].",1,neutral
", ANIL [38], MetaOptNet [30], and R2D2 [29], are chosen as the benchmark algorithms.",2,positive
"Besides MAML, some gradient-based approaches aim to learn a cross-task representation as meta-knowledge, which can generalize to new classes [29], [30].",1,neutral
MetaOptNet and R2D2: MetaOptNet [30] and R2D2 [29] use support vector machine [39] and ridge regression as the,2,positive
"In few-shot meta-learning [1], the inner function g(x, ·) often takes a quadratic form together with a strongly-convex regularizer.",1,neutral
"Bilevel optimization has become a timely and important topic recently due to its great effectiveness in a wide range of applications including hyperparameter optimization [7, 5], meta-learning [33, 16, 1], reinforcement learning [14, 24].",1,neutral
Each combination was evaluated in a 5-shot 5-way few-shot setting on the CIFAR-FS dataset [51].,0,negative
"We train our model on miniImageNet, tieredImageNet, CIFAR-FS and CUB-200-2011 for 200K, 200K, 100K and 100K iterations respectively.",2,positive
"• We conduct extensive experiments on four benchmarks
(i.e., miniImageNet, tieredImageNet, CIFAR-FS and CUB-200-2011) for the transductive few-shot classification task, and the results show that the proposed method achieves the state-of-the-art performances.",2,positive
CIFAR-FS [1] is reorganized from the CIFAR-100 dataset for the few-shot classification task.,2,positive
"We follow the popularly used train/val/test setting proposed in [35, 36, 1, 47, 29].",0,negative
"Few-shot learning is a fundamental yet unsolved problem in machine learning and computer vision [1, 19, 13, 14, 11, 25, 12].",1,neutral
"In addition, it is difficult for the SOT modules in many of them to benefit from the end-to-end training of CNNs or to keep the objective of offline training consistent with that of online tracking, limiting the power of the SOT module.",2,positive
"Different from the previous methods [11, 46] which employ the features extracted via the ImageNet pre-trained CNNs to train discriminative models, modern methods [34, 4, 47] integrate the solver of discriminative model into the offline training of CNNs to learn the optimal feature embeddings for the SOT task.",1,neutral
"3) can be integrated into the offline training of CNNs [2, 47], the SOT branch can be trained in an end-toend way following the above, learning the optimal feature embeddings for the ridge regression model based single object tracker which tracks the target object by distinguishing it from its surrounding similar ones.",2,positive
taught a deep network to use standard machine learning tools like ridge regression for quickly learning parameters [18].,1,neutral
"CIFAR-FS [24] contains 100 classes with 600 images per class, and it is split into 64 base, 16 validation, and 20 novel classes.",2,positive
• CIFAR-FS and FC100: two datasets derived from CIFAR-100 [23].,2,positive
"The minimax bound applies regardless of the target fine-tuning procedure in use, including those used in practice, e.g. iMAML, MetaOptNet (Lee et al., 2019), and R2D2 (Bertinetto et al., 2019).",2,positive
"Applications of optimization-based modeling include computer vision [36, 37], reinforcement learning [5, 14, 42], game theory [30], and inverse optimization [38], and metalearning [11, 29].",1,neutral
"This dataset [36] is obtained by randomly splitting 100 classes in CIFAR-100 [37] into 64 training classes, 16 validation",2,positive
"* means results for miniImageNet and CUB-200-2011 datasets are from [39], and results for CIFAR-FS are from [36].",0,negative
"Optimization-based works learn task-agnostic knowledge on model parameters [35,4,65] for fast adaptation to new tasks on limited training data, using only a few gradient update steps.",1,neutral
"Existing few-shot learning methods based on data augmentation [12,6,5], metric learning [26,27,2], and initialization [10,25,23] ameliorate the models in terms of supervised empirical growth, hypothesis space reduction, and initial parameter setting, respectively, so as to enhance the generalization ability of the models under the premise of inadequate training data.",2,positive
"MAML uses a gradient descent method for fine-tuning, where the gradient of the gradient is needed for backpropagation through the gradient descent steps, which can be costly in terms of memory [5].",1,neutral
"Typical examples include CIFAR-FS [7], mini-ImageNet [71, 52], TCGA [58], MultiMNIST [57, 62], CU Birds [75], FGVC Planes [36] and Fungi [64, 61], VGG Flowers [41], and Omniglot [29, 30].",1,neutral
"Some extensions to ProtoNet centered around learning and improving a specialized distance metric for a given task, typically by solving a convex optimization problem [7, 31, 83].",1,neutral
"[7, 71]) or leverage class semantic relationships (e.",1,neutral
"We denote by CNN4 the 4-layer CNN with 64 hidden described in [63], which we use for few-shot learning experiments on FC100, CIFAR-FS, EMNIST, and LFW10.",2,positive
"…in tasks such as hyper-parameter optimization (Maity et al., 2019), architecture search (Souquet et al., 2020; Hou and Jin, 2020) and meta-learning (Bertinetto et al., 2019), where the problem is solved by constructing the explicit gradient∇θR (Grazzi et al., 2020; Finn et al., 2017; Okuno et al.,…",1,neutral
", 2020; Hou and Jin, 2020) and meta-learning (Bertinetto et al., 2019), where the problem is solved by constructing the explicit gradient∇θR (Grazzi et al.",1,neutral
"Few-shot learning aims to reduce these demands by training models to recognize completely novel objects from only a few examples [9, 49, 40, 2, 38, 11, 46].",1,neutral
"In optimization-based approaches, the model takes many [51, 46, 5] or few [9, 52, 2] gradient steps on the context examples, and the updated model then classifies the target examples.",1,neutral
", 2016), CIFAR-FS (Bertinetto et al., 2019), FC100 (Oreshkin et al.",1,neutral
"Established episodic evaluation benchmarks range in scale and domain diversity from Omniglot (Lake et al., 2015) to mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), FC100 (Oreshkin et al., 2018), and tieredImageNet (Ren et al., 2018).",2,positive
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al.",2,positive
…approach used both in multi-task learning Argyriou et al. (2008); Caruana (1997); Jacob et al. (2009) and meta-learning Balcan et al. (2019); Bertinetto et al. (2018); Bullins et al. (2019); Denevi et al. (2019b); Finn and Levine (2018); Finn et al. (2019); Maurer (2009); Pentina and…,1,neutral
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al.",2,positive
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al. (2020); Yao et al. (2019) and propose a so-called…",2,positive
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al.",2,positive
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al.",2,positive
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al.",2,positive
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al.",2,positive
"Bertinetto et al. (2018); Finn et al. (2017)) and develop more efficient versions of our method, using less expensive algorithms to update the positive matrices, such as the Frank-Wolfe algorithm used in Bullins et al.",1,neutral
"In particular it will be valuable to investigate how to predict non-linear conditioning functions (similarly to e.g. Bertinetto et al. (2018); Finn et al. (2017)) and develop more efficient versions of our method, using less expensive algorithms to update the positive matrices, such as the…",1,neutral
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al. (2020); Yao et al. (2019) and propose a so-called conditional meta-learning approach for meta-learning a representation.",2,positive
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al. (2020); Yao et al.",2,positive
"To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al. (2020); Yao et al. (2019) and propose a so-called conditional meta-learning approach for meta-learning a representation. Our algorithm learns a conditioning function mapping available tasks’ side information into a linear representation that is tuned to that task at hand. Our approach borrows from Denevi et al. (2020), where the authors proposed a conditional meta-learning approach for fine tuning and biased regularization.",2,positive
"Existing few-shot learning methods based on data augmentation [11], [12], [13], metric learning [14], [15], [16], and initialization [17], [18], [19] ameliorate the models in terms of supervised empirical growth, hypothesis space reduction, and initial parameter setting, respectively, so as to enhance the generalization ability of the models under the premise of inadequate training data.",2,positive
"Specifically, compared with global-level metriclearning based methods (i.e., Relation Networks [6], Prototypical Networks [5] and Fine-tuning [23]), MML is 20.3% and 3.5% better than the best one of them on CIFAR-FS and FC100 under 5-way 5-shot setting.",2,positive
"Table 4 evaluates our method on two CIFAR derivatives, i.e., CIFAR-FS and FC100.",2,positive
CIFAR derivatives: Both CIFAR-FS [16] dataset and FC100 [17] dataset are subsets of CIFAR-100.,2,positive
RR-dual-cls [2] develops a closed-form solution of RR in dual space for a more discriminative classifier considering the stepwise optimization negates the chances of the model reaching its optimal.,1,neutral
"Following the state-of-the-art approaches in FSL, the optimization-based few-shot learners can be implemented as either as a stepwise gradient descender (GD) [15, 37] or a differentiable quadratic programming (QP) solver [24, 2], which can be further inserted into network as a layer enabling an end-to-end training with feature extractor.",2,positive
"For CIFAR-FS, FC100, miniImageNet, tieredImageNet datasets we set the initial learning rate to 0.05 and use a weight decay of 5e − 4.",2,positive
Two of these datasets are subset of the CIFAR100 dataset: CIFAR-FS [4] and FC100 [50].,2,positive
"Implementation Details: Following [72, 46, 50, 40], we use a ResNet-12 network as our base learner to conduct experiments on CIFAR-FS, FC100, miniImageNet, tieredImageNet datasets.",2,positive
"Effect of the number of Transformations: To investigate the effect of the total number of applied transformations, we perform an ablation study on the CIFAR-FS validation set by varying the number of transformations, M .",2,positive
"However, unlike [15], which achieves the current best results on the CIFAR-FS 1-shot task, we do not perform any transductive fine-tuning.",2,positive
"To be more specific, our method outperforms the current best results on CIFAR-FS dataset (Table 1) by 1.3% in the 1-
shot task whereas for the 5-shot task it improves the score by 2.8%.",0,negative
"To study the contribution of different components of our method we do a thorough ablation study on three bench-
mark FSL datasets: miniImageNet, CIFAR-FS, and FC100 (Table 6).",2,positive
"Ridge regression differentiable discriminator [9] and meta-learning with differentiable convex optimization [45] find a global optimum linear projection for quick adaptation in meta-learning, although they consider classification tasks, and solves a linear",1,neutral
R2D2 was ridge regression differentiable discriminators [9].,1,neutral
least square problem [9] or a convex optimization problem [45].,1,neutral
"The contrasted ones include MAML [16], Matching networks [60], IMP [1], Prototypical networks [54], TAML [26], SAML [19], GCR [34], KTN (Visual) [46], PARN [61], Dynamic few-shot [17], Relation networks [56], R2D2 [4], SNAIL [40] and AdaResNet [42].",2,positive
"In particular, for the cifar-M and FC-M datasets, the ValGen ranking of algorithm snapshots seems to be only weakly correlated with the true meta-test ranking for all the meta-learning methods.",1,neutral
"(miniImageNet, CIFAR-FS, FC-100), only 20 novel classes are used for meta-testing.",2,positive
"Here the original 600 examples of each base class are still only used for meta-training. ii) CIFAR-FS-Mod (cifar-M) [30], FC-100-Mod (FC-M) [4], and tieredImageNet-Mod (tiered-M) [33]: As we don’t have additional samples for base classes, we randomly partition each base class’s current examples into an approximate 80/20 split where the training tasks are constructed using the former and the latter is reserved for ID evaluation.",2,positive
"ii) CIFAR-FS-Mod (cifar-M) [30], FC-100-Mod (FC-M) [4], and tieredImageNet-Mod (tiered-M) [33]: As we don’t have additional samples for base classes, we randomly partition each base class’s current examples into an approximate 80/20 split where the training tasks are constructed using the former and the latter is reserved for ID evaluation.",2,positive
"A plethora of few-shot image classification benchmarks (e.g., miniImageNet (mini in short) [42], CIFAR-FS [4]) have been developed for FSL evaluation.",2,positive
", miniImageNet (mini in short) [42], CIFAR-FS [4]) have been developed for FSL evaluation.",2,positive
"We evaluate the ID performance of four popular meta-learning methods: Prototypical Networks (PN) [39], MetaOptNet-SVM (SVM) [25], MetaOptNet-Ridge Regression (RR) [25, 4] and FOMAML [15] on our identified ID FSL benchmarks (Table 1).",2,positive
"Another issue that may cause some to view the current FSL benchmarks as performing ID evaluation is that in some of these benchmarks, the base, val, novel classes are random partitions of iid drawn classes from a class level distribution (specifically miniImageNet, CIFAR-FS; but not FC-100, tieredImageNet as the classes are not partitioned randomly).",2,positive
"Based on these two trends, for more reliable comparisons of meta-learning methods’ OOD performance we suggest using datasets like tieredImageNet and MetaDataset (both with much larger set of base and novel classes) in addition to the smaller benchmarks like miniImageNet, CIFAR-FS, and FC-100, which some recent works [e.g., 30, 4] still solely rely upon.",2,positive
"In practice, because 1) we never specify exactly what and how big the underlying set of classes that we care about is, and 2) some of the recent meta-learning methods (SVM vs PN on cifar in Table 2 of [25], R2-D2 vs GNN on mini in Table 1 of [4], FIX-ML [38]) sometimes only improve over the prior works by < 1%, we believe researchers should be aware of the possibility of getting a performance conclusion that is inconsistent over a single randomly chosen and fixed set of 20 novel classes used by some of these benchmarks.",2,positive
"We also test our proposed methods on CIFAR-FS (Bertinetto et al., 2018), which is an image classification dataset containing 64 classes of training data and 20 classes of evaluation data.",2,positive
"We also test our methods on CIFAR-FS (Bertinetto et al., 2018) and Omniglot (Lake et al., 2015), and provide the results in Table 5 and Figure S3, respectively (more details can be viewed in Appendix 6 and Appendix 7).",0,negative
"Table S2: SA/RA performance of our proposed methods on CIFAR-FS (Bertinetto et al., 2018) (1-Shot 5-",2,positive
"There are 1028 classes of training data and 423 classes of evaluation
Table S3: SA/RA performance of our proposed methods on CIFAR-FS (Bertinetto et al., 2018) (5-Shot 5-",0,negative
"We also test our methods on CIFAR-FS (Bertinetto et al., 2018) and Omniglot (Lake et al.",2,positive
"Table 5: SA/RA performance of our proposed methods on CIFAR-FS (Bertinetto et al., 2018).",2,positive
"(15) as the nonconformity measure for label y = j.
Differentiable ridge regression (Bertinetto et al., 2019).",1,neutral
"Our meta nonconformity measure consists of a few-shot, closed-form ridge regressor (Bertinetto et al., 2019) on top of a directed Message Passing Network molecular encoder (Yang et al., 2019).5",2,positive
"…a popular approach to transferring knowledge gained from auxiliary tasks—e.g., via featurizations or statistics (Edwards & Storkey, 2017)— to a target task that is otherwise resource-limited (Vinyals et al., 2016; Finn et al., 2017; Snell et al., 2017; Bertinetto et al., 2019; Bao et al., 2020).",1,neutral
", via featurizations or statistics (Edwards & Storkey, 2017)— to a target task that is otherwise resource-limited (Vinyals et al., 2016; Finn et al., 2017; Snell et al., 2017; Bertinetto et al., 2019; Bao et al., 2020).",1,neutral
"Our meta nonconformity measure consists of a few-shot, closed-form ridge regressor (Bertinetto et al., 2019) on top of a directed Message Passing Network molecular encoder (Yang et al.",2,positive
"The former learns a generative metric to compare andmatch few-examples [2, 25, 28].",1,neutral
The performance of the stated methods was measured based on standardised few-shot classification datasets CIFAR-FS (Bertinetto et al. 2019) and CUB (Wah et al. 2011).,0,negative
"Note that the above quadratic subclass also covers a large collection of applications such as few-shot meta-learning with shared embedding model (Bertinetto et al., 2018) and biased regularization in hyperparameter optimization (Grazzi et al.",1,neutral
"…y) ≡ H, ∇x∇yg(x, y) ≡ J, ∀x ∈ X , y ∈ Rd. (4)
The condition of g(x, y) in Assumption 2 covers a large collection of applications such as few-shot metalearning (Bertinetto et al., 2018) and biased regularization in hyperparameter optimization (Grazzi et al., 2020), where the inner-level problem…",1,neutral
"We also evaluate the effectiveness of illumination feature augmentation on standardized one/few-shot image classification datasets: miniImageNet [18], CUB [19] and CIFAR-FS [20].
miniImageNet [18] is introduced by Vinyals et al. in [18] for small sample learning research for the first time.",2,positive
"4) Generalized one/few-shot image classification on miniImageNet, CUB and CIFAR-FS
Since our method requires template images for the separation of features, the model can not be directly trained on natural image datasets without regular templates such as ImageNet.",2,positive
CIFAR-FS [20] is randomly sampled from CIFAR-100 [21] by using the same criteria with which miniImageNet has been generated.,2,positive
"We also evaluate the effectiveness of illumination feature augmentation on standardized one/few-shot image classification datasets: miniImageNet [18], CUB [19] and CIFAR-FS [20].",2,positive
"To stress the genericity of the illumination repository, we perform experiments on standardized few-shot classification datasets: miniImageNet [18], CUB [19] and CIFAR-FS [20].",2,positive
"3) We evaluate Sill-Net on several object classification benchmarks, i.e., two traffic datasets (GTSRB and TT100K), three logo datasets (Belgalogos, FlickrLogos32, and TopLogo-10) and three generalized one/few-shot benchmarks (miniImageNet, CUB, CIFAR-FS).",2,positive
"Our theory applies to regression problems, and assumes a limited number of tasks where data is independently drawn in each task, while some applications use a large number of tasks with correlated draws (for example, images may be shared across tasks in few-shot image classification, see Bertinetto et al. (2019)).",1,neutral
"…to regression problems, and assumes a limited number of tasks where data is independently drawn in each task, while some applications use a large number of tasks with correlated draws (for example, images may be shared across tasks in few-shot image classification, see Bertinetto et al. (2019)).",1,neutral
"In this context, metalearning received increased attention in the past few years, several new benchmarks have been introduced, and a large number of algorithms and models have been proposed to solve them (Vinyals et al. (2017), Bertinetto et al. (2019), Triantafillou et al. (2020)).",2,positive
"Then we evaluate our model and make comparisons to related work on four few-shot classification benchmark datasets: miniImageNet [36], tieredImageNet [29], CIFAR-FS [1], Fewshot-CIFAR100 (FC100) [25].",2,positive
The CIFAR-FS dataset is a recently proposed few-shot image classification benchmark derived from CIFAR.,2,positive
"We observe that the relative improvement rate on the CIFAR-FS dataset is larger compared to the FC100 dataset which is similar to generalization pattern on the Im-
ageNet derivatives.",2,positive
Our model achieves comparable performance on all tasks in both CIFAR-FS and FC100 benchmark.,2,positive
"In addition, we also analyze the result of the number of items in the component dictionary D, map dictionary S.
Table 3 shows the result of our ablation studies on miniImageNet, tieredImageNet, CIFAR-FS and FC100.",2,positive
Table 2 summarizes the performance on the 5- way CIFAR-FS and FC100.,0,negative
"Optimization based methods [4, 14, 27] learn representations that lead to generalizable models measured using pre-defined classification model, objective, or a training procedure.",1,neutral
"Meanwhile, partial experimental results on the CIFAR-FS dataset dropped slightly, the reason of which might lie in the categories in the CIFAR-FS dataset are highly distinguishable.",0,negative
"To evaluate our module, we select two GNN-based few-shot models: EGNN and DPGN, and four standard few-shot learning benchmarks: mini-ImageNet [28], tiered-ImageNet [30], CUB-200-2011 [31] and CIFAR-FS [32].",2,positive
"We conducted extensive experiments on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB-200-2011, and CIFAR-FS.",2,positive
"Experimental results demonstrate that it improves the performance of recently proposed GNNbased methods on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB-200-2011, and CIFAR-FS.",2,positive
"Our results on CIFAR-FS (Table 1) and miniImageNet (Table 2) show that, on its own, the rotation prediction pretext task limits the generality of the learned representations, significantly lagging behind in few-shot accuracy.",2,positive
"Initial experimental results showed that BYOL on its own could only achieve 47.09±0.96% accuracy on CIFAR-FS, which is significantly lower than the results reported in Table 1.",0,negative
"On both CIFAR-FS (Table 1) and miniImageNet (Table 2), we find that stronger data augmentation improves the supervised baseline.",2,positive
"As noted in §4.1, we changed the learning schedule for CIFAR-FS but did not do so for miniImageNet.",0,negative
"In this section, we evaluate our proposed multi-task framework on two widely used few-shot image recognition benchmarks: miniImageNet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2018).",2,positive
"On CIFAR-FS, we report an accuracy of 82.19± 0.83% for this run, compared to 82.51± 0.82% when using τ = 0.99 on the same seed.",0,negative
Note that the performance gap between BYOL and the supervised baseline on miniImageNet is bigger than the one observed on CIFAR-FS.,2,positive
"All models are trained for 90 epochs on CIFAR-FS with a decay step at epochs 45, 60 and 75, except when BYOL is used (alone or in combination with other tasks).",0,negative
"On CIFAR-FS, our multi-task framework outperforms previous works by at least 1.5%.",2,positive
"On CIFAR-FS, we explore different combinations of tasks for our multi-task framework of Figure 1.",2,positive
"The CIFAR-FS dataset (Bertinetto et al., 2018) is derived from the original CIFAR-100 dataset by randomly splitting 100 classes into 64 classes for training, 16 for validation and 20 for testing.",2,positive
"Based on our detailed experiments on CIFAR-FS and miniImageNet, we show that leveraging self-supervision improves transfer learning performance on novel classes.",2,positive
", CNN-based relation modules [51, 59], ridge regression [4], and graph neural networks [43, 17, 61]).",1,neutral
"Grad-CAM is formed by weighted summation of feature maps, which can show the importance of each area to its classification.",1,neutral
"In order to further evaluate the effectiveness of our method, we apply Grad-CAM [27] to visualize the images of the CUB200-2011 dataset.",2,positive
"In order to further evaluate the effectiveness of our method, we apply Grad-CAM [33] to visualize the images of the CUB-200-2011 dataset.",2,positive
"We perform our experiments on four benchmark datasets: MiniImageNet [10] denoted MINet, CUB [11], CIFAR-FS [12] and TieredImageNet [13] denoted TINet.",2,positive
"We perform our experiments on 3 standardized few-shot classification datasets: miniImageNet [11], CUB [32] and CIFAR-FS [16].",2,positive
"CIFAR-FS: This dataset has 100 classes, each class contains 600 images of size 32 × 32 pixels.",2,positive
"In [15] and [16], the authors create a classweight generator by training the model with a linear classifier (e.",1,neutral
"CIFAR-FS [3] was created by randomly sampling from CIFAR-100 [27] by using the same criteria as miniImageNet (100 classes with 600 images per class, split into folds of 64/16/20 for meta-train/val/test).",2,positive
"Results Table 1-3 summarize the results onminiImageNet, tieredImageNet and CIFAR-FS.",0,negative
"For example, many have relied on episodic training schemes [52, 59], where few-shot learning problems are simulated at each iteration of training; differentiable optimisers [3, 30], or new neural network modules [55, 15]",1,neutral
"There exist approaches for directly back-propagation through the solution z∗ for convex problems such as (2b) using the implicit function theorem [18, 33] or closed-from expressions [5].",1,neutral
Model/Experiment 2 way accuracy 1-shot 5-shot MAML[23] 82.,0,negative
Model/Experiment 5 way accuracy 1-shot 5-shot MAML[23] 58.,0,negative
Table I shows the results of 5-way classifcation tasks at CIFAR-FS [1] and FC100 [8].,1,neutral
† denotes CIFAR-FS results taken from [1] and FC100 results taken from [8].,0,negative
"For CIFAR-CS, the classes are divided into 64, 16 and 20 classes for meta-training, metavalidation, and meta-testing respectively.",2,positive
"…base our implementation on the publicly available code of (Tian et al., 2020b) and conduct experiments on four popular few-shot classification benchmarks: mini-ImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFAR-CS (Bertinetto et al., 2019) and FC100 (Oreshkin et al., 2018).",2,positive
"For the experimental section, we base our implementation on the publicly available code of [43] and conduct experiments on ImageNet derivatives: mini -ImageNet [47] and tiered -ImageNet [33], and CIFAR-100 derivatives: CIFAR-CS [2] and FC100 [28].",2,positive
"For the experimental section, we base our implementation on the publicly available code of (Tian et al., 2020b) and conduct experiments on four popular few-shot classification benchmarks: mini-ImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFAR-CS (Bertinetto et al., 2019) and FC100 (Oreshkin et al., 2018).",2,positive
"CIFAR-CS (Bertinetto et al., 2019)
and FC100 (Oreshkin et al., 2018) are both CIFAR-100 (Krizhevsky et al., 2010) derivatives, containing 100 classes and images of size 32×32.",2,positive
"CIFAR-FS [2] contains 100 classes with the class split for (64,16,20).",1,neutral
"We further conduct FSOR experiments on two fewshot benchmark datasets: CIFAR-FS [2], FC100 [29].",2,positive
"We benchmark our models on miniImageNet, CIFAR-FS, and tieredImageNet, and show that NCA fairs surprisingly well against methods that use meta-learning and also against recent highperforming baselines which pre-train with the cross-entropy loss.",2,positive
Results for CIFAR-FS can be found in Fig.,2,positive
"Without bells and whistles, our implementation of the NCA loss achieves an accuracy that is competitive with the state-of-the-art on multiple FSL benchmarks: miniImageNet, CIFAR-FS and tieredImageNet.",2,positive
"We conduct our experiments on miniImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019) and tieredImageNet (Ren et al., 2018), using the ResNet12 variant first adopted by Lee et al. (2019) as embedding function fθ.",2,positive
3.4 on miniImageNet and CIFAR-FS.,2,positive
", 2016), CIFAR-FS (Bertinetto et al., 2019) and tieredImageNet (Ren et al.",2,positive
"Optimization-based methods attempt to learn model parameters that are able to adapt fast in novel tasks [12, 47, 68, 48, 40, 30, 6].",1,neutral
", 2017), and optimization-based meta-learners that embed an optimization procedure into the meta-learner (Finn et al., 2017; Li et al., 2017b; Rusu et al., 2018; Zintgraf et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Lee et al., 2019; Yoon et al., 2018; Finn et al., 2018).",1,neutral
"…et al., 2017), and optimization-based meta-learners that embed an optimization procedure into the meta-learner (Finn et al., 2017; Li et al., 2017b; Rusu et al., 2018; Zintgraf et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Lee et al., 2019; Yoon et al., 2018; Finn et al., 2018).",1,neutral
"Besides, many strategies such as Convolutional Neural Networks (CNN) [6], Ridge Regression, and Logistic Regression [7] and k-NearestNeighbors (k-NN) [8] are proposed for metric learning.",1,neutral
This formulation is owed to the Woodbury Identity [24] as applied in [4]:,1,neutral
", 2018) or apply faster adaptation (Bertinetto et al., 2018; Zintgraf et al., 2019; Rajeswaran et al., 2019) through meta-training.",2,positive
"Another direction is to learn how to better initialize parameters for new classes (Finn et al., 2017; Finn et al., 2018) or apply faster adaptation (Bertinetto et al., 2018; Zintgraf et al., 2019; Rajeswaran et al., 2019) through meta-training.",2,positive
"Meta-learning methods: We focus our initial experiments on protoypical-networks (PN) [25] which uses a non-parametric last layer solver, as Protonets is a highly competitive ML approach, and also has the benefit of training faster and with less memory than competitors such as SVM [17], Ridge Regression (RR) [3].",2,positive
"validation and 20 test, and (ii) CIFAR-FS (cifar) [3] with an identical split but with 32× 32 images.",2,positive
"Recently, last-layer meta-learning methods [3, 17, 21, 25] have gained popularity.",1,neutral
"Here, distancebased approaches [3, 21, 34, 39, 40, 49, 64, 67, 70, 73, 80, 84, 87] aim at transferring the reduced intra-class variation from base to novel classes, while initialization-based approaches [18, 19, 35] are designed to carry the best starting model configuration for novel class training.",2,positive
"Here, distance-based approaches [3, 17, 28, 32, 33, 43, 57, 59, 62, 65, 72, 75, 78] aim at transferring the reduced intra-class variation from base to novel classes, while initialization-based approaches [14, 15, 29] are designed to carry the best starting model configuration for novel class training.",2,positive
4) FC 100 [3] is also derived from CIFAR100 [26].,1,neutral
3) CIFAR FS [3] is a few-shot learning dataset that contains all 100 classes from CIFAR100 [26].,2,positive
"In metatest stage, these models are evaluated in the same way their authors originally did [4,2,13,14].",1,neutral
"In the experiment, we build our method on the top of several state-of-the-art meta-learning methods, including Prototypical Network, Matching Network, Prototypical Matching Network and Ridge Regression Differentiable Discriminator [4,2,13,14].",2,positive
"state-of-the-art meta-learning algorithms as our base meta-learning methods in our experiments: Prototypical Network (PN) [2], Matching Network (MN) [4], Prototype Matching Network (PMN) [13] and Ridge Regression Differentiable Discriminator (R2D2) [14].",2,positive
The same setting is also mentioned in other mainstream few-shot methods [14].,1,neutral
"We evaluate the models using query sets and support sets constructed in the same way as their authors originally did [4,2,13,14].",1,neutral
", [37, 5]) is that we only have a single source task and a single target task.",1,neutral
"[5] speeds up the implementation of MAML [10] with closed-form solution of the inner loop, which is a technique that we also use.",1,neutral
"Such popularity led to a surge of MAML-based variants [2, 3, 9, 10, 11, 13, 14, 25, 26, 27, 30, 37, 39, 41, 42, 44], where they try to resolve the known issues of MAML, such as (meta-level) overfitting.",1,neutral
"[3]) on miniImageNet and tieredImageNet, along with comparisons to the other state-of-the-art metalearning algorithms for few-shot learning.",2,positive
"Following this trend, many recent studies [3, 9, 11, 30, 39, 41] focused on learning a better initialization.",1,neutral
46% MAML + L2F [3] 4-CONV 52.,1,neutral
"This makes learning tasks from new different domains difficult, as suggested in [3].",1,neutral
Differentiable convex optimization: Recent works have considered the meta-learning setup of differentiating through a convex solver in the setting of few-shot learning Bertinetto et al. (2018); Lee et al. (2019b).,1,neutral
"Other related work has attempted to devise loss functions to learn more transferable embeddings for few-shot learning [62, 65, 7, 15, 49], but embeddings of models trained with softmax cross-entropy often perform on par with these more sophisticated techniques [68].",1,neutral
"We specifically run each experiment setting with the three popular representation learning protocols - ProtoNet [21], Ridge [24] and MetaOptNet (SVM) [23].",2,positive
"We consider three popular approaches from the robust-representation view of the meta-learning paradigm, termed ProtoNet [21], Ridge [24] and MetaOptNet [23].",2,positive
"Task classifier could be a nearest neighbour (ProtoNet [21]), linear regression (Ridge [24]) or linear SVM (MetaOptNet [23]).",1,neutral
"Generally, max-margin classifiers such as SVM tend to outperform nearest neighbor distance based approaches, we find
(a) Fluent Speech Commands (b) Google Commands
Figure 3: The confusion matrix is mean computed for 5-shot classification task over 1000 test episodes.
that the performance of ProtoNet is often superior to SVM. Similarly, a closed-form solution of Ridge may be more sensitive to noise than ProtoNet leading to lower performance.",1,neutral
"Google Commands Fluent Speech Commands 5-Shot 1-Shot 5-Shot 1-ShotModel
SPO No-SPO SPO No-SPO SPO No-SPO SPO No-SPO Val 85.45 ± 0.32 83.48 ± 0.35 71.07 ± 0.52 70.61 ± 0.53 83.55 ± 0.38 68.57 ± 0.45 70.42 ± 0.55 56.14 ± 0.56ProtoNet [21] Test 89.63 ± 0.27 78.86 ± 0.40 74.35 ± 0.50 69.30 ± 0.54 78.86 ± 0.40 78.00 ± 0.39 65.61 ± 0.52 64.24 ± 0.52 Val 82.38 ± 0.34 81.33 ± 0.35 68.49 ± 0.51 68.03 ± 0.51 81.47 ± 0.39 67.75 ± 0.42 70.56 ± 0.51 56.69 ± 0.55Ridge [24] Test 89.11 ± 0.29 86.17 ± 0.31 75.05 ± 0.48 76.34 ± 0.49 75.75 ± 0.40 78.51 ± 0.39 61.64 ± 0.53 60.84 ± 0.51 Val 76.31 ± 0.39 83.48 ± 0.35 62.90 ± 0.51 60.50 ± 0.51 78.52 ± 0.43 65.90 ± 0.46 67.68 ± 0.53 52.77 ± 0.53MetaOptNet [23] Test 84.37 ± 0.32 88.64 ± 0.29 66.61 ± 0.53 70.82 ± 0.50 70.16 ± 0.43 69.84 ± 0.44 58.71 ± 0.50 59.44 ± 0.51
is trained with all the available training data in an end-to-end fashion.",0,negative
"Task independent learning, or learning to learn is a popular paradigm of machine learning termed meta-learning [22, 18, 23, 24, 21, 25].",1,neutral
"42% on the 5-way 1-shot setting, surpassing the second best R2D2 [4] by 1.",0,negative
"Datasets and settings We evaluate our model on four standard few-shot classification tasks: miniImageNet [71], tieredImageNet [53], CIFAR-FS [4] and Omniglot [33].",2,positive
"The third group explicitly learns a base-learner that incorporates knowledge acquired by the meta-learner and effectively solves individual tasks [20, 4, 81].",1,neutral
"On CIFAR-FS, our model delivers 63.42% on the 5-way 1-shot setting, surpassing the second best R2D2 [4] by 1.12%.",0,negative
"(b) CIFAR-FS [19] has 100 object classes, split into 64, 16, and 20 for training, validation and test sets, respectively.",2,positive
"Overall, our approach achieves faster convergence and performs better classification datasets, including miniImageNet, tieredImageNet, and CIFAR-FS.",2,positive
"Similarly, on the CIFAR-FS dataset, our method achieves state-of-the-art performance compared to the family of MAML algorithms.",2,positive
Table 2 Few-shot learning results on CIFAR-FS [19] and tieredImageNet [20] datasets.,2,positive
"Methods miniImageNet, 5-way CIFAR-FS, 5-way tieredImageNet, 5-way1-shot 5-shot 1-shot 5-shot 1-shot 5-shot
MAML [5] 48.70 ± 1.84 63.11 ± 0.92 58.9 ± 1.9 71.5 ± 1.9 51.67 ± 1.87 70.30 ± 1.75 MAML++ [2] 52.15 ± 0.26 68.32 ± 0.44 - - FOMAML [5] 48.07 ± 1.75 63.15 ± 0.91 55.6 ± 0.9 70.2 ± 0.7 47.37 ± 0.80 66.12 ± 0.79 Reptile [14] 49.97 ± 0.32 65.99 ± 0.58 - - Meta-LSTM [17] 43.44 ± 0.77 60.60 ± 0.71 43.4 ± 0.8 60.6 ± 0.7 - - Meta-SGD [13] 50.47 ± 1.87 64.03 ± 0.94 56.9 ± 0.9 70.1 ± 0.7 50.92 ± 0.93 69.28 ± 0.80 iMAML-HF [16] 49.30 ± 1.88 - - - MT-Net [12] 51.70 ± 1.84 - - - R2D2 [3] 49.50 ± 0.20 65.40 ± 0.20 62.3 ± 0.2 77.4 ± 0.2 - - L-MAML [4] 49.40 ± 1.83 - - - HSML [22] 50.38 ± 1.85 - - -
PAMELA 53.50 ± 0.89 70.51 ± 0.67 63.5 ± 0.9 79.1 ± 0.7 54.81 ± 0.88 74.39 ± 0.71
Figure 3: Few-shot learning results on miniImageNet [17], CIFAR-FS [3] and tieredImageNet [18] datasets.",0,negative
"For experiments on miniImageNet, CIFAR-FS and tieredImageNet, we use a four-layer convolutional neural network, each with 64 filters.",2,positive
"We combined training data generating networks with two meta learning approaches (R2D2 (Bertinetto et al., 2019) and MetaOptNet (Lee et al.",2,positive
"However, as we discussed above, differentiable optimization methods (Bertinetto et al., 2019; Lee et al., 2019) are generally better than hypernetworks.",2,positive
"(2)
This process is done by a base learner (machine learning algorithm) in some meta learning methods (Bertinetto et al., 2019; Lee et al., 2019).",1,neutral
"The formulation of few-shot learning we use here is similar to Lee et al. (2019); Bertinetto et al. (2019), but also other formulations of few shot learning exist, e.g., MAML (Finn et al., 2017).",1,neutral
"Recent meta learning approaches use differentiable learners, e.g., R2D2 (Bertinetto et al., 2019) uses Ridge Regression and MetaOptNet (Lee et al., 2019) uses Support Vector Machines (SVM).",1,neutral
"Different than the learner in R2D2 and MetaOptNet, we use kernelized algorithms.",2,positive
"R2D2 (Bertinetto et al., 2019) showed that using a light-weight and differentiable base learner (e.",1,neutral
", R2D2 (Bertinetto et al., 2019) uses Ridge Regression and MetaOptNet (Lee et al.",1,neutral
"We combined training data generating networks with two meta learning approaches (R2D2 (Bertinetto et al., 2019) and MetaOptNet (Lee et al., 2019)) in our framework.",2,positive
"R2D2 (Bertinetto et al., 2019) showed that using a light-weight and differentiable base learner (e.g. ridge regression) leads to better results.",1,neutral
"(2) This process is done by a base learner (machine learning algorithm) in some meta learning methods (Bertinetto et al., 2019; Lee et al., 2019).",1,neutral
Bertinetto et al. (2019) showed that using a light-weight and differentiable base learner (e.,1,neutral
Bertinetto et al. (2019) showed that using a light-weight and differentiable base learner (e.g. ridge regression) leads to better results.,1,neutral
"Bertinetto et al. (2019) showed that using a light-weight and differentiable base learner (e.g. ridge regression) leads to better results. To further developing the idea, Lee et al. (2019) used multi-class support vector machine (Crammer & Singer (2001)) as base learner and incorporated differentiable optimization (Amos & Kolter (2017); Gould et al.",1,neutral
"…to the parameters of the last linear layer of a neural network and φ are the parameters of the remaining layers (e.g., 4 convolutional layers in Bertinetto et al. 2018; Ji et al. 2020a), and hence the lowerlevel function is strongly-convex w.r.t. w̃ and the upper-level function LD(φ, w̃∗(φ))…",1,neutral
"…attention recently and become an influential framework in various machine learning applications including metalearning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyperparameter
1Department of Electrical and Computer Engineering, The Ohio…",2,positive
"Bilevel optimization has received significant attention recently and become an influential framework in various machine learning applications including metalearning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyperparameter",1,neutral
"…to the parameters of the last linear layer of a neural network and φ are the parameters of the remaining layers (e.g., 4 convolutional layers in Bertinetto et al. (2018); Ji et al. (2020a)), and hence the lower-level function is strongly-convex w.r.t. w̃ and the upper-level function LD(φ,…",1,neutral
"1 Introduction Bilevel optimization has received significant attention recently and become an influential framework in various machine learning applications including meta-learning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyper-parameter optimization (Franceschi et al.",1,neutral
"…attention recently and become an influential framework in various machine learning applications including meta-learning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyper-parameter optimization (Franceschi et al., 2018; Shaban et al., 2019;…",1,neutral
"1 Introduction Bilevel optimization has received significant attention recently and become an influential framework in various machine learning applications including meta-learning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyperparameter optimization (Franceschi et al.",1,neutral
", 4 convolutional layers in Bertinetto et al. (2018); Ji et al.",1,neutral
"We perform our experiments on the mini-ImageNet and CIFAR-FS datasets [2, 22].",2,positive
"R2-D2 and MetaOptNet instead use differentiable solvers with a ridge regression and SVM head, respectively.",2,positive
"As we increase m and include a large number of augmentations in the pool, we observe performance boosts as high as 4% over the baseline, which uses horizontal flip, random crop, and color jitter data augmentations from the original work corresponding to the R2-D2 meta-learner used [2].",2,positive
We empirically evaluate the performance of all four different augmentation modes identified in Section 3.1 on the CIFAR-FS dataset using an R2-D2 base-learner paired with both a 4-layer CNN backbone (as used in the original work) and a ResNet-12 backbone.,2,positive
"To this end, we plot the training and validation accuracy over time for R2-D2 metalearners with ResNet-12 backbones using baseline augmentations, query Self-Mix, and Meta-MaxUp with a medium sized pool and m = 4.",2,positive
"“CNN-4” denotes a 4-layer convolutional network with 96, 192, 384, and 512 filters in each layer [2].",1,neutral
"Existing frameworks for few-shot image classification use only horizontal flips, random crops, and color jitter to augment images in a way that parallels augmentation for conventional training [2, 14].",1,neutral
"We conduct experiments on four meta-learning algorithms: ProtoNet [21], R2-D2 [2], MetaOptNet [14], and MCT [13].",2,positive
"In this section, we improve the performance of four different popular meta-learning methods including ProtoNet [21], R2-D2 [2], MetaOptNet [14], and MCT [13].",2,positive
"There is a line of works that analyzed the theoretical properties of meta-learning (Denevi et al., 2019; Finn et al., 2019; Khodak et al., 2019; Lee et al., 2019; Bertinetto et al., 2018).",1,neutral
"Moreover we report the results of ADKL (Tossou et al., 2019), R2-D2 (Bertinetto et al., 2019), and ALPaCA (Harrison et al., 2018) obtained on a similar task (as defined in Yoon et al., 2018).",2,positive
", 2019), R2-D2 (Bertinetto et al., 2019), and ALPaCA (Harrison et al.",1,neutral
"Method in-range out-of-range Periodic functions ADKL (Tossou et al., 2019)∗ 0.14 – R2-D2 (Bertinetto et al., 2019)∗ 0.46 – ALPaCA (Harrison et al., 2018) 0.14 ± 0.09 5.92 ± 0.11 Feature Transfer/1 2.94 ± 0.16 6.13 ± 0.76 Feature Transfer/100 2.67 ± 0.15 6.94 ± 0.97 MAML (1 step) 2.76 ± 0.06 8.45 ± 0.25 DKBaseline + RBF 2.85 ± 1.14 3.65 ± 1.63 DKBaseline + Spectral 2.08 ± 2.31 4.11 ± 1.92 DKT + RBF (ours) 1.38 ± 0.03 2.61 ± 0.16 DKT + Spectral (ours) 0.08 ± 0.06 0.10 ± 0.06 Head pose trajectory Feature Transfer/1 0.25 ± 0.04 0.20 ± 0.01 Feature Transfer/100 0.22 ± 0.03 0.18 ± 0.01 MAML (1 step) 0.21 ± 0.01 0.18 ± 0.02 DKT + RBF (ours) 0.12 ± 0.04 0.14 ± 0.03 DKT + Spectral (ours) 0.10 ± 0.01 0.11 ± 0.02
We consider two tasks: amplitude prediction for unknown periodic functions, and head pose trajectory estimation from images.",0,negative
"Method in-range out-of-range Periodic functions ADKL (Tossou et al., 2019)∗ 0.14 – R2-D2 (Bertinetto et al., 2019)∗ 0.46 – ALPaCA (Harrison et al., 2018) 0.14 ± 0.09 5.92 ± 0.11 Feature Transfer/1 2.94 ± 0.16 6.13 ± 0.76 Feature Transfer/100 2.67 ± 0.15 6.94 ± 0.97 MAML (1 step) 2.76 ± 0.06 8.45 ±…",1,neutral
"ADKL, R2-D2, and ALPaCA (0.14, 0.46, 0.14) are better than DKT with an RBF kernel (1.38), but worse than DKT with a Spectral kernel (0.08).",1,neutral
"There is a line of works analyzed the theoretical properties of meta-learning [Denevi et al., 2019; Finn et al., 2019; Khodak et al., 2019; Lee et al., 2019; Bertinetto et al., 2018].",1,neutral
"2018), CIFAR-FS (Bertinetto et al. 2018), and FC100 (Oreshkin, López, and Lacoste 2018) (See our Supplementary for more detailed introduction).",2,positive
"For few-shot image classification, we conduct experiments on four public benchmark datasets: miniImageNet [Vinyals et al., 2016], tiered-ImageNet [Ren et al., 2018], CIFAR-FS [Bertinetto et al., 2018], and FC100 [Oreshkin et al., 2018].",2,positive
"Compared to Meta-Base [Chen et al., 2020], our Meta-UAFS achieves significant improvement of 1.12%, 1.41%, 1.72%, and 1.76% in 1-shot accuracy on mini-ImageNet, tiered-ImageNet, CIFAR-FS, and FC00, respectively for 1-shot classification.",2,positive
"Ridge regression differentiable discriminator (R2-D2) [5] is a neural network-based meta-learning method, where the last layer is adapted by solving a",1,neutral
"Lastly, R2-D2, LRD2 (Bertinetto et al., 2019), and Lee et al.",1,neutral
"CIFAR-FS (Bertinetto et al., 2019) and FC-100 (Oreshkin et al.",1,neutral
"The technique can also be applied to iterative solvers when the optimization steps are differentiable (Bertinetto et al., 2019).",1,neutral
R2-D2/LR-D2 (Bertinetto et al. 2019) MetaOptNet (Lee et al.,1,neutral
"Many variants of the CIFAR data sets can be sampled, giving rise to e.g. CIFAR-FS (Bertinetto et al.",1,neutral
"Our method also achieves competitive few-shot classification performances on non fine-grained datasets such as CIFAR-FS[3] and mini-ImageNet[47, 35].",2,positive
"For a linear base network bθ, this leads to a linear least squares ridge regression problem, as previously considered in a metalearning context [1].",1,neutral
Recent works have explored closed form solutions [1] and implicit differentiation of the optimality conditions [15].,1,neutral
"Moreover, compared to MetaOptNetSVM [15] and R2D2 [1], our framework can utilize a wider class of objective functions, allowing us to integrate the nonconvex transductive objective (14) and also to meta-learn important parameters of the objective and the base learner itself.",2,positive
"In few-shot classification, two types of approaches have been particularly successful, namely metric learning [30, 27, 28] and optimization-based [6, 23, 22, 15, 1].",1,neutral
"While the CIFAR-100 dataset is split based on the subclasses to derive the CIFAR-FS dataset; FC100, similar to tieredImageNet, splits CIFAR-100 based on superclasses to minimize semantic similarity.",2,positive
"[1] utilize a closed-form solution of the base learner, formulated as a ridge regression problem.",1,neutral
"While achieving promising performance, both these works [15, 1] are restricted to specific types of task-specific models.",1,neutral
"Note that this configuration implies a linear ridge regression objective, similar to [1].",1,neutral
"Moreover, compared to MetaOptNetSVM [9] and R2D2 [10], our framework can utilize a wider class of objective functions, allowing us to integrate the non-convex transductive objective (5) and also to meta-learn important parameters of the objective and the base learner itself.",2,positive
"Among the compared methods, R2D2 [1] and MetaOptNet-SVM [15] employ an optimization-based base learner that predicts the parameters of a linear classification head.",2,positive
"CIFAR-100 Derivatives: Both, the CIFAR-FS [10] and the FC100 [26] benchmarks encompass the full CIFAR100 dataset [27].",2,positive
"CIFAR-100 Derivatives: Both, the CIFAR-FS [1] and the FC100 [20] benchmarks encompass the full CIFAR-100 dataset [12].",2,positive
"Among the compared methods, R2D2 [10] and MetaOptNet-SVM [9] employ an optimization-based base learner that predicts the parameters of a linear classification head.",2,positive
"Our meta-learning approach follows the paradigm in [15, 1] by having two components: the base learner and a metalearner.",2,positive
"Meta-learning [2, 14, 24, 27, 30], within the context of image classification, addresses the problems of data scarcity and generalization, trying to mimic the learning process of humans in two aspects: 1) using few samples to learn a new task (i.",1,neutral
"Unlike for instance, in few-shot classification [30, 4, 63] and tracking [5, 57], our learner constitutes an internal network module of a larger architecture.",2,positive
"Optimization-based meta-learning: Our approach is related to optimization-based meta-learning [30, 4, 63, 5, 57].",1,neutral
PASCAL5i (Shaban et al. 2017) is derived from PASCAL VOC 2012 (Everingham et al. 2010) and SBD (Hariharan et al. 2011).,2,positive
One of the motivations of introducing CIFAR-FS was that there was a gap in the challenge between training models in Omniglot and miniImageNet and that successfully training models in the latter took hours [3].,2,positive
"This dataset consists of 20 images of each of its 1623 handwritten characters, which are usually augmented with four multiples of 90◦ to obtain 1623× 4 = 6492 classes [34, 3, 32, 9].",1,neutral
"We use the increased number of episodes to compute 95% confidence intervals like previous work for few-shot multiclass classification [3, 20].",2,positive
"The first modification is the replacement of CIFAR-10 by the CIFAR-FS dataset [3], a new split of CIFAR-100 for few-shot classification in which there is no class overlap between the training, validation and test sets.",0,negative
"[34] by resizing the images to 28× 28 pixels, and using 4800 classes for training and 1692 for testing, which is nowadays standard in few-shot classification work [9, 32, 3].",1,neutral
"CIFAR-FS (Bertinetto et al. 2019) is randomly sampled from CIFAR-100 (Krizhevsky, Hinton, and others 2009) by applying the same criteria in (Bertinetto et al. 2019) as same as MiniImageNet, which means we split the 100 classes to 64 classes for meta-training, 16 for meta-validation and 20 for…",2,positive
"CIFAR-FS (Bertinetto et al. 2019) is randomly sampled from CIFAR-100 (Krizhevsky, Hinton, and others 2009) by applying the same criteria in (Bertinetto et al. 2019) as same as MiniImageNet, which means we split the 100 classes to 64 classes for meta-training, 16 for meta-validation and 20 for meta-testing.",2,positive
"2019) is randomly sampled from CIFAR-100 (Krizhevsky, Hinton, and others 2009) by applying the same criteria in (Bertinetto et al. 2019) as same as MiniImageNet, which means we split the 100 classes to 64 classes for meta-training, 16 for meta-validation and 20 for meta-testing.",2,positive
We will show the results of ablation experiments of other two datasets(CIFAR-FS and Stanford Dogs) in the supplementary materials.,2,positive
"CIFAR-FS (Bertinetto et al. 2019) is randomly sampled from CIFAR-100 (Krizhevsky, Hinton, and others 2009) by applying the same criteria in (Bertinetto et al.",2,positive
"CIFAR-FS [159] 60,000 64/26/20 common objects",1,neutral
"They might parameterize the task-specific predictor in base learner [152], [153], [154], [157], [158], [159], [160], or the intermediate feature extraction layers in base learner [56], [150], [155], even or the whole base learner [151], [156].",1,neutral
R2-D2 [159] ridge regression layer predictor weights,1,neutral
"Comparably, R2-D2 [159] adopted a differentiable ridge regression layer to parameterize the task-specific predictor, while MeteOptNet [160] advocated a differentiable convex optimization on SVM for generating final predictor weights.",2,positive
"Then, they compare whether two images embeddings belong to the same class, based on different metrics, such as similarity functions [17], [20], [21], SVM classifiers [22] and ridge regression model [23].",1,neutral
"2016) datasets with new results on CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, Rodríguez López, and Lacoste 2018).",2,positive
"For example, we could easily complement ANIL’s (Raghu et al. 2019) original results on the Omniglot (Lake, Salakhutdinov, and Tenenbaum 2015) and mini-Imagenet (Vinyals et al. 2016) datasets with new results on CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, Rodríguez López, and Lacoste 2018).",2,positive
"…example, we could easily complement ANIL’s (Raghu et al. 2019) original results on the Omniglot (Lake, Salakhutdinov, and Tenenbaum 2015) and mini-Imagenet (Vinyals et al. 2016) datasets with new results on CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, Rodríguez López, and Lacoste 2018).",2,positive
"5 Related Work MAML [5] is one of the most famous algorithms in gradient-based meta-learning, achieving a competitive performance on few-shot learning benchmark data sets [34, 26, 1, 23].",1,neutral
"We observe that ARCADe-H outperforms ARCADe-M on Omniglot, while ARCADe-M achieves higher retained accuracy on MiniImageNet and CIFAR-FS.",2,positive
"The features meta-learned on the meta-training set of Omniglot, which includes by far more classes than the ones of MiniImageNet and CIFAR-FS, require less adaptation to perform well on the meta-testing set.",2,positive
For meta-testing task-sequence lengths between 1 and 100 are used for Omniglot and between 1 and 5 for the more challenging MiniImageNet and CIFAR-FS.,2,positive
"CIFAR-FS was derived from CIFAR-100 by dividing its classes into 64
1Our code is made public under: https://github.com/AhmedFrikha/ ARCADe-A-Rapid-Continual-Anomaly-Detector
classes for meta-training, 16 for meta-validation and 20 for meta-testing to make it suitable for meta-learning problems.",2,positive
"We evaluate ARCADe on three meta-learning benchmark datasets: Omniglot [48], MiniImageNet [49] and CIFAR-FS [50].",2,positive
"Our explanation for this is that since MiniImageNet and CIFAR-FS have a higher variance in the input space, adapting the parameters of the feature extractor to the normal classes of the test tasks is beneficial.",2,positive
We use task-sequences composed of 10 tasks for meta-training on Omniglot and 5 tasks for meta-training on MiniImageNet and CIFAR-FS.,2,positive
The performance of the two ARCADe variants and the baselines is shown in Figure 1 on Omniglot and in Figure 2 on MiniImageNet and CIFAR-FS.,0,negative
"Some works have learned alternative training curricula [3] or modified the task specialisation [2,8].",1,neutral
"Prior works on meta-learning have not sought to exploit context, even when readily available [1,2,3,4,5,6,7,8,9,10,11,12,13].",1,neutral
"Few-shot Learning: Existing few-shot methods belong to one of three categories: generative approaches [17,18], embedding-based meta-learners [9,10,11] and adaptation-based meta-learners [1,2,3,4,5,6,7,8,12,13].",1,neutral
"The meta-learner either learns to produce new parameters directly from the new data [9, 33, 56, 62, 64, 72, 73], or learns to produce an update rule to iteratively optimize the base learner to fit the new data [2, 6, 8, 38, 63, 97].",1,neutral
"Intuitively, it outperforms those with ResNet-12, especially on CIFAR-FS and miniImageNet.",2,positive
"As detailed in TABLE I, in 1-shot and 5-shot test, our method achieves 10.04% and 4.67% improvement over Finetuning [32] on CIFAR-FS dataset.",0,negative
"Our results demonstrate that MCRNet achieves state-of-the-art performance in classification tasks on three few-shot learning datasets including CIFAR-FS [21], FC100 [22], and miniImageNet [14], [23].",2,positive
FC100 is another dataset derived from CIFAR-100 and similar to CIFAR-FS.,2,positive
"φ is a proportional optimizable parameter which has shown good performance in few-shot learning [21], [22] under conditions of SVM and RR as base-learners.",1,neutral
"CIFAR-FS is a new standard benchmark for few-shot learning tasks, consisting of 100 classes from CIFAR-100 [37].",2,positive
"We adopt PN on the CIFAR-FS dataset and report the average training time for each epoch, which includes task sampling, forward and backward propagation phases.",2,positive
"We show 16 classes of CIFAR-FS, where the green and red colors denote the classes sampled by random sampling and gcp-sampling, respectively.",1,neutral
"For example, PN with gcp-sampling outperforms the PN with ResNet-12 by around 1.84 and 1.2 percentage points in miniImageNet and 1.89 and 1.0 percentage points in CIFAR-FS.",2,positive
"(3) We study the impact of the adaptive task sampling method by integrating it with various meta-learning approaches and performing comprehensive experiments on the miniImageNet and CIFAR-FS few-shot datasets, which quantitatively demonstrates the superior performance of our method.",2,positive
"Secondly, CIFAR-FS is another recent few-shot image classification benchmark [6] constructed by randomly sampling from the CIFAR-100 dataset [25] using the same criteria as the miniImageNet, and has the same number of classes and samples.",2,positive
We demonstrate the evolution of class-pair potentials about 16 classes of CIFAR-FS dataset.,2,positive
"We also use the 64 / 16 / 20 divisions for consistency with previous studies [6,28].",0,negative
"Tables 1 and 2 present the 5-way 1-shot and 5- way 5-shot results on miniImageNet and CIFAR-FS datasets, respectively.",0,negative
"In this section, we evaluate the proposed adaptive task sampling method on two fewshot classification benchmarks: miniImageNet [55] and CIFAR-FS [6].",2,positive
"Extensive experiments show that our simple approach achieves appealing performance on four widely used fewshot visual recognition benchmark datasets including miniImageNet, tieredImageNet, CIFAR-FS, and CUB.",2,positive
"5), the norm of somewrongly-predicted instances (see the lowest
TABLE 2 The Averaged Accuracies With 95 percent Confidence Intervals Over 2000 Episodes on Several Datasets
Setting Model miniImageNet tieredImageNet CIFAR-FS CUB
1shot 5shot 1shot 5shot 1shot 5shot 1shot 5shot
In. Baseline [20] 51.75 0:80 74.27 0:63 - - - - 65.51 0:87 82.85 0:55 Baseline++ [20] 51.87 0:77 75.68 0:63 - - - - 67.02 0:90 83.58 0:54 MatchingNet [10] 52:911 0:88 68:881 0:69 - - - - 72:361 0:90 83:641 0:60 ProtoNet [8] 54:161 0:82 73:681 0:65 - - 72:203 83:503 71:881 0:91 87:421 0:48 MAML [7] 49:611 0:92 65:721 0:77 - - - - 69:961 1:01 82:701 0:65 RelationNet [9] 52:481 0:86 69:831 0:68 - - - - 67:591 1:02 82:751 0:58 adaResNet [86] 56.88 71.94 - - - - - -
TapNet [87] 61.65 76.36 63.08 80.26 - - - - CTMy [88] 64.12 80.51 68.41 84.28 - - - - MetaOptNet [82] 64.09 80.00 65.81 81.75 72.60 84.30 - -
Tran.",0,negative
"(iv) Extensive experiments under two few-shot settings show the effectiveness of our approach on four widely used few-shot learning benchmark datasets including miniImageNet, tieredImageNet, CIFAR-FS, and CUB.",2,positive
"Extensive experiments under two few-shot settings show the effectiveness of our approach on four widely used few-shot visual recognition benchmark datasets includingminiImageNet, tieredImageNet, CIFAR-FS, and CUB.",2,positive
"Our experiments are conducted on four widely used few-shot learning benchmark datasets including miniImageNet [73], tieredImageNet [23], CIFAR-FS [74] and CUB [75]. miniImageNet2 consists of 100 classes with 600 labeled instances per category.",2,positive
"Our experiments are conducted on four widely used few-shot learning benchmark datasets including miniImageNet [73], tieredImageNet [23], CIFAR-FS [74] and CUB [75].",2,positive
"We follow the common split given by [74], using 64 classes to construct the base set, 16 for validation, and 20 as the novel set.",1,neutral
CIFAR-FS5 is a dataset derived from CIFAR100 [78] with lower-resolution images.,2,positive
"Different from existing methods [11], [40], where feature embedding is reshaped into one dimensional vector as the input of classifiers, we keep the spatial information in the feature map by leveraging the 3D feature map.",1,neutral
"To adapt to the regime of (very) small training datasets, optimization-based meta-learning techniques replace the vanilla SGD approach by a trainable update mechanism (Bertinetto et al., 2019; Finn et al., 2017; Ravi & Larochelle, 2017), e.",2,positive
"…of (very) small training datasets, optimization-based meta-learning techniques replace the vanilla SGD approach by a trainable update mechanism (Bertinetto et al., 2019; Finn et al., 2017; Ravi & Larochelle, 2017), e.g., by learning a parameter initialization, such that a small number of SGD…",1,neutral
"…task by performing gradient descent on a very small number of labeled samples, and (ii) amortized-inference (Snell et al., 2017; Lee et al., 2019; Bertinetto et al., 2018) based approaches that directly infer the optimal parameters of a new task without performing any gradient based optimization.",1,neutral
To the best of our knowledge none of the existing meta-learning algorithms like Bertinetto et al. (2018); Rajeswaran et al. (2019); Ravi & Beatson (2018); Finn et al. (2018) explicitly utilize the information present in the covariates to improve the estimate of the adapted parameters.,2,positive
", 2017) approaches that metalearn parameters of optimization algorithms (like initialization and learning rate) in a way that the meta-learner (optimizer) is amenable to quickly adapt on a new task by performing gradient descent on a very small number of labeled samples, and (ii) amortized-inference (Snell et al., 2017; Lee et al., 2019; Bertinetto et al., 2018) based approaches that directly infer the optimal parameters of a new task without performing any gradient based optimization.",1,neutral
"However, existing Transformer-based models are mainly used for tasks in natural language processing [4], and only a few studies investigate the use of Transformer in healthcare domain [20, 34].",1,neutral
R2D2 [1] makes use of fast convergent methods like ridge regression for few-shot learning.,1,neutral
Few-shot classification performance on the CIFAR-FS dataset are shown in Table 3.,0,negative
"CIFAR-FS consists of 64 train, 16 validation, and 20 test classes with images of size 32× 32 pixels.",2,positive
"We perform few-shot classification experiments on 4 benchmark datasets: mini-ImageNet [42], tiered-ImageNet [31], CIFAR-FS [1] and FC-100 [27].
mini-ImageNet [42] consists of 100 classes, each of which has around 600 images of size 84 × 84 pixels.",2,positive
CIFAR-FS and Few-shot-CIFAR100 (FC-100) are both derived from CIFAR-100 [17] dataset.,2,positive
20% R2-D2 [1] (ICLR’19) Conv-4-512 51.,1,neutral
20% R2-D2 [1] (ICLR’19) Conv-4-512 65.,1,neutral
"We perform few-shot classification experiments on 4 benchmark datasets: mini-ImageNet [42], tiered-ImageNet [31], CIFAR-FS [1] and FC-100 [27].",2,positive
We perform ablations to validate our transformation choices by using various combinations of transformations as the auxiliary task used along with RFS on the CIFAR-FS dataset with ResNet12 architecture.,2,positive
"The last setting, reminiscent of (Franceschi et al., 2018; Bertinetto et al., 2019), concerns learning a (common) linear transformation of the data and is formulated as
f(H) = 1
2 ‖X ′Hw(H)− y′‖2
w(H) = argmin w∈Rd
1 2 ‖XHw − y‖2 + β 2 ‖w‖2
where H ∈ Rp×d and β ∈ R++.
LR and KRR are high…",1,neutral
"The last setting, reminiscent of (Franceschi et al., 2018; Bertinetto et al., 2019), concerns learning a (common) linear transformation of the data and is formulated as",1,neutral
"Then, the circular correlation X ?WCF is equal to AWCF, and the filter WCF has the following closed-form solution [34], [56], [57]:",1,neutral
"We use a simple logistic regression classifier [2, 39] to map the labels from support set to query set.",1,neutral
"Existing works mainly approach FSL using meta-learning [2, 12, 18, 22, 23, 33, 35] to adapt the base learner for the new tasks, or by enforcing margin maximizing constraints",1,neutral
Our results shown in Table 1 (miniImageNet [41] & tieredImageNet [34] datasets ) and Table 2 (CIFAR-FS [2] & FC100 [28] datasets) suggest that the proposed SKD consistently outperforms the existing methods across all datasets.,2,positive
", CIFAR-FS [2] and FC100 [28], and a very large-scale Meta-dataset [40] (composed of multiple datasets of diverse nature).",2,positive
"We comprehensively compare our method on five benchmark few-shot learning datasets that include miniImageNet [41], tieredImageNet [34], CIFAR-FS [2], FC100 [28] and Metadataset [40].",2,positive
Figure 3: Performance of SKD on CIFARFS [2] dataset for different self-supervision tasks.,1,neutral
"CIFAR-FS [2] has a random split of 100 classes into 64, 16 and 20 for training, validation, and testing, while FC100 [28] uses splits similar to tieredImageNet, making them more diverse.",2,positive
"Table 2: FSL results on CIFAR-FS [2] and FC100 [28] datasets, with mean accuracy and 95% confidence interval.",0,negative
"Table 3: FSL results on CIFAR-FS [2] and FC100 [28], with different combinations of loss functions for Gen-0 and Gen-1.",0,negative
"Building on the embedded features, task-specific parameters are then searched as a minimizer of the inner-loop loss function [3, 18].",1,neutral
"The strongly-convex case occurs often when w corresponds to parameters of the last linear layer of a neural network, so that the loss function of such a w is naturally chosen to be a quadratic function or a logistic loss with a strongly convex regularizer [3, 18].",1,neutral
"As in [3, 18], the inner-loop loss function adopts L(2) regularization on w with a hyper-parameter λ > 0, and hence is strongly convex.",1,neutral
"Apart from MAML-type meta-initialization algorithms, another well-established framework in few-shot meta learning [3, 18, 26, 28, 32] aims to learn good parameters as a common embedding model for all tasks.",1,neutral
Ridge regression layers have previously been used for few-shot learning [5] within minibatch.,1,neutral
"We are inspired by recent approaches in few-shot learning [5, 18] that avoid this issue through use of convex optimisation layers.",1,neutral
"While ridge regression (RR) is obviously oriented at regression problems, it has been shown [5] to work well for classification when regressing label vectors.",1,neutral
"Other uses of such differentiable optimization have been found in learning attention models [26], meta-learning to differentiate through the base learning algorithm [21, 22], or to train the generator in a generative adversarial model by optimizing out the discriminator [20], or for end-to-end planning and control [23].",1,neutral
"For example, [66–68] used simple metric-based nearest neighbor, [69, 70] optimized standard learning algorithms iteratively, and [21, 22] leveraged closed-form solutions for base learners.",1,neutral
"(1) Learnet [15] improves upon convolutional siamese net [61] by incorporating the specialty
of Dtrain of each task T toZ.",2,positive
R2-D2 [14] adaptive CNN the same as f yes combined,1,neutral
"Instead of directly predicting for x test as in matching nets [127], the memory is used to refine the f (x (i)), and to parameterize a CNN as in Learnet [14].",1,neutral
The recent work [14] replaces the classification layer of Learnet by a ridge regression model whose parameter can be found by cheap closed-form solution.,1,neutral
"In some applications like classification, other categories of meta learning algorithms, namely black-box [1] and parametric methods [23] also achieve state of the art results.",1,neutral
"For fair comparison, we also cite the original results of R2-D2 (Bertinetto et al., 2019) using 64 channels.",2,positive
"We cite the original results of R2-D2 (Bertinetto et al., 2019) using 64 channels for fair comparison.",2,positive
"± ± (Snell et al., 2017) 47.4 ± 0.6 65.4 0.5 55.5 0.7 72.0 0.6 R ELATION NET (Sung et al., 2018) 50.4 0.8 ± ± ± 65.3 0.7 55.0 1.0 69.3 0.8 ± ± ± ± SNAIL (32C) by (Bertinetto et al., 2019) 45.1 55.2 — — GNN (Garcia & Bruna, 2018) 50.3 66.4 61.9 75.3 PLATIPUS (Finn et al., 2018) 50.1 1.9 — — — ± VERSA (Gordon et al., 2019) 53.3 1.8 67.3 0.9 62.5 1.7 75.1 0.9 ± R2-D2 ( 64 C) (Bertinetto et al., 2019) 49.5 0.2 ± 65.4 0.2 ± ± 62.3 0.2 77.4 0.2 ± ± ± R2-D2 (Devos et al., 2019) 51.7 1.8 63.3 0.9 60.2 1.8 ± 70.9 0.9 CAVIA (Zintgraf et al., 2019) 51 The key hyperparameter for the number of bases D in (7) is set to D = 780 for MetaVRF in all experiments, while we use RFFs with D = 2048 as this produces the best performance.",0,negative
"Generally speaking, existing meta-learning algorithms (Ravi & Larochelle, 2017; Bertinetto et al., 2019) design the meta-learner to extract meta-knowledge that improves the performance of the baselearner on individual tasks.",2,positive
"For tieredImageNet and CIFAR-FS, the best accuracy are obtained on validation classes when β = 0.5, λ = 10, α = 0.3 for s = 1; β = 0.5, λ = 10, α = 0.2 for s = 5.",2,positive
"We evaluate the performance of the proposed method using standardized few-shot classification datasets: miniImageNet [32], tieredImageNet [20], CUB [33] and CIFAR-FS [1].",2,positive
"The CIFAR-FS dataset has 100 classes, each class contains 600 images of size 32× 32 pixels.",2,positive
[5] and [21] used the closed-form solutions directly.,1,neutral
The CIFAR-FS dataset [49] is a few-shot learning benchmark containing all 100 classes from CIFAR-100 [43].,2,positive
Comparisons: We present the results of different methods on the MiniImageNet and CIFAR-FS datasets in Tables 1 and 2).,2,positive
"However, although our method performs much better than GNN [17] on MiniImageNet, their results on CIFAR-FS are just comparable, possibly due to the dataset difference.",2,positive
CIFAR-FS [2] is randomly sampled from CIFAR-100 [10] by applying the same criteria as miniImagenet.,2,positive
", 2011), CIFAR-FS (Bertinetto et al., 2019) and miniImageNet (Vinyals et al.",2,positive
Sequential MAML gives a noticeable drop in the performance of Omniglot and miniQuickDraw when meta-training on CIFAR-FS.,2,positive
There is a small trade-off in the performance of CIFAR-FS as BOMLA and BOMVI avoid catastrophically forgetting Omniglot and miniQuickDraw.,2,positive
"Some popular examples of the few-shot classification datasets are Omniglot (Lake et al., 2011), CIFAR-FS (Bertinetto et al., 2019) and miniImageNet (Vinyals et al., 2016).",2,positive
"The distributional shift from Omniglot to miniQuickDraw is less drastic, compared to the shift from miniQuickDraw to CIFAR-FS.",2,positive
"The current practice to few-shot classify the novel classes from different datasets is to meta-learn a model for each dataset separately (Snell et al., 2017; Vinyals et al., 2016; Bertinetto et al., 2019).",2,positive
"The CIFAR-FS dataset [11] is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100 [32].",2,positive
"The current practice to few-shot classify the novel classes from different datasets is to metalearn a model for each dataset separately (Snell et al., 2017; Vinyals et al., 2016; Sung et al., 2018; Bertinetto et al., 2019).",2,positive
"CIFAR-FS: The CIFAR-FS dataset (Bertinetto et al., 2019) is a variation on CIFAR100 (Krizhevsky, 2009) for the few-shot classification purpose, with 100 classes of objects and each class comprises 600 images of size 32× 32.",2,positive
", 2011), CIFAR-FS (Bertinetto et al., 2019) and miniImageNet (Vinyals et al.",2,positive
"CIFAR-FS is proposed by Bertinetto et al. (2018), which is created by dividing the original CIFAR-100 into 64 training classes, 16 validation classes and 20 testing classes; each image is of size 32×32.",2,positive
"64 49.4 0.8% 68.2 0.7% 55.5 0.7% 72.0 0.6% Relation Net (Sung et al., 2018) Conv-4-64 50.4 0.8% 65.3 0.7% 55.0 1.0% 69.3 0.8% GNN (Satorras &amp; Bruna, 2017) Conv-4-64 50.3% 66.4% 61.9% 75.3% R2-D2 (Bertinetto et al., 2018) Conv-4-64 49.5 0.2% 65.4 0.2% 62.3 0.2% 77.4 0.2% TPN (Liu et al., 2018) Conv-4-64 55.5% 69.9% – – Gidaris et al. (2019) Conv-4-64 54.8 0.4% 71.9 0.3% 63.5 0.3% 79.8 0.2% SIB K=0 (Pre-trained feature",0,negative
"Net is proposed by Vinyals et al. (2016), which contains 100 classes, split into 64 training classes, 16 validation classes and 20 testing classes; each image is of size 84 84. CIFAR-FSis proposed by Bertinetto et al. (2018), which is created by dividing the original CIFAR-100 into 64 training classes, 16 validation classes and 20 testing classes; each image is of size 32 32. Evaluation metrics In few-shot classiﬁcation,",2,positive
"MetaOptNet [73] is developed under base learner and meta-learner double-layer framework [77], where base learner is formulated as a regularized linear classifier.",2,positive
[77] specifies base learner as an efficient and differentiable learner preferably with an explicit solution.,1,neutral
"In R2D2 (Ridge Regression Differentiable Discriminator) [77], ridge regression is specified to be base learner.",1,neutral
"[77] lays out base learner and meta-learner double-layer framework, in which base learner concentrates upon model fitting and meta-learner focuses upon model adaptation.",2,positive
"In LR-D2 (Logistic Regression Differentiable Discriminator), iteratively reweighted least squares (IRLS) derived from logistic regression is applied as base learner.",1,neutral
MetaOptNet is an extension of [77] in the sense that it explores more options of base learner specification under similar framework as in [77].,2,positive
"This idea of base learner specification is similar to that in [77], where an efficient and differentiable statistical base learner is preferred.",1,neutral
CIAFR-FS [77] is randomly sampled from CIFAR-100 for few-shot learning in the same mechanism as miniImageNet.,2,positive
"…cosine similarity (Vinyals et al. 2016), euclidean distance to class prototypes (Snell, Swersky, and Zemel 2017; Ren et al. 2018), ridge regression (Bertinetto et al. 2019), relation network (Sung et al. 2018), task attention (Yan, Zhang, and He 2019), category traversal (Li et al. 2019a), and…",1,neutral
"2018), ridge regression (Bertinetto et al. 2019), relation network (Sung et al.",1,neutral
"CIFAR-FS [1] consists of 100 classes randomly selected from CIFAR-100 [14] and each class has 600 images, each of size 32 × 32.",2,positive
", 2019] [Bertinetto et al., 2018], our proposed base learner is generated under the supervision of the presented masks of input support images.",2,positive
"Different from the existing base learner used in [Lee et al., 2019] [Bertinetto et al., 2018], our proposed base learner is generated under the supervision of the presented masks of input support images.",2,positive
", 2019] and [Bertinetto et al., 2018] introduce machine learning methods such as SVM and ridge regression into the inner loop of the base learner, and [Rusu et al.",1,neutral
"In the latest study, [Lee et al., 2019] and [Bertinetto et al., 2018] introduce machine learning methods such as SVM and ridge regression into the inner loop of the base learner, and [Rusu et al., 2018] directly replaces the inner loop with an encoded-decode network.",2,positive
"Evaluation Protocols We evaluate DPGN in 5way1shot/5shot settings on standard few-shot learning datasets,
miniImageNet, tieredImageNet, CUB-200-2011 and CIFAR-FS.",2,positive
"As shown in Table 1, we list details for images number, classes number, images resolution and train/val/test splits following the criteria of previous works [41, 31, 4, 3].",0,negative
"The total number of generations is an important ingredient for DPGN, so we perform experiments to obtain the trend of test accuracy with different generation numbers in DPGN on miniImageNet, tieredImageNet, CUB-200-2011, and CIFAR-FS.",2,positive
"Additionally, to visualize the procedure of cyclic update, we choose a test scenario where the ground truth classes of five query images are [1, 2, 3, 4, 5] and visualize instance-level similarities which is used for predictions of five query samples as shown in Figure 8.",1,neutral
CUB-200-2011 is initially designed for fine-grained classification and CIFAR-FS is a subset of CIFAR-100 for fewshot classification.,2,positive
"For fair comparisons, we employ DPGN on miniImageNet, tieredImageNet, CIFAR-FS and CUB-200-2011 datasets, which is compared with other methods in the same backbones.",2,positive
"We evaluate DPGN on four standard few-shot learning benchmarks: miniImageNet [41], tieredImageNet [31], CUB-200-2011 [42] and CIFAR-FS [3].",2,positive
52 R2D2 [1] 51.,1,neutral
"Recently, [19,1] alleviate the optimization problem by closed-form model like SVM, and achieve better performance on few-shot classification benchmark of large dataset.",1,neutral
"We follow the split given by [5], using 64 classes to construct the base set, 16 for validation and 20 as the novel set.",1,neutral
"Our experiments are conducted on several widely few-shot learning benchmark datasets for general object recognition and fine-grained classification, including miniImageNet [36], tieredImageNet [37], CIFAR-FS [5] and CUB [54].",2,positive
"We train 100 epochs for miniImageNet, 60 epochs for tieredImageNet, and 90
epochs for both CIFAR-FS and FC100.",2,positive
"Table 2 summarizes the results, which shows that our simple baseline is comparable to Prototypical Networks [46] and MetaOptNet [26] on CIFAR-FS dataset, and outperforms both of them on FC100 dataset.",2,positive
"Table 4 shows the results of our ablation studies on miniImageNet, tieredImageNet, CIFAR-FS, and FC100.",2,positive
"For 4-layer convnet, we also the same training setup as ResNet-12 on tieredImageNet, CIFAR-FS, and FC100, For miniImageNet, we train for 240 epochs with learning rate decayed at epochs 150, 180, and 210 with a factor of 0.1.",2,positive
"In Table 1, Table 2, and Table 4, we evalute the model of the second generation on miniImageNet, CIFAR-FS and
FC100 datasets; we use the first generation on tieredImageNet.",2,positive
"The CIFAR-FS dataset [3] is a derivative of the original CIFAR-100 dataset by randomly splitting 100 classes into 64, 16 and 20 classes for training, validation, and testing, respectively.",2,positive
"We conduct experiments on four widely used few-shot image recognition benchmarks: miniImageNet [54], tieredImageNet [42], CIFAR-FS [3], and FC100 [34].",2,positive
The plots of 1-shot and 5-shot results on miniImageNet and CIFAR-FS are shown in Figure 4.,0,negative
"In [19], the final layer of a segmentation network is predicted by closed-form ridge regression [3], using the reference example pair.",1,neutral
"Meta-learning for VOS: Since the VOS task itself includes a few-shot learning problem, it can be addressed with techniques developed for meta-learning [10,3,16].",1,neutral
"Most of the current few-shot classification benchmarks [1,22,36,51] include a single visual domain, i.",0,negative
"We conduct few-shot classification experiments on five popular benchmark datasets, namely, miniImageNet [1], tieredImageNet [61], Fewshot-CIFAR100 (FC100) [4], Caltech-UCSD Birds-200-2011 (CUB) [110], and CIFAR-FewShot (CIFAR-FS) [111].
miniImageNet. miniImageNetwas first proposed in [1] and becomes the most popular benchmark in the few-shot classification literature.",2,positive
"We observe that on the FC100 and CIFAR-FS datasets, DeepEMD-FCN outperforms DeepEMD-Grid and DeepEMD-Sampling, which is different from the observations on other datasets.",2,positive
"Experiments on five popular few-shot classification benchmark datasets—miniImagenet, tieredImagenet, FC100, CUB, and CIFAR-FS show that our algorithm on both 1-shot and 5-shot classification tasks significantly outperforms the baselinemethods and achieves new state-of-the-art performance.",2,positive
"We conduct few-shot classification experiments on five popular benchmark datasets, namely, miniImageNet [1], tieredImageNet [61], Fewshot-CIFAR100 (FC100) [4], Caltech-UCSD Birds-200-2011 (CUB) [110], and CIFAR-FewShot (CIFAR-FS) [111].",2,positive
CIFAR-FS [111] is also a few-shot classification dataset built on CIFAR100 [113].,2,positive
"We report 1-shot 5-way and 5-shot 5-way performance on 5 popular benchmarks:miniImageNet, tieredImageNet, FC100, CUB and CIFAR-FS.",2,positive
"Our extensive experiments validate the effectiveness of our algorithm which outperforms state-of-the-art methods by a significant margin on five widely used few-shot classification benchmarks, namely, miniImageNet, tieredImageNet, Fewshot-CIFAR100 (FC100), Caltech-UCSD Birds-200-2011 (CUB), and CIFAR-FewShot (CIFAR-FS).",2,positive
"In addition, we show that StarNet few-shot learner is effective at few-shot classification, significantly improving the state-of-the-art (SOTA) baselines on the CUB [50] and ImageNetLOC-FS [15] few-shot benchmarks, and comparing favorably to the SOTA methods on: miniImageNet [49], CIFAR-FS [2] and FC100 [30].",2,positive
"Thus, for benchmarks with 84 × 84 input image resolution, the block strides were [2, 2, 2, 1] resulting in 10×10 feature grids, and for 32× 32 input resolution, we used [2, 2, 1, 1] strides resulting in 8× 8 feature grids.",1,neutral
"The CIFAR-FS dataset [2], consists of all 100 classes from CIFAR-100 [17].",2,positive
"The main-stream approaches of meta-learning can be broadly categorized into three groups: optimization-based [22][10][11][25], metric-based [34][28][23][2][31] and memory-based [26].",1,neutral
"Secondly, few-shot learning is an application to use meta learning [15],[16].",1,neutral
"76% improvement over R2D2 [Bertinetto et al., 2019], CovaMNet, and DN4.",2,positive
"We also obtain very competitive accuracy on 5-way 1-shot task with Conv embedding module, gaining 3.8%, 2.11%, 1.76% improvement over R2D2 [Bertinetto et al., 2019], CovaMNet, and DN4.",2,positive
"The following FSL baselines are selected: (1) State-of-theart GCN-based FSL methods [33, 12, 8]; (2) Representative/latest FSL methods (w/o GCN) [39, 6, 40, 30, 2, 1, 3, 16].",2,positive
"(2) The improvements achieved by our method over the stateof-the-art FSL baselines [30, 2, 1, 3, 16] range from 1% to 6%, showing that AdarGCN has a great potential for FSL even with sufficient and clean training samples, due to its Branch d",0,negative
"This dataset (Bertinetto et al., 2019) is a variant of CIFAR-100 dataset used for few-shot classification, which contains 100 classes that describe general object categories.",2,positive
"More recent approaches leverage the fact that, in certain settings, the initial estimate can instead be updated using a convex optimization algorithm (Bertinetto et al., 2018; Lee et al., 2019).",1,neutral
"In fact, the scheme we analyze in this paper is closely related to Lee et al. (2019), Bertinetto et al. (2018).",2,positive
Table 2 also offers a comparison between LS Meta-Learning and Bertinetto et al. (2019). As discussed in Sec. 4.2 the two methods use same inner algorithm (empirical risk minimization with respect to the least-square loss) but different task loss functions (least squares for ours and cross-entropy for Bertinetto et al. (2019)).,2,positive
"Bertinetto et al. (2019) proposed Alg(θ,D) to perform empirical risk minimization of fW over D = (xi, yi) m i=1 with respect to the least-squares loss `(y, y′) = ‖y − y′‖(2).",1,neutral
"Similar to Bertinetto et al. (2019), we chose the least-squares empirical risk minimizer as our inner algorithm.",2,positive
"We introduce a practical and efficient algorithm for TASML, along with several algorithmic modifications aimed at improving model efficiency and performance, including: representation pre-training, optimization as a layer Amos & Kolter (2017); Bertinetto et al. (2019), and least-squares relaxation of classification loss.",2,positive
"(2018), Bertinetto et al. (2019); Qiao et al. (2018), CAVIA Zintgraf et al. (2019), LEO Rusu et al. (2019) and META-SGD Li et al. (2017) with LEO’s feature maps φ as input (from Rusu et al.",2,positive
Several MAML variants have focused on mitigating such issues Bertinetto et al. (2019); Rajeswaran et al.,1,neutral
Several MAML variants have focused on mitigating such issues Bertinetto et al. (2019); Rajeswaran et al. (2019).,2,positive
We note that TASML is at least twice as fast as LEO since the model is both simpler and admits efficient meta-gradient computation with 2We tested our method with a cross entropy meta loss and achieved results similar to Bertinetto et al. (2019).,2,positive
Table 2 also offers a comparison between LS Meta-Learning and Bertinetto et al. (2019). As discussed in Sec.,2,positive
"Similar to Bertinetto et al. (2019), we chose the least-squares empirical risk minimizer as our inner algorithm. However, we note that Bertinetto et al. (2019) uses the cross-entropy ` to induce L.",1,neutral
"There are two perspectives on approaching meta-learning: optimization based (Li et al., 2017; Bertinetto et al., 2019; Zhou et al., 2018; Zintgraf et al., 2019; Rajeswaran et al., 2019), and probabilistic (Grant et al.",1,neutral
"There are two perspectives on approaching meta-learning: optimization based (Li et al., 2017; Bertinetto et al., 2019; Zhou et al., 2018; Zintgraf et al., 2019; Rajeswaran et al., 2019), and probabilistic (Grant et al., 2018; Finn et al., 2018; Kim et al., 2018; Harrison et al., 2018).",1,neutral
"This problem is often motivated by the ability of humans to learn new tasks from few examples [18, 19], which has given rise to meta-learning [37, 27, 31, 2, 10], or learning to learn.",1,neutral
", 2019) and R2-D2 (Bertinetto et al., 2018), we find that meta-learning tends to cluster object classes more tightly in feature space.",1,neutral
"Such methods include R2-D2 and MetaOptNet (Bertinetto et al., 2018; Lee et al., 2019).",1,neutral
"…strategies that fix the feature extractor and only update the last (classification) layer of a network during the inner-loop, such as MetaOptNet (Lee et al., 2019) and R2-D2 (Bertinetto et al., 2018), we find that meta-learning tends to cluster object classes more tightly in feature space.",1,neutral
"We train the R2-D2 and MetaOptNet backbones in this fashion on the mini-ImageNet and CIFAR-FS datasets, and we test these networks on both 1-shot and 5-shot tasks.",2,positive
"The CIFAR-FS dataset samples images from CIFAR-100 (Bertinetto et al., 2018).",2,positive
R2-D2 and MetaOptNet achieve stronger performance than MAML and are able to harness larger architectures without overfitting.,2,positive
"Using both R2-D2 and MetaOptNet backbones on both mini-ImageNet and CIFAR-FS datasets, networks trained with RFC exhibit higher similarity scores to meta-learned networks than networks trained classically but without RFC .",2,positive
"Among a variety of meta-learning formulations, MAML [12] has become especially popular due to its efficiency and flexibility, inspiring many follow-up works [1, 22, 26, 5, 21].",1,neutral
"For R2-D2, we set the same training shot as for M-SVM, and used a learnable scale and bias following [3].",2,positive
"the new images are associated to the novel classes with the method proposed in [3] on CIFAR-FS, FC100, miniImageNet few-shot learning tasks, and showed the second case got better results.",2,positive
"In the evaluation of Task Aug for ProtoNets and M-SVM, we set pmax to the value getting the best results for R2-D2.",2,positive
The CIFAR-FS [3] containing all 100 classes from CIFAR100 [12] is proposed as few-shot classification benchmark recently.,2,positive
"Therefore, in the experiment, the methods applied in the “inner loop” are able to classify data, and they are K-nearest neighbor (KNN), Support Vector Machine (SVM) and ridge regression, respectively [27, 15, 3].",1,neutral
"We proved that Task Aug was valid for CIFAR-FS, FC100, and miniImageNet,
and exceeded the result of the previous works.",2,positive
It was different from [3] we used a fixed regularization parameter of ridge regression which was set to 50 because [3] has confirmed that making it learnable might not be helpful.,2,positive
"For M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.1; and a learnable scale was used following [15].",2,positive
"Previous studies have introduced many popular regularization techniques to few-shot learning from deep learning, such as weight decay, dropout, label smooth [3], and data augmentation.",1,neutral
"C V
] 8
the new images are associated to the novel classes with the method proposed in [3] on CIFAR-FS, FC100, miniImageNet few-shot learning tasks, and showed the second case got better results.",0,negative
"Same as CIFAR-FS, there are 600 nature color images of size 32× 32 in each class.",1,neutral
"In the experiments of comparing Task Aug and Image Aug by rotating, R2-D2 was applied, and we set T to 80000.",1,neutral
"We used ProtoNets [27], MetaOptNet-SVM [15] (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) [3] as basic methods to verify the effective of Task Aug.",2,positive
"Then the proposed method is evaluated by experiments with the state of art meta-learning methods [27, 15, 3] on CIFAR-FS, FC100, miniImageNet fewshot learning tasks, and compare with the results without the data augmentation by rotating.",2,positive
"In [16] and [1], the authors create a class-weight generator by training the model with a linear classifier (e.",1,neutral
"We perform our experiments on 3 standardized few-shot classification datasets: miniImageNet [34], CUB [35] and CIFAR-FS [1].",2,positive
"CIFAR-FS: This dataset has 100 classes, each class contains 600 images of size 32× 32 pixels.",2,positive
"The common benchmarks for eval-
uation are miniImageNet [33], CUB [34], Omniglot [18], CIFAR-FS [3] and tieredImageNet [27].",2,positive
"uation are miniImageNet [33], CUB [34], Omniglot [18], CIFAR-FS [3] and tieredImageNet [27].",2,positive
"Metric-based approaches [2,12,21,25,27,33,42,44,45,47,53,57] learn a metric with the intent of reducing the intra-class variations while training on base categories.",0,negative
"Recently proposed approaches to few-shot learning problem can be roughly divided into meta-learning based [16, 3, 4, 17, 18, 19] and weight-generation based approaches [20, 12, 5, 13, 21].",1,neutral
The paper [17] shows that on top of the common feature extractor one may simply use a classifier with a closed-form solution for each few-shot task.,1,neutral
-shot 5-shot 1-shot 5-shot MAML [6] ConvNet-32 58.9±1.9 71.5±1.0 - - Prototypical Networks [31] ConvNet-64 55.5±0.7 72.0±0.6 35.3±0.6 48.6±0.6 Relation Net [32] ConvNet-256 55.0±1.0 69.3±0.8 - - R2D2 [3] ConvNet-512 65.3±0.2 79.4±0.1 - - TADAM [23] ResNet-12 - - 40.1±0.4 56.1±0.4 MetaOptNet-SVM [14] ResNet-12 72.0±0.7 84.2±0.5 41.1±0.6 55.5±0.6 CSPN (ours) WRN-28-10 63.68±0.85 80.00±0.68 37.67±0.67 5,0,negative
"-level categories. These categories are split into 20/6/8 categories for training/validation/test. The splits include 351, 97, 160 lowlevel classes respectivelywith images of size 84 × 84. TheCIFAR-FS[3]isrecentlyproposedwhichisderived fromCIFAR-100[12] containingall 100classes ofCIFAR100. The 100 classes are randomly split into 64, 16, 20 classes for training, validation and test, by using the same ",0,negative
The CIFAR-FS includes 100 classes which is derived from CIFAR-100 dataset [1] and each class has 600 images of size 32 × 32.,2,positive
"In fact, the ridge regression was originally designed for the regression task, we also adjust the prediction of base linear Λ by Equation (5), as in (Bertinetto et al. 2019).",1,neutral
"In order to optimize the φ in Equation (2) by backpropagation and stochastic gradient descent (SGD), Λ is preferred to be a simple and efficient model (e.g., nearest neighbor methods or linear models) (Bertinetto et al. 2019).",1,neutral
", nearest neighbor methods or linear models) (Bertinetto et al. 2019).",1,neutral
"In fact, the ridge regression was originally designed for the regression task, we also adjust the prediction of base linear Λ by Equation (5), as in (Bertinetto et al. 2019).
ŷ = αX′w + β, (5)
where X′ ∈ Rn×c is the feature matrix of the test image.",1,neutral
Catastrophic forgetting (Kemker et al. 2018) has been a long-standing issue in machine learning community due to the stability-plasticity dilemma (Ditzler et al. 2015).,1,neutral
", 2015), CIFAR-FS (Bertinetto et al., 2019), and mini-ImageNet (Vinyals et al.",2,positive
"Datasets and settings In the following study, we use the standard 5-ways and 5-shots setting on the Omniglot (Lake et al., 2015), CIFAR-FS (Bertinetto et al., 2019), and mini-ImageNet (Vinyals et al., 2016) datasets.",2,positive
"At CNN(6), there are degradations in performance by the original MAML on Omniglot and CIFAR-FS such that LinNet does not improve further.",2,positive
All methods improve the original MAML while meta-kfo improves the most on Omniglot and CIFAR-FS.,2,positive
", 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al.",2,positive
"As reported in Table 6, ours improves consistently 5-way 1/5-shot classification accuracy on mini-ImageNet, CIFAR-FS, and FC100.",0,negative
"We evaluate our method on various classification datasets: CIFAR10/100 (Krizhevsky et al., 2009), Caltech-UCSD Birds or CUB200 (Wah et al.,
2011), Indoor Scene Recognition or MIT67 (Quattoni & Torralba, 2009), Stanford Dogs (Khosla et al., 2011), and tiny-ImageNet3 for standard or imbalanced image classification; mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al., 2018) for few-shot classification.",2,positive
"…Scene Recognition or MIT67 (Quattoni & Torralba, 2009), Stanford Dogs (Khosla et al., 2011), and tiny-ImageNet3 for standard or imbalanced image classification; mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al., 2018) for few-shot classification.",2,positive
"%) with 95% confidence intervals of 1000 5-way few-shot tasks on mini-ImageNet, CIFAR-FS, and FC100.",1,neutral
"The best accuracy is indicated as bold.
mini-ImageNet CIFAR-FS FC100
Method 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot
MAML† (Finn et al., 2017) 48.70±1.84 63.11±0.92 58.9±1.9 71.5±1.0 - - R2D2† (Bertinetto et al., 2019) - - 65.3±0.2 79.4±0.1 - -
RelationNet† (Sung et al., 2018) 50.44±0.82 65.32±0.70 55.0±1.0 69.3±0.8 - - SNAIL (Mishra et al., 2018) 55.71±0.99 68.88±0.92 - - - - TADAM (Oreshkin et al., 2018) 58.50±0.30 76.70±0.30 - - 40.1±0.4 56.1±0.4 LEO‡ (Rusu et al., 2019) 61.76±0.08 77.59±0.12 - - - - MetaOptNet-SVM (Lee et al., 2019) 62.64±0.61 78.63±0.46 72.0±0.7 84.2±0.5 41.1±0.6 55.5±0.6
ProtoNet (Snell et al., 2017) 59.25±0.64 75.60±0.48 72.2±0.7 83.5±0.5 37.5±0.6 52.5±0.6 ProtoNet + SLA+AG (ours) 62.22±0.69 77.78±0.51 74.6±0.7 86.8±0.5 40.0±0.6 55.7±0.6
MetaOptNet-RR (Lee et al., 2019) 61.41±0.61 77.88±0.46 72.6±0.7 84.3±0.5 40.5±0.6 55.3±0.6 MetaOptNet-RR + SLA+AG (ours) 62.93±0.63 79.63±0.47 73.5±0.7 86.7±0.5 42.2±0.6 59.2±0.5
(DeVries & Taylor, 2017), CutMix (Yun et al., 2019), AutoAugment (Cubuk et al., 2019), and FastAutoAugment (Lim et al., 2019) into recent architectures (Zagoruyko & Komodakis, 2016b; Han et al., 2017).",0,negative
"…CIFAR-FS FC100
Method 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot
MAML† (Finn et al., 2017) 48.70±1.84 63.11±0.92 58.9±1.9 71.5±1.0 - - R2D2† (Bertinetto et al., 2019) - - 65.3±0.2 79.4±0.1 - -
RelationNet† (Sung et al., 2018) 50.44±0.82 65.32±0.70 55.0±1.0 69.3±0.8 - - SNAIL (Mishra…",0,negative
"These include optimization-based meta-learners, such as model-agnostic meta-learner (MAML) [16], gradient unrolling [49], closed-form solvers [4], and convex learners [35].",1,neutral
"2019b) or directly use a meta-optimizer to learn the optimization process (Ravi and Larochelle 2016); (2) metricbased few-shot learning methods, which propose to learn a generalized metric and matching functions from training tasks (Snell, Swersky, and Zemel 2017; Vinyals et al. 2016; Yang et al. 2018; Bertinetto et al. 2019).",1,neutral
"We focus on four meta-learning algorithms: MAML, R2-D2, MetaOptNet, and ProtoNet [8, 3, 18, 29].",2,positive
"In this work, we report performance on Omniglot, Mini-ImageNet, and CIFAR-FS [16, 31, 3].",2,positive
"Table 1: R2-D2 [3], adversarially trained transfer learning, ADML [33], and our adversarially queried (AQ) R2-D2 model on 5-shot Mini-ImageNet.",2,positive
This amplitude is similar to the reported difference in accuracy between algorithms and higher than the confidence intervals usually reported when evaluating meta-learning algorithms [34] [8] [9] [11] [7] [36].,1,neutral
"From the image domain we use 4 few-shot learning benchmarks, namely MiniImageNet [37], Omniglot [25], CIFAR-FS [5] and FC100 [33] and 1 OCC benchmark dataset, the Multi-Task MNIST (MT-MNIST) dataset.",2,positive
"Table 4 shows that applying the proposed sampling technique to MetaOptNet and Meta-SGD results in a significant accuracy increase in FS-OCC on the MiniImageNet, CIFAR-FS and FC100 datasets.",2,positive
"To this end, we apply the proposed approach of learning meta-optimizers to the example synthetic dataset, as well as popular benchmark datasets: Omniglot (Lake et al., 2015), mini-ImageNet (Ravi & Larochelle, 2017), and CIFAR-FS (Bertinetto et al., 2019).",2,positive
"To examine this claim, we meta-train a model consisting of four convolutional layers (C1 - C4) and a final fully-connected layer (FC) on Omniglot (Lake et al., 2015) and CIFAR-FS (Bertinetto et al., 2019).",2,positive
", 2015), mini-ImageNet (Ravi & Larochelle, 2017), and CIFAR-FS (Bertinetto et al., 2019).",2,positive
"…datasets: the Omniglot where the setting is 10-way classification with 5-shots and 4 adaptation steps, using the original 4-layer convolutional network (CNN) of Finn et al. (2017), and the CIFAR-FS dataset (Bertinetto et al., 2019), doing 10- way classification with 3-shots and 2 adaptation steps.",2,positive
"Table A1: Accuracies and standar deviation of Meta-Learning of Non-Linear Models
Omniglot CIFAR-FS
Num.",1,neutral
"We focus on two datasets: the Omniglot where the setting is 10-way classification with 5-shots and 4 adaptation steps, using the original 4-layer convolutional network (CNN) of Finn et al. (2017), and the CIFAR-FS dataset (Bertinetto et al., 2019), doing 10- way classification with 3-shots and 2 adaptation steps.",2,positive
"(2017), and the CIFAR-FS dataset (Bertinetto et al., 2019), doing 10way classification with 3-shots and 2 adaptation steps.",2,positive
"As opposed to Bertinetto et al. (2019), our model closely resembles the one of our Omniglot experiments.",2,positive
"The KFC architecture consists of 4 layers, such that the meta-optimizers contains a total of 134,171 parameters for the 2-layer CNN model and 267,451 parameters for the 4-layer CNN.
CIFAR-FS We obtained the splits created by Bertinetto et al. (2019) and exactly reproduced their preprocessing setting for our experiments on CIFAR-FS.",2,positive
"…layers, such that the meta-optimizers contains a total of 134,171 parameters for the 2-layer CNN model and 267,451 parameters for the 4-layer CNN.
CIFAR-FS We obtained the splits created by Bertinetto et al. (2019) and exactly reproduced their preprocessing setting for our experiments on CIFAR-FS.",2,positive
"Table 2 contains 5-shot natural and robust accuracy on the Mini-ImageNet and CIFAR-FS datasets (Vinyals et al., 2016; Bertinetto et al., 2018).",2,positive
"(Finn et al., 2017; Bertinetto et al., 2018; Lee et al., 2019; Snell et al., 2017).",1,neutral
"We found the expressiveness of the generator architecture used in the original DefenseGAN setup to be insufficient for even CIFAR-FS, so we substitute a stronger ProGAN generator to model the CIFAR-100 classes (Karras et al., 2017).",2,positive
"We test this method on the MAML, ProtoNet, R2-D2, and MetaOptNet algorithms on the Mini-ImageNet and CIFAR-FS datasets (see Table 4).",2,positive
"In this work, we report performance on OmniGlot, Mini-ImageNet, and CIFAR-FS (Lake et al., 2015; Vinyals et al., 2016; Bertinetto et al., 2018).",2,positive
"All R2-D2 models are fine-tuned with a ridge regression head as in (Bertinetto et al., 2018), and we re-implement ADML from (Yin et al.",2,positive
"We evaluate our method on various classification datasets: CIFAR10/100 (Krizhevsky et al., 2009), Caltech-UCSD Birds or CUB200 (Wah et al., 2011), Indoor Scene Recognition or MIT67 (Quattoni & Torralba, 2009), Stanford Dogs (Khosla et al., 2011), and tinyImageNet2 for standard or imbalanced image classification; mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al., 2018) for few-shot classification.",2,positive
", 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al.",2,positive
"…Scene Recognition or MIT67 (Quattoni & Torralba, 2009), Stanford Dogs (Khosla et al., 2011), and tinyImageNet2 for standard or imbalanced image classification; mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al., 2018) for few-shot classification.",2,positive
"As reported in Table 5, ours improves consistently 5-way 1/5-shot classification accuracy on mini-ImageNet, CIFAR-FS, and FC100.",0,negative
"Other optimization-based algorithms have also since been developed, for example [18, 10, 4, 17, 38], which learn functions to embed the support set and test examples of a few-shot learning task, and then learn the weights of a task-specific classifier (using the support set) to perform few-shot classification on the embedded test examples.",1,neutral
", 2018), CIFAR-FS (Bertinetto et al., 2018), and Fewshot-CIFAR100 (Oreshkin et al.",2,positive
"The library currently contains 5 few-shot classification problems: Omniglot (Lake et al., 2015, 2019), Mini-ImageNet (Vinyals et al., 2016; Ravi and Larochelle, 2017), Tiered-ImageNet (Ren et al., 2018), CIFAR-FS (Bertinetto et al., 2018), and Fewshot-CIFAR100 (Oreshkin et al., 2018).",2,positive
"[14, 15], and (iii) “hyper-parameter optimisation” which has been characterised as meta-learning for a single task [16].",1,neutral
"Prior work has considered a number of inner loops, ranging from a very general setting where all parameters are adapted using gradient descent [15], to more structured and specialized settings, such as ridge regression [8], Bayesian linear regression [23], and simulated annealing [2].",1,neutral
"and produce weight updates [25, 5, 33, 48] or predictions for new inputs [50, 12, 58, 40, 38], and optimization-based approaches that use bi-level optimization to embed learning procedures, such as gradient descent, into the meta-optimization problem [15, 13, 8, 60, 34, 17, 59, 23].",1,neutral
"This indicates that CIFAR-FS, FC-100 and Mini-ImageNet may be good benchmarks for applications with few classes.",2,positive
"The first is the CIFAR-FS dataset [10] which splits classes randomly into 64 training, 16 validation and 20 test with 600 images in each.",2,positive
"Our base28 line outperforms the state-of-the-art on a variety of benchmark datasets such as Mini-ImageNet [1], 29 Tiered-ImageNet [4], CIFAR-FS [5] and FC-100 [3], all with the same hyper-parameters.",2,positive
"Our baseline outperforms the state-of-the-art on a variety of benchmark datasets such as Mini-ImageNet [1], Tiered-ImageNet [9], CIFAR-FS [10] and FC-100 [5], all with the same hyper-parameters.",2,positive
"This section shows results of transductive fine-tuning on benchmark datasets in few-shot learning, 71 namely Mini-ImageNet [1], Tiered-ImageNet [4], CIFAR-FS [5] and FC-100 [3].",2,positive
"For the Mini-ImageNet, CIFAR-FS and FC-100 datasets using additional data from the validation set to pre-train the backbone results in 2-8% improvements on the few-shot episodes; the improvement is smaller for Tiered-ImageNet.",0,negative
"3 also shows that due to fewer test classes, CIFAR-FS, FC-100 and Mini-ImageNet have less diversity in the hardness of episodes while Tiered-ImageNet and Imagenet-21k allow sampling of both very hard and very easy diverse episodes.",2,positive
"This section shows results of transductive fine-tuning on benchmark datasets in few-shot learning, namely Mini-ImageNet [1], Tiered-ImageNet [9], CIFAR-FS [10] and FC-100 [5].",1,neutral
"All hyper-parameters are kept constant for experiments on benchmark datasets, namely Mini-ImageNet, Tiered-ImageNet, CIFAR-FS and FC-100.",2,positive
"Learning algorithms In addition to the ridge regressor (RR) (Bertinetto et al., 2019), we evaluate two standard supervised learning algorithms and two meta-learning algorithms.",2,positive
"We adopt ridge regression (Bertinetto et al., 2019) to fit the labeled support set for the following reasons: 1) ridge regression admits a closed-form solution that enables end-to-end differentiation through the model, and 2) with proper regularization, ridge regression reduces over-fitting on the small support set.",2,positive
"Although we optimized for a regression objective in Eq equation 5, the learned transformation has been shown to work well in few-shot classification after a calibration step (Bertinetto et al., 2019), as ŶQ = aΦQW + b (7) where a ∈ R and b ∈ R are meta-parameters learned through meta-training.",1,neutral
"Current approaches transfer knowledge from the source to the target by either fine-tuning a pre-trained encoder (Howard & Ruder, 2018; Peters et al., 2018; Radford et al., 2018; Bertinetto et al., 2019), or multi-task learning with a shared encoder (Collobert & Weston, 2008; Liu et al.",2,positive
"To learn an effective comparison model, these methods make their prediction conditioned on distances to few labeled instances during the training process [1, 34, 13, 2].",1,neutral
"The proposed methodology
(S2M2) outperforms the state-of-the-art methods by 3-8% over the CIFAR-FS, CUB, mini-ImageNet and tiered-ImageNet datasets.",2,positive
"We show that our proposed method S2M2 beats the current state-of-the-art accuracy on standard fewshot learning datasets like CIFAR-FS, CUB, mini-ImageNet and tiered-ImageNet by 3 − 8%.",2,positive
"Datasets: We perform experiments on four standard datasets for few-shot image classification benchmark, miniImageNet [63], tiered-ImageNet [52], CUB [64] and CIFAR-FS [4]. mini-ImageNet consists of 100 classes from the ImageNet [53] which are split randomly into 64 base, 16 validation and 20 novel classes.",2,positive
"For training ResNet-18 and ResNet-34 architectures, we use Adam [33] optimizer for mini-ImageNet and CUB whereas SGD optimizer for CIFAR-FS.",2,positive
"CIFAR-FS is created by randomly splitting 100 classes of CIFAR-100 [34] into 64 base, 16 validation and 20 novel classes.",2,positive
We find that using only rotation prediction as an auxiliary task during backbone training also outperforms the existing state-of-the-art methods on all datasets except CIFAR-FS.,2,positive
"Datasets: We perform experiments on four standard datasets for few-shot image classification benchmark, miniImageNet [63], tiered-ImageNet [52], CUB [64] and CIFAR-FS [4].",2,positive
"[1] proposed both closed-form and iterative solvers, based on ridge regression and logistic regression components, to teach a CNN to use standard machine learning tools as part of its internal model, enabling it to adapt to novel data quickly.",2,positive
", MAML[9], gradient unrolling [35], closed form solvers [2], convex learners [23], etc.",1,neutral
"For more experiments on other datasets, such as FC100 [17], CIFAR-FS [3], and Meta-Dataset [31], please see the supplementary materials.",2,positive
We perform this study using the MiniImageNet and CIFAR-FS datasets and report results in Tables 1 and 2 respectively.,2,positive
"In Tables 5, 6, and 7, we compare our approach with prior few-shot methods on the MiniImageNet, CIFAR-FS, and tiered-MiniImageNet datasets respectively.",2,positive
"CIFAR-FS is a few-shot dataset created by dividing the 100 classes of CIFAR-100 into 64 base classes, 16 validation classes, and 20 novel test classes.",2,positive
"Our detailed experiments on MiniImagenet, CIFAR-FS, tiered-MiniImagenet, and ImageNet-FS few-shot datasets reveal that indeed adding self-supervision leads to significant improvements on the few-shot classification performance, which makes the employed few-shot models achieve stateof-the-art results.",2,positive
"Also, we consider only the MiniImageNet dataset and not CIFAR-FS since the latter contains thumbnail images of size 32 × 32 from which it does not make sense to extract patches: their size would have to be less than 8× 8 pixels, which is too small for the evaluated architectures.",2,positive
"(2) We study the impact of the added self-supervised loss by performing exhaustive quantitative experiments on MiniImagenet, CIFAR-FS, tiered-MiniImagenet, and ImageNetFS few-shot datasets.",2,positive
"We perform experiments on four few-shot datasets, MiniImageNet [55], tiered-MiniImageNet [46], CIFAR-FS [2], and ImageNet-FS [20].",2,positive
"Following the setting of most recent methods [45, 52, 70], we use ResNet variants [5, 22] to implement the embedding backbone φ.",2,positive
"works chooses to learn the common optimization strategy [5, 47] across few-shot tasks, e.",1,neutral
"Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps. Our subspace networks method can also be seen as a form of meta-learning, in the sense that it dynamically produces a simple classifier from incoming test episodes, yet the parametrized embedding function fφ remains fixed after training. Oreshkin et al. [2018] show that, following Hinton et al. [2015], by adding a learnable temperature α in the softmax (pφ,α(y = n|x) = softmax(−αd(ei,Pnei))), they enable the model to learn the best regime for each similarity metric. By using such a learnable temperature, the performance difference between matching networks and prototypical networks vanishes. However, the performance of prototypical networks improves only slightly. Also, the idea to make the embedding function conditionally dependent on the support set (Vinyals et al. [2016]) is used in the form of conditional batch normalization by Oreshkin et al. [2018]. They show that by combining support-set conditioned batch normalization with temperature learning, impressive performance gains can be achieved. Concurrently, similar work by Simon et al. [2019] explores subspace representations for few-shot learning.",2,positive
"Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps. Our subspace networks method can also be seen as a form of meta-learning, in the sense that it dynamically produces a simple classifier from incoming test episodes, yet the parametrized embedding function fφ remains fixed after training. Oreshkin et al. [2018] show that, following Hinton et al. [2015], by adding a learnable temperature α in the softmax (pφ,α(y = n|x) = softmax(−αd(ei,Pnei))), they enable the model to learn the best regime for each similarity metric. By using such a learnable temperature, the performance difference between matching networks and prototypical networks vanishes. However, the performance of prototypical networks improves only slightly. Also, the idea to make the embedding function conditionally dependent on the support set (Vinyals et al. [2016]) is used in the form of conditional batch normalization by Oreshkin et al.",2,positive
"Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps.",1,neutral
"Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters.",1,neutral
"Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps. Our subspace networks method can also be seen as a form of meta-learning, in the sense that it dynamically produces a simple classifier from incoming test episodes, yet the parametrized embedding function fφ remains fixed after training. Oreshkin et al. [2018] show that, following Hinton et al. [2015], by adding a learnable temperature α in the softmax (pφ,α(y = n|x) = softmax(−αd(ei,Pnei))), they enable the model to learn the best regime for each similarity metric.",2,positive
"Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps. Our subspace networks method can also be seen as a form of meta-learning, in the sense that it dynamically produces a simple classifier from incoming test episodes, yet the parametrized embedding function fφ remains fixed after training. Oreshkin et al. [2018] show that, following Hinton et al. [2015], by adding a learnable temperature α in the softmax (pφ,α(y = n|x) = softmax(−αd(ei,Pnei))), they enable the model to learn the best regime for each similarity metric. By using such a learnable temperature, the performance difference between matching networks and prototypical networks vanishes. However, the performance of prototypical networks improves only slightly. Also, the idea to make the embedding function conditionally dependent on the support set (Vinyals et al. [2016]) is used in the form of conditional batch normalization by Oreshkin et al. [2018]. They show that by combining support-set conditioned batch normalization with temperature learning, impressive performance gains can be achieved.",1,neutral
Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function.,1,neutral
"In addition to the reproduced metric (meta-)learning based few-shot methods (Snell et al., 2017; Vinyals et al., 2016; Sung et al., 2018; Bertinetto et al., 2019), there is a large body of work on few-shot learning and metric (meta-)learning.",1,neutral
"Compared to our direct approach, R2D2 is a meta-learning technique which leverages the closed-form solution of multinomial regression indirectly for classification (See Section 4).",2,positive
Bertinetto et al. (2019) propose to use regularized linear regression as a classifier on top of the embedding function.,1,neutral
", 2019) of MatchingNet, ProtoNet, RelationNet, MAML and extend it with R2D2 (Bertinetto et al., 2019).",2,positive
"Secondly, as the backbone gets deeper, regression networks and prototypical networks begin to perform significantly better than matching networks and relation networks with R2D2 following close.",1,neutral
"To ensure a fair comparison with other methods, we perform experiments under the same conditions using the verified re-implementation (Chen et al., 2019) of MatchingNet, ProtoNet, RelationNet, MAML and extend it with R2D2 (Bertinetto et al., 2019).",2,positive
"CIFAR-FS: This dataset (Bertinetto et al., 2019) is a variant of CIFAR-100 dataset that consists of 100 general object categories.",2,positive
"In general, we observe that the real-world datasets are challenging for all methods but ADKL methods consistently outperform R2-D2 and CNP.",1,neutral
"Once again, the difference in performance between ADKL-KRR and R2-D2 can be attributed to the kernel adaptation at test-time as it is the only difference between both methods.",2,positive
The gap between ADKL-KRR and R2-D2 shows the importance of adapting the kernel to each task rather than sharing a single kernel.,2,positive
[12] have also tackled this lack of adaptation for new tasks by using KRR and Logistic Regression to find the appropriate weighting of the training samples.,1,neutral
"2 Benchmarking analysis We evaluate model performance against R2-D2 [12], CNP[31], and MAML[14].",2,positive
"It is worth mentioning that using the linear kernel and the KRR algorithm, we recover the few-shot classification algorithm R2-D2 proposed by Bertinetto et al. [12].",1,neutral
"We evaluate model performance against R2-D2 [12], CNP[31], and MAML[14].",2,positive
R2-D2 is a natural comparison to ADKL-KRR (when the latter uses the linear kernel) to show whether the adapted deep kernel provides more test-time adaptation.,2,positive
"Moreover, for small support sets, ADKL-KRR shows better within-task generalization than ADKL-GP and R2-D2.",2,positive
"Hence, few of the currently-used base learners have enough capacity to truly adapt [12, 13].",1,neutral
"We test our algorithm on three datasets: miniImagenet [21], tieredImagenet [12] and CIFAR Few-Shot [1].",2,positive
"Finally, [1] incorporates ridge regression in an endto-end manner into a deep-learning network.",1,neutral
"We test our algorithm on three datasets: miniImagenet [20], tieredImagenet [12] and CIFAR Few-Shot [1].",2,positive
"The class identities are then either obtained through a function defined a-priori such as the sample mean in [16], an attention kernel [21], or ridge regression [1].",1,neutral
"Also shown in Table 4 is the perfor-
mance of our method on the CIFAR Few-Shot dataset.",2,positive
The performance numbers for CIFAR Few-Shot are from [1].,0,negative
"Finally, we use CIFAR Few-Shot, (CIFAR-FS) [1] containing images of size 32× 32, a reorganized version of the CIFAR-100 [8] dataset.",2,positive
"We use the same data split as in [1], dividing the 100 classes into 64 for training, 16 for validation, and 20 for testing.",2,positive
From this table we see that our method performs the best for CIFAR Few-Shot.,2,positive
R2-D2 [3] Conv-4-64 48.,1,neutral
"Improved upon Learnet, the classification layer of the learner is replaced by ridge regression in Reference [13], such that parameters can be efficiently obtained in closed-form.",1,neutral
hybrid Learnet [14] adaptive CNN CNN weighted 1 distance DCCN [162] adaptive CNN CNN R2-D2 [13] adaptive CNN CNN TADAM [100] adaptive CNN the same as f squared 2 distance,2,positive
"(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods. Our results show that a simple baseline method with a distancebased classifier (without training over a collection of tasks/episodes as in meta-learning) achieves competitive performance with respect to other sophisticated algorithms. Besides meta-learning methods, both Gidaris & Komodakis (2018) and Qi et al. (2018) develop a similar method to our Baseline++ (described later in Section 3.",2,positive
"(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods. Our results show that a simple baseline method with a distancebased classifier (without training over a collection of tasks/episodes as in meta-learning) achieves competitive performance with respect to other sophisticated algorithms. Besides meta-learning methods, both Gidaris & Komodakis (2018) and Qi et al. (2018) develop a similar method to our Baseline++ (described later in Section 3.2). The method in Gidaris & Komodakis (2018) learns a weight generator to predict the novel class classifier using an attentionbased mechanism (cosine similarity), and the Qi et al. (2018) directly use novel class features as their weights.",2,positive
"(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods. Our results show that a simple baseline method with a distancebased classifier (without training over a collection of tasks/episodes as in meta-learning) achieves competitive performance with respect to other sophisticated algorithms. Besides meta-learning methods, both Gidaris & Komodakis (2018) and Qi et al.",2,positive
"(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods.",1,neutral
"(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018).",1,neutral
"(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods. Our results show that a simple baseline method with a distancebased classifier (without training over a collection of tasks/episodes as in meta-learning) achieves competitive performance with respect to other sophisticated algorithms. Besides meta-learning methods, both Gidaris & Komodakis (2018) and Qi et al. (2018) develop a similar method to our Baseline++ (described later in Section 3.2). The method in Gidaris & Komodakis (2018) learns a weight generator to predict the novel class classifier using an attentionbased mechanism (cosine similarity), and the Qi et al.",2,positive
"Recently, the approaches of predicting class centers or weights [22], [23] have attracted much interest.",1,neutral
"Others relate to Prototypical Networks by learning a data representation as well as a compact representation for a classifier of data under that representation (Bertinetto et al., 2019; Gidaris & Komodakis, 2018; Oreshkin et al.,
2018; Gidaris & Komodakis, 2018).",1,neutral
"Others relate to Prototypical Networks by learning a data representation as well as a compact representation for a classifier of data under that representation (Bertinetto et al., 2019; Gidaris & Komodakis, 2018; Oreshkin et al., 2018; Gidaris & Komodakis, 2018).",1,neutral
"More specifically, the embedding modules [1, 2, 3, 4] have [3, 4, 6, 3] SENet blocks respectively, as per [18].",1,neutral
"Recent extensions include also learning perparameter learning rates [26], and accelerating fine-tuning through solving some layers in closed form [1].",1,neutral
"Recent extensions also include learning perparameter learning rates [25], and accelerating fine-tuning through solving some layers in closed form [26].",1,neutral
"Compared to [4], our proposed method using recurrent back-propagation [18, 1, 25] is more general as it does not require a closed-form update, and the inner loop solver can employ any existing continuous optimizers.",2,positive
"To address this problem, [4] proposes to use fast convergent models like logistic regression (LR), which can be back-propagated via a closed form update rule.",1,neutral
"Unlike [4], we do not rely on an analytic form of the gradients of the optimization process.",1,neutral
"Most of the Methods use different techniques of metric learning [11, 12], attention mechanism [13], data augmentation [14], or meta learning [12, 15].",1,neutral
"Generally, these approaches can be roughly categorized as either meta-learning algorithms (including MAML [38], Meta-SGD [39], DEML+Meta-SGD [40], META-LEARN LSTM [41], Meta-Net [42], R2-D2[43], Reptile[44], WRN [45]) and metric-learning algorithms (including Matching Nets [36], PROTO-NET [37], RELATION NET [46], MACO [47], and Cos & Att.",1,neutral
"(including MAML [38], Meta-SGD [39], DEML+Meta-SGD [40], META-LEARN LSTM [41], Meta-Net [42], R2-D2[43], Reptile[44], WRN [45]) and metric-learning algorithms (including Matching Nets [36], PROTO-NET [37], RELATION NET [46], MACO [47], and Cos & Att.",1,neutral
"[48], Delta-encoder [57] and R2-D2[43].",1,neutral
"CUB-200(%)1-shot 5-shot 1-shot 5-shot META-LEARN LSTM [41] 43.44±0.77 60.60±0.71 40.43 49.65
MAML [38] 48.70±1.84 63.11±0.92 38.43 59.15 Meta-Net [42] 49.21±0.96 - - -
Reptile[44] 49.97 65.99 - - MAML* [38] 52.23±1.24 61.24±0.77 - - Meta-SGD* [39] 52.31±1.14 64.66±0.89 - - DEML+Meta-SGD [40] 58.49±0.91 71.28±0.69 - -
MACO [47] 41.09±0.32 58.32±0.21 60.76 74.96 Matching Nets* [36] 47.89±0.86 60.12±0.68 - -
PROTO-NET [37] 49.42±0.78 68.20±0.66 45.27 56.35 GNN [52] 50.33±0.36 66.41±0.63 - -
R2-D2 [43] 51.5±0.2 68.8±0.1 - - MM-Net [50] 53.37±0.48 66.97±0.35 - - Cos & Att.",0,negative
"CIFAR-FS is a standard benchmark for few-shot learning tasks, containing 100 classes from CIFAR-100 [68].",2,positive
"As shown in Table II, in 1- and 5-shot test, our method attains 10.04% and 4.67% improvement over Fine-tuning [45] on CIFAR-FS dataset.",0,negative
"FC100 is another dataset stemmed from CIFAR-100, which is similar to CIFAR-FS dataset with 100 classes grouped into 20
advanced classes differently.",2,positive
"The extensive experiments on three few-shot learning datasets, CIFAR-FS [32], FC100 [33], and miniImageNet [23], [34] demonstrate that the proposed GCLR achieves remarkable performance in image classification tasks.",2,positive
"Compared to the conference version, GCLR with GNN achieves further improvement in classification accuracy for 5-, 10-, 15-, and 20-shot tasks on CIFAR-FS, FC100, and miniImageNet.",2,positive
"φ is a proportional optimizable parameter which has shown good performance in few-shot learning [32], [33] with SVM and RR as base-learners.",1,neutral
"We evaluate our approach on the miniImageNet, CIFAR-FS and FC100 datasets, and present results demonstrating its advantages over previous work.",2,positive
"For the fully connected layer in the auxiliary task the weight decay is 0.00001 on miniImageNet, and 0.0005 on FC100 and CIFAR-FS.",2,positive
"Experiments on few-shot image classification using the miniImageNet, CIFAR-FS and FC100 datasets confirm these findings, and we observe improved accuracy using the variational approach to train the VERSA model (Gordon et al., 2019).",2,positive
"We integrate SAMOVAR with the deterministic TADAM architecture (Oreshkin et al., 2018), and find that our stochastic formulation leads to significantly improved performance, competitive with the state of the art on the miniImageNet, CIFAR-FS and FC100 datasets.",2,positive
"In Table 3.5, we compare our model to the state of the art on CIFAR-FS.",2,positive
"In the 5-shot setup, the weight decay parameter in the inference networks is 0.00001 on miniImageNet, and 0.00005 on FC100 and CIFAR-FS.",2,positive
"Our stochastic formulation significantly improves performance over the
3.2 Related work 40
base architecture, and yields results competitive with the state of the art on the miniImageNet, CIFAR-FS and FC100 datasets.",2,positive
"We consider three main benchmarks for few-shot learning: MiniIamgeNet, FC100 and CIFAR-FS.",2,positive
"On FC100 and CIFAR-FS, we use 30k SGD updates with the same momentum and initial learning rate, and the latter is decreased after 15k, 20k and 25k updates.",2,positive
"56
3.4 Accuracy and 95% confidence intervals of the state-of-the-art models on the
5-way task on FC100. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
3.5 Accuracy and 95% confidence intervals of the state-of-the-art models on the
5-way task on CIFAR-FS. . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
4.1 Ablation experiments with different continuous adapters. . . . . . . . . . .",1,neutral
"CIFAR-FS (Bertinetto et al., 2019) is another meta-learning dataset derived from CIFAR100.",2,positive
"In R2-D2, Bertinetto et al. (2019) propose to replace the gradient descent or LSTM updates in the inner loop of meta-optimisation models, referred to as the base learners, with standard machine learning algorithms that involve closed-form solutions, such as ridge regression.",1,neutral
"To adapt to the regime of (very) small training datasets, optimisationbased meta-learning techniques replace the vanilla SGD approach with a trainable update mechanism (Bertinetto et al., 2019; Finn et al., 2017; Ravi & Larochelle, 2017).",2,positive
"CIFAR-FS: CIFAR-FS(Bertinetto et al., 2018) dataset used in our experiment is adapted from the CIFAR-100 dataset (Krizhevsky et al.",2,positive
", 2021), we conduct the experiments on four datasets: VGGFlowers(Nilsback & Zisserman, 2008), miniImagenet(Ravi & Larochelle, 2017), CIFAR-FS(Bertinetto et al., 2018), and Omniglot(Lake et al.",2,positive
"Following exiting works (Yap et al., 2021; Zhang et al., 2021), we conduct the experiments on four datasets: VGGFlowers(Nilsback & Zisserman, 2008), miniImagenet(Ravi & Larochelle, 2017), CIFAR-FS(Bertinetto et al., 2018), and Omniglot(Lake et al., 2011).",2,positive
"CIFAR-FS: CIFAR-FS(Bertinetto et al., 2018) dataset used in our experiment is adapted from the CIFAR-100 dataset (Krizhevsky et al., 2009) for few-shot learning, which consists of 100 classes.",2,positive
"Unless otherwise specified, the ablations are performed on CIFAR-FS with the ResNet12, in the 5-way zero-shot setting.",0,negative
2 and 3 presents the experimental results on CIFAR-FS [4] and miniImageNet [47] respectively.,2,positive
"Due to the lack of reliable and scalable baselines of adversarially robust methods in ZSL setting, we first applied LAAT to two popular few-shot benchmark datasets CIFAR-FS [4] and miniImageNet [47] and compared our method with several adversarially robust few-shot methods [14, 42, 50] directly.",2,positive
"In most cases (except ResNet12 on CIFAR-FS), 1-shot performance of LAAT can further surpass the zero-shot performance.",2,positive
"CIFAR-FS [4], a variant of CIFAR100 [24], is a classification dataset containing 64 categories of training data, 16 categories of validation data, and 20 categories of test data for evaluation.",2,positive
"Several studies have shown the adaptation of only the last layer performs quite well (Bertinetto et al., 2018; Lee et al., 2019b; Kumagai et al., 2021).",1,neutral
"…this assumption is not unique to the proposed method but is common to almost all metalearning methods (for anomaly detection) (Snell et al., 2017; Finn et al., 2017; Bertinetto et al., 2018; Rajeswaran et al.,
2019; Kumagai et al., 2021; Frikha et al., 2021; Kruspe, 2019; Kumagai et al., 2019).",2,positive
"However, many iterations can be problematic in the meta-learning since they significantly increase the computation cost (Rajeswaran et al., 2019; Bertinetto et al., 2018).",1,neutral
"Since they require the secondorder derivative of the whole parameters for training, they have considerable computation and memory burdens (Rajeswaran et al., 2019; Bertinetto et al., 2018).",1,neutral
"Recently, “shallow” machine learning methods have been successfully integrated into CNNs for few-shot learning [29], [35], [36].",1,neutral
[6] proposed a differentiable ridge regression classifier to quickly adapt to novel classes.,1,neutral
", 2019) and “R2-D2” (Bertinetto et al., 2018) for more details.",1,neutral
"You can check the paper “ANIL” (Raghu et al., 2019) and “R2-D2” (Bertinetto et al., 2018) for more details.",0,negative
"Geometric ideas such as cosine similarity and Euclidean distance are utilized in [1] and [17], respectively.",1,neutral
"Meanwhile, R2-D2 (Bertinetto et al., 2019) and MetaOptNet (Lee et al., 2019) reduce the dimensionality of trainable model parameters by freezing feature extraction layers during inner loop optimization.",2,positive
"…few gradient steps away from θ (Finn et al., 2017, 2018, Grant et al., 2018, Yoon et al., 2018), while other meta-learning approaches assume that φτ and θ share the parameters in the feature extractor and only differ in the top layer (Bertinetto et al., 2019, Lee et al., 2019, Snell et al., 2017).",1,neutral
"CIFAR-FS (Bertinetto et al., 2019) is a derivative of the original CIFAR-100 dataset by randomly splitting 100 classes into 64, 16, and 20 classes for training, validation, and testing, respectively (Bertinetto et al., 2019).",2,positive
", 2019) is a derivative of the original CIFAR-100 dataset by randomly splitting 100 classes into 64, 16, and 20 classes for training, validation, and testing, respectively (Bertinetto et al., 2019).",2,positive
"CIFAR-FS (Bertinetto et al., 2019) is a derivative of the original CIFAR-100 dataset by randomly splitting 100 classes into 64, 16, and 20 classes for training, validation, and testing, respectively (Bertinetto et al.",2,positive
"Therefore, the temperature scaling factor can be applied to a
0 100 200 300 400 500 600 Singular value index i
0.0
0.2
0.4
0.6
0.8
1.0
No rm
al ize
d sin
gu la
r v al
ue
i/ m
ax miniImageNet
w.o. SWA: ilog i = 68.49 SWA: ilog i = 58.49
0 100 200 300 400 500 600 Singular value index i
0.0
0.2
0.4
0.6
0.8
1.0
No rm
al ize
d sin
gu la
r v al
ue
i/ m
ax
tieredImageNet w.o. SWA: ilog i = 83.98 SWA: ilog i = 80.01
0 100 200 300 400 500 600 Singular value index i
0.0
0.2
0.4
0.6
0.8
1.0
No rm
al ize
d sin
gu la
r v al
ue
i/ m
ax
CIFAR-FS
w.o. SWA: ilog i = 40.94 SWA: ilog i = 33.63
0 100 200 300 400 500 600 Singular value index i
0.0
0.2
0.4
0.6
0.8
1.0
No rm
al ize
d sin
gu la
r v al
ue
i/ m
ax
FC100
w.o. SWA: ilog i = 40.22 SWA: ilog i = 34.34
Figure 2: Normalized singular values for representation with and without SWA.",0,negative
"Meanwhile, R2-D2 (Bertinetto et al., 2019) and MetaOptNet (Lee et al.",2,positive
Note that the proposed method is fundamentally different from R2-D2 and MetaOptNet because our method requires neither episodic meta-learning nor bi-level optimization.,2,positive
We speculate that this property is connected to R2-D2’s few-shot learning driven design and simulation of adapting to new tasks during its inner loop.,2,positive
"As we see from Table 3, with the same fine-tune setting (See Appendix A.2), models pretrained by R2-D2 can achieve ∼ 5% higher top-1 accuracy than those pre-trained by SimCLR after fine-tuning on labeled data.",2,positive
"From the results in Table 4, we find that R2-D2 initialized model consistently outperforms its contrastive counterpart on all 8 datasets.",1,neutral
"Now that we have established a framework for sampling tasks, we can directly apply various metalearning algorithms, such as R2-D2 and ProtoNet described in Section 2.1, in order to learn the parameters θ of the base model F .",2,positive
"These results suggest that for the same number of epochs, a model trained with R2-D2 works better as an initialization for downstream tasks than one trained with SimCLR.",1,neutral
We observe that representations learned via meta-learning (R2-D2 and ProtoNet) can achieve performance on par with SimCLR on CIFAR-10 but worse on ImageNet.,2,positive
"We will see in the following experiments that although R2-D2 achieves worse linear evaluation on ImageNet with this hyperparameter setting, it actually performs better than SimCLR on downstream tasks, such as semi-supervised learning and transfer learning, other popular (and plausibly more realistic) evaluation scenarios for SSL methods.",2,positive
"For the rotation angle predictor loss, we weight the additional loss term with coefficient λ = 1 for all experiments except for pre-training with R2-D2, where we set λ = 0.01.",2,positive
"Meanwhile, meta-learning is an established popular framework for learning models that quickly adapt to on-the-fly tasks given a small number of examples (Hochreiter et al., 2001; Finn et al., 2017; Nichol et al., 2018; Bertinetto et al., 2018; Lee et al., 2019).",1,neutral
"Other algorithms, such as MetaOptNet and R2-D2 (Lee et al., 2019; Bertinetto et al., 2018), keep the feature extractor frozen during fine-tuning; MetaOptNet uses SVM, and R2D2 uses ridge regression on top of the feature extractor.",2,positive
"For CIFAR-FS, our method outperforms best baselines by 4.8% and 5.7% for 10-shot and 20-shot learning, respectively.",2,positive
"For CIFAR-FS, our method outperforms best baselines by 1.5% and 2.3% for 10-shot and 20-shot learning, respectively.",2,positive
"For CIFAR-FS, our method outperforms best baselines by 2.3% and 3.2% for 10-shot and 20-shot learning, respectively.",2,positive
Table 2 shows the evaluation results for 5-way classification on CIFAR-FS and Mini-Imagenet respectively.,0,negative
"To evaluate the effectiveness of the proposed method on more challenging real image datasets, we perform experiments on CIFAR-FS [Bertinetto et al., 2019] and MiniImagenet [Vinyals et al.",2,positive
Results Table 3 shows the evaluation results for 5-way classification on CIFAR-FS and Mini-Imagenet respectively.,0,negative
"In addition, Table 3 shows the evaluation results for 10-way classification on CIFAR-FS and Mini-Imagenet re-
spectively.",0,negative
"For our proposed benchmarks with CIFAR-FS and Mini-ImageNet pre-trained models, our method improves over baselines in the range of 2% to 7%, demonstrating the effectiveness of the proposed approach.",2,positive
"For CIFAR-FS, our method outperforms best baselines by 2.3% and 3.7% for 10-shot and 20-shot learning, respectively.",2,positive
"To evaluate the effectiveness of the proposed method on more challenging real image datasets, we perform experiments on CIFAR-FS [Bertinetto et al., 2019] and MiniImagenet [Vinyals et al., 2016].",2,positive
"While the authors used meta-batch size of 2 for 5-shot and 4 for 2-shot experiment to reduce training memory consumption, we stick to 4 as it leads to slightly better performance on CIFAR-FS [8] dataset during our experiments.",2,positive
For the experiments we have used the novel CIFARFS [8] dataset.,2,positive
"In [8] it has been suggested to split 100 classes into train, validation and test sets.",0,negative
The testing results will be shown on a publicly-available few-shot learning dataset CIFAR-FS [8].,0,negative
The exact classes that go into each split are important for testing the resulting accuracy and are defined in [8].,1,neutral
"R2D2 [Bertinetto et al., 2018] parameterize a feature map φθ : X → R which give rise to a kernel Mθ(x, x′) = ⟨φθ(x), φθ(x)⟩.",1,neutral
"For example, in regression settings, a common choice of inner algorithm is ridge regression and the meta-parameter is a representation or embedding shared across the tasks that we wish to meta-learn [Bertinetto et al., 2018].",1,neutral
"For example, [Bertinetto et al., 2018] considered the case that A performs ridge regression (see Sec.",1,neutral
"Additionally we experiment with using a neural network random feature kernel, an extension of R2D2 [Bertinetto et al., 2018], and show competitive performance.",2,positive
"R2D2 [Bertinetto et al., 2018].",1,neutral
"While most previous work focused on learning a shared data representation or feature map [Bertinetto et al., 2018, Finn et al., 2017, Franceschi et al., 2018] across tasks, here we propose the dual approach of learning a shared kernel function.",1,neutral
"Table 1: Validation results for meta-hyperparameter configurations for IKML, R2D2 [Bertinetto et al., 2018] and ANP [Kim et al.",2,positive
"We evaluate our approach using four datasets: (i) Mini-ImageNet (Vinyals et al., 2016), (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al., 2018), (iv) and EMNIST (balanced) (Cohen et al., 2017).",2,positive
"This occurred around iteration 16,000 for CIFAR-FS and around iteration 20,000 for Mini-ImageNet,
Galanti, György and Hutter
slightly after the first learning rate decay (at 15,000 and 18,000 steps, respectively).",2,positive
"CIFAR-FS and FC-100 are both derived from the CIFAR-100 dataset (Krizhevsky, 2012).",2,positive
"To demonstrate this, we compared the 1- and 5-shot performance of our approach to several other few-shot learning algorithms on the Mini-ImageNet, CIFAR-FS, and FC-100 datasets, as summarized in Table 1.",2,positive
", 2016), (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al.",1,neutral
"CIFAR-FS consists of a random split of the CIFAR-100 classes into 64 meta-train classes, 14 metavalidation classes, and 20 meta-test classes.",2,positive
"Therefore, we empirically investigated the dynamics of mini 6=j∈[l] ‖µf (S̃i)−µf (S̃j)‖ during training in our standard setting (WRN-28-4 with the default hyperparameters, see Section 2) on CIFAR-FS, considering a varying number source classes (l ∈ {5, 10, 20, 30, 40, 50, 60}) and learning rates (η ∈ {2−2i−2}4i=1).",2,positive
"We consider WideResNet (WRN) [46], ResNet-12 [11] and a shallow network of 4 convolutional blocks (CONV) [2].",2,positive
"We use three benchmarks for performance evaluation: miniImageNet [39], CUB [40] and CIFARFS [2].",2,positive
"We meta-train the WRN, ResNet, CONV following [22], [19] and [2], respectively.",2,positive
"For example, the overall performance of WRN outperforms CONV, and the performance boost of ADV-CE over CE with WRN in 1-shot tasks is 10.5%, which is larger than the boost with CONV (4.8%).",2,positive
"[5], the Woodbury formulation, W ∗ = Z (ZZ + λI)−1Y is used to alleviate the problem, leading to an O(d(3)) complexity, where d is the hidden size hyperparameter, fixed to some value (see Appendix D).",1,neutral
"We achieve this by leveraging a ridge regression closed-form solver [5], on top an INR, illustrated in Figure 2b.",1,neutral
"We search through the values μ = [1, 3, 5, 7, 9], and select the best value based on the validation loss.",1,neutral
"We further leverage Implicit Neural Representations [24, 36] as our choice of deep time-index models, a random Fourier features layer [38] to ensure that we are able to learn high frequency information present in time-series data, and a closed-form ridge regressor [5] to efficiently tackle the meta-learning formulation.",2,positive
"As exhibited in Table 4, regardless of whether RRML or PN is used as the classifier, SaAML obtains some performance progress across different datasets in contrast to the published original model and MLADA.",2,positive
"Therefore, this meta-learning framework achieves outstanding performance when combined with distribution signatures, where DS+RRML is the best method.",2,positive
"Ridge Regression Meta-Learner (RRML) (Bertinetto et al., 2018) exploits the ridge regression to obtain the class vector and develops proper regularization to reduce model overfitting and speed up model convergence.",1,neutral
"We adopt RRML (Bertinetto et al., 2018) and PN (Snell
et al., 2017) as the classifier to build the model, respectively.",2,positive
Results on CIFARFS The CIFARFS [3] dataset consists of 100 classes sampled from CIFAR100 [23].,2,positive
Table 4 shows the few-shot accuracies on CIFARFS.,0,negative
"Following [3], we divide all classes into 64, 16, and 20 classes for training, validation, and testing, respectively.",2,positive
"Based on the Conv-4 [46] and ResNet-12 backbones, we conduct experiments on the Omniglot [24], miniImageNet [46], tieredImageNet [41], and CIFARFS [3] datasets.",2,positive
"During the evaluation, we compared our methods on five standard datasets for few-shot classification, miniImageNet [48], tieredImageNet [40], CIFAR-FS [5], FC100 [37], and CUB [49].
miniImageNet and tieredImageNet are subsets of ImageNet [41].miniImageNet consists of 100 classes with 600 samples per class and is randomly divided into three disjoint sets of the training set (64 classes), validation set (16 classes), and testing set (20 classes). tieredImageNet, a bigger version of miniImageNet, contains 608 classes with 1200 samples per class and is randomly split into 351/97/160 for train/val/test.",0,negative
"CIFAR-FS is randomly split into 64/16/20 classes for train/val/test, while FC100 is divided into 60/20/20 classes according to 20 superclasses.",0,negative
"During the evaluation, we compared our methods on five standard datasets for few-shot classification, miniImageNet [48], tieredImageNet [40], CIFAR-FS [5], FC100 [37], and CUB [49].",0,negative
"From table 3, We can see that the transferring effect of miniImageNet on CUB is better than the previous method, and the mutual evaluation effect of miniImageNet and CIFAR-FS is close to the result of the intra-domain training, partly because they both are randomly divided.",2,positive
CIFAR-FS and FC100 both are variants of CIFAR100.,2,positive
"Popular meta-learning algorithms can be roughly divided into three categories: metric-based (Vinyals et al., 2016; Snell et al., 2017; Bertinetto et al., 2018; Oreshkin et al., 2018; Lee et al., 2019), memory-based (Santoro et al.",1,neutral
"(iii) Meta-Dataset-CIO, which consists of three widely-used few-shot datasets: CIFAR-FS (Bertinetto et al., 2018), mini-ImageNet (Vinyals et al., 2016), and Omniglot (Lake et al., 2015).",2,positive
"Popular meta-learning algorithms can be roughly divided into three categories: metric-based (Vinyals et al., 2016; Snell et al., 2017; Bertinetto et al., 2018; Oreshkin et al., 2018; Lee et al., 2019), memory-based (Santoro et al., 2016; Munkhdalai & Yu, 2017), and optimizationbased.",1,neutral
"(iii) Meta-Dataset-CIO, which consists of three widely-used few-shot datasets: CIFAR-FS (Bertinetto et al., 2018), mini-ImageNet (Vinyals et al.",2,positive
"Besides, we also used the cifar-fs (Bertinetto et al., 2019) sampled from cifar-100 dataset (Krizhevsky et al., 2009), which consists of size 32x32 colored images.",2,positive
"We follow the splits for this dataset according to (Bertinetto et al., 2019).",2,positive
"Besides, we also used the cifar-fs (Bertinetto et al., 2019) sampled from cifar-100 dataset (Krizhevsky et al.",2,positive
", 2019) and R2D2 (Bertinetto et al., 2018) consider semiamortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model.",1,neutral
"MetaOptNet (Lee et al., 2019) and R2D2 (Bertinetto et al., 2018) consider semiamortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model.",2,positive
"Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a; Liu et al., 2021a), hyperparamater optimization (Franceschi et al.,…",1,neutral
"Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a; Liu et al., 2021a), hyperparamater optimization (Franceschi et al.",1,neutral
"Instead, many machine learning tasks – such as adversarial learning, meta learning (Franceschi et al., 2018; Bertinetto et al., 2018), hyperparameter optimization (Franceschi et al., 2018; Feurer & Hutter, 2019), reinforcement/imitation learning (Arora et al., 2020; Hong et al., 2020), and neural…",1,neutral
"Instead, many machine learning tasks – such as adversarial learning, meta learning (Franceschi et al., 2018; Bertinetto et al., 2018), hyperparameter optimization (Franceschi et al.",1,neutral
"Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning (Bertinetto et al., 2018; Rajeswaran et al., 2019), hyperparameters and model parameters training in automated hyperparameter tuning (Franceschi et al.",1,neutral
"Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning (Bertinetto et al., 2018; Rajeswaran et al., 2019), hyperparameters and model parameters training in automated hyperparameter tuning (Franceschi et…",1,neutral
"Results on miniImageNet and tieredImageNet: As contending metalearning algorithms, we choose the vanilla MAML along with notable metalearners such as Meta-SGD [12], Reptile [16], LLAMA [7], R2-D2 [3], and BOIL [17].",2,positive
"Here, for example, we examined the 5-way (5 classes) 1-shot task of CIFAR-FS, which is a kind of standard task in one-shot classification.",1,neutral
"Also, for demonstrating evaluation of DNNs in DONE, we used CIFAR-FS [26] by Torchmeta [30].",2,positive
"…the task-shared outerparameters can be the weights of a neural network that acts as a feature extractor that will help a task-specific classifier or regressor parameterized by the inner-parameters to solve the task at hand (Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019).",1,neutral
"The previous formulation can be extended to meta-learning (Schmidhuber, 1987; Finn et al., 2017; Bertinetto et al., 2019) by considering several tasks.",1,neutral
Bertinetto et al. (2019) utilizes ridge-regression based task-specific few-shot learners within a discriminative meta-learning framework.,1,neutral
"The other two are linear classifiers, namely SVM (MetaSVM, Lee et al., 2019) and ridge regression (R2D2, Bertinetto et al., 2019).",1,neutral
"CIFAR-FS: The CIFAR-FS dataset (Bertinetto et al., 2019) contains all the 100 classes form CIFAR100.",2,positive
"(15)
Another choice of base learner is a discriminatively trained linear classifier, e.g., SVM (Lee et al., 2019) or ridge regression (Bertinetto et al., 2019).",1,neutral
"We examined the 5-way (5 classes) 1-shot task of CIFAR-FS, which is a kind of standard task in one-shot classification.",2,positive
"Also, for transfer learning, we used CIFAR-FS [28] by Torchmeta [31].",2,positive
"Furthermore, the EFIL assumption is empirically reasonable, since previous works (Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020) yield comparable performance while leaving the encoder untouched during the inner loop.",2,positive
"Similar ideas of freezing feature extractors during the inner loop have also been explored (Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020), and have been held as an assumption in theoretical works (Du et al., 2021; Tripuraneni et al., 2020; Chua et al., 2021).",1,neutral
"Similar ideas of freezing feature extractors during the inner loop have also been explored (Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020), and have been held as an assumption in theoretical works (Du et al.",1,neutral
"Existing meta-learning benchmarks such as MiniImagenet (Ravi & Larochelle, 2016) or CIFAR-FS (Bertinetto et al., 2018) are unsuitable, as they are built for the traditional few-shot learning setting, in which the task Ti is not associated with task descriptors but is meant to be inferred through…",2,positive
"Existing meta-learning benchmarks such as MiniImagenet (Ravi & Larochelle, 2016) or CIFAR-FS (Bertinetto et al., 2018) are unsuitable, as they are built for the traditional few-shot learning setting, in which the task Ti is not associated with task descriptors but is meant to be inferred through exposure to the support set Dsi.",2,positive
"Existing meta-learning benchmarks such as MiniImagenet (Ravi & Larochelle, 2016) or CIFAR-FS (Bertinetto et al., 2018) are unsuitable, as they are built for the traditional few-shot learning setting, in which the task Ti is not associated with task descriptors but is meant to be inferred through exposure to the support set Ds i.",2,positive
"The optimizedbased approaches [24,4,49,27,48,2,28,79] meta-learn the learning procedures to rapidly update models online with few examples.",1,neutral
", CIFAR-FS [3], miniImageNet [31] and tieredImageNet [26] datasets.",2,positive
"CIFAR-FS [3] is built upon CIFAR-100 dataset [13], which is divided into 64, 16 and 20 categories for training, validation and testing, respectively.",2,positive
", miniImageNet [31], tieredImageNet [26] and CIFAR-FS [3].",2,positive
"Considering that using the prototype-based nearest-neighbor classifier seems unfair for the comparison between the prototypical loss and contrastive losses, we provide the results with ridge regression classifier [6] in Fig.",1,neutral
"The bi-level formulation Problem (4) is closely related to metric-based meta-learning (Snell et al., 2017; Bertinetto et al., 2019), where a shared representation fθ̂ is learned across all tasks.",1,neutral
"To accelerate the meta-training, literature [29] and [30] propose two approaches to accelerate meta-training via closed-form solvers in the inner step progress.",1,neutral
"This class of problems has attracted great attention due to their applications in hyper-parameter optimization [15, 46], meta-learning [4, 42], and reinforcement learning [23, 28], to name a few.",1,neutral
"In practice, 1) we never specify exactly what and how big the underlying set of classes that we care about is, and 2) many of the recent meta-learning methods (svm vs pn on CIFAR-FS Table 2 in Lee et al. [18], gnn vs r2-d2 on miniImageNet Table 1 in Bertinetto et al. [3], and ironically fix-ml) sometimes only improve over the prior works by < 1%.",2,positive
"(ii) CIFAR-FS-Mod (cifar-M) and FC-100-Mod (FC-M): As we don’t have additional samples for the base classes, we randomly partition each base class’s 600 examples into a 500, 100 split where the meta-training tasks are constructed only from the 500 examples and the remaining 100 examples are reserved to generate fresh tasks from τ(CB).",2,positive
"2) Datasets: We consider three of the most widely-used few-shot learning benchmarks: (i) miniImageNet (mini) [31], which consists of 100 ImageNet [25] classes of 84 × 84 images, randomly split into 64 base, 16 validation, and 20 novel classes; (ii) CIFAR-FS (cifar) [3] with an identically sized random base-val-novel split of the CIFAR-100 [17] dataset of 32× 32 images; (iii) FC-100 (FC) [20], another split of the CIFAR-100 dataset, where the split is according to 20 super classes (each having 5 classes).",2,positive
"[3] correctly claimed that methods like rr and svm outperform pn on τ(CN ) for these benchmarks, but if we consider the BaseGen performance, pn consistently performs the best.",2,positive
", miniImageNet [31] and CIFAR-FS [3]) are particularly popular for evaluating meta-learning methods on this objective.",1,neutral
"Always using fix-ml could potentially cause meta-test performance loss if the meta-test task distribution is not that different from τ(CB), e.g., the continual learning task distribution in CIFAR-FS-Mod when λ = 20/(64 + 20) ≈ 0.238 in Figure 1.",1,neutral
"However, for many widely used FSL benchmarks (miniImageNet, CIFAR-FS, FC-100), only 20 novel classes are used for meta-test evaluation.",2,positive
"To fully evaluate the performance differences, we compare fix-ml and ml along two major axes: 1) Metalearning methods: We explore using fix-ml’s modified objective with three state-of-the-art meta-learning methods: protoypical-networks (pn) [28], MetaOptNet-SVM (svm) [18], and MetaOptNet-Ridge Regression (rr) [3, 18].",2,positive
"Moreover, many works [3, 18, 22, 28] that propose new meta-learning methods do not explicitly state whether their method is intended to perform well in-distribution or out-of-distribution, yet only evaluate empirically on the out-of-distribution FSL benchmarks, leading to ambiguous and possibly incorrect claims that their methods generally work well in both settings.",1,neutral
"[3], and ironically fix-ml) sometimes only improve over the prior works by < 1%.",1,neutral
"Few-shot classification benchmarks (e.g., miniImageNet [31] and CIFAR-FS [3]) are particularly popular for evaluating meta-learning methods on this objective.",1,neutral
"Table 1 and 2 summarize the results of the few-shot classification tasks on CIFAR-FS, FC100, and mini-ImageNet, respectively.",0,negative
"The CIFAR-FS dataset (Bertinetto et al., 2018) is a few-shot classification benchmark containing 100 classes from CIFAR-100 (Krizhevsky et al., 2009).",2,positive
"We broadly divide the existing few-shot learning approaches into three categories: (1) Gradient-based methods optimize feature embedding with gradient descent during meta-test stage (Finn et al., 2017; Bertinetto et al., 2018; Lee et al., 2019).",2,positive
"Our ResNet-12 model beats (Lee et al., 2019) 1-shot result by 2.7% on FC100, 3.4% on CIFAR-FS, and 1.72% on mini-ImageNet.",0,negative
"1 DATASETS We adopt three standard benchmark datasets that are widely used in few-shot learning, CIFAR-FS dataset (Bertinetto et al., 2018), FC100 dataset (Oreshkin et al.",2,positive
"We demonstrate the effectiveness of our approach on standard few-shot benchmarks, including FC100 (Oreshkin et al., 2018), CIFAR-FS (Bertinetto et al., 2018) and mini-ImageNet (Vinyals et al., 2016) by showing a significant improvement over the existing methods.",2,positive
", 2018), CIFAR-FS (Bertinetto et al., 2018) and mini-ImageNet (Vinyals et al.",2,positive
"We adopt three standard benchmark datasets that are widely used in few-shot learning, CIFAR-FS dataset (Bertinetto et al., 2018), FC100 dataset (Oreshkin et al., 2018), and mini-ImageNet dataset (Vinyals et al., 2016).",2,positive
CIFARFS is a recently proposed few-shot classification benchmark.,2,positive
"In Table 5 of Appendix A, we also test MAML-L and TSA-MAML on CIFARFS [Bertinetto et al., 2019] and observe that TSA-MAML makes about at least 1.",2,positive
"1 3 5 7 9 11 13 15 Number m of Initializations
36
38
40
42
44
46
Cl as
si fic
at io
n Ac
cu ra
cy (
% )
38.48
40.52 39.77 40.44 40.55 40.19 39.75 39.12
39.97
42.91 42.18 42.59 42.67 42.57 41.91
41.29
1-shot 10-way on CIFARFS Non-transduction Transduction
Figure 4: Effects of m to TSA-MAML.",0,negative
"Specifically, on CIFARFS, TSAMAML respectively brings about 1.09%, 2.46%, 1.29% and 2.81% improvements on the four test cases (from left to right) under non-transduction setting, and under transduction setting it also makes about 0.75%, 0.77%, 2.21% and 2.48% improvements for the four cases.",0,negative
"In TSA-MAML, the training iteration number S is 40, 000 for CIFARFS and 80, 000 for tieredImageNet and miniImageNet, and the cluster number m is five for all datasets.",2,positive
"We evaluate TSA-MAML on three benchmarks, CIFARFS [Bertinetto et al., 2019], tieredImageNet [Ren et al., 2018] and miniImageNet [Ravi and Larochelle, 2017] .",2,positive
%) of the compared approaches on the CIFARFS dataset.,2,positive
"Besides, compared with MAML, TSA-MAML respectively makes about 1.73% and 1.44% average improvements on CIFARFS and tieredImageNet.",2,positive
"In Table 5 of Appendix A, we also test MAML-L and TSA-MAML on CIFARFS [Bertinetto et al., 2019] and observe that TSA-MAML makes about at least 1.5% average improvement on the four test settings (n-way k-shot, n = 5 or 10 and k = 1 or 5) over both MAML and MAML-L.",0,negative
"We evaluate TSA-MAML on three benchmarks, CIFARFS [Bertinetto et al., 2019], tieredImageNet [Ren et al.",2,positive
"Specifically, we sequentially meta-train VC-BML and baselines on: VGG-Flowers, miniImagenet, CIFAR-FS and Omniglot, and show the experimental results in Figure 1.",2,positive
"In the setting of non-stationary task distribution, we sequentially meta-train VC-BML on four datasets: Omniglot, CIFAR-FS, miniImagenet and VGG-Flowers.",2,positive
"We use the same split as [12]: 64 classes for meta-training, 16 classes for validation and 20 classes for meta-test.",2,positive
"In the settings of nonstationary task distribution, we use an inner learning rate of 0.1, an outer learning rate of 0.001 on Omniglot and CIFAR-FS, and use an inner learning rate of 0.01, an outer learning rate of 0.0001 on miniImagenet and VGG-Flowers.",2,positive
"For example, on CIFAR-FS, the accuracies of parametric methods (FTML, OSML, DPMM and OSAKA) decrease from 69.79%-71.41% to 52.29%-59.74% at the end of training, while the accuracies of Bayesian methods (BOMVI, VC-BML) barely change (from 69.12%-75.61% to 70.16%-75.20%).",0,negative
"Note that on CIFAR-FS, miniImagenet and VGG-Flowers datasets, we follow the same preprocessing steps as Omniglot to generate a sequence of tasks.",2,positive
Similar results can also be found on CIFAR-FS and miniImagenet datasets.,2,positive
"From Figure 3, we can observe that similar results can also be found on CIFAR-FS and miniImagenet datasets.",2,positive
"In the settings of non-stationary task distribution, we use 5 inner gradient descent steps with an inner learning rate of 0.01, and use an outer learning rate of 0.001 on Omniglot, 0.0001 on CIFAR-FS, miniImagenet and VGG-Flowers.",2,positive
"To learn OSAKA, we use 3 inner gradient descent steps with an inner learning rate of 0.1, and use an outer learning rate of 0.001 on Omniglot, CIFAR-FS, 0.0001 on miniImagenet, VGG-Flowers.",2,positive
CIFAR-FS [12]: CIFAR-FS is adapted from the CIFAR-100 dataset [13] for few-shot learning.,2,positive
"It can be observed from Figure 3 that Bayesian methods, i.e., VC-BML and BOMVI, always obtain the best and the second best performance on unseen tasks, i.e., miniImagenet and VGG-Flowers at CIFAR-FS meta-training stage and VGG-Flowers at miniImagenet meta-training stage.",2,positive
"CIFAR-FS [1] is an anagolous version of miniImagenet, but for CIFAR-100.",2,positive
"For tieredImageNet only we increased the batch size to 1024, and train on 64 classes (like miniImageNet and CIFAR-FS) and 16 images per class within a batch, as we found it being beneficial.",0,negative
"For miniImageNet and CIFAR-FS we decrease the learning rate by a factor of 10 after 70% of epochs have been trained, and train for a total of 120 epochs.",2,positive
"All our miniImageNet and CIFAR-FS experiments took about 2 hours to finish training, and the tieredImageNet experiments took 8 hours per model.",0,negative
Results on miniImageNet and CIFAR-FS are shown in Table 4.,0,negative
"For CIFAR-FS and tieredImageNet, we found this did not help performance.",2,positive
"On CIFAR-FS, we increase the number of training epochs from 120 to 240, which improved accuracy by about 0.5%.",2,positive
"The model is trained for 100 epochs, with each epoch consisting of 600 randomly sampled episodes for both 1-shot and 5-shot cases on MiniImageNet, CUB-200-2011, CIFAR-FS and FC100 datasets, and is evaluated by averaging metrics over 600 randomly generated episodes from Dn, with each episode having 15 randomly sampled query samples.",2,positive
"Table 1 and Table 2 summarize the results of the few-shot classification tasks on MiniImageNet, CIFAR-FS, FC100, and CUB-200-2011, respectively.",0,negative
", 2011), CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al.",1,neutral
"We conduct a comparison of our method to state-of-the-art methods in terms of few-shot classification accuracy on four benchmarks, including MiniImageNet (Vinyals et al., 2016), CUB-200-2011 (Wah et al., 2011), CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al., 2018).",2,positive
"To further validate the effectiveness of our method, we conduct a series of ablation studies on miniImageNet and CIFAR-FS datasets.",2,positive
"As shown in Figure 3(b), we can observe that, the optimal λ for MiniImageNet in 1- shot and 5-shot cases are 0.2 and 0.3, respectively, while for the CIFAR-FS dataset, the optimal λ reaches at 0.1 for both 1-shot and 5-shot cases.",1,neutral
We sample one episode in the test split of miniImageNet and CIFAR-FS datasets under the 5-way 1-shot and 5-way 5-shot settings.,2,positive
CUB-2002011 is initially designed for fine-grained classification and CIFAR-FS is a subset of CIFAR-100 for few-shot classification.,2,positive
"Meanwhile, partial experimental results on the CIFAR-FS dataset dropped slightly, the reason of which might lie in the categories in the CIFAR-FS dataset are highly distinguishable.",0,negative
"Experimen-
tal results demonstrate that it improves the performance of recently proposed GNN-based methods on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB-200-2011, and CIFAR-FS.",2,positive
"To evaluate our module, we select two GNN-based few-shot models: EGNN and DPGN, and four standard few-shot learning benchmarks: mini-ImageNet [20], tiered-ImageNet [28], CUB-200-2011 [29] and CIFAR-FS [30].",2,positive
"• The comprehensive experimental results on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB200-2011, and CIFAR-FS show that our proposed module is effective for GNN-based few-shot model.",2,positive
"5% improvement for miniImageNet [5], CIFAR-FS [1], and FC100 [3] datasets respectively (section 4.",2,positive
To further investigate the effect of knowledge distillation we perform multiple stages of self knowledge distillation on CIFAR-FS [1] dataset.,2,positive
"13% for miniImageNet [5], CIFAR-FS [1], and FC100 [3] datasets respectively (section 4.",0,negative
We conduct an ablation study to measure the effect of different values of the coefficient of inductive loss (without multi-head distillation) on the CIFAR-FS [1] validation set; the results of 5-way 1-shot FSL tasks are presented in fig.,2,positive
To analyse the effect of knowledge distillation temperature (for Kullback Leibler (KL) divergence losses) we conduct an ablation study on the validation set of CIFAR-FS [1] dataset.,2,positive
"The CIFAR-FS dataset consists of 100 classes from CIFAR-100 randomly divided into groups of 64, 16 and 20 for training, validation, and testing datasets respectively.",2,positive
CIFAR-FS.,2,positive
"The CIFAR-FS and FC100 datasets have a structure of coarse classes where distinct classes are
grouped together based on semantic similarities e.g., insects is a coarse class that might contain finer classes such as bee, butterfly.",1,neutral
"We conducted experiments on four datasets – CIFAR-FS [16], FC100 [25], miniImageNet [9] and tieredImageNet [21] (Tables 1, 2, 3, 4).",2,positive
R2D2 [16] and MetaOptNet [2] improved accuracy by using Ridge Regression and SVM as classifier correspondingly.,2,positive
"We designed several experiments settings, according to the Section 3.3, to research the relative advantage of using the multi-task loss function (3) and SPSA-based optimization against original methods: MTM Backprop, where multi-task weights in the loss function are optimized jointly with the network parameters θ; MTM Inner First-Order, where a separate gradient-based multi-task weights optimizer is used; MTM SPSA and MTM SPSA-Track where zero-order methods (5) and (6) are used as a multi-task weights optimizer respectively; MTM SPSA-Coarse (on CIFAR-FS and FC100) which used SPSA-based approach (5) but had a separate weight per coarse class as in (7).",2,positive
"On CIFAR-FS we improve against original method up to 2.0%, with the largest improvement in 1-shot 2-way MAML MTM SPSA-Track.",2,positive
"Note that unlike other algorithms in the literature, we evaluate our frame-
1https://github.com/eriklindernoren/PyTorch-GAN
Dataset CIFAR100 miniImagenet CUB200 TieredImagenet
5way-5shot 2way-5shot 5way-5shot 2way-5shot 5way-5shot 2way-5shot 5way-5shot 2way-5shot
Pretrain 74.93% 95.61% 69.00% 95.54% 90.00% 89.27% 46.00% 66.70% Incremental 88.57% 96.77% 83.57% 95.56% 87.00% 86.98% 69.58% 78.68%
Table 2: 5 shot Results for SemGIF using Resnet-50 backbone encoder
Dataset CIFAR100 miniImagenet CUB200 TieredImagenet
pretrain Accb Inc AccH Inc Accb Inc Accn pretrain Accb Inc AccH Inc Accb Inc Accn pretrain Accb Inc AccH Inc Accb Inc Accn pretrain Accb Inc AccH Inc Accb Inc Accn
5-way 5-shot 66.52 79.95 87.27 73.76 63.63 75.49 86.09 67.22 84.41 86.56 91.09 82.46 47.23 69.89 83.16 60.27 2-way 5-shot 93.40 91.23 84.82 98.68 95.41 95.21 92.44 98.15 88.12 83.56 88.22 79.37 69.44 79.71 94.39 68.98 5-way 1-shot 44.22 57.21 75.50 46.06 40.22 56.75 71.89 46.87 43.01 57.35 67.31 49.96 33.04 55.63 67.25 47.43 2-way 1-shot 69.08 75.74 74.46 77.06 65.21 75.16 71.32 79.44 64.13 58.44 70.30 50.00 60.03 62.23 71.19 55.28 5-way 10-shot 72.65 87.61 94.64 81.54 69.82 83.39 92.09 76.20 91.56 87.45 85.00 90.03 51.85 68.47 94.20 53.78 2-way 10-shot 96.24 97.74 96.67 98.84 96.27 96.59 94.52 98.75 90.00 89.24 88.22 79.37 71.55 81.95 95.64 71.68
Table 3: IFSL Results on multiple combinations of N-way K-shot across the four datasets
work across a wider variety of datasets.",0,negative
"We consider a total of four standard datasets to evaluate the proposed SemGIF framework: CIFAR100 [3], miniImagenet [39], CUB200-2011 [40] and TieredImagenet [28].",2,positive
"We also have employed batch-norm between the layers in the image branch, text branch, and the Visual-to-semantic mapping networks, while the embedding function also utilizes a dropout with p= 0.5 between its layers. fastText word
Dataset CIFAR100 miniImagenet CUB200 TieredImagenet*
Method 5way-1shot 5way-5shot 5way-1shot 5way-5shot 5way-1shot 5way-5shot 5way-1shot 5way-5shot
ProtoNet [34] B1 40.96% 62.50% 41.07% 55.15% 29.45% 46.00% 30.04% 41.38% CADA-VAE [32] B2 - - - - 54.15% 62.05% - - aCASTLE [44] B2 - - 43.63 % 56.33% - - 22.23% 33.54% LwoF [9] - - 52.37% 59.89% - - 52.40% 62.63% Imprint [25] - - 41.25% 43.92% 47.62% 61.59% 39.13% 53.60% Attractor [27] - - 53.62% 62.83% - - 56.11% 65.52% XtarNet [45] - - 55.28% 66.86% - - 61.37% 69.58%
Ours without semantic 42.86% 55.17% 38.98% 49.89% 39.74% 63.29% 49.65% 62.83% Ours (full) 57.21% 79.95% 56.75% 75.49% 57.35% 86.56% 55.63% 69.89%
Table 1: A comparative study with existing algorithms in the literature.",0,negative
"Base Dataset CIFAR100 miniImagenet CUB200 TieredImagenet
Novel Dataset 5way-1shot 5way-5shot 5way-1shot 5way-5shot 5way-1shot 5way-5shot 5way-1shot 5way-5shot
CIFAR100 - - 60.73% 81.00% 57.91% 78.63% 54.87% 78.45% miniImagenet 55.89% 75.95% - - 51.41% 75.68% 50.69% 74.86% CUB200 56.32% 84.61% 57.19% 83.03% - - 50.38% 82.19% TieredImagenet 55.19% 69.07% 55.88% 67.75% 51.42% 69.49% - -
Table 4: Heterogeneous evaluation by choosing Dbase and Dnovel from different domains
Heterogeneous evaluation study: We perform a heterogeneous evaluation study using the standard datasets considered.",0,negative
"On 5-way-1-shot, it slightly underperforms compared to a few methods ([27], [49]) on Mini-ImageNet and CIFAR-FS.",2,positive
"We use 4 datasets to evaluate few-shot learning algorithms - MiniImageNet [51], Tiered-ImageNet [39], CIFAR-FS [1] & FC100 [35]:",2,positive
"• CIFAR-FS : CIFAR-FS contains all 100 classes from CIFAR-100 [25] and the classes are randomly split into 64, 16 and 20 for training, validation and testing with each class contains 600 images.",0,negative
"On the other hand, optimization based methods use a bi-level optimization to facilitate learning-to-learn and differ in the choice of inner/base learner - MAML [12] uses a linear predictor, MetaOptNet [27] uses SVM [8] & R2D2 [1] uses ridge regression.",1,neutral
"We use 4 datasets to evaluate few-shot learning algorithms - MiniImageNet [51], Tiered-ImageNet [39], CIFAR-FS [1] & FC100 [35]:
• Mini-ImageNet : Mini-ImageNet contains 100 randomly chosen classes from ILSVRC-2012 [41] and these classes are randomly split into 64, 16 and 20 classes for train, validation and test with each class containing 600 images.",2,positive
", 2017), ridge regression classifier (Bertinetto et al., 2019) and SVM classifier (Lee et al.",1,neutral
"The compared methods include ProtoNet, MetaOptNet-RR and MetaOptNet-SVM, whose task-specific learners are nearest-neighbor classifier (Snell et al., 2017), ridge regression classifier (Bertinetto et al., 2019) and SVM classifier (Lee et al., 2019), respectively.",2,positive
"The CIFAR-FS dataset (Bertinetto et al., 2019) is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100.",2,positive
"2 Experiments on CIFAR derivatives The CIFAR-FS dataset (Bertinetto et al., 2019) is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100.",2,positive
"To understand and explain the success of popular meta-representation learning approaches such as ANIL [43], MetaOptNet [36], R2D2 [9], and OML [33], we study a alternating gradient-descent minimization (AltMinGD) method (and its variant alternating minimization (AltMin) in the Appendix) which underlies the aforementioned methods.",2,positive
"This is becoming increasingly popular with empirical successes in the few-shot learning scenarios [33, 36, 9, 42, 43, 27, 47, 14].",1,neutral
"This approach is becoming increasingly popular with a growing list of recent applications [33, 36, 9, 42, 43, 27, 47, 14, 13, 18] and has been empirically shown to achieve the state-of-the-art performances on benchmark few-shot learning datasets [47, 14, 43].",1,neutral
"Several closely related algorithms have been proposed, including separating training-set used for the inner loop and the validation-set used for the outer-loop [43, 36, 9, 5], early stopping the inner-loop [33], applying to datasets with imbalanced data sizes [42, 14], and proposing new architectures and regularizers [27].",1,neutral
"Several variations of this algorithm are widely used, for example [43, 36, 9].",1,neutral
"Based on deep kernels [42], recent state-of-the-arts (R2D2 [4], MetaOptNet [22], and DKT [26]) propose to use a base kernel in the base learner and update the deep network in the meta-learner.",2,positive
"Typical models include non-parametric prototype classifier (ProtoNet [35]), linear models like ridge regression (R2D2 [4]), SVM classifier (MetaOptNet-SVM [22]), and softmax classifier (ANIL [27]).",1,neutral
"We compare MetaProx with the state-of-the-arts: (i) meta-initialization: MAML [12] and its variants FOMAML [12], and REPTILE [25]; (ii) meta-regularization: iMAML [28] and Meta-MinibatchProx [43]; and (iii) metric learning: ANIL [27], R2D2 [4], ProtoNet [35], and MetaOptNet [22] with SVM using the linear kernel and cosine kernel.",2,positive
"Popular meta-learning algorithms usually construct the task-specific model by: (i) metainitialization [12, 25, 11, 38], (ii) meta-regularization [7, 8, 9, 28, 43], or (iii) metric learning [35, 4, 22, 27].",1,neutral
"In particular, the base learners in R2D2 [4], MetaOptNet [22] and DKT [26] seek solutions in the dual space, which achieve state-ofthe-art performance.",2,positive
"By setting fθ = 0, this recovers the state-of-the-arts of MetaOptNet [22], R2D2 [4], and DKT [26].",2,positive
"For example, R2D2 [4] and MetaOptNet [22] use deep kernels [42] in meta-learning for few-shot",1,neutral
"With the dual formulation, θ in (2) allows extra flexibility over [22, 4, 7].",1,neutral
"Metric learning methods have been widely studied in few-shot learning [39, 35, 4, 22, 27].",1,neutral
"We perform our experiments on four benchmark datasets: MiniImageNet [10], CUB [11], CIFAR-FS [12] and TieredImageNet [13].",2,positive
"Existing few-shot learning methods based on data augmentation [16], [17], [18], metric learning [19], [20], [21], and initialization [22], [23], [24] ameliorate the models in terms of supervised empirical growth, hypothesis space reduction, and initial parameter setting, respectively, so as to enhance the generalization ability of the models under",2,positive
"Metric learning-based approaches [19], [20], [21] imar X iv :2 10 3.",1,neutral
"Numbers of metric learning algorithms have been explored including centroids based method, dimensionality reduction based method and so on[13], Euclidean distance to class-mean representations [14], CNN relation modules [15], ridge regression [16], and graph neural networks [17].",1,neutral
"Ridge Regression Meta-Learner (Bertinetto et al., 2019) (RRML) calculates the class vector by solving a Ridge regression problem on the support set.",1,neutral
"LaSAML with other meta-learning framework To further explore the potential of LaSAML, we incorporate it into the Ridge Regression Meta-learner (RRML) (Bertinetto et al., 2019), which is achieved by simply replacing the feature extractor f and g with the feature extractors used in LaSAML-PN.",2,positive
"…this setting as “few-shot learning” and it is considered as the primary setting to evaluate meta-learning algorithms [San-
toro et al., 2016, Finn et al., 2017, 2018, Ren et al., 2018a], even if meta-models can be defined over a broader variety of learning problems [e.g., Bertinetto et al., 2019].",1,neutral
"Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a; Liu et al., 2021a), hyperparamater optimization (Franceschi et al.,…",1,neutral
"Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a; Liu et al., 2021a), hyperparamater optimization (Franceschi et al.",1,neutral
"They can also be extended to other applications such as regression and image classification by changing the architecture and training objective [22, 62, 6, 41].",1,neutral
"They can also be extended to other applications such as regression and image classification by changing the architecture and training objective (Finn et al., 2017a; Rusu et al., 2019; Bertinetto et al., 2019; Lee et al., 2019).",2,positive
"These models learn by conditioning predictions on distance metrics such as cosine similarity [39], Euclidean distances [33], network based [36], ridge regression [3], convex optimization based [25], or graph neural networks [32].",1,neutral
"A common framework for such settings is few-shot learning [10, 18, 41, 53, 58, 64].",1,neutral
"The adaptation of the entire network makes it hard to be scaled to large networks, and many recent efforts focus on adapting the last classification layer only [14, 5], while assuming a universal feature extractor that is shared across all tasks.",1,neutral
"Note the trainable temperature ⌧ here allows automatic scaling to the unnormalized multi-class posterior predictive, and a similar implementation can also be found in [5].",1,neutral
"Similar to previous works [4, 25], we conduct experiments on four datasets: Omniglot [35], CIFARFS [36], miniImagenet [37] and VGG-Flowers [38].",2,positive
"2 [6] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi.",0,negative
"However, the typical meta-testing stage just adapts the last classification head with the frozen backbone, which is commonly a fully connected (FC) layer [6].",2,positive
"5-way few-shot classification accuracies (%) on mini-ImageNet [66], tiered-ImageNet [51], and CIFAR-FS [4].",0,negative
"We evaluate our approach on three standard few-shot classification datasets: miniImageNet [66], tiered-ImageNet [51], and CIFAR-FS [4].",2,positive
"Much progress has been made in these settings with some state-of-the-art methods, such as MAML [6], Reptile [24], MetaOptNet [12], and R2-D2 [4].",2,positive
"More precisely, the value of t0 is drawn from the set: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512], while the time budget T is set to 512.",1,neutral
"CIFAR-FS & FC100 Proposed by Bertinetto et al. (2019) and Oreshkin et al. (2018), both are splits between the original classes of CIFAR100 (Krizhevsky et al.).",2,positive
"In order to predict weights, MetaOpt Net [28] advocates SVM, R2-D2 adopts ridge regression layer [29], while Dynamic Net [30] uses a memory module.",2,positive
"One prominent line of research is to increase the interdependence between the base learner and the metalearner by adjusting the optimization process to ensure feedback is sent in both directions [29, 18, 19, 9].",1,neutral
"This can be visualized as a double-loop architecture [45, 9], where the base learner iterates over a training set to learn model parameters under a fixed hypothesis space, in what is described as the inner loop, while concurrently, the metalearner iterates over different tasks to learn metaparameters under a family of hypothesis spaces, in what is described as the outer loop (see Figure 3).",1,neutral
"Table 1 and 2 summarize the results of the few-shot classification tasks on CIFAR-FS, FC100, and mini-ImageNet, respectively.",0,negative
"We broadly divide the existing few-shot learning approaches into three categories: (1) Gradient-based methods optimize feature embedding with gradient descent during meta-test stage (Finn et al., 2017; Bertinetto et al., 2018; Lee et al., 2019).",2,positive
"Our ResNet-12 model beats (Lee et al., 2019) 1-shot result by 2.7% on FC100, 3.4% on CIFAR-FS, and 1.72% on mini-ImageNet.",0,negative
"We demonstrate the effectiveness of our approach on standard fewshot benchmarks, including FC100 (Oreshkin et al., 2018), CIFAR-FS (Bertinetto et al., 2018) and mini-ImageNet (Vinyals et al., 2016) by showing a significant improvement over the existing methods.",2,positive
"A.1 DATASETS The CIFAR-FS dataset (Bertinetto et al., 2018) is a few-shot classification benchmark containing 100 classes from CIFAR-100 (Krizhevsky et al., 2009).",2,positive
", 2018), CIFAR-FS (Bertinetto et al., 2018) and mini-ImageNet (Vinyals et al.",2,positive
"We adopt three standard benchmark datasets that are widely used in few-shot learning, CIFAR-FS dataset (Bertinetto et al., 2018), FC100 dataset (Oreshkin et al., 2018), and mini-ImageNet dataset (Vinyals et al., 2016).",2,positive
"We adopt three standard benchmark datasets that are widely used in few-shot learning, CIFAR-FS dataset (Bertinetto et al., 2018), FC100 dataset (Oreshkin et al.",2,positive
"CIFAR-FS, on the other hand, is similar to miniImageNet, where the dataset is randomly split.",2,positive
"In particular, miniImagenet meta-train set is used for meta-training, while corresponding meta-test splits of Omniglot [7], FC100 [12], and CIFAR-FS [3] are used for evaluation.",2,positive
"B Additional Experiments on Few-Shot Classification We further validate the effectiveness of our proposed dynamic inner-loop update rule ALFA, through evaluating the performance on the relatively new CIFAR100-based [6] few-shot classification datasets: FC100 (Fewshot-CIFAR100) [12] and CIFAR-FS (CIFAR100 few-shots) [3].",2,positive
Table B: Test accuracy on 5-way classification for FC100 and CIFAR-FS.,0,negative
"All models are only trained with miniImageNet meta-train set and tested on various datasets (domains) without any fine-tuning.
miniImageNet
→ Omniglot → FC100 → CIFAR-FS ALFA + Random Init 91.02± 0.29% 62.49± 0.48% 63.49± 0.45% MAML [4] 85.68± 0.35% 55.52± 0.50% 55.82± 0.50% ALFA + MAML 93.11± 0.23% 60.12± 0.49% 59.76± 0.49% MAML + L2F [2] 94.96± 0.22% 61.99± 0.49% 63.73± 0.48% ALFA + MAML + L2F 94.10± 0.24% 63.33± 0.45% 63.87± 0.48%",0,negative
"We further validate the effectiveness of our proposed dynamic inner-loop update rule ALFA, through evaluating the performance on the relatively new CIFAR100-based [6] few-shot classification datasets: FC100 (Fewshot-CIFAR100) [12] and CIFAR-FS (CIFAR100 few-shots) [3].",2,positive
"Backbone FC100 CIFAR-FS
1-shot 5-shot 1-shot 5-shot
Random Init 4-CONV 27.50± 0.45% 35.37± 0.48% 29.74± 0.46% 39.87± 0.49% ALFA + Random Init 4-CONV 38.20± 0.49% 52.98± 0.50% 60.56± 0.49% 75.43± 0.43% MAML † [4] 4-CONV 36.67± 0.48% 49.38± 0.49% 56.80± 0.49% 74.97± 0.43% ALFA + MAML 4-CONV 37.99± 0.48% 53.01± 0.49% 59.96± 0.49% 76.79± 0.42% MAML + L2F † [2] 4-CONV 38.96± 0.49% 53.23± 0.48% 60.35± 0.48% 76.76± 0.42% ALFA + MAML + L2F 4-CONV 38.50± 0.47% 53.20± 0.50% 60.36± 0.50% 76.60± 0.42% Random Init ResNet12 32.26± 0.47% 42.00± 0.49% 36.86± 0.48% 49.46± 0.50% ALFA + Random Init ResNet12 40.57± 0.49% 53.19± 0.50% 64.14± 0.48% 78.11± 0.41% MAML † ResNet12 37.92± 0.48% 52.63± 0.50% 64.33± 0.48% 76.38± 0.42% ALFA + MAML ResNet12 41.46± 0.49% 55.82± 0.50% 66.79± 0.47% 83.62± 0.37% MAML + L2F † ResNet12 41.89± 0.47% 54.68± 0.50% 67.48± 0.46% 82.79± 0.38% ALFA + MAML + L2F ResNet12 42.37± 0.50% 55.23± 0.50% 68.25± 0.47% 82.98± 0.38% Prototypical Networks∗ [17] 4-CONV 35.3± 0.6% 48.6± 0.6% 55.5± 0.7% 72.0± 0.6% Relation Networks [18] 4-CONV+ - - 55.0± 1.0 69.3± 0.8 TADAM [12] ResNet12 40.1± 0.4% 56.1± 0.4% - - MetaOpt ‡ [8] ResNet12 41.1± 0.6% 55.5± 0.6% 72.0± 0.7% 84.2± 0.5%
* Meta-network is trained using the union of meta-training set and meta-validation set.",0,negative
"3We exactly reproduced MetaOptNet on CIFAR-FS, but were unable to close the gap on miniImageNet.",2,positive
"Lastly, alternative optimization-based methods train a meta feature extractor followed by different base learners such as ridge or logistic regression in [6, 49], and support vector machine (SVM) in [21].",1,neutral
"CIFAR-FS [6] is a popular few-shot classification benchmark, designed to be more complicated than the previous Omniglot [20] yet more compact than miniImageNet [53].",2,positive
"In addition to comparing with ProtoNets [44] and R2D2 [6] on their original small backbones, we also compare with these two methods with larger convolutional backbones.",1,neutral
We follow this practice to use 15-shot episodes for miniImageNet and 5-shot for CIFAR-FS.,2,positive
"We compare against a few competitive methods, including MAML [10], ProtoNets [44], Relation Networks [45], R2D2 [6], MetaOptNet [21] and RFS [48].",2,positive
"However, the optimization for correction terms require a set of models, while most recent meta-learning frameworks assume to learn a single model [6, 10, 21, 27, 40, 49], limiting the general applicability of [1].",1,neutral
"On a separate note, although many meta-learning frameworks [21, 40] have achieved impressive results on few-shot learning benchmarks such as CIFAR-FS and miniImageNet [53], task representation remains to be rarely exploited.",1,neutral
"2 Experiments on CIFAR-FS CIFAR-FS [6] is a popular few-shot classification benchmark, designed to be more complicated than the previous Omniglot [20] yet more compact than miniImageNet [53].",2,positive
Each class in CIFAR-FS contains 600 images of size 32×32.,1,neutral
"Interestingly, We find that once we try replace the backbone feature extractor with the same ResNet-12 used in MetaOptNet, ProtoNets and R2D2 both show competitive results, and especially R2D2 already performs better than MetaOptNet just by ensuring a fair backbone.",2,positive
"In this section, we first describe the implementation details (Section 4.1), and then benchmark MATE on two few-shot classification datasets, CIFAR-FS [6] and miniImageNet [53] (Sections 4.2 and 4.3).",2,positive
The results of 5-way classification on CIFAR-FS are shown in Table 1.,0,negative
Model Backbone CIFAR-FS [6] 5-way 1-shot 5-way 5-shot MAML [10] 32-32-32-32 58.,0,negative
"Then, MATE can still consistently provide improvements to both (enhanced) baselines: 1) applying MATE to ProtoNets+ResNet12 yields +0.64% 5-shot accuracy and slightly better 1-shot accuracy (+0.14%); 2) applying MATE to R2D2+ResNet12 yields +0.44% 5-shot accuracy improvement and similar 1-shot accuracy (+0.08%).",0,negative
"1), and then benchmark MATE on two few-shot classification datasets, CIFAR-FS [6] and miniImageNet [53] (Sections 4.",2,positive
"…methods Ravi & Larochelle (2016), metric learning based methods Vinyals et al. (2016); Snell et al. (2017); Ren et al. (2018); Sung et al. (2018); Guo & Cheung (2020); Li et al. (2020) and methods which use ridge regression and support vector machine Bertinetto et al. (2018); Lee et al.
(2019).",1,neutral
"(2019); Chen et al. (2020), model optimization based methods Ravi & Larochelle (2016), metric learning based methods Vinyals et al. (2016); Snell et al. (2017); Ren et al. (2018); Sung et al. (2018); Guo & Cheung (2020); Li et al.",2,positive
"(2019); Chen et al. (2020), model optimization based methods Ravi & Larochelle (2016), metric learning based methods Vinyals et al.",1,neutral
(2020) and methods which use ridge regression and support vector machine Bertinetto et al. (2018); Lee et al.,1,neutral
"(2019); Chen et al. (2020), model optimization based methods Ravi & Larochelle (2016), metric learning based methods Vinyals et al. (2016); Snell et al. (2017); Ren et al. (2018); Sung et al. (2018); Guo & Cheung (2020); Li et al. (2020) and methods which use ridge regression and support vector machine Bertinetto et al.",2,positive
"CIFAR-FS, on the other hand, is similar to miniImageNet, where the dataset is randomly split.",2,positive
"In particular, miniImagenet meta-train set is used for meta-training, while corresponding meta-test splits of Omniglot [7], FC100 [12], and CIFAR-FS [3] are used for evaluation.",2,positive
"B Additional Experiments on Few-Shot Classification We further validate the effectiveness of our proposed dynamic inner-loop update rule ALFA, through evaluating the performance on the relatively new CIFAR100-based [6] few-shot classification datasets: FC100 (Fewshot-CIFAR100) [12] and CIFAR-FS (CIFAR100 few-shots) [3].",2,positive
Table B: Test accuracy on 5-way classification for FC100 and CIFAR-FS.,0,negative
"All models are only trained with miniImageNet meta-train set and tested on various datasets (domains) without any fine-tuning.
miniImageNet
→ Omniglot → FC100 → CIFAR-FS ALFA + Random Init 91.02± 0.29% 62.49± 0.48% 63.49± 0.45% MAML [4] 85.68± 0.35% 55.52± 0.50% 55.82± 0.50% ALFA + MAML 93.11± 0.23% 60.12± 0.49% 59.76± 0.49% MAML + L2F [2] 94.96± 0.22% 61.99± 0.49% 63.73± 0.48% ALFA + MAML + L2F 94.10± 0.24% 63.33± 0.45% 63.87± 0.48%",0,negative
"We further validate the effectiveness of our proposed dynamic inner-loop update rule ALFA, through evaluating the performance on the relatively new CIFAR100-based [6] few-shot classification datasets: FC100 (Fewshot-CIFAR100) [12] and CIFAR-FS (CIFAR100 few-shots) [3].",2,positive
"Backbone FC100 CIFAR-FS
1-shot 5-shot 1-shot 5-shot
Random Init 4-CONV 27.50± 0.45% 35.37± 0.48% 29.74± 0.46% 39.87± 0.49% ALFA + Random Init 4-CONV 38.20± 0.49% 52.98± 0.50% 60.56± 0.49% 75.43± 0.43% MAML † [4] 4-CONV 36.67± 0.48% 49.38± 0.49% 56.80± 0.49% 74.97± 0.43% ALFA + MAML 4-CONV 37.99± 0.48% 53.01± 0.49% 59.96± 0.49% 76.79± 0.42% MAML + L2F † [2] 4-CONV 38.96± 0.49% 53.23± 0.48% 60.35± 0.48% 76.76± 0.42% ALFA + MAML + L2F 4-CONV 38.50± 0.47% 53.20± 0.50% 60.36± 0.50% 76.60± 0.42% Random Init ResNet12 32.26± 0.47% 42.00± 0.49% 36.86± 0.48% 49.46± 0.50% ALFA + Random Init ResNet12 40.57± 0.49% 53.19± 0.50% 64.14± 0.48% 78.11± 0.41% MAML † ResNet12 37.92± 0.48% 52.63± 0.50% 64.33± 0.48% 76.38± 0.42% ALFA + MAML ResNet12 41.46± 0.49% 55.82± 0.50% 66.79± 0.47% 83.62± 0.37% MAML + L2F † ResNet12 41.89± 0.47% 54.68± 0.50% 67.48± 0.46% 82.79± 0.38% ALFA + MAML + L2F ResNet12 42.37± 0.50% 55.23± 0.50% 68.25± 0.47% 82.98± 0.38% Prototypical Networks∗ [17] 4-CONV 35.3± 0.6% 48.6± 0.6% 55.5± 0.7% 72.0± 0.6% Relation Networks [18] 4-CONV+ - - 55.0± 1.0 69.3± 0.8 TADAM [12] ResNet12 40.1± 0.4% 56.1± 0.4% - - MetaOpt ‡ [8] ResNet12 41.1± 0.6% 55.5± 0.6% 72.0± 0.7% 84.2± 0.5%
* Meta-network is trained using the union of meta-training set and meta-validation set.",0,negative
"Our results on three few-shot benchmark datasets – miniImageNet, CIFAR-FS, and FC100 – showed that MABAS significantly enhanced the performance of the base methods with various characteristics, and consequently achieved the state-of-the-art performance in several tasks.",2,positive
"This class split is designed to minimize the overlap of information between all three subsets, to be more challenging than CIFAR-FS for few-shot learning.",1,neutral
"Our experiments demonstrate that MABAS provides all of the three few-shot learners with significant performance gains and achieves the state-of-the-art
performance in a number of tasks on three benchmarks: miniImageNet [45], CIFAR-FS [3] and FC100 [34].",2,positive
"performance in a number of tasks on three benchmarks: miniImageNet [45], CIFAR-FS [3] and FC100 [34].",2,positive
"Our method achieves the new state-of-the-art performance on four of the six tasks (miniImageNet 5-shot, CIFAR-FS 1-shot and 5-shot, and FC100 5-shot settings) if we exclude the methods with WRN-28-10 [50], which consumes about three times more parameters than ResNet-12 [22].",2,positive
"(2) CIFAR-FS [3] splits all of the classes in CIFAR100 [20] into 64 training, 16 validation and 20 test sets, respectively.",0,negative
"We ran experiments on Omniglot [14], CIFAR-FS [2], and miniImageNet [24], which are popular benchmark datasets used for few-shot learning.",2,positive
"The dimension of the final
CNN layer is 256, 256, and 288 for Omniglot, CIFAR-FS, and miniImageNet, respectively.",2,positive
"After the meta-training of OOD-MAML with benchmark dataset (CIFAR-FS), we compared the extracted features of in-distribution samples, OOD samples, θfake, and θifake on both θfake-classifier and (θfake + θifake)-classifier.",2,positive
"Each module consists of 3× 3 convolutions and 64 filters for Omniglot and CIFAR-FS, and 32 filters for miniImageNet, which are followed by batch normalization [12], the exponential linear units (ELU) activation function [6], and max-pooling with 2× 2 stride and padding.",2,positive
"Our base model in both OOD-MAML and MAML has a convolution neural network (CNN) architecture, which has four modules for Omniglot and CIFAR-FS and five modules for miniImageNet.",2,positive
"On Omniglot and CIFAR-FS, we only report ours (Reptile) due to its low computation cost.",2,positive
"…Prototypical Networks (Snell et al., 2017), which uses the Euclidean distance to compute the similarity, Relation Network (Sung et al., 2017), which uses a relation module as the similarity function, ridge regression (Bertinetto et al., 2018), and graph neural networks (Satorras & Estrach, 2018).",1,neutral
", 2017), which uses a relation module as the similarity function, ridge regression (Bertinetto et al., 2018), and graph neural networks (Satorras & Estrach, 2018).",1,neutral
"CIFAR-FS re-purposes CIFAR-100 (Krizhevsky & Hinton, 2009), splitting its 100 classes into 64, 16, and 20 classes for meta-training, meta-validation, and meta-test, respectively.",2,positive
"We experiment with four datasets for few-shot learning: Omniglot (Lake et al., 2011), MiniImageNet (Vinyals et al., 2016b), TieredImageNet (Ren et al., 2018a), and CIFAR-FS (Bertinetto et al., 2018).",2,positive
"Extended Experiments on Classification To further validate that our method consistently provides benefits regardless of scenarios, we compare our method against the baseline on additional datasets that have been recently introduced: FC100 (Fewshot-CIFAR100) [7] and CIFAR-FS (CIFAR100 few-shots) [1].",2,positive
"Standard meta learning models utilizes gradient ascent/descent techniques to compute the updated parameters on new tasks [23, 3, 42, 56].",1,neutral
"Meta learning techniques aim to train a general model with general parameters that can quickly adapt to a variety of new learning tasks with refined parameters [23, 3, 42, 56].",1,neutral
"CIFAR-FS [2] contains 100 classes with the class split for (64,16,20).",1,neutral
"We further conduct FSOR experiments on two fewshot benchmark datasets: CIFAR-FS [2], FC100 [29].",2,positive
"One is gradient-based method that empower the model with ability to rapidly fine-tune to novel classes with limited labeled images (Finn et al., 2017; Ravi & Larochelle, 2017; Rusu et al., 2019; Bertinetto et al., 2019; Lee et al., 2019).",2,positive
"Standard meta learning models utilizes gradient ascent/descent techniques to compute the updated parameters on new tasks [23, 3, 42, 56].",1,neutral
"Meta learning techniques aim to train a general model with general parameters that can quickly adapt to a variety of new learning tasks with refined parameters [23, 3, 42, 56].",1,neutral
"Bertinetto et al. (2018) resized all the images to 32× 32 and divided this dataset into 64 classes for meta-training, 16 classes for meta-validation, and 20 classes for meta-testing.",2,positive
"We perform extensive experiments on two popular few-shot learning benchmarks, MiniImagenet (Snell et al., 2017), and CIFAR-FS (Bertinetto et al., 2018).",2,positive
And CIFAR-FS benchmark is much more chanllenging than Mini-Imagenet due to its more constrained splits between training set and test set and lower image resolution.,2,positive
"Others relate to Prototypical Networks by learning a representation on which differentiable training can be performed on some form of classifier (Bertinetto et al., 2019; Gidaris & Komodakis, 2018; Oreshkin et al., 2018).",1,neutral
"Larger-scale few-shot classification benchmarks were also proposed using CIFAR-100 (Krizhevsky et al., 2009; Bertinetto et al., 2019; Oreshkin et al., 2018), tiered-ImageNet (Ren et al.",2,positive
"Larger-scale few-shot classification benchmarks were also proposed using CIFAR-100 (Krizhevsky et al., 2009; Bertinetto et al., 2019; Oreshkin et al., 2018), tiered-ImageNet (Ren et al., 2018), and ImageNet-21k (Dhillon et al., 2019).",2,positive
"It can be seen that our AdarGCN FSL method yields 2–5% improvements over the latest GCN-based FSL methods [9, 6, 5] and 2–7% improvements over the state-of-theart FSL baselines [8, 2, 1, 3, 7], validating the effectiveness of our AdarGCN module under one-shot setting.",2,positive
"Then, we amend this MAML implementation to reproduce the results on the new CIFAR-FS dataset proposed by their paper (Bertinetto et al. [2019]). When reproducing the R2D2 algorithm, our first consideration is that the feature extractors in MAML and R2D2 are very different. MAML uses four convolutional blocks with an organization of [32, 32, 32, 32] filters. Whereas, R2D2’s four blocks employ a [96, 192, 384, 512] scheme, as shown in Figure 3. In other words, the feature extractor in R2D2 is more complex hence is expected to yield better results (Mhaskar et al. [2016]).",2,positive
"In this work we reproduce the paper of Bertinetto et al. [2019] (referenced as ""their paper""); it falls into the class of gradient-based meta-learning algorithms that learn a model parameter intialization for rapid fine-tuning with a few shots (Finn et al.",2,positive
com/ArnoutDevos/maml-CIFAR-FS (4)Bertinetto et al. [2019] code: https://github.,2,positive
"In this work we reproduce the paper of Bertinetto et al. [2019] (referenced as ""their paper""); it falls into the class of gradient-based meta-learning algorithms that learn a model parameter intialization for rapid fine-tuning with a few shots (Finn et al. [2017], Nichol and Schulman [2018]).",2,positive
"Then, we amend this MAML implementation to reproduce the results on the new CIFAR-FS dataset proposed by their paper (Bertinetto et al. [2019]).",2,positive
"3 Analysis of the R2D2 Classifier In their paper, Bertinetto et al. [2019] present a new approach that relies on using fast and simple base learners such as ridge regression differentiable discriminator (R2D2) or (regularized) logistic regression differentiable discriminator (LRD2).",1,neutral
"Then, we amend this MAML implementation to reproduce the results on the new CIFAR-FS dataset proposed by their paper (Bertinetto et al. [2019]). When reproducing the R2D2 algorithm, our first consideration is that the feature extractors in MAML and R2D2 are very different. MAML uses four convolutional blocks with an organization of [32, 32, 32, 32] filters. Whereas, R2D2’s four blocks employ a [96, 192, 384, 512] scheme, as shown in Figure 3. In other words, the feature extractor in R2D2 is more complex hence is expected to yield better results (Mhaskar et al. [2016]). In order to provide a meaningful comparison, we implement and evaluate both the simple and more complex feature extractors for the R2D2 algorithm, denoted by R2D2* and R2D2 respectively. In order to make a working reproduction of their paper we had to make the following assumptions. We first considered the aforementioned complex architecture and feature extractor. In particular, for the feature extractor, we made assumptions on the convolutional block options. We considered a 3x3 convolution block with a ’same’ padding and a stride of 1. For the 2x2 maximum pooling, we use a stride of 2 and no padding. Second, concerning the ridge regression base-learner, we opted for a multinomial regression that returns the class with the maximum value through one-hot encoding. Following the guidelines for the feature extractor presented in Section 4.2 of their paper, we were not successful in reproducing the exact number of features at the output of the feature extractor. In their paper, the overall numbers of features at the output of the extractor are 3584, 72576 and 8064 for Omniglot, miniImageNet and CIFAR-FS, respectively. However, by implementing the feature extractor described in their paper, we obtain 3988, 51200 and 8192 respectively. For comparison purposes, we use the same number of classes (e.g. 5) and shots during (e.g. 1) training and testing, despite their paper using a higher number of classes during training (16 for miniImageNet, 20 for CIFAR-FS) than during testing (5 for miniImageNet and CIFAR-FS). Regarding the amount of shots, their paper uses a random number of shots during training. This is different from the way most baselines are trained using the same number of shots per class during training and testing (Finn [2018], Nichol and Schulman [2018], Vinyals et al.",2,positive
"In this paper, we present a reproduction of the paper of Bertinetto et al. [2019] ""Meta-learning with differentiable closed-form solvers"" as part of the ICLR 2019 Reproducibility Challenge.",2,positive
"(2019); Bertinetto et al. (2018) on CIFAR-FS, FC100, miniImageNet few-shot learning tasks with the standard training protocol, and the training protocol with ensemble method Huang et al.",2,positive
∗CIFAR-FS results from Bertinetto et al. (2018). †Result from Lee et al. (2019). The best results are highlighted.,0,negative
"To identify whether the rotation multi 90 degrees for Task Aug is better than that for Data Aug, we analyzed the experiment on CIFAR-FS and miniImageNet.",2,positive
"Besides, Table 2 and Table 3 summarize the results on the CIFAR-FS and FC100 5-way tasks, and in most cases our method rises accuracy by 0.5%-3%.",0,negative
"We used ProtoNets Snell et al. (2017), MetaOptNet-SVM Lee et al. (2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug.",2,positive
"The proposed method is evaluated by experiments with the state of art meta-learning Methods Snell et al. (2017); Lee
et al. (2019); Bertinetto et al. (2018) on CIFAR-FS, FC100, miniImageNet few-shot learning tasks with the standard training protocol, and the training protocol with ensemble method Huang et al. (2017).",2,positive
"We proved that Task Aug was valid for CIFAR-FS, FC100, and miniImageNet, and exceeded the result of the previous works.",2,positive
"(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al.",2,positive
"(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al. (2019), For M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.1; and a learnable scale was used following Lee et al. (2019). We did not use label smoothing like Lee et al. (2019), because we did not find that label smoothing can improve the performance in our environment.",2,positive
"Therefore, in the experiment, the methods applied in the “inner loop” are able to classify data, and they are K-nearest neighbor (KNN), Support Vector Machine (SVM) and ridge regression, respectively Snell et al. (2017); Lee et al. (2019); Bertinetto et al. (2018).",1,neutral
"For R2-D2, we set the same training shot as for M-SVM, and used a learnable scale and bias following Bertinetto et al. (2018).",2,positive
"(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al. (2019), For M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.",2,positive
"(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al. (2019), For M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.1; and a learnable scale was used following Lee et al. (2019). We did not use label smoothing like Lee et al.",2,positive
The CIFAR-FS Bertinetto et al. (2018) containing all 100 classes from CIFAR-100 Krizhevsky et al. (2010) is proposed as few-shot classification benchmark recently.,2,positive
"(2019); Bertinetto et al. (2018) on CIFAR-FS, FC100, miniImageNet few-shot learning tasks with the standard training protocol, and the training protocol with ensemble method Huang et al. (2017). The experimental result analysis shows that Task Aug can reduce over-fitting and improve the performance, while the conventional data augmentation (referred to Data Aug) of rotation, which converts the novel data into the classes of original data, does not improve the performance and even causes the worse result.",2,positive
"Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al. (2019),
For M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.1; and a learnable scale was used following Lee et al. (2019).",2,positive
"(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al.",2,positive
We set pmax to 0.5 for CIFAR-FS and FC100; 0.25 for miniImageNet; and T was set to 80000 for all experiments.,2,positive
It was different from Bertinetto et al. (2018) we used a fixed regularization parameter of ridge regression which was set to 50 because Bertinetto et al. (2018) has confirmed that making it learnable might not be helpful.,2,positive
"Same as CIFAR-FS, there are 600 nature color images of size 32× 32 in each class.",1,neutral
"The proposed method is evaluated by experiments with the state of art meta-learning Methods Snell et al. (2017); Lee
et al. (2019); Bertinetto et al. (2018) on CIFAR-FS, FC100, miniImageNet few-shot learning tasks with the standard training protocol, and the training protocol with ensemble method…",2,positive
"Previous studies have introduced many popular regularization techniques to few-shot learning from deep learning, such as weight decay, dropout, label smooth Bertinetto et al. (2018), and data augmentation.",1,neutral
∗CIFAR-FS results from Bertinetto et al. (2018). †Result from Lee et al.,0,negative
(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug.,1,neutral
"[1], R2D2 (with its more complex network architecture) performs better than the MAML method for most simulations.",1,neutral
[1] present a new approach that relies on using fast and simple base learners such as ridge regression differentiable discriminator (R2D2) or (regularized) logistic regression differentiable discriminator (LRD2).,1,neutral
[1] MAML ours R2D2* ours R2D2 ours R2D2 paper Bertinetto et al.,1,neutral
[1] ”Metalearning with differentiable closed-form solvers” as part of the ICLR 2019 Reproducibility Challenge.,2,positive
"[1] (referenced as ”their paper”); it falls into the class of gradient-based meta-learning algorithms that learn a model parameter initialization for rapidfine-tuningwith a few shots (Finn, Abbeel, andLevine [5], Nichol and Schulman [6]).",1,neutral
"A recent line of work learns the base-level in closed-form using simpler models such as SVMs [10, 11] which restricts the capacity of the base-level although it alleviates the optimization problem.",1,neutral
"The first is the CIFAR-FS dataset [10] which splits classes randomly into 64 training, 16 validation and 20 test with 600 images in each.",2,positive
"Other uses of such differentiable optimization have been found in meta-learning to differentiate through the learning algorithm in the middle [32, 33], or to train the generator in a generative adversarial model by optimizing out the discriminator [43], or for end-to-end planning and control [45].",1,neutral
"For example, [27–29] used simple metric-based nearest neighbor, [30, 31] optimized standard learning algorithms iteratively, and [32, 33] leveraged closed-form solutions for base learners.",1,neutral
We use CIFAR-FS [46] and Omniglot [47] datasets for our few-shot learning tasks; see Appendix A for details.,2,positive
"In the CIFAR-FS experiments, the prototypical methods outperform our method only in the 1-shot scenario.",2,positive
