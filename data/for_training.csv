context,label_score,label
"Recently, several losses [18], [24], [25] constructed different graph structures to formulate the",0.0,Neutral
"The subsequent designs consider multiple negatives including N-pair [9], Lifted Structure [37] and Multi-Similarity [36], but are slow convergence [18], [19].",0.0,Neutral
"the mainstream methods [1], [5], [6], [18], [68], we also adopt the conventional setting, where no intersection exists in train and test set split.",0.0,Neutral
"Accordingly, several works [24], [25] based on graph structure construct various losses to capture the relations in the pairs [18].",0.0,Neutral
"The proposed method can be seamlessly implanted into different kinds of deep metric learning models, which are represented here by three works including SCT [5], HDML [6], and HIST [18].",0.5,Weak
The drawbacks of these two types of loss functions were limited to the number of classes [2] and not good at leveraging relations among data points [18].,0.0,Neutral
Please refer to [18] for detailed explanations.,0.0,Neutral
"As aforementioned, triplet loss is a seminar example and classical design in this field [18], which has spawned a lot of elegant works.",0.0,Neutral
"convergence of these loss functions is not good [18], [19].",0.0,Neutral
"3) Graph-Based Loss: Beyond graph modeling, HIST [18] employed hyper-graph to model the multilateral semantic relation between every instance and every class with a hyper-graph induced semantic tuplet loss, defined as:",0.0,Neutral
"For one thing, the pairbased methods [64], [65], [66], [67] can mine rich semantic information from anchor-to-sample relations, but converge slowly due to its high training complexity.",0.0,Neutral
"If two embedding nodes are close, their semantic information usually overlaps, they probably have a semantic connection [25].",0.0,Neutral
HIST [25] constructs a hyper-graph to formulate higher-order relations between samples.,0.0,Neutral
HIST [25] constructs a hypergraph to formulate higher-order relations between samples.,0.0,Neutral
"To further demonstrate the effectiveness of BiasAdv, we evaluated the model robustness to various input corruptions following the protocol [29].",0.5,Weak
"field [48]–[50], a multiview-enhanced knowledge integration module based on HGCN is developed, as shown in Fig.",0.0,Neutral
"Modern image retrieval methods (Lim et al., 2022; Roth et al., 2022; Kim et al., 2022; Ermolov et al., 2022; Patel et al., 2022) can be roughly decomposed into two major components: (1) the encoder (e.",0.0,Neutral
"Modern image retrieval methods (Lim et al., 2022; Roth et al., 2022; Kim et al., 2022; Ermolov et al., 2022; Patel et al., 2022) can be roughly decomposed into two major components: (1) the encoder (e.g., Convolutional Neural Networks (Szegedy et al., 2015; He et al., 2016) or Vision Transformer…",0.0,Neutral
"focusing on the feature fusion [39], [49] within a single domain, we leverage feature-point-based hypergraph to model",0.5,Weak
", multi-modal learning [24], [39], trajectory prediction [81], and deep metric learning [49].",0.0,Neutral
"To improve embedding quality, detaching class-discriminative and classshared features [14, 31, 42], intra-batch feature aggregation [30, 49], ranking surrogates [39], and further regularization terms [19, 23, 45, 66] are utilized.",0.5,Weak
"In Crabbé & van der Schaar (2022), the feature importance for unlabelled data is proposed, using XAI methods at the initial phase of data prepossessing to distinguish features that may play a key role in further ML tasks.",0.0,Neutral
[48] Jonathan Crabbé and Mihaela van der Schaar.,0.0,Neutral
"(2)We also restrict to supervised models, since only early works exist to interpret unsupervised models [48, 49].",0.0,Neutral
"a-b, Multiple methods (the proposed likelihood ratio ranking, integrated gradients [26; 27], and Hotspot [28]) were applied to rank the genes in our simulated dataset by how strongly they were captured by multiGroupVI’s group-specific latent spaces.",0.0,Neutral
"We compared the performance of our likelihood ratio ranking with two other methods designed for interpreting the latent spaces of unsupervised machine learning models: Hotspot [28], a method that ranks genes by spatial autocorrelation when provided a given metric of cell-cell similarity (e.g. the latent space of an autoencoder), and an adaptation of integrated gradients [26] for unsupervised models proposed in Crabbé and van der Schaar [27] applied to multiGroupVI’s group-specific latent spaces.",0.5,Weak
"the latent space of an autoencoder), and an adaptation of integrated gradients [26] for unsupervised models proposed in Crabbé and van der Schaar [27] applied to multiGroupVI’s group-specific latent spaces.",0.5,Weak
[65] Jonathan Crabbé and Mihaela van der Schaar.,0.0,Neutral
"We quantitatively compare these various feature importance scores by computing their Pearson correlation r as in [64, 65].",0.5,Weak
"We do not compare with methods that are not post-hoc, that require exposure to outliers, or are not actionable (most existing XAI methods) to match model monitoring settings.",0.0,Neutral
"To determine trust in model predictions, current works typically use (a) explainability methods (XAI) [11]–[13]; which, though explainable, post-hoc and suitable for providing qualitative insights, require humans to oversee the explanations and are not directly actionable for continuous and automated model monitoring; or (b) uncertainty estimation techniques",0.0,Neutral
"To determine trust in model predictions, current works typically use (a) explainability methods (XAI) [11]–[13]; which, though explainable, post-hoc and suitable for providing qualitative insights, require humans to oversee the explanations and are not directly actionable for continuous and automated model monitoring; or (b) uncertainty estimation techniques [6], [14]–[18]; that are difficult to train or are computationally expensive.",0.0,Neutral
"XAI methods provide complementary, post-hoc explanations to the predictions of black-box models to induce trust.",0.0,Neutral
"To determine trust in model predictions, current works typically use (a) explainability methods (XAI) [11]–[13]; which, though explainable, post-hoc and suitable for providing qualitative insights, require humans to oversee the explanations and are not directly actionable for continuous and automated model monitoring; or (b) uncertainty estimation techniques",0.0,Neutral
"To determine trust in model predictions, current works typically use (a) explainability methods (XAI) [11]–[13]; which, though explainable, post-hoc and suitable for providing qualitative insights, require humans to oversee the explanations and are not directly actionable for continuous and automated model monitoring; or (b) uncertainty estimation techniques [6], [14]–[18]; that are difficult to train or are computationally expensive.",0.0,Neutral
"We don’t compare with methods that are not post-hoc, that require exposure to outliers, or are not actionable (most existing XAI methods) to match model monitoring settings.",0.0,Neutral
"XAI methods provide complementary, post-hoc explanations to the predictions of black-box models to induce trust.",0.0,Neutral
"Dialogue summarization, a recently popular subfield of text summarization, has more challenging factual issues involved (Wang et al., 2022; Gao and Wan, 2022).",0.0,Neutral
"The outputs of each system on the SAMSum test set are obtained from DialSummEval (Gao and Wan, 2022).",0.5,Weak
DialSummEval: Revisiting summarization evaluation for dialogues.,0.0,Neutral
"The DialSummEval (Gao and Wan, 2022) benchmark is a summarization evaluation benchmark created following the format of SummEval (Fabbri et al., 2021) for the domain of dialogue summarization.",0.0,Neutral
"The DialSummEval (Gao and Wan, 2022) benchmark is a summarization evaluation benchmark created following the format of SummEval (Fabbri et al.",0.0,Neutral
", 2022) and DialSummEval (Gao and Wan, 2022) and uncover limitations that guide the design principles of the SUMMEDITS benchmark we build.",0.5,Weak
"Prior work (Kryściński et al., 2020; Fabbri et al., 2021; Gao and Wan, 2022) has annotated corpora Human Perform.",0.0,Neutral
"In this section we analyze two popular benchmarks for factual consistency detection in summarization: AggreFact (Tang et al., 2022) and DialSummEval (Gao and Wan, 2022) and uncover limitations that guide the design principles of the SUMMEDITS benchmark we build.",0.5,Weak
"In DialSummEval, each (dialogue, summary) tuple is evaluated by three annotators, each assigning a Likert score (1-5) assessing the consistency of the summary.",0.0,Neutral
"Although most annotation effort has focused on the summarization of news, some prior work also looked at dialogue summarization (Gao and Wan, 2022), or the medical domain (Tang et al.",0.0,Neutral
"Following previous research (Gao and Wan, 2022; Kryscinski et al., 2019), we demand human annotators evaluate samples on the summary level from the following three aspect: Relevance measures how well the question summary captures the main concerns of the patient’s questions.",0.5,Weak
"∗ Equal contribution for manual evaluation (Bhandari et al., 2020; Fabbri et al., 2022a; Gao and Wan, 2022).",0.0,Neutral
"Thus, recent efforts have focused on aggregating model outputs and annotating quality dimensions to better assess summarization model and metric progress (Huang et al., 2020; Bhandari et al., 2020; Stiennon et al., 2020; Zhang and Bansal, 2021; Fabbri et al., 2022a; Gao and Wan, 2022).",0.0,Neutral
", 2021b) and DialSummEval (Gao and Wan, 2022) collections of system summaries, respectively, rather than generating summaries from scratch.",0.0,Neutral
"With each dataset we collect system summaries for a set of 100 randomly selected samples from the test set, following recent work on measuring correlations between metrics (Bhandari et al., 2020; Fabbri et al., 2021b; Gao and Wan, 2022).",0.5,Weak
"12https://github.com/PKULCWM/PKUSUMSUM is used for Lead, LexPageRank, and ClusterCMRW
13https://github.com/RaRe-Technologies/ gensim
14https://pypi.org/project/ bert-extractive-summarizer/
15https://github.com/Yale-LILY/SummEval 16https://github.com/kite99520/
DialSummEval
Models: LEAD-3, LONGEST-3, Pointergenerator (See et al., 2017), Transformer (Vaswani et al., 2017), BART (Lewis et al., 2019), Pegasus (Zhang et al., 2020), UniLM (Dong et al., 2019), CODS (Wu et al., 2021), ConvoSumm (Fabbri et al., 2021a), MV-BART (Chen and Yang, 2020), PLM-BART (Feng et al., 2021), Ctrl-DiaSumm (Chen et al., 2021), S-BART (Chen and Yang, 2021).",0.0,Neutral
"Evaluation metrics have also been reevaluated in the context of scientific articles (Cohan and Goharian, 2016), and more recently, dialogues (Gao and Wan, 2022), both using single documents as input.",0.0,Neutral
"For comparable results, for the CNN/DM (Hermann et al., 2015) and SAMSum (Gliwa et al., 2019) datasets, we use the model outputs from the SummEval (Fabbri et al., 2021b) and DialSummEval (Gao and Wan, 2022) collections of system summaries, respectively, rather than generating summaries from scratch.",0.5,Weak
"According to stakeholders considered in the algorithm, there are user-side fairness [15], item-side fairness [14, 20], and two-sided fairness [35, 36].",0.0,Neutral
"Compared to some fairness-aware studies [19, 35, 36], although they can also achieve systemic group exposure regulation, they do not take userlevel calibration into consideration.",0.0,Neutral
"Recommender systems are known to suffer from exposure bias; few items are over-exposed in the recommendation lists, while the majority of other items are under-exposed [1, 7, 12, 23].",0.0,Neutral
"• What metrics and summary statistics usefully capture the distributional efects of a system within a stakeholder class or across stakeholder classes? There are several promising directions here, including the Expected Exposure construct [28] and its multi-sided extension [81] along with positive-sum aggregation of utility across user subgroups [80].",0.0,Neutral
"0K gender, age, occupation category timestamps ✓ ✓ ✓ [39, 41, 63, 86, 122, 126, 149] MovieLens 10M[48] movie 69.",0.0,Neutral
"[40] 2022 Group Single Round Demographic Parity NDCG KL-divergence [94] 2022 Group Single Round Demographic Parity Recommended Times Ratio Diference [68] 2022 Individual Single Round Fairness through awareness Rank-Weighted Exposure Mean Absolute Diference [41] 2022 Group Single Round Demographic Parity Recommended Times KL-divergence [126] 2022 Individual and Group Single Round Demographic Parity NDCG (Customer), Outcome of item(Provider) Discrepancy between two Groups",0.0,Neutral
"0M gender, age, occupation category timestamps ✓ ✓ ✓ [9, 16, 34, 98, 103, 138] [11, 32, 57, 70, 148, 150] [29, 39, 53, 71, 96, 127] [66, 106, 122, 126] MovieLens 20M[48] movie 138.",0.0,Neutral
"Examples include fairness metrics [15, 39, 44], learning-to-rank applications [34, 40, 45, 46], outlier-aware fair ranking [23, 36], online fair ranking [22], and multi-stakeholder fair recommendation [42].",0.0,Neutral
"Few recent works propose a framework to learn the relevance scores considering the joint multi-objective optimization [21, 51].",0.0,Neutral
"[10, 38, 57] draw single permutations from a deterministic ranker by perturbing its scores using the Concrete distribution [36].",0.0,Neutral
"Other works handle multisided fairness criteria [52, 57] and learning fair stochastic policies via the policy-gradient approach [49, 59].",0.0,Neutral
"Since fairness in recommender systems relates to the benefits from multiple stakeholders [144, 154, 155, 156, 157], the request of fairness may come from different sides.",0.0,Neutral
"In recent years, fairness has been widely used in many aspects.[3, 8, 11] use different fairness measurement methods to solve the fairness problem of resource allocation in different fields, and have achieved certain results.",0.0,Neutral
"In recent years, the question of fairness of exposure attracted a lot of attention, and has been mostly studied in a static ranking setting (Geyik et al., 2019; Beutel et al., 2019; Yang & Stoyanovich, 2017; Singh & Joachims, 2018; Patro et al., 2022; Zehlike et al., 2021; Kletti et al., 2022; Diaz et al., 2020; Do & Usunier, 2022; Wu et al., 2022).",0.0,Neutral
"…attracted a lot of attention, and has been mostly studied in a static ranking setting (Geyik et al., 2019; Beutel et al., 2019; Yang & Stoyanovich, 2017; Singh & Joachims, 2018; Patro et al., 2022; Zehlike et al., 2021; Kletti et al., 2022; Diaz et al., 2020; Do & Usunier, 2022; Wu et al., 2022).",0.0,Neutral
"4 Fairness in Recommendation With the increasing attention on the fairness in recommendation [9, 16, 20, 22, 40], there have been numerous attempts to define notions of fairness [19, 30, 33, 35, 47].",0.0,Neutral
"For example, if the system presents its recommendation as a static list of people ranked by their expertise on a topic, small differences in estimated expertise may translate into disparately different levels of exposure, as presentation bias causes people to over-prioritize those at the top of the list [7, 30, 34].",0.0,Neutral
"This means, for instance, including the interuser equity objective into the loss function [26, 55, 56], sometimes through a regularization term [29, 58].",0.0,Neutral
"Reinforcement learning has also been applied to multi-sided fairness, through contextual multi-armed bandits which simultaneously optimize stakeholder utility and fairness objectives (Mehrotra et al., 2020, 2018; Wu et al., 2022).",0.0,Neutral
Granularity* Populational [30] [83] [129] [87] [261] [141] [96] [215] [177] [219] [162] [11] Personalized [131] [223],0.0,Neutral
Side* Single-side [124] [83] [258] [96] [129] [131] [125] [108] [220] [217] [215] [177] Multi-side [37] [2] [168] [169] [222] [218] [25] [159] [219] [162] [143] [197],0.0,Neutral
"The issue of fairness in recommendation has received growing concerns as recommender systems touch and influence people’s daily lives more deeply and profoundly [28, 41, 62].",0.0,Neutral
Granularity Populational [24] [68] [104] [71] [200] [111] [78] [172] [141] [176] [127] [9] Personalized [105] [179],0.0,Neutral
Side Single-side [102] [68] [200] [78] [104] [105] [103] [87] [177] [174] [172] [141] Multi-side [31] [1] [132] [133] [178] [175] [19] [124] [176] [127],0.0,Neutral
704) whereby Black candidates are systematically matched to Black-owned businesses and white candidates are systematically matched to white-owned businesses [214].,0.0,Neutral
"In the government or social services domain, screening tools to identify children at-risk for maltreatment can amplify already-existing biases against poor parents [74, 214].",0.0,Neutral
Crosswalk [Khajehnejad et al. 2021] ✓ ✗ ✗ ✗ ✗ ✗ ✗ ✓ ✗ ✓ ✗ ✓ ✗ ✓,0.0,Neutral
"Along this research path – learning node representations for fair IM – the works that are closest to ours are [16, 17].",0.0,Neutral
The follow-upwork [16] revisits generic algorithms for learning node representations (e.,0.0,Neutral
"The same scalability limits are exhibited by the two state-of-the-art methods on fair IM that do rely on node representation [16, 17], yet learned only from the social connectivity.",0.0,Neutral
"Compared to [16, 17], we revisit IM with fairness under a more flexible formulation, by algorithmic solutions that are applicable to arbitrary sets of sensitive attributes and to large, realistic datasets.",0.0,Neutral
"Crosswalk [16] is a randomwalk based graph representation method, which enhances fairness by re-weighting the edges between nodes from different groups.",0.0,Neutral
"The limitations of [16, 17] are threefold: (i) as they exploit the social connectivity, they incur a high computation cost and cannot reasonably scale; in particular, training the adversarial neural network in [17] grows exponentially with the number of users in the social network, (ii) they assume that the probability of diffusion between a pair of nodes is constant and follows the Markovian assumption, and (iii) they are not generic, i.",0.0,Neutral
[29] serves as a seminal work for fairness-aware random walk-based studies [30].,0.0,Neutral
"[21] propose CrossWalk, a method that enhances fairness in graph algorithms by biasing random walks to cross group boundaries.",0.0,Neutral
"[15] developed Crosswalk, the key idea is to bias random walks to cross group boundaries, which enhances fairness.",0.0,Neutral
"To address the fairness issues, most existing works learn a fair node or graph representation by optimizing adjacency matrices [18], [31], adversarial training [8], or fairness-oriented DeepWalk [15], [24].",0.0,Neutral
"First, some works adapt existing unsupervised graph embedding approaches for fairness (Rahman et al., 2019; Khajehnejad et al., 2021), but it is challenging to accommodate all such models.",0.0,Neutral
"Both of these are widely used by the research community to assess the fairness of machine learning models in graph data [1], [8], [11], [13], [16], [24], [44].",0.0,Neutral
"The remaining parameters are the same as stated in their papers [19], [24], [33].",0.5,Weak
"CrossWalk [24]: This method enhances the fairness of various graph algorithms applied to node embeddings, including influence maximization, link prediction, and node classification.",0.0,Neutral
"The first group of research works focuses on the design of an embedding mechanism that would be fair for the sensitive attribute [8], [24], [33].",0.0,Neutral
"Recent studies on the fairness of GNNs and Node2Vec have also reported similar issues [8], [24], [33].",0.0,Neutral
"On query-/user-induced recommendation networks such as those on Amazon and YouTube, structural bias hinders the discovery of diversified content, reducing serendipity (Ge et al. 2010; Kotkov et al. 2016; Anagnostopoulos et al. 2020).",0.0,Neutral
"On query/user-induced recommendation networks such as those on Amazon and YouTube, structural bias hinders the discovery of diversified content, reducing serendipity (Ge et al. 2010; Kotkov et al. 2016; Anagnostopoulos et al. 2020).",0.0,Neutral
"Recommender systems may also reduce serendipity (Ge et al. 2010; Kotkov et al. 2016; Anagnostopoulos et al. 2020), i.e., the possibility of “stomping” on content/users expressing different opinions.",0.0,Neutral
"Recommender systems may also reduce serendipity (Ge et al. 2010; Kotkov et al. 2016; Anagnostopoulos et al. 2020), i.",0.0,Neutral
[88] also proposed a reweighting method that can be applied to any random walk,0.0,Neutral
"CR – [167] [167] – – [167] – IM [58] [7, 10, 20, 56, 88, 89, 125, 153, 154, 162, 165] [7, 10, 20, 56, 58, 88, 89, 125, 153, 154, 162, 165] – – [7, 10, 20, 56, 58, 88, 89, 125, 153, 154, 162, 165] –",0.0,Neutral
"IBM – – – – – – – CD – [88] [88, 108] – – [88] [108]",0.0,Neutral
"Research Topic Individual fairness Group Fairness Feature-Aware FeatureBlind PreProcessing In-Processing PostProcessing LP [96, 124] [88, 96, 104, 124, 132, 134] [88, 96, 104, 124, 132, 134] – [96] [88, 104, 124, 134] [104, 132]",0.0,Neutral
"Several works, including [56, 88, 104, 108, 124], have highlighted unfairness in different SNA algorithms, i.",0.0,Neutral
[88] used disparity to compare the fairness of node classification methods.,0.0,Neutral
"CrossWalk aims to address the shortcomings of Fairwalk by assigning more weights to both edges that connect nodes Manuscript submitted to ACM
A Survey on Fairness for Machine Learning on Graphs 13
on the boundary of the protected groups, and edges connecting nodes from different groups.",0.0,Neutral
"In the same spirit, CrossWalk [34] is based on a re-weighting procedure for building the random walks and can therefore be used with any random walk based algorithms including DeepWalk [59] and Node2vec [26], to name a few.",0.0,Neutral
"Method Reference Code Pre-processing In training Post-processing Keywords FairOT [41] Github ✓ Optimal Transport, Laplacian regularization FairDrop [65] Github ✓ Edge Drop, Homophily UGE [70] NA ✓ Structural generative graph model FairWalk [60] Github∗ ✓ Random walk CrossWalk [34] Github ✓ Random walk DeBayes [11] Github ✓ Conditional Network Embeddings, Bayeisan prior FIPR [12] Github ✓ I-Projection regularizer CFC [10] Github ✓ Adversarial Learning, Compositional filtering FLIP [50] Github ✓ Adversarial Learning, Modularity DKGE [21] NA ✓ Adversarial, Knowledge graphs FairGNN [17] Github ✓ GNNs, Adversarial Learning FairAdj [45] Github ✓ Graph Neural Networks MONET [58] Github ✓ GNNs, metadata NIFTY [3] Github ✓ GNNs, augmented views, stability InFoRM [31] Github ✓ ✓ ✓",0.5,Weak
"C1 Facebook∗ [63] group, individual 1,034 26,749 224 gender (2) [5], [24], [37], [39], [44], [73], [78], [80] [83], [87], [101], [128], [146], [171] Pokec∗ [142] group 1,632,803 30,622,564 59 region (2), gender (2) [38], [40], [50], [67], [82], [110] Twitter∗ [107] group 81,306 1,768,149 1,364 political opinion (2) [77], [83], [149] Lastfm [27] group, provider 49,900 518,647 gender (2), age (3) [117], [159], [164] Oklahoma97 [126] group 3,111 73,230 8 gender (2) [91] UNC28 [126] group 4,018 65,287 8 gender (2) [91] Google+ [107] popularity 4,938 547,923 5 [101] Epinion [144] popularity 8,806 157,887 [1], [174] Filmtrust [58] provider 3,579 35,494 [99] Ciao [144] popularity 7,317 85,205 [174]",0.0,Neutral
3) Rebalancing in Applications: Recommender Systems: Upsampling is a common rebalancing approach in recommender systems.,0.0,Neutral
Information Flow-Based Rebalancing: Information flowbased rebalancing techniques are commonly adopted to achieve fair influence maximization.,0.0,Neutral
"[77] proposed CrossWalk, which extends the rebalancing range to the whole walk by assigning larger transition probabilities to nodes that are closer to the sensitive groups’ topological peripheries.",0.0,Neutral
Node Sampling/Generation-Based Rebalancing: Rebalancing can also be achieved via node sampling or node generation.,0.0,Neutral
Other Applications: Rebalancing has been adopted to fulfill fairness in real-world applications other than recommender systems.,0.0,Neutral
1) Improving Group Fairness: Edge/Path-Based Rebalancing: A number of works adopt the rebalancing strategy to promote group fairness based on the edges or paths in the input network data.,0.0,Neutral
Rebalancing can also be leveraged to improve user fairness.,0.0,Neutral
"Rebalancing aims to reduce the distribution difference of certain properties (e.g., the appearance rate of a node in random walks and frequency of recommendations of an item) between advantaged and disadvantaged nodes.",0.0,Neutral
"Group Optimization with Regularization [71] Recommendation Optimization with Regularization [67] Node classification Optimization with Regularization [173] Node classification Optimization with Regularization [3] Node classification Optimization with Regularization [24] Link prediction Optimization with Regularization [167] Recommendation Optimization with Regularization [88] Node classification Optimization with Regularization [44] Node classification Optimization with Regularization [110] Node classification Optimization with Regularization [50] Node classification Optimization with Regularization [175] Recommendation Optimization with Regularization [52] Recommendation Optimization with Regularization [156] Link prediction Optimization with Regularization [83] Recommendation Optimization with Regularization [87] Link prediction Optimization with Regularization [21] Recommendation Optimization with Constraint(s) [80] Graph clustering Optimization with Constraint(s) [171] Node classification Optimization with Constraint(s) [45] Influence maximization Optimization with Constraint(s) [123] Influence maximization Optimization with Constraint(s) [124] Influence maximization Optimization with Constraint(s) [5] Influence maximization Rebalancing [128] Link prediction Rebalancing [25] Link prediction Rebalancing [171] Node classification Rebalancing [46] Recommendation Rebalancing [122] Recommendation Rebalancing [149] Node ranking Rebalancing [77] Influence maximization, link prediction, and node classification Rebalancing [146] Influence maximization Rebalancing [138] Influence maximization Rebalancing [148] Influence maximization Rebalancing [82] Node classification Rebalancing [37] Link prediction Adversarial [18] Recommendation Adversarial [38] Node classification Adversarial [78] Influence Maximization Adversarial [164] Recommendation Adversarial [159] Recommendation Adversarial [78] Influence maximization Edge rewiring [91] Node classification Edge rewiring [82] Node classification Edge rewiring [65] Topology debiasing Edge rewiring [40] Node classification Edge rewiring [82] Node classification Edge rewiring [136] Node classification Orthogonal projection [114] Node classification and recommendation Orthogonal projection [113] Node classification and recommendation Orthogonal projection [171] Node classification",0.0,Neutral
"[100] propose a re-weighting approach for generating the random walks, however, they assign more weights to the links that connect nodes from different groups to provide a higher chance of discovery in extreme cases that Rahman et al.",0.0,Neutral
"Repairing Graph [106, 151] Learn Unbiased Embeddings [29, 100, 140]",0.0,Neutral
"…typical accuracy, AUROC, F1-score, average precision as well as true and negative false rate have been widely used to assess predictive performance [Khajehnejad et al., 2021; Spinelli et al., 2021; Zeng et al., 2021; Ma et al., 2022; Tang et al., 2020b; Palowitch and Perozzi, 2020] while stability…",0.0,Neutral
"In terms of evaluation, in addition to the proposed graph fairness notions discussed in Section 4, the typical accuracy, AUROC, F1-score, average precision as well as true and negative false rate have been widely used to assess predictive performance [Khajehnejad et al., 2021; Spinelli et al., 2021; Zeng et al., 2021; Ma et al., 2022; Tang et al., 2020b; Palowitch and Perozzi, 2020] while stability [Agarwal et al.",0.0,Neutral
"Various methods have been proposed in this direction, including adversarial learning based approaches [2, 3, 6, 12, 21, 33], bayesian based approach [4], statistical based approaches [5, 16, 19, 23, 27, 35] and others [20, 22].",0.0,Neutral
"However, only a few studies [19] investigate the unfairness caused by the graph structure without knowing a sensitive feature.",0.0,Neutral
"Crosswalk [33] is also a random walk-based embedding method, but, unlike Fairwalk, extends the range of the weighting including multi-hop neighbors.",0.0,Neutral
"Most of the bias related work focuses on link prediction [32,23,24,49], node classification [33] and recommendation [36,8,45,10] tasks.",0.0,Neutral
"NC REC LP EA Direct Group [33] [36,8,45,10] [32,23,24,36,8,45,33,10,49] [21,31]",0.0,Neutral
"Other than the individual and group level parity based graph fairness [Spinelli et al., 2021; Khajehnejad et al., 2021; Buyl and Bie, 2021], graph causal reasoning fairness has been investigated, particularly graph counterfactual fairness.",0.0,Neutral
"balancing methods, however, improve the overall performance but are usually at the risk of overfitting to the minority classes or the loss of information [52, 36, 20].",0.0,Neutral
"These methods have been shown to increase classification accuracy for DNNs and demonstrated their efficacy on long-tailed data [38, 11, 52, 25].",0.0,Neutral
[52] directly exploit pure noise images as tail class samples.,0.0,Neutral
"A recent approach, OPeN [29], adds pure noise images to the original instances from rare classes.",0.0,Neutral
"The multiple normalization module has been explored to improve the generalization of the model in the field of adversarial training (Xie et al., 2020) and insufficient data (Zada et al., 2022).",0.0,Neutral
"Recently, several studies have suggested using multiple normalization layers in a parallel manner (Pan et al., 2018; Xie et al., 2020; Wang et al., 2021; Zada et al., 2022).",0.0,Neutral
"Besides, the core
algorithmic principle of our CBN is different to that of DAR-BN and Auxiliary BN. DAR-BN and Auxiliary BN essentially depends on a main branch to implement the feature normalization for input images.",0.0,Neutral
"Targeted at preventing pure noise images from distorting the estimation of the feature distribution, DAR-BN [42] splits the mean and variance variables for normal images and pure noise images.",0.0,Neutral
", 2021), perform data-augmentation (Chawla et al., 2002; Müller et al., 2019; Chu et al., 2020; Temraz & Keane, 2022; Zada et al., 2022), ensemble the base classifier (Fan et al.",0.0,Neutral
Existing work focuses on collecting realistic training data [9] and introducing random but realistic noise [10].,0.0,Neutral
"Although DCL does not use any external data, DCL achieved higher accuracy than SKS. 5) We further analyze the impact of the sequence between the two stages.",0.0,Neutral
"Compared with the best-performed baseline model SKS, DCL is superior in terms of both metrics.",0.0,Neutral
This is because SKS used an external sentiment dataset to enhance the performance.,0.0,Neutral
[7] proposed the sentiment knowledge sharing (SKS) model integrated with an insulting word list and multi-task learning to detect hate speech.,0.0,Neutral
"Although achieving promising performance in this task, the SKS model holds a strong assumption that insulting and negative emotions can distinguish between hate speech and non-hate speech.",0.0,Neutral
[7] proposed the sentiment knowledge sharing (SKS) model combined,0.0,Neutral
Zhou et al. [7] proposed the sentiment knowledge sharing (SKS) model integrated with an insulting word list and multi-task learning to detect hate speech.,0.0,Neutral
"Therefore, the SKS model with an insulting word list of hate speech achieved limited performance by overly focusing on the token-level emotional semantics.",0.0,Neutral
"We used the different F1 score metrics on two datasets following existing studies, such as the SOTA baseline model SKS [7] for fair comparisons.",0.5,Weak
"For the DV dataset, we adopt the mean accuracy and the weighted F1 after five-fold cross-validation, and save the parameters corresponding to the optimal model, which follows the settings in previous work [7].",0.5,Weak
SKS: It was proposed by Zhou et al. [7].,0.0,Neutral
[7] proposed the sentiment knowledge sharing (SKS) model combined with a negative word list and multi-task learning for hate speech detection.,0.0,Neutral
"The increasing social issue caused by online hate speech has attracted considerable attention of researchers in the natural language processing (NLP) field, seeking efficient and appropriate solutions to detecting online hate speech [3], [4], [5], [6], [7].",0.0,Neutral
"Furthermore, SKS, benefiting from its sentiment knowledge-sharing mechanism and multi-task learning, achieved the best performance among all the baselines.",0.0,Neutral
"4) On the DV dataset, DCL achieved the best performance by accuracy, and better performance by weighted-F1 than all the baseline models except SKS.",0.0,Neutral
"[25] work, authors developed a multitasking framework utilizing sentiment knowledge for hate speech detection based on multi-head attention and category information of hate words.",0.0,Neutral
"Various studies in social sciences and psychology verify the existence of several cues that can aid in detecting hate [35,10,19,5,45] such as the hater’s prior history, the conversational thread, overall sentiment, and aggression in the text.",0.0,Neutral
[32] incorporated sentiment knowledge into a hate speech detection task by employing a multi-task learning framework.,0.0,Neutral
"Recently, most researchers have utilized methods of deep learning based on the pretrained language model to tackle this problem (Mou et al., 2020; Cao and Lee, 2020; Tekiroglu et al., 2020; Mathew et al., 2021; Zhou et al., 2021a).",0.0,Neutral
"Inspired by Zhou et al. (2021a), we design a toxic embedding to introduce lexical knowledge.",0.0,Neutral
"(Mou et al., 2020; Cao and Lee, 2020; Tekiroglu et al., 2020; Founta et al., 2018; Zhou et al., 2021a; Mathew et al., 2021; Caselli et al., 2020; Hanu and Unitary team, 2020).",0.0,Neutral
"The training data with these markers is often labeled as toxic language, leading to spurious associations in the models (Zhou et al., 2021b).",0.0,Neutral
[63] Applies attention based neural networks and word embedding feature extraction methods for classification.,0.0,Neutral
(3) The multi-task learning framework SKS performs well on both datasets.,0.0,Neutral
11https://github.com/dadangewp/HurtBERT 12https://github.com/1783696285/SKS,0.0,Neutral
"2) Baselines: We compare our framework with five categories of baselines: feature-based models (SVM), neural text classification models (LSTM+ATT, CNN+GRU, BiGRU+Capsule, Transformer), pre-trained language model (Bert, HurtBert), Graph Neural Network (DepGCN), and multi-task model (SKS) for abusive language detection.",0.5,Weak
"[34] constructs a largescale abusive language dataset, on which [45] applies GPT-2 to detect abusive language.",0.0,Neutral
Sentiment Knowledge Sharing (SKS) [45] is a multitask abusive language detection framework based on sentiment knowledge sharing.,0.0,Neutral
"(4) Our model achieves better performance than the stateof-the-art SKS. Specifically, the accuracy and F1-macro are increased by nearly 2% on SemEval, while the accuracy is improved by about 1% on OLID.",0.0,Neutral
"(5) Compared with other pre-trained language models (Bert, HurtBert) and multi-task learning model (SKS), we can also observe that our framework w/ BERT is significantly more robust as shown in Figure 3(a) and Figure 3(b).",0.5,Weak
"Furthermore, our framework does not require any extra knowledge, while SKS requires human-annotated sentiment classification datasets 13.",0.0,Neutral
[45] proposes an abusive language detection framework based on external emotional knowledge sharing and combines the characteristics of different feature extraction units to detect abusive language.,0.0,Neutral
"Multi-task learning (MTL) can simultaneously learn multiple related tasks and share knowledge in one framework [23], [45].",0.0,Neutral
"The hate speech detection framework proposed by [29] based on sentiment knowledge sharing (SKS), which includes multiple feature extraction units and a controlled attention mechanism for feature fusion.",0.0,Neutral
"Negative sentiment is a salient toxicity feature, which has been used in designing feature-based and neural toxicity detection systems (Fortuna and Nunes, 2018; Zhou et al., 2021; Chiril et al., 2022), and highly",0.0,Neutral
"Negative sentiment is a salient toxicity feature, which has been used in designing feature-based and neural toxicity detection systems (Fortuna and Nunes, 2018; Zhou et al., 2021; Chiril et al., 2022), and highly correlates with toxic language when targeted at demographic groups.",0.0,Neutral
[5] proposes Sentiment Knowledge Sharing that parallel trains Hate Speech Task and Sentiment Task to improve model generalization.,0.0,Neutral
Zhou et al. (2021) integrate features from external resources to support the model performance.,0.0,Neutral
"In [9], the authors designed a deep learning model fusing affective features with other features for hate speech detection.",0.0,Neutral
Zhou et al. (2021) integrate features from external resources to support the model performance.,0.0,Neutral
"Several works have theoretically studied the success of self-supervised learning (Arora et al., 2019; HaoChen et al., 2021; Lee et al., 2020; Tian et al., 2021; Tosh et al., 2021).",0.0,Neutral
"Several theoretical investigations have delved into the realm of feature decorrelation based methods within the domain of self-supervised learning, as evidenced by a collection of notable studies [4, 16, 30, 35, 44, 48, 51, 55].",0.0,Neutral
"Research identifies that combining asymmetrical structures and special tricks [7, 8, 12] enables contrastive learning to",0.0,Neutral
"SimSiam [8] subsequently built on BYOL to conduct abundant comparative experiments and demonstrated that the stop-grad [8, 12] is the most vital part in asymmetric method.",0.0,Neutral
"3 School of Automation, Southeast University, Nanjing 210096, Jiangsu, China collapses all outputs of the model into constant solutions [11, 12].",0.0,Neutral
"Compared to contrastive learning, they are generally more efficient and conceptually simple while maintaining state-of-the-art performance [60].",0.0,Neutral
"These methods leverage an additional learnable predictor and employ a stop-gradient operation to prevent collapsing, contributing to their successful performance [111].",0.0,Neutral
"We will use BYOL (Grill et al. (2020), Definition 2.3)6 for our investigation into scaling as it is wellstudied (Tian et al., 2021; Richemond et al., 2023), relatively simple to implement due to minimal hyper-parameters, and obtains competitive results (Grill et al., 2020; Koppula et al., 2022).",0.5,Weak
"3)6 for our investigation into scaling as it is wellstudied (Tian et al., 2021; Richemond et al., 2023), relatively simple to implement due to minimal hyper-parameters, and obtains competitive results (Grill et al.",0.5,Weak
"Kontrastif öğrenme, aynı nesnenin artırılmış görüntülerine ait temsil vektörlerini bir araya getirirken negatif örnekleri uzaklaştırmayı teşvik etmek olarak tanımlanabilir [3].",0.0,Neutral
"These models will not collapse to a trivial solution because they construct subtle asymmetry in the structure of the siamese network and create a dynamic buffer area (Tian, Chen, and Ganguli 2021).",0.0,Neutral
"Tian, Chen, and Ganguli (2021) showed that a regularizer is essential for the existence of the non-collapsed solution.",0.0,Neutral
"The linear representation setting has been widely adopted in transfer learning and self-supervised learning (Jing et al., 2021; Tian et al., 2021; Ji et al., 2021; Wu et al., 2022; Tian, 2022; Nakada et al., 2023).",0.0,Neutral
"(4)In fact, dimensional collapse is a more salient issue for non-contrastive approaches in SSL (Hua et al., 2021; Tian et al., 2021) due to the lack of negative pairs.",0.0,Neutral
"To address dimensional collapse in contrastive learning (and more so in non-contrastive SSL), a line of work proposes to refine loss functions and design structured projectors (Balestriero et al., 2023), but a systematic treatment is still lacking.",0.0,Neutral
"Among SSL methods (Chen et al., 2020a; Zbontar et al., 2021; Bardes et al., 2021), contrastive learning (Chen et al., 2020a) is arguably the most popular one, which is also the focus of this paper.",0.0,Neutral
"4In fact, dimensional collapse is a more salient issue for non-contrastive approaches in SSL (Hua et al., 2021; Tian et al., 2021) due to the lack of negative pairs.",0.0,Neutral
"Self-supervised learning (SSL) (Balestriero et al., 2023) has recently emerged as a novel paradigm to learn meaningful representations from huge unlabeled datasets (Misra and van der Maaten, 2019; Chen et al., 2020a; He et al., 2020; Dwibedi et al., 2021; HaoChen et al., 2021; Jing et al., 2021; Wang and Isola, 2020; Ji et al., 2021).",0.0,Neutral
"While there are many lenses one may take up to study the problem [18, 31, 19, 29, 28, 16], a particularly related to this work concurrent body of literature has adopted the view of the kernel or laplacian-based spectral representation learning [11, 1], which we also share in this work.",0.0,Neutral
"Various theoretical studies have also investigated non-contrastive methods for self-supervised learning [5, 18, 33, 48, 54, 58, 63, 70].",0.0,Neutral
"attempted to analyze the training dynamics [42] and build a connection between non-contrastive and contrastive methods [40, 16].",0.0,Neutral
"Mean squared error – Defined as MSE(v, v̂) = 1n ∑n
i=1(vi − v̂i)2, the mean squared error (MSE) is employed in a number of prominent distillation-based SSL frameworks to measure feature alignment (Grill et al., 2020; Tian et al., 2021b; Caron et al., 2021).",0.0,Neutral
"…domains such as medical imaging (Ramesh et al., 2022; Chen et al., 2023a) or other tasks such as classification in the wild (Goyal et al., 2021a; Tian et al., 2021a), object detection (Mishra et al., 2021; Li et al., 2022b), pose estimation (Chen et al., 2023c), action detection as well as…",0.0,Neutral
"These losses are reminiscent of SSL, where they have been theoretically well-studied (Tian et al., 2021; Balestriero & LeCun, 2022), and their translation to VLP has the potential to solve the challenge of the batch size sensitivity and heavily reduce the computational cost.",0.0,Neutral
"Such self-distillation has been explored theoretically and empirically (Chen & He, 2021; Tian et al., 2021) to prevent the collapsing problem, but we do not discuss the distillation scheme in this paper.",0.0,Neutral
"The predictor acts as a whitening operator preventing collapse [Tian et al., 2021], and momentum network can be applied only to the projector [Pham et al.",0.0,Neutral
"Existing Theory of Contrastive Learning Besides the empirical success, theoretical foundations, which explain the efficiency of the methods in contrastive learning, are gradually gathering attention [23, 56, 65, 61, 59].",0.0,Neutral
"…learning [Chen et al. (2020); Grill et al. (2020)] yield new types of learning dynamics that can also be well modelled by deep linear networks [Tian et al. (2020, 2021)], even in settings where the learning dynamics do not correspond to gradient descent on any function [Grill et al. (2020)].",0.0,Neutral
"…hyperparameter
Neural networks: from the perceptron to deep nets 21
choices that work well for training deep linear models, also work well for their highly nonlinear counterparts [Tian et al. (2021)], thereby opening the door to the use of mathematical analysis to drive practical design decisions.",0.0,Neutral
"The selfsupervised learned features are typically more transferable to new tasks than features from supervised learning (Ericsson et al., 2021), even for non-contrastive objectives (Tian et al., 2021).",0.0,Neutral
", 2021), even for non-contrastive objectives (Tian et al., 2021).",0.0,Neutral
"Specifically, inspired by (Chen & He, 2021; Grill et al., 2020; Tian et al., 2021), we question the proposed usage of negative pairs for time series forecasting and the idea of augmenting the data to generate positive pairs, which is empirically investigated in several experiments with different…",0.0,Neutral
"Specifically, inspired by (Chen & He, 2021; Grill et al., 2020; Tian et al., 2021), we question the proposed usage of negative pairs for time series forecasting and the idea of augmenting the data to generate positive pairs, which is empirically investigated in several experiments with different contrastive methods.",0.0,Neutral
", 2021a;b), loss landscapes and training dynamics (Tian et al., 2020; Wang & Isola, 2020; Chen et al., 2021; Tian et al., 2021; Jing et al., 2021; Wen & Li, 2021; Pokle et al., 2022; Ziyin et al., 2022), assran:2022-ssl-hidden-clusterprior, and kernel and spectral methods (Kiani et al.",0.0,Neutral
"…(Tsai et al., 2020; 2021; Tosh et al., 2021a;b), loss landscapes and training dynamics (Tian et al., 2020; Wang & Isola, 2020; Chen et al., 2021; Tian et al., 2021; Jing et al., 2021; Wen & Li, 2021; Pokle et al., 2022; Ziyin et al., 2022; Assran et al., 2022a), and kernel and spectral methods…",0.0,Neutral
"shown in [19] that for contrastive learning, the stop-gradient operation is essential and its removal will lead to representation collapse.",0.0,Neutral
DirectPred [49] provided a theoretical understanding of this non-contrastive SSL setting.,0.0,Neutral
"UniGrad [31] unifies common contrastive learning methods [17, 5, 7, 32, 15, 45, 2] into the same form.",0.0,Neutral
"Tian et al. (2021) study the dynamics of non-contrastive learning, but only focus on the predictor parameters.",0.0,Neutral
Tian et al. (2021) investigate the collapse phenomenon in non-contrastive learning and show in a simplified setting how the stop gradient operation can prevent it.,0.0,Neutral
", 2022), partly explained by the fact that SSL composes the DN of interest fθ with a projector DN gγ appended to it during training and thrown away afterward, (ii) too many per-loss and per-projector hyper-parameters whose impact on the DN’s performances are hard to control or predict (Grill et al., 2020; Tian et al., 2021; He & Ozay, 2022), and which are even widely inconsistent across datasets and architectures Zhai et al.",0.0,Neutral
"…(ii) too many per-loss and per-projector hyper-parameters whose impact on the DN’s performances are hard to control or predict (Grill et al., 2020; Tian et al., 2021; He & Ozay, 2022), and which are even widely inconsistent across datasets and architectures Zhai et al. (2019); Cosentino et…",0.0,Neutral
"The linear representation setting has been widely adapted in the machine learning literature (Jing et al., 2021; Tian et al., 2021; Ji et al., 2021; Wu et al., 2022; Tian, 2022).",0.0,Neutral
"This reflects the decorrelation of features seen above and was suggested in prior work, either using eigendecomposition (Tian et al., 2021) or Cholesky factorization towards optimal whitening (Ermolov et al., 2021).",0.0,Neutral
"Despite the simplicity of the BYOL objective (1), prior work on BYOL theory has involved non-trivial matrix ordinary differential equation analysis under strong assumptions (Tian et al., 2021).",0.0,Neutral
", 2020), or also relied on strong assumptions such as isotropy and multiplicative EMA (Tian et al., 2021) and on differential equation tools for their conclusions.",0.0,Neutral
", 2020) ( Z> θ Zθ )−1 Z> θ Z ′ ξ DirectPred (Tian et al., 2021) (Z> θ Zθ) 1/2 (eigendecomp.",0.0,Neutral
"Yet, several works started unveiling the underlying mechanisms behind self-predictive unsupervised learning (Tian et al., 2021; Liu et al., 2022; Halvagal et al., 2022) (see Sec.",0.0,Neutral
"This reflects the decorrelation of features seen above and was suggested in prior work, either using eigendecomposition (Tian et al., 2021) or Cholesky factorization towards optimal whitening (Ermolov et al.",0.0,Neutral
"This subsumes prior work (Tian et al., 2021; Liu et al., 2022; Halvagal et al., 2022) and enables a more general view informed by optimization on Riemannian manifolds of orthogonal matrices (Edelman et al., 1998; Absil et al., 2007; Bonnabel, 2013).",0.0,Neutral
"This fact can be leveraged thanks to the balancing relationship (Tian et al., 2021), valid in the presence of a small weight decay parameter λ:
Aθ,tA > θ,t = P > θ,tPθ,t +M0e −2λt (7)
where Aθ,t and Pθ,t are now indexed by time t, and M0 is a constant matrix determined at initialization.",0.0,Neutral
"This fact can be leveraged thanks to the balancing relationship (Tian et al., 2021), valid in the presence of a small weight decay parameter λ: Aθ,tA > θ,t = P > θ,tPθ,t +M0e −2λt (7)",0.0,Neutral
"This subsumes prior work (Tian et al., 2021; Liu et al., 2022; Halvagal et al., 2022) and enables a more general view informed by optimization on Riemannian manifolds of orthogonal matrices (Edelman et al.",0.0,Neutral
"…at such explanation have involved implicit contrastive properties of normalizations later disproved empirically (Richemond et al., 2020), or also relied on strong assumptions such as isotropy and multiplicative EMA (Tian et al., 2021) and on differential equation tools for their conclusions.",0.0,Neutral
"And it is shown that self-supervised learning can even be performed without contrastive pairs (Grill et al., 2020; Chen & He, 2021; Tian et al., 2021) by establishing a dual pair of Siamese networks to facilitate the training.",0.0,Neutral
"Recent Siamese network based self-supervised learning methods (Grill et al., 2020; Chen & He, 2021; Tian et al., 2021; He et al., 2020; Chen et al., 2021) alleviate the huge batch challenge by deploying an momentum copy of the target model to facilitate the training and prevent trivial solutions.",0.0,Neutral
"Recent contrastive self-supervised learning methods (Grill et al., 2020; Chen & He, 2021; Tian et al., 2021; He et al., 2020; Chen et al., 2021) alleviate the huge batch challenge at the cost of deploying an momentum copy of the target model to facilitate the training and prevent trivial solutions.",0.0,Neutral
"Many efforts have been devoted to studying the loss function, and the construction of positive pairs [6, 7, 8, 9, 10, 11], while less are paid on the investigation of the architectures.",0.0,Neutral
"SimSiam [67] do not collapse [271] have been conducted, but the fundamental reason remains elusive.",0.0,Neutral
"BYOL [18] and SimSiam [19] extend similarity loss and remove the dependency on negative instances [20], [21], [22].",0.0,Neutral
"Several works have theoretically analysed self-supervised approaches, both for contrastive [48], [49], [50], [51], [52] and non-contrastive methods [53], [54], [55], [56], to motivate the reasons for their successes, identify the main underlying principles and subsequently provide more principled/simplified solutions.",0.0,Neutral
"In this regard, asymmetries, in the form of stop-gradient and diversified predictors, are sufficient to ensure well-behaved training dynamics [53], [55], [56].",0.0,Neutral
"In[34], it is mentioned that the potential representation of nodes can be better learned by not using negative samples when performing contrasting learning.",0.0,Neutral
"There are some efforts to theoretically understand the SSL methods [30, 14], the role of data augmentation [28, 26], and some empirical analyses of the contrastive loss [4] and the predictor in the so-called BYOL framework [25].",0.0,Neutral
SPIRAL proposed in-utterance contrastive loss& position randomization to avoid model collapse& positional collapse that arise on its own specific SG teacher design but not on the nonlinear learning dynamics of non-contrastive SSL[25].,0.0,Neutral
"Hence the fundamental question arises: how do multiple factors, like stop-gradients, EMA, teacher networks, and regularization, all come into play to avoid collapse? This leads to experimental studies like our TriNet and theoretical studies like [25, 26].",0.0,Neutral
"Building on DirectPred [1], we presented a simple analysis formulated in the eigenspace of representations that illustrates how BYOL/SimSiam’s asymmetric similarity loss avoids representational collapse.",0.0,Neutral
[1] underscored the importance of boosting small eigenvalues and suggested that evolving the weights in the target network using EMA serves as an automatic curriculum for small eigenvalues.,0.0,Neutral
"Here, by building on DirectPred [1], we lay out a theoretical framework that reconciles these two views.",0.5,Weak
[1] for the case of linear feedforward and predictor networks.,0.0,Neutral
"Finally, instead of gradient-based optimization, we directly set the predictor network as a simple function of this correlation matrix as suggested in DirectPred [1].",0.0,Neutral
"In this work, we consider the linear network setting used previously for studying non-contrastive SSL in [1, 8], and provide a straightforward analysis of how the learning dynamics in DirectPred and DirectCopy prevent representational collapse.",0.0,Neutral
"The learning dynamics induced by such asymmetric loss Siamese architectures are surprisingly intricate [1, 8, 9] but not fully understood.",0.0,Neutral
"Further, compared to contrastive learning, the non-contrastive learning frameworks require smaller sized batches to train the models (Tian et al., 2021).",0.0,Neutral
"Several studies (Jaiswal et al., 2020; Tian et al., 2021; Balestriero and LeCun, 2022) have proposed theoretical analysis to form justifications for the empirical performance of selfsupervised approaches.",0.0,Neutral
[17] concluded the contrastive learning methods and present a comprehensive theoretical study of SSL without contrastive pairs.,0.0,Neutral
"Several theoretical works also study non-contrastive methods for self-supervised representation learning [Wen and Li, 2022, Tian et al., 2021, Garrido et al., 2022, Balestriero and LeCun, 2022].",0.0,Neutral
"Ideally, this model should not only perform better than BGRL in the inductive setting, but should also have the same time complexity as BGRL.",0.0,Neutral
"As such, we refer to these two methods as BGRL.",0.0,Neutral
This has also been shown to be true for BGRL. Tian et al. (2021) claim that the eigenspace of predictor weights will align with the correlation matrix of the online network under the assumption of a one-layer linear encoder and a one-layer linear predictor.,0.0,Neutral
"We can see that T-BGRL pushes apart unseen negative and positive pairs much better than BGRL.
Table 3: Transductive performance of T-BGRL compared to ML-GCN and BGRL (same numbers as Table 1 above; full figure in Table 5).",0.0,Neutral
BGRL.,0.0,Neutral
We also evaluate the performance of T-BGRL in the transductive setting to ensure that it does not significantly reduce performance when compared to BGRL.,0.0,Neutral
"We experiment with several different corruptions methods, but limit ourselves to linear-time corruptions in order to maintain the efficiency of BGRL.",0.0,Neutral
"served that the collapse can be avoidable in carefully designed training frameworks [9, 31, 62], it is still a problem in certain settings depending on model choices and trainingdataset sizes [38].",0.0,Neutral
"Several non-contrastive methods are proposed to learn image-level representations solely based on positive samples [2, 9, 13, 26, 51, 59].",0.0,Neutral
"Instance discrimination contains several sub-frameworks, including contrastive learning [13, 31], asymmetric networks [15, 27] and feature decorrelation [6, 89], which are found of similar mechanism [66,70].",0.0,Neutral
collapse resulting from the absence of negative samples [162].,0.0,Neutral
"[43] investigated the elements of these negative-free approaches relying on architectural update (adding a predictor block) as well as new training protocol (stop-gradient policy), which enables them to substantially outperform contrastive approaches while avoiding the trivial representation.",0.0,Neutral
"3) Contrastive Learning: Most successful self-supervised or unsupervised visual representation methods [38], [39], [40] rely on contrastive learning.",0.0,Neutral
"Self-supervised learning [7, 30, 31, 35] has achieved remarkable progress in recent years, in representation learning without the need for class label supervision.",0.0,Neutral
"More recent works [4], [32], [33] have shown that we can learn high-quality representations without negative samples.",0.0,Neutral
"Indeed, it has been shown that pretraining the same joint-embedding methods on long-tailed datasets can lead to significant drops in performance (Tian et al., 2021a).",0.0,Neutral
"Recent theoretical work (Tian et al., 2021b) explores why certain joint-embedding methods with architectural constraint avoid representation collapse without explicit use of a volume maximization penalty; the implicit collapse prevention mechanisms here are not mutually exclusive.",0.0,Neutral
"…dynamics of joint-embedding methods, they do not directly explain why empirical use of these methods with real-world classimbalanced data has often led to a degradation in downstream task performance (Tian et al., 2021a; Goyal et al., 2022) (see Appendix A for a broader discussion of related work).",0.0,Neutral
"There is also theoretical work (Tian et al., 2021b) which aims to understand why certain joint-embedding methods, such as BYOL (Grill et al., 2020), can avoid representation collapse without explicit use of a volume maximization penalty.",0.0,Neutral
"8, we find that: 1) BW-based whitening loss ensures a whitened target Ẑ2, while SimSiam does not put constraint on the target Z2; 2) SimSiam uses a learnable predictor Pθp(·), which is shown to empirically avoid collapse by matching the rank of the covariance matrix by back-propagation [40], while BW-based whitening loss has an implicit predictor φ(Z1) depending on the input itself, which is a full-rank matrix by design.",0.0,Neutral
"It remains not clear how the asymmetric network avoids collapse without negative pairs, leaving the debates on batch normalization (BN) [14, 41, 36] and stop-gradient [8, 46], even though preliminary works have attempted to analyze the training dynamics theoretical with certain assumptions [40] and build a connection between asymmetric network with contrastive learning methods [39].",0.0,Neutral
"The success of BYOL (Grill et al., 2020) inspired empirical (Chen & He, 2021) and theoretical (Tian et al., 2021) analyses into what enables BYOL to effectively learn and avoid collapse with the EMA Teacher during pre-training.",0.0,Neutral
", 2020) inspired empirical (Chen & He, 2021) and theoretical (Tian et al., 2021) analyses into what enables BYOL to effectively learn and avoid collapse with the EMA Teacher during pre-training.",0.0,Neutral
"Preventing such collapsed representations is a frequently discussed topic in literature (Hua et al., 2021; Jing et al., 2021; Pokle et al., 2022; Tian et al., 2021) and has motivated the design of several SSL techniques (Zbontar et al., 2021; Bardes et al., 2021; Ermolov et al., 2021).",0.0,Neutral
"In practice, however, SSL training often experiences the phenomenon of dimensional collapse (Jing et al., 2021; Tian et al., 2021; Pokle et al., 2022), where the learned representation spans a low dimensional subspace of the overall available space.",0.0,Neutral
"Preventing such collapsed representations is a frequently discussed topic in literature (Hua et al., 2021; Jing et al., 2021; Pokle et al., 2022; Tian et al., 2021) and has motivated the design of several SSL techniques (Zbontar et al.",0.0,Neutral
"…causality and data-generating processes (Zimmerman et al., 2021; Kugelgen et al., 2021; Trivedi et al., 2022; Tian et al., 2020; Mitrovic et al., 2020; Wang et al., 2022), dynamics (Wang and Isola, 2020; Tian et al., 2021; Tian, 2022; Wang and Liu, 2021), and loss landscapes (Pokle et al., 2022).",0.0,Neutral
", 2022), dynamics (Wang and Isola, 2020; Tian et al., 2021; Tian, 2022; Wang and Liu, 2021), and loss landscapes (Pokle et al.",0.0,Neutral
"[107] Yuandong Tian, Xinlei Chen, and Surya Ganguli.",0.0,Neutral
"Many investigators have appreciated the importance of improving our understanding of unsupervised representation learning and taken pioneering steps to simplify SOTA methods [18; 19; 114; 22], to establish connections to classical methods [69; 4], to unify different approaches [4; 39; 97; 62; 55], to visualize the representation [9; 116; 15], and to analyze the methods from a theoretical perspective [3; 45; 107; 4].",0.0,Neutral
Tian et al. (2021) studies the effect of the non-linear predictor and stop-gradient in these methods and observe that both components are essential to prevent collapse.,0.0,Neutral
"Some prior work has analyzed non-contrastive learning dynamics in a simple linear model [34], but analysis of when collapse happens is still ad hoc and largely anecdotal.",0.0,Neutral
"Contrary to previous methods that claim that the stop-gradient, prediction head, and high predictor learning rate are enough to prevent the collapse [7,34], we show that collapse additionally depends on the model capacity relative to the data complexity.",0.0,Neutral
Understanding Self-supervised Learning [34] analyzes a surprisingly predictive linear model that represents the BYOL and SimSiam settings.,0.0,Neutral
"negative pairs, and ii) prevents representational collapse in an intuitive and explainable manner [15], unlike approaches such as BYOL [2] which are theoretically poorly understood (although some attempts have recently been made [16]).",0.0,Neutral
[24] performs a spectral analysis of DNN’s mapping induced by non-contrastive loss and the momentum encoder approach.,0.0,Neutral
"The main risk in such an approach is the so-called the feature collapse phenomenon [19, 24, 27], where the learned representations are invariant to input samples that belong to different manifolds.",0.0,Neutral
"Most work [24, 25, 34, 36, 55, 103, 107, 108] in designing and understanding non-contrastive methods concerns how to avoid the “collapsing” of the teacher to a constant.",0.0,Neutral
"Many recent work [55, 103, 107, 108] have studied how distillating SSL methods work and the importance of optimization tricks such as stop-gradients, exponential moving average, and normalizations.",0.0,Neutral
"This can be indicated using the stop-gradient operation stopgrad(·) as follows [58,59]: z′t S = stopgrad(E(ŝ ′t S )) (6)",0.0,Neutral
"Families of Models Model Rationale Representative Strategies and Methods
Pretext tasks Pixel-level reconstruction [124], [125], inpainting [126], MAE [127], denoising [128], colorization [129], [130], [131] Instance-level predict image rotations [123], scaling and tiling [122], patch ordering [11], patch re-ordering [121]
Discriminative models Instance discrimination negative sampling large batch size (SimLR [12]), memory bank (InstDis [132]), queue (MoCo [16]) input transformation data augmentation (PIRL [133]), multi-view augmentation (CMC [134]) negative-sample-free simple siamese (SimSiam [135]), Bootstrap (BYOL [136]), DirectPred [137]
Deep clustering offline clustering DeepCluster [138], JULE [139], SeLa [140] online clustering IIC [141], PICA [142], AssociativeCluster [143], SwAV [144]
Deep generative models Discriminator-level DCGAN [145], Self-supervised GAN [146], Transformation GAN [147] Generator-level BiGAN [148], BigBiGAN [149]
✓",0.0,Neutral
"negative-sample-free simple siamese (SimSiam [135]), Bootstrap (BYOL [136]), DirectPred [137]",0.0,Neutral
"(12)), another alternative non-contrastive scheme for instance discrimintation operates in a negativesample-free manner [135], [136], [137], [181], as exemplified by bootstrap (BYOL) [136] and simple siamese networks (SimSiam) [135]).",0.0,Neutral
"Without contrasting negative instances, the training process of non-contrastive methods is more efficient and conceptually simple [52, 55].",0.0,Neutral
"To solve this problem, some non-contrastive approaches are developed with only using positive pairs but achieving remarkable performance, such as BYOL [53], SwAV [54], SimSiam [55], DirectPred [52], and DINO [19].",0.0,Neutral
constructed and need a large batch size or memory bank for storage [52].,0.0,Neutral
"However, an implicit contrast is applied by the batch normalization layer in the implemented network [75, 79].",0.0,Neutral
Later work [42] concentrates on the theoretical influence of the asymmetric network structures.,0.0,Neutral
"There are follow-up studies on the asymmetric structure that are mainly about the theoretical understanding [42,9] and the effectiveness for linear classification [9,10].",0.0,Neutral
"In such methods, using various architecture tricks (like prediction head, stop-gradient, momentum encoder, batch normalization or centering) is shown empirically to be sufficient to avoid collapse without instance discrimination, even though it is not fully understood how these multiple factors induce a regularization during training (Richemond et al., 2020; Tian et al., 2021).",0.0,Neutral
"Relation-based approaches learn features to increase the similarity among a sample [6, 10, 11, 25, 54] and its transformed positive instances while some also treat other training samples as negative instances.",0.0,Neutral
"Some recent works [12,27,72] introduce asymmetry in the alignment of the positive pair to learn meaningful representations without explicit uniformity.",0.0,Neutral
"Furthermore, it has been shown that the stop-grad operation is critical to avoid the problem of complete collapse in the representations (Tian et al., 2021).",0.0,Neutral
"Second, we construct a framework to abstract and maximize similarity object-level agreement (foreground and background) across different views beyond augmentations of the same image [13,18,23].",0.0,Neutral
"Moreover, it pushes the anchor embedding similar to positive emedding and dissimilar to negative embedding [Tian et al., 2021].",0.0,Neutral
"Then, DirectPred (Tian et al., 2021) provides theoretical analysis to verify the effectiveness of BYOL.",0.0,Neutral
"There are already some works like SimSiam [84] and [249] that try to investigate the underline theory, yet they are not enough.",0.0,Neutral
"To measure subspaces dimensionality, we compute the singular value decomposition on the covariance matrix Covx = UΣV T ,Σ = diag(σ), following general practice in SSL theory [39, 73].",0.0,Neutral
"[73] Yuandong Tian, Xinlei Chen, and Surya Ganguli.",0.0,Neutral
"Subsequent theoretical analysis [12, 13, 14, 15] have demonstrated why these techniques can avoid trivial solutions and learn meaningful representations from different aspects.",0.0,Neutral
", contrastive learning [7], [35], [36], [37], [38], [39], [40], self-clustering [41], [42], [43], and representation alignment [5], [6], [44], [45], [46], [47].",0.0,Neutral
The terms in Equation 1 can be decomposed using a variance-covariance perspective [31].,0.0,Neutral
The fact that a method like SimSiam does not collapse is studied in [29].,0.0,Neutral
The fact that a method like SimSiam does not collapse is studied in Tian et al. (2021).,0.0,Neutral
"Even though they do not avoid collapse explicitly through their criteria, recent works such as Halvagal et al. (2022) or Theorem 3 from Tian et al. (2021) have shown links between the training dynamics of SimSiam and variance and covariance regularization, akin to what Lnc would lead to.",0.0,Neutral
The work [32] replaces the encoder in BYOL with a two-layer model and gives a theoretical analysis of why the two models (online and target) do not collapse.,0.0,Neutral
"This is often due to the lack of proper objective functions or architectures [6, 32].",0.0,Neutral
"However, they suffer from the lack of explainability [32].",0.0,Neutral
"1Note [32] provides an analysis of their learning dynamics with twolayer models, which accounts for the reason why the two models do not fail with trivial solutions.",0.0,Neutral
"Recently, some theoretical works have tried to understand how these new methods succeed in avoiding representational collapse [15, 27].",0.0,Neutral
"To prevent trivial solutions (Tian et al., 2021), a popular trick is to apply additional repulsive force between the embeddings of semantically dissimilar images, known as contrastive learning (Chopra et al.",0.0,Neutral
"To prevent trivial solutions (Tian et al., 2021), a popular trick is to apply additional repulsive force between the embeddings of semantically dissimilar images, known as contrastive learning (Chopra et al., 2005; Schroff et al., 2015; Sohn, 2016).",0.0,Neutral
"[28, 29] on SimCLR [8], [30] on the projector of contrastive models, [14] on BYOL [31] and SimSIAM [8].",0.0,Neutral
"Theory of SSL: Recently, substantial advances have been made towards demystifying SSL methods from the perspectives of learning theory (Arora et al., 2019), information theory (Tsai et al., 2021), causality (Kugelgen et al., 2021), and dynamical systems (Tian et al., 2021a).",0.0,Neutral
"Since centralized SSL techniques are known to be sensitive to heavy-tailed gradient distributions (Tian et al., 2021b) and require large batch-sizes (Chen et al., 2020), it is unlikely their direct extensions will function well in the high heterogeneity and resource constrained setting of…",0.0,Neutral
", at least 4 GPUs or 32 TPU cores) for learning better representations from images [10].",0.0,Neutral
"What type of negative sampling scheme to use is an essential question, and the role and necessity of negative sampling in contrastive methods is an open issue [274, 277].",0.0,Neutral
"2010) (also known as Contrastive Learning) has emerged as a highly effective approach for unsupervised representation learning using deep networks (Chen et al., 2020; Chen & Li, 2020; Tian et al., 2021; Grill et al., 2020).",0.0,Neutral
"Noise contrastive estimation (NCE) (Gutmann & Hyvärinen, 2010) (also known as Contrastive Learning) has emerged as a highly effective approach for unsupervised representation learning using deep networks (Chen et al., 2020; Chen & Li, 2020; Tian et al., 2021; Grill et al., 2020).",0.0,Neutral
"Finally, there has also been recent work exploring whether contrastive learning can be performed without the use of negative samples while avoiding the phenomenon of feature collapse (Tian et al., 2021; Grill et al., 2020).",0.0,Neutral
"In particular, this technique contrasts positive pairs against negative pairs and minimizes differences between positive pairs to avoid collapsing solutions [47], [50].",0.0,Neutral
Tian et al [43] performs several experiments and report that the predictor network at the end of the online network and stop-gradients for the target network are necessary to avoid the representation collapse.,0.0,Neutral
"However, the absence of the negative pairs in BYOL stirred a lot of commotion in the community and several works [39, 44, 43, 40] have tried to understand the phenomenon.",0.0,Neutral
"It has been shown [24, 29] that this training procedure is sufficient to avoid collapsed solutions such as constant representations, since the updates to the target network parameters ξ are not in general in the direction of ∇ξL BY OL θ,ξ , due to the stop grad operation in the target network.",0.0,Neutral
Instance discrimination compares pairs of images to identify which are most similar; it then moves those together while pushing dissimilar images apart [47].,0.0,Neutral
"This interpretation echos well with the finding that the eigenspace of hweight aligns well with that of correlation matrix (Tian et al., 2021).",0.0,Neutral
"Subsequent works based on data augmentation also showed promising results for methods based on non-contrastive learning (non-CL), which do not require explicit negative samples (Grill et al., 2020; Richemond et al., 2020; Chen & He, 2021; Zbontar et al., 2021; Tian et al., 2021).",0.0,Neutral
"Namely, Tian et al. (2021) adopts a linear network and calculates the optimization dynam-
ics of non-contrastive learning, while Wen & Li (2021) analyzes the feature learning process of contrastive learning on a single-layer linear model with ReLU activation.",0.0,Neutral
"For an input x, the augmented views a1,a2 ∈ Rp×1 are generated as ∗:
a1 := D1x; a2 := D2x (3)
Network architecture We use a dual network architecture inline with prior work Arora et al. (2015); Tian et al. (2021); Wen & Li (2021).",0.5,Weak
"To understand how non-contrastive learning works, existing works mostly focus on analyzing what elements help it avoid learning collapsed representations (Grill et al., 2020; Richemond et al., 2020; Chen & He, 2021; Zbontar et al., 2021; Tian et al., 2021; Wang et al., 2021).",0.5,Weak
Our model architecture gets inspirations from Tian et al. (2021) and Wen & Li (2021).,0.5,Weak
"For this proof, we borrow theoretical findings from the DirectPred literature [47].",0.5,Weak
[47] theoretically analyzed on why the non-contrastive methods work well.,0.0,Neutral
"Self-supervised learning (SSL) is a framework for learning representations of data [6, 13, 19, 7, 5, 56, 47, 34, 27, 36].",0.0,Neutral
"In addition, the theoretical analysis and experimental study in Tian et al.51 has raised two additional suggestions for training non-contrastive SSL models like BYOL and SimSiam.",0.0,Neutral
", the extra learnable predictor and a stop-gradient operation.(51) ll OPEN ACCESS Review",0.0,Neutral
"In addition, the theoretical analysis and experimental study in Tian et al.(51) has raised two additional suggestions for training non-contrastive SSL models like BYOL and SimSiam.",0.0,Neutral
"Although promising performance has been achieved, we observed that the existing deep graph clustering algorithms [9], [14], [15] suffer from the representation collapse issue [16] and easily embed the nodes from different classes into the same embedding.",0.0,Neutral
Representation collapse is a common problem that the network tends to encode samples from different classes into the same representation in the field of the self-supervised learning [16].,0.0,Neutral
"The recent focus in research has gradually shifted to only minimizing the distance between the positive pairs without simultaneously maximizing the distance between negative pairs [8, 9, 10].",0.0,Neutral
The paper[10] also highlights the impact of a potential asymmetry with the larger number of negative keys than the number of positive keys skewing the learning.,0.0,Neutral
"MSI dataset is binned between the (m/z) range of [50, 1000] to 1024 bins.",0.0,Neutral
"We vary k in the interval of [50, 1000] with a sensible step.",0.0,Neutral
"In addition to framework design, theoretical analyses and empirical studies have also been proposed to better understand the behavior and properties of contrastive learning [1, 3, 6, 9, 24, 31, 35, 39, 39, 41, 44, 52].",0.0,Neutral
"To alleviate such constraint, non-contrastive approaches that do not use negative samples have been proposed [23, 5, 71, 63].",0.0,Neutral
"The theory behind is under investigation (Chen & He, 2021; Tian et al., 2021).",0.0,Neutral
"Moreover, Tian et al. (2021) analyzed these non-contrastive siamese frameworks from a theoretical view, justifying some key designs including the stop gradient and asymmetric predictor.",0.0,Neutral
to boost downstream performance on image [165] and video tasks [161].,0.0,Neutral
"In the branch without predictor the gradient is not backpropagated during training, which was found to be crucial in preventing collapse to trivial solutions [55].",0.0,Neutral
"The second line of research further simplify the contrastive assumption, which only imposes invariant constraints between paired positive samples [9, 15, 46, 47] in the absence of the negative samples.",0.0,Neutral
"This aligns with what has been shown in self-supervised learning [41, 42].",0.0,Neutral
"[42] Yuandong Tian, Xinlei Chen, and Surya Ganguli.",0.0,Neutral
"This paper mainly investigates this phenomenon of non-contrastive representation learning for deep clustering, and the theoretical analysis can be found in [14], [54].",0.0,Neutral
", in the settings of transfer learning [8, 10, 44, 45] and self-supervised learning [26, 34, 43].",0.0,Neutral
"2) Using siamese network [8] to avoid representation collapse [36, 20, 85].",0.0,Neutral
"This module is present in a number of contrastive self-supervised learning methods (Chen et al., 2020a; Grill et al., 2020; Zbontar et al., 2021; Tian et al., 2021).",0.5,Weak
…the dynamics of learning without contrasting pairs is far from trivial and beyond the scope of this paper; we refer the reader to the recent work by Tian et al. (2021) that studies this learning paradigm in depth and discusses why trivial solutions are avoided when learning without negatives as in…,0.0,Neutral
"As also recently noted in Tian et al. (2021), a crucial part of learning with non-contrastive pairs is the projector.",0.0,Neutral
"To reduce the annotation cost for representation learning, self-supervised representation learning (SSL) methods including (Goyal et al., 2021; Tian et al., 2021a; Zbontar et al., 2021; Tian et al., 2020b;a; Chen et al., 2020a; He et al., 2020; Tian et al., 2020b; Chen et al., 2020b) and many more…",0.0,Neutral
"…point (FP) networks (Goyal et al., 2021; Tian et al., 2021a; Zbontar et al., 2021; Li et al., 2021a; Cai et al., 2021; Ericsson et al., 2021; Tian et al., 2021b; Ermolov et al., 2021; Tian et al., 2020b; Chen et al., 2020b; Grill et al., 2020; Caron et al., 2020; He et al., 2020) that…",0.0,Neutral
"Recent years have witnessed great successes in self-supervised learning (SSL) for floating point (FP) networks (Goyal et al., 2021; Tian et al., 2021a; Zbontar et al., 2021; Li et al., 2021a; Cai et al., 2021; Ericsson et al., 2021; Tian et al., 2021b; Ermolov et al., 2021; Tian et al., 2020b; Chen…",0.0,Neutral
"A.3 DISCUSSION ON COMPARISON TO SUPERVISED PRETRAINING
Following the previous literature (Zbontar et al., 2021; Goyal et al., 2021; Tian et al., 2021a; Grill et al., 2020; Caron et al., 2020; He et al., 2020), we used the same amount of labeled and unlabeled data for supervised pretraining or BSSL.",0.0,Neutral
"Several works have also theoretically studied the success of self-supervised learning [Arora et al., 2019, HaoChen et al., 2021, Wei et al., 2021, Lee et al., 2020b, Tian et al., 2021, Tosh et al., 2020, 2021].",0.0,Neutral
"In this paper, we make a first attempt towards the second question, by studying a family of algorithms named DirectSet(α), in which the DirectPred algorithm proposed by Tian et al. (2021) is a special case with α = 1/2.",1.0,Strong
"The numbers for DirectPred, DirectPred (freq=5) and SGD baseline on STL-10/CIFAR-10 are obtained from Tian et al. (2021).",0.5,Weak
"Comparison with Tian et al. (2021) Tian et al. (2021) only explained why the representation in nc-SSL does not collapse to zero, but did not study what representation is learned and how the representation is related to the data distribution and augmentation process.",0.0,Neutral
"Tian et al. (2021) also analyzed nc-SSL on a linear network, but did not analyze their proposed approach DirectPred.",0.0,Neutral
"Our code is adapted from (Tian et al., 2021) 5, and we follow the same data augmentation process.",1.0,Strong
"Note in the previous work (Tian et al., 2021), they assumed the covariance of the augmentation distribution to be σ2I and did not study what representation is learned.",0.0,Neutral
"While Tian et al. (2021) addressed the first question, i.e., why the learned representation does not collapse to zero, they did not address the second question, i.e., how the training dynamics in nc-SSL leads to a meaningful representation that depends on the data augmentations and reduces the…",0.0,Neutral
"Dynamics for λB: We can write down the dynamics for λB as follows:
λ̇B = λB [ −(1 + σ2) |λB |4α + |λB |2α − η ] Similar as the analysis in (Tian et al., 2021), when η > 14(1+σ2) , we know λ̇B < 0 for any λB > 0 and λB = 0 is a critical point.",0.5,Weak
"Motivated by the analysis, we also design a simpler and more efficient algorithm (DirectCopy), which achieves comparable or even better performances than the original DirectPred proposed by Tian et al. (2021).",1.0,Strong
"Note in the previous work (Tian et al., 2021), they assumed the covariance of the augmentation distribution to be σ(2)I and did not study what representation is learned.",0.0,Neutral
"As one of the first work towards this direction, Tian et al. (2021) showed that while the global optimum of the non-contrastive loss is indeed a trivial one, following gradient direction in nc-SSL, one can find a local optimum that admits a nontrivial representation.",0.0,Neutral
Tian et al. (2021) proposed DirectPred that directly sets the predictor based on the correlation matrix of the predictor inputs.,0.0,Neutral
"Inspired by the analysis, we designed a simpler and more efficient algorithm DirectCopy, which achieved comparable or even better performance than the original DirectPred (Tian et al., 2021) on various datasets.",1.0,Strong
"Similar as the analysis in Tian et al. (2021), when η > 1 4(1+σ2) , we know λ̇B < 0 for any λB > 0 and λB = 0 is a stable stationary point, as illustrated in Figure 4 (Left).",0.5,Weak
"Thresholding role of weight decay in feature learning: While Tian et al. (2021) showed why nc-SSL does not collapse, one key question is how nc-SSL learns useful features and how the method determines which feature is learned.",0.0,Neutral
"Stop-gradient For the optimization on variational representation reconstruction, related work have found that adding the stop-gradient operator (SG) as a regularizer can make the training more stable without collapse both empirically [11, 28] and theoretically [73].",0.0,Neutral
"27 [73] Yuandong Tian, Xinlei Chen, and Surya Ganguli.",0.0,Neutral
"Moreover, Wen and Li (2021) considered the representation learning under the sparse coding model and studied the optimization properties on shallow ReLU neural networks, (Tian et al., 2021; Wang et al., 2021) investigated why self-supervised learning can learn features without contrastive pairs in a linear representation setting, and (Jing et al.",0.0,Neutral
"Recent theoretical works have also shed light on why the linear predictor and gradient block help prevent collapse (Tian et al., 2021).",0.0,Neutral
"The recent advances can be classified into two categories (Tian et al., 2021): contrastive SSL and non-contrastive SSL.",0.0,Neutral
"This operation has also been shown to be crucial in siamese, non-contrastive, self-supervised learning, both empirically [21, 12] and theoretically [36].",0.0,Neutral
"We next provide a variance-covariance perspective to the new objective, following similar lines of reasoning in [41, 42].",0.5,Weak
"However, though BGRL could avoid collapse empirically, it still remains as an open problem concerning its theoretical guarantee for preventing trivial solutions [41].",0.0,Neutral
"It is an interesting question to understand the design decisions in these pipelines (Tian et al., 2021), but this is outside the scope of the present paper.",0.0,Neutral
"…started exploring this direction in both nonlinear CCA and AM-SSL (see, e.g., (Lyu & Fu, 2020; von Kügelgen et al., 2021; Zimmermann et al., 2021; Tian et al., 2021; Saunshi et al., 2019; Tosh et al., 2021)), but more insights and theoretical underpinnings remain to be discovered under more…",0.0,Neutral
", (Lyu & Fu, 2020; von Kügelgen et al., 2021; Zimmermann et al., 2021; Tian et al., 2021; Saunshi et al., 2019; Tosh et al., 2021)), but more insights and theoretical underpinnings remain to be discovered under more realistic and challenging settings.",0.0,Neutral
"Interestingly, recent work shows that a variant of simple one-way consistency evades trivial solutions even in the context of self-supervised representation learning [50,51].",0.0,Neutral
"[116] Yuandong Tian, Xinlei Chen, and Surya Ganguli.",0.0,Neutral
"Some non-contrastive approaches [36], [90], [91] maximize the similarity of different output versions of the image and avoid negative pairs.",0.0,Neutral
"[41] provide a theoretical analysis and some insights on how collapse is avoided by asymmetric methods, but the complete dynamics is far from being understood and these methods might not work in other self-supervised learning setups.",0.0,Neutral
"These properties have been leveraged to better understand the role of over-parameterization [29], implicit regularization [30], network pruning [31], continual learning [58], and self-supervised learning [32].",0.0,Neutral
"This formula unifies an array of conservation properties noticed under gradient flow [1, 29, 30, 31, 32] with a formal theoretical connection to Noether’s theorem.",0.0,Neutral
"Overall, just like how Noether’s theorem [28] unified an array of conservation laws and provided a theoretical foundation to discover new ones in physics, we have further unified conservation laws previously observed in learning systems [1, 29, 30, 31, 32] and generalized these results for any combination of differentiable symmetries in neural network architectures and learning rules (e.",0.0,Neutral
provide an analysis of how various factors involved in BYOL and SimSiam work together to prevent collapse [42].,0.0,Neutral
"Recently, several self-supervised learning methods have achieved the state-of-the-art performance on the large-scale natural image dataset ImageNet [37] without negative sample pairs [38].",0.0,Neutral
"Other works (Saunshi et al., 2019; Tosh et al., 2020; Tian et al., 2021) study the generalization error of contrastive learning based SSL, whose setting is different from our paper.",0.0,Neutral
"In contrast, our method avoids trivial solutions by construction, making our method conceptually simpler and more principled than these alternatives (until their principle is discovered, see (Tian et al., 2021) for an early attempt).",0.0,Neutral
"The theoretical analysis on self-supervised representation algorithms without negative samples [Tian et al., 2021] cannot be applied to the contrastive learning setting.",0.0,Neutral
"This non-collapsing behavior even without relying on negatives has been studied further (Tian et al., 2021).",0.0,Neutral
"Feature learning has been widely investigated from the theoretical perspective in other domains, such as supervised learning Allen-Zhu & Li (2020); Du et al. (2021); Tripuraneni et al. (2020), constrastive learning Tian et al. (2021) and RL Agarwal et al. (2020a).",0.0,Neutral
[215] showed why algorithms without negative examples such as SimSiam [65] and BYOL [63] work: the dynamics of the eigenspace alignment between the predictor and its input correlation matrix play a vital role in preventing complete collapse.,0.0,Neutral
"For example, many studies have been conducted on why BYOL and SimSiam [65] do not collapse [215].",0.0,Neutral
"Tian et al. (2021) study the dynamics of non-contrastive learning, but only focus on the predictor parameters.",0.0,Neutral
"However, directly adding the alignment part will cause degenerate solutions (Tian et al., 2021; Wang & Isola, 2020), which means all the images are encoded to the same and collapsed representation.",0.0,Neutral
"Besides, Moco and BYOL use momentum and stop-gradient mechanisms are adopted to prevent degenerate solutions (Tian et al., 2021; Wang & Isola, 2020).",0.0,Neutral
"Many researchers [47], [48], [49], [50], [51] have endeavored to comprehend and elucidate its characteristics, along with its impacts on downstream tasks.",0.0,Neutral
"We note some dimensional collapse is still observed for Barlow Twins projectors, as found for BYOL (Grill et al., 2020; Tian et al., 2021) & SimCLR (Chen et al.",0.0,Neutral
"The proof of Proposition 3.3 can be found in Appendix A, & is largely inspired from previous work (Saxe et al., 2013; Ji & Telgarsky, 2018; Tian et al., 2021; Jing et al., 2021).",0.5,Weak
"We note some dimensional collapse is still observed for Barlow Twins projectors, as found for BYOL (Grill et al., 2020; Tian et al., 2021) & SimCLR (Chen et al., 2020a; Jing et al., 2021), as the encoder dimension is 512 with projector width of 1024.",0.0,Neutral
"We point out that although we provide empirical evidence from practical settings to corroborate our theoretical results, our theory has some non-standard assumptions to ease analytical exposition, such as linear projector MLPs, much like related theoretical work in SSL (Tian et al., 2021; Wang et al., 2021; Jing et al., 2021).",0.5,Weak
"Existing theoretical analyses into feature collapse & its mechanisms in SSL have focused on explaining why it does not occur in non-contrastive SSL (Tian et al., 2021; Zhang et al., 2022) or how a related notion of dimensional collapse (Hua et al., 2021), where features span a low-dimension…",0.0,Neutral
"Existing theoretical analyses into feature collapse & its mechanisms in SSL have focused on explaining why it does not occur in non-contrastive SSL (Tian et al., 2021; Zhang et al., 2022) or how a related notion of dimensional collapse (Hua et al.",0.0,Neutral
"3 can be found in Appendix A, & is largely inspired from previous work (Saxe et al., 2013; Ji & Telgarsky, 2018; Tian et al., 2021; Jing et al., 2021).",0.5,Weak
"…provide empirical evidence from practical settings to corroborate our theoretical results, our theory has some non-standard assumptions to ease analytical exposition, such as linear projector MLPs, much like related theoretical work in SSL (Tian et al., 2021; Wang et al., 2021; Jing et al., 2021).",0.5,Weak
"Moreover, Wei et al. (2020) and Tian et al. (2021) studied the theoretical properties of self-training and the contrastive learning without the negative pairs respectively.",0.0,Neutral
[41] conducted a theoretical analysis on why the non-contrastive methods work well.,0.0,Neutral
"We further note that the InfoMax interpretation of these objectives may not be consistent with its behavior in practice [45] and many recent studies provide theoretical understanding behind their success [46, 47].",0.0,Neutral
"Several different perspectives have recently been used to successfully analyze SSL’s behavior, including learning theory [15, 14, 34], causality [18, 17], information theory [27], and dynamical systems [35].",0.0,Neutral
"[35] Yuandong Tian, Xinlei Chen, and Surya Ganguli.",0.0,Neutral
"Several different perspectives have recently been used to successfully analyze SSL’s behavior, including learning theory [14, 15, 35], causality [17, 18], information theory [27], and dynamical systems [36].",0.0,Neutral
[254] studied the nonlinear learning dynamics of uncollated SSL in a simple linear network where SSL with only positive pairs avoids expression decay.,0.0,Neutral
"Following [44], we assume that ∂qMi ∂z is positive definite.",0.5,Weak
"In practice, however, SSL training often experiences the failure mode of dimensional collapse (Jing et al., 2021; Tian et al., 2021; Pokle et al., 2022), where the learned representation spans a low dimensional subspace of the overall available space.",0.0,Neutral
"In contrast, we interpret the information loss in the context of identifiability for CL [22], learning dynamics [1, 17, 11, 18], and the content-style partitioning of latent factors [19].",0.0,Neutral
"1, 2 [18] Yuandong Tian, Xinlei Chen, and Surya Ganguli.",0.0,Neutral
"Currently, most works focus on linear variants of deep models [19; 2; 22; 21; 32; 33].",0.0,Neutral
"[32] Yuandong Tian, Xinlei Chen, and Surya Ganguli.",0.0,Neutral
The terms in Equation 1 can be decomposed using a variance-covariance perspective [23].,0.0,Neutral
"Note that optimizingLview(Θ) alone without stopping gradient results in a degenerated solution (Chen & He, 2021; Tian et al., 2021).",0.0,Neutral
", commission fee [105], surge pricing rate [106], incentive threshold [107], working speed [108]) and run the allocation engine to simulate What If the parameters were different (5a), or request recommendations of fairer settings (5b).",0.0,Neutral
"In the context of mobility on demand, [6] proposes a deep-learning approach to operate a system that considers its equity impacts, while [7] points to similar profit for every driver and also similar rejection rates at every zone (as we do), but using a method that deals only with hundreds of users and tens of zones.",0.0,Neutral
[51]’s approaches to eliminate inequity while increasing utility might help ridehailing providers design a more equitable price discrimination algorithm.,0.0,Neutral
[51] studied the impact of rider-driver matching policy and redistributing income to reduce forms of inequality,0.0,Neutral
"We examine two different categories of related work in the space of algorithmic bias: research examining bias specifically in ridehailing and taxi service pickup rates [12, 31, 32], and research detailing how to ensure the fairness of supervised learning models [24, 28, 29, 51, 69].",0.5,Weak
"ur work does not rely on a user study, and unlike both Ge et al. [32] and Brown [12], our work is the first to provide an analysis on ridehailing trip fare pricing rather than frequency. Raman et al. [51] studied the impact of rider-driver matching policy and redistributing income to reduce forms of inequality in ridehailing. The analysis revealed that policies minimizing the variance of income also m",0.0,Neutral
"ace of algorithmic bias: research examining bias specifically in ridehailing and taxi service pickup rates [12, 31, 32], and research detailing how to ensure the fairness of supervised learning models[24,28,29,51,69].WealsoexaminetwopapersontheuseofACS demographic data rather than individual demographic attributes to make inferences about an individual [33, 55]. Dillahunt et al. [27] recruited 13 low-income indiv",0.0,Neutral
"ocation on supply, transit geography, and economic geography of the cities in which they operate when designing fare pricing algorithms. Moreover, measuring bias, simulating fairness, or Raman et al. [51]’s approaches to eliminate inequity while increasing utility might help ridehailing providers design a more equitable price discrimination algorithm. To extend this analysis, obtaining the supply allo",0.0,Neutral
This leads directly to the next thrust of research: Is there a way to select actions that improve long-term fairness? Existing work [6] tries to add variance as a cost to the optimization objective in the ridesharing context.,0.0,Neutral
"systems, formulating the TNDP as a Deep Reinforcement Learning (Deep RL) problem can inspire new solutions that enable nonmyopic long-term decisions, as noted in recent work [5, 17].",0.0,Neutral
"[19], which looks at disparate treatment of passengers and income disparity amongst drivers.",0.0,Neutral
"[19] as a baseline for fairness, using their passenger-side fairness implementation, which we call FairNN.",0.5,Weak
Recent work [19] aims to maximize the minimum service rate by including variance in service rates across different zones in the,0.0,Neutral
"Similarly, the SOS bias scores measured using the NCSP metric in the inspected static word embeddings, are limited to the used word lists, and even if I use two different swear word lists and identity terms that are coherent according to (Antoniak and Mimno, 2021), using other word lists may give different results.",0.0,Neutral
"This lack of positive correlation could be due to limitations in the used metrics to measure social bias in static word embeddings (Antoniak and Mimno, 2021).",0.0,Neutral
"of target sets and attribute words are modified (Du et al., 2021; Antoniak and Mimno, 2021).",0.0,Neutral
"Additionally, it has been shown that distance-based metrics can change considerably with different initialization (Antoniak and Mimno, 2021).",0.0,Neutral
"This is prone to instability and data quality issues (Antoniak and Mimno, 2021; Blodgett et al., 2021) and difficult to adapt across languages.",0.0,Neutral
"In this work, we define social bias as the unbalanced disposition (or prejudice) in favor of or against a thing, person or group, relative to another, in a way that is deemed as unfair (Adewumi et al., 2019; Antoniak and Mimno, 2021; Maddox, 2004).",0.0,Neutral
"The lexica are adapted from public sources(4) and may be expanded as the need arises, given that bias terms and attitudes are ever evolving (Antoniak and Mimno, 2021; Haemmerlie and Montgomery, 1991).",0.0,Neutral
"specific choices of templates, prompts, lexicon seeds, metrics, sampling strategies is also a concern (Akyürek et al., 2022; Antoniak and Mimno, 2021; Delobelle et al., 2021).",0.0,Neutral
"The lack of robustness of the proposed metrics w.r.t. specific choices of templates, prompts, lexicon seeds, metrics, sampling strategies is also a concern (Akyürek et al., 2022; Antoniak and Mimno, 2021; Delobelle et al., 2021).",0.0,Neutral
"Biased opinions arise from differing attitudes toward different groups, and in the biased expression, dominant and marginalized groups are usually assigned different attribute tags [5, 11, 18].",0.0,Neutral
"Aside from exploring at the linguistic level [5, 18, 93, 94], some works investigate stereotypes and biases against different groups based on supervised datasets related to gender, race, religion, and immigrants [11, 120], aiming to develop more robust detectors and fairer generation models.",0.0,Neutral
"to scrutiny: measures have been shown to be brittle (Ethayarajh et al., 2019; Nissim et al., 2020; Antoniak and Mimno, 2021; Delobelle et al., 2022), contradictory (Bommasani et al.",0.0,Neutral
"In particular, several works (Ethayarajh et al., 2019; Nissim et al., 2020; Antoniak and Mimno, 2021) shows prior bias measures are highly sensitive to word list perturbations.",0.0,Neutral
"Last, the majority of debiasing methods ground the bias by word list; different lists can lead to different debias performance (Antoniak and Mimno, 2021).",0.0,Neutral
", 2020a), as well as assessing the reliability of the tests (Gonen and Goldberg, 2019; Ethayarajh et al., 2019; Antoniak and Mimno, 2021; Delobelle et al., 2021; Blodgett et al., 2021).",0.0,Neutral
This directly addresses concerns related to using predetermined keywords without ensuring their concurrent relevance to each other within a localized data set [5].,0.0,Neutral
"Relying on single-word poles for axes can be unstable to the choice of each word (An et al., 2018; Antoniak and Mimno, 2021).",0.0,Neutral
"Antoniak and Mimno [2021] compile a comprehensive set of seed lexicons used to measure bias from prior work, and demonstrate that bias measurements tend to be unstable and highly dependent on the seed set in use.",0.0,Neutral
"Antoniak and Mimno [2021] compile a comprehensive set of seed lexicons used to measure bias from prior work, and demonstrate that bias measurements tend to be unstable and highly dependent on the seed set in use. Orgad and Belinkov [2022] highlight that the degree of balancing in test data and choice of metric to measure bias can also lead to different bias conclusions.",0.0,Neutral
"These words have a crucial impact on how and which biases
are detected and mitigated, but they are not central in the efforts devoted to this task, as argued in Antoniak and Mimno (2021).",0.0,Neutral
"We give concrete examples in Appendix A.
Antoniak and Mimno (2021) argues that the most important variable when exploring biases in word embeddings are not the automatizable parts of the problem but the manual part, that is the word lists used for modelling the type of bias to be explored and the…",0.0,Neutral
"They can also
help to understand the implications of using historical datasets to train models that will be used to predict data that is markedly different from the training data (Antoniak and Mimno, 2021).",0.0,Neutral
"Also aligned with the rest of the NLP area, work has been focused on the technical nuances instead of the more impacting qualitative aspects, like who develops the word list used for bias measurement and evaluation techniques (Antoniak and Mimno, 2021).",0.0,Neutral
"with the rest of the NLP area, work has been focused on the technical nuances instead of the more impacting qualitative aspects, like who develops the word list used for bias measurement and evaluation techniques (Antoniak and Mimno, 2021).",0.0,Neutral
"…aforementioned gap information and convinced that the origins and rationale underlying the lists’ selection must be explicit, tested, and documented, Antoniak and Mimno (2021) proposed a systematic framework that enables the analysis of the sources of information and the characteristics of the…",0.0,Neutral
"We develop on the insights of Antoniak and Mimno (2021) by facilitating access to these technologies to domain experts with no technical expertise, so that they can provide well-founded word lists, by pouring their knowledge into those lists.",0.5,Weak
"They can also help to understand the implications of using historical datasets to train models that will be used to predict data that is markedly different from the training data (Antoniak and Mimno, 2021).",0.0,Neutral
"For this, we reproduced an experiment by Antoniak and Mimno [1] ranking the cosine similarity between the first Principal Component (PC) of the bias subspace and all words in the corpus.",1.0,Strong
Our second contribution is an augmentation of the seed dataset provided by Antoniak and Mimno [1].,0.5,Weak
"In addition to the original paper, Antoniak and Mimno [1] published a Github repository that contained a JSON with the metadata on seed sets gathered from prior works4.",0.5,Weak
"The selection of seed terms varies considerably across the literature, and seed sets themselves may exhibit social and cognitive biases [1].",0.0,Neutral
"We seek to replicate the Antoniak and Mimno [1] paper, hereafter referred to as ”the original paper/work”.",1.0,Strong
Another source of instability claimed by Antoniak and Mimno [1] is the ordering and pairing of seed sets.,0.0,Neutral
"Furthermore, looking at the official dataset statistics, for example for WikiText [7], it is clear that our reproduced vocabulary size is a lot closer to the ground truth than the one by Antoniak and Mimno [1].",0.5,Weak
"This reproducibility study focuses on Antoniak and Mimno [1]’s main claim that the rationale for the construction of these lexicons needs thorough checking before usage, as the seeds used for bias measurement can themselves exhibit biases.",1.0,Strong
"Finally, the process of assembling word lists itself can be tricky, as seed lexica often have several practical (Antoniak and Mimno, 2021) and conceptual (Dinan et al.",0.0,Neutral
"Along099 this line, focus has been given to bias analysis in100 models’ innards and ouputs (Vig et al., 2020; Costa-101 jussà et al., 2020b), and to ascertain the validity of102 bias measurament practices (Blodgett et al., 2021;103 Antoniak and Mimno, 2021; Goldfarb-Tarrant et al.,104 2021).",0.0,Neutral
", 2022), and to ascertain the validity of bias measurement practices (Blodgett et al., 2021; Antoniak and Mimno, 2021; Goldfarb-Tarrant et al., 2021).",0.0,Neutral
"Recent works investigating bias in language models have found issues with inconsistencies between seed words (Antoniak and Mimno, 2021),",0.0,Neutral
"Furthermore, we acknowledge that our analysis of gender associated biases is limited to binary gender and our intrinsic evaluations require discrete categorizations (Dev et al., 2021b; Antoniak and Mimno, 2021).",0.0,Neutral
"Keyword-based approaches are appropriate in some cases — for example, when counterfactuals can be obtained by making local substitutions of closed-class words like pronouns — but they cannot guarantee fluency or coverage of all labels and covariates of interest (Antoniak and Mimno, 2021), and are difficult to generalize across languages.",0.0,Neutral
"However, our tool can assist in selecting the most relevant group words by facilitating comparison against a set of alternatives (as recommended in [2]).",0.0,Neutral
The user is advised to examine the default set of group words and update them via the visual interface as required [2].,0.0,Neutral
"Test (WEAT) [13], would require more heuristic choices, as they have been found to be highly dependent on the initial selection of seed words [2].",0.0,Neutral
", 2020; Bird, 2020), rigorous and meaningful evaluation (Caglayan et al., 2020; Ethayarajh and Jurafsky, 2020; Antoniak and Mimno, 2021; Tan et al., 2021), environmental impact (Strubell et al.",0.0,Neutral
"Norms around different intersectional identities guide how algorithms on these systems perceive individuals’ digital identities and influence the creation of datasets that are often used to make decisions (CheneyLippold, 2017; Das et al., 2022; Antoniak and Mimno, 2021).",0.0,Neutral
"Prior research has highlighted that selecting these lexical seeds or keywords can implicitly introduce researchers’ biases in an artifact (Das et al., 2022; Antoniak and Mimno, 2021).",0.0,Neutral
"These resources have a crucial impact on how and which biases are detected and mitigated (Antoniak and Mimno, 2021), but they are not central in the efforts devoted to this task.",0.0,Neutral
"Instead, we believe what can most contribute to an effective assessment of bias in NLP is precisely the linguistic characterization of the discrimination phenomena (Antoniak and Mimno, 2021).",0.0,Neutral
"Proper validation is not consistent even in NLP research using lexicon-based methods (Antoniak and Mimno, 2021).",0.0,Neutral
"These studies have used seed words from the literature for their tests without mitigating for their limitations as specified by (Antoniak and Mimno, 2021).",0.0,Neutral
"The motivation behind using NOI words is clearer than using seed words used in the literature (Antoniak and Mimno, 2021).",0.0,Neutral
"These metrics also use lists of seed words that are unreliable as explained by (Antoniak and Mimno, 2021).",0.0,Neutral
"Moreover, According to the reported coherence scores in (Antoniak and Mimno, 2021), The used NOI words for women, men, white and non-white ethnicity groups, score the highest coherence which are 0.",0.0,Neutral
"In addition to 74 the original paper, Antoniak and Mimno [1] published a Github repository that contained a JSON with the metadata on 75 seed sets gathered from prior works 2.",0.5,Weak
"Furthermore, 98 looking at the official dataset statistics, for example for WikiText [7], it is clear that our reproduced vocabulary size is a 99 lot closer to the ground truth than the one by Antoniak and Mimno [1].",1.0,Strong
"The selection of seed terms varies considerably across the literature, 38 and seed sets themselves may exhibit social and cognitive biases [1].",0.0,Neutral
Our second contribution is an augmentation of 232 the seed dataset provided by Antoniak and Mimno [1].,0.5,Weak
"For this, we reproduced an experiment by Antoniak and Mimno [1] ranking the cosine similarity between 155",1.0,Strong
"We seek to replicate the Antoniak and Mimno [1] paper, hereafter referred to as ”the original paper/work”.",1.0,Strong
Another source of instability claimed by Antoniak and Mimno [1] is the ordering and pairing of seed sets.,0.0,Neutral
"This reproducibility study focuses on 4 Antoniak and Mimno [1]’s main claim that the rationale for the construction of these lexicons needs thorough checking 5 before usage, as the seeds used for bias measurement can themselves exhibit biases.",1.0,Strong
"Antoniak and Mimno (2021) argues that the most important variable when exploring biases in word embeddings are not the automatizable parts of the problem but the manual part, that is the word lists used for modelling the type of bias to be explored and the list of words that should be neutral.",0.0,Neutral
"These words have a crucial impact on how and which biases are detected and mitigated, but they are not central in the efforts devoted to this task, as argued in (Antoniak and Mimno, 2021).",0.0,Neutral
"We develop on the insights of Antoniak and Mimno (2021) by facilitating access to these technologies to domain experts with no technical expertise, so that they can provide well-founded word lists, by pouring their knowledge into those lists.",0.5,Weak
"Also aligned with the rest of the NLP area, work has been focused on the technical nuances instead of the more impacting qualitative aspects, like who develops the word list used for bias measurement and evaluation techniques (Antoniak and Mimno, 2021).",0.0,Neutral
"These can be general decisions involving prompting or decoding hyperparameters, or they can be bias-specific considerations such as the choice of words used to identify groups [2] or the specific mathematical form of the metrics you compute [16].",0.0,Neutral
"Recent works investigating bias in language models have found issues with inconsistencies between seed words (Antoniak and Mimno, 2021), unvoiced assumptions and data quality issues in StereoSet and CrowS-Pairs templates (Blodgett et al.",0.0,Neutral
"Although paired seed words like “man-woman” and “he-she” are suitable to capture a male-female component [AM21], they might transport unwanted correlations (e.",0.0,Neutral
"These metrics also use lists of seed words that have been shown to be unreliable (Antoniak and Mimno, 2021).",0.0,Neutral
"Similarly, our SOS bias scores are limited to the used word lists and even if we used two different swear word lists and identity terms that are coherent according to (Antoniak and Mimno, 2021), using different word lists may give different results.",0.0,Neutral
"by word list; different lists can lead to different debias performance (Antoniak and Mimno, 2021).",0.0,Neutral
(2019) and Antoniak and Mimno (2021). We focused on these seed words as they were successfully used in prior work on extracting associations from word embedding models; we plan to create our own seed words in future work.,0.0,Neutral
", 2020; Bird, 2020), rigorous and meaningful evaluation (Caglayan et al., 2020; Ethayarajh and Jurafsky, 2020; Antoniak and Mimno, 2021; Tan et al., 2021), environmental impact (Strubell et al.",0.0,Neutral
"Although machine learning approaches have been proposed for many types of inverse problems [1, 2, 3, 4], most of them make prior assumptions on the specific form of the underlying partial differential equation (PDE) and use discretization i.",0.0,Neutral
"A similar application is a correction term within a fixed-point iterator, as outlined in [439].",0.0,Neutral
"Other PDE modeling approaches include accurate neural PDE solvers [40, 8, 70] or other improved PINN variants such as competitive PINNs [97] and robust PINNs [3].",0.0,Neutral
"Other approaches of ML-based PDE solvers include the physics informed neural networks (PINNs) which utilize the physics-informed loss [40, 50, 51, 60, 61], neural operators [5, 29, 33, 34, 38, 57] , and autoregressive methods [3, 6, 14, 23, 26] , etc.",0.0,Neutral
", [33] – they lack convergence guarantees and predictive uncertainty modeling, i.",0.0,Neutral
"[33] Jun-Ting Hsieh, Shengjia Zhao, Stephan Eismann, Lucia Mirabella, and Stefano Ermon.",0.0,Neutral
"Recent approaches can be broadly classified into three categories: (i) neural approaches that approximate the solution function of the underlying PDE [24, 66]; (ii) hybrid approaches, where neural networks either augment numerical solvers or replace parts of them [1, 2, 18, 33, 43, 79]; (iii) neural approaches in which the learned evolution operator maps the current state to a future state of the system [4, 7, 9, 21, 49, 54, 68, 87].",0.0,Neutral
"Also, one can consider optimization problems or solving ordinary or partial diferential equations using numerical methods, which are frequently used in the computational and physical sciences [9, 20, 25, 32, 40, 49, 72, 73, 75, 77, 83, 86, 103, 114, 116, 117, 129, 132, 144].",0.0,Neutral
"Often, these approaches speed up classical methods [68, 30, 2], augment weaknesses in end-to-end deep learning solvers [41], or provide guarantees that deep networks by themselves, do not [29, 10].",0.0,Neutral
"On the other hand, works like [29, 46, 53] apply neural networks iteratively multiple times, improving the obtained approximation of the solution each time.",0.0,Neutral
"As an alternative to MLPs and PINNs, convolutional neural networks (CNNs) have also been used to solve PDEs, either as independent solvers [12, 13], or as part of fluid solvers, such as to perform pressure projection of incompressible fluid flows [14, 15], to model acoustic wave propagation [16], or to solve the Poisson equation for plasma fluid flows [17].",0.0,Neutral
"In [10], iterative solvers for elliptic problems were learned using neural networks, but these were built upon existing solvers in order to guarantee high order convergence.",0.0,Neutral
"While some approaches use deep learning to accelerate traditional CFD solvers (Hsieh et al., 2019; Kochkov et al., 2021a), a certain body of research treats the flow problems as problems defined over a cartesian grid or an irregular mesh and uses techniques involving convolutional or graph neural operators to predict the flow fields (Hennigh, 2017; Jiang et al.",0.0,Neutral
"While some approaches use deep learning to accelerate traditional CFD solvers (Hsieh et al., 2019; Kochkov et al., 2021a), a certain body of research treats the flow problems as problems defined over a cartesian grid or an irregular mesh and uses techniques involving convolutional or graph neural…",0.0,Neutral
"Sec-
ond, the local differential operators that span this functional space can be treated as numerically employing convolution kernels (Hsieh et al., 2018; Lin et al., 2013).",0.0,Neutral
"Second, the local differential operators that span this functional space can be treated as numerically employing convolution kernels (Hsieh et al., 2018; Lin et al., 2013).",0.0,Neutral
"Another different approach known as autoregressive methods was developed in [1, 5, 15, 17], where the PDEs are simulated iteratively, resembling conventional numerical methods with time marching.",0.0,Neutral
"There are researches about the so-called neural augmentation where a neural component is added to finite elements [11], multigrid solvers [10], and eikonal solvers [19].",0.0,Neutral
"This differs from other learned PDE solvers and surrogate models, which are almost always trained for a single mesh or geometry and cannot be used when the geometry varies [11, 12, 14, 26].",0.0,Neutral
"PDEs are a fundamental modeling techniques, and designing neural networks-aided solvers, particularly in high-dimensions, is of widespread usage in many scientific domains (Hsieh et al., 2019; Brandstetter et al., 2022).",0.0,Neutral
[10] utilized a convolutional neural network (CNN) to accelerate the convergence of Jacobi method.,0.0,Neutral
"Various works are numerical-neural hybrid approaches where the computation graph of the solver is preserved and heuristically-chosen parameters are left for the neural network to predict (Bar-Sinai et al., 2019; Kochkov et al., 2021; Greenfeld et al., 2019; Hsieh et al., 2019; Praditia et al., 2021; Um et al., 2020; Garcia Satorras et al., 2019).",0.0,Neutral
[29] proposed to use neural networks to modify acobi-style iterative solvers.,0.0,Neutral
"[29] Hsieh JT, Zhao S, Eismann S, Mirabella L, Ermon S.",0.0,Neutral
"Application IV: Physics-Informed Neural Network As a differentiation modality, HoD-Net is also useful for solving neural PDEs problems (Hsieh et al. 2019; Yang, Meng, and Karniadakis 2021) a.",0.0,Neutral
"Application IV: Physics-Informed Neural Network As a differentiation modality, HoD-Net is also useful for solving neural PDEs problems (Hsieh et al. 2019; Yang, Meng, and Karniadakis 2021) a.k.a. physics-informed neural networks (PINNs).",0.0,Neutral
"…or enhancing conventional ones in many cases [Guo et al., 2016, Zhu and Zabaras, 2018, Sirignano and Spiliopoulos, 2018, Han et al., 2018, Hsieh et al., 2019, Raissi et al., 2019, Bhatnagar et al., 2019, Bar-Sinai et al., 2019, Berner et al., 2020, Li et al., 2020a,c,b, Um et al., 2020,…",0.0,Neutral
"A common and straightforward approach is to follow an Encoder-Process-Decoder (EPD) scheme to map the input solution at time t to the solution at next time step [7, 27, 57, 60, 64, 70].",0.0,Neutral
", 2019), or aimed at correcting iterative solvers (Hsieh et al., 2019).",0.0,Neutral
"Other research focused on efficient simulations by learning conservation laws (Cranmer et al., 2020; Greydanus et al., 2019), or aimed at correcting iterative solvers (Hsieh et al., 2019).",0.0,Neutral
"Three important works in this area are Bar-Sinai et al. (2019), Greenfeld et al. (2019), and Hsieh et al. (2019).",0.0,Neutral
"Hsieh et al. (2019) even have convergence guarantees for their method, something rare in deep learning.",0.0,Neutral
"The literature also includes studies focused on applying deep learning techniques in multigrid and numerical PDEs [25, 20].",0.0,Neutral
"Using, for example, the special activation function σ(x) = ReLU(x) := max{0, x} ≥ 0, the above iterative process can be naturally modified to preserve the constraint (1.2):
ui = ui−1 + σ ◦Bi ∗ σ(f − A ∗ ui−1), i = 1 : ν. (1.4)
This forms the basic block of MgNet, precisely as in [15]. partial differential equations (PDEs) [52, 53], we introduce this residual
ri = f − A ∗ ui.",0.0,Neutral
"The literature also includes studies focused on applying deep learning techniques in multigrid and numerical PDEs [19, 16].",0.0,Neutral
"Although much recent effort has been dedicated to investigating the PINN framework for solving PDEs, other neural PDE solution techniques exist, notably techniques which learn iterators that are not solutions to PDEs themselves but rather provide a method of quickly computing such solutions [21].",0.0,Neutral
"The first category is using deep neural network to improve classical numerical methods, see for example [45,47,24,20].",0.0,Neutral
"Because of its multi-scale architecture, the U-Net is widely used in many problems in scientific computing, such as Navier–Stokes simulations [42], and PDE-solvers [15, 44].",0.0,Neutral
"[82], where an iterative solver is coupled to a deep linear network to guarantee the accuracy level of the network prediction.",0.0,Neutral
[19] aims to improve an existing solver through the supplemental application of a neural network.,0.0,Neutral
"A different direction within the optimization of multigrid methods, which has recently become popular, is applying machine learning to improve the individual solver components, such as [15, 19, 20, 22].",0.0,Neutral
"The first category is using deep neural network to improve classical numerical methods, see for example [40, 42, 21, 15].",0.0,Neutral
This is an attempt to reproduce results from [17].,1.0,Strong
The other multilevel solver that we tried is a U-Net from [17].,0.0,Neutral
"As we pointed in Section VI, we cannot be sure that we reproduce results from [17] because the paper contains omissions.",-1.0,P-NR
"Given that, the whole scheme from [17] is a generalized Richardson iteration for the preconditioned system.",0.0,Neutral
Neural network of [48] is applied to speed up iterative solver for elliptic type PDEs.,0.0,Neutral
"Hybrid approaches combine an existing iterative method with a feed-forward network to compute the properties of the target system accurately while enhancing the convergence property and the solution quality of the existing method [18, 19, 32].",0.0,Neutral
[24] trained a convolutional network to improve a GMG algorithm for the structured Poisson problem.,0.0,Neutral
[34] used the NN for learning PDE solvers with convergence guarantees.,0.0,Neutral
"Another example from scientific computing is [26], which deals with solving partial differential equations.",0.0,Neutral
"An orthogonal line of work use neural networks as powerful function approximators in existing numerical PDE and linear system solvers to achieve faster convergence, generalize to different boundary conditions or larger problems, and approximate underresolved features in coarse-grained simulations (Hsieh et al., 2018; Luz et al., 2020; Bar-Sinai et al., 2019).",0.0,Neutral
"As suggested in [Hsieh et al., 2019], we also choose different iteration number k, 1 ≤ k ≤ b in the training, so that H learns to converge at each iteration, where larger b mimics the behavior of solving problems to higher accuracy while smaller b mimics inexpensive smoothing steps in multigrid.",0.0,Neutral
"Consequently, it is deeply unavoidable to find a numerical solution to the PDEs, which has always been a research hotspot by the researchers over the past few decades [9-13].",0.0,Neutral
2 learning tools in designing data-driven methods for solving PDEs with the improvement of the computing performance of computers [9-13].,0.0,Neutral
"The Poisson equation serves as an example problem in the recent literature; see [32, 11, 34].",0.0,Neutral
"A fast, iterative PDE-solver was proposed by learning to modify each iteration of the existing solver [11].",0.0,Neutral
"Instead of emulating the analog computing blocks, neural networks are used to find specific hyper-parameters of them or analog circuit system such as the arrangement of units or blocks [8], layout [9], and non-linear factor of crossbar arrays [2].",0.0,Neutral
"As neural networks have the ability to find solutions of specific partial or ordinary differential equations [15, 9], we use FCNN or Neural ODE [18] as circuit equation solvers.",0.0,Neutral
"As deep neural networks (DNNs) have the ability to solve ordinary or partial differential equations [15, 9], DNNs are used as a model to emulate the circuit behavior which can be represented by differential equations [16, 5].",0.0,Neutral
"In addition, supervised learning has also been used to guide the discretization process in a data-driven way [3] or to learn efficient iterative solvers [13].",0.0,Neutral
"Learnable surrogates were proposed for various scientific computing tasks in the natural sciences by exploiting fully-connected [18]–[20], convolutional [21]– [23], and hybrid [24]–[26] neural architectures.",0.0,Neutral
"Inspired by the recently proposed deep PDE solver [2], we introduce a deep learning-based thickness solver.",0.5,Weak
"The thickness estimation problem is more challenging than [2], since additional procedures are involved, such as integrating lines and interpolating missing values (refer to section 2.",0.0,Neutral
"Prior work has shown that neural networks can learn how to solve NP-complete decision problems and optimization problems [43, 39, 23].",0.0,Neutral
Existing studies have also identified discontinuities in finite-difference solutions with deep learning [46] and focused on improving the iterative behavior of linear solvers [24].,0.0,Neutral
[17] aims to improve an existing solver through the supplementary application of a neural network.,0.0,Neutral
"A different direction within the optimization of multigrid methods, that has recently become popular, is the application of machine learning to improve the individual components of a solver, such as [12, 17, 18].",0.0,Neutral
The authors in [12] modified existing iterative PDEs solvers with a deep neural network in order to accelerate their convergence speed.,0.0,Neutral
"ML techniques have been used to effectively solve differential equations [5], [12], [21], [22], and [27] but also to discover underlying dynamics from data [2], [20] and [23] and even to build robust neural networks architectures based on differential equations [3], [17] and [25] .",0.0,Neutral
"Recently, machine-learning based models have been developed to either learn new discretization schemes from solution data [11, 12] or to mimic these schemes through novelties in neural network architectures [13, 14].",0.0,Neutral
"The second approach does not directly seek to find the parametric map from X to Y but rather is thought of, for fixed x ∈ X , as being a parametrization of the solution y ∈ Y by means of a deep neural network [19, 20, 29, 32, 44, 50].",0.0,Neutral
"Another notable related paper is Hsieh et al. (2019), which uses a convolutional network to improve on an existing linear iterative solver.",0.0,Neutral
"Another notable related paper is Hsieh et al. (2019), which uses a convolutional network to improve on an existing linear iterative solver. In particular, learning is applied to improve a GMG algorithm for structured Poisson problems in an end-to-end manner, by using a U-Net architecture with several downsampling and upsampling layers, and learning from supervised data. Schmitt et al. (2019) use evolutionary methods to optimize a GMG solver.",0.0,Neutral
"Another notable related paper is Hsieh et al. (2019), which uses a convolutional network to improve on an existing linear iterative solver. In particular, learning is applied to improve a GMG algorithm for structured Poisson problems in an end-to-end manner, by using a U-Net architecture with several downsampling and upsampling layers, and learning from supervised data. Schmitt et al. (2019) use evolutionary methods to optimize a GMG solver. Katrutsa et al. (2017) optimize restriction and prolongation operators for GMG, by formulating the entire two-grid algorithm as a deep neural network, and approximately minimizing the spectral radius of the resulting iteration matrix. They evaluate their method on single instances of various structured-grid differential equations in 1D. Sun et al. (2003) use a tailored network with a single hidden layer to solve the Poisson equation on a specific mesh.",0.0,Neutral
"Another notable related paper is Hsieh et al. (2019), which uses a convolutional network to improve on an existing linear iterative solver. In particular, learning is applied to improve a GMG algorithm for structured Poisson problems in an end-to-end manner, by using a U-Net architecture with several downsampling and upsampling layers, and learning from supervised data. Schmitt et al. (2019) use evolutionary methods to optimize a GMG solver. Katrutsa et al. (2017) optimize restriction and prolongation operators for GMG, by formulating the entire two-grid algorithm as a deep neural network, and approximately minimizing the spectral radius of the resulting iteration matrix.",0.0,Neutral
"In this regard, Hsieh et al. (2019) and Farimani et al. (2017) have, for example, demonstrated that it is possible to learn a general PDE solver for some simple linear and elliptic PDEs.",0.0,Neutral
Tadmor (2012)).,0.0,Neutral
"Recently, because of the trends for the efficient hardware implementations, neural networks have been increasingly applied in solving PDEs [6, 32, 51, 59, 60, 74, 89, 97, 99, 101, 13, 12, 14, 15, 22, 24, 31, 33, 36, 43, 47, 50, 52, 58, 63, 68, 69, 72, 73, 77, 80, 85, 86, 106, 91, 100, 102, 103, 107, 108, 109, 110] and inverse problems involving PDEs [109, 79, 78, 87, 88, 90, 92, 93, 95, 96, 94, 105, 112, 113].",0.0,Neutral
"Hsieh et al. (Hsieh et al., 2019) attempted to learn domain specific fast PDE solvers by learning how to iteratively improve the solution using a deep neural network, resulting in a 2-3 times speedup compared to state of the art solvers.",0.0,Neutral
"[12] attempted to learn domain-specific fast PDE solvers by learning how to iteratively improve the solution using a deep neural network, resulting in a 2-speedup compared to state-of-the-art solvers.",0.0,Neutral
"raight forward with graph convolution operations. Another approach is to solve the problem inside a larger bounding box and then ﬁlter out the solutions that does not belong to the region of interest [25]. Acknowledgement We would like to thank Dr. Yi Ren for the helpful suggestions in experiments and paper writing, Dr. Yuzhong Chen for proofreading the paper, and Haoyang Wei, Dr. Yang Yu for helping ",0.0,Neutral
"ions: (1) All loading/ response observations are in image form. This assumption makes the use of convolutional neural networks as data-driven model possible. (2) Consider linear physics only. As with [24, 25], we start with simpler linear physics ﬁrst since it is easier to prove the convergence of the proposed algorithm. Future work will extend this framework to non-linear physics and irregular mesh data.",0.0,Neutral
"es inspired by FEA. Parallel works have been done to improve the convergence and accuracy of ﬁnite dierence analysis (FDA) solvers to initial value problems (IVP) through learning the optimum ﬁlters [25], or by building a hybrid model with ODE information hard-coded [44]. It is found that similarities exist between dierent FDA solvers and some neural network structures in [45]. Based on this ﬁnding,",0.0,Neutral
"ve been made to predict physics response or parameters with data driven models [8, 11, 12, 13, 16], and several seminal works have been done to build hybrid learning mechanisms with physics knowledge [14, 25, 41, 42, 43, 44, 45, 46].Early pioneering work has shown that the global or element stiness matrix can be learnt with neural network for simple systems [41].Based on the optimality condition of topology optimization, ecien",0.0,Neutral
"In this context, several works have proposed methods for improving the solution of PDE problems (Long et al., 2018; Bar-Sinai et al., 2019; Hsieh et al., 2019) or used PDE formulations for unsupervised optimization (Raissi et al.",0.0,Neutral
"In this context, several works have proposed methods for improving the solution of PDE problems (Long et al., 2018; Bar-Sinai et al., 2019; Hsieh et al., 2019) or used PDE formulations for unsupervised optimization (Raissi et al., 2018).",0.0,Neutral
"ptimization methods [38, 39, 40, 147] and neural networks[7, 42, 81, 65, 77, 78, 98, 118, 129, 132, 134, 136]. Among these methods, neural networks have become increasingly popular tools to solve PDEs[7, 15, 14, 16, 18, 29, 31, 42, 41, 43, 46, 54, 59, 63, 64, 65, 66, 75, 77, 78, 79, 83, 90, 91, 96, 97, 98, 102, 107, 112, 113, 116, 118, 121, 129, 132, 133, 134, 136, 137, 138, 142, 144, 145, 146]and inverse problems involving PDEs [106, 105, 114, 115, 120, 124, 125, 127, 128, 126, 141, 145, 148, 149]. Their popularity is due to universal approximation theorems that state that neural networks ",0.0,Neutral
Motivated by [6] we construct a neural iterator from a semi-implicit update rule.,0.5,Weak
[6] develop a promising way to learn numerical solver while providing a theoretical convergence guarantee.,0.0,Neutral
"Implementation Details: Following [6], we use a three-layer convolutional neural network to model each of the Hi.",0.5,Weak
"On a stark contrast with previous work [6], we have several sets of parameters {Θi}i=1:N , δx, δt, and attached to the PDEs governing equation.",0.0,Neutral
2 Neural Solver We propose the following iterator using similar notation as in [6],0.5,Weak
"Once the iterative methods are optimized on a set of problems, generalization to different boundary conditions, domain geometries, and other similar models, is explored and can be sometimes guaranteed [23].",0.0,Neutral
"The last group, very different from previous two, adopts NN to optimize traditional iterative methods [14,23,24,35].",0.0,Neutral
", 1998), many suggested to design a network to solve specific PDEs (Hsieh et al., 2019; Baque et al., 2018; Baymani et al., 2010; Berg & Nyström, 2018; Han et al., 2017; 2018; Katrutsa et al., 2017; Mishra, 2018; Sirignano & Spiliopoulos, 2018; Sun et al., 2003; Tang et al., 2017; Wei et al., 2018), generalizing for different choices of right hand sides, boundary conditions, and in some cases to different domain shapes.",0.0,Neutral
"Starting with the classical paper of (Lagaris et al., 1998), many suggested to design a network to solve specific PDEs (Hsieh et al., 2019; Baque et al., 2018; Baymani et al., 2010; Berg & Nyström, 2018; Han et al., 2017; 2018; Katrutsa et al., 2017; Mishra, 2018; Sirignano & Spiliopoulos, 2018;…",0.0,Neutral
"(Hsieh et al., 2019) proposes an elegant learning based approach to accelerate existing iterative solvers, including multigrid solvers.",0.0,Neutral
"ity pattern are trained by minimizing the Frobenius norm of a large power of the multigrid error propagation matrix with a sampling technique similar to that used in machine learning. In Hsieh et al. [16], a linear U-net structure is proposed as a solver for linear PDEs on regular mesh. In this paper, we explore the connection between multigrid and convolutional neural networks, in several directions.",0.0,Neutral
"[21] Hsieh J T, Zhao S, Eismann S, et al.",0.0,Neutral
"We also note that other works where neural networks replace a whole or part of numerical methods [8, 9, 10, 11, 12, 14, 15, 24] can be organized in the same way.",0.0,Neutral
"For example, [10, 11, 20, 21, 22, 23] propose to use predicted solutions by machine learning as initial guesses of subsequent traditional numerical methods, and [24] combines a neural network and an iterative solver to accelerate it while maintaining convergence guarantee.",0.0,Neutral
"The Poisson equation serves as an example problem in the recent literature; see [10, 26, 28].",0.0,Neutral
"[10] Jun-Ting Hsieh, Shengjia Zhao, Stephan Eismann, Lucia Mirabella, and Stefano Ermon, Learning neural PDE solvers with convergence guarantees, arXiv preprint arXiv:1906.",0.0,Neutral
"A fast, iterative PDE-solver was proposed by learning to modify each iteration of the existing solver [10].",0.0,Neutral
"In a recent Stanford study, the authors solved the 2D Poisson equation using a deep neural network and had 2-3 times speedup in comparison to standard iterative solvers [7].",0.0,Neutral
"There are roughly three distinct directions emerging in the literature: (1) discovery of governing equations directly from data [3, 20, 12]; (2) development of augmented numerical methods [2, 21, 7, 15, 18]; (3) surrogate modeling [4, 19, 1, 14, 13, 5].",0.0,Neutral
"The original paper proposes to use machine learning techniques in order to find high performing update rules instead of designing them by hand [1], while still guaranteeing convergence.",0.0,Neutral
A common approach to build T and c is to splitA intoA = M −N and by rewritingAu = f asMu = Nu+f the following updating rule naturally arises: u = M−1Nuk +M−1f For more details we refer readers to [4] or to [1].,0.0,Neutral
For more information we kindly refer to the original paper [1].,0.0,Neutral
"With k ∈ DU(1, 20) we denote the sampling of k from a discrete uniform distribution on the interval [1, 20].",0.0,Neutral
"This is the reason why our work was focused on reproducing the results of [1], and on empirically proving the generalization of their model to arbitrary shapes and grid sizes.",1.0,Strong
"While tables with simple structures and clean backgrounds can be recognized well [6, 12, 14, 15, 23, 24, 30, 35, 38, 41, 47], recognizing complicated table structures remains a challenging problem, which is primarily due to two main difficulties: 1) Firstly, tables in images vary widely in terms of structure and shape.",0.0,Neutral
"Note that, there are fundamental differences between the representation in [8, 20, 36, 38, 46] and ours despite the representation is also termed as ""grid"".",0.0,Neutral
"In the works of [8, 20, 27, 36, 38, 46], a table is depicted as a grid of regions.",0.0,Neutral
"For instance, region-based methods [8, 20, 36, 38, 46] employ a split model to divide input table images into a grid of regions, and a merge model to combine over-split spanning cells.",0.0,Neutral
"Early works [37, 34] directly use visual features encoded by convolutional neural networks (CNN) [19] for layout units detection [36, 30, 35, 17], and have been proven to be effective.",0.0,Neutral
"Recent deep learning works [37, 34] consider DLA as a classic visual object detection or segmentation problem and utilize convolutional neural networks (CNN) [19] to solve this task [36, 30, 35, 17].",0.0,Neutral
"for tables [21,20,4,27] or structured diagrams [12,16,31,8].",0.0,Neutral
"former takes the document as an image input and frames entity detection as object detection or instance segmentation [40, 31].",0.0,Neutral
"For example, Sebastian Schreiber in 2017 [15] presented a deep learning-based solution called DeepDeSRT for table detection in document images and table structure recognition, using the concept of transfer learning and domain adaptation from a pre-trained model of Faster R-CNN [16].",0.0,Neutral
"Subsequent research introduced end-to-end deep learning systems capable of not only detecting tables but also recognising their structure in document images, without the need for metadata or heuristics [23].",0.0,Neutral
"The experimental results of CascadeTabNet [4], TableDet [3], DeCNT [36], YOLOv3TD [33], DeepDeSRT [35], TableNet [45], GAN-TD [46], TableRadar [43] and NLPR-PAL [43] in Table 2, 3 and 4 are from study [3].",0.0,Neutral
"There are many other studies discussing the TD problem, including DeepDeSRT [35], TableDet [3] and many others [36, 37] .",0.0,Neutral
"In order to provide a new state-of-the-art benchmark for table detection and table structure recognition, DeepDeSRT [40] utilizes a novel image transformation strategy to identify the visual features of the table structures and feed them into a fully convolution network with skip pooling.",0.0,Neutral
"On the other hand, the problem of table structure recognition (TSR) is a lot more challenging and remains a very active area of research, in which many novel machine learning algorithms are being explored [3,4,5,9,11,12,13,14,17,18,21,22].",0.0,Neutral
"Object-detection based methods [11,12,13,14,21] rely on tablestructure annotation using (overlapping) bounding boxes for training, and produce bounding-box predictions to define table cells, rows, and columns on a table image.",0.0,Neutral
"Deep learning approaches [16,17,18] do not rely on rules and can accurately generalize the problem.",0.0,Neutral
"Later, more efficient single-stage object detectors like RetinaNet [58] and YOLO [59] and two-stage object detectors like Fast R-CNN [11], Faster R-CNN [12], Mask R-CNN [60], and Cascade Mask R-CNN [61] were applied for other document objects such as figures and formulas detection in document images [62,63,64,65,66,67,68,16,17,18].",0.0,Neutral
"Recently, researchers employed statistical methods [28] and deep learning approaches to make the table detection systems more generalizable [16,29,30,31].",0.0,Neutral
"There are also many other studies discussing the TD problem, such as TableDet [7], DeCNT [32], DeepDeSRT [33], TableNet [34], and most of these studies follow the object detection formulation and utilize different types of object detection models that are mentioned above.",0.0,Neutral
"Since the advent of deep learning and CNN-based approaches [53,55], the segmentation of document layouts has been reformulated as DOD.",0.0,Neutral
"Researchers in [37,41,40] have proposed to detect row/column regions based on segmentation and off-the-shelf object detectors.",0.0,Neutral
"For example, Faster R-CNN was adopted by [37,6,42,36,44], and YOLO was used in [11].",0.0,Neutral
"[7,26] focused on extracting tabular data from documents by combining heuristic rules and convolutional networks to detect and recognize tabular data.",0.0,Neutral
Earlier methods attempted to solve these two tasks separately [15].,0.0,Neutral
[15] 2017 DeepDeSRT ICDAR Marmot Marmot - - NR,0.0,Neutral
DeepDeSRT [1] first applied an FCN-based semantic segmentation method [28] to table structure extraction.,0.0,Neutral
"In view of visual saliency, DeepDeSRT [38] and TableNet [31] are two rep-
resentative works exploiting semantic segmentation to obtain table cell boundaries.",0.0,Neutral
"With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",0.0,Neutral
"In view of visual saliency, DeepDeSRT [38] and TableNet [31] are two rep-",0.0,Neutral
"the filed, which can be mainly categorized into boundary extraction-based methods [38, 31, 15, 41, 25] and element relationship-based methods [23, 4, 34, 36] according to the component type leveraged.",0.0,Neutral
"The first group are the single component-based methods, which rely on either boundary extraction [15, 25, 31, 38, 41] or element relationship [4, 23, 34, 36].",0.0,Neutral
"To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in",0.0,Neutral
"In recent years, inspired by the success of deep learning in various tasks, especially object detection and semantic segmentation, many deep learning-based methods (Raja et al., 2020; Schreiber et al., 2017) have been presented to recognize table structures.",0.0,Neutral
"S. Schreiber et al. (Schreiber et al., 2017) proposed a two-fold system named DeepDeSRT that applies Faster RCNN (Ren et al., 2015) and FCN(Long et al., 2015) for both table detection and row/column segmentation.",0.0,Neutral
"(Schreiber et al., 2017) proposed a two-fold system named DeepDeSRT that applies Faster RCNN (Ren et al.",0.0,Neutral
", 2021), many researchers only focused on the table structure recognition problem (Prasad et al., 2020; Raja et al., 2020; Schreiber et al., 2017).",0.0,Neutral
"(Schreiber et al., 2017) proposed a two-fold system named DeepDeSRT that applies Faster RCNN (Ren et al.",0.0,Neutral
"In recent years, motivated by the success of deep learning, especially in object detection and semantic segmentation, many deep learning-based methods (Prasad et al., 2020; Raja et al., 2020; Schreiber et al., 2017) have been proposed and proven to be powerful models for table structure recognition.",0.0,Neutral
"For example, DeepDeSRT [40] and TableNet [32] adjusted FCN from the semantic segmentation to segment rows and columns.",0.0,Neutral
"Limited by the training datasets [7, 2, 37, 36] used for TSR, most previous works [28, 24, 35, 26] focus on document images that are obtained from digital documents (e.",0.0,Neutral
"Therefore, TSR as a precursor to contextual table understanding will be beneficial in a wide range of applications [27, 26].",0.0,Neutral
"Distinct from previous segmentationbased methods [35, 26, 28, 20] in the “split” stage, we aim to distinguish each table separation line and formulate table separation line detection as an instance segmentation task.",0.0,Neutral
Early works (Schreiber et al. 2017; Siddiqui et al. 2019) introduce segmentation or detection frameworks to locate and extract splitting lines of table rows and columns.,0.0,Neutral
[31] proposed DeepDeSRT that employs the Faster R-CNN model for table row and column detection followed by a semantic segmentation approach for TSR.,0.0,Neutral
DeepDeSRT [18] split the competition dataset into a training set and a test set of just 34 samples.,0.0,Neutral
"These developments have enabled significant advances in deep learning (DL) modeling for TE [18,16,25,21,13,12].",0.0,Neutral
"Several deep learning-based methods and datasets from the literature (TabStructNet [17], TableNet [14], CDeCNet [1], UNLV [19], DeepDeSRT [18], TableBank [11], PubTabNet [23], ICDAR 2013 Table Competition [9], DeepFigures [20], PubLayNet [24]) explore solutions to table detection and table structure recognition tasks.",0.0,Neutral
DeepDeSRT [3] uses the fuzzy cognitive network (FCN) [18] to split the table structure based on semantic segmentation.,0.0,Neutral
"For table region detection, DeepDeSRT [34] built an end-to-end system based on deep learning for table detection in image documents, which can identify the row, column, and cell positions in detected tables without relying on any heuristics or metadata.",0.0,Neutral
[14] brought forward a novel deep learning based solution not only for table detection but also would recognize the structure of the tables as two separate parts for born- digital PDFs and scanned documents.,0.0,Neutral
"In DTE, there are three main cases: TD predicts bounding boxes of table candidates on document images (Shafait and Smith, 2010; Schreiber et al., 2017; Siddiqui et al., 2018; Paliwal et al., 2019; Prasad et al., 2020; Hashmi et al., 2021b; Zheng et al., 2021); TD searches for text lines signaling table candidates in plain-text (Hu et al.",0.0,Neutral
"In this scenario, TSR usually deals with tables which are subareas of document images (Zuyev, 1997; Schreiber et al., 2017; Siddiqui et al., 2019a, 2019b; Zheng et al., 2021; Hashmi et al., 2021c), lines of plain-text (Kieninger, 1998; Ng et al.",0.0,Neutral
"In DTE, there are three main cases: TD predicts bounding boxes of table candidates on document images (Shafait and Smith, 2010; Schreiber et al., 2017; Siddiqui et al., 2018; Paliwal et al., 2019; Prasad et al., 2020; Hashmi et al., 2021b; Zheng et al., 2021); TD searches for text lines signaling…",0.0,Neutral
"In this scenario, TSR usually deals with tables which are subareas of document images (Zuyev, 1997; Schreiber et al., 2017; Siddiqui et al., 2019a, 2019b; Zheng et al., 2021; Hashmi et al., 2021c), lines of plain-text (Kieninger, 1998; Ng et al., 1999; Hu et al., 2000), or text chunks and rulings…",0.0,Neutral
S Schreiber[20] ICDAR2013 Mask R-CNN Precision 97.,0.0,Neutral
"As a result, the network misses out on critical visual cues that may aid in the detection and recognition of tables [20].",0.0,Neutral
"Deep learning models are now widely used in many aspects of computer vision, including general table detection[20, 21, 22, 23, 24].",0.0,Neutral
"S Schreiber[20] transfer learning methods + Faster R-CNN end-to-end strategy for detecting tables and table structures that is straightforward and efficient When compared to other state-of-the-art techniques, it is less accurate.",0.0,Neutral
[20] were the first to perform table detection and structure recognition using Faster RCNN.,0.0,Neutral
S Schreiber[20] ICDAR2013 Fully CNN Precision 95.,0.0,Neutral
Sebastian Schreiber et al. [20] were the first to perform table detection and structure recognition using Faster RCNN.,0.0,Neutral
This can further be split into a problem of detecting rows and columns and then combined at a later stage to obtain respective cells [5].,0.0,Neutral
[5] published an in-depth picture-based study program that examined the task of tabular structure extraction.,0.0,Neutral
"DeepDeSRT [11] is a typical top-down approach that uses a segmentation method to segment table columns and table rows directly, which can be implemented by Fully Convolution Networks.",0.0,Neutral
DeepDeSRT [24] is simple and effective end-to-end approach to detect tables but is not as accurate as compared to other state-of-the-art approaches [12].,0.0,Neutral
"The original dataset suffered from incorrect ground truth annotations, hence we list the corrected version of the dataset from [24], which has 1967 images, in Table 2.",0.0,Neutral
[24] also apply Faster R-CNN [13] for detecting tables in scanned document images.,0.0,Neutral
"Similar to previous works [8, 38, 46, 49, 51], the text content and structure information are obtained separately.",0.0,Neutral
"The first group of methods [49, 51, 52] starts by detecting the row and columns of a",0.0,Neutral
"[3] proposed DeepDeSRT, an end-to-end system for table understanding in document images and detecting PDF documents.",0.0,Neutral
"Video Salient Document Detection (VSDD) is an essential task in several real-world applications, such as video document recognition [1], video document compression [2], video document captioning [3] and many more.",0.0,Neutral
"the range of object detection using models like YOLO [32, 38, 47] to, more recently, Faster R-CNN [16, 34, 37, 43, 49] and Mask-CNN [2, 18, 26].",0.0,Neutral
"Methods span
5 makesense.ai 6 http://www.astroexplorer.org/
the range of object detection using models like YOLO [32, 38, 47] to, more recently, Faster R-CNN [16, 34, 37, 43, 49] and Mask-CNN [2, 18, 26].",0.0,Neutral
"Furthermore, table detection and structure recognition is performed with a two-fold deep-learning-based system using Faster R-CNN in [12].",0.0,Neutral
"More recent studies have thus focused mostly on developing deep CNN-based table detection and recognition approaches (see [2, 26, 9, 13, 27, 23] and references therein), leading to significant performance improvements.",0.0,Neutral
"As addressed in Section 3.1, there are lots of state-of-theart methods for table detection, which include but not limited to YOLOv5 [14], DETR-R50 [3], deformable DETR [32], CascadeTabNet [26], DeCNT [28], DeepDeSRT [27], TableNet [23], CDeC-Net [2], and TableRadar [8].",0.0,Neutral
It was shown in [27] how to fine-tune a pre-trained faster R-CNN model.,0.0,Neutral
"1, there are lots of state-of-theart methods for table detection, which include but not limited to YOLOv5 [14], DETR-R50 [3], deformable DETR [32], CascadeTabNet [26], DeCNT [28], DeepDeSRT [27], TableNet [23], CDeC-Net [2], and TableRadar [8].",0.0,Neutral
"Popular table structure recognition methods include DeepDeSRT [7], ReS2Tim [15], DeepTabStR [16], etc.",0.0,Neutral
"Unfortunately, the Component-based approaches such as DeepDeSRT [7], TableNet [8] and LGPMA [9] still suffer from boundary ambiguity problems in unlined tables and cannot achieve decent performance in complex scenarios such as tables with empty cells.",0.0,Neutral
"[17] uses a deep learning-based method to detect tables and identify table structure by detecting rows, columns, and table cells.",0.0,Neutral
"ICDAR2013 UNLV Method Prec Recall F1 Prec Recall F1
TabbyPDF 78.90 84.50 81.60 − − − GraphTSR 81.90 85.50 83.70 − − − DeepDeSRT 57.30 56.40 56.80 − − − CATT-Net 94.10 90.70 92.30 86.28 88.31 87.24 Ours 92.85 93.29 93.04 92.66 86.78 89.52",0.0,Neutral
"For the TSR task, we list TabbyPDF [19], GraphTSR [7], DeepDeSRT [8] and CATT-Net [17] as benchmark models.",0.0,Neutral
"The performance scores of TabbyPDF, GraphTSR, and DeepDeSRT on the ICDAR2013 dataset come from the study [7].",0.0,Neutral
"In contrast, some work, such as DeepDeSRT [8], CascadeTabNet [9] and TableDet [10], using top-down approaches would define the structural recognition as object detection or segmentation problem, often together with table detection problem.",0.0,Neutral
[42] presents a data-driven system and does not need any heuristics or metadata to detect and recognize tabular structures on the ICDAR 2013 dataset [19].,0.0,Neutral
DeepDeSRT [39] first applied an FCN-based semantic segmentation method [25] to table structure extraction.,0.0,Neutral
Faster R-CNN uses an end-to-end region suggestor instead of selective search method to improve training speed [13][19].,0.0,Neutral
"The authors employed, with the model learned features, some heuristic rules and document meta-information to enhance the output result [3][13].",0.0,Neutral
ICDAR2013 Table Competition database [13].,0.0,Neutral
"Moreover, the model is independent to the size of input image [13][19].",0.0,Neutral
Their approach is identified as DeepDeSRT [13].,0.0,Neutral
"For the past decade, table detection, extraction and annotation have been key research areas [17], leading to a variety of extraction approaches [11, 22, 26, 27, 50, 61, 70, 71, 86].",0.0,Neutral
[18] proposed the deep transfer learning-based algorithm DeepDeSRT for table detection and table structure recognition.,0.0,Neutral
"With the surge in deep learning, various CNN based architectures [6, 7, 10, 15,16,18,22] have been proposed for table detection and cell extraction.",0.0,Neutral
"We approach table detection as a general object detection problem, as was done by Schreiber et al. ((Schreiber et al. 2017)), and use a Faster-RCNN model to detect and localize tables in page images (Ren et al. 2015).",0.0,Neutral
"For example, DeepDeSRT is another approach which uses a Fast-RCNN to detect the tables (Schreiber et al. 2017).",0.0,Neutral
"((Schreiber et al. 2017)), and use a Faster-RCNN model to detect and localize tables in page images (Ren et al.",0.0,Neutral
"The table can therefore be represented as a grid [68,78].",0.0,Neutral
DeepDeSRT [41] proposes a novel end-to-end system for table understanding in document images called DeepDeSRT.,0.0,Neutral
"The RoI segmentation is basically categorized into four different ategories: Hough Transform [ 26 ], Projection profiles [ 23 , 28 ], Smearing [ 29 ], and segmentation
CM Trans.",0.0,Neutral
"Second, the RoIs class type (title, text, table, figure, and list) [26] within each image.",0.0,Neutral
"The RoI segmentation is basically categorized into four different categories: Hough Transform [26], Projection profiles [23, 28], Smearing [29], and segmentation based on connected components.",0.0,Neutral
"The segmentaion techniques are basically characterized into four categories: Hough Transform [ 20 ], Projection rofiles [ 21 ], Smearing [ 22 ], and segmentation based on connected components.",0.0,Neutral
"Driven by the success of object detection [17, 42] and semantic segmentation [8, 31] in images, layout analysis in documents is also framed as detection and segmentation tasks in some works [26,43,62], where detector models are trained to detect semantically coherent text blocks as objects.",0.0,Neutral
[15] is the first to apply FCN based semantic segmentation models to the TSR task.,0.0,Neutral
"Generally speaking, early attempts can be divided into the categories of textual-based [4,6,10], convolution-based [12,15, 24,26,34] and GCN-based [19] methods.",0.0,Neutral
"One such method [2] trains a deep learning network on Marmot dataset [9] for locating structural components like rows, columns and cells.",0.0,Neutral
"Recent methods such as TableNet [1], DeepDeSRT [2], Graph Neural Networks based table recognition [3] often fail to work on very complex tables due to their low generalization ability.",0.0,Neutral
Table 1: Performance Comparison of TSR-DSAW against TableNet [1] and DeepDeSRT [2].,0.0,Neutral
"Experimental Results: Now, we present comparison results of TSR-DSAW against two previous methods of TSR - TableNet [1] and DeepDeSRT [2].",0.5,Weak
DeepDeSRT [24] is a deep learning based approach that aims at detecting tables and recognizing table structures.,0.0,Neutral
"DeepDeSRT [24] uses semantic segmentation to segment the rows and columns in a table, meaning that it only relies on the visual features.",0.0,Neutral
"Several published works [46,42,56] exploit the advances in object detection [40,19] to further improve the accuracy in document layout analysis.",0.0,Neutral
DeepDeSRT [18] became the first popular object detection approach for table detection,0.0,Neutral
"The DL-based methods in [7, 11] are among the first to apply neural networks designed for object detection to table parsing.",0.0,Neutral
"As pioneering works in table structure parsing, [3] and [7] have both included a review of works in table structure recognition prior to DL.",0.0,Neutral
"After [7], researchers have started to revisit table structure parsing with DL methods, which turned out highly promising compared to the rule-based (e.",0.0,Neutral
"Table detection is a popular task with a large body of literature, table structure parsing and table recognition were revisited2 after the pioneering work of [7] using state-of-the-art deep neural networks.",0.0,Neutral
"The success of DL has marked the revisiting of table structure parsing by [7], which inspired follow-up research [27, 1, 6, 2, 28, 29, 30, 19, 31, 18, 32, 17].",0.0,Neutral
"Other researchers have used transfer learning to alleviate the lack of training data  [23, 26].",0.0,Neutral
"For instance, in [26, 29, 30, 32], the authors considered columns and rows as object types and reconstructed table structures from the detected rows and columns.",0.0,Neutral
", object detection and segmentation), table recognition has not been formulated in a principled way so far, and deep neural networks have only been used to address sub-tasks in heuristically designed steps [26, 30].",0.0,Neutral
[26] suggested the first method to address the table detection and structure recognition problems using deep learning.,0.0,Neutral
"Due to recent rapid development of image acquisition devices, data storage and processing capacity, document processing has made a great advancements [6, 26].",0.0,Neutral
"With the development of deep learning, DeepDeSRT [7] was proposed, which uses deep learning to conduct table detection and table structure recognition, that is, to identify the positions of rows, columns and cells in the detected table.",0.0,Neutral
"Therefore, subsequent post-processing steps are necessary [16], [18], [20].",0.0,Neutral
"In the field of document analysis, the combination of Support Vector Machine and Deep Neural Network initially replaced traditional machine learning to promote RPA to help solve unstructured document data [22], thus, the convolution model has been gradually used for document analysis [23,24].",0.0,Neutral
"[24] proposed that DeepDeSRT could conduct table detection and structure identification, as based on Faster R-CNN, to identify the positions of rows, columns, and cells in a table.",0.0,Neutral
"We also compare performance of several best methods on this dataset in Table 5, including rule-based method using text extracted from PDF files [43] and page images [2], deep CNN-basedmethods likeDeepDeSRT [16], TableNet [23], CascadeTableNet [18], and the result of two commercial systems ABBYY FineReader 11.0 and OmniPage 18 Professional.",0.5,Weak
"The DeepDeSRT [16], DeCNT [17], and CascadeTableNet [18] use Faster R-CNN as the basic framework for table detection.",0.0,Neutral
"For example, the DeepDeSRT and TableNet were tested on a set of randomly chosen 34 images since the remaining images were used for training [16,23].",0.0,Neutral
"We also compare performance of several best methods on this dataset in Table 5, including rule-based method using text extracted from PDF files [43] and page images [2], deep CNN-basedmethods likeDeepDeSRT [16], TableNet [23], CascadeTableNet [18], and the result of two commercial systems ABBYY FineReader 11.",0.5,Weak
"For learning feature maps, DeepDeSRT uses ZFNet [19] and VGG-16 [10] as the backbone, while DeCNT uses the deformable convolution.",0.0,Neutral
"In Section 2.1, we introduced the application of the Convolutional Neural Network (CNN) in document layout analysis (He et al., 2015; Ren et al., 2016; He et al., 2018; Liu et al., 2016; Redmon & Farhadi, 2018; Yang et al., 2017a; Schreiber et al., 2017).",0.0,Neutral
"Schreiber et al. (2017) first apply the Faster R-CNN model to table detection and recognition in document layout analysis as shown in Figure 2, achieving SOTA performance in the ICDAR 2013 table detection dataset (Göbel et al., 2013).",0.0,Neutral
"1, we introduced the application of the Convolutional Neural Network (CNN) in document layout analysis (He et al., 2015; Ren et al., 2016; He et al., 2018; Liu et al., 2016; Redmon & Farhadi, 2018; Yang et al., 2017a; Schreiber et al., 2017).",0.0,Neutral
"Cognitive methods in this space broadly classified into five categories — image-to-sequence models [17, 2, 14], segmentation networks [26, 18, 20, 23], graph formulations [22, 4, 24], conditional generative adversarial networks [16] and a recent multi-modal method by [40].",0.0,Neutral
"For DeepDeSRT [26], we use our implementation.",1.0,Strong
"In order to compare our method against others on TUCD dataset, we develop our implementation of DeepDeSRT [26], and use open source implementations of DGCNN (TIES) [22], SPLERGE [30], and TabStruct-Net [24].",1.0,Strong
"DeepDeSRT, a deep learning neural network, performs image analysis to identify table formats and constructs templates [27].",0.0,Neutral
Method Train Dataset P R F1 DeepDeSRT [32] ICDAR-2013 0.,0.0,Neutral
DeepDeSRT [32] - - SPLERGE [35] SciTSR + ICDAR-2019 0.,0.0,Neutral
"[13, 25, 32] attempt to predict row/column boundaries or even invisible grid lines, which are limited in identifying cells spanning multiple rows and columns.",0.0,Neutral
"They can be categorized into two groups: non-table-element-based approaches [13, 17, 25, 32, 35, 44] and tableelement-based approaches [2, 19, 27–29, 31, 41, 43].",0.0,Neutral
[16] ICDAR 2013 ICDAR 2013 (Test Set) N/A ü ü ü Row/Column Adjacency [19] relations,0.0,Neutral
[16] propose a deep learning based model for Faster-RCNN-based table detection and Fully Convolutional Network (FCN)-based structure recognition to segment the rows and columns in detected table regions.,0.0,Neutral
"TE is challenging for automated systems [8, 11, 16, 22] due to the wide variety of formats, styles, and layouts found in presented tables.",0.0,Neutral
"Recently, there has been a shift in the research literature from traditional rule-based methods [3,10,17] for TE to data-driven methods based on deep learning (DL) [13,16,21].",0.0,Neutral
"To get around deficiencies in training data, some approaches model TSR in ways that are only partial solutions to the task, such as row and column detection in DeepDeSRT [16], which ignores spanning cells, or image-tomarkup without text content, as in models trained on TableBank [8].",0.0,Neutral
"Modeling approaches One of the most common modeling approaches for TSR is to frame the task as some form of object detection [13, 16, 21].",0.0,Neutral
"DeepDeSRT, a deep learning neural network performs image analysis to identify table formats, constructs templates [17].",0.0,Neutral
"Limited by this, existing TSP approaches can only handle table structure parsing in a relative simple scenario by grouping detected cells into tables [11, 16, 9, 23].",0.0,Neutral
"For a more practical requirement of parsing table structures from images taken by hand-held cameras in the wild, the existing state-of-the-art approaches [13, 14, 11, 16, 9, 23] are prone to fail as the commonly-used assumption of tabular images no longer holds.",0.0,Neutral
"However, these methods mainly focuses on the well-conditioned document images, where the tables [16, 23, 12, 9, 23, 14] are well-aligned to the image axes.",0.0,Neutral
"For direct comparison with previous work [20], we used the cleaned version of the dataset by Reference [7] and did not incorporate any sample of the dataset in the training set.",0.0,Neutral
"Moreover, in Reference [33], the authors employed Faster RCNN with a coronerocating an approach to improve the predicted tabular boundaries in document images.",0.0,Neutral
"For a comprehensive explanation of the RFP module, please refer to Reference [24].",0.0,Neutral
"(4)
In case of SAC explained in Reference [24], the above convolutionalayer converts into:
Con(i, w, 1) SAC−−→ S(i) .",0.0,Neutral
"It is important to emphasize that methods introduced in References [1,20] either rely on the heavy backbone with memory-intensive deformable convolutions [53] or are dependent on multiple preand post-processing methods to achieve the results.",0.0,Neutral
"Analogous to Reference [55], the network in the final cascaded stage segments the object in a bounding box, along with classification and regression.",0.0,Neutral
"We direct our readers to References [15,16,38–40] for a thorough understanding of these rule-based methods.",0.0,Neutral
We refer readers to Reference [24] for a detailed explanation on SAC.,0.0,Neutral
[7] presented another method that exploits Faster R-CNN [50] equipped with pre-trained base networks (ZFNet [51] and VGG-16 [52]) to detect tables in document images.,0.0,Neutral
"If we include feature transformations Tj before joining
the feedback connections from FPN to the bottom-up backbone, then, the output feature f j of RFP is explained in Reference [24] as:
f j = Fj( f j+1, ij), ij = Nj(ij−1, Tj( f j)), (2)
where j enumerates over S, and the transformation of FPN to RFP makes it a recursive function.",0.0,Neutral
"As depicted in Figure 5, the architecture of our utilized cascade Mask R-CNN closely follows the cascaded architecture introduced in Reference [25], along with the addition of segmentation branch at the final network head [55].",0.0,Neutral
"Different from Census; CDC; BLS; IMF that only provide PDF reports where table hierarchies are hard to extract precisely (Schreiber et al., 2017), StaCan and NSF also provide reports in HTML, from which cell information such as text and formats can be extracted precisely using HTML tags.",0.0,Neutral
[28] proposed a deep learning architecture for detecting table location and identifying the row and column positions.,0.0,Neutral
"[42] then devised a very standard deep learning approach called DeepDeSRT for table detection and structure recognition, where no prior knowledge or assumption about table structures was necessary.",0.0,Neutral
"These specific tasks range from document content understanding, document structural and syntactic analysis [6, 42, 48] and so on.",0.0,Neutral
"However, [4, 11] do not consider that complex tables which contain spanning cells, so that they cannot handle the structure recognition of complex tables well.",0.0,Neutral
"Although significant efforts have been made in the past to recognize the internal structure of tables through an automated process [4, 6, 7, 8, 9, 10], most of these methods [4, 11] only focus on simple tables and are hard to accurately recognize the structure of complex tables.",0.0,Neutral
"[4, 11] utilize recently published insights from semantic segmentation [14] research for identifying rows, columns, and cell positions within tables to recognize table structures.",0.0,Neutral
"Comparing with other methods [9, 4, 7], our method achieves state-of-the-art.",0.0,Neutral
"Analyzing tabular data in unstructured documents focuses mainly on three problems: i) table detection: localizing the bounding boxes of tables in documents [18, 19], ii) table structure recognition: parsing only the structural (row and column layout) information of tables [4, 7, 8], and iii) table recognition: parsing both the structural information and content of table cells [6].",0.0,Neutral
"Numerous efforts have been made in the past to automatically extract the relevant information from documents [1, 2, 3, 4, 5].",0.0,Neutral
"Due to the rapid development of deep learning and the massive amounts of tabular data in documents on the Web, many deep learning-based methods [4, 6, 7, 9, 11] have also been presented to understand table structures as they are robust to the input type (whether being scanned images or native digital).",0.0,Neutral
"Most previous methods [4, 7, 9, 11, 12] only use the spatial or visual features without considering the textual information of each table cell to recognize the table structure.",0.0,Neutral
"Document understanding methods in the literature have used various combinations of image, spatial and text features in order to understand and extract information from structurally rich documents such as forms [18, 57, 12], tables [44, 56, 24], receipts [27, 26] and invoices [35, 42, 37].",0.0,Neutral
DeepDeSRT [25] is a 2- fold system that applies Faster RCNN [24] and FCN [16] for both table detection and row/column segmentation.,0.0,Neutral
"For example, the DeepDeSRT [25] model was evaluated on a random subset of ICDAR13-Table.",0.0,Neutral
"For cell spatial location detection, we use the same evaluation metrics with recent methods [25, 27, 29, 28, 20].",0.0,Neutral
"2, with the success of deep learning, recent deep learning-based table structure recognition approaches can be divided into three categories: 1) identify cell bounding boxes through visual detection and segmentation methods [25, 27, 29, 28, 8]; 2) transform a table image into the markup sequence, such as LaTeX and HTML [10, 2]; and 3) explore the adjacency relation between different table cells [30, 22, 11].",0.0,Neutral
"Recently, segmentation-based methods have been popular in table cell detection due to its statistical significance along table rows and columns [25, 27, 28].",0.0,Neutral
DeepDeSRT [25] is a 2fold system that applies Faster RCNN [24] and FCN [16] for both table detection and row/column segmentation.,0.0,Neutral
DeepDeSRT [1] is contain two steps: first step is deep learning method for table detection where using fine-tuning a pre-trained model of Faster RCNN and second step is deep learning method for table structure recognition by using fine-tuning FCN proposed by Shelhamer et al.,0.0,Neutral
"Deep learning has recently achieving state-of-the-art using convolutional neural network (CNN) [9] in many tasks including object detection [10], face recognition [11], sequence to sequence learning [12, 13], speech recognition [14], semantic segmentation [15], image classification [16], handwritten recognition [17, 18, 19], and table detection [1, 8, 6] is demanding because they need to classify tables among the texts and other figures.",0.0,Neutral
"A few studies have been conducted on the identification of tables in documents [1, 2, 3, 4, 5].",0.0,Neutral
[8] proposed a deep learning-based approach for table detection and table structure recognition in documents or images.,0.0,Neutral
Schreiber et al. (2017) proposed DeepDeSRT that employs the Faster R-CNN model for table detection and a semantic segmentation approach for structure recognition.,0.0,Neutral
[15] addressed TD and TSR in a single approach using a two-fold system based on Faster R-CNN [12] for TD and DL-based semantic segmentation for TSR that utilizes transfer learning.,0.0,Neutral
"Conclusion: Despite the extensive interest of the NLP community in leveraging document structures (e. g., Apostolova and Tomuro 2014; Schäfer et al. 2011; Schäfer and Weitz 2012; Schreiber et al. 2018; Katti et al. 2018), the task of parsing complete document structures from renderings has been overlooked.",0.0,Neutral
"…for structure parsing on documents focused on a subset of simpler tasks such as segmentation of text regions (Antonacopoulos et al. 2009), locating tables (Zanibbi, Blostein, and Cordy 2004; Embley et al. 2006), or parsing them (Schreiber et al. 2018), but not parsing complete document structures.",0.0,Neutral
"On the other hand, efficient learning is prevented as large-scale training sets are lacking (cf. Arif and Shafait 2018; Schreiber et al. 2018).",0.0,Neutral
"The works by Schreiber et al. (2018); Qasim, Mahmood, and Shafait (2019) draw upon deep neural networks to identify table structures for rendered inputs.",0.0,Neutral
"Altogether, our weak supervision outperforms the state-of-theart (Schreiber et al. 2018) by a considerable margin.",0.0,Neutral
"…Despite the extensive interest of the NLP community in leveraging document structures (e. g., Apostolova and Tomuro 2014; Schäfer et al. 2011; Schäfer and Weitz 2012; Schreiber et al. 2018; Katti et al. 2018), the task of parsing complete document structures from renderings has been overlooked.",0.0,Neutral
"For instance, nested tables are fairly easy to recognize for human readers, yet detecting them is known to impose computational hurdles (cf. Schreiber et al. 2018).",0.0,Neutral
"2006), or parsing them (Schreiber et al. 2018), but not parsing complete document structures.",0.0,Neutral
"Works of [30,31,32] firstly obtain the rows and columns regions using the detection or segmentation models and then intersect these two regions to obtain the grids of cells.",0.0,Neutral
"With the great success of deep neural network in computer vision field, works began to focus on the image-based table with more general structures [21,30,24,9,13,36,23,14,33].",0.0,Neutral
"Though recent works [30,22,32,31] attempt to predict row/column regions or even invisible grid lines [33], they are limited to handle tables that cross span multiple rows/columns.",0.0,Neutral
"Thus, table structure recognition [10,21,34,30,5,4,39] becomes one of the important techniques in current document understanding systems.",0.0,Neutral
"DeepDeSRT can segment cells, which are large enough and fully filled with texts.",0.0,Neutral
"We also compared the performance of CluSTi to DeepDeSRT [34], which is known as the best",0.5,Weak
"(2017) proposed a deep learning method called DeepDeSRT to detect tables in document images like PDF, as well as to recognize their structure [34].",0.0,Neutral
"In DeepDeSRT, the cell’s boundaries were recognized using a pre-trained Fully Convolutional Networks (FCN) for semantic segmentation [12, 21].",0.0,Neutral
"We also compared the performance of CluSTi to DeepDeSRT [34], which is known as the best
recent method for table structure recognition on the ICDAR 2013 and ICDAR 2019 competition’s datasets.",0.5,Weak
"In this case, the table structure can not be recognized using DeepDeSRT due to the fact that there exist many empty cells.",0.0,Neutral
table cells relying on their boundaries [34].,0.0,Neutral
"This approach overcome the limitations of DeepDeSRT method, which segments table cells relying on their boundaries [34].",0.0,Neutral
"That’s why when cells are empty or not large enough, they are still recognized by CluSTi but not by DeepDeSRT.",0.0,Neutral
"For instance, Schreiber et al. (2017) proposed a deep learning method called DeepDeSRT to detect tables in document images like PDF, as well as to recognize their structure [34].",0.0,Neutral
"This result also outperformed DeepDeSRT, which is known as the best recent method applied on document images.",0.5,Weak
CluSTi outperforms DeepDeSRT with an overall F1-score of 98.48% on 193 document images compared to 91.44% on 34 images (Table 2).,0.5,Weak
"TableNet showed comparable results to DeepDeSRT method [34], and their model is end-to-end which means further improvements can be made with richer semantic knowledge, and additional branches for learning row-based segmentation.",0.0,Neutral
"This method outperformed DeepDeSRT and TableNet with a significant higher F1-score on the 34 test images of ICDAR 2013 competition dataset, that demonstrated for the efficiency of our method.",0.5,Weak
"Table 2 Comparison of detection accuracy (%) among CluSTi, DeepDeSRT [34], and TableNet [23] on ICDAR 2013 dataset",0.0,Neutral
"In contrast, DeepDeSRT is based on Faster RCNN, a semantic segmentation model which focuses on cell object detection [28].",0.0,Neutral
The authors have reported the F1-score of 93.42% with an IOU of 0.5 on the ICDAR 2013 dataset [66].,0.0,Neutral
"[7], they have formulated the problem of structure recognition as the semantic segmentation problem.",0.0,Neutral
DeepDeSRT [7] Faster R-CNN with transfer learning techniques (Section III-A1a) Simple and effective end-to-end approach to detect tables and structures of the tables.,0.0,Neutral
Deep learning leverages huge datasets [7].,0.0,Neutral
The threshold of Intersection Over Union (IOU) for calculating precision and recall is also defined in Table 6.,0.0,Neutral
These three metrics are calculated on a specific IOU threshold established by the authors.,0.0,Neutral
"The performance of deep neural networks has a direct relation with the size of the dataset [7], [24].",0.0,Neutral
"Their end to end system known as DeepDeSRT not only detects the tabular region but also distinguishes the structure of the table and both of these tasks are dealt with by applying distinctive
87666 VOLUME 9, 2021
deep learning techniques.",0.0,Neutral
"[45] S. Schreiber, S. Agne, I. Wolf, A. Dengel, and S. Ahmed, ‘‘DeepDeSRT: Deep learning for detection and structure recognition of tables in document images,’’ in Proc.",0.0,Neutral
"The task of table structural segmentation is evaluated based on how accurate the rows or columns of the tables are separated [7], [44], [47].",0.0,Neutral
We strongly believe that the threshold value for IOU needs to be standardized in order to have an impartial comparison.,0.0,Neutral
"For table detection, one of the most exploited evaluation metrics is IOU [45], [46].",0.0,Neutral
"To recognize the structure in tables, the authors of DeepDeSRT [7] have exploited the concept of semantic segmentation.",0.0,Neutral
"The author tries to convince the readers that due to the interdependence between the table detection and structural segmentation, both of the problems can be solved efficiently by using a single network.
a: FULLY CONVOLUTIONAL NETWORKS To recognize the structure in tables, the authors of DeepDeSRT [45] have exploited the concept of semantic segmentation.",0.0,Neutral
"For table detection, one of the most exploited evaluation metrics is IOU [7], [40], [44].",0.0,Neutral
"It is crucial to mention that some of the approaches have not quoted the threshold value for IOU; however, they have compared their results with other methods where the threshold value is defined.",0.0,Neutral
"[8], [18], [1] and [22] made use of Faster R-CNN [17] with their own take on handcrafted features and preprocessing methodologies.",0.0,Neutral
[18] mentions the unnatural approach of detecting rows and columns through Faster R-CNN [17] and instead proposes fine-grained image segmentation through FCN-X’s architecture by Shelhamer et al.,0.0,Neutral
"To achieve convergence, datasets with a massive amount of images are required to train these networks optimally [14,19].",0.0,Neutral
[14] where they implemented Faster R-CNN for detection of tables in document images.,0.0,Neutral
DeepDeSRT [14] Faster R-CNN [50] with transfer learning Straightforward and effective approach to detect tables.,0.0,Neutral
"DeepDeSRT [26], uses separate, specially made neural networks to identify tables and extract their data.",0.0,Neutral
"However, extracting tabular structures directly from images is perplexing compared to operating over digital-born PDFs [17].",0.0,Neutral
[27] published the first natural image-based deep learning system which explored the problem of table structure analysis.,0.0,Neutral
"ICDAR-2013 [18] dataset has been used to standardize the state-of-the-art results for the task of table detection and table structure recognition [27], [32].",0.0,Neutral
"However, extracting tabular structures directly from images is perplexing as compared to operating over digital-born PDFs [27].",0.0,Neutral
"In this paper, we exhibit that current object detectors that have already shown remarkable improvements in resolving the problem of table detection [27], [42], are also extremely effective in improving the performance of table structure recognition systems.",0.0,Neutral
This problem can be further dissolved into detecting rows and columns in a table that can be later combined to produce the respective cells [27].,0.0,Neutral
"In order to compare our approach with state-of-the-art methods [27], [32], [33], we have used the identical evaluation metrics which are explained below:",0.5,Weak
"[27] in order to implement a direct comparison against the similar approaches [27], [32], [33].",0.0,Neutral
All these techniques are heavily dependent on the meta-data available in digital-born PDFs.,0.0,Neutral
"Borrowing from computer vision, other works [1, 5, 6, 12] showed that a trained object detection or image semantic model, such as a convolutional neural network, can learn to detect boundaries of tables, figures, lists, paragraphs with satisfying results; however, they do not tackle the issue of parsing smaller elements such as list items or sentences with computer vision techniques.",0.0,Neutral
"Many previous works [22, 26, 23] and tools 16 have been developed to identify and parse table structures.",0.0,Neutral
"Object detection-based methods like Faster R-CNN [24] and Mask R-CNN [11] are used for identifying document elements [34] and detecting tables [26, 22].",0.0,Neutral
"…Fu, & Zhang, 2019; Holeček, Hoskovec, Baudiš, & Klinger, 2019; Schreiber, Agne, Wolf, Dengel, & Ahmed, 2017) through convolutional (Dong et al., 2019; Holeček et al., 2019) layers and recurrent neural
networks (Schreiber et al., 2017) trained either on the imaged document or on other formats.",0.0,Neutral
"Examples include detecting tables, equations, figures [53, 43, 44], signatures and logos [46, 47].",0.0,Neutral
"Examples for table and cell region detection include [2, 4, 6] while [4–7, 9] address table structure extraction.",0.0,Neutral
"Convolutional neural networks [150, 151], fully-convolutional neural networks [152, 153], region-based convolutional neural networks [154, 155, 156, 157], and graph neural networks [158, 159] have all been exploited to parse the physical layout of documents or to detect elements of interest (e.",0.0,Neutral
"For example, Schreiber et al. (2017) [4]) proposed a method based on Faster-RCNN network; Li et al. (2019) [5]) presented a method combined with GAN and so on.",0.0,Neutral
(2017) [4]) used the FCN to recognize rows and columns in tables.,0.0,Neutral
(2017) [4]) proposed a method based on Faster-RCNN network; Li et al.,0.0,Neutral
Schreiber et al. (2017) [4]) used the FCN to recognize rows and columns in tables.,0.0,Neutral
"For example, Schreiber et al. (2017) [4]) proposed a method based on Faster-RCNN network; Li et al. (2019) [5]) presented a method combined with GAN and so on.",0.0,Neutral
(2017) [4]) used the FCN to recognize rows and columns in tables.,0.0,Neutral
(2017) [4]) proposed a method based on Faster-RCNN network; Li et al.,0.0,Neutral
Schreiber et al. (2017) [4]) used the FCN to recognize rows and columns in tables.,0.0,Neutral
"been restricted to structure detection only [6, 9, 11].",0.0,Neutral
"Such approaches include the following: (i) binary classification based on convolutional neural networks [10], (ii) fine-tuning pre-trained models for object detection in images [1], [6], [30], [34], [35], (iii) semantic segmentation [11], [14], and (iv) feature generation [19].",0.0,Neutral
[30] discovered that the table detection in document images is similar to detection of objects in natural scene images.,0.0,Neutral
"The contemporary deep neural networks for table detection in document images [1], [6], [13], [24], [30], [34], [35] demonstrate a high accuracy on the competition datasets.",0.0,Neutral
[30] for developing a DNN-model for table detection.,0.0,Neutral
"We explore three neural models used in previous works on abusive language classi-
cation: Convolutional Neural Network (CNN)
GRU
fasttext .887 .661 .312 .284
word2vec .887 .633 .301 .254
-GRU random .868 .586 .236 .219 fasttext .891 .639 .324 .365 word2vec .890 .631 .315 .306
Table 4: Results on st. False negative/positive equality differences are larger when pre-trained embedding is used and CNN or -RNN is trained
(Park and Fung, 2017), Gated Recurrent Unit (GRU) (Cho et al., 2014), and Bidirectional GRU with self-attention ( -GRU) (Pavlopoulos et al.,
2017), but with a simpler mechanism used in
Felbo et al. (2017).",0.0,Neutral
"CNN: Convolution layers with 3 lters with the size of [3,4,5], feature map size=100, Embedding Size=300, Maxpooling, Dropout=0.5
2.",0.0,Neutral
In: IJCNN. pp. 1–8 (2019) 38.,0.0,Neutral
"More recently, some deep learning methods based on Convolutional Neural Networks (CNN) [34], Conditional Generative Adversarial Networks (CGAN) [37], and a combination of a CNN, saliency and graphical models [20] have been evaluated.",0.0,Neutral
The natural language approach has been widely researched and implemented in recent years [5].,0.0,Neutral
"…using convolutional neural networks (CNNs) provide considerably better performance (Xu et al., 2020; Kavasidis et al., 2019; Siegel et al., 2018; Schreiber et al., 2017; Gilani et al., 2017; Hao et al., 2016), the quality of the labeled training data often determines the success of these…",0.0,Neutral
"Among these, the problem of table structure recognition has been of high interest in the community [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20].",0.0,Neutral
"In the space of document images, researchers have been working on understanding equations [30,31], figures [32,33] and tables [6,7,8,9,10,11,12,13,14,15,16,17].",0.0,Neutral
deepdesrt [7] scitsr 12K S-A 0.,0.0,Neutral
"Table structure recognition is a challenging problem due to complex structures and high variability in table layouts [4,5,6,7,8,9,10,11,12,13,14,15,16,17].",0.0,Neutral
"In S-A, we observe that our model outperforms deepdesrt [7] method by a 27.",0.5,Weak
"Many cognitive methods [6,7,8,9,10,11,12,14,15,16,37,38,39,40,41,42,43] have also been presented to understand table structures as they are robust to the input type (whether being scanned images or native digital).",0.0,Neutral
"We compare the performance of our tabstruct-net against seven benchmark methods — deepdesrt [7], tablenet [12], graphtsr [14], splerge [10], dgcnn [9], Bi-directional gru [15] and Image-to-Text [11].",0.5,Weak
"Deep learning-based approaches can be used for document layout analysis and content parsing (Shen et al., 2021; Zhong et al., 2019; Schreiber et al., 2017).",0.0,Neutral
"Deep learning-based approaches have recently been widely applied to document layout analysis and content parsing (Zhong, Tang, and Yepes 2019; Schreiber et al. 2017).",0.0,Neutral
"applied to document layout analysis and content parsing (Zhong, Tang, and Yepes 2019; Schreiber et al. 2017).",0.0,Neutral
"For analysing the tables in scanned documents, (Schreiber et al. 2017; Paliwal et al. 2019; Prasad et al. 2020) propose different modifications to standard CNN network architectures such as VGGNet (Si-
.
monyan and Zisserman 2014) used for classification and Faster R-CNN (Ren et al. 2015) for…",0.0,Neutral
"For analysing the tables in scanned documents, (Schreiber et al. 2017; Paliwal et al. 2019; Prasad et al. 2020) propose different modifications to standard CNN network architectures such as VGGNet (SiFigure 3: Results of Table Token Classification.",0.0,Neutral
"We refer the readers to [25, 26] for table detection and [27, 28] for figure detection algorithms.",0.0,Neutral
"The contemporary deep neural network models for the table detection [1], [5], [16], [18] show a high accuracy on the competition datasets such as UNLV [17], Marmot1, ICDAR 2013 [7], and ICDAR 2017 [4]).",0.0,Neutral
"The current trend involves deep learning techniques: binary classification based on convolutional neural networks [8], fine-tuned object detection models [1], [5], [16], [18], and semantic segmentation [9], [10].",0.0,Neutral
"Thanks to the development of several public databases, document processing has made a great progress in recent years [1], [2].",0.0,Neutral
"There also exist deep learning methods to detect tables from images (Schreiber et al., 2017); (Paliwal et al., 2019).",0.0,Neutral
"There also exist deep learning methods to detect tables from images (Schreiber et al., 2017); (Paliwal et al.",0.0,Neutral
"[22], Siddiqui et al.",0.0,Neutral
"State of the art algorithms (such as [7, 13, 14, 21, 22, 24, 26]) for graphical object detection are motivated by the success of object detection in computer vision (such as faster r-cnn and mask r-cnn).",0.0,Neutral
"Recent advances in object detection in natural scene images using deep learning inspire researchers [7, 13, 14, 16, 18, 21, 22, 24, 26] to develop deep learning based algorithms for detecting graphical objects in documents.",0.0,Neutral
"a lot of attention in the research community [7, 10, 13–16, 18, 21, 22, 24, 26, 27].",0.0,Neutral
There have been many deep learning models that have been successful at tabular structure detection [4] [29] .,0.0,Neutral
Schreiber et al.11 presented a system that is completely data driven and not require heuristics or meta data to detect and recognize table structures on the ICDAR 2013 dataset.,0.0,Neutral
"The comparison of performance between open source F. Shafait et al.5 technique (Tesseract),Schreiber et al. Hao et al.10 , Gilani et al.12 and our method is shown in Table 2.",0.5,Weak
Performance Measures Accuracy (%) Tesseract(5) Schreiber et al.(11) Gilani et al.,0.0,Neutral
Schreiber et al.(11) presented a system that is completely data driven and not require heuristics or meta data to detect and recognize table structures on the ICDAR 2013 dataset.,0.0,Neutral
"One particular area where automation is of utmost importance and desirable is digitization of scanned documents like bank application forms, receipts and insurance claim forms [22, 20, 16, 14] to facilitate easy and quick retrieval and management of information for faster processing.",0.0,Neutral
"For converting the image into a binary image adaptive thresholding algorithm can be used and for removing the noise, algorithms such as KFILL algorithms can be utilized [24].",0.0,Neutral
"Table Detection and Tabular Structure Identification: Often real world invoices and other documents contain data in tables with highly variable structure, and while deep learning has made important strides in table detection [12, 16], extraction techniques that generalize well across unseen table formats remains a challenge.",0.0,Neutral
"Most existing work on object detection-based methods detect entire rows and column separately, and represents the intersection of detected rows and columns as cells [26, 33].",0.0,Neutral
"Deep learning approaches include two categories: (a) End-to-end image-to-sequence models [18, 36]; (b) Object detection based methods [26, 33, 23].",0.0,Neutral
"However, few vision-based deep learning models for table extraction that have been proposed, with most existing deep learning approaches directly use off-the-shelf object detectors [24, 26, 18] without any major architectural adaptation.",0.0,Neutral
"Also, [23, 26] used different train/test split from the original competition without publishing their split and so cannot be compared directly.",-1.0,P-NR
"used to detect tables by adapting state-of-the-art object detectors such as Faster-RCNN to table detection [26, 18, 6].",0.0,Neutral
[19] adapt Faster R-CNN [17] and FCN to identify their structures and parse the contents.,0.0,Neutral
"We only use 40 images from the dataset for fine-tuning the general model and 198 images for testing, while [18] and [21] used only 34 images for testing and rest of the dataset for training.",0.0,Neutral
"As done by DeepDeSRT [21], to achieve the best possible results, we removed the errors in the ground-truth annotations of the dataset.",0.0,Neutral
"[21] were the first to perform table detection and structure recognition together with a 2 fold system which Faster RCNN for table detection and, Subsequently, deep learning-based semantic segmentation for table structure recognition.",0.0,Neutral
Figure 1: Table Detection Result on ICDAR 2013 dataset [3],0.0,Neutral
1) Faster Recurrent Conventional Neural Network (FRCNN) [2] [3] algorithm to detect the table.,0.0,Neutral
"[3], proposed a deep learning-based approach to detect table and structure recognition of table in Document or Image by using the ICDAR 2013 table completion dataset which containing 67 documents with 238 pages.",0.0,Neutral
"Method proposed in [1, 2] handles the unavailability of large training data by using transfer learning approach with very carefully tuned parameters [2] also uses data augmentation to handle annotated data problem.",0.0,Neutral
"Although both are validated on totally different data sets, F1 score in [1] is 0.",0.0,Neutral
"DL-based techniques are reasonably good in localization [19, 20], and taking inspiration from it [1, 9] have proposed the use of Faster-RCNN.",0.0,Neutral
"In [1, 2], a framework for table detection and recognition is proposed.",0.0,Neutral
"In [1, 2], efforts are made to apply DL-based methods for table localization and detection from image or scanned documents.",0.0,Neutral
The results of the method presented in [2] are validated on publicly available UNLV data set [23] and [1] on ICDAR 2013 data.,0.0,Neutral
"The literature focuses on using NLP-based techniques for data that has a model, template-based techniques for data that does not have a meta-dictionary available and deep learning-based extraction techniques for sequence [26] and image [9] based analysis of the unstructured data.",0.0,Neutral
"Thus, the problem of pattern or relationship extraction is extremely challenging due to the uneven distribution and high degree of variation between different structures [9].",0.0,Neutral
"After that, [21, 24, 29] also leveraged more advanced Faster R-CNN model [19] or Mask R-CNN model [9] to further improve the accuracy of document layout analysis.",0.0,Neutral
Nowadays document image analysis is still a relevant and challenging problem in computer vision [1-4].,0.0,Neutral
"Currently, deep learning techniques are the state of the art approach to deal with computer vision tasks [32]; and, this is also the case for table detection in document images [21, 23, 34].",0.0,Neutral
"This is the approach followed in [11, 34, 36], where they use models trained on natural images to fine-tune their models for table detection.",0.0,Neutral
"Namely, the main algorithm applied in this context is Faster R-CNN [31], that has been directly employed using different backbone architectures [21,23,34], and combined with deformable CNNs [36] or with image transformations [11].",0.0,Neutral
"With the introduction of deep-learning methods, major developments have been made for page objects segmentation and detection [4, 8, 9, 10].",0.0,Neutral
Significant efforts have been invested in the domain of table detection [11] and table structure detection [8].,0.0,Neutral
"Faster-RCNN has been successfully used for page object detection from document images in the recent past [8, 11, 21], but mask-RCNN is used for the very first time to detect objects from document images to the best of the authors’ knowledge.",0.0,Neutral
"For instance, deep networks trained on ImageNet data, which comprises of natural images of various objects, have been shown to perform surprisingly well on various document analysis tasks such as document classification [11] and table detection [12].",0.0,Neutral
[12] as the baseline for our experiment as their approach provides the unprocessed image as an input to the Faster R-CNN for table detection.,0.5,Weak
"[12] presented a data-driven, deep learning approach for table detection.",0.0,Neutral
", paragraphs, figures, lists, tables [48, 38, 30].",0.0,Neutral
"While there are other works [33, 38] that perform table decomposition into rows and columns (which our model is capable of doing), we discuss table detection only in the scope of this paper.",0.0,Neutral
"ion [23]–[25]. In addition, deep neural networks for object detection, such as Faster-RCNN [26], Mask-RCNN [27], and YOLO [28] have been exploited for table detection and row/column segmentation [7], [29]–[31]. Furthermore, graph neural networks are used for table detection and recognition by encoding document images as graphs [5], [32]. There are several tools (see Table II) that can convert tables i",0.0,Neutral
"Altogether, our weak supervision outperforms the state-of-the-art with image-based input (Schreiber et al., 2018) by a considerable margin.",0.5,Weak
The work by Schreiber et al. (2018) draws upon a CNN to perform semantic segmentation of row and column pixels and identifies structure via postprocessing.,0.0,Neutral
"The ICDAR labels now serve as the target dataset, while we continue to use arXivdocs-weak for weak supervision.7 Following (Schreiber et al., 2018), we use a random subset of 50 % of the ICDAR 2013 competition dataset for testing.",0.0,Neutral
"On the other hand, efficient learning is prevented as large-scale training sets are lacking (cf. Arif and Shafait, 2018; Schreiber et al., 2018).",0.0,Neutral
"Earlier attempts for structure parsing on documents focused on a subset of simpler tasks such as segmentation of text regions (Antonacopoulos et al., 2009), locating tables (Zanibbi et al., 2004; Embley et al., 2006), or detecting hierarchical structures in tables (Schreiber et al., 2018).",0.0,Neutral
"Furthermore, (Schreiber et al., 2018) chooses the best system based on the test set as indicated by F1*.",0.0,Neutral
"For instance, nested tables are fairly easy to recognize for human readers, yet detecting them is known to impose computational hurdles (cf. Schreiber et al., 2018).",0.0,Neutral
"(Schreiber et al., 2018) uses a different, non-public 50 % random subset.",-1.0,P-NR
"7 Following (Schreiber et al., 2018), we use a random subset of 50 % of the ICDAR 2013 competition dataset for testing.",0.0,Neutral
"The dataset comes without predefined train/test split; hence, we follow Schreiber et al. (2018) and split the so-called “competition” part of the dataset with a 50%/50%-ratio.",0.5,Weak
"Others build models specifically to extract tables [6, 12, 22, 23, 14, 9], figures [15], and equations [11, 18, 26, 7].",0.0,Neutral
Deep learning based semantic segmentation has been used by Schreiber et al. (2017) where an image of a document is fed to the neural network to identify the rows and columns of a table.,0.0,Neutral
"We can enhance the novel deep learning-based approach for table structure detection, DeepDeSRT [14], as proposed by Sebastian Schreiber et al. The PDF documents can be converted to image format.",0.0,Neutral
"We can enhance the novel deep learning-based approach for table structure detection, DeepDeSRT [14], as proposed by Sebastian Schreiber et al.",0.0,Neutral
"Recently, DeepDeSRT [8] was proposed which uses deep learning for both table detection and table structure recognition, i.",0.0,Neutral
"In DeepDSert, separate models are made for Table detection and structure recognition, which were trained on different datasets such as Marmot for table detection, and the ICDAR 2013 table dataset for table structure recognition.",0.0,Neutral
"While the results are not conclusively better than DeepDSert, they are certainly comparable and the fact that our model is end-to-end means further improvements can be made with richer semantic knowledge, and additional branches for learning row based segmentation.",0.5,Weak
"Recently, DeepDeSRT [8] was proposed which uses deep learning for both table detection and table structure recognition, i.e. identifying rows, columns, and cell positions in the detected tables.",0.0,Neutral
"Average time taken for our system for each document image is 0.3765 seconds, however this could not be compared with DeepDSert as their model was not publicly available.",-1.0,P-NR
"Additionally, Experiment 3 was carried out to compare TableNet with the closest deep-learning based solution, DeepDSert [8].",0.0,Neutral
"As done in DeepDSert, we also randomly chose 34 images for testing and used the rest of the data images for fine-tuning our model.",0.0,Neutral
We reimplemented the DeepDeSRT table structure model [6] and trained it on the same private data as our proposed model.,1.0,Strong
We did so by reimplementing the DeepDeSRT model [6] and training on the same data as our proposed model.,1.0,Strong
"However, we were unable to obtain reasonable performance, even after exploring a variety of values for post processing thresholds and training hyperparameters (values not specified in [6]).",-2.0,O-NR
The Deep DeSRT model [6] uses a neural network originally designed for semantic segmentation of natural scenes and thus primarily uses local information to classify pixels.,0.0,Neutral
The DeepDeSRT [6] learning model formulates table structure extraction as two independent pixel labeling tasks to respectively segment row objects and segment column objects.,0.0,Neutral
"Recently, deep learning has been proposed to learn table structure directly from images [6].",0.0,Neutral
"In [6], better results were obtained when resizing the initial input to make the separator regions bigger.",0.0,Neutral
"We were unable to find any official implementations of prior works, so for comparison, we use the commercial software system Acrobat Pro DC and our reimplementation of the DeepDeSRT model [6].",1.0,Strong
"Category Method F-measure Recall Precision PDF Input Image Input
Proposed Models
Split 86.79 86.64 86.93 Split-PDF 91.63 91.26 92.00 SPLERGE-PDF 90.89 90.44 91.36 SPLERGE-PDF + Heuristics 91.95 91.46 92.45
Split + Heuristics 93.00 92.24 93.78 Split-PDF + Heuristics 95.26 94.64 95.89
Previously Reported Results
Nurminen [3] 94.60 94.09 95.12 TEXUS [4] 82.59 84.23 81.02 Shigarov [5] C1 91.50 91.21 91.80 Shigarov [5] C2 93.64 92.33 94.99 DeepDeSRT [6] 91.44† 87.36† 95.93†
† result not directly comparable due to evaluation on a random subset of 34 tables.",-1.0,P-NR
[2] proposed a deep learning based approach for recognizing rows and columns of tables in document images.,0.0,Neutral
[2] table structure extraction system based on semantic segmentation by a significant margin.,0.0,Neutral
"This approach provides a significant improvement over heuristic algorithms and CNN based models [2], owing to the powerful representation of the sequence models that capture",0.0,Neutral
[2] which is the state-of-the-art deep learning based approach towards table structure recognition.,0.0,Neutral
[2] proposed a deep learning based approach for table structure recognition.,0.0,Neutral
"For that purpose, we used the publicly available ICDAR 2013 table competition dataset containing 67 documents with 238 pages, since this dataset was used in [2].",0.0,Neutral
"However, this limits the applicability of these systems to only PDFs where many of the documents are scanned or present in the form of images [2].",0.0,Neutral
Schreiber et al. (2017) [2] used only 31 images to test their model.,0.0,Neutral
Automatic extraction of such information for the purpose of digitization/processing is highly valuable for organizations [2].,0.0,Neutral
(2017) [2] used only 31 images to test their model.,0.0,Neutral
"Following the work of Schreiber et al. (2017) [2], we converted the cell-based annotations to the corresponding annotations for rows and columns.",0.5,Weak
"In contrast to the annotations generated by Schreiber et al. (2017) [2], we label the complete row regardless of the textual region for consistency.",0.5,Weak
"Training data-driven models for the task of table structure analysis requires access to a large amount of labeled data, specifically for deep models [2].",0.0,Neutral
"Significant efforts have been made in the past for automated extraction of information from documents [1], [2], [3], [4], [5].",0.0,Neutral
"The same evaluation scheme was used for the ICDAR-13 table structure recognition competition and Schreiber et al. (2017) [6], [2].",0.0,Neutral
Schreiber et al. (2017) [2] translated the dataset to labels for rows and columns in order for the image-based models to be trained.,0.0,Neutral
[2] and our custom ICDAR-17) neglect row/column span (hierarchical labels).,0.0,Neutral
"Once a table is detected, the structure of the table is analyzed [2].",0.0,Neutral
"detection of the table itself [7], [3], [2].",0.0,Neutral
One of the recent image-based deep learning methods for table structure analysis has been proposed by Schreiber et al. (2017) [2].,0.0,Neutral
We used the same train and test split as used by Schreiber et al. (2017) [2] in order to enable a direct comparison against their approach.,0.5,Weak
"hand-designed heuristics to data-driven methodologies [1], [2].",0.0,Neutral
"In contrast to the Fully-Convolutional Network (FCN) based formulation presented by Schreiber et al. (2017) [2], we treat the problem of row/column identification in a tabular structure as that of object detection where the document can be considered analogous to scene and row/column can be…",0.0,Neutral
(2017) [2] translated the dataset to labels for rows and columns in order for the image-based models to be trained.,0.0,Neutral
This is consistent with ICDAR-13 image-based table structure recognition dataset generated by Schreiber et al. (2017) [2] where row/column span (hierarchical labels) were also discarded.,0.0,Neutral
"Significant efforts have been made in the past to extract this tabular information from documents through an automated process [1], [2], [3], [6], [7].",0.0,Neutral
"Similarly, we follow an identical data split (with the same files segregated into train and test sets) as the one defined by Schreiber et al. (2017) [1] comprising of 125 training and 31 test table images.",0.5,Weak
This problem of cell region detection can be further decomposed into row and column identification which can ultimately be combined together for the discovery of the corresponding cells in the table [1].,0.0,Neutral
This intermediate representation can also be the output of the system as in the case of Schreiber et al. (2017) [1].,0.0,Neutral
We compare our method using these image-based row and column-level statistics [1].,0.0,Neutral
[1] proposed a table recognition system where they computed precision and recall based on the rows and columns instead of using the cell-level information from the ICDAR-2013 table competition dataset [7].,0.0,Neutral
• Benchmarking of the results obtained by the proposed prediction tiling approach using the evaluation metrics used by Schreiber et al. (2017) [1] on the publicly available ICDAR-13 table structure recognition dataset [7].,0.5,Weak
Schreiber et al. (2017) [1] made a recent attempt for the incorporation of deep learning based techniques for the task of table structure recognition where they used two different fully-convolutional networks for the identification of the corresponding rows and columns.,0.0,Neutral
"Therefore, automated extraction of these tabular regions can be useful in a wide range of applications [1], [2], [3].",0.0,Neutral
Our post-processing is similar to the one used by Schreiber et al. (2017) [1].,0.5,Weak
"Abstract—Based on the recent advancements in the domain of semantic segmentation, Fully-Convolutional Networks (FCN) have been successfully applied for the task of table structure recognition in the past [1].",0.0,Neutral
Minor efforts have also been made on performing analysis of tabular regions directly on images [1].,0.0,Neutral
"Numerous efforts have been made in the past to automatically extract the relevant information from documents [1], [2], [3], [4], [5].",0.0,Neutral
"Numerous methods have dealt with this problem in the past [1], [2], [3] and achieved near perfect detection rates on publicly available datasets.",0.0,Neutral
(2017) [1] on the publicly available ICDAR-13 table structure recognition dataset [7].,0.0,Neutral
We use Marmot data set for training our model similar to DeepDeSRT [6].,0.5,Weak
"[6] proposed a deep learning based solution for table detection and structure identification, which does not require any assumption about the structure of the tables.",0.0,Neutral
"The GOD is compared to state-of-the-arts: Kavasidis et al. [8], DeepDeSRT [6] and Tran et al. [26] on ICDAR-2013 table competition data set.",0.0,Neutral
"precision, recall and F1 measures [6], [8], [26] to evaluate the performance of our algorithm for detecting graphical objects in the document images.",0.0,Neutral
[3] used a pre-trained model over Faster RCNN.,0.0,Neutral
"There are also proposed methods [2], [3] for table detection based on Faster R-CNN [10] architecture; however, Schreiber et al.",0.0,Neutral
[3] have used data-driven deep learning approach using fully convolutional networks (FCN) for semantic segmentation architectures [17] with skip connections.,0.0,Neutral
"Recently deep learning techniques are used to localize a table but mostly applied on contemporary documents [2], [3], [4].",0.0,Neutral
"It is interesting to note that [9] also uses FRCNN to detect multiple line-items regions, but their task-oriented evaluation measure makes the comparison with [7] difficult (and most of the invoices in their dataset have only less than three items).",0.0,Neutral
"[7] uses Faster R-CNN for the table recognition task, and also offers a complementary",0.0,Neutral
"A follow-up work of [7] proposes DeCNT [8], an approach based on a",0.0,Neutral
[17] and Gilani et al.,0.0,Neutral
"A similar approach based on a region proposal network is also proposed in DeepDeSRT [24] for detecting tables, they further extended it to rows and column detection.",0.0,Neutral
"Table detection and recognition in unconstrained documents is considered a challenging task and recently has received significant attention within the community [2], [7], [11], [16], [19], [22], [24].",0.0,Neutral
"[5] presented a deep learning-based solution for the identification of rows, columns, and cells, where transfer learning is performed by augmenting and fine-tuning a FCN semantic segmentation model [15].",0.0,Neutral
"The first is to classify table cells into specific categories [4], [5], e.",0.0,Neutral
"More recent works [4], [5] have used deep-learning methods to recognize table structure.",0.0,Neutral
"Recently deep learning approaches have been attempted for table detection [19], [20] and are showing very good results.",0.0,Neutral
"Recently, [6] proposes DeepDeSRT, a combination of two deep learning systems, one for table detection, and a second for table understanding.",0.0,Neutral
"The fine tuned F-RCNN model achieves the state-of-the-art performance reported in [6], where the F-RCNN model was fine tuned with 1600 samples from a pre-trained object detection model.",0.0,Neutral
"More recently, image analytics methods based on deep learning are becoming available [5] and are used to train document layout understanding pipelines [1], [6].",0.0,Neutral
"In 2017, Schreiber et al. first proposed a model called DeepDeSRT, which treats the table structure recognition task as an image semantic segmentation problem, and then recognizes the regions of columns and rows respectively (Schreiber et al., 2017).",0.0,Neutral
"first proposed a model called DeepDeSRT, which treats the table structure recognition task as an image semantic segmentation problem, and then recognizes the regions of columns and rows respectively (Schreiber et al., 2017).",0.0,Neutral
"The existing approaches can be classified into two categories: rule-based methods (Ramel et al., 2003; Yildiz et al., 2005; Hassan and Baumgartner, 2007) and data-driven methods (Schreiber et al., 2017; Li et al., 2019).",0.0,Neutral
", 2005; Hassan and Baumgartner, 2007) and data-driven methods (Schreiber et al., 2017; Li et al., 2019).",0.0,Neutral
"I R
] 2
8 A
ug 2
01 9
DeSRT (Schreiber et al., 2017) and Tabby (Shigarov et al., 2016).",0.0,Neutral
"• DeepDeSRT: DeepDeSRT (Schreiber et al., 2017) is a data-driven method that utilizes a semantic segmentation model to recognize the table structure as a set of segmented rows and columns.",0.0,Neutral
is good and is comparable to [16] which uses FCN.,0.0,Neutral
"A variety of methods tackled this problem [16], [18]–[20] on publicly available datasets.",0.0,Neutral
DeepDeSRT [16] uses Fully Convolutional Networks (FCN) [17] to segment the rows and columns of tables.,0.0,Neutral
DeepDeSRT [24] 0.,0.0,Neutral
Approaches like [15] partially solve the issue but it is still not a natural approach.,0.0,Neutral
[15] also used Faster RCNN for table detection and extraction of rows and columns.,0.0,Neutral
Approaches like [15] partially solve the issue but it is still not a natural approach.,0.0,Neutral
[15] also used Faster RCNN for table detection and extraction of rows and columns.,0.0,Neutral
Reference [17] also uses (pretrained) Fast R-CNN and FCN semantic segmentation model for table extraction problem.,0.0,Neutral
Reference [17] also uses (pretrained) Fast R-CNN and FCN semantic segmentation,0.0,Neutral
"Recently, (Schreiber et al., 2017) used the deep learningbased object detection model with pre-processing to recognize the row and column structures for the ICDAR 2013 dataset.",0.0,Neutral
"(Schreiber et al., 2017) presented a system that is totally data-driven and does not need any heuristics or metadata to detect as well as to recognize tabular structures on the ICDAR 2013 dataset.",0.0,Neutral
"Table II provides A comparison of the proposed system with the approaches presented in [15] and [14], trained on our proposed dataset.",0.0,Neutral
[14] used ICDAR 2013 table competition dataset for testing.,0.0,Neutral
[14] focuses on table detection and structure analysis as well.,0.0,Neutral
"This evaluation scheme is different from [5], [30] where they first compute",0.0,Neutral
the problem of table detection and recognition which makes the problem significantly harder to tackle [5]–[7].,0.0,Neutral
[5] (2017) where they utilized Faster R-CNN for detection of documents achieving state-of-the-art performance on ICDAR-2013.,0.0,Neutral
"5 for IoU to compute the F1-measure [5], we also evaluated our model based on this threshold.",0.0,Neutral
[6] and Gilani et al.,0.0,Neutral
"The latest approaches use deep learning for table detection and recognition [8], [9].",0.0,Neutral
"we compared the performance of the four different configurations of our method to those achieved by DeepDeSRT [59], Tran [34] and Hao [27] in detecting only tables on the ICDAR 2013 dataset.",0.5,Weak
"To ground our work with state of the art in table detection, we compared the performance of the four different configurations of our method to those achieved by DeepDeSRT [59], Tran [34] and Hao [27] in detecting only tables on the ICDAR
2013 dataset.",0.5,Weak
"915 for the tablestructure recognition and data extraction task, which outperformed that of a deep neural network-based method, DeepDeSRT (Schreiber et al., 2017), by 0.",0.0,Neutral
"As a result, their method achieved an F-measure value of 0.915 for the tablestructure recognition and data extraction task, which outperformed that of a deep neural network-based method, DeepDeSRT (Schreiber et al., 2017), by 0.07 percentage points.",0.0,Neutral
"2016) and (Schreiber et al. 2017) proposed table detection model in document image based on CNN and Faster R-CNN, respectively.",0.0,Neutral
"(Hao et al. 2016) and (Schreiber et al. 2017) proposed table detection model in document image based on CNN and Faster R-CNN, respectively.",0.0,Neutral
[18] proposed DeepDeSRT that employs the Faster R-CNN model for table detection and a semantic segmentation approach for structure recognition.,0.0,Neutral
"Recently, there has been a shift in the research literature from traditional rule-based methods [7–9] for TE to data-driven methods based on deep learning (DL) [2, 10, 11].",0.0,Neutral
"Recently, there has been a shift in the research literature from traditional rule-based methods [7–9] for TE to data-driven methods based on deep learning (DL) [2, 10, 11].",0.0,Neutral
"[20] use a fine-tuned version of popular object detection framework, Faster RCNN [4], to detect tables in document images.",0.0,Neutral
[5] first discovered that deep learning (DL) based “object detection” [6] in natural scene images can be successfully applied to the table detection in document images via the transfer learning.,0.0,Neutral
"From 2013 to date, in addition to the enhancement of these deterministic approaches, several new techniques based on machine learning algorithms have been introduced, like a method based on the identification of the horizontal and vertical lines classified through Support Vector Machine (SVM) [15] or methods based on Fast-RCNN (FRCNN) [34] trained on the Marmot dataset for table recognition [35].",0.0,Neutral
"Recently, there has been a shift in the research literature from traditional rule-based methods [7–9] 34 for table extraction to data-driven methods based on deep learning (DL) [2, 10, 11].",0.0,Neutral
"With the recent and rapid development of deep learning techniques, approaches employing convolutional neural networks (CNNs) have been proposed and have shown a superior detection accuracy [1], [2], [11].",0.0,Neutral
"However, table detection is a challenging task due to the high degree of intra-class variability and inter-class similarity between tables, as shown in 1(b) [2].",0.0,Neutral
[2] proposed a table detection system applying a completely data-driven method that does not require metadata of the document or heuristic rules for detection.,0.0,Neutral
"And we can see these problems in the multitude of methods currently available to detect tables in PDF documents [26, 27, 28, 29], where there is no author who proposes a general deterministic solution to identify tables in PDF documents[25].",0.0,Neutral
Trying to teach computers to see and also“understand” what is a table has proven be extremely difficult [25].,0.0,Neutral
", paragraphs, figures, lists, tables [49,41,30].",0.0,Neutral
"While there are other works [34,41] that perform table decomposition into rows and columns (which our model is capable of doing), we discuss table detection only in the scope of this paper.",0.0,Neutral
"The solution is suggested to be a deep neural network, which typically consists of several stacked deep neural networks ([2]), which reduces the problem to the object detection task.",0.0,Neutral
"In particular, deep neural networks and machine learning were shown to be very effective in the context of tabulating (see [2], [3], [4], [5]).",0.0,Neutral
"As contemporary works [47, 26, 2, 58] show the deep neural network models provide a good performance for the table detection.",0.0,Neutral
"The current trend involves deep learning techniques: binary classification based on convolutional neural networks [29], fine-tuned object detection models [47, 26, 2, 58], and semantic segmentation [30, 33].",0.0,Neutral
", [7, 13, 17, 18, 21, 29, 37, 44, 55, 56]) utilize a deep learning (DL)-based approach, focusing on either one, two, or all three steps.",0.0,Neutral
"[44] leveraged the ICDAR 2017 POD dataset to add table structural information in the annotations and propose TabStructDB, which includes just over a thousand table images.",0.0,Neutral
"[14] came up with a new table detection dataset (from document images) consisting of 1081 dense tables, collected from the ICDAR 2013 dataset, with the addition of structural information for all the tables in the dataset; and Li et al.",0.0,Neutral
Class Labels TabStructDB [14] TableBank [7] TNCR [6] TERED,0.0,Neutral
Fully convolutional networks minimize the complexity of recognizing table structure [90].,0.0,Neutral
"On the other hand, the problem of table structure recognition (TSR) is a lot more challenging and remains a very active area of research, in which many novel machine learning algorithms are being explored [3,4,5,9,11,12,13,14,17,18,21,22].",0.0,Neutral
"Object-detection based methods [11,12,13,14,21] rely on tablestructure annotation using (overlapping) bounding boxes for training, and produce bounding-box predictions to define table cells, rows, and columns on a table image.",0.0,Neutral
"Researchers in [37,41,40] have proposed to detect row/column regions based on segmentation and off-the-shelf object detectors.",0.0,Neutral
[28] 2019 DeeptabSTR ICDAR TabStructDB ICDAR 2013 - - NR,0.0,Neutral
"Another group of approaches [3, 30, 31] treated TSR as an object detection problem and used some object detection methods to directly detect the bounding boxes of rows and columns.",0.0,Neutral
Early works (Schreiber et al. 2017; Siddiqui et al. 2019) introduce segmentation or detection frameworks to locate and extract splitting lines of table rows and columns.,0.0,Neutral
"In this scenario, TSR usually deals with tables which are subareas of document images (Zuyev, 1997; Schreiber et al., 2017; Siddiqui et al., 2019a, 2019b; Zheng et al., 2021; Hashmi et al., 2021c), lines of plain-text (Kieninger, 1998; Ng et al., 1999; Hu et al., 2000), or text chunks and rulings…",0.0,Neutral
SA Siddiqui[51] ICDAR2013 Deformable CNN Precision 99.,0.0,Neutral
SA Siddiqui[51] ICDAR2013 Deformable CNN Precision 93.,0.0,Neutral
"Using the potential of deformable convolutional networks, SA Siddiqui [51] proposes a unique approach for analyzing tabular patterns in document",0.0,Neutral
SA Siddiqui[51] ICDAR2017 Deformable CNN Precision - - 96.,0.0,Neutral
SA Siddiqui [51] deformable CNN + Faster R-CNN 1) The use of deformable convolution can handle various tabular structures.,0.0,Neutral
TabStructDB TabStructDB is a different publicly available image-based table structure recognition dataset that was promoted by SA Siddiqui [51].,0.0,Neutral
"Although [34] treated tabular structure analysis as an objectfinding problem, there were significant dissimilarities between the two approaches.",0.0,Neutral
"Similar to previous works [8, 38, 46, 49, 51], the text content and structure information are obtained separately.",0.0,Neutral
"The first group of methods [49, 51, 52] starts by detecting the row and columns of a",0.0,Neutral
"Popular table structure recognition methods include DeepDeSRT [7], ReS2Tim [15], DeepTabStR [16], etc.",0.0,Neutral
"Quite a number of table recognition techniques have been reported in recent years [14]–[16], and most of them can be broadly classified into three categories.",0.0,Neutral
"Another group of approaches [8, 42] treated TSR as an object detection problem and used some object detection methods to directly detect the bounding boxes of rows and columns.",0.0,Neutral
"ICDAR-2017 [85], TabStructDB [94] 2017, 2019 1081 digital image yes",0.0,Neutral
"Information on datasets related to table recognition
Datasets Year Number of tables Source Format
Official split
train/val/ test
FUNSD [2] (IIT-CDIP [90])
2006, 2019 199 (15k) scan image yes
UNLV [91] 2010 558 scan image no Marmot [92] 2012 958 digital image no ICDAR-2013 [84] 2013 254 digital pdf yes CamCap [93] 2015 75 camera image no ICDAR-2017 [85], TabStructDB [94] 2017, 2019 1081 digital image yes ICDAR-2019 [86] modern 2019 340 digital image no ICDAR-2019 [86] historical 2019 1099 scan image yes ICDAR-2019 SROIE [95] 2019 1000 scan image yes IIIT-AR-13K [96] 2020 16k+ digital image no
Open datasets mainly consist of images of tables in digital sources, such as articles and open business documents (IIIT-AR-13K), mostly financial reports.",0.0,Neutral
"[19] proposed to formulate the problem of row/column identification in a tabular structure as an object detection problem instead of a semantic segmentation problem, and leveraged three",0.0,Neutral
"Hybrid Deep Learning-Rule-Based approach: A popular current model for table-structure identification is the use of a hybrid Deep Learning-Rule-Based approach similar to [27, 29].",0.0,Neutral
"For instance, in [26, 29, 30, 32], the authors considered columns and rows as object types and reconstructed table structures from the detected rows and columns.",0.0,Neutral
"[29] used a detection framework to alleviate the burden of the post-processing task of recovering spanning cells, but this method often failed to handle cells of multi-line contents.",0.0,Neutral
"In order to avoid the shortcoming of fCN-based table structure recognition method [9], which relies heavily on post-processing, [10] regards row and column recognition in table structure as a target detection problem, in which documents can be regarded as scenes, and rows and columns can be regarded as objects.",0.0,Neutral
[17] propose to use a combination of deformable convolutional networks with Faster R-CNN and FPN.,0.0,Neutral
[17] ICDAR 2013 ICDAR 2013 (Complete) N/A Í ü Í Row/Column Adjacency Custom ICDAR 2017 ICDAR 2013 (Test Set) relations Paliwal et al.,0.0,Neutral
"In the literatures [28, 27], methods were evaluated on ICDAR13-Table with table cell boxes instead of the original text-level bounding box annotations.",0.0,Neutral
"Recently, segmentation-based methods have been popular in table cell detection due to its statistical significance along table rows and columns [25, 27, 28].",0.0,Neutral
"For cell spatial location detection, we use the same evaluation metrics with recent methods [25, 27, 29, 28, 20].",0.0,Neutral
"2, with the success of deep learning, recent deep learning-based table structure recognition approaches can be divided into three categories: 1) identify cell bounding boxes through visual detection and segmentation methods [25, 27, 29, 28, 8]; 2) transform a table image into the markup sequence, such as LaTeX and HTML [10, 2]; and 3) explore the adjacency relation between different table cells [30, 22, 11].",0.0,Neutral
"Works of [30,31,32] firstly obtain the rows and columns regions using the detection or segmentation models and then intersect these two regions to obtain the grids of cells.",0.0,Neutral
"Though recent works [30,22,32,31] attempt to predict row/column regions or even invisible grid lines [33], they are limited to handle tables that cross span multiple rows/columns.",0.0,Neutral
868 - - - - - DeepTabStR [31] ICDAR 2013 0.,0.0,Neutral
The traditional anchors are given as input to K-means clustering technique along with the training datasets of ICDAR 2013 [18] and TabStructDB [33] in order to retrieve optimized anchors for each dataset.,0.0,Neutral
"[33] has treated the table structure analysis as an object detection problem, there are various considerable differences between the two methods.",0.0,Neutral
"Although few considerable efforts have also been made to recognize the tabular structures straight from images [28], [32], accurate structural recognition is far from achievable [33].",0.0,Neutral
"The pre-condition for the task of table structure recognition is the accurately detected tabular regions [32], [33].",0.0,Neutral
"While the system DeepTabStr [33] relied on memory-intensive deformable convolutions [34], our approach consists of intuitive utilization of Mask R-CNN [37] with optimized anchors along with a simple and effective post-processing method.",0.0,Neutral
This paper extends the idea of treating the problem of table structure recognition as an object detection problem [33].,0.0,Neutral
"Considering the diversity in the structures of rows and columns, it has been settled that the separate model performs better [33].",0.0,Neutral
"Furthermore, we have also surpassed the baseline results on the TabStructDB dataset [33].",0.5,Weak
The system DeepTabStr [33] has adopted Faster R-CNN [35] with deformable convolutions [34] while our proposed approach works with Mask R-CNN [37] exploiting optimized anchors to directly detect boundaries of respective rows and columns in a tabular image.,0.0,Neutral
"[27] in order to implement a direct comparison against the similar approaches [27], [32], [33].",0.0,Neutral
[10] introduced the concept of deformed convolution [11] and regarded the rows and columns of the table as the objects to be detected.,0.0,Neutral
Some other works use applied graph convolutional neural network technique [15] and segmentation-based method for table structure decomposition [2].,0.0,Neutral
"There are attempts of applying deep learning to detect tables and decompose table structure [2], [3].",0.0,Neutral
"DeepDeSRT[28] and DeepTabStr[32] split the ICDAR2013 test set into two parts, leaving only 31 of 156 tables for testing and the rest incorporated into training.",0.0,Neutral
"Top-down methods [19,33,34,37] try to split entire table images into rows and columns using detection or segmentation models, then cells can be obtained through row-column intersection.",0.0,Neutral
"2) The majority of them are not all-rounders, making them less effective in handling complicated scenarios such as wireless tables [25], oriented or distorted tables [31, 34–36, 47], tables with blank cells [44, 48], or tables without additional text annotations [21, 22, 33].",0.0,Neutral
"Graph-based research [21, 22, 33] treat detected text bounding boxes as table elements, construct graphs based on them, and use graph neural networks (GNNs) to predict whether two elements share a row or column, or cell.",0.0,Neutral
"Category 3, according to [36], is the hardest difficulty level, including tables with cell and column merging.",0.0,Neutral
"Researchers have also used graph neural networks for table recognition from images [24, 26, 33, 43].",0.0,Neutral
[26] uses a computer-vision feature augmented graph and a GNN for segmentation in order to perform table structure recognition.,0.0,Neutral
"One approach is using graph neural networks to encode structural information, capturing dependencies and relationships between elements (Qasim et al., 2019).",0.0,Neutral
Graph neural networks utilize both spatial and textual features [92].,0.0,Neutral
"They analyze the connection between cell relationships using a graph neural network [29,2,34,18].",0.0,Neutral
[27] [28] [29] [30] share the identical GNN structure.,0.0,Neutral
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR
"With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",0.0,Neutral
The method [34] employs DGCNN [44] to model interactions between visual and geometric feature vertices for their cell/row/column relations prediction.,0.0,Neutral
"the filed, which can be mainly categorized into boundary extraction-based methods [38, 31, 15, 41, 25] and element relationship-based methods [23, 4, 34, 36] according to the component type leveraged.",0.0,Neutral
"The first group are the single component-based methods, which rely on either boundary extraction [15, 25, 31, 38, 41] or element relationship [4, 23, 34, 36].",0.0,Neutral
"To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in",0.0,Neutral
"Recently, graph neural networks are also used for table structure recognition by encoding document images as graphs (Qasim et al., 2019).",0.0,Neutral
"Some other researchers aimed to classify the cell relationship to construct table structure [3], [35], [20], [52].",0.0,Neutral
"One group of bottom-up methods [3, 23, 32] treat words or cell contents as nodes in a graph and use graph neural networks to predict whether each sampled node pair is in the same cell, row, or column.",0.0,Neutral
"…mechanism (Vaswani et al. 2017) in LORE to avoid making additional assumptions about the distribution of table structure, rather than graph neural networks employed by previous methods (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021), which will be further discussed in experiments.",0.0,Neutral
"Previous methods employ heuristic rules based on spatial locations (Liu et al. 2022) or graph optimizations (Qasim, Mahmood, and Shafait 2019) to reconstruct the tables.",0.0,Neutral
"Following this work, there are models devoted to improving the relationship classification by using elaborated neural networks and adding multi-modal features (Qasim, Mahmood, and Shafait 2019; Raja, Mondal, and Jawahar 2020, 2022; Liu et al. 2021, 2022).",0.0,Neutral
"In experiment 2a, we replace the self-attention encoder with a graph-attention encoder similar to graph-based TSR models (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021) with an equal amount of parameters with LORE.",0.5,Weak
"[6] used a convolutional neural network [7] and graph neural network (GNN) [8] to identify table structures, the former for extracting image features and the latter for improving the correlation between vertices.",0.0,Neutral
"Recently, many studies have explored table extraction by solely leveraging neural networks (NNs) [14]–[16].",0.0,Neutral
"SR Qasim [115] Graph NN + CNN 1) This paper also presents a unique, memoryefficient training strategy based on Monte Carlo.",0.0,Neutral
SR Qasim [115] presents a graph network-based architecture for table recognition as a superior alternative to typical neural networks.,0.0,Neutral
They confirm their approach to the artificial table pictures [25] [26].,0.0,Neutral
"[34, 37, 45, 66] treat these cells as nodes in a graph and train another Graph Neural Network (GNN) to predict the relations.",0.0,Neutral
"For line detection, we take advantage of recent GNN proposals such as (Qasim et al., 2019) or (Carbonell et al.",0.0,Neutral
"To do this, a GNN based on (Qasim et al., 2019) is implemented with the aim of connecting the different words previously extracted as entity tags of interest in a same line.",0.5,Weak
"For line detection, we take advantage of recent GNN proposals such as (Qasim et al., 2019) or (Carbonell et al., 2021).",0.5,Weak
"In addition to object-detection-based methods, earlier methods leveraged the concepts of Fully Convolutional Networks (FCN) [43,44] and Graph Neural Networks (GNN) [37,45] to resolve table detection in document images.",0.0,Neutral
also use SynthTable proposed in TIES [4].,0.0,Neutral
"We conduct experiments on several popular benchmarks including PubTabNet [3] and SynthTable [4], our method achieves new state-of-the-art results.",0.0,Neutral
We also evaluate the SynthTable dataset proposed in TIES [4] that mainly consists of tables in diverse categories.,0.0,Neutral
"For example, TIES [4] combines CNN [17] and GNN [14] to construct a bottom-up model to recognize the table structure.",0.0,Neutral
"Therefore, we
6
also use SynthTable proposed in TIES [4].",0.0,Neutral
GNN for document understanding was first introduced for mainly key DLA sub-tasks that include table detection [25] and table structure recognition [23].,0.0,Neutral
Following ideas presented in Section II-C that have been proven successful for TD [36] and TSR [37] we enrich our graph nodes with positional and textual features.,0.0,Neutral
"A more recent work [10] proposes another meaning for TE, providing TD, TSR, and
TFA annotations.",0.0,Neutral
"TSR in segmented tables is addressed in [37] by classifying edges for cells, rows, and columns.",0.0,Neutral
"More recently, [38] reformulate the problem of TSR as an end-to-end table reconstruction through node classification.",0.0,Neutral
TSS is referred to as Table Structure Recognition (TSR) in [10] where the recognition of column and projected row headers is defined as Table Functional Analysis (TFA).,0.0,Neutral
"The proposed framework can address also TSR, but implementation details are still under investigation.",-1.0,P-NR
"TSR in segmented tables is addressed in [36] by classifying edges for cells, rows, and columns.",0.0,Neutral
In this way it will be possible to compare this approach with both TD and TSR methods.,0.0,Neutral
Following ideas presented in Section II-C that have been proven successful for TD [35] and TSR [36] we enrich our graph nodes with positional and textual features.,0.0,Neutral
"[37], [38], [14] employ graph neural networks to integrate multi-modal information and reconstruct tables by node correlations.",0.0,Neutral
"XXXXXXX thus facilitatingmany graph-related tasks from various fields including recommendations [7, 48], natural language processing [50, 54], drug discovery [27, 34], and computer vision [9, 32].",0.0,Neutral
"The first group [2, 20, 34, 49] treats words or cell contents as nodes in a graph and uses graph neural networks to predict whether each sampled node pair is in a same cell, row or column.",0.0,Neutral
"While there are many datasets for Table Detection and LIR [15,18,22,24,26, 57,63,70,71,87,90,98,99,100], some of them are not accessible anymore [18,24, 26,70].",0.0,Neutral
"We argue that the problems of KILE and LIR, as defined in Sec.",0.0,Neutral
"We define Line Item (LI) and the task of Line Item Recognition (LIR) as follows:
Definition 2 (LI).",0.0,Neutral
"Note that this definition of LIR allows: (i) detection of several tables with different item types, as well as different item types within a single table; (ii) a single field (e.g., a date) to belong to several line items.",0.0,Neutral
Definition 3 (LIR).,0.0,Neutral
"Certain relational understanding tasks already play the important role in building electronic archives and developing office automation, which include table structure recognition [24,25,27,31,33],",0.0,Neutral
"Now mainstream relational understanding tasks like table structure recognition [24, 25, 27, 31, 33], key information extraction [16, 17, 46] and reading order detection [37] are born with entitylevel.",0.0,Neutral
"One group of bottom-up methods [21, 25, 75, 76] treat words or cell contents as nodes in a graph and use graph neural networks to predict whether each sampled node pair is in a same cell, row, or column.",0.0,Neutral
"In the case of IETD, this OCR engine is implicit in the decoder similar to [24].",0.0,Neutral
"[10], a graph model is used for the structural analysis problem of documents.",0.0,Neutral
"The DL-based methods in [7, 11] are among the first to apply neural networks designed for object detection to table parsing.",0.0,Neutral
[24] regarded a table as a graph of text contents.,0.0,Neutral
"Some authors attempted to replace the heuristics with machinelearning methods [24, 25].",0.0,Neutral
"Therefore, recent methods [2, 30, 34] attempt to attack the problem via constructing visual cues of table elements as graphs and applying the deep graph model, such as Graph Convolutional Networks (GCN) [15] to reason their relationships.",0.0,Neutral
"With the development of deep learning, table structure recognition methods have recently advanced substantially on performance, which can be classified into three categories: boundary extractionbased [13, 22, 27, 35, 40], generative model-based [18, 46], and graph-based [2, 20, 30, 34] methods.",0.0,Neutral
The method [30] introduces DGCNN to predict the relationship between words represented by the appearance and geometry features.,0.0,Neutral
"Although many previous algorithms [2,13,18,20,22,30,31,34,35,40,45,46] have achieved impressive progress in the community, TSR is still a challenging task due to two factors of complicated tables.",0.0,Neutral
"Table structure recognition (TSR) aims to recognize the table internal structure to the machine readable data mainly presented in two formats: logical structure [18, 46] and physical structure [2, 13, 20, 22, 27, 30, 31, 34, 35, 40, 45].",0.0,Neutral
"In the similar spirit with works [30, 34], we adopt the following asymmetric edge function hΘ(xi,xj) = xi∥(xi − xj) to combine graph edge features to each node, which can be denoted as HΘ ∈ R ·(N−1)/2)×d .",0.0,Neutral
"For comparison, we also visualize the multi-head self-attention maps from the last blocks of “Transformer-Mixed” [42] and KNN (K = 5) selection heatmaps of all layers in DGCNN [30], where a lighter color indicates a closer relationship.",0.5,Weak
"To introduce richer table information, several methods [20, 30, 34] con-",0.0,Neutral
"In previous works using DGCNN [30, 34], only local context of each node is selected by k-Nearest Neighbors algorithm (KNN) to be aggregated into node feature.",0.0,Neutral
"3 compares the effectiveness of various extractors, including DGCNN [30] and Transformer [42], with ECE in our method.",0.5,Weak
"Similar to previous works [28, 31] using DGCNN, only 𝑘 nearest neighbours of each node are selected by k-Nearest Neighbors algorithm (KNN) to construct the local context which is applied by the CNN to aggregate the edge information into node feature D𝑖 ∈ R𝑁× 𝑑 ℎ for 𝑖-th head.",0.0,Neutral
"Furthermore, some methods [2, 19, 28, 31] attempt to construct the graphs of elements to reason the relationships.",0.0,Neutral
Qasim et al. [28] introduce DGCNN to build the relationships of the fused image and position features between text blocks to predict the relations between nodes.,0.0,Neutral
"Similar to previous works [28, 31] using DGCNN, only k nearest neighbours of each node are selected by k-Nearest Neighbors algorithm (KNN) to construct the local context which is applied by the CNN to aggregate the edge information into node feature Di ∈ RN× d h for i-th head.",0.0,Neutral
"As for the sparse context, we build SCA upon DGCNN [28] to softly introduce the relational inductive bias to our model and enable it to learn sparse contextual information in local pattern.",0.5,Weak
[28] introduce DGCNN to build the relationships of the fused image and position features between text blocks to predict the relations between nodes.,0.0,Neutral
"For the relational reasoning aspect, recent mainstream algorithms [2, 19, 28, 31] construct table elements as contextual graphs and apply the graph-based aggregator, such as Graph Convolutional Networks (GCN) [14], to reason their relationships.",0.0,Neutral
"In addition, considering memory complexity of the classification between each proposal pair, we also introduce Monte Carlo sampling [28] to generate a fixed number of samples.",0.0,Neutral
"Among existing methods, many of them [2, 19, 28] regard off-line extracted meta-data or OCR results as table elements for the subsequent reconstruction of table structure.",0.0,Neutral
"For example, literature [28] simply exploits k-Nearest Neighbors algorithm (KNN) to build local context in a hard-coded way.",0.0,Neutral
"To achieve this purpose, existing computer vision methods either predict cell bounding boxes [6, 13], explore the adjacency relation between different cells [11, 15], or transform a table image into the markup sequence (e.",0.0,Neutral
"Other approaches include those based on image-to-text [8] and graph-based approaches [2,14].",0.0,Neutral
"As this assumption does not hold on to more challenging tables, some researches tried to get rid of the wellaligned assumption and modeled the table structure parsing problem with graph convolution networks [2, 13, 24].",0.0,Neutral
"For a more practical requirement of parsing table structures from images taken by hand-held cameras in the wild, the existing state-of-the-art approaches [13, 14, 11, 16, 9, 23] are prone to fail as the commonly-used assumption of tabular images no longer holds.",0.0,Neutral
"Although researchers have employed Fully Convolutional Network (FCN) [47,48] and Graph Neural Network (GNN) [34,49] to perform table detection in document images, object detection-based approaches [7,8,11,12,19,20,30–34] have delivered state-of-the-art results.",0.0,Neutral
The graph neural network is also used in [27].,0.0,Neutral
"A recent application example was the detection of tables in case of administrative document images [21,20].",0.0,Neutral
"Generally, these methods can be divided into the edge classification [1, 22, 11, 30] and the node classification [15].",0.0,Neutral
"2, with the success of deep learning, recent deep learning-based table structure recognition approaches can be divided into three categories: 1) identify cell bounding boxes through visual detection and segmentation methods [25, 27, 29, 28, 8]; 2) transform a table image into the markup sequence, such as LaTeX and HTML [10, 2]; and 3) explore the adjacency relation between different table cells [30, 22, 11].",0.0,Neutral
"The techniques employed in extracting tabular data from images usually involves advanced machine techniques such as Deep learning [3], Graph Neural networks [4] etc.",0.0,Neutral
"The works by Schreiber et al. (2018); Qasim, Mahmood, and Shafait (2019) draw upon deep neural networks to identify table structures for rendered inputs.",0.0,Neutral
"GCNs have been applied to other structured document tasks, such as table extraction [13,15].",0.0,Neutral
"Inspired by [24], we adopt the algorithm of Maximum Clique Search [1] to find all maximum cliques in the graph.",0.5,Weak
"With the great success of deep neural network in computer vision field, works began to focus on the image-based table with more general structures [21,30,24,9,13,36,23,14,33].",0.0,Neutral
[24] alleviates the problem of large graph nodes numbers by the pair sampling strategy.,0.0,Neutral
"The above three works [14,2,24] also published new table datasets for this research area.",0.0,Neutral
"Another type of methods [11,2,14,24,26] treat the detected boxes as nodes in a graph and attempt to predict the relations based on techniques of Graph Neural Networks [29].",0.0,Neutral
"That is why many segmentation-based methods [24,23,22] struggle with complicated post-processing, such as fracture completion and threshold setting.",0.0,Neutral
"Following the same naming convention with [14,2,24], the connecting relations can be divided into horizontal and vertical types.",0.0,Neutral
"Another group of methods solves the above problems in a bottom-up way to firstly detect the text blocks’ positions and then recover the bounding-boxes’ relations by heuristic rules [38] or GNN(Graph Neural Networks) [29,14,2,24,26].",0.0,Neutral
"(2019) argued that graph networks are a more natural choice for table recognition problem, and they further explored two gradient-based graph neural networks for this issue [24].",0.0,Neutral
"Furthermore, Qasim et al. (2019) argued that graph networks are a more natural choice for table recognition problem, and they further explored two gradient-based graph neural networks for this issue [24].",0.0,Neutral
[28] published a method to synthetically create camera captured images from the UNLV dataset.,0.0,Neutral
"It is important to mention that apart from these two approaches, other methods [28], [30], [100] have extracted the contents of cells in order to recognize either the tabular boundaries or tabular structures.",0.0,Neutral
[28] Graph Neural Networks with Convolutional Neural Networks (Section III-B2).,0.0,Neutral
FIGURE 11: Example of a synthetically created camera captured image by linear perspective transform method [28].,0.0,Neutral
[28] exploited the graph neural networks to perform table recognition for the first time.,0.0,Neutral
[28] which is explained in Section III-A3 did not use any well known dataset to evaluate their approach.,0.0,Neutral
[17] made use of Graph Neural Networks for generating cell adjacency matrix for all existing OCR detected words and Tensmeyer et al.,0.0,Neutral
"[17] GNN model, makes use of large proprietary dataset to train the network for an effective model to be tested on ICDAR 2013.",0.0,Neutral
[17] mentions that lack of large datasets has been a major hindrance for Deep Learning methods in table structure recognition and makes use of synthetic data to show the effectiveness of their network.,0.0,Neutral
[25] use a graph neural network to identify cell locations within tables.,0.0,Neutral
"Many previous works [22, 26, 23] and tools 16 have been developed to identify and parse table structures.",0.0,Neutral
"Most recently, Graph Neural Networks [25] have also been used in table detection [23].",0.0,Neutral
"[12] applied Graph Neural Network (GNN) to the table structure recognition task, effectively",0.0,Neutral
"Convolutional neural networks [150, 151], fully-convolutional neural networks [152, 153], region-based convolutional neural networks [154, 155, 156, 157], and graph neural networks [158, 159] have all been exploited to parse the physical layout of documents or to detect elements of interest (e.",0.0,Neutral
Some other works use applied graph convolutional neural network technique [15] and segmentation-based method for table structure decomposition [2].,0.0,Neutral
"(2019 [9]) presented a method that combined the advantages of convolutional neural network and graph neural network, so that the effect is better than the traditional neural network.",0.0,Neutral
(2019 [9]) presented a method that com-,0.0,Neutral
"Therefore, we firstly generate a synthetic dataset with the aid of the open code [10].",0.5,Weak
"When compared with the method in [10], our proposed method can still get considerable results on tables in Category 3 and Category 4.",0.5,Weak
"Some recent approaches [10], [11] utilize Graph Convolutional Network to predict the relationship between word (or cell).",0.0,Neutral
Table images in different categories [10].,0.0,Neutral
[10] divide the relationships between words into three types: belonging to the,0.0,Neutral
"search for structure analyses (Li et al., 2020; Qasim et al., 2019; Zhong et al., 2019).",0.0,Neutral
"The lack of large-scale labeled document datasets has been recognized as a major hindrance in deep-learning research for structure analyses (Li et al., 2020; Qasim et al., 2019; Zhong et al., 2019).",0.0,Neutral
"Different statistical models have been used, for example, probabilistic modelling [30], the Naive Bayes classifier [31], [32], decision trees [33], [34], Support Vector Machine [33], [35], Conditional Random Fields [35]–[37], graph neural network [14], [38], [39], attention module [40], etc.",0.0,Neutral
and table recognition [39].,0.0,Neutral
"Considering memory efficiency, we also introduce Monte Carlo sampling for constructing collaborative graph embedding pairs in the training phase, which is similar to [12].",0.0,Neutral
They presented a new large-scale synthetic dataset for the problem of table recognition [17].,0.0,Neutral
B Categories of table styles in the synthetic dataset The synthetic dataset introduced in [4] contains four categories of table styles.,0.0,Neutral
S3: Sample table image of the four categories of table styles defined in [4].,0.0,Neutral
"Bottom-up methods [5,26,27,40] first detect cells or text segments using detection models or OCR engines, then analyze the relations between neighbouring cells using GNN or LSTM.",0.0,Neutral
"Experimental results indicate that our model achieves robustness across different transformations (all transformations, including scaling, rotation, adding noise, blurring, random cropping, and more) [46].",0.0,Neutral
"Furthermore, to assess the effectiveness of our method in oriented and distorted scenarios, we compare it with two mainstream open-source methods, SPLERGE [39] and Table-Master [44], on the TAL, TAL_rotated, and TAL_curved datasets.",0.5,Weak
"Furthermore, to assess the effectiveness of our method in oriented and distorted scenarios, we compare it with two mainstream open-source methods, SPLERGE [39] and TableMaster [44], on the TAL, TAL_rotated, and TAL_curved datasets.",0.5,Weak
"In [8, 20, 27, 39, 46], a table is represented by a grid of regions.",0.0,Neutral
This system works well on both PDF and scanned document images [91].,0.0,Neutral
"TRACE employs a split-merge strategy, inspired by SPLERGE [45], to reconstruct tables.",0.0,Neutral
"In recent years, a split-merge approach has emerged as a popular technique for TSR, in which the separators between cells are initially detected and then subsequently merged [45,14,48,19,25].",0.0,Neutral
Tensmeyer et al.[31]4 2019 SPLERGE ICDAR Web-screaped PDFs + ICDAR 2013 ICDAR 2013 - X NR,0.0,Neutral
"The results shown in Figure 3 and Figure 4 indicate that none of the 4 methods that allow inference on custom data [13, 17, 16, 31] was replicable with respect to the GenTSR dataset, under a threshold of 10% absolute F1-score.",-2.0,O-NR
"To alleviate this problem, methods like [4, 6, 29] tried different context enhancement techniques, e.",0.0,Neutral
"Under the new evaluation setting, the result of SPLERGE significantly drops by 10.2% absolutely in F1-score.",-2.0,O-NR
"Among these methods, SPLERGE [6] was the first to deal with spanning cells, which proposed to add a simple cell merging module after a row/column extraction module to recover spanning cells by merging adjacent cells.",0.0,Neutral
"The SPLERGE [41] divides table into grid elements and merges adjacent ones to restore spanning cells, where the boundary ambiguity issue still remains unsolved.",0.0,Neutral
"With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",0.0,Neutral
"TRUST [9] has the similar spirit with SPLERGE [41], where the features of row/column separators are extracted for a further vertex-based merging module to predict the linking relations between adjacent cells, which thus still suffers from boundary ambiguity problem.",0.0,Neutral
"Method #Param FLOPs GPU CPU SPLERGE [41] 0.37 115.49 0.95 24.25 TabStruct-Net [36] 68.63 3719.06 22.63 76.52 FLAG-Net [23] 17.00 71.69 0.13 2.37 GrabTab 57.88 513.65 0.82 11.54
Table H4.",0.0,Neutral
Method #Param FLOPs GPU CPU SPLERGE [41] 0.,0.0,Neutral
"the filed, which can be mainly categorized into boundary extraction-based methods [38, 31, 15, 41, 25] and element relationship-based methods [23, 4, 34, 36] according to the component type leveraged.",0.0,Neutral
"The first group are the single component-based methods, which rely on either boundary extraction [15, 25, 31, 38, 41] or element relationship [4, 23, 34, 36].",0.0,Neutral
"To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in",0.0,Neutral
The SPLURGE method [47] proposed the idea of table splitting and merging.,0.0,Neutral
C Tensmeyer [120] Dilated Convolutions + Fully CNN The technique is effective with both scanned and PDF document images.,0.0,Neutral
"C Tensmeyer [120] has presented SPLERGE (Split and Merge), another method using dilated convolutions.",0.0,Neutral
C Tensmeyer[120] ICDAR2013 Dilated Convolutions + Fully CNN Precision 95.,0.0,Neutral
[31] used dilated convolutions but depend upon heuristics approaches during post-processing [12].,0.0,Neutral
"To handle the cells crossing multiple rows/columns, [59, 71] predicts another indicator to merge the separated cells.",0.0,Neutral
"For example, SPLERGE [10] first predicts the basic table grid pattern using Row Projection Networks and Column Projection Networks with novel projection pooling and then combines them to get table structure.",0.0,Neutral
"However, recent Splitting-based approaches such as SPLERGE [10] and SEM [11] may suffer from following disadvantages: (1) The pipeline of SEM is inefficient, which may involve time-consuming Region of Interest (RoI) [12] operations and context features extraction via BERT [13].",0.0,Neutral
"Split: split model proposed in SPLERGE [10], QBS: Query-Based Splitting Module, Heuristic: Heuristic Post-processing, Merge: merge model proposed in SPLERGE [10], VBM: Vertex-Based Merging Module",0.0,Neutral
We expanded the definition of splitter in SPLERGE [10] to support inclined separators.,0.5,Weak
Splitting Model Merging Model Performance(Pubtabnet/SynthTable(C4)) # Split [10] QBS Heuristic [10] Merge [10] VBM Str-TEDs TEDs,0.0,Neutral
"Compared with the training of two independent modules in SPLERGE [10], the whole framework of TRUST can be trained in an end-to-end manner and achieve better performance.",0.0,Neutral
"To evaluate this module, we replace the Query-Based Splitting Module with the Split Model proposed in SPLERGE [10].",0.5,Weak
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc.",0.0,Neutral
"In contrast, some work, such as DeepDeSRT [8], CascadeTabNet [9] and TableDet [10], using top-down approaches would define the structural recognition as object detection or segmentation problem, often together with table detection problem.",0.0,Neutral
"All six axes add up to the unique, complete generic identity for the examination, as per the LONIC nomenclature guideline (31).",0.0,Neutral
"Among these methods, only SPLERGE [45] can deal with spanning cells, which proposed to add a simple cell merging module after a row/column extraction module to recover spanning cells by merging adjacent cells.",0.0,Neutral
"To alleviate this problem, methods like [13, 43, 45] tried different context enhancement techniques, e.",0.0,Neutral
"In order to verify the effectiveness of TSRFormer for more challenging borderless tables, we re-implement another split-and-merge based method SPLERGE [45] and compare our approach with it on serveral datasets.",1.0,Strong
", [45]), we formulate separation line prediction as a line regression problem instead of an image segmentation problem and propose a new separator prediction approach, dubbed Separator REgression TRansformer (SepRETR), to predict separation lines from table images directly.",0.0,Neutral
"As shown in Table 4, the re-implemented SPLERGE can achieve competitve results on SciTSR and PubTabNet datasets while it is still 11.4% worse than TSRFormer in F1-score on our challenging in-house dataset.",-2.0,O-NR
"The table can therefore be represented as a grid [68,78].",0.0,Neutral
"[17], didn’t take spanning cells into consideration and can only recover the basic grid structures of tables.",0.0,Neutral
1st row: original images; 2nd row: results from SPLERGE [17]; 3rd row: results from our table structure recognizer.,0.0,Neutral
"Following SPLERGE [17], we calculate the GT separator masks by maximizing the size of the separation regions without intersecting any non-spanning cell contents, as shown in Fig.",0.0,Neutral
"As shown in Table 8, our approach outperforms SPLERGE significantly by improving the WAvg.",0.0,Neutral
"As shown in Table 7, our approach outperforms the closest method, SPLERGE [17], substantially by improving the WAvg.",0.0,Neutral
"[17] presented the SPLERGE method, which used a Split model to produce the grid structure of an input table first, and then used a Merge model",0.0,Neutral
"To further validate the robustness of our approach to distorted or even curved table images, we conducted
experiments on the in-house dataset and compared our table structure recognizer with SPLERGE.",0.5,Weak
"Following SPLERGE [17], we calculate the GT separator masks by maximizing the size of the separation regions",0.0,Neutral
"SPLERGE [17] 75.9 55.2 63.9 75.8 55.1 63.8 75.7 55.0 63.7 75.7 55.0 63.7 63.8 Ours 94.9 94.5 94.7 94.8 94.4 94.6 94.8 94.4 94.6 94.7 94.3 94.5 94.6
CornerNet based table proposal generation algorithm for achieving higher localization accuracy and better end-to-end table detection results.",0.0,Neutral
"To deal with spanning cells, Tensmeyer et al. [17] presented the SPLERGE method, which used a Split model to produce the grid structure of an input table first, and then used a Merge model to predict which grid elements should be merged to recover spanning cells.",0.0,Neutral
"vanilla FCN based row/column segmentation method cannot robustly predict complete segmentation masks for rows and columns when tables contain large blank spaces [16, 17].",0.0,Neutral
"SPLERGE [17], substantially by improving the WAvg.",0.0,Neutral
"[32] proposed a method called SPLERGE, which first split tables into rows and columns (split module) and recovered the spanning cells using FCN (merge module).",0.0,Neutral
"Although we tried to train split network with the same training data we used, we failed to reproduce their results and used the model trained by the authors [32].",-2.0,O-NR
SPLERGE [32] predicts cell-regions from table images using split and merge modules.,0.0,Neutral
"For example, the authors of [32] used their private collection of 93,000 tables.",0.0,Neutral
"For instance, in [26, 29, 30, 32], the authors considered columns and rows as object types and reconstructed table structures from the detected rows and columns.",0.0,Neutral
"of parameters CascadeTabNet [23] 82,852,033 TabStructNet [25] 68,636,098 SPLERGE [32] 255,862 Ours 1,120,692",0.0,Neutral
"8 Examples of qualitative results on complex tables, the colored regions are the recognized cell regions: Table structure recognition results of (a) CascadeTabNet  [23], (b) TabStructNet  [25], (c) SPLERGE [32], and (d) the proposed method",0.0,Neutral
"We compare the performance of our method with three coventional methods: CascadeTabNet [23], TabStructNet [25], and SPLERGE [32].",0.0,Neutral
"Results of CascadeTabNet [23], TabStructNet [25], SPLERGE [32], and the proposed method, from top to bottom 5844 Multimedia Tools and Applications (2022) 81:5827–5848",0.0,Neutral
"(a) Result from CascadeTabNet [23], (b) TabStructNet [25] with ground truth table locations, (c) SPLERGE [32] with ground truth table locations, and (d) result from the proposed method 5845 Multimedia Tools and Applications (2022) 81:5827–5848",0.0,Neutral
91 - - - - - - - - - - - SPLERGE(H) [30] Private 0.,0.0,Neutral
"While these methods contribute to significant progress, they make certain assumptions like the availability of accurate word bounding boxes, machine readable PDF documents, and others, as additional inputs [18, 22, 4, 30].",0.0,Neutral
95 - - - - - - - - - - - SPLIT [30] Private SEC 0.,0.0,Neutral
"Table structure recognition generates a machine-interpretable output for a given table image, which encodes its layout according to a pre-defined standard [30, 17, 20, 42, 4, 39, 24].",0.0,Neutral
"In order to compare our method against others on TUCD dataset, we develop our implementation of DeepDeSRT [26], and use open source implementations of DGCNN (TIES) [22], SPLERGE [30], and TabStruct-Net [24].",0.5,Weak
"A combination of heuristics and deep learning methods was also proposed [30] based on splitting the table into sub-cells, and then merging semantically connected",0.0,Neutral
"[35] train the SPLERGE to split the grid structure of table and merge adjacent spanning cells, which is still unable to achieve decent results for the skew table images.",0.0,Neutral
DeepDeSRT [32] - - SPLERGE [35] SciTSR + ICDAR-2019 0.,0.0,Neutral
"They can be categorized into two groups: non-table-element-based approaches [13, 17, 25, 32, 35, 44] and tableelement-based approaches [2, 19, 27–29, 31, 41, 43].",0.0,Neutral
Method #Param FLOPs GPU CPU SPLERGE [35] 0.,0.0,Neutral
"To solve this problem, Tensmeyer et al. [35] train the SPLERGE to split the grid structure of table and merge adjacent spanning cells, which is still unable to achieve decent results for the skew table images.",0.0,Neutral
"Although the model size of SPLERGE [35] is the smallest among the compared methods, it spends round 7 times GPU time and 12 times CPU time than our Session 10: Industrial Track MM ’21, October 20–24, 2021, Virtual Event, China",0.0,Neutral
"Although the model size of SPLERGE [35] is the smallest among the compared methods, it spends round 7 times GPU time and 12 times CPU time than our",0.0,Neutral
"Different from the previous table structure recognition methods [6, 7, 8] which mostly recover the table structure based on the visual modality, we fuse the output features for each basic table grid from both vision and language modalities.",0.0,Neutral
"Analyzing tabular data in unstructured documents focuses mainly on three problems: i) table detection: localizing the bounding boxes of tables in documents [18, 19], ii) table structure recognition: parsing only the structural (row and column layout) information of tables [4, 7, 8], and iii) table recognition: parsing both the structural information and content of table cells [6].",0.0,Neutral
"Although significant efforts have been made in the past to recognize the internal structure of tables through an automated process [4, 6, 7, 8, 9, 10], most of these methods [4, 11] only focus on simple tables and are hard to accurately recognize the structure of complex tables.",0.0,Neutral
"For cell spatial location detection, we use the same evaluation metrics with recent methods [25, 27, 29, 28, 20].",0.0,Neutral
"In [8, 28, 29], they classify an entire row or column into the cell or non-cell categories instead of the pixel-wise classification.",0.0,Neutral
[29] trained the SPLERGE model on a private dataset and evaluated it on ICDAR13-Table by randomly choosing a subset as well.,0.0,Neutral
"2, with the success of deep learning, recent deep learning-based table structure recognition approaches can be divided into three categories: 1) identify cell bounding boxes through visual detection and segmentation methods [25, 27, 29, 28, 8]; 2) transform a table image into the markup sequence, such as LaTeX and HTML [10, 2]; and 3) explore the adjacency relation between different table cells [30, 22, 11].",0.0,Neutral
Table structure recognizer is our own implementation of the model proposed in [13].,0.5,Weak
[33] detects the rows and columns by learning the interval areas’ segmentation between rows/columns and then predicting the indicator to merge the separated cells.,0.0,Neutral
"With the great success of deep neural network in computer vision field, works began to focus on the image-based table with more general structures [21,30,24,9,13,36,23,14,33].",0.0,Neutral
"Though recent works [30,22,32,31] attempt to predict row/column regions or even invisible grid lines [33], they are limited to handle tables that cross span multiple rows/columns.",0.0,Neutral
"…TABBIE’s pretraining task of corrupt cell detection, which again is practically useful as a postprocessing step after table structure decomposition (Tensmeyer et al., 2019; Raja et al., 2020) because mistakes in predicting row/column/cell boundaries (sometimes compounded by OCR errors) can lead…",0.0,Neutral
"…for tabular data, as corrupt cell detection is actually a fundamental task in table structure decomposition pipelines such as (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicted row/column separators or cell boundaries can lead to corrupted cell text.",0.0,Neutral
"While this objective was originally motivated as enabling more efficient training compared to BERT’s masked language modeling objective, it is especially suited for tabular data, as corrupt cell detection is actually a fundamental task in table structure decomposition pipelines such as (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicted row/column separators or cell boundaries can lead to corrupted cell text.",0.0,Neutral
"We emphasize that this pretraining objective is a fundamental task in table structure decomposition pipelines (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicting row/column separators or cell boundaries leads to corrupted cell text.",0.0,Neutral
"We first examine how TaBERT performs on TABBIE’s pretraining task of corrupt cell detection, which again is practically useful as a postprocessing step after table structure decomposition (Tensmeyer et al., 2019; Raja et al., 2020) because mistakes in predicting row/column/cell boundaries (sometimes compounded by OCR errors) can lead to inaccurate extraction.",0.0,Neutral
"We intentionally leave out the Partial Detections, Missed Segments, and False Positive Detections from our evaluation metrics, as due to the problem formulation of Split Model [23] they always evaluate to zero.",0.0,Neutral
"[23] on table structure recognition, we see a more stable and natural approach towards the formulation of problem.",0.0,Neutral
"Following the promising results of Split-model [23] trained on the publicly available ICDAR 2013 dataset using TabAug, we believe our work provides a strong foundation for numerous future extensions.",0.0,Neutral
"[23], even though more data-efficient than Qasim et al.",0.0,Neutral
"[23] formulating the problem of structure recognition as a combination of row, column splits and cell mergings for defining the structure of a table.",0.0,Neutral
"This ground-truth format is used for the augmentation process, however, Split model [23] requires pixel-wise annotations.",0.0,Neutral
"promising results of Split-model [23] trained on the publicly available ICDAR 2013 dataset using TabAug, we believe our work provides a strong foundation for numerous future extensions.",0.0,Neutral
[23] on ICDAR 2013 dataset reveals sub-optimal results than the network potential due to the lack of diverse and large training dataset.,0.0,Neutral
"To evaluate the efficacy of our proposed augmentation methodology, we train the Split model proposed by [23] on ICDAR 2013 dataset.",0.5,Weak
[55] Dilated Convolutions in Fully Convolutional Networks (Section III-B4b).,0.0,Neutral
"[6] proposed a top-down and then bottomup two-stage table structure recognition method called SPLERGE, which is divided into two parts: Split and Merge.",0.0,Neutral
"To capture long-range column and row features globally, we add our proposed TPM at each downsampling shortcut of ResNet backbone inspired by [17], where they utilize the row projection and column projection with maximum pooling to downsample.",0.0,Neutral
In [17] an approach of capturing global information with row pooling and column pooling was used.,0.0,Neutral
"More recently, [17] extended the traditional approach of detecting table separation lines by predicting table grid with Split model and predicting the merge of grid elements with Merge model.",0.0,Neutral
SPLERGE [20] model is free from spanning cells.,0.0,Neutral
"Among these, the problem of table structure recognition has been of high interest in the community [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20].",0.0,Neutral
"In the space of document images, researchers have been working on understanding equations [30,31], figures [32,33] and tables [6,7,8,9,10,11,12,13,14,15,16,17].",0.0,Neutral
"[10] presented another interesting deep model, called splerge, which is based on the fundamental idea of first splitting the table into sub-cells, and then merging semantically connected sub-cells to preserve the complete table structure.",0.0,Neutral
"Table structure recognition is a challenging problem due to complex structures and high variability in table layouts [4,5,6,7,8,9,10,11,12,13,14,15,16,17].",0.0,Neutral
"It can be represented in the form of either physical [10,12,14,17] ar X iv :2 01 0.",0.0,Neutral
"Many cognitive methods [6,7,8,9,10,11,12,14,15,16,37,38,39,40,41,42,43] have also been presented to understand table structures as they are robust to the input type (whether being scanned images or native digital).",0.0,Neutral
"split+heuristic [10] method outperforms tabstruct-net by a small margin, however, it requires icdar-2013 dataset-specific cell merging heuristics and is trained on a considerably larger set of images.",0.0,Neutral
", meta-features extracted from the pdfs [10], content-level bounding boxes from ground truths [12,14] and cell’s location features generated from synthetic dataset [9]).",0.0,Neutral
"Table structure recognition refers to representation of a table in a machinereadable format, where its layout is encoded according to a pre-defined standard [10,11,12,13,14,17].",0.0,Neutral
"We compare the performance of our tabstruct-net against seven benchmark methods — deepdesrt [7], tablenet [12], graphtsr [14], splerge [10], dgcnn [9], Bi-directional gru [15] and Image-to-Text [11].",0.0,Neutral
"Recently, a lot of works use deep learning method have been proposed [11], [12], [13], [14].",0.0,Neutral
In the last few years an important research topic in DIAR has been the analysis of tables in contemporary documents by using graph neural networks [49] or dealing directly with PDF documents [50].,0.0,Neutral
"Deep learning approaches include two categories: (a) End-to-end image-to-sequence models [18, 36]; (b) Object detection based methods [26, 33, 23].",0.0,Neutral
"Most existing work on object detection-based methods detect entire rows and column separately, and represents the intersection of detected rows and columns as cells [26, 33].",0.0,Neutral
"olutional neural network to determine whether the regions contain a table [22]. Fullyconvolutional neural networks, followed by a conditional random ﬁeld, have also been used for table detection [23]–[25]. In addition, deep neural networks for object detection, such as Faster-RCNN [26], Mask-RCNN [27], and YOLO [28] have been exploited for table detection and row/column segmentation [7], [29]–[31]. Fu",0.0,Neutral
Table structure recognizer is our own implementation of the model proposed in [13].,0.5,Weak
"Top-down methods [19,33,34,37] try to split entire table images into rows and columns using detection or segmentation models, then cells can be obtained through row-column intersection.",0.0,Neutral
"Deep learning approaches [16,17,18] do not rely on rules and can accurately generalize the problem.",0.0,Neutral
"Later, more efficient single-stage object detectors like RetinaNet [58] and YOLO [59] and two-stage object detectors like Fast R-CNN [11], Faster R-CNN [12], Mask R-CNN [60], and Cascade Mask R-CNN [61] were applied for other document objects such as figures and formulas detection in document images [62,63,64,65,66,67,68,16,17,18].",0.5,Weak
"Another group of approaches [3, 30, 31] treated TSR as an object detection problem and used some object detection methods to directly detect the bounding boxes of rows and columns.",0.0,Neutral
[8] recently reported an F-score of 0.,-2.0,O-NR
"…candidates on document images (Shafait and Smith, 2010; Schreiber et al., 2017; Siddiqui et al., 2018; Paliwal et al., 2019; Prasad et al., 2020; Hashmi et al., 2021b; Zheng et al., 2021); TD searches for text lines signaling table candidates in plain-text (Hu et al., 1999; Ng et al., 1999;…",0.0,Neutral
"According to Hashmi et al. (2021a), on “ICDAR2013 Table Competition” dataset (Göbel et al., 2013), F1-score is close to 1.0 for TD when the threshold of
“Intersection Over Union” (IOU) equals 0.5, and this score reaches 0.95 (IOU = 0.5) for TSR.",0.0,Neutral
"…deals with tables which are subareas of document images (Zuyev, 1997; Schreiber et al., 2017; Siddiqui et al., 2019a, 2019b; Zheng et al., 2021; Hashmi et al., 2021c), lines of plain-text (Kieninger, 1998; Ng et al., 1999; Hu et al., 2000), or text chunks and rulings clipped from PDFs (Hassan…",0.0,Neutral
"…(e.g., Hu et al. (2002); Wang et al. (2004); Shahab et al. (2010); e Silva (2011); Fang et al. (2012b); Göbel et al. (2012)) and datasets (e.g., SciTSR12, TableBank13, PubTabNet14) for the assay and comparison of proposals for the TD/TSR steps; Hashmi et al. (2021a) summarize them comprehensively.",0.0,Neutral
"The recent surveys summarize and compare the existing solutions intended for table detection and recognition in document images (Hashmi et al., 2021a), web table extraction (Rold an et al., 2020), analysis of heterogenous tables (Bonfitto et al., 2021), spreadsheet data transformation (Bonfitto et…",0.0,Neutral
"The task statements of TD/TSR are essentially different for DTE (Zanibbi et al., 2004; Hashmi et al., 2021a), WTE (Rold an et al., 2020; Zhang and Balog, 2020), and STE (Bonfitto et al., 2021).",0.0,Neutral
Hashmi et al. (2021a) provide a systematic review of the deep learning-based methods for the tasks of table detection and recognition in document images.,0.0,Neutral
"In the past decades, considerable efforts were dedicated to developing methods and software for the individual steps of TU and some combinations of these steps (Rold an et al., 2020; Zhang and Balog, 2020; Bonfitto et al., 2021; Hashmi et al., 2021a).",0.0,Neutral
KA Hashmi[118] ICDAR2013 Object Detection Methods Precision 95.,0.0,Neutral
"To identify rows and columns in tables, KA Hashmi [118] suggested a",0.0,Neutral
"To identify rows and columns in tables, KA Hashmi [118] suggested a
guided technique for table structure identification.",0.0,Neutral
KA Hashmi [118] Utilizing an optimization technique for anchors+ Mask RCNN Networks of region proposals converge more quickly and effectively thanks to optimized anchoring.,0.0,Neutral
This further urges the development of robust systems and techniques for information extraction from these raw document images [1].,0.0,Neutral
[1] for retrieval of finer anchors and thus improve performance.,0.0,Neutral
"Another group of approaches [8, 42] treated TSR as an object detection problem and used some object detection methods to directly detect the bounding boxes of rows and columns.",0.0,Neutral
"[20] adopted another object detection model, i.",0.0,Neutral
"These case of close false positives can be resolved by leveraging the instance segmentation networks where an additional segmentation loss is added along with the bounding box and classification loss [12,17,19].",0.0,Neutral
[51] proposed a guided table structure recognition method to detect rows and columns in tables.,0.0,Neutral
"In recent years, a split-merge approach has emerged as a popular technique for TSR, in which the separators between cells are initially detected and then subsequently merged [45,14,48,19,25].",0.0,Neutral
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR
Khan et al.[33]3 2020 No name ICDAR UNLV ICDAR 2013 - X NR,0.0,Neutral
"To alleviate this problem, methods like [4, 6, 29] tried different context enhancement techniques, e.",0.0,Neutral
"With the same goal, bidirectional GRUs [15] extracts the boundaries of rows and columns in a context-driven manner.",0.0,Neutral
"With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",0.0,Neutral
"the filed, which can be mainly categorized into boundary extraction-based methods [38, 31, 15, 41, 25] and element relationship-based methods [23, 4, 34, 36] according to the component type leveraged.",0.0,Neutral
"The first group are the single component-based methods, which rely on either boundary extraction [15, 25, 31, 38, 41] or element relationship [4, 23, 34, 36].",0.0,Neutral
"To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in",0.0,Neutral
"We build the TFE as an attention bi-directional GRU network [38], [39] to recurrently process word embeddings in",0.5,Weak
"[12] tried to use a variant of recurrent neural network (RNN) [13–15], gated recurrent units (GRU) [16], to identify table structure.",0.0,Neutral
SA Khan [113] RNN The reduced receptive field of CNNs is solved by the bi-directional GRU.,0.0,Neutral
SA Khan [113] presents a robust deep learning-based solution for extracting rows and columns from a recognized table in document pictures in this work.,0.0,Neutral
SA Khan[113] ICDAR2013 Bi-directional RNN Precision 96.,0.0,Neutral
"Recurring neural networks [27] were also utilized to tackle the task of tabular structure extraction [28], [29].",0.0,Neutral
"Targeting wide classes of documents, many recent works often use neural networks [19, 20, 21, 22] to recognize table structures in documents by means of large training sets.",0.0,Neutral
[36] provides a bidirectional GRU recurrent neural network to detect rows and columns in a table.,0.0,Neutral
[36] uses Gated Recurrent Unit (GRU) based sequential deep models for table structure extraction.,0.0,Neutral
"To alleviate this problem, methods like [13, 43, 45] tried different context enhancement techniques, e.",0.0,Neutral
"There are three approaches in the literature to handle table detection in documents: conventional rule-based [30, 87], metadata extraction [6, 31, 57], and machine learning and deep learning approaches [5, 25, 41, 47, 89].",0.0,Neutral
[41] used the CNNmodel introduced by Gilani et al.,0.0,Neutral
[41] used the CNN model introduced by Gilani et al.,0.0,Neutral
"We unfortunately could not directly evaluate the approaches presented in References [5, 25, 30, 41, 47, 89] using our cybersecurity corpus documents, because their respective implementations were not available online.",-1.0,P-NR
"Researchmodels trained on reference datasets such as References [5, 25, 30, 41, 47, 89] often have difficulties coping with the complexity of real world document layouts [15].",0.0,Neutral
(2019) [41] Faster R-CNN + PDF Table Boundary Detection Relies on heuristics Gated Recurrent Columns and Rows Detection Fails to return text Unit (GRU) Fails to detect cell structures Zheng et al.,0.0,Neutral
"Thus, this paper proposes a novel token-level metaphor identification method based on pre-training of deep bidirectional transformers (BERT) [6], Bi-Gated Recurrent Unit (Bi-GRU) [10] and Conditional Random Field (CRF) [13].",0.5,Weak
[18] proposed to use sequential models like bi-directional gated recurrent unit networks,0.0,Neutral
"Experimentation achieved the highest accuracy of 90.17 for Bi-GRU, applying learned word class features along with embedding with GloVe.",0.5,Weak
"(ii) LSTM [42], Bi-LSTM [43], GRU [44], and Bi-GRU [45] are investigated as classifiers (with one-dimensional convolution layer).",0.5,Weak
"Maximum average accuracy is achieved by the GloVe-WCFBi-GRU model, which is 90.41% for the Saraiki-Hindi dataset, while for the English-Bengali-Saraiki-Hindi-Roman Urdu mix dataset, minimum accuracy is observed (i.e., 85% in Figure 7).",0.0,Neutral
"Moreover, through experimental investigation, different architectures are optimized for the task associated with Long Short-Term Memory (LSTM), Bidirectional LSTM, Gated Recurrent Unit (GRU), and Bidirectional Gated Recurrent Unit (Bi-GRU).",0.0,Neutral
"*e highest average accuracy is achieved for the GloVe-WCFBi-GRU model for which the optimized approach is presented
in Figure 7.",0.5,Weak
"On the other hand, for the Parzen estimator, highest accuracy is achieved by Bi-GRU implemented on top of GloVe for Eng-Bengali scripts.",0.0,Neutral
"It is done with its variants LSTM, Bi-LSTM, GRU, and Bi-GRU.",0.0,Neutral
"More variations in standard LSTM such as Bi-LST [60], GRU [5], and Bi-GRU [61] are found to be adequate to address the mentioned issues.",0.0,Neutral
"According to [4, 45, 62], Bi-LSTM can capture or calculate both directions of contexts, such as upcoming and previous hidden layers.",0.0,Neutral
"*e architecture gets data and performs on dataset word-by-word analysis and feeds the representation into LSTM, Bi-LSTM, GRU, and Bi-GRU.",0.0,Neutral
"In our work, the input is captured by tweet as the token as an underlying layer of RNN variants as LSTM, BI-LSTM, GRU, and Bi-GRU as word embedding.",0.0,Neutral
"*erefore, dataset consisting of five different languages (3 cursive and 2 noncursive) is selected for effective validation of the proposed method
*e significance of this study is to explore (1) two kinds of word embeddings; (2) four classifiers (LSTM, Bi-LSTM, GRU, and Bi-GRU); (3) various deep neural network architectures; (4) optimal value of different hyperparameters to find the optimal language detection for the mixed-script dataset consisting of Roman Urdu, English, Saraiki, Hindi, and Bengali languages.",0.5,Weak
"With the development of deep learning, table structure recognition methods have recently advanced substantially on performance, which can be classified into three categories: boundary extractionbased [13, 22, 27, 35, 40], generative model-based [18, 46], and graph-based [2, 20, 30, 34] methods.",0.0,Neutral
"Although many previous algorithms [2,13,18,20,22,30,31,34,35,40,45,46] have achieved impressive progress in the community, TSR is still a challenging task due to two factors of complicated tables.",0.0,Neutral
"Besides, another technique [13] exploits bi-directional GRUs to establish row and column boundaries in a context driven manner.",0.0,Neutral
"Table structure recognition (TSR) aims to recognize the table internal structure to the machine readable data mainly presented in two formats: logical structure [18, 46] and physical structure [2, 13, 20, 22, 27, 30, 31, 34, 35, 40, 45].",0.0,Neutral
"Cognitive methods in this space broadly classified into five categories — image-to-sequence models [17, 2, 14], segmentation networks [26, 18, 20, 23], graph formulations [22, 4, 24], conditional generative adversarial networks [16] and a recent multi-modal method by [40].",0.0,Neutral
"To achieve this purpose, existing computer vision methods either predict cell bounding boxes [6, 13], explore the adjacency relation between different cells [11, 15], or transform a table image into the markup sequence (e.",0.0,Neutral
"[13, 25, 32] attempt to predict row/column boundaries or even invisible grid lines, which are limited in identifying cells spanning multiple rows and columns.",0.0,Neutral
"They can be categorized into two groups: non-table-element-based approaches [13, 17, 25, 32, 35, 44] and tableelement-based approaches [2, 19, 27–29, 31, 41, 43].",0.0,Neutral
"2, with the success of deep learning, recent deep learning-based table structure recognition approaches can be divided into three categories: 1) identify cell bounding boxes through visual detection and segmentation methods [8], [25], [27]–[29]; 2)",0.0,Neutral
"In [8], [28], [29], they classify an entire row or column into the cell or non-cell categories instead of the pixel-wise classification.",0.0,Neutral
"With the great success of deep neural network in computer vision field, works began to focus on the image-based table with more general structures [21,30,24,9,13,36,23,14,33].",0.0,Neutral
[102] has experimented with bi-directional recurrent neural networks along with Gated Recurrent Units (GRU) [103] to extract the structure of the table.,0.0,Neutral
"Recurrent neural networks [29] have also been employed to handle the problem of table structure extraction [30], [31].",0.0,Neutral
[9] proposed to use the recurrent neural networks (RNN) to identify the table structure according to the characteristics that the cells have repetitive sequence characteristics on the row and column.,0.0,Neutral
[21] exploit RNN based sequence model to capture the repetitive row/column structures.,0.0,Neutral
Recurrent neural networks (RNNs) are used to predict independent outputs and future input information [2].,0.0,Neutral
"and scanned tables, and bidirectional RNNs and LSTMs are frequently adopted in web tables to capture the order of rows and columns [15, 16, 21, 28].",0.0,Neutral
"Among these, the problem of table structure recognition has been of high interest in the community [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20].",0.0,Neutral
"In the space of document images, researchers have been working on understanding equations [30,31], figures [32,33] and tables [6,7,8,9,10,11,12,13,14,15,16,17].",0.0,Neutral
"Table structure recognition is a challenging problem due to complex structures and high variability in table layouts [4,5,6,7,8,9,10,11,12,13,14,15,16,17].",0.0,Neutral
"[15], through their gru based sequential models, showed improvements over several cnn based methods for table structure extraction.",0.0,Neutral
"Many cognitive methods [6,7,8,9,10,11,12,14,15,16,37,38,39,40,41,42,43] have also been presented to understand table structures as they are robust to the input type (whether being scanned images or native digital).",0.0,Neutral
"We compare the performance of our tabstruct-net against seven benchmark methods — deepdesrt [7], tablenet [12], graphtsr [14], splerge [10], dgcnn [9], Bi-directional gru [15] and Image-to-Text [11].",0.5,Weak
[46] Marmot 2K ICDAR-2013 204 ICDAR-2013 34 0.,0.0,Neutral
" 57.40 52.20 pdf2table [40] N 59.51 57.52 58.50 TABFIND [36] N 70.52 68.74 69.62 Ours GTE N 94.70 94.49 94.57 Academic Systems Tensmeyer [37] Y 94.64 95.89 95.26 Nurminen [7] Y 94.09 95.12 94.60 Khan [17] Y 90.12 96.92 93.39 TABFIND [36] Y 64.01 61.44 62.70 Ours GTE Y 95.74 95.39 95.55 Cell Structure Ablation Study To analyze our GTE-Cell network further, we compare the several variations in Table 4 u",0.0,Neutral
"Disadvantages of neural networks:  a high probability of the training and adaptation method hitting a local extremum [13];  inaccessibility for human understanding of the knowledge accumulated by the network (it is impossible to represent the relationship between input and output in the form of rules), since they are distributed among all of the elements of the neural network and are presented in the form of its weight coefficients [14, 15];  difficulty in determining the structure of the network, since there are no algorithms for calculating the number of layers and neurons in each layer for specific applications [8, 16];  difficulty in forming a representative sample [17, 18].",0.0,Neutral
"The following recurrent networks are most often used as neural networks for translation: • Elman neural network (ENN or SRN) [12, 13], the simplest of recurrent neural networks; • bidirectional recurrent neural network (BRNN) [14, 15], which is built based on two Elman neural networks; • long short-term memory (LSTM) [16, 17]; • bidirectional recurrent neural network (BLSTM) [18, 19], which is built based on two LSTM neural networks; • gated recurrent unit (GRU) [20, 21]; • bidirectional recurrent neural network (BGRU) [22], which is built based on two GRU neural networks.",0.0,Neutral
"The disadvantages are a higher complexity of determining the architecture, a lower learning rate than in a conventional Elman neural network; • idirectional recurrent neural network (BGRU) [25], which is a recurrent network and is built on the basis of two GRU neural networks.",0.0,Neutral
"Top-down methods [19,33,34,37] try to split entire table images into rows and columns using detection or segmentation models, then cells can be obtained through row-column intersection.",0.0,Neutral
"In the works of [8, 20, 27, 36, 38, 46], a table is depicted as a grid of regions.",0.0,Neutral
"For instance, region-based methods [8, 20, 36, 38, 46] employ a split model to divide input table images into a grid of regions, and a merge model to combine over-split spanning cells.",0.0,Neutral
"TabStructNet [36] combines table element detection and vertex relationship prediction into a single network, providing an end-to-end solution.",0.0,Neutral
"[16, 25, 35, 36, 47] represent tables by a group of cells.",0.0,Neutral
"Note that, there are fundamental differences between the representation in [8, 20, 36, 38, 46] and ours despite the representation is also termed as ""grid"".",0.0,Neutral
"Several studies have proposed detectors for detecting cells or their contents [28,31,30,49].",0.0,Neutral
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR
Raja et al.[34]6 2020 TabStruct Net ECCV SciTSR UNLV X X NR,0.0,Neutral
TabStruct-Net [7] proposed an end-to-end network to detect cells and predict cell relations jointly.,0.0,Neutral
"Some recent works [7, 8, 12] have proposed a modified TEDS metric named TEDS-Struct to evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
"To bypass this problem, the second group of methods [7, 8, 12, 45, 46] detects the bounding boxes of table cells directly and uses different methods to group them into rows and columns.",0.0,Neutral
"Also based on DGCNN, TabStructNet [36] is proposed for end-to-end training cell detection and structure recognition in a joint manner.",0.0,Neutral
"With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",0.0,Neutral
"Similar to [36], we randomly extract 80% of the data for training and others for testing.",0.0,Neutral
"the filed, which can be mainly categorized into boundary extraction-based methods [38, 31, 15, 41, 25] and element relationship-based methods [23, 4, 34, 36] according to the component type leveraged.",0.0,Neutral
"The first group are the single component-based methods, which rely on either boundary extraction [15, 25, 31, 38, 41] or element relationship [4, 23, 34, 36].",0.0,Neutral
"To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in",0.0,Neutral
"In recent years, inspired by the success of deep learning in various tasks, especially object detection and semantic segmentation, many deep learning-based methods (Raja et al., 2020; Schreiber et al., 2017) have been presented to recognize table structures.",0.0,Neutral
"Sachin et al. (Raja et al., 2020) presented a table structure recognizer named TabStruct-Net that combines cell detection and interaction modules to localize the cells and predicts their row and column associations with other detected cells.",0.0,Neutral
"(Raja et al., 2020) presented a table structure recognizer named TabStruct-Net that combines cell detection and interaction modules to localize the cells and predicts their row and column associations with other detected cells.",0.0,Neutral
"(Raja et al., 2020; Schreiber et al., 2017) have been presented to recognize table structures.",0.0,Neutral
21 PubTabNet TabStructNet [37] SciTSR 90.,0.0,Neutral
TableStructNet [37] and FLAG-NET [24] both utilized Mask R-CNN [13] network to obtain the region of cells and cell visual features.,0.0,Neutral
"To eliminate this assumption, another group of methods [25, 24] proposed to detect the bounding boxes of table cells directly.",0.0,Neutral
"Due to the rapid development of deep learning in documents, many deep learning-based TSR approaches [37, 3, 35, 25] have been presented.",0.0,Neutral
"Following this work, there are models devoted to improving the relationship classification by using elaborated neural networks and adding multi-modal features (Qasim, Mahmood, and Shafait 2019; Raja, Mondal, and Jawahar 2020, 2022; Liu et al. 2021, 2022).",0.0,Neutral
"It should be noted that ICDAR-2013 provides no training data, so we extend it to the partial version for cross validation following previous works (Raja, Mondal, and Jawahar 2020; Liu et al. 2022, 2021).",0.0,Neutral
"Then we compare LORE with models mining the adjacency of cells by relation-based metrics: TabStrNet (Raja, Mondal, and Jawahar 2020), LGPMA (Qiao et al. 2021), TOD (Raja, Mondal, and Jawahar 2022), FLAGNet (Liu et al. 2021) and NCGM (Liu et al. 2022).",0.0,Neutral
"We also report the performance of cell spatial location prediction, using the F-1 score under the IoU threshold of 0.5, following recent works (Raja, Mondal, and Jawahar 2020; Xue et al. 2021).",0.0,Neutral
"56 million, while the method in reference [22] uses the Resnet101 [10] network, and the parameter amount reaches 44.",0.0,Neutral
"Several deep learning-based methods and datasets from the literature (TabStructNet [17], TableNet [14], CDeCNet [1], UNLV [19], DeepDeSRT [18], TableBank [11], PubTabNet [23], ICDAR 2013 Table Competition [9], DeepFigures [20], PubLayNet [24]) explore solutions to table detection and table structure recognition tasks.",0.0,Neutral
GTE [39] PubTabNet-train PubTabNet-test 93.,0.0,Neutral
S Raja [116] describes a method for recognizing table structure that combines cell detection and interaction modules to locate the cells and forecast their relationships with other detected cells in terms of row and column.,0.0,Neutral
S Raja [116] Mask R-CNN + ResNet-101 based Net 1) An additional alignment loss is suggested for precise cell detection.,0.0,Neutral
S Raja [121] suggests a novel object-detection-based deep model that is tailored for quick optimization and captures the natural alignments of cells inside tables.,0.0,Neutral
com/doc-analysis/TableBank S Raja S Raja [116] TabStructNet 2020 tensorflow https://github.,0.0,Neutral
S Raja[116] ICDAR2013 Object Detection Methods Precision 92.,0.0,Neutral
"[12] proposed to use deep learning [13], [14] to identify the structure information of the table and extract the structure of the table through the text box in the cell, but this method has limitations in dealing with some complex cells.",0.0,Neutral
[21] usedMask R-CNNwith ResNet-101 as a backbone network.,0.0,Neutral
"[33], approaches table structure detection as a relationship problem between the row and column of the detected cell.",0.0,Neutral
"Some recent works [(Raja, Mondal, and Jawahar 2020), (Qiao et al. 2021), (Zheng et al. 2021)] have proposed a modified TEDS metric named TEDS-Struct to
evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
"According to the underlying alignment information in the table, [38, 46, 47] aim to obtain more accurate aligned cells which can be effectively used to infer the final structure.",0.0,Neutral
"2% among all published methods for this widely studied dataset, TabStruct-Net [18] has low TEDs because it cannot handle the problem of unlined tables.",0.0,Neutral
TabStruct-Net [18] first detects individual cells and then links them to get table structure by graphs.,0.0,Neutral
"As the table shows, the TRUST achieves the best Structure TEDs 97.1% and TEDs 96.2% among all published methods for this widely studied dataset, TabStruct-Net [18] has low TEDs because it cannot handle the problem of unlined tables.",0.0,Neutral
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc.",0.0,Neutral
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc. Unlike many state-of-the-art methods that perform evaluations only at TEDs, our method also test the Structure TEDs on PubTabNet.",0.0,Neutral
"Table detection [25,26], structure recognition [20,24] and extraction [9,30] in DLA gathered some special attention in recent years due to the high variability of layouts that make the both necessary to be solved and challenging to be tackled.",0.0,Neutral
"Although the mentioned methods made progress toward understanding complex structured tables, several assumptions were made, such as that accurate word bounding boxes were available and that accurate document text could be used as additional inputs [66].",0.0,Neutral
"Certain relational understanding tasks already play the important role in building electronic archives and developing office automation, which include table structure recognition [24,25,27,31,33],",0.0,Neutral
"Now mainstream relational understanding tasks like table structure recognition [24, 25, 27, 31, 33], key information extraction [16, 17, 46] and reading order detection [37] are born with entitylevel.",0.0,Neutral
"Some recent works [8, 22, 23] have proposed a modified TEDS metric, denoted as TEDS-Struct, to evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
"To eliminate this assumption, another group of methods [8, 22, 23] proposed to detect the bounding boxes of",0.0,Neutral
[22] introduced a novel loss function that modeled the inherent alignment of cells in the cell detection,0.0,Neutral
"Net [22] and LGPMA [23], typically use CNNbased object detection or segmentation models like Mask R-CNN to detect table cells first, then adopt some cell grouping/clustering algorithms to predict row/column relationships between the detected cells.",0.0,Neutral
"Notably, the experimental results of Tabby, GraphTSR, DeepDeSRT on the ICDAR2013, SciTSR and SciTSR-COMP dataset come from the study [3], and the results of TableStrucNet and Split+Heur are from study [22].",0.0,Neutral
TableStrucNet [22] considers two experiment settings in their work.,0.0,Neutral
"Document Intelligence can be considered as an umbrella term covering problems of Key Information Extraction [10,54], Table Detection [41,38] and Structure Recognition [39,55], Document Layout Segmentation [5,4] Document Layout Generation [6,36,3,48], Document Visual Question Answering [51,50,32], Document Image Enhancement [49,22,47] which involves the understanding of visually rich semantic information and structure of different layout entities of a whole page.",0.0,Neutral
"We use four existing recognizers —ocr [26], equation descriptor [19], table recognizer [23], and figure classifier [12] to recognize content from the segmented regions.",0.5,Weak
We use TabStruct-Net [23] to recognize the physical structure of the table and then Tesseract [26] to recognize content.,0.5,Weak
"The success of DL has marked the revisiting of table structure parsing by [7], which inspired follow-up research [27, 1, 6, 2, 28, 29, 30, 19, 31, 18, 32, 17].",0.0,Neutral
"In some best performing frameworks [17, 18, 19], they all jointly optimize the structure detection and entity relations in the structure, as in DocParser.",0.0,Neutral
"We see from the previous works, the most effective methods [17, 18, 19] always jointly optimize the cell locations and cell relationships.",0.0,Neutral
"In order to visualize predicted structures, we have drawn blue cell boxes that belong to the same column and row to the selected red cells as [25].",0.0,Neutral
[25] also attempted to remove heuristics.,0.0,Neutral
"TabStructNet [25] detected cell-level bounding boxes, not content-level bounding boxes.",0.0,Neutral
"of parameters CascadeTabNet [23] 82,852,033 TabStructNet [25] 68,636,098 SPLERGE [32] 255,862 Ours 1,120,692",0.0,Neutral
"Some authors attempted to replace the heuristics with machinelearning methods [24, 25].",0.0,Neutral
"8 Examples of qualitative results on complex tables, the colored regions are the recognized cell regions: Table structure recognition results of (a) CascadeTabNet  [23], (b) TabStructNet  [25], (c) SPLERGE [32], and (d) the proposed method",0.0,Neutral
"We compare the performance of our method with three coventional methods: CascadeTabNet [23], TabStructNet [25], and SPLERGE [32].",0.5,Weak
"Results of CascadeTabNet [23], TabStructNet [25], SPLERGE [32], and the proposed method, from top to bottom 5844 Multimedia Tools and Applications (2022) 81:5827–5848",0.0,Neutral
"(a) Result from CascadeTabNet [23], (b) TabStructNet [25] with ground truth table locations, (c) SPLERGE [32] with ground truth table locations, and (d) result from the proposed method 5845 Multimedia Tools and Applications (2022) 81:5827–5848",0.0,Neutral
"Therefore, recent methods [2, 30, 34] attempt to attack the problem via constructing visual cues of table elements as graphs and applying the deep graph model, such as Graph Convolutional Networks (GCN) [15] to reason their relationships.",0.0,Neutral
"Compared with “DGCNN”, although “Transformer” can deploy the global information of nodes, it ignores the directed edge effects between nodes.",0.0,Neutral
"With the development of deep learning, table structure recognition methods have recently advanced substantially on performance, which can be classified into three categories: boundary extractionbased [13, 22, 27, 35, 40], generative model-based [18, 46], and graph-based [2, 20, 30, 34] methods.",0.0,Neutral
"For comparison, we also visualize
the multi-head self-attention maps from the last blocks of “Transformer-Mixed” [42] and KNN (K = 5) selection heatmaps of all layers in DGCNN [30], where a lighter color indicates a closer relationship.",0.0,Neutral
The method [30] introduces DGCNN to predict the relationship between words represented by the appearance and geometry features.,0.0,Neutral
"For “DGCNN”, it only aggregates information from top K similar nodes of each node instead of all ones.",0.0,Neutral
"Although many previous algorithms [2,13,18,20,22,30,31,34,35,40,45,46] have achieved impressive progress in the community, TSR is still a challenging task due to two factors of complicated tables.",0.0,Neutral
"To compare in a unified protocol, we follow two different experimental setups in [34]: (a) SetupA where only table image is taken as input without additional information and (b) Setup-B where table image along with additional features such as cell/text segment bounding boxes and text contents.",0.0,Neutral
"Also based on DGCNN, TabStruct-Net [34] proposes an end-to-end network training cell detection and structure recognition networks in a joint manner.",0.0,Neutral
"It should be noted that there is no training set in ICDAR-2013 and UNLV datasets, so we extend the two datasets to the partial versions, which is similar to TabStruct-Net [34].",0.0,Neutral
"Table structure recognition (TSR) aims to recognize the table internal structure to the machine readable data mainly presented in two formats: logical structure [18, 46] and physical structure [2, 13, 20, 22, 27, 30, 31, 34, 35, 40, 45].",0.0,Neutral
"The KNN results of DGCNN show that the feature aggregation of one node only pays attention to the top K similar features of other nodes instead of all the nodes, and relies on the choice of K.",0.0,Neutral
"In the similar spirit with works [30, 34], we adopt the following asymmetric edge function hΘ(xi,xj) = xi∥(xi − xj) to combine graph edge features to each node, which can be denoted as HΘ ∈ R ·(N−1)/2)×d .",0.0,Neutral
"To introduce richer table information, several methods [20, 30, 34] con-",0.0,Neutral
"Besides, the DGCNN-based methods apply CNN to perform local context aggregation.",0.0,Neutral
"In previous works using DGCNN [30, 34], only local context of each node is selected by k-Nearest Neighbors algorithm (KNN) to be aggregated into node feature.",0.0,Neutral
"3 compares the effectiveness of various extractors, including DGCNN [30] and Transformer [42], with ECE in our method.",0.5,Weak
"Contrarily, the TabStruct-Net [24] does not make any such assumptions and produces adjacency relations and cell locality information as the output.",0.0,Neutral
• Introduce channel attention [19] for table object detection and define two additional regularizers — continuity and overlapping loss between every pair of cells in addition to the alignment loss from [24].,0.0,Neutral
"Our formulation uses rectilinear adjacencies instead of row/column adjacencies [22, 24].",0.0,Neutral
"Table structure recognition generates a machine-interpretable output for a given table image, which encodes its layout according to a pre-defined standard [30, 17, 20, 42, 4, 39, 24].",0.0,Neutral
"Not taking them into account might lead to false negatives and, in-turn, incorrect structure [24].",0.0,Neutral
"Recently, many researchers have opted for a graph-based formulation of the problem as a graph is inherently an ideal data structure to model associations between entities [22, 4, 24].",0.0,Neutral
"We further observe that empty cells account for an average of 12.3% across UNLV and ICDAR-2013 datasets, where our method outperforms TabStruct-Net by 4.2% F1 score.",0.5,Weak
"Inspired by human cognition, we say that table cells, in addition to completely encapsulating their content, should adhere to alignment [24], continuity and non-overlapping constraints, which in-turn makes it easier to locate table columns and rows as independent objects.",0.0,Neutral
"In order to compare our method against others on TUCD dataset, we develop our implementation of DeepDeSRT [26], and use open source implementations of DGCNN (TIES) [22], SPLERGE [30], and TabStruct-Net [24].",0.5,Weak
"Cognitive methods in this space broadly classified into five categories — image-to-sequence models [17, 2, 14], segmentation networks [26, 18, 20, 23], graph formulations [22, 4, 24], conditional generative adversarial networks [16] and a recent multi-modal method by [40].",0.0,Neutral
Raja [24] proposed a first end-to-end object detection and graph based model for collective cells detection and structure recognition.,0.0,Neutral
"To detect table cells, we propose TOD-Net, where we augment the cell detection network of TabStruct-Net [24] with additional loss components to further improve the table object performance (rows/columns/cells) detection.",0.0,Neutral
"4(c) shows our method can well handle the table including non-gridded cells, which may cause the “cell boundary ambiguity” problem to the cell detection-based methods [29, 31, 43].",0.0,Neutral
"Furthermore, some methods [2, 19, 28, 31] attempt to construct the graphs of elements to reason the relationships.",0.0,Neutral
"Different from previousworks [29, 31, 43], we adopt word bounding boxes rather than cells as table elements to avoid cell boundary ambiguity issue.",0.0,Neutral
"Similar to previous works [28, 31] using DGCNN, only k nearest neighbours of each node are selected by k-Nearest Neighbors algorithm (KNN) to construct the local context which is applied by the CNN to aggregate the edge information into node feature Di ∈ RN× d h for i-th head.",0.0,Neutral
inference speed than the method [31] greedily employing large number of proposals with redundancy to model their relationships.,0.0,Neutral
"To overcome this issue, Raja et al. [31] propose TabStruct-Net, which predicts the aligned cell regions and the localized cell relations in a joint manner.",0.0,Neutral
"[31] propose TabStruct-Net, which predicts the aligned cell regions and the localized cell relations in a joint manner.",0.0,Neutral
"For the relational reasoning aspect, recent mainstream algorithms [2, 19, 28, 31] construct table elements as contextual graphs and apply the graph-based aggregator, such as Graph Convolutional Networks (GCN) [14], to reason their relationships.",0.0,Neutral
"To solve this problem, we randomly extract 80% of the data for training and others for testing, which is similar to [31].",0.0,Neutral
"While on both ICDAR-2019 and UNLV, the F1 score of our approach can overtake that of TabStruct-Net as much as 4%.",0.0,Neutral
"Although methods [29, 31, 43] achieve performance improvement by directly predicting cell boxes, they may suffer from “cell boundary ambiguity” problem, especially on those blank or non-gridded cell cases.",0.0,Neutral
"In addition, our model is only trained on the training set of SciTSR for a fair comparison with TabStruct-Net [31].",0.5,Weak
"Compared with the strong baseline TabStruct-Net [31] greedily exploiting large numbers of proposals (round 2,000), our proposed FLAG-Net can achieve marginally better performance with less parameters and computational consumption, which thanks to the proposal filtering mechanism in our method.",0.5,Weak
"For a more practical requirement of parsing table structures from images taken by hand-held cameras in the wild, the existing state-of-the-art approaches [13, 14, 11, 16, 9, 23] are prone to fail as the commonly-used assumption of tabular images no longer holds.",0.0,Neutral
"However, these methods mainly focuses on the well-conditioned document images, where the tables [16, 23, 12, 9, 23, 14] are well-aligned to the image axes.",0.0,Neutral
"For instance, the non-rigid image deformation and complicated image background presented in natural images will challenge existing approaches [14] for document images on detecting and grouping the tabular cells.",0.0,Neutral
"…for tabular data, as corrupt cell detection is actually a fundamental task in table structure decomposition pipelines such as (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicted row/column separators or cell boundaries can lead to corrupted cell text.",0.0,Neutral
"…of corrupt cell detection, which again is practically useful as a postprocessing step after table structure decomposition (Tensmeyer et al., 2019; Raja et al., 2020) because mistakes in predicting row/column/cell boundaries (sometimes compounded by OCR errors) can lead to inaccurate extraction.",0.0,Neutral
"While this objective was originally motivated as enabling more efficient training compared to BERT’s masked language modeling objective, it is especially suited for tabular data, as corrupt cell detection is actually a fundamental task in table structure decomposition pipelines such as (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicted row/column separators or cell boundaries can lead to corrupted cell text.",0.0,Neutral
"We emphasize that this pretraining objective is a fundamental task in table structure decomposition pipelines (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicting row/column separators or cell boundaries leads to corrupted cell text.",0.0,Neutral
"We first examine how TaBERT performs on TABBIE’s pretraining task of corrupt cell detection, which again is practically useful as a postprocessing step after table structure decomposition (Tensmeyer et al., 2019; Raja et al., 2020) because mistakes in predicting row/column/cell boundaries (sometimes compounded by OCR errors) can lead to inaccurate extraction.",0.0,Neutral
works (trained on ImageNet [20] or COCO [43]) on the problem of table detection and table structure recognition in document images [44]–[53].,0.0,Neutral
[53] introduced a table structure recognition method that directly regresses the cellular boundaries.,0.0,Neutral
"The random splits are performed ten rounds for computing averaged performance, which is similar to TabStruct-Net [14].",0.0,Neutral
"Compared with TabStructNet [14], NCGM can achieve better performance with less parameters and similar computational budgets.",0.5,Weak
"In particular, note that TabStruct-Net [14] and FLAG-Net [10] are only tested for structure recognition, so we do not count the parameters and operations of cell detection for a fair comparison.",0.5,Weak
"Bottom-up methods [5,26,27,40] first detect cells or text segments using detection models or OCR engines, then analyze the relations between neighbouring cells using GNN or LSTM.",0.0,Neutral
TabStruct-Net [27] extract cell regions in object detection manner and they can only predict rectangular cell bounding boxes.,0.0,Neutral
"While tables with simple structures and clean backgrounds can be recognized well [6, 12, 14, 15, 23, 24, 30, 35, 38, 41, 47], recognizing complicated table structures remains a challenging problem, which is primarily due to two main difficulties: 1) Firstly, tables in images vary widely in terms of structure and shape.",0.0,Neutral
"Due to the absence of released annotations for the test set, we follow previous approaches [20, 35, 46, 47] and evaluate our model on the validation set using TEDS and TEDS-Struct [48] metrics.",0.5,Weak
"LGPMA [35] applies soft pyramid masks at the local and global levels, allowing the model to detect cell boundaries of wireless tables more accurately.",0.0,Neutral
- 93.0 SEM [46] 93.7 - LGPMA [35] 94.6 96.7 FLAG-Net [22] 95.1 - NCGM [21] 95.4 - TableFormer [29] 93.60 96.75 TSRFormer [20] - 97.5 TRUST [8] 96.20 97.10 VAST [10] 96,0.0,Neutral
"[16, 25, 35, 36, 47] represent tables by a group of cells.",0.0,Neutral
"In works such as [16, 25, 32, 35, 47], a table is represented by a group of cells.",0.0,Neutral
", [7, 13, 17, 18, 21, 29, 37, 44, 55, 56]) utilize a deep learning (DL)-based approach, focusing on either one, two, or all three steps.",0.0,Neutral
"Table 2 illustrates some of these limitations, comparing the MVP predictions obtained from the table recognition ground
truth (baseline) and from the results of LGPMA and VCGroup to the target.",0.0,Neutral
LGPMA obtained a TEDS score (see Sec.,0.0,Neutral
"6, we can see that LGPMA generates many extraneous empty cells; these would have been removed during the HTML to Token conversion process, but would have misaligned the NAME/VALUE pairing when generating the NLP token string.",0.5,Weak
The goal of LGPMA [37] is to obtain better aligned cell regions and solve issues with empty cell generation and partition.,0.0,Neutral
"5.1.1) of 96.32 in the ICDAR 2021 competition, the second highest among the 30 submissions after LGPMA.",0.0,Neutral
"The paper also proposes a table recognition and summarization pipeline that links the two tasks and allows for comparing state-of-the-art table recognition methods (LGPMA and VCGroup) for the end goal of table summarization, utilizing MVP as the data-to-text summarization model.",0.0,Neutral
"We selected the Local and Global Pyramid Mask Alignment (LGPMA) method [37] and the VCGroup method [55],
which came in first and second place respectively in the ICDAR 2021 Competition on Scientific Literature Parsing - Task B Table Recognition [15].",0.5,Weak
"From Table 1, the performance at both stages matches the final standings of the Task B challenge, with LGPMA slightly outperforming VCGroup overall, although that changes from one visual variation to the next.",0.0,Neutral
"We selected the Local and Global Pyramid Mask Alignment (LGPMA) method [37] and the VCGroup method [55], which came in first and second place respectively in the ICDAR 2021 Competition on Scientific Literature Parsing - Task B Table",0.5,Weak
"Interestingly, Variation 15, with a shear horizontal transformation, yields very different TEDS scores compared to the basic Variation 1: lower for LGPMA but higher for VCGroup.",0.5,Weak
"Several studies have proposed detectors for detecting cells or their contents [28,31,30,49].",0.0,Neutral
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR
Qiao et al.[36]10 2021 LGPMA ICDAR PubTabNet + SciTSR + ICDAR 2013 PubTabNet X X NR,0.0,Neutral
hierarchical cell← null for r in R do if r[0] is a colspan cell OR r[1] is an empty cell then,0.0,Neutral
"Most of the previous works [1]–[4] of table recognition focused on two-step approaches that divide the problem into two sub-problems: table structure recognition and table cell content recognition, and then attempt to solve each sub-problem independently by two separate systems.",0.0,Neutral
Input: R (a list of rows of table cells with their bounding boxes) Output: R’ (a list of rows of table cells with hierarchical information) hierarchical cell← null different bbox flag ← False for r in R do if r[0] is a colspan cell OR r[1] is an empty cell then hierarchical cell← r[0] else if r[0] is a rowspan cell OR r[0] is an empty cell then hierarchical cell← null else if different bbox flag AND r[0].,0.0,Neutral
"After cell detection, methods like [8, 12, 46] used heuristic rules to cluster detected cells into rows and columns.",0.0,Neutral
"Some recent works [7, 8, 12] have proposed a modified TEDS metric named TEDS-Struct to evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
"To bypass this problem, the second group of methods [7, 8, 12, 45, 46] detects the bounding boxes of table cells directly and uses different methods to group them into rows and columns.",0.0,Neutral
"Moreover, LGPMA [35] applies a soft pyramid mask when learning both global and local feature maps.",0.0,Neutral
"With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",0.0,Neutral
"To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in",0.0,Neutral
"Note that LGPMA requires additional
annotation information for training.",-1.0,P-NR
"On the PubTabNet dataset, our model achieved TEDS-struc. of 97.88% which again improves TableFormer and LGPMA (Qiao et al., 2021) by about 1.1% and other methods by more than 4.87%.",0.5,Weak
"All other methods except EDD (Zhong et al., 2020) are non-end-to-end
approach and the methods in (Qiao et al., 2021; Ye et al., 2021; Zhang et al., 2022) requires additional annotation information for training.",-1.0,P-NR
LGPMA: Complicated Table Structure Recognition with Local and Global Pyramid Mask Alignment.,0.0,Neutral
"Most of the previous works (Nassar et al., 2022; Qiao et al., 2021; Ye et al., 2021) focus on non-end-to-end approaches which divide the problem into two separate sub-problems: table structure recognition; and cell-content recognition, and then attempt to solve each sub-problem independently using…",0.0,Neutral
"Note that the 1st ranking solution is a non-end-to-end approach which employs LGPMA (Qiao et al., 2021) to recognize the structure of the table and then uses attention-based text recognizer to provide the OCR information of the table cells.",0.5,Weak
"Table recognition: Most of the previous works of table recognition (Nassar et al., 2022; Qiao et al., 2021; Ye et al., 2021; Zhang et al., 2022) focus on non-end-to-end approaches which divide the problem into two separate sub-problems: table structure recognition; and cell-content recognition, and…",0.0,Neutral
"LGPMA (Qiao et al., 2021) is the table structure recognizer component in the 1st ranking solution in ICDAR2021 competition.",0.0,Neutral
"Specifically, our model achieved TEDS of 96.67% which improves VCGoup’s solution (Ye et al., 2021) by 0.41%, LGPMA + OCR (Qiao et al., 2021) by 2%, and others by more than 3%.",0.0,Neutral
LGPMA: Complicated Table Structure Recognition with Local and Global Pyramid Mask Alignment.,0.0,Neutral
"All
FTN
EDD (Zhong et al., 2020) 88.40 92.08 90.60
GTE (Zheng et al., 2021) - - 87.14
GTE (FT) (Zheng et al., 2021) - - 91.02
TableFormer (Nassar et al.,
2022) 97.50 96.00 96.80
WSTabNet 99.06 98.33 98.72
PTN
EDD (Zhong et al., 2020) 91.10 88.70 89.90
GTE (Zheng et al., 2021) - - 93.01
LGPMA (Qiao et al., 2021) - - 96.70
TableFormer (Nassar et al.,
2022) 98.50 95.00 96.75
WSTabNet 99.06 96.37 97.74 (FT) Model was trained on PubTabNet and then finetuned.",0.0,Neutral
"All IM2TEX (Deng et al.,
2019) 81.70 75.50 78.60
EDD (Zhong et al., 2020) 91.20 85.40 88.30 TabStruct-Net (Raja et al.,
2020) - - 90.10
GTE (Zheng et al., 2021) - - 93.00 TableFormer (Nassar et al.,
2022) 95.40 90.10 93.60
SEM (3) (Zhang et al., 2022) 94.80 92.50 93.70 LGPMA (1) (Qiao et al.,
2021) - - 94.60
VCGoup (2) (Ye et al., 2021) - - 96.26 WSTabNet 97.89 95.02 96.48
(1)(2)(3) are 1st, 2nd, and 3rd solutions in ICDAR2021 competition.",0.0,Neutral
"LGPMA (Qiao et al., 2021) is the table structure recognizer component in the 1st ranking solution in ICDAR2021 competition.",0.0,Neutral
"Although, the proposed model requires only table HTML annotations for the training step, it outperforms all the fully supervised methods (Nassar et al., 2022; Qiao et al., 2021; Raja et al., 2020; Ye et al., 2021; Zhang et al., 2022; Zheng et al., 2021) that require both table HTML and the cell bounding boxes annotations for training the models.",0.0,Neutral
"Recently, some researchers (Nassar et al., 2022; Qiao et al., 2021; Ye et al., 2021; Zhang et al., 2022) worked on both table structure recognition and cell content recognition to build a complete table recognition system.",0.0,Neutral
"For the irregular layout table, a good cell detection result could effectively improve the accuracy of table recognition, [26, 33, 36, 55] were committed to improving the accuracy of cell detection.",0.0,Neutral
"To eliminate this assumption, another group of methods [25, 24] proposed to detect the bounding boxes of table cells directly.",0.0,Neutral
"Limited by the training datasets [7, 2, 37, 36] used for TSR, most previous works [28, 24, 35, 26] focus on document images that are obtained from digital documents (e.",0.0,Neutral
"Then we compare LORE with models mining the adjacency of cells by relation-based metrics: TabStrNet (Raja, Mondal, and Jawahar 2020), LGPMA (Qiao et al. 2021), TOD (Raja, Mondal, and Jawahar 2022), FLAGNet (Liu et al.",0.5,Weak
"Then we compare LORE with models mining the adjacency of cells by relation-based metrics: TabStrNet (Raja, Mondal, and Jawahar 2020), LGPMA (Qiao et al. 2021), TOD (Raja, Mondal, and Jawahar 2022), FLAGNet (Liu et al. 2021) and NCGM (Liu et al. 2022).",0.5,Weak
"Reference [4] uses the method of object detection to identify the table structure, and proposed complicated table structure recognition with local and global pyramid mask alignment (LGPMA) based on Mask R-CNN [5], which detects the local and global boundaries of the table, and aligns and fuses the results.",0.0,Neutral
LGPMA [12] PubTabNet-train PubTabNet-test 94.,0.0,Neutral
"Davar-Lab proposed the local and global pyramid mask alignment (LGPMA) [12] method, which learned the local pyramid mask alignment (LPMA) and the global pyramid mask alignment (GPMA) simultaneously.",0.0,Neutral
"Some recent works [(Raja, Mondal, and Jawahar 2020), (Qiao et al. 2021), (Zheng et al. 2021)] have proposed a modified TEDS metric named TEDS-Struct to
evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
"Some recent works [(Raja, Mondal, and Jawahar 2020), (Qiao et al. 2021), (Zheng et al.",0.0,Neutral
"Table 5 shows the results of SLANet and some state-of-the-art methods on PubTabNet such as EDD(Zhong, ShafieiBavani, and Jimeno Yepes 2020b), TableMaster(Ye et al. 2021) and LGPMA(Qiao et al. 2021).",0.0,Neutral
"Similar to previous works [8, 38, 46, 49, 51], the text content and structure information are obtained separately.",0.0,Neutral
"Since all the tables are extracted from PDF files and all horizontally aligned, we adopt the post-processing of cell matching in [46] to construct the cells relations.",0.5,Weak
"2) Since all of the tables are horizontally displayed, we adopt the cell matching strategy in [46] to generate the column/row indexes.",0.5,Weak
"According to the underlying alignment information in the table, [38, 46, 47] aim to obtain more accurate aligned cells which can be effectively used to infer the final structure.",0.0,Neutral
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc. Unlike many state-of-the-art methods that perform evaluations only at TEDs, our method also test the Structure TEDs on PubTabNet.",0.0,Neutral
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc.",0.0,Neutral
"Unfortunately, the Component-based approaches such as DeepDeSRT [7], TableNet [8] and LGPMA [9] still suffer from boundary ambiguity problems in unlined tables and cannot achieve decent performance in complex scenarios such as tables with empty cells.",0.0,Neutral
"Recently, two new approaches have beaten the state-of-the-art: combining vision, semantic and relations for layout analysis and table detection [15] and applying a soft pyramid mask learning mechanism in both the local and global feature maps for complicated table structure recognition [11].",0.0,Neutral
"In VSR, visual, semantic, and structural features are combined to detect objects, exploiting a GNN for the final refinement; LGPMA uses a soft pyramid mask learning mechanism in both local and global feature maps to recover the table structure, also taking into account empty cells location.",0.0,Neutral
"In the ICDAR 2021 competition on DLA and TR [39], the DAVARLab-OCR obtained SOTA results on both tasks by using two different approaches: VSR [40] and LGPMA [41].",0.0,Neutral
"In the ICDAR 2021 competition on DLA and TR [38], the DAVARLab-OCR obtained SOTA results on both tasks by using two different approaches: VSR [39] and LGPMA [40].",0.0,Neutral
"To bypass this problem, the second group of methods [19, 23, 33, 35, 36, 54] detects the bounding boxes of table cells or cell contents directly and uses different methods to group them into rows and columns.",0.0,Neutral
"After cell detection, methods like [19, 35, 54] used heuristic rules to cluster detected cells into rows and columns.",0.0,Neutral
"Some recent works [35, 36, 54] have proposed a modified TEDS metric named TEDS-Struct to evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
"Other common forms of document understanding tasks include layout analysis [32, 34], Reading Order Detection (ROD) [16, 30], table recognition [14, 21] and understanding [12, 29], document Question-Answering (QA) [19], Named Entity Recognition (NER) [7, 10, 24, 31], etc.",0.0,Neutral
"(5) TP[22], MANGO[20], M-RCNN-e2e YORO [4] Chargrid[13]♥♣, TRIE[35]♥♣♦ BERT-Softmax /Span/CRF[5] ♣ BiLSTM-CRF[10]♣ VSR[34]♥♣♦ GCN-PN[16]♥♦ LGPMA[21]♥",0.0,Neutral
"Recent best performing table structure recognition approaches, like TabStructNet [22] and LGPMA [23], typically use CNNbased object detection or segmentation models like Mask R-CNN to detect table cells first, then adopt some cell grouping/clustering algorithms to predict row/column relationships between the detected cells.",0.0,Neutral
"Net [22] and LGPMA [23], typically use CNNbased object detection or segmentation models like Mask R-CNN to detect table cells first, then adopt some cell grouping/clustering algorithms to predict row/column relationships between the detected cells.",0.0,Neutral
"It is noted that, the recent best performing method LGPMA [23] (the winner",0.0,Neutral
"It is noted that, the recent best performing method LGPMA [23] (the winner of ICDAR 2021 Competition on Scientific Literature Parsing Task B [83]) has leveraged an important task constraint, namely tables are axis-aligned, to achieve higher accuracy.",0.0,Neutral
[23] designed some rules to cluster cells into rows and columns.,0.0,Neutral
"Some recent works [8, 22, 23] have proposed a modified TEDS metric, denoted as TEDS-Struct, to evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
"To eliminate this assumption, another group of methods [8, 22, 23] proposed to detect the bounding boxes of",0.0,Neutral
[21] propose a Local and Global Pyramid Mask Alignment framework by applying the soft pyramid mask learning mechanism to local and global feature maps.,0.0,Neutral
"Tabular data is a popular format to express compact and important information for readers in different types of digital documents, including web pages, PDFs, Word processors, and document images [21].",0.0,Neutral
"Although many previous algorithms [2,13,18,20,22,30,31,34,35,40,45,46] have achieved impressive progress in the community, TSR is still a challenging task due to two factors of complicated tables.",0.0,Neutral
"In the similar spirit, LGPMA [31] applies soft pyramid mask learning mechanism on both the local and global feature maps.",0.0,Neutral
"Table structure recognition (TSR) aims to recognize the table internal structure to the machine readable data mainly presented in two formats: logical structure [18, 46] and physical structure [2, 13, 20, 22, 27, 30, 31, 34, 35, 40, 45].",0.0,Neutral
"Cognitive methods in this space broadly classified into five categories — image-to-sequence models [17, 2, 14], segmentation networks [26, 18, 20, 23], graph formulations [22, 4, 24], conditional generative adversarial networks [16] and a recent multi-modal method by [40].",0.0,Neutral
"Although methods [29, 31, 43] achieve performance improvement by directly predicting cell boxes, they may suffer from “cell boundary ambiguity” problem, especially on those blank or non-gridded cell cases.",0.0,Neutral
"Different from previousworks [29, 31, 43], we adopt word bounding boxes rather than cells as table elements to avoid cell boundary ambiguity issue.",0.0,Neutral
"4(c) shows our method can well handle the table including non-gridded cells, which may cause the “cell boundary ambiguity” problem to the cell detection-based methods [29, 31, 43].",0.0,Neutral
"A group of methods [27, 29, 41, 43] try to recover the relations of elements based on heuristic algorithms.",0.0,Neutral
"LGPMA (Qiao et al., 2021) incorporates a soft pyramid mask learning mechanism in both local and global feature maps for table structure recognition.",0.0,Neutral
"Since LGMPA [13] and CycleCenterNet [11] recover table structure based on heuristic rules after detecting cells, which is infeasible to perform the comparison between them and our method, we do not report them in Tab.",-1.0,P-NR
FinTabNet [47] is a large dataset containing financial tables.,0.0,Neutral
"As shown in Figure 8, we list the visualization results of our methods on tables scanned from documents, including PubTabNet dataset, SciTSR dataset and FinTabNet dataset.",0.0,Neutral
"On FinTabNet, our method achieves a TEDS-Struct score of 98.6%, improving the score by 1.8% compared to the competitive method TableFormer.",0.0,Neutral
"While tables with simple structures and clean backgrounds can be recognized well [6, 12, 14, 15, 23, 24, 30, 35, 38, 41, 47], recognizing complicated table structures remains a challenging problem, which is primarily due to two main difficulties: 1) Firstly, tables in images vary widely in terms of structure and shape.",0.0,Neutral
"We conducted a comprehensive validation of our model’s performance on various datasets, including well-known regular table benchmarks such as SciTSR, PubTabNet, and FinTabNet, which are derived from PDF documents.",0.5,Weak
"Due to the absence of released annotations for the test set, we follow previous approaches [20, 35, 46, 47] and evaluate our model on the validation set using TEDS and TEDS-Struct [48] metrics.",0.0,Neutral
GTE [47] uses an object detection-based method to detect cells directly and uses heuristic rules in post-processing to recover the table structure.,0.0,Neutral
"Following [29, 47], we use the split set of training for training and validating samples for testing.",0.0,Neutral
"We evaluated our proposed method on regular tables that were scanned from PDF documents, and compared it with several state-of-the-art methods on PubTab-Net, FinTabNet, and SciTSR datasets, and the results are reported in 3.",0.5,Weak
"[16, 25, 35, 36, 47] represent tables by a group of cells.",0.0,Neutral
"With a simple pipeline, our method has achieved comparable or state-of-the-art performance on the public benchmarks, including PubTabNet [48], FinTabNet [47], SciTSR [2], WTW [25], and TAL [3].",0.5,Weak
"In works such as [16, 25, 32, 35, 47], a table is represented by a group of cells.",0.0,Neutral
", [7, 13, 17, 18, 21, 29, 37, 44, 55, 56]) utilize a deep learning (DL)-based approach, focusing on either one, two, or all three steps.",0.0,Neutral
"Therefore, the existing approaches [28, 44, 26] to TDR are vision-only approaches.",0.0,Neutral
", table cells) and leverages this prior knowledge in the model design and post-processing [28, 44, 26].",0.0,Neutral
"The study also considers the use of TABBIE for data discovery and clustering, with table embeddings derived from the CLS token in the (0,0) position of the table being used to cluster the FinTabNet dataset which is composed of tables from S&P’s corporate filings [41].",0.0,Neutral
"(ICDAR), vol. 1, Nov. 2017, pp. 1162– 1167
[13] X. Zheng, D. Burdick, L. Popa, X. Zhong, and N. X. R. Wang, ‘‘Global table extractor (GTE): A framework for joint table identification and cell structure recognition using visual context,’’ in
Proc.",0.0,Neutral
Global table extractor (GTE) [13] Proposed a generic abject detection approach A comprehensive approach that is compatible with all object detection,0.0,Neutral
"Global table extractor (GTE) [13]
Proposed a generic abject detection approach
A comprehensive approach that is compatible with all object detection frameworks.",0.0,Neutral
"Document Understanding encompasses datasets related to various subtasks like document layout analysis [109, 49], classification [30], key information extraction [85, 35], table extraction [83, 108, 107], and visual question answering [57, 59, 91].",0.0,Neutral
"Created by eleven finance professionals, FinQA is based on earnings reports from S&P 500 companies (Zheng et al., 2020).",0.0,Neutral
"On the other hand, the problem of table structure recognition (TSR) is a lot more challenging and remains a very active area of research, in which many novel machine learning algorithms are being explored [3,4,5,9,11,12,13,14,17,18,21,22].",0.0,Neutral
In section 3 we review the current HTML table encoding (popularised by PubTabNet and FinTabNet) and discuss its flaws.,0.0,Neutral
"While the majority of research in TSR is currently focused on the development and application of novel neural model architectures, the table structure representation language (e.g. HTML in PubTabNet and FinTabNet) is usually adopted as is for the sequence tokenization in Im2Seq models.",0.0,Neutral
"Object-detection based methods [11,12,13,14,21] rely on tablestructure annotation using (overlapping) bounding boxes for training, and produce bounding-box predictions to define table cells, rows, and columns on a table image.",0.0,Neutral
"In reality though, one needs at least 28 HTML tokens to describe the most common complex tables observed in real-world documents [21,22], due to a variety of spanning cells definitions in the HTML token vocabulary.",0.0,Neutral
"It is clearly evident that the model trained on OTSL outperforms HTML across the board, keeping high TEDs and mAP scores even on difficult financial tables (FinTabNet) that contain sparse and large tables.",0.0,Neutral
"TSR and cell detection results compared between OTSL and HTML on the PubTabNet [22], FinTabNet [21] and PubTables-1M [14] data sets using TableFormer [9] (with enc=6, dec=6, heads=8).",0.0,Neutral
"Public table-structure data sets such as PubTabNet [22], and FinTabNet [21], which were created in a semi-automated way from paired PDF and HTML sources (e.g. PubMed Central), popularized primarily the use of HTML as ground-truth representation format for TSR.",0.0,Neutral
"Public table-structure data sets such as PubTabNet [22], and FinTabNet [21], which were created in a semi-automated way from paired PDF and HTML sources (e.",0.0,Neutral
"Secondly we pick the best hyper-parameters found in the first step and evaluate how OTSL impacts the performance of TableFormer after training on other publicly available data sets (FinTabNet, PubTables-1M [14]).",0.0,Neutral
"We picked the model parameter configuration that produced the best prediction quality (enc=6, dec=6, heads=8) with PubTabNet alone, then independently trained and evaluated it on three publicly available data sets: PubTabNet (395k samples), FinTabNet (113k samples) and PubTables-1M (about 1M samples).",0.5,Weak
"Several studies have proposed detectors for detecting cells or their contents [28,31,30,49].",0.0,Neutral
"TRACE’s F1-measure shows competitive performance with GTE [49], and it achieved a higher score in terms of Purity and Completeness.",0.0,Neutral
proposed Global Table Extractor (GTE)[49] that used two separate table and cell detectors based on Faster-RCNN.,0.0,Neutral
"RobusTabNet[25] used CornerNet[16] for TD, and proposed line prediction model for TSR. Recently, Zheng et al. proposed Global Table Extractor (GTE)[49] that used two separate table and cell detectors based on Faster-RCNN.",0.0,Neutral
"For example, when comparing the result with and without table detection in GTE, the performance dropped by 2.7%.",0.0,Neutral
Zheng et al.[37] 2022 GTE WACV PubTabNet ICDAR 2013 + ICDAR 2019 - - NR Jain et al.,0.0,Neutral
"The following are examples of deep learning implementations for image classification, cell structure recognition, tissue segmentation, and computer-assisted disease diagnosis [11].",0.0,Neutral
"Those researches have mainly focused on Visually Rich Document(VRD)-based tasks, such as academic papers[18, 33], receipts[10, 17], and forms [11, 28], and many benchmark problems has been solved, including layout analysing [14, 33], table structure recognition [3, 31, 32], document question answering [16, 22].",0.0,Neutral
This dataset contains document images from the FinTabNet dataset [11] and relevant questions about these document images.,0.0,Neutral
"With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",0.0,Neutral
"To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in",0.0,Neutral
"To attack it, a hierarchical GTE [45] employs clustering algorithm while Cycle-CenterNet [25] designs a cycle-pairing module that simultaneously detect table cells and group them into structured tables.",0.0,Neutral
"Limited by the training datasets [7, 2, 37, 36] used for TSR, most previous works [28, 24, 35, 26] focus on document images that are obtained from digital documents (e.",0.0,Neutral
"Recently, FinTabNet [36] and SciTSR [2] add the cell coordinates and row-column information to become relatively comprehensive datasets for TSR.",0.0,Neutral
"When evaluating on TEDS, we use the non-styling text extracted from PDF files following Zheng et al. (2021).",0.5,Weak
As our baseline training datasets we adopt PubTables-1M [21] and FinTabNet [25].,0.0,Neutral
"These developments have enabled significant advances in deep learning (DL) modeling for TE [18,16,25,21,13,12].",0.0,Neutral
"This includes the development of task-specific metrics for evaluating table structure recognition (TSR) models [5,26,20] as well as the increasing variety of datasets and benchmarks [3,25,26,21].",0.0,Neutral
"To address the need for training data, several large-scale crowd-sourced datasets [3,26,11,25,21] have been released for training table structure recognition models.",0.0,Neutral
"This track is derived from the task of Line Item Recognition (LIR) [26] and is related to Table Understanding [13] and Table Extraction [8, 35] — problems where the tabular structure is also crucial for IE.",0.0,Neutral
"FinQA FinQA is a dataset of numerical reasoning over long-form financial data, containing 8, 281 financial reports, along with their QA pairs and annotated numerical reasoning processes by eleven finance professionals based on the earnings reports of S&p 500 companies (Zheng et al., 2021).",0.0,Neutral
"In DTE, there are three main cases: TD predicts bounding boxes of table candidates on document images (Shafait and Smith, 2010; Schreiber et al., 2017; Siddiqui et al., 2018; Paliwal et al., 2019; Prasad et al., 2020; Hashmi et al., 2021b; Zheng et al., 2021); TD searches for text lines signaling table candidates in plain-text (Hu et al.",0.0,Neutral
"…images (Shafait and Smith, 2010; Schreiber et al., 2017; Siddiqui et al., 2018; Paliwal et al., 2019; Prasad et al., 2020; Hashmi et al., 2021b; Zheng et al., 2021); TD searches for text lines signaling table candidates in plain-text (Hu et al., 1999; Ng et al., 1999; Pinto et al., 2003); TD…",0.0,Neutral
"In this scenario, TSR usually deals with tables which are subareas of document images (Zuyev, 1997; Schreiber et al., 2017; Siddiqui et al., 2019a, 2019b; Zheng et al., 2021; Hashmi et al., 2021c), lines of plain-text (Kieninger, 1998; Ng et al.",0.0,Neutral
"…scenario, TSR usually deals with tables which are subareas of document images (Zuyev, 1997; Schreiber et al., 2017; Siddiqui et al., 2019a, 2019b; Zheng et al., 2021; Hashmi et al., 2021c), lines of plain-text (Kieninger, 1998; Ng et al., 1999; Hu et al., 2000), or text chunks and rulings…",0.0,Neutral
The most common words from PubTabNet and FinTabNet as well as randomly produced text make up the corpora used to create the table content.,0.0,Neutral
"FinTabNet [65] introduces GTE, a vision-guided systematic framework for combined table detection and cell structured identification that can be constructed on top of any object detection model.",0.0,Neutral
"FinTabNet FinTabNet [65] introduces GTE, a vision-guided systematic framework for combined table detection and cell structured identification that can be constructed on top of any object detection model.",0.0,Neutral
FinTabNet is a collection of real-world and complicated scientific and financial datasets with thorough table structure annotations to aid in structure identification training and testing.,0.0,Neutral
"2021), (Zheng et al. 2021)] have proposed a modified TEDS metric named TEDS-Struct to evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
"Some recent works [(Raja, Mondal, and Jawahar 2020), (Qiao et al. 2021), (Zheng et al. 2021)] have proposed a modified TEDS metric named TEDS-Struct to
evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
• FinTabNet [67] We employ FinTabNet to increase samples’ diversity.,0.5,Weak
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc. Unlike many state-of-the-art methods that perform evaluations only at TEDs, our method also test the Structure TEDs on PubTabNet.",0.5,Weak
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc.",0.5,Weak
(2021) [89] Object Detector PDF Table Boundary Detection Fails to detect cell structures +NN Fails to return text,0.0,Neutral
"[89] introduced a Global table extractor (GTE) model based on object detector techniques, which themselves are based on neural networks",0.0,Neutral
"We unfortunately could not directly evaluate the approaches presented in [5, 25, 30, 41, 47, 89] using our cybersecurity corpus documents because their respective implementations were not available online.",-1.0,P-NR
"There are three approaches in the literature to handle table detection in documents: conventional rule-based [30, 87], metadata extraction [6, 31, 57] and machine learning and deep learning approaches [5, 25, 41, 47, 89].",0.0,Neutral
"Research models trained on reference datasets such as [5, 25, 30, 41, 47, 89] often have di culties coping with the complexity of real world document layouts [15].",0.0,Neutral
"The analysis of the layout of documents has been used by numerous researchers to develop techniques for detecting tables, layouts, and sections [5, 6, 18, 22, 23, 25, 27, 30, 34, 77, 89].",0.0,Neutral
"Data in MULTIHIERTT is collected from the FinQA dataset (Chen et al., 2021) and FinTabNet dataset (Zheng et al., 2021).",0.0,Neutral
"MULTIHIERTT are deployed based on the FinTabNet dataset (Zheng et al., 2021), which contains 89,646 pages with table annotations extracted from the annual reports of S&P 500 companies.",0.0,Neutral
"Examples for such models include OCR [7], document layout analysis [8]–[10], table structure recovery [11], [12], figure understanding [13], reference and citation resolution [14], etc.",0.0,Neutral
GTE [46] is a Global Table Extractor that consists of table detection and cell structured recognition.,0.0,Neutral
"Although [10,46] adopt post-processing operations to improve the accuracy, the result is not as expectedwhen the",0.0,Neutral
"Some recent works [8, 22, 23] have proposed a modified TEDS metric, denoted as TEDS-Struct, to evaluate table structure recognition accuracy only by ignoring OCR errors.",0.0,Neutral
[8] Figure 1: An outline of our table extraction approach.,0.0,Neutral
"To eliminate this assumption, another group of methods [8, 22, 23] proposed to detect the bounding boxes of",0.0,Neutral
"There have been a few studies that achieved promising results, such as
TableCellNet [10] reporting an F1 score of 0.937, GTE [35] reporting an F1 score of 96.24, but still this step may introduce extra to the table structure recognition result.",0.0,Neutral
"937, GTE [35] reporting an F1 score of 96.",0.0,Neutral
"Lately, a set of new model-architectures has been proposed by the community to address table-structure decomposition [37, 36, 18, 20].",0.0,Neutral
"However, this has definitely changed in recent years with the deliverance of PubTabNet [37], FinTabNet [36], TableBank [17] etc.",0.0,Neutral
"We rely on large-scale datasets such as PubTabNet [37], FinTabNet [36], and TableBank [17] datasets to train and evaluate our models.",0.0,Neutral
"• An augmented dataset based on PubTabNet [37], FinTabNet [36], and TableBank [17] with generated ground-truth for reproducibility.",0.5,Weak
"Recent public datasets include ICDAR 2019 [41], TableBank [65], PubTabNet [114], SciTSR [26], and FinTabNet [112].",0.0,Neutral
"The success of DL has marked the revisiting of table structure parsing by [7], which inspired follow-up research [27, 1, 6, 2, 28, 29, 30, 19, 31, 18, 32, 17].",0.0,Neutral
"In some best performing frameworks [17, 18, 19], they all jointly optimize the structure detection and entity relations in the structure, as in DocParser.",0.0,Neutral
"We see from the previous works, the most effective methods [17, 18, 19] always jointly optimize the cell locations and cell relationships.",0.0,Neutral
"Although many previous algorithms [2,13,18,20,22,30,31,34,35,40,45,46] have achieved impressive progress in the community, TSR is still a challenging task due to two factors of complicated tables.",0.0,Neutral
"To tackle this issue, the hierarchical GTE [45] leverages clustering algorithm for cell structure recognition.",0.0,Neutral
"Table structure recognition (TSR) aims to recognize the table internal structure to the machine readable data mainly presented in two formats: logical structure [18, 46] and physical structure [2, 13, 20, 22, 27, 30, 31, 34, 35, 40, 45].",0.0,Neutral
"Since FinTabNet has bounding boxes wrapped around the cell’s content, we pre-process the ground truth to obtain cell level coordinates (refer supplementary paper)2.",0.5,Weak
"Further, most cell detection methods [7, 41] evaluate using an Intersection over Union (IoU) threshold of 0.",0.0,Neutral
"Another recent work, GTE-Cell [41], follows a nested approach by first classifying whether a table includes ruling lines or not, and then uses specifically tailored heuristics to identify the table structure.",0.0,Neutral
We use FinTabNet [41] dataset for training.,0.5,Weak
We use FinTabNet [41] dataset for training and evaluation.,0.5,Weak
"Other datasets [4, 42, 41, 8] have annotations such that a cell’s bounding box is the smallest rectangle that encapsulates its content.",0.0,Neutral
"However, there are two concerning factors for cell detection: (i) How are the ground truth cell boundingboxes annotated? (ii) What is the IoU threshold value used to compute evaluation metrics? For table cells, most datasets [22, 4, 6, 17, 42, 41] have cell box annotation that spans the smallest rectangle encapsulating its content.",0.0,Neutral
"For evaluation also, we pre-process ICDAR-2013 [8], cTDaR [7], SciTSR [4], PubTabNet [42] and FinTabNet [41] datasets before computing IoU with the corresponding predictions.",0.0,Neutral
"We use FinTabNet [41] dataset to train TOD-Net for cell, row, and column detection.",0.5,Weak
"Most datasets [22, 4, 6, 17, 42, 41] use words or cell content as low-level entities to build inter-tabular relationships.",0.0,Neutral
"[22, 4, 17, 42] introduced many large-scale automatically generated datasets, but they do not accurately represent real-world complex tables as seen in the business documents [41, 27, 8].",0.0,Neutral
"While it is true that there are a few datasets of documents [6, 7, 22, 23] available with ground-truths for the layout bounding boxes, they focus on specific corpora such as scientific publications and are difficult to extend to other domains or customize for new element types.",0.0,Neutral
The current iteration of SciA11y focuses on improving screen reader accessibility in terms of navigation within the HTML document.,0.0,Neutral
"An intrinsic evaluation of HTML quality revealed that around 86% of papers in our sample had reasonable extractions (good or okay readability per criteria described in Wang et al. [17]), and a preliminary user study with 6 BLV researchers was also positive, with all users stating they would be likely to use the system in the future were it to have high coverage of papers.",0.0,Neutral
"The system renders this content in HTML and introduces accessibility features such as navigational headings, tagged objects, table of contents, and within-document navigational links.",0.0,Neutral
"For example, we intend to integrate features for reading graphs and charts [4–6], mathematical equations [2, 7, 13, 16], and further processing table images into HTML [8, 18, 19].",0.0,Neutral
A set of 1.5 million open access papers are available to read in HTML format at our demo site: https://scia11y.org/.,0.0,Neutral
SciA11y: Converting Scientific Papers to Accessible HTML.,0.0,Neutral
Science publishers are shifting towards dual publishing or alternate publishing schemes2 that yield accessible HTML or XML versions of papers in addition to PDF.,0.0,Neutral
We propose and demonstrate a pipeline for extracting the semantic content of paper PDFs and rendering this content as an accessible HTML document.,0.0,Neutral
"In summary, we introduce the SciA11y system for rendering scientific PDFs as HTML, which can increase the accessibility of these documents for screen readers.",0.0,Neutral
We combine textual elements from S2ORC and figure/table elements from DeepFigures to create the HTML representation.,0.0,Neutral
"Although methods [29, 31, 43] achieve performance improvement by directly predicting cell boxes, they may suffer from “cell boundary ambiguity” problem, especially on those blank or non-gridded cell cases.",0.0,Neutral
"Different from previousworks [29, 31, 43], we adopt word bounding boxes rather than cells as table elements to avoid cell boundary ambiguity issue.",0.0,Neutral
"4(c) shows our method can well handle the table including non-gridded cells, which may cause the “cell boundary ambiguity” problem to the cell detection-based methods [29, 31, 43].",0.0,Neutral
"A group of methods [27, 29, 41, 43] try to recover the relations of elements based on heuristic algorithms.",0.0,Neutral
"Recently, there has been a shift in the research literature from traditional rule-based methods [3,10,17] for TE to data-driven methods based on deep learning (DL) [13,16,21].",0.0,Neutral
"Recently, larger datasets [2, 8, 21, 22] for TSR have been created by collecting crowd-sourced annotations automatically from existing documents.",0.0,Neutral
"To overcome this, researchers have turned recently to crowd-sourcing to construct larger datasets [8, 21, 22].",0.0,Neutral
"Modeling approaches One of the most common modeling approaches for TSR is to frame the task as some form of object detection [13, 16, 21].",0.0,Neutral
"Other approaches use custom pipelines that branch to consider different cases separately, such as training separate models to recognize tables with and without visible borders surrounding every cell [13, 21].",0.0,Neutral
"Limited by this, existing TSP approaches can only handle table structure parsing in a relative simple scenario by grouping detected cells into tables [11, 16, 9, 23].",0.0,Neutral
"For a more practical requirement of parsing table structures from images taken by hand-held cameras in the wild, the existing state-of-the-art approaches [13, 14, 11, 16, 9, 23] are prone to fail as the commonly-used assumption of tabular images no longer holds.",0.0,Neutral
"Recently, FinTabNet [23] and SciTSR [2] datasets add the cell coordinates and row-column information to become the most complete and large-scale dataset for table structure parsing task.",0.0,Neutral
"However, these methods mainly focuses on the well-conditioned document images, where the tables [16, 23, 12, 9, 23, 14] are well-aligned to the image axes.",0.0,Neutral
"Moreover, they either rely on external pre-/post-processing methods to further refine their predictions [11,13] or incorporate memory intensive deformable convolutions [12,20].",0.0,Neutral
"We develop FINQA based on the publicly available earnings reports of S&P 500 companies from 1999 to 2019, collected in the FinTabNet dataset (Zheng et al., 2021).",0.0,Neutral
"Eleven finance professionals collectively constructed FINQA based on the earnings reports of S&P 500 companies (Zheng et al., 2021).",0.0,Neutral
"This diversity should help using the trained models in other domains, which could be evaluated using new data sets generated for other domains such as FinTabNet [15] for the financial domain.",0.0,Neutral
"For table extraction, we use our Global Table Extractor (GTE) (Zheng et al. 2020), which leverages specialized object detection models and clustering techniques to extract, for each table, both its bounding box and cell structure.",0.5,Weak
"After that, a group of methods [36,23,38] tries to recover the cell relations based on some heuristic rules and algorithms.",0.0,Neutral
"Another group of methods solves the above problems in a bottom-up way to firstly detect the text blocks’ positions and then recover the bounding-boxes’ relations by heuristic rules [38] or GNN(Graph Neural Networks) [29,14,2,24,26].",0.0,Neutral
"To find out, we perform clustering experiments on the FinTabNet dataset from Zheng et al. (2021).",0.0,Neutral
"Applying the graph-based table representation for perceptional tasks, such as cell structure recognition [68] and functional block detection [29], is another meaningful direction.",0.0,Neutral
[52] published a framework for both the detection and structure recognition of tables in document images.,0.0,Neutral
"Recently, the problem of table structure recognition has been evaluated on the precise prediction of cellular boundaries in a tabular image [48], [52], [94].",0.0,Neutral
[52] is an end-to-end framework that not only detects the tables but recognizes the structures of tables in document images.,0.0,Neutral
There are a few existing large-scale datasets for scientific papers [9] and financial reports [8] but many documents in business are confidential.,0.0,Neutral
"To begin, we apply our table extraction module (based on the GTE framework [8]) to the user’s document collection.",0.5,Weak
"Paper metadata from these sources are harmonized, PDFs are converted into machinereadable JSON using the S2ORC pipeline described in [54] and HTML representations of tables in papers are added using IBM Watson Discovery’s Global Table Extractor [115].",0.5,Weak
"This tool is available online.12 For table extraction, Zheng et al (2021) proposed Global Table Extractor (GTE) to detect tables and recognize cell structure jointly based on visual context.",0.5,Weak
[36] introduced an end-to-end framework that not only detected but also recognized table structures in document images.,0.0,Neutral
"MULTIHIERTT (Zhao et al., 2022), which is also based on FinTabNet, combines the challenges of the above-mentioned datasets, bringing together complex tabular structures and hybrid table/text contexts.",0.0,Neutral
"companies that were released as part of FinTabNet (Zheng et al., 2021).",0.0,Neutral
"FinQA (Chen et al., 2021) is based on a collection of financial reports published by U.S. companies that were released as part of FinTabNet (Zheng et al., 2021).",0.0,Neutral
"TableBank[4] Image 145k X SciTSR[16] Image 15k X X PubTabNet[3, 11] Image 568k X X X† FinTabNet[11] Image, PDF 113k X X X†",0.0,Neutral
"Datasets Several large datasets have been introduced recently for TE [17, 18, 4, 3, 11].",0.0,Neutral
"Among previous datasets, PubTabNet is the largest with 568k tables, although no test set has been released for benchmarking.",0.0,Neutral
"PubTabNet, for example, is created using an automated alignment procedure [18] to match the same table in unaligned pairs of PDF and XML versions of the same scientific articles from the PMCOA database.",0.0,Neutral
"Recently, there has been a shift in the research literature from traditional rule-based methods [7–9] for TE to data-driven methods based on deep learning (DL) [2, 10, 11].",0.0,Neutral
"In terms of usability, FinTabNet is the most widely applicable, as it annotates source PDF documents rather than rendered images; and both FinTabNet and the updated version of PubTabNet [11] have the most complete annotations, as they both contain location information for cells.",0.0,Neutral
"However, both FinTabNet and PubTabNet are missing bounding boxes for rows, columns, and blank cells; and in these datasets a cell’s bounding box covers only its text portion, which ignores the role of the non-text portion of the cell.",0.0,Neutral
"We hope to apply canonicalization to data from additional domains, such as the financial documents in FinTabNet.",0.0,Neutral
"Recent datasets for table structure recognition (TSR) [4, 3, 11], while large, have several limitations, including in some cases lack of location information for cells, compatibility with only specific model architectures, and lack of guarantees for data quality and consistency.",0.0,Neutral
"TableBank[4] Image 145k X SciTSR[16] Image 15k X X PubTabNet[3, 11] Image 568k X X X† FinTabNet[11] Image, PDF 113k X X X†",0.0,Neutral
"Datasets Several large datasets have been introduced recently for TE [17, 18, 4, 3, 11].",0.0,Neutral
"Among previous datasets, PubTabNet is the largest with 568k tables, although no test set has been released for benchmarking.",0.0,Neutral
"PubTabNet, for example, is created using an automated alignment procedure [18] to match the same table in unaligned pairs of PDF and XML versions of the same scientific articles from the PMCOA database.",0.0,Neutral
"Recently, there has been a shift in the research literature from traditional rule-based methods [7–9] for TE to data-driven methods based on deep learning (DL) [2, 10, 11].",0.0,Neutral
"In terms of usability, FinTabNet is the most widely applicable, as it annotates source PDF documents rather than rendered images; and both FinTabNet and the updated version of PubTabNet [11] have the most complete annotations, as they both contain location information for cells.",0.0,Neutral
"However, both FinTabNet and PubTabNet are missing bounding boxes for rows, columns, and blank cells; and in these datasets a cell’s bounding box covers only its text portion, which ignores the role of the non-text portion of the cell.",0.0,Neutral
"We hope to apply canonicalization to data from additional domains, such as the financial documents in FinTabNet.",0.0,Neutral
"Recent datasets for table structure recognition (TSR) [4, 3, 11], while large, have several limitations, including in some cases lack of location information for cells, compatibility with only specific model architectures, and lack of guarantees for data quality and consistency.",0.0,Neutral
"Name Format # Tables Cell Topology Cell Content Cell Location Canonical Ground Truth TableBank[4] Image 145k X SciTSR[16] Image 15k X X PubTabNet[3] Image 568k X X FinTabNet[11] Image, PDF 113k X X X",0.0,Neutral
"Recent datasets for table structure recognition (TSR) [4, 3, 11], while large, have several limitations, 40 including in some cases missing cell-level location information, compatibility with only specific 41 model architectures, and lack of guarantees for data quality and consistency.",0.0,Neutral
"Datasets Several large datasets have been introduced recently for table extraction [17, 18, 4, 3, 11].",0.0,Neutral
"Recently, there has been a shift in the research literature from traditional rule-based methods [7–9] 34 for table extraction to data-driven methods based on deep learning (DL) [2, 10, 11].",0.0,Neutral
"This diversity should help using the trained models in other domains, which could be evaluated using new data sets generated for other domains such as FinTabNet [15] for the financial domain.",0.0,Neutral
"• Auto-generated annotations: These statements are auto-generated using a random paraphraser and table understanding service (Zheng et al., 2020).",0.0,Neutral
"…papers Author-written and expertderived TLDRs FacetSum (Meng et al, 2021) 60k articles from Emerald journals Paper and structured abstract
For table extraction, Zheng et al (2021) proposed Global Table Extractor (GTE) to detect tables and recognize cell structure jointly based on visual context.",0.0,Neutral
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR
[37] 2022 GTE WACV PubTabNet ICDAR 2013 + ICDAR 2019 - - NR Jain et al.[38]9 2022 TSR-DSAW ESANN PubTabNet ICDAR 2013 - - NR,0.0,Neutral
A Jain [125] spatial associations + dynamic programming techniques Recognizing complex table structures having multi-span rows/columns and missing cells Uses OCR to read words from images Not language agnostic,0.0,Neutral
A Jain [125] suggests training a deep network to recognize the spatial relationships between various word pairs included in the table picture in order to decipher the table structure.,0.0,Neutral
[39]12 2021 No name ICDAR PubTabNet ICDAR 2019 + unlv - X NR,0.0,Neutral
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR
"The success of DL has marked the revisiting of table structure parsing by [7], which inspired follow-up research [27, 1, 6, 2, 28, 29, 30, 19, 31, 18, 32, 17].",0.0,Neutral
[28] used biLSTM on table cell detection by encoding rows/columns in neural networks before the softmax layer.,0.0,Neutral
