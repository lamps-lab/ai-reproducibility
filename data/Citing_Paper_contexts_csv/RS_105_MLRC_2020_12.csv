text,label_score,label
"images, and let the model learn the mapping of a noisy image to a clean image [37], [75]–[78], [81], [82], [86] or let the residual of a clean image and a noisy image be used as a target, and learn to separate the noise from the noisy image [47], [79], [80].",,
"Next, we improved the structure of the loss used in both the SADNet and Restormer structures.",,
"We selected SADNet [25], which represents a small network based on the UNet improvement, and Restormer, with a more complex network and better fitting abilities, as the night defogging network.",,
"…2021), MPRNet (Zamir et al. 2021), HE (Gonzalez and Woods 2008), LDR (Lee, Lee, and Kim 2013), WAHE (Arici, Dikbas, and Altunbasak 2009), SADNet (Chang et al. 2020), DnCNN (Zhang et al. 2017)), two domain adaptation methods (ENT (Rusak et al. 2021), BNA (Schneider et al. 2020)) and one feature…",,
"We select eight image enhancement methods (SRN-Deblur (Tao et al. 2018), MIMOUNet (Cho et al. 2021), MPRNet (Zamir et al. 2021), HE (Gonzalez and Woods 2008), LDR (Lee, Lee, and Kim 2013), WAHE (Arici, Dikbas, and Altunbasak 2009), SADNet (Chang et al. 2020), DnCNN (Zhang et al. 2017)), two domain adaptation methods (ENT (Rusak et al. 2021), BNA (Schneider et al. 2020)) and one feature restoration method (FD-Module (Wang et al. 2020)) as comparison.",,
"image denoising [32], dehazing [33], and SR [15].",,
"The MCWNNM [3], TWSC [4], DnCNN-B [5], CBDNet [18], RIDNet [12], AINDNet [22], VDN [20], SADNet [28], DANet+ [31], DeamNet [50], VDIR [32], and CycleISP [51] were compared.",,
"The BM3D [1], TNRD [68], MCWNNM [3], TWSC [4], DnCNN-B [5], CBDNet [18], RIDNet [12], AINDNet [22], VDN [20], SADNet [28], DANet+ [31], DeamNet [50], VDIR [32], CycleISP [51], BUIFD [19], IRCNN [26], FFDNet [6], ADNet [11], BRDNet [9], DudeNet [10], ADNet [11], and AirNet [27] were utilized for comparison.",,
Models Parameters Gray Color TNRD [68] 27 DnCNN-B [5] 668 673 BUIFD [19] 1075 1085 IRCNN [26] 186 188 FFDNet [6] 485 852 ADNet [11] 519 521 DudeNet [10] 1077 1079 BRDNet [9] 1113 1117 RIDNet [12] 1497 1499 CBDNet [18] - 4365 VDN [20] 7810 7817 VDIR [32] - 2227 DeamNet [50] 1873 1876 AINDNet [22] - 13764 AirNet [27] - 8930 SADNet [28] 3450 3451 DANet+ [31] - 9154 CycleISP [51] - 2837 DRANet 1612 1617,,
"A spatial-adaptive denoising network (SADNet) was designed in [28] for image blind denoising, where the deformable convolution [29, 30] was used to adjust the convolution kernel size to fit the spatial support area of the network.",,
SADNet [137] introduces a residual spatial-adaptive block and context block to sample related features and obtain multi-scale information.,,
"DNN Methods Supervised MLP [115] 2012 AWGN A multilayer perceptron model TNRD [116] 2016 AWGN A trainable nonlinear diffusion model DnCNN [24] 2017 AWGN A CNN model with batch normalization and residual learning NLNet [30] 2017 AWGN A nonlocal CNN model for grayscale/color image denoising UDNet [117] 2018 AWGN A robust and flexible CNN model using UNet HSID-CNN [118] 2018 AWGN A 2D and 3D combined CNN model VNLNet [31] 2018 AWGN The first nonlocal CNN model for video denoising FFDNet [119] 2018 AWGN A flexible CNN model with tunable input noise levels HSI-DeNet [120] 2018 AWGN and Stripe A CNN model for mixed noise removal PRI-PB-CNN [121] 2018 AWGN an Rician A combination of sliding window scheme and 3D CNN GCBD [28] 2018 AWGN and Realistic A GAN-based blind denoiser DnGAN [122] 2018 AWGN and Blur A GAN model with maximum a posteriori (MAP) framework DBF [123] 2019 AWGN and Realistic Integration of CNN into a boosting algorithm FCCF [40] 2019 AWGN and Realistic A deep fusion scheme of collaborative filtering (CBM3D) and CNN DIDN [124] 2019 AWGN and Realistic A deep iterative down-up CNN model CBDNet [125] 2019 Realistic A convolutional blind denoising network ViDeNN [126] 2019 AWGN A combination of spatial and temporal filtering with CNN RIDNet [127] 2019 AWGN and Realistic A single stage model with feature attention MIFCN [128] 2019 Realistic A fully convolutional network model DRDN [129] 2019 Realistic A dynamic residual dense network model SGN [130] 2019 Realistic A self-guided network with top-down architecture ADGAN [131] 2019 Realistic An attentive GAN model with noise domain adaptation QRNN3D [132] 2020 AWGN and Stripe A deep recurrent neural network model with 3D convolution CycleISP [133] 2020 Realistic A GAN based framework modeling the camera pipeline GCDN [134] 2020 AWGN and Realistic A graph convolution network based denoising model FastDVDNet [43] 2020 AWGN A real-time video denoising network without flow estimation DANet [135] 2020 Realistic A Bayesian framework for noise removal and generation LIDIA [136] 2020 AWGN A lightweight model with instance adaptation SADNet [137] 2020 AWGN A CNN model with residual spatial-adaptive blocks AINDNet [138] 2020 AWGN and Realistic A CNN model based on a transfer learning scheme MIRNet [139] 2020 Realistic A multi-scale model with parallel convolution streams PD-denosing [140] 2020 AWGN and Realistic A CNN model with pixel-shuffle down-sampling adaptation ADRN [141] 2020 AWGN A deep residual network model with channel attention scheme MPRNet [142] 2021 Realistic A multi-stage network with cross-stage feature fusion and attention modules DRUNet [143] 2021 AWGN A plug-and-play method with deep denoiser prior DudeNet [144] 2021 AWGN and Realistic A dual network with four different blocks and sparse mechanism InvDN [145] 2021 Realistic An invertible denoising network with wavelet transformation Restormer [145] 2021 AWGN and Realistic An efficient Transformer model with multi-head attention networks DCDicL [146] 2021 AWGN A deep convolution dictionary learning denoising network NBNet [147] 2021 AWGN and Realistic A UNet based model that learns subspace basis and image projection DeamNet [148] 2021 AWGN and Realistic A CNN model with adaptive consistency prior and self-attention mechanism PNGAN [42] 2021 AWGN and Realistic A GAN based model for real image synthesis with domain alignment SwinIR [149] 2021 AWGN A shifted window (Swin) Transformer model with self-attention mechanism NAFNet [150] 2022 Realistic A UNet based model without nonlinear activation layers MalleNet [151] 2022 AWGN and Realistic A CNN with spatially-varying convolution kernels Masked [152] 2023 AWGN and Realistic A novel training approach that randomly masks pixels of the input image SERT [153] 2023 AWGN, Mixed and Realistic A Transformer framework with rectangle self-attention modeling",,
"Category Training srategy Methods Year Noise modeling Key words
DNN Methods
Supervised
MLP [115] 2012 AWGN A multilayer perceptron model TNRD [116] 2016 AWGN A trainable nonlinear diffusion model DnCNN [24] 2017 AWGN A CNN model with batch normalization and residual learning NLNet [30] 2017 AWGN A nonlocal CNN model for grayscale/color image denoising
UDNet [117] 2018 AWGN A robust and flexible CNN model using UNet HSID-CNN [118] 2018 AWGN A 2D and 3D combined CNN model
VNLNet [31] 2018 AWGN The first nonlocal CNN model for video denoising FFDNet [119] 2018 AWGN A flexible CNN model with tunable input noise levels
HSI-DeNet [120] 2018 AWGN and Stripe A CNN model for mixed noise removal PRI-PB-CNN [121] 2018 AWGN an Rician A combination of sliding window scheme and 3D CNN
GCBD [28] 2018 AWGN and Realistic A GAN-based blind denoiser DnGAN [122] 2018 AWGN and Blur A GAN model with maximum a posteriori (MAP) framework
DBF [123] 2019 AWGN and Realistic Integration of CNN into a boosting algorithm FCCF [40] 2019 AWGN and Realistic A deep fusion scheme of collaborative filtering (CBM3D) and CNN
DIDN [124] 2019 AWGN and Realistic A deep iterative down-up CNN model CBDNet [125] 2019 Realistic A convolutional blind denoising network ViDeNN [126] 2019 AWGN A combination of spatial and temporal filtering with CNN RIDNet [127] 2019 AWGN and Realistic A single stage model with feature attention MIFCN [128] 2019 Realistic A fully convolutional network model DRDN [129] 2019 Realistic A dynamic residual dense network model SGN [130] 2019 Realistic A self-guided network with top-down architecture ADGAN [131] 2019 Realistic An attentive GAN model with noise domain adaptation QRNN3D [132] 2020 AWGN and Stripe A deep recurrent neural network model with 3D convolution CycleISP [133] 2020 Realistic A GAN based framework modeling the camera pipeline GCDN [134] 2020 AWGN and Realistic A graph convolution network based denoising model
FastDVDNet [43] 2020 AWGN A real-time video denoising network without flow estimation DANet [135] 2020 Realistic A Bayesian framework for noise removal and generation LIDIA [136] 2020 AWGN A lightweight model with instance adaptation
SADNet [137] 2020 AWGN A CNN model with residual spatial-adaptive blocks AINDNet [138] 2020 AWGN and Realistic A CNN model based on a transfer learning scheme MIRNet [139] 2020 Realistic A multi-scale model with parallel convolution streams
PD-denosing [140] 2020 AWGN and Realistic A CNN model with pixel-shuffle down-sampling adaptation ADRN [141] 2020 AWGN A deep residual network model with channel attention scheme
MPRNet [142] 2021 Realistic A multi-stage network with cross-stage feature fusion and attention modules DRUNet [143] 2021 AWGN A plug-and-play method with deep denoiser prior DudeNet [144] 2021 AWGN and Realistic A dual network with four different blocks and sparse mechanism
InvDN [145] 2021 Realistic An invertible denoising network with wavelet transformation Restormer [145] 2021 AWGN and Realistic An efficient Transformer model with multi-head attention networks DCDicL [146] 2021 AWGN A deep convolution dictionary learning denoising network NBNet [147] 2021 AWGN and Realistic A UNet based model that learns subspace basis and image projection DeamNet [148] 2021 AWGN and Realistic A CNN model with adaptive consistency prior and self-attention mechanism PNGAN [42] 2021 AWGN and Realistic A GAN based model for real image synthesis with domain alignment SwinIR [149] 2021 AWGN A shifted window (Swin) Transformer model with self-attention mechanism NAFNet [150] 2022 Realistic A UNet based model without nonlinear activation layers MalleNet [151] 2022 AWGN and Realistic A CNN with spatially-varying convolution kernels Masked [152] 2023 AWGN and Realistic A novel training approach that randomly masks pixels of the input image
SERT [153] 2023 AWGN, Mixed and Realistic A Transformer framework with rectangle self-attention modeling
Self-supervised/ Unsupervised
Noise2Noise [154] 2018 AWGN and Poisson A model trained on noisy image pairs of the same scene SCGAN [155] 2019 AWGN Unsupervised modeling with self-consistent GAN Noise2Void [156] 2019 AWGN A blind-spot masking strategy that excludes central pixels of the input Self2Self [157] 2020 AWGN and Realistic A dropout based strategy that generates noisy pairs with the Bernoulli sampler
C2N [158] 2021 Realistic A GAN based model that generates real noisy images from arbitrary clean ones UDVD [159] 2021 AWGN An unsupervised video denoising network based on blind-spot strategy
R2R [160] 2021 AWGN and Realistic A model trained on recorrupted noisy pairs Neighbor2Neighbor [161] 2021 AWGN and Realistic A model trained on noisy pairs generated by the downsampling strategy
IDR [162] 2022 AWGN and Realistic A model trained on noisy pairs with an iterative refinement strategy CVF-SID [163] 2022 Realistic A CNN model with a self-supervised cycle
Blind2Unblind [164] 2022 AWGN and Realistic A blind-spot network with a global-aware mask mapper AP-BSN [165] 2022 Realistic A blind-spot network (BSN) with an asymmetric pixel-shuffle downsampling strategy DDS2M [166] 2023 AWGN A deep diffusion model with a variational spatio-spectral module C-BSN [167] 2023 Realistic A conditional BSN with downsampled invariance loss
MM-BSN [168] 2023 Realistic A BSN method with multiple masks of different shapes LGBPN [169] 2023 Realistic A BSN with a patch-masked convolution module and a dilated Transformer block SASL [170] 2023 Realistic A BSN with spatially adaptive supervision
traditional denoisers at certain noise levels.",,
"Therefore, a context block [26] here is introduced into the minimum size network between the extraction path and expansion path to expand the receptive field while maintaining the resolution, as shown in Fig.",,
conventional methods lack adaptability to image content and result in over-smoothing artifacts [26].,,
2 illustrates the neural network structure of the SpatialAdaptive denoising network (SADNet) in SAID method [26].,,
"TABLE IV REAL IMAGE DENOISING COMPARISON WITH DNCNN [12], BM3D [40], CBDNET [46], RIDNET [47], AINDNET [48], VDN [49], SADNET [50], DANET+ [51], CYCLEISR [52], DEAMNET [53] ON SIDD [38] (? DENOTE THE MODEL USING ADDITIONAL TRAINING SETS TO TRAIN THE MODEL).",,
"image [5], [6], [8], [9], [10], [24], [25], [26], [27].",,
"[5], [6], [7] have relatively better denoising effects on public datasets.",,
"Subsequently, many researchers proposed other image denoising methods [2, 5, 9, 10, 17, 21, 25, 32] based on deep learning by adding AWGN to clean sRGB images.",,
"The supervised denoising methods [2,5,7,12,40,41,43] have relatively better performance than the self-supervised.",,
Method RIDNet AINDNet VDN SADNet DANet+ CycleISP MIRNet DeamNet MPRNet DAGL Uformer MAXIM Restormer CSformer CSformer∗ Dataset [5] [39] [90] [11] [91] [93] [94] [64] [95] [55] [83] [77] [92] (Ours) (Ours),,
"Qualitative enhancement comparisons of our model on synthetic compression blur samples with SADNet (Chang et al., 2020) and MPRNet (Zamir et al.",,
"A B C D E
FIGURE 7 Qualitative enhancement comparisons of our model on synthetic compression blur samples with SADNet (Chang et al., 2020) and MPRNet (Zamir et al., 2021).",,
"The baselines for compression deblur are (Dong et al., 2015; Chang et al., 2020; Chen et al., 2021; Jiang et al., 2021; Zamir et al., 2021).",,
"In detail, we report the evaluation results from the classic denoising method BM3D [11], CNN-based methods DnCNN [59], CBDNet [15], RIDNet [3], AINDNet [19], VDN [52], SADNet [6], DANet [53], CycleISP [54], MIRNet [55], DeamNet [39], DAGL [32], MAXIM [45], and Transformerbased methods Uformer [49] and Restormer [57].",,
"Firstly, we set the layer numbers of both branches the same, which are [2, 4, 4, 6, 4, 4, 2].",,
BM3D DnCNN CBDNet RIDNet AINDNet VDN SADNet DANet CycleISP MIRNet DeamNet DAGL MAXIM Uformer Restormer Xformer Dataset Method [11] [59] [15] [3] [19] [52] [6] [53] [54] [55] [39] [32] [45] [49] [57] (ours),,
"They use globally-shared convolution kernels in the convolution operator for aggregating neighboring information, such as using dilated convolutions [6, 11] to increase the receptive fields and adopting multi-stage [71] or multi-scale features [23, 70] for better encoding spatial context.",,
"With the development of deep convolutional neural networks (CNNs), many learning-based methods [61, 62, 9, 63, 41] have been proposed for image denoising.",,
"Following RDN [63] and SADNet [9], we adopt 800 highresolution training images from the DIV2K dataset [3] to train our models for Gaussian denoising at four different noise levels (σ = 10, 30, 50, 70).",,
"To evaluate denoising performance on synthetic noisy images, we compared our proposed DUMRN with several state-of-the-art denoising methods including classical model-based methods (BM3D [13] and CBM3D [12]), deep unfolding methods (TNRD[11], CSCNet [50] and DeamNet [46]), and deep-learning based methods (DnCNN [61],
FFDNet [62], NLRN[38], SADNet [9], DudeNet [53], COLANet [41], Neb2Neb [30], and RDN [63]).",,
"[9] incorporated multi-size dilated convolutions into a U-Net [47] structure to capture multi-scale contextual information, which helps to restore rich details in complex scenes.",,
"Benefiting from the incorporation of the physical model and deep CNNs, our model also outperforms state-of-the-art deep learning-based methods DnCNN, SADNet, COLANet, and RDN. Taking color image denoising with noise level σ = 50 as an example, our DUMRN obtains 0.65dB/0.0207, 0.45dB/0.0161,
and 1.37dB/0.0320 improvements over DnCNN on Kodak24, CBSD68, and Urban100 respectively.",,
"FFDNet [62], NLRN[38], SADNet [9], DudeNet [53], COLANet [41], Neb2Neb [30], and RDN [63]).",,
"Recently, several methods [23, 9, 59, 58] have employed multi-scale strategies to enlarge the receptive field and improve the performance of deep networks.",,
"Like other denoising methods [61, 62, 63, 9, 41, 53], we performed data augmentation on the training images, using random flipping and rotation.",,
"To assess the effectiveness of the proposed network, we adopt the same L2 loss function as previous works [61, 62, 9, 41].",,
"Although DUMRN is a little slower than DnCNN [61], DudeNet [53], and SADNet [9], it achieves much better denoising performance.",,
"our method with CBM3D [53], DnCNN [2], FFDNet [54], IRCNN [10], DHDN [55], SADNet [56], RDN [57], and IPT [14].",,
"For the denoising, we compared our method with CBM3D [53], DnCNN [2], FFDNet [54], IRCNN [10], DHDN [55], SADNet [56], RDN [57], and IPT [14].",,
"Following (Chang et al. 2020), our ADFNet adopts an encoder-decoder framework to pursue an effective and efficient target.",,
"Besides, multi-scale features have played an important role in the image denoising task, including two mainstream designs: global encoder-decoder architectures (Chang et al. 2020) and local multi-scale feature extraction module (Zamir et al.",,
"2019), dilated convolution (Chang et al. 2020), multi-scale design (Gou et al.",,
"To verify the effectiveness of the proposed ADFNet for Gaussian noisy images, we compare it with the existing methods include DnCNN (Zhang et al. 2017), FFDNet (Zhang, Zuo, and Zhang 2018), RNAN (Zhang et al. 2019), RIDNet (Tian, Xu, and Zuo 2020), RDN (Zhang et al. 2020), SADNet (Chang et al. 2020), DeamNet (Ren et al. 2021), P3AN (Hu et al. 2021), and MSANet (Gou et al. 2022).",,
"2020), SADNet (Chang et al. 2020), DeamNet (Ren et al.",,
"Shao, X.; Chen, P.; Zhang, Y.; Chang, S.K. Domain Fusion CNN-LSTM for Short-Term Power Consumption Forecasting.",,
Meng Chang [24] proposed a new adaptive denoising network (SADNet) that can effectively remove blind noise from single images.,,
"Chang, M.; Li, Q.; Feng, H.; Xu, Z. Spatial-Adaptive Network for Single Image Denoising.",,
"For image denoising, the applicability of GANs has been explored in recent years (Chen et al. 2018; Kim et al. 2019; Yue et al. 2020; Chang et al. 2020; Lin et al. 2019; Marras et al. 2020).",,
"While the NSS has been broadly explored in classic denoisers, a few works have attempted to incorporate this internal image property into deep networks for image denoising  (Lefkimmiatis 2017; Xia and Chakrabarti 2020; Plötz and Roth 2018; Zhang et al. 2019; Liu et al. 2018; Guo et al. 2021; Xu et al. 2020; Lefkimmiatis 2018; Chang et al. 2020; Tachella et al. 2021).",,
[6] utilized the deformable convolution to sample the spatially related features for weighting.,,
"denoising [21, 56], gamma correction, tone mapping and auto-contrast) to the pipeline in the same order, except white-balancing strategies.",,
"They generally contain several convolution layers with skip connections and non-linear activation functions, such as recursively branched deconvolutional network RBDN [21], multi-level wavelet based network MWCNN [22], feed-forward blind denoising network DnCNN [23], fast and flexible denoising network FFDNet [24] and residual spatial-adaptive denoising network SADNet [25].",,
"We also compare our method with several state-of-the-art CNN-based filters, including DnCNN [65], TNRD [8], RDN [68], SADNet [6], KPN [40], ADNet [46], and DeamNet [42].",,
"In addition, our method also achieves better accuracy than the CNN-based methods, i.e. TNRD, DnCNN, SADNet, RDN, in all the four tasks.",,
"(a) Input (b) Bilateral (c) Guided (d) NLM
(e) BM3D (f) TNRD (g) DnCNN (h) SADNet
(i) RDN (j) Swin (k) IPT (l) KPN
(m) ADNet (n) DeamNet (o) RNAN (p) SwinIR
(q) Resformer (r) Ours (s) GT
Fig.",,
"Base(�2=50) Large(�2=50)
Method CBSD68 Urban100 CBSD68 Urban100
TNRD 26.64/0.762 25.51/0.804 27.25/0.765 26.30/0.814 DnCNN 26.45/0.729 25.22/0.768 27.46/0.776 26.63/0.826 SADNet 27.50/0.785 26.53/0.829 27.96/0.801 27.57/0.861 RDN 27.53/0.778 26.85/0.834 27.78/0.789 27.38/0.850 Swin 25.99/0.738 24.26/0.765 27.66/0.790 26.71/0.840 IPT 27.10/0.765 26.17/0.817 27.83/0.806 27.55/0.860 KPN 27.17/0.762 26.42/0.828 27.69/0.797 27.32/0.848 ADNet 26.33/0.756 25.69/0.808 27.32/0.762 26.53/0.828 DeamNet 27.59/0.758 27.38/0.853 27.79/0.798 27.68/0.863 RNAN 27.82/0.793 27.30/0.850 28.01/0.801 27.95/0.872 SwinIR 27.73/0.789 27.05/0.843 27.90/0.794 27.71/0.868 Resformer 27.65/0.792 27.24/0.853 27.94/0.801 27.89/0.871 Ours 27.94/0.799 27.64/0.864 28.15/0.806 28.29/0.876
Table 9.",,
"Method Flops/G params/M memory/MB time/s/img
TNRD 2.832 0.056 2961 0.1816 DnCNN 28.02 0.558 2175 0.0223 SADNet 14.52 3.451 1363 0.0082 RDN 278.6 5.552 13761 0.0651 Swin 77.72 1.557 9435 0.1131 IPT 573.2 176.7 13346 0.2565 KPN 40.61 27.65 2399 0.0217 ADNet 26.16 0.521 2501 0.0270 DeamNet 111.9 1.876 6077 0.0707 SwinIR 43.99 0.866 14058 0.0935 Resformer 107.9 26.12 20381 0.3003 Ours 121.7 2.425 4105 0.0898
Table 7.",,
"Method Gaussian Bilateral Guided NLM BM3D TNRD DnCNN SADNet RDN Swin PSNR 21.98 22.39 22.23 22.14 22.41 22.85 22.49 22.97 23.03 22.31 SSIM 0.796 0.812 0.808 0.768 0.829 0.820 0.684 0.830 0.837 0.765
Method IPT KPN ADNet DeamNet RNAN SwinIR Resformer CRM LIME BIMEF PSNR 19.08 21.71 22.86 22.19 23.00 23.01 23.04 17.20 16.76 13.88 SSIM 0.719 0.727 0.750 0.818 0.831 0.832 0.829 0.622 0.444 0.595
Method SRIE MF RRM Dong JED DeepUPE RetinexNet KinD GLAD Ours PSNR 13.03 16.97 15.36 16.72 13.69 13.36 16.77 19.66 19.72 23.11 SSIM 0.607 0.505 0.654 0.479 0.658 0.465 0.429 0.821 0.685 0.849
We highlight the best-performing model in each metrics.",,
"We also compare our method with several state-of-the-art CNN-based ilters, including DnCNN [65], TNRD [8], RDN [68], SADNet [6], KPN [40], ADNet[46] and DeamNet[42].",,
"LIVE1 Classic5
Method CQL=10 CQL=20 CQL=30 CQL=40 CQL=10 CQL=20 CQL=30 CQL=40
Gaussian 25.24/0.735 26.44/0.785 26.84/0.803 27.05/0.812 27.69/0.757 28.63/0.796 28.95/0.811 29.09/0.818 Bilateral 26.07/0.766 28.52/0.842 29.83/0.872 30.73/0.889 28.48/0.785 30.60/0.843 31.75/0.868 32.45/0.881 Guided 25.96/0.742 27.67/0.790 28.45/0.809 28.95/0.820 28.08/0.762 29.41/0.801 30.06/0.818 30.42/0.827 NLM 25.69/0.749 28.06/0.830 29.37/0.865 30.29/0.886 27.82/0.767 30.14/0.841 31.51/0.872 32.46/0.889 BM3D 26.06/0.768 28.61/0.848 29.97/0.880 30.91/0.897 28.72/0.795 31.05/0.854 32.30/0.875 33.09/0.886 SA-DCT 26.63/0.778 28.83/0.848 30.03/0.879 30.88/0.897 28.88/0.795 30.91/0.853 32.13/0.879 32.99/0.894 ARCNN 26.50/0.774 28.75/0.846 30.01/0.877 30.83/0.894 28.59/0.784 30.75/0.848 32.00/0.877 32.87/0.894 TNRD 26.89/0.783 29.19/0.853 30.48/0.885 31.39/0.902 28.99/0.792 31.15/0.853 32.42/0.880 33.34/0.897 DnCNN 26.78/0.786 29.13/0.856 30.48/0.887 31.38/0.903 28.98/0.799 31.27/0.859 32.58/0.885 33.40/0.900 SADNet 27.12/0.792 29.29/0.859 30.67/0.890 31.44/0.905 29.12/0.802 31.32/0.861 32.62/0.885 33.37/0.898 RDN 27.13/0.793 29.48/0.861 30.80/0.891 31.70/0.908 29.28/0.804 31.42/0.861 32.71/0.887 33.60/0.901 Swin 26.37/0.768 28.58/0.840 29.79/0.873 30.64/0.891 28.39/0.777 30.52/0.842 31.82/0.873 32.71/0.891 IPT 22.04/0.721 19.64/0.751 17.18/0.735 16.69/0.738 20.87/0.675 19.07/0.691 16.76/0.663 15.13/0.669 KPN 27.14/0.794 29.55/0.871 30.82/0.895 31.73/0.915 29.26/0.806 31.47/0.865 32.73/0.882 33.62/0.899 ADNet 26.95/0.787 29.23/0.841 30.52/0.892 31.40/0.911 29.12/0.799 31.25/0.855 32.48/0.885 33.47/0.900 DeamNet 27.20/0.791 29.53/0.856 30.89/0.895 31.79/0.909 29.34/0.809 31.46/0.869 32.63/0.871 33.52/0.887 RNAN 27.23/0.796 29.64/0.864 30.88/0.894 31.78/0.910 29.27/0.807 31.50/0.864 32.78/0.889 33.66/0.903 SwinIR 27.22/0.794 29.60/0.862 30.90/0.892 31.81/0.908 29.26/0.803 31.48/0.861 32.79/0.887 33.68/0.902 Restormer 27.22/0.796 29.53/0.864 30.87/0.893 31.79/0.910 29.24/0.808 31.52/0.864 32.79/0.888 33.64/0.902 Ours 27.31/0.806 29.68/0.873 30.97/0.902 31.85/0.918 29.42/0.817 31.60/0.873 32.87/0.898 33.74/0.912
We highlight the best-performing model in each column.",,
The background block [27] obtained good results in the image fragment [28] and the blur removal task [29].,,
"Furthermore, several recent methods using deep CNNs[33,34,35,36,37,38] have also demonstrated promising denoising performance.",,
"Similar to many denoising methods [10,12], the plug-in denoisers d0 and d1 are designed in a multiscale manner.",,
"We then modify the original loss function of CBDNet and SADNet, i.e., L2 + LAsymmetric + LTV and L2, by attaching our proposed objective.",,
", CBDNet [13] and SADNet [4] are availed as the generation network G(·).",,
"The most representative denoising network, i.e., FFDNet [62], as well as the state-of-theart denoising networks, i.e., CBDNet [13] and SADNet [4] are availed as the generation network G(·).",,
"On image denoising task, our IDLIR is compared with DnCNN, MLP, BM3D, CBDNet, RIDNet, AINDNet, VDN, SADNet, DANet+ and CycleISP.",,
", RESCAN [3] , PReNet [2] , MSPFN [4] for deraining and SADNet [7] and DANet+ [8] for denoising.",,
", MPRNet [1], PReNet [2] , RESCAN [3] and MSPFN [4] for image deraining, and HINet [5], DnCNN [6], SADNet [7] and DANet+ [8] for image denoising.",,
"Image denoising and image deraining are two representative tasks, and a variety of restoration methods have been developed, e.g., MPRNet [1], PReNet [2] , RESCAN [3] and MSPFN [4] for image deraining, and HINet [5], DnCNN [6], SADNet [7] and DANet+ [8] for image denoising.",,
"Thanks to the power of deep learning, state-of-the-art restoration networks have been developed by learning a mapping from degraded image to latent clean image, e.g., RESCAN [3] , PReNet [2] , MSPFN [4] for deraining and SADNet [7] and DANet+ [8] for denoising.",,
"In addition, to maintain the global context information and enlarge the receptive filed, Context Block (CB) [64] is introduced which also constructs multi-scale information and makes network robust to noise.",,
"“D2Conv” (Dynamic Deformable Convolution, introduced in Section V-C) is utilized based on the encoded physical feature from Physics-informed Network fH∗ and the “CB” (Context Block [64]) helps keep the global context of features at the bottleneck of Restoration Network fRN .",,
The encoder and decoder of Restoration Network is composed of HINBlocks and ResBlocks respectively adopted from HINet [65] which proposes half-instance normalization for image restoration.,,
"With the great learning capability of deep neural networks [12, 13], plenty of methods were proposed to solve the image restoration tasks [3, 25, 35, 46, 48, 49], as well as image dehazing [7, 27, 31, 36], in a supervised manner.",,
"We choose MLP [2], CBDNet [3], RIDNet [4], DANet [7], SADNet [8] and DeamNet [10] as the comparison methods and use the commonly used PSNR and SSIM as the quantitative metrics to measure the denoising performance.",,
"We compare our DGUNet with several recent methods [10, 53, 76, 77, 79] and report the evaluation results (PSNR and SSIM) in Tab.",,
"Recently, deep learning models [6], [9], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42] make significant advances in image denoising, yielding",,
"Later the optimization strategies were substitute by deep learning methods, building on excellent results reported for in image processing tasks like denoising [40,30,39,3], deblurring [37,25,4], super-resolution [35,26,7,21], etc.",,
"After that, more advanced denoisers [3, 6, 13, 35, 36, 39] are proposed to improve denoising performance under supervision.",,
", U-Net [29], DnCNN [38], FFDNet [39], RIDNet [3], SANet [6], rely on numerous noisy-clean pairs, which are costly and hard to collect.",,
"However, supervised denoisers, e.g., U-Net [29], DnCNN [38], FFDNet [39], RIDNet [3], SANet [6], rely on numerous noisy-clean pairs, which are costly and hard to collect.",,
"∗Corresponding author With the development of neural networks, learningbased denoisers [3, 6, 13, 29, 35, 36, 38, 39] have recently shown superior performance than traditional methods [5, 8, 9, 12].",,
"Note that the FLOPs number of our method (14.1G) is much smaller than that of RDN (46.6G) or SADNet (45.8G), when the input is a 64 × 64 RGB image.",,
"state-of-the-art task-specific methods, including deraining methods (DDN [23], SPANet [67], RESCAN [43], PreNet [58], BRN [57],SPDNet [73] and PCNet [34]); demoireing methods ( DMCNN [63], MopNet [29], FHDe2Net [29], HRDN [71], WDNet [47] and MBCNN [84]); and denoising methods (DnCNN [78], FFDNet [80], RDN [81], and SADNet [9]) on PSNR.",,
"A.2 Comparison with task-specific methods
As shown in Table 7, we firstly compare our methods with state-of-the-art denoising methods (DnCNN [78], FFDNet [80], RDN [81], and SADNet [9]).",,
"In the supplementary material, we compare our TAPE-Net with 12
state-of-the-art task-specific methods, including deraining methods (DDN [23], SPANet [67], RESCAN [43], PreNet [58], BRN [57],SPDNet [73] and PCNet [34]); demoireing methods ( DMCNN [63], MopNet [29], FHDe2Net [29], HRDN [71], WDNet [47] and MBCNN [84]); and denoising methods (DnCNN [78], FFDNet [80], RDN [81], and SADNet [9]) on PSNR. Qualitative results on deraining are shown in Figs.",,
"Specifically, MSANet outperforms RIDNet with 2.48dB (0.0049), SADNet with 0.6dB (0.0024), DeamNet with 1.49dB (0.0073) in PSNR (SSIM) values.",,
"In brief, MSANet achieves the highest PSNR and SSIM values compared to other methods, e.g., 0.85dB, 0.1dB, 0.09dB gains in PSNR, and 0.0066, 0.0015, 0.0013 gains in SSIM over the RIDNet, SADNet, and DeamNet, respectively.",,
"In addition, [6, 11, 35] employed encoderdecoder architectures to combine the high-to-low with low-to-high resolution features through the skip-connections.",,
"To solve this problem, image denoising, as an essential step for image perception, has been extensively studied in the past decades [6, 10, 50, 51].",,
", BM3D [10], DnCNN [50], FFDNet [51], CLEARER [12], RNAN [53], SADNet [6] and DeamNet [33].",,
"In recent, a large number of methods have been proposed and achieved state-of-the-art performance [6, 12, 33, 50, 51].",,
"3, CBDNet and PD result in residual noises and pseudo artifacts, RIDNet, SADNet and DeamNet severely destroy the textures and obtain over-smoothed results.",,
"Taking the noise level of 70 as an example, our method can achieve PSNR gains about 0.03 ∼ 0.27dB, and SSIM gains about 0.0010 ∼ 0.0111 over the stateof-the-art methods, i.e., SADNet, RNAN, and DeamNet.",,
SADNet [6] proposed residual spatial-adaptive block and multi-scale context block to constitute a denoising network.,,
"For comparisons, we choose seven representative denoising methods, i.e., BM3D [10], DnCNN [50], FFDNet [51], CLEARER [12], RNAN [53], SADNet [6] and DeamNet [33].",,
"For comparisons, we compare MSANet with 10 denoising methods, i.e., CDnCNN-B, CBM3D [9], FFDNet+, CBDNet, N3Net [32], PD [54], PR [47], RIDNet [4], SADNet and DeamNet, and use the corresponding pretrained models provided by their authors and refer to their results reported in the online submission system and papers.",,
"With the popularity of deep neural networks, various network architectures have been designed and achieved state-of-the-art performance [6, 33, 50, 51].",,
", AWGN, read noise), while the model from [14, 26, 27, 28, 29] have the ability to process the real-world signal-dependent noise (e.",,
Noises suffered from demosaicing procedure gradually deminish after iterately soving Equation (5).,,
We iterately conduct the demosaic and denoising algorithm according to Equation (5).,,
"1, 2 [6] Meng Chang, Qi Li, Huajun Feng, and Zhihai Xu.",,
"RIDNet [29], SADNet [51], MIRNet-v2 [52].",,
"We also compare our DDS-Net with other state-of-theart static denoising methods: FFDNet [50], CBDNet [28], RIDNet [29], SADNet [51], MIRNet-v2 [52].",,
"Besides, the visual results of DDS-Nets are comparable to SADNet and MIRNet-v2.",,
"Following the works proposed by [46, 8], Deformable ResBlocks are employed in each scale of the decoder (as shown in the bottom right of Fig.",,
"In terms of the hyperparameter of training, our settings are basically the same as [Chang et al. 2020].",,
"2008], denoising [Buades et al. 2005; Chang et al. 2020; Condat 2010; Foi et al. 2008], white balancing [Gijsenij et al.",,
"Therefore, we introduce a context block [Chang et al. 2020] into the minimum scale between encoder and decoder, which increases the receptive field and reconstructs multiscale information without further downsampling.",,
"…image signal processing subtasks, such as image demosaicing [Dubois 2006; Hirakawa and Parks 2005; Li et al. 2008], denoising [Buades et al. 2005; Chang et al. 2020; Condat 2010; Foi et al. 2008], white balancing [Gijsenij et al. 2012; Schwartzburg et al. 2014; van de Weijer et al. 2007], and…",,
"Therefore, we introduce a
context block [Chang et al. 2020] into the minimum scale between encoder and decoder, which increases the receptive field and reconstructs multiscale information without further downsampling.",,
"While different from the method in [Chang et al. 2020], we directly concatenate the input and the upsampled offset.",,
"Deep Learning With the rapid development of computing power, deep learning technology has led to many breakthroughs in the field of vision, including low-level denoising [10,30,48], deblurring [15,31], super-resolution [32,52] and high-level recognition [53], segmentation [54].",,
SADNet [10] introduced the deformable convolution to implement spatial,,
"Many works based on deep convolutional neural networks (DCNNs) have achieved excellent results [10,23,25].",,
"The results of [62], [64], [65], [66] are obtained from their reported results and those of [52], [57], [60], [61], [67], [68] are obtained from [57].",,
"These approaches perform well on
TABLE 4 Quantitative Evaluations for the Natural Image Denoising Problem on the SIDD Validation Dataset [63] in Terms of PSNR
Methods BM3D [52] DnCNN [67] FFDNet [60] CBDNet [61] RIDNet [68] IERD [57] GradNet [64] AINDNet [62] DANet [65] SADNet [66] SVLRM
Avg.",,
Methods BM3D [52] DnCNN [67] FFDNet [60] CBDNet [61] RIDNet [68] IERD [57] GradNet [64] AINDNet [62] DANet [65] SADNet [66] SVLRM,,
"For the evaluation of the cascaded designs, we tested seven handcrafted or learning-based denoisers, namely BM3D [89], DnCNN [90], FFDNet [91], CBDNet [92], GRDN [78], SADNet [93], and CycleISP [74].",,
"[6], in order to better estimate the current offset values, we transfer the offset values obtained in the last offset block {Δplast,Δmlast} to the current offset block (the purple line in Figs.",,
[5] proposed a novel spatial-adaptive denoising network for efficient single image noise removal.,,
"The learning-based methods focus on learning a latent mapping from the noisy image to the clean version, and can be divided into traditional learning-based [14, 9, 46, 33, 36] and deep network-based methods [31, 62, 41, 22, 18, 6, 17, 5, 13].",,
"Denoising is a widely studied research topic [6, 13], however the numerous works recently proposed [41, 25, 27, 9] suggest that the interest towards this problem is still very active, especially in the more challenging case of real raw data [4, 21, 23, 10].",,
"These methods most notably leverage residual learning [41], wavelet decomposition [27], attention mechanisms [25], and spatially adaptive processing [9].",,
"Our method obtains considerable gains over the state-of-the-art approaches, i.e., 0.19 dB over CycleISP [86] on SIDD and 0.21 dB over SADNet [11] on DND. Note that the DND dataset does not contain any training images, i.e., the complete publicly released dataset is just a test set.",,
Noisy Image CycleISP [86] AINDNet [40] DANet [85] SADNet [11] MPRNet (Ours),,
Reference Noisy RIDNet [4] AINDNet [40] VDN [84] SADNet [11] CycleISP [86] DANet [85] MPRNet (Ours),,
"opment of deep neural networks has a significant boost for image denoising algorithms [56], [57], [58], [59], [60], [61], [62].",,
"Due to powerful nonlinear modeling capabilities, deep learning has become the dominant method for image denoising [8, 23, 30, 46].",,
"Methods SIDD DND Model ProfilePSNR SSIM PSNR SSIM # Param FLOPs Time CBM3D [4] 25.65 0.685 34.51 0.851 - - 21.49
DnCNN [17] 23.66 0.583 32.43 0.790 0.67 175 0.22 CBDNet [22] 30.78 0.801 38.06 0.942 4.37 161 0.19 RIDNet [23] 38.71 0.951 39.26 0.953 1.5 393 0.68
AINDNet [86] 38.95 0.952 39.37 0.951 13.76 1284 0.49 VDN [27] 39.23 0.955 39.38 0.952 7.81 168 0.20
SADNet [87] 39.46 0.957 39.59 0.952 4.23 76 0.22 DANet [24] 39.47 0.957 39.58 0.955 9.15 59 0.12 CycleISP [88] 39.52 0.957 39.56 0.956 2.83 739 1.36 MPRNet [25] 39.62 0.958 39.80 0.954 15.74 2296 2.75
VIRNet (Ours) 39.64 0.958 39.83 0.954 15.40 658 0.88 PNGAN [89] 40.06 0.960 40.25 0.962 15.74 2296 2.75
Fig.",,
"We compared VIRNet with several typical real-world denoising methods, including MPRNet [25], CycleISP [88], DANet [24], SADNet [87], VDN [27] and so on (see Table 4).",,
"Combining the results in Table 1 and Table 2, it should be rational to say
9 (a) Noisy (b) VDN (c) SADNet (d) DANet (e) CycleISP (g) VIRNet (f) MPRNet
Fig.",,
"Specifically, we still use the VAE [23] for image quality estimation and develop a new restoration network based on deformable network architecture like [24].",,
"The context block comprises several dilated convolution blocks and a final fusion block, and we put it into the minimum scale between the encoder and the decoder, similar to a previous network [58].",,
"Note that the FLOPs number of our method (14.1G) is much smaller than that of RDN (46.6G) or SADNet (45.8G), when the input is a 64 × 64 RGB image.",,
"Method DnCNN [21] FFDNet [22] RDN [23] SADNet [1] TAPE-Net (Ours) TAPE-Net-swin-L (Ours)
PSNR/SSIM 34.31/0.892 33.26/0.890 38.70/0.901 38.41/0.900 37.90/0.896 38.76/0.901 FLOPS (G) 14.4 0.87 46.6 45.8 14.1 5.3
2 Table S3: Quantitative comparison with the state-of-the-art deraining methods on Rain200L and Rain200H.",,
"As shown in Table S2, we firstly compare our methods with state-of-the-art denoising methods (DnCNN [21], FFDNet [22], RDN [23], and SADNet [1]).",,
Method DnCNN [21] FFDNet [22] RDN [23] SADNet [1] TAPE-Net (Ours) TAPE-Net-swin-L (Ours) PSNR/SSIM 34.,,
"Similarly, [25] introduces deformable convolution [26] to adapt to spatial textures and edges for image denoising task.",,
CBM3D TNRD MLP DnCNN CBDNet SADNet RIDNet VDN AINDNet GNSCNet COLA-Net Dataset [69] [35] [70] [16] [71] [60] [25] [72] [61] [62] [31] Proposed 25.,,
BM3D DnCNN MWCNN NLRN SADNet RIDNet AINDNet GNSCNet DudeNet GCDN DAGL COLA-Net Dataset σ [12] [16] [22] [32] [60] [25] [61] [62] [63] [64] [65] [31] Proposed 32.,,
"The results on the first row are obtained from the paper [1], the second row represents our results on a similar patch.",,
"In the original paper [1], an encoder-decoder architecture consisting a residual spatial-adaptive block, namely RSAB, is proposed for removing spatially-variant and channel-dependent noise while processing larger regions in each step by utilizing deformable convolutions.",,
"Compared methods: CBM3D [18], CDnCNN-B [19], CBDNet [4], PD [3], RIDNet [5], SADNet [1].",,
"The results on the first two rows are obtained from the paper [1], the third row represents our results on the same image.",,
"In particular, convolutional neural networks (CNN) can learn the hierarchy of complex image features, so that a variety of CNN-based methods have been developed for denoising (Zhang et al., 2017b; Chang et al., 2020), deraining (Wei et al.",,
"For the denoising, we compared our method with CBM3D (Dabov et al., 2007), DnCNN (Zhang et al., 2017a), FFDNet (Zhang et al., 2018b), IRCNN (Zhang et al., 2017b), DHDN (Park et al., 2019), and SADNet (Chang et al., 2020).",,
"…can learn the hierarchy of complex image features, so that a variety of CNN-based methods have been developed for denoising (Zhang et al., 2017b; Chang et al., 2020), deraining (Wei et al., 2019; Ren et al., 2019), deblurring (Nah et al., 2017; Kupyn et al., 2019), deblocking (Li et al., 2020b;…",,
