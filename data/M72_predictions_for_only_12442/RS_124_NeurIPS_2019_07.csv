text,target_predict,target_predict_label,target_model_6_predict,target_predict_model_6_label
"As exhibited in Table 2 , we compare the proposed learning aradigm with the other representative approaches for data-free nowledge distillation, including DAFL [4] , ZSKT [5] , DFQ [26] , FAD [25] , ADI [6] , and CMI [7] .",1,related,1,positive
"Comparison of DFKD methods
As exhibited in Table 2 , we compare the proposed learning aradigm with the other representative approaches for data-free nowledge distillation, including DAFL [4] , ZSKT [5] , DFQ [26] , FAD [25] , ADI [6] , and CMI [7] .",1,related,1,positive
"DFKD methods incline to exploit a generator to synthesize masive samples to support the knowledge distillation learning beween teacher and student [4,5,25] .",1,related,1,positive
"Given the aforementioned context, we present a pipeline that extracts the functionality of a black-box classification model (named teacher) into a locally created copymodel (called student) via knowledge distillation [1, 7, 27, 29, 53] and self-paced active learning, as shown in Figure 1.",1,related,1,positive
"Compared Methods: We compare our proposed KD(3) with representative data-free methods, including DataFree Learning (DAFL) [7], Data-Free Adversarial Learning (DFAD) [15], Dual Discriminator Adversarial Distillation (DDAD) [50], DeepInversion (DI) [45], Zero-Shot Knowledge Transfer (ZSKT) [30], Pseudo Replay Enhanced Data-Free Knowledge Distillation (PRE) [3], DataFree Quantization (DFQ) [10], Contrastive Model Inversion (CMI) [16], and Data-Free Noisy Distillation (DFND) [6] (the only existing method using the webly collected data).",1,related,1,positive
"Compared Methods: We compare our proposed KD3 with representative data-free methods, including DataFree Learning (DAFL) [7], Data-Free Adversarial Learning (DFAD) [15], Dual Discriminator Adversarial Distillation (DDAD) [50], DeepInversion (DI) [45], Zero-Shot Knowledge Transfer (ZSKT) [30], Pseudo Replay Enhanced Data-Free Knowledge Distillation (PRE) [3], DataFree Quantization (DFQ) [10], Contrastive Model Inversion (CMI) [16], and Data-Free Noisy Distillation (DFND) [6] (the only existing method using the webly collected data).",1,related,1,positive
ZSKT [10] extends the basic DFKD framework to the adversarial DFKD framework by making the prediction mismatch between the teacher and student.,1,related,1,positive
It also establishes the basic framework of DFKD. ZSKT [10] takes the student network into image synthesis and proposes the adversarial DFKD framework.,1,related,1,positive
"We compare IFHE with advanced DFKD methods including DAFL [9], ZSKT [10], ADI [11], DFQ [22] and CMI [12].",1,related,1,positive
"DFKD methods generate hard samples on which the student disagree with the teacher by enlarging the divergence between their prediction distribution [11], [14]–[16] (see Fig.",1,related,1,positive
"Some methods generate pseudo samples via adversarial training [9], [13].",1,related,1,positive
"We use ZSKT (Micaelli & Storkey, 2019), CMI (Fang et al., 2021), and OOD (Asano & Saeed, 2021) as the baseline distillation methods.",1,related,1,positive
"We evaluated one vanilla KD using clean training data (Hinton et al., 2015) and three training-datafree KD method which use synthetic data (ZSKT (Micaelli & Storkey, 2019) & CMI (Fang et al., 2021)) or
out-of-distribution (OOD) data as surrogate distillation data (Asano & Saeed, 2021).",1,related,1,positive
"Following the setup of ZSKT (Micaelli & Storkey, 2019), we use WideResNet (Zagoruyko & Komodakis, 2016) for training 10-way or 43-way classifiers on CIFAR10 and GTSR-B, respectively.",1,related,1,positive
"Here, representative implementations include the first adversarial data-free distillation, Zero-Shot Knowledge Transfer (ZSKT) (Micaelli & Storkey, 2019), the state-of-theart data-free KD methods, CMI (Fang et al., 2021).",1,related,1,positive
"Unlike previous DFKD methods, which store synthetic images [7, 10, 13, 27, 29, 43], we use a feature pool to store the hidden features of the synthetic images when optimizing G and use them to improve the diversity of later training image generation.",1,related,1,positive
"Since the existing complete opensource SOTA methods do not report results on ImageNet or
*https://github.com/fastai/imagenette †https : / / www . kaggle . com / datasets / ambityga /
imagenet100
its subsets in their papers, we use two open-sourced methods CMI and ZSKT for comparison.",1,related,1,positive
"Table 1 shows the DFKD results by our method and several state-of-the-art (SOTA) methods, i.e., DAFL [7], ZSKT [29], ADI [43], DFQ [10], LS-GDFD [27], and CMI [13]) when using the same teacher network.",1,related,1,positive
"Next, we compare our mSARC with the feature-level constraint used in several feature-level constraints used in recent KD methods [16, 18, 29, 32, 49].",1,related,1,positive
"Inspired by adversarial knowledge distillation (AKD), which aims to iteratively improve the student model’s performance by forcing it to learn from generated hard samples (Fang et al., 2019; Micaelli and Storkey, 2019a; Heo et al., 2019), we propose an adversarial framework for distilling a proprietary LLM into a compact student model.",1,related,1,positive
"To verify the efficiency and efficacy of our method, we apply our AKD framework to transfer the knowledge of ChatGPT 2 onto an open-source foundation LLM, known as LLaMA (Touvron et al., 2023), consisting of 7 billion parameters.",1,related,1,positive
"We select Alpaca’s training data (generated from only 175 manually selected seed instructions) as the initial training instructions and execute three iterations of AKD, resulting in a total of 70K data that our model is trained on. we’ve christened our model as Lion, drawing inspiration from the art of “distillation”.",1,related,0,negative
"Inspired by the success of adversarial knowledge distillation (AKD) (Fang et al., 2019; Micaelli and Storkey, 2019a; Heo et al., 2019), we turn to optimize an upper bound of the expectation —the expectation of the model discrepancy on “hard samples”, where the teacher T and the student S have a relatively large performance gap.",1,related,1,positive
"We compare our proposed method with different data-free generation methods, including: Dream [1], DeepInv [44], DAFL [4], ZSKT [29], DFQ [7], CMI [12], and Fast [11].",1,related,1,positive
"Student update strategies: (a) Typical student update by optimizing the Knowledge-Acquisition loss (LAcq) with the batch pseudo samples (x̂), produced by the generator (G) [5, 10, 20].",1,related,1,positive
AVKD [16] extends the ZSKT [12] and formulates the adversarial exploration process as variational autoencoders (VAE).,1,related,1,positive
"Finally, we optimize the closeness of activations [41] between the last k layers of model M and B on the forget set Df",1,related,1,positive
We consider two related baselines of MAD which are ABM [31] and DFKD-Mem [3].,1,related,1,positive
"In this experiment, we found that DFKD-Mem often performs worse than ABM on CIFAR100 and TinyImageNet.",1,related,0,negative
"2, it is clear that MAD significantly outperforms both ABM and DFKD-Mem on all datasets.",1,related,1,positive
2 Comparison with related baselines We consider two related baselines of MAD which are ABM [31] and DFKD-Mem [3].,1,related,1,positive
"In ABM, LKD(x) is the Kullback-Leibler (KL) divergence between class probabilities of T and S computed on x:
LKD(x) , DKL (Tp(x)‖Sp(x)) = C∑ c=1 Tp(x)[c] · (log Tp(x)[c]− log Sp(x)[c]) , (3)
where Tp(x) = softmax(T(x)) and Sp(x) = softmax(S(x)) denote the class probabilities of T and S computed on x, respectively; and C is the total number of classes.",1,related,1,positive
We trained ABM and DFKD-Mem using exactly the same settings for training MAD.,1,related,0,negative
"Adversarial Belief Matching (ABM) [31] proposed an adversarial learning framework between S and G via optimizing the following min-max objective:
min S max G
Ez∼p(z) [LKD(G(z))] (1)
⇔min S max G Ez∼p(z),x=G(z) [LKD(x)] , (2)
where LKD(x) denotes the knowledge distillation (KD) loss, i.e., the discrepancy between S(x) and T(x).",1,related,1,positive
"For the baselines, we compare state-of-the-art DFKD methods as DAFL[7], ZSKT[41], ADI[61], DFQ[9], CMI[16] and PRE-DFKD[4].",1,related,1,positive
"For the baselines, we compare SOTA DFKD methods as DAFL[7], ZSKT[27], ADI[43], DFQ[9], CMI[14] and PRE-DFKD[4].",1,related,1,positive
"Note that we adopt mean square error (MSE) as objective in both phases other than KL divergence adopted in [20], because logit matching has better generalization capacity [16].",1,related,1,positive
"In observing the fact that distilling knowledge using uncertain data is more effective since they are usually close to the model’s decision boundaries [20], we introduce an entropy-regularized method to explicitly encourage the replayed data to be close to decision boundaries given by the reference model.",1,related,1,positive
We follow [20] to train the generator by including an auxiliary model A(·; θA) as a helper to assist the convergence of the generator.,1,related,1,positive
We use the toy experiment proposed by [20] to illustrate the effects of our entropy regularization in Figure 5.,1,related,1,positive
"To unconditionally distill knowledge from a given DNN, Data-Free Distillation (DFD) methods have been proposed [14, 15].",1,related,1,positive
"For adversarial training, this paper uses the training scheme of AdvProp [10], which uses two separate batch normalization (BN) layers for clean and adversarial examples, arg ∑   ∝ , ; , + ∑   , ; ∗, = arg + (7)",1,related,1,positive
"∗ =   ( , ) (8) To avoid estimating the tricky ∗ the data, a generative network is introduced G( , g) to control the data distribution [10].",1,related,1,positive
"For adversarial training, this paper uses the training scheme of AdvProp [10], which uses two separate batch normalization (BN) layers for clean and adversarial examples,arg ∑ ∝ , ; , +∑ , ; ∗, = arg + (7)
where balances the contrast loss with parameterized contrast loss and the contrast loss with ∗ parametric .",1,related,1,positive
AVKD [119] extends the ZSKT [39] and formulates the adversarial exploration process as variational autoencoders (VAE).,1,related,1,positive
"…are compared in our experiments: (1) generative methods that train a generative model for synthesis, including DAFL (Chen et al. 2019), ZSKT (Micaelli and Storkey 2019), DFQ (Choi et al. 2020), and Generative DFD (Luo et al. 2020) (2) non-generative methods that craft transfer set in a…",1,related,1,positive
"In Table 2, we find that there is something unique about using a single image, as our method outperforms several synthetic datasets, such as FractalDB Kataoka et al. (2020), randomly initialized StyleGAN Baradad et al. (2021), as well as the GAN-based approach of (Micaelli & Storkey, 2019).",1,related,1,positive
"We compare the proposed MosaicKD to various baselines, including data-free KD methods (DAFL [7], ZSKT [33], DeepInv.",1,related,1,positive
"…Distillation is motivated by robust optimization, where the x is forced to produce large disagreement between teacher ft(x; θt) and student fs(x; θs) [Micaelli and Storkey, 2019; Fang et al., 2019], i.e., maximize a Kullback–Leibler divergence term:
Ladv(x) = −KL(ft(x)/τ‖fs(x)/τ) (3) Unified…",1,related,1,positive
"We compare our approach with the following baselines: DAFL [Chen et al., 2019], ZSKT [Micaelli and Storkey, 2019], ADI [Yin et al., 2020], DFQ [Choi et al., 2020] and
LS-GDFD [Luo et al., 2020].",1,related,1,positive
"Finally, to achieve the desired tradeoffs, we give a criterion to tune the selection or generation (e.g., using GANs) of reference data used in DMP.
Notations Dtr is a private training data.",1,related,1,positive
"The adversary has complete access to the victim model, and uses data-free knowledge transfer (Micaelli & Storkey, 2019; Fang et al., 2019) to train a student model.",1,related,0,negative
"As can be seen, our approach achieves 42.4% mIoU on Cityscapes, which gains the improvements of DFAD, DAFL and ZSKT by 3%, 12.3% and 36.1%, respectively.",1,related,0,negative
"For baselines, we adopt the vanilla KD [24] method and several very recent data-free knowledge distillation works that achieve strong performance, including two non-generative based methods ZSKD [34] and BNS [39], and some generative based data-free methods, i.e., ZSKT [33], KEGNET [36], DAFL [32], DFAD [38], DFQ [58] and CMI [59].",1,related,1,positive
"The other generative based data-free methods, i.e., ZSKT [33], KEGNET [36], DAFL [32], DFAD [38], DFQ [58] and CMI [59], achieve the test accuracies of 85.95%, 91.83%, 92.22%, 93.30%, 93.26% and 94.08% on CIFAR-10 dataset, 66.29%, 73.91%, 74.47%, 69.43%, 67.01% and 74.01% on CIFAR-100 dataset.",1,related,1,positive
"For VOC dataset, our method yields mIoU 40.7%, which boosts the performance of DFAD, DAFL and ZSKT by 5%, 11.4% and 29.9%, respectively.",1,related,0,negative
"The student model is trained simultaneously with the generator via KD. Adversarial Belief Matching (ABM) was proposed in (Micaelli and Storkey 2019), which trains a generative adversarial network (Goodfellow et al. 2014) to search for samples on which the student model poorly matches the teacher,…",1,related,1,positive
"Our work builds on recent advances in data-free knowledge distillation, which involve a generative model to synthesize queries that maximize disagreement between the student and teacher models [27, 14].",1,related,1,positive
"Our work systematically transitions from a data-free knowledge distillation paradigm [14, 27] to a data-free model extraction scenario.",1,related,1,positive
"Naively, one could generate these queries randomly [27, 14].",1,related,1,positive
"Our work is related to zero-shot knowledge distillation methods [1, 3, 4, 8, 24, 28, 38], with the difference that we regard the teacher model as a black box, and to model stealing methods [17, 30, 31, 32, 35, 36], with the difference that we focus on accuracy and not on minimizing the number of API calls to the black box.",1,related,1,positive
"In this context, we train the student on a proxy data set with images and classes different from those used to train the black-box, in a setting known as zero-shot or data-free knowledge distillation [1, 3, 4, 8, 24, 28, 38].",1,related,1,positive
We do not include Modified-ZSKT because samples of Modified-ZSKT vastly outnumber the other two approaches.,1,related,1,positive
ModifiedZSKT performs worse than Random Text on DBPedia.,1,related,1,positive
"Modified-ZSKT Modified-ZSKT is extended from ZSKT (Micaelli and Storkey, 2019).",1,related,1,positive
"Train-
ing epochs are 2.5k(AG News), 10k(DBPedia), 10k(IMDb) with 48 samples per batch for all methods except ZSKT, which needs to train its generator from scratch (25k epochs in Modified-ZSKT).",1,related,0,negative
"d to generate synthetic data, which is either directly used as the training dataset (Chen et al., 2019a) or used to augment the training dataset (Liu et al., 2018b), shown in Fig. 8 (a). Furthermore, Micaelli and Storkey (2019) utilized an adversarial generator to generate hard examples for knowledge transfer. 2) A discriminator is introduced to distinguish the samples from the student and the teacher models by using either",1,related,1,positive
"o-shot knowledgedistillationmethod that doesnot useexistingdata. The transfer data is produced by modelling the softmax space using the parameters of the teacher network. In fact, the target data in (Micaelli and Storkey, 2019; Nayak et al., 2019) is generated by using the information from the feature representations of teacher networks. Similar to zero-shot learning, a knowledge distillation method with few-shot learning ",1,related,1,positive
"Not used N/A [45]* Inferred in the image domain [33], [34] [43], [41]* Generated from generators N/A [35], [36], Ours*",1,related,1,positive
"We compare our scheme to the previous data-free KD methods in [35,36,41] and show that we achieve the state-of-the-art data-free KD performance in all evaluation cases.",1,related,1,positive
"The key difference from [36] lies in the fact that given any metadata, we utilize them to constrain a generator in the adversarial learning framework.",1,related,1,positive
"If α = 0 in (2), the proposed scheme reduces to the adversarial belief matching presented in [36].",1,related,1,positive
"By iteratively updating the generator and student model, ABM performs knowledge distillation between T and S .
x = G(z) (19) LG = −DKL (T (x) ∥ S (x)) (20) LS = DKL (T (x) ∥ S (x)) (21)
In addition to the basic idea presented above, ABM also uses an additional Attention Transfer [43] term in the loss function of the student.",1,related,1,positive
"Our work is related to prior work on data-efficient distillation, which attempts to distill knowledge from a larger model to a small model with access to limited input data (Li et al., 2018) or in a zeroshot setting (Micaelli & Storkey, 2019; Nayak et al., 2019).",1,related,1,positive
"This is a natural assumption for a theft-motivated adversary who wishes to steal the oracle for local use—the adversary has data they want to learn the labels of without querying the model! For other adversaries, progress in generative modeling is likely to offer ways to remove this assumption [29].",1,related,1,positive
"We adopt a public library4 to reproduce the results of compared approaches: ZSKT [10], DAFL [3] and CMI [5], with the default model hyper-parameters.",1,related,1,positive
"For the baselines, we compare state-of-the-art DFKD methods as DAFL [11], ZSKT [10], ADI [12], DFQ [13], CMI [16] and PRE-DFKD [17].",1,related,1,positive
"• To solve an inherent biased sample generation problem of AL-based C-ZSKD, we propose a method to increase the variance of the adversarial sample distribution by using the convolution of probability distributions and Taylor series approximation.",1,related,1,positive
The numerical figures in the last row indicate the performance improvements compared to [7].,1,related,0,negative
"In the future, we will expand the AL-based C-ZSKD study in the direction of generating adversarial samples with high entropy in the embedding space.",1,related,1,positive
Numerical figures in the last row indicate improvements over [7].,1,related,0,negative
"• By analyzing the distribution of adversarial samples in the embedding space, this paper provides an insight into the characteristics of adversarial samples that are useful for AL-based C-ZSKD.",1,related,1,positive
The numerical figures in the last row indicate improvements over [7].,1,related,0,negative
We used the same training hyperparameters as in [20] with the proposed loss introduced in Eq.,1,related,0,negative
"To further evaluate the influence of the hyperparameter τ on the student distillation, we performed ablation with τ ∈ [2, 5, 10, 15, 20].",1,related,1,positive
"Similar to the original paper [20], we also use an attention-transfer loss LAT .",1,related,1,positive
"To evaluate this, we use recently proposed zero-shot knowledge transfer [20] with the skeptical students using a loss function enhanced by the auxiliary self KD, LSDF = LKL ( σ(gΦS (x, y), τ), σ(gΦT (x, y), τ) ) + LKL ( σ(gΦS (x, y), τ), σ(gΦS (x, y), τ) ) + γatLAT (4) The first term takes care of knowledge transfer from the teacher, while the second term helps train the final classifier.",1,related,1,positive
"To demonstrate skeptical student’s performance under data-free scenario, we leverage the idea of zero shot knowledge transfer [20], a state-of-the-art data-free distillation technique.",1,related,0,negative
Here the teacher model is WideR40-2 and student is WideR40-1 for comparability to [45].,1,related,1,positive
"In Table 4, we find that there is something unique about using a single image, as our method outperforms several synthetic datasets, as well as the GAN-based approach of [45].",1,related,1,positive
"For all of the methods used to derive the results of this paper, we used the PyTorch framework to train our deep networks along with external components such as Adversarial Belief Matching.",1,related,1,positive
"In detail, we had to integrate the following settings in our work, which were not mentioned in the paper[1] but implemented in the official repository of the authors: • To our knowledge, there is no mention about weight initialization in [2] or [3] from the authors of Wide ResNets.",1,related,0,negative
"Following the notations of [1], we let T (x), S(x; θ) and G(z;φ) be pretrained teacher network, student network and generator, where the weights θ and φ parameterize their respective networks that are to be trained.",1,related,1,positive
To follow the notation of [3] and [1] for the rest of this paper we refer to this method as KD-AT.,1,related,1,positive
• In the zero-shot method of [1] the paper does not mention that weight clipping is performed on both the student and generator networks.,1,related,0,negative
"In this work, we reproduce the paper Zero-shot Knowledge Transfer via Adversarial Belief Matching [1], where the authors present a method for distilling the knowledge of a larger pre-trained network to a smaller one, without the use of real data from the side of the student network.",1,related,1,positive
"• There is no description of the Generator network in [1] apart from ""We use a generic generator with only three convolutional layers, and our input noise z has 100 dimensions"".",1,related,1,positive
"We adapt the original ABM method for discrete sequences of text by applying first permuting the input sequence within the continuous embedding space, then quantizing the input such that it becomes a valid discrete sequence.",1,related,1,positive
We propose a more nuanced approach based on Adversarial Belief Matching (ABM) [10] which crafts a targeted input that maximizes the KL divergence between the teacher’s output distribution and the student’s output distribution.,1,related,1,positive
We also reduce the need for collecting and learning from personal data [76].,1,related,0,negative
"The adversary has complete access to the victim model, and uses data-free knowledge transfer (Micaelli & Storkey, 2019; Fang et al., 2019) to train a student model.",1,related,0,negative
