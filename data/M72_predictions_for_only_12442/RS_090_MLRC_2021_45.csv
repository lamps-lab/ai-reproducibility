text,target_predict,target_predict_label,target_model_6_predict,target_predict_model_6_label
com/chrisjtan/gnn_cff RCExplainer [6] https://developer.,1,related,0,negative
"Overall, RCExplainer performs best in terms of the Jaccard index.",1,related,0,negative
"We also consider generative methods: PGExplainer (Luo et al., 2020), GSAT (Miao et al., 2022), GraphCFE (CLEAR) (Ma et al., 2022), D4Explainer and RCExplainer (Bajaj et al., 2021).",1,related,1,positive
"We observe that a random edge modification removes more informative edges than GradCAM, Integrated Gradient, Occlusion, RCExplainer, and PGExplainer.",1,related,1,positive
"We also observe that RCExplainer and PGExplainer which perform well on the GInX score have a low edge ranking power, except for the BA-HouseGrid dataset.",1,related,1,positive
"So as to illustrate the effectiveness of our model, we compare our proposed method with interpretable graph learning methods including GRAD [51], ATT [40], GNNExplainer [51], PGExplainer [31], RCExplainer [1], and CF-GNNExplainer [30].",1,related,1,positive
We do not consider [34] and [4] since they are limited to graph classification.,1,related,1,positive
"Unfortunately, we were unable to apply RCExplainer and ProtGNN to this dataset due to an out-of-memory error and scalability issues, respectively.",1,related,0,negative
"RCExplainer [3] identifies decision regions based on graph embeddings that generate a subgraph explanation such that removing it changes the prediction of the remaining graph (i.e., counterfactual).",1,related,1,positive
"Finally, we consider inductive GNN explainers: PGExplainer [2], RCExplainer [3], TAGE [29].",1,related,1,positive
"We can achieve this goal by considering the decision boundary [11], manipulating the input with masks [113] or any other manipulations [2].",1,related,1,positive
"Then we will summarize existing works into a general framework of graph counterfactual explanation followed by a detailed review of existing approaches [2, 11, 24, 71, 107, 113, 115, 130, 131, 139, 164, 169].",1,related,1,positive
"com/lyingdoog/PGExplainer [4, 69] ADHD [10] -omics https://github.",1,related,0,negative
"com/RexYing/gnn-model-explainer [4, 12, 39] Tree-Ininity synthetic https://github.",1,related,1,positive
com/RexYing/gnn-model-explainer [4] BA-2motifs [40] synthetic https://github.,1,related,1,positive
"com/RexYing/gnn-model-explainer [4, 12, 39, 69] Tree-Grid [86] synthetic https://github.",1,related,1,positive
"com/RexYing/gnn-model-explainer [4, 12, 39, 69] BA-Community [86] synthetic https://github.",1,related,1,positive
"Finally, we collected fourteen papers (ifteen methods) [1, 4, 12, 13, 28, 36, 39, 41, 50, 53, 68, 69, 79, 82] that are at the base of this survey.",1,related,0,negative
87 Method [5] 2021 RCExplainer 3 3 3 3 0.,1,related,0,negative
"t the inputs is zero) and explanation misleading [166], [136].",1,related,1,positive
"We shall discuss and compare 19 recent GNN interpretability methods from the aforementioned categories: GNNExplainer [36], PGExplainer [37], GraphMask [38], SubgraphX [39], PGMExplainer [40], RelEx [41], GraphLime [42], RCExplainer [43], DnX [44], GCFExplainer [45], CF2 [46], SA [26], GuidedBP [26], CAM [21], Grad-CAM [47], LRP [48], GNNLRP [49], ExcitationBP [21], and XGNN [50].",1,related,1,positive
"We shall discuss and compare 19 recent GNN interpretability methods from the aforementioned categories: GNNExplainer [36], PGExplainer [37], GraphMask [38], SubgraphX [39], PGMExplainer [40], RelEx [41], GraphLime [42], RCExplainer [43], DnX [44], GCFExplainer [45], CF(2) [46], SA [26], GuidedBP [26], CAM [21], Grad-CAM [47], LRP [48], GNNLRP [49], ExcitationBP [21], and XGNN [50].",1,related,1,positive
