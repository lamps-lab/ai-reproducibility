text,target_predict,target_predict_label,target_model_6_predict,target_predict_model_6_label
The code of one paper (TGRNet; [35]) was executable after we contacted the original authors.,1,related,0,negative
"First, we compare LORE with models which directly predict logical locations including Res2TIM (Xue, Li, and Tao 2019) and TGRNet (Xue et al. 2021).",1,related,1,positive
We tune the model provided by Xue et al. (2021) on WTW dataset to make a thorough comparison.,1,related,1,positive
"In experiment 2a, we replace the self-attention encoder with a graph-attention encoder similar to graph-based TSR models (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021) with an equal amount of parameters with LORE.",1,related,1,positive
"We evaluate LORE on a wide range of benchmarks, including tables in digital-born documents, i.e., ICDAR-2013 (GoÌˆbel et al. 2013), SciTSR-comp (Chi et al. 2019), PubTabNet (Zhong, ShafieiBavani, and Jimeno Yepes 2020),
TableBank (Li et al. 2020) and TableGraph-24K (Xue et al. 2021), as well as tables from scanned documents and photos, i.e., ICDAR-2019 (Gao et al. 2019) and WTW (Long et al. 2021).",1,related,1,positive
"In this section, we conduct comprehensive experiments to research and answer two key questions: 1) Is the proposed LORE able to effectively predict the logical locations of table cells from input images? 2) Does the LORE framework, modeling TSR as logical location regression, overcome the limitations and cover the abilities of other paradigms? For the first question, we compare LORE with baselines directly predicting logical locations (Xue, Li, and Tao 2019; Xue et al. 2021).",1,related,1,positive
"We also report the performance of cell spatial location prediction, using the F-1 score under the IoU threshold of 0.5, following recent works (Raja, Mondal, and Jawahar 2020; Xue et al. 2021).",1,related,0,negative
"For the first question, we compare LORE with baselines directly predicting logical locations (Xue, Li, and Tao 2019; Xue et al. 2021).",1,related,1,positive
"We take deep-learning-based GAN, CFM, TGRNet, and Faster RCNN, SSD as baselines.",1,related,1,positive
