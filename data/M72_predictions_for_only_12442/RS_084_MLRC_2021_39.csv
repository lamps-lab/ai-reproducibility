text,target_predict,target_predict_label,target_model_6_predict,target_predict_model_6_label
We use the FSC-147 dataset [5] to train the base counting model and the error predictor.,1,related,1,positive
"To verify that, we use our selected patches as the exemplars for four other different exemplar-based methods: FamNet+ [5], BMNet [6], BMNet+ [6] and SAFECount [38].",1,related,1,positive
"By using our patch selection method with the SD-generated class prototype, the error rates are further reduced for most cases, e.g., we observe for FamNet+ [5], there is an error reduction of 12 .",1,related,1,positive
", we observe for FamNet+ [5], there is an error reduction of 12.",1,related,1,positive
Xian et al. [54] use a conditional Wasserstein Generative Adversarial Network (GAN) [56] to generate unseen features which can then be used to train a discriminative classifier for ZSL.,1,related,1,positive
"To select the class-relevant patches, we use the Region Proposal Network of Faster RCNN pre-trained on MS-COCO dataset to generate 100 object proposals per image.",1,related,1,positive
"Motivated by the previous crowd counting methods [Liu et al. 2019; Ranjan et al. 2021], we generate the groundtruth density map, P∗ ∈ RH×W , from the 2D root coordinates by using a Gaussian kernel with adaptive window size.",1,related,1,positive
"To evaluate the counting ability, we use the standard FSC-147 dataset [46], which contains 6135 images covering 147 object categories, with counts ranging from 7 to 3731 and an average count of 56 objects per image.",1,related,0,negative
"Next, we compare with previous methods on two standard counting datasets: FSC-147 [46] and MSO [61].",1,related,1,positive
We first train a base counting model using images from the single-class counting dataset [30].,1,related,1,positive
"Specifically, we use our synthetic multi-class images to fine-tune three pre-trained single-class counting models: BMNet+ [32], FamNet+ [30] and SAFECount [41].",1,related,1,positive
"We compare our method with recent class-agnostic counting methods, including CounTR (Counting TRansformer [23]), FamNet (Few-shot adaptation and matching Network [30]), SAFECount (Similarity-Aware Feature Enhancement block for object Counting [41]) and BMNet (Bilinear Matching Network [32]).",1,related,1,positive
"Network architecture For the base counting model, we use ResNet-50 as the backbone of the feature extractor, initialized with weights of a pre-trained ImageNet model.",1,related,1,positive
"We use the FSC147 data with the “car” category excluded to train our model, and test on CARPK without fine-tuning and fine-tuning respectively.",1,related,0,negative
"Following the previous work [7, 9, 10], we also test the generalization performance of our model on the CARPK dataset.",1,related,1,positive
"Our method was compared with GMN [7], MAML [25], FamNet [9], CFOCNet [8] and BMNet+ [10].",1,related,1,positive
"We trained the model on the training set of FSC147 and
2925
Authorized licensed use limited to the terms of the applicable license agreement with IEEE.",1,related,0,negative
"In Table I, we compare the counting results obtained with our post-processing method to the density map integration results on FamNet and BMNet+.",1,related,1,positive
"For the FSC147 dataset, we define σ as follows:
σs = min(wi, hi)/2, i ∈ {1, 2, 3} (11)
σl = mean( √ w2i + h 2 i /2), i ∈ {1, 2, 3} (12)
σs is a more stringent standard than σl.",1,related,1,positive
"Note that GMN and FamNet use 5 and 12
2924
Authorized licensed use limited to the terms of the applicable license agreement with IEEE.",1,related,0,negative
"We evaluate our approaches on two commonly used counting datasets, namely, FSC147 [15] and CARPK [4].",1,related,1,positive
"The Binary Locating Metric covers the data from VOC2012, FSC147, and LSP.",1,related,1,positive
"Therefore, we conducted tests on the subset of the FSC147 dataset with less than 10 objects to evaluate the performance of the models on simple data, as shown in Figure 5 (b).",1,related,1,positive
"CounTX is evaluated on FSC-147 [29], a class-agnostic object counting dataset containing 6135 images.",1,related,1,positive
"In addition to this model, we make the following contributions: (i) we compare the performance of CounTX to prior work on open-world object counting, and show that our approach exceeds the state of the art on all measures on the FSC-147 [29] benchmark for methods that use text to specify the task; (ii) we present and release FSC-147-D, an enhanced version of FSC-147 with text descriptions, so that object classes can be described with more detailed language than their simple class names.",1,related,1,positive
"We are the first to tackle this open-world counting problem using a single-stage approach, without relying on an exemplar-based counting model; Second, we augment the FSC-147 [29] dataset with class descriptions and release the modified dataset, FSC-147-D, for future research; Third, we verify the effectiveness of our model and training procedure on the FSC-147 dataset through both quantitative and qualitative results.",1,related,1,positive
"We conducts our experiments on the FSCD147 dataset, which is recently introduced in [13] for the exemplar-based class-agnostic counting task and extended to FSCD task by [12].",1,related,1,positive
"FSC [13] only provides point-wise annotations and a few box-wise annotations, which makes most of the existing advance detectors invalid.",1,related,0,negative
"We compare our model against previous methods on the FSCD147 benchmark, which included FAMNet [13], CFOCNet [19], and CountingDETR [12].",1,related,1,positive
"The paper compares the proposed SAMbased method with other few-shot counting methods on two datasets, FSC-147 [111] and MS-COCO [112], and finds that",1,related,1,positive
"We compare our CACViT with CNN-based method FamNet+ [24], RCAC [5], BMNet+ [25], SAFECount [31], SPDCN [15], and the most recent state-of-the-art ViT-based method CounTR [16].",1,related,1,positive
"Experiments on the public benchmark FSC147 [24] show that CACVit outperforms the previous best approaches by large margins, with relative error reductions of 19.",1,related,0,negative
Table 2 presents the performance of SAM on the FSC-147 datasets.,1,related,0,negative
We consider two incremental learning sequences based on the FSC147 dataset.,1,related,1,positive
Figure 3 shows the qualitative results on the FSC-147 dataset.,1,related,0,negative
"According to the division method of the original dataset (Ranjan et al., 2021), we divide the dataset into training set, validation set, and test set.",1,related,1,positive
"Results: Experiment results on FSC-147 show that our network performs best compared to the existing methods, and the mean absolute counting error on the test set improves from 14.32 to 12.74.",1,related,0,negative
Our model is first pre-trained on FSC-147 and then finetuned on the CARPK dataset.,1,related,0,negative
"In Table 2, we have observed that our method sets a new state-of-art on the standard dataset FSC-147.",1,related,1,positive
"The ablation studies show our modules are useful, and the results get improved on the FSC-147 dataset.",1,related,0,negative
Experiment results demonstrate that our HMFENet reaches a new sate-of-art on the standard dataset FSC-147 and performs best on the class-specific dataset CAPRK.,1,related,0,negative
"To verify that, we use our selected patches as the exemplars for three other different exemplar-based methods: FamNet [34], BMNet and BMNet+ [38].",1,related,1,positive
Dataset We use FSC-147 dataset [34] to train the base counting model and the error predictor.,1,related,1,positive
"Network architecture For the base counting model, we use ResNet-50 as the backbone of the feature extractor, initialized with the weights of a pre-trained ImageNet model.",1,related,1,positive
Xian et al. [44] use a conditional Wasserstein Generative Adversarial Network (GAN) [2] to generate unseen features which can then be used to train a discriminative classifier for ZSL.,1,related,1,positive
"By using the generated class prototype to select class-relevant patches, the error rate is reduced by 5.18, 8.59 and 5.60 on FamNet, BMNet and BMNet+, respectively.",1,related,1,positive
"To verify that, we use our selected patches as the exemplars for three
other different exemplar-based methods: FamNet [34], BMNet and BMNet+ [38].",1,related,1,positive
"In order to make other exemplar based class-agnostic methods including GMN (General Matching Network [28]), FamNet (Fewshot adaptation and matching Network [34]) and BMNet
(Bilinear Matching Network [38]) work in the exemplarfree setup, we replace the human-provided exemplars with the exemplars generated by a pre-trained object detector.",1,related,1,positive
"In order to make other exemplar based class-agnostic methods including GMN (General Matching Network [28]), FamNet (Fewshot adaptation and matching Network [34]) and BMNet (Bilinear Matching Network [38]) work in the exemplarfree setup, we replace the human-provided exemplars with the exemplars generated by a pre-trained object detector.",1,related,1,positive
"In addition, as the error predictor is additionally adopted, the error rate is further reduced by 1.76, 1.00 and 1.08 on FamNet, BMNet and BMNet+, respectively.",1,related,1,positive
• Performance: The state-of-the-art accuracy is achieved on the prevailing benchmark FSC147 [6] compared to the exemplar-free RepRPN-Counter and the BMNet-based baseline.,1,related,0,negative
"4 as follows:
Le = 0.5 1
B i∑ B ||N̂e(i)−N(i)||22 + 0.5L. (5)
c) CAC-oriented FSC147.",1,related,1,positive
"The evolution of counting frameworks: (a) Class-specific methods [1], [2] count objects from fixed categories; (b) Inchoate exemplar-dependent class-agnostic counters learn to match user-provided exemplars with query scenes [3], [4], [5], [6], [7]; (c) Our GCNet removes the requirement of exemplar annotations and learns self-similarity from repetitive object patterns.",1,related,1,positive
: We perform ablation studies on the validation and test sets of FSC147 to assess the impacts of individual components.,1,related,0,negative
Impressive results on FSC147 also demonstrate the superiority of our GCNet compared to traditional CAC approaches using both exemplars and location annotations.,1,related,0,negative
• Performance: The state-of-the-art accuracy is achieved on the prevailing benchmark FSC147 [6] compared to the exemplar-free RepRPN-Counter and the BMNet-based,1,related,0,negative
"CFOCNet [5] treats the feature maps of the input exemplar as a kernel to convolve the feature maps from an input query image, whereas FAMNet [6] requires explicit testtime adaptation to perform well on novel classes.",1,related,1,positive
Note that even the baseline obtains lower MAE values (23.14 and 21.88) on Val and Test compared to the conventional FamNet (24.32 and 22.56) & FamNet+ (23.75 and 22.08) that require laborious annotations of both exemplar and density map.,1,related,1,positive
": For fair comparisons, we use the same strategy to resize the original image as in FAMNet [6] and BMNet [7].",1,related,1,positive
"superiority of our framework on actively learning the similar and repeated matters, we deploy our work on FSC-147 [22] which is a multi-class objects counting benchmark.",1,related,1,positive
"To further show the
superiority of our framework on actively learning the similar and repeated matters, we deploy our work on FSC-147 [22] which is a multi-class objects counting benchmark.",1,related,1,positive
"In the few-shot counting scenario, we compare LOCA with GMN [18], MAML [8], FamNet [24] and the most recent state-of-the-art methods CFOCNet [30], BMNet+ [26], SAFECount [31] and CounTR [16].",1,related,1,positive
LOCA is evaluated on the recent few-shot counting dataset FSC147 [24].,1,related,0,negative
"We follow the standard evaluation protocol [24, 26, 31] and compute Mean Absolute Error (MAE) and Root of Mean Squared Error (RMSE) given the predicted and ground truth object counts.",1,related,1,positive
"Experiments show that LOCA outperforms state-of-the-art on the FSC147 public benchmark in few-shot, one-shot and zero-shot settings.",1,related,0,negative
Proposals with the highest repetition scores are used as exemplars and sent through FamNet [24] to predict multiple density maps.,1,related,1,positive
"As shown in Table 3, it can be easily found that our model still has a huge improvement even compared to the best-performing Mask-RCNN [10], halving its error on both Val-COCO and Test-COCO.",1,related,1,positive
90 FamNet [24] CVPR2021 Regression Generic 18.,1,related,0,negative
"Net [24], and our model outperforms it with a large advance (15.",1,related,1,positive
"We experiment on FSC-147 [24], which is a multi-class few-shot object counting dataset containing 6135 images.",1,related,1,positive
"7 shows the qualitative comparison between our approach and the other methods, including FSDetView [45], Attention-RPN [6], and FamNet [32]+RR.",1,related,1,positive
"Also, the number of exemplar boxes is set to K = 3, as in FamNet [32] for a fair comparison.",1,related,1,positive
FamNet [32] correlates the features extracted from a few exemplars with the feature map to obtain the density map for object counting.,1,related,1,positive
"Since there is no existing method for the new FSCD task, we compare CountingDETR with several strong baselines adapted from few-shot object counting and few-shot object detection: FamNet [32]+RR, FamNet [32]+MLP, Attention-RPN [6]+RR, and FSDetView [45]+RR.",1,related,1,positive
We compare VCN with several state-of-the-art few-shot detection and counting approaches on the Val and Test splits of FSC147.,1,related,0,negative
"We compare VCN with several object detectors on FSC147-Val-COCO and FSC147-Test-COCO sets, which are subsets of images from FSC147 Val and Test set which share categories with MSCOCO dataset [21].",1,related,1,positive
"We show the effectiveness of the proposed VCNs for few-shot counting task by conducting extensive experiments on the FSC147 dataset, and improve on the previous state-of-the-art results by a significant margin.",1,related,0,negative
"We compare VCN with object detectors [11, 20, 32] trained on MSCOCO dataset and also the state-of-the-art fewshot counting network FamNet [29].",1,related,1,positive
"We perform experiments on the FSC147 dataset, which is the only dataset suitable for the few-shot counting task.",1,related,0,negative
"Since the size of the objects can vary a lot across the images of a few-shot counting dataset, we follow [29] and use an adaptive window size for the Gaussian kernel across different images.",1,related,1,positive
Note that FamNet also follows the same test time adaptation strategy.,1,related,0,negative
"VCN and VCN∗ outperform FamNet [29] by a large margin, even though the architecture of FamNet is same as that of our few-shot regressor.",1,related,1,positive
"To obtain annotation for unannotated objects in the FSC147 dataset, we propose a novel knowledge transfer strategy where we use a RepRPN trained on a large scale object detection dataset [19] and a density prediction network [30] trained on FSC-147 as teacher networks.",1,related,1,positive
"Compared with the state-of-the-art FamNet [29], our model (BMNet+) generates high-fidelity results.",1,related,1,positive
"From Fig 1, by examining a recent model FamNet [29], we observe obvious noise on background and weak responses on target positions.",1,related,1,positive
"Experiments on the public benchmark FSC147 [29] show that our method outperforms the previous best approaches by large margins, with a relative improvement of +33.",1,related,0,negative
"For a fair comparison, we apply the same pre-processing to query images and the feature extractor as in FamNet [29].",1,related,1,positive
", using the vanilla dot production) used in prior arts [26, 46] is not adapted to fit the FSC task.",1,related,0,negative
"methods specifically designed for one-shot counting, for comprehensive evaluation, we modify FamNet [4] and CFOCNet [5] for this setting and also compare with other few-shot counting approaches [25, 26, 16, 27, 17].",1,related,1,positive
We follow the few-shot setting in [4] and modify it to one-shot object counting.,1,related,1,positive
• The experimental results show that our model achieves state-of-the-art results with significant improvements on FSC-147 [4] and COCO [6] datasets under the oneshot setting without fine-tuning.,1,related,0,negative
"We choose Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) to measure the performance of object counting approaches following [9, 24, 28]:",1,related,1,positive
"Following [28], we utilize the Gaussian smoothing with adaptive window size to generate the GT density maps.",1,related,1,positive
"To solve the problem of class-agnostic counting, we design architecture different from previous works [16, 23], which is illustrated in Figure 1.",1,related,1,positive
Figure 2 presents several examples from the FSC-147 validation set.,1,related,0,negative
"Following FamNet [23], we next present experimental results on CARPK [11].",1,related,1,positive
We first compare our method with state-of-the-art class-agnostic models on the FSC-147 dataset.,1,related,1,positive
"As shown in Table 4, SPDCN is compared with FamNet [23] and BMNet [26] (the results of BMNet are reproduced with our code).",1,related,1,positive
"The dataset for class-agnostic counting FSC-147 is introduced by FamNet [23], in which it is proposed for a few-shot counting task.",1,related,1,positive
