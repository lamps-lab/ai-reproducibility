text,target_predict,target_predict_label,target_model_6_predict,target_predict_model_6_label
"Although DCL does not use any external data, DCL achieved higher accuracy than SKS. 5) We further analyze the impact of the sequence between the two stages.",1,related,0,negative
"We used the different F1 score metrics on two datasets following existing studies, such as the SOTA baseline model SKS [7] for fair comparisons.",1,related,0,negative
"For the DV dataset, we adopt the mean accuracy and the weighted F1 after five-fold cross-validation, and save the parameters corresponding to the optimal model, which follows the settings in previous work [7].",1,related,1,positive
"Inspired by Zhou et al. (2021a), we design a toxic embedding to introduce lexical knowledge.",1,related,1,positive
11https://github.com/dadangewp/HurtBERT 12https://github.com/1783696285/SKS,1,related,0,negative
"2) Baselines: We compare our framework with five categories of baselines: feature-based models (SVM), neural text classification models (LSTM+ATT, CNN+GRU, BiGRU+Capsule, Transformer), pre-trained language model (Bert, HurtBert), Graph Neural Network (DepGCN), and multi-task model (SKS) for abusive language detection.",1,related,1,positive
"(5) Compared with other pre-trained language models (Bert, HurtBert) and multi-task learning model (SKS), we can also observe that our framework w/ BERT is significantly more robust as shown in Figure 3(a) and Figure 3(b).",1,related,1,positive
"Furthermore, our framework does not require any extra knowledge, while SKS requires human-annotated sentiment classification datasets 13.",1,related,0,negative
