text,target_predict,target_predict_label,target_model_6_predict,target_predict_model_6_label
"Within the domain of algorithmic fairness, our work is related to recent investigations into the effects of distribution shift, or data mismeasurement, on fair learning [17, 33, 37, 38].",1,related,1,positive
", 2021), Shifty (Giguere et al., 2022), and our framework.",1,related,1,positive
"6, we add a new baseline called Shifty (Giguere et al., 2022), which focuses on the distribution shift most relevant to ours.",1,related,1,positive
"Our framework thus works best when the x distribution does not change, but does not strictly require this condition unlike other previous works on fairness under different types of shifts (Maity et al., 2021; Giguere et al., 2022).",1,related,1,positive
"• Similarly, the demographic shift (Giguere et al., 2022) assumes that the joint probabilities of x and y on the training and deployment distributions are identical (i.",1,related,0,negative
"To give a favorable condition to Shifty, we assume that Shifty knows the exact test distribution.",1,related,1,positive
"• Similarly, the demographic shift (Giguere et al., 2022) assumes that the joint probabilities of x and y on the training and deployment distributions are identical (i.e., Prtrain(x = x, y = y|z = z) = Prtest(x = x, y = y|z = z)).",1,related,1,positive
"Table 9 shows the accuracy and fairness performances of the in-processing-only baseline FairBatch, Shifty, and our framework w.r.t. a single metric (DP) and multiple metrics (DP & EO) in the synthetic and COMPAS datasets used in Tables 1 and 2.",1,related,1,positive
"We would like to note that the procedure that first chooses a candidate set of tuning parameters and then selects the best one has been commonly used in machine learning, such as in Seldonian algorithm framework to control safety and fairness [43, 21, 48], the Learn then Test framework for risk control [3], and in high-dimensional statistics [47].",1,related,1,positive
