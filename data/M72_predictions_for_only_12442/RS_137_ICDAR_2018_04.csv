text,target_predict,target_predict_label,target_model_6_predict,target_predict_model_6_label
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",1,related,0,negative
"In experiment 2a, we replace the self-attention encoder with a graph-attention encoder similar to graph-based TSR models (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021) with an equal amount of parameters with LORE.",1,related,1,positive
"For line detection, we take advantage of recent GNN proposals such as (Qasim et al., 2019) or (Carbonell et al.",1,related,1,positive
"To do this, a GNN based on (Qasim et al., 2019) is implemented with the aim of connecting the different words previously extracted as entity tags of interest in a same line.",1,related,1,positive
"For line detection, we take advantage of recent GNN proposals such as (Qasim et al., 2019) or (Carbonell et al., 2021).",1,related,1,positive
"We conduct experiments on several popular benchmarks including PubTabNet [3] and SynthTable [4], our method achieves new state-of-the-art results.",1,related,1,positive
We also evaluate the SynthTable dataset proposed in TIES [4] that mainly consists of tables in diverse categories.,1,related,1,positive
"Therefore, we
6
also use SynthTable proposed in TIES [4].",1,related,1,positive
"We argue that the problems of KILE and LIR, as defined in Sec.",1,related,1,positive
"We define Line Item (LI) and the task of Line Item Recognition (LIR) as follows:
Definition 2 (LI).",1,related,1,positive
"Note that this definition of LIR allows: (i) detection of several tables with different item types, as well as different item types within a single table; (ii) a single field (e.g., a date) to belong to several line items.",1,related,1,positive
Definition 3 (LIR).,1,related,1,positive
"In the case of IETD, this OCR engine is implicit in the decoder similar to [24].",1,related,1,positive
"In the similar spirit with works [30, 34], we adopt the following asymmetric edge function hΘ(xi,xj) = xi∥(xi − xj) to combine graph edge features to each node, which can be denoted as HΘ ∈ R ·(N−1)/2)×d .",1,related,1,positive
"For comparison, we also visualize the multi-head self-attention maps from the last blocks of “Transformer-Mixed” [42] and KNN (K = 5) selection heatmaps of all layers in DGCNN [30], where a lighter color indicates a closer relationship.",1,related,1,positive
"3 compares the effectiveness of various extractors, including DGCNN [30] and Transformer [42], with ECE in our method.",1,related,1,positive
"As for the sparse context, we build SCA upon DGCNN [28] to softly introduce the relational inductive bias to our model and enable it to learn sparse contextual information in local pattern.",1,related,1,positive
"Inspired by [24], we adopt the algorithm of Maximum Clique Search [1] to find all maximum cliques in the graph.",1,related,1,positive
"Therefore, we firstly generate a synthetic dataset with the aid of the open code [10].",1,related,1,positive
"When compared with the method in [10], our proposed method can still get considerable results on tables in Category 3 and Category 4.",1,related,0,negative
"Considering memory efficiency, we also introduce Monte Carlo sampling for constructing collaborative graph embedding pairs in the training phase, which is similar to [12].",1,related,1,positive
