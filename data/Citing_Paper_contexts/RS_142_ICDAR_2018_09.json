{
    "offset": 0,
    "data": [
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "In the works of [8, 20, 27, 36, 38, 46], a table is depicted as a grid of regions.",
                "For instance, region-based methods [8, 20, 36, 38, 46] employ a split model to divide input table images into a grid of regions, and a merge model to combine over-split spanning cells.",
                "TabStructNet [36] combines table element detection and vertex relationship prediction into a single network, providing an end-to-end solution.",
                "[16, 25, 35, 36, 47] represent tables by a group of cells.",
                "Note that, there are fundamental differences between the representation in [8, 20, 36, 38, 46] and ours despite the representation is also termed as \"grid\"."
            ],
            "citingPaper": {
                "paperId": "3e797270bd42586b0e46ce597a5ef6d754465e43",
                "externalIds": {
                    "ArXiv": "2309.14962",
                    "CorpusId": 262825477
                },
                "corpusId": 262825477,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3e797270bd42586b0e46ce597a5ef6d754465e43",
                "title": "GridFormer: Towards Accurate Table Structure Recognition via Grid Prediction",
                "abstract": "All tables can be represented as grids. Based on this observation, we propose GridFormer, a novel approach for interpreting unconstrained table structures by predicting the vertex and edge of a grid. First, we propose a flexible table representation in the form of an MXN grid. In this representation, the vertexes and edges of the grid store the localization and adjacency information of the table. Then, we introduce a DETR-style table structure recognizer to efficiently predict this multi-objective information of the grid in a single shot. Specifically, given a set of learned row and column queries, the recognizer directly outputs the vertexes and edges information of the corresponding rows and columns. Extensive experiments on five challenging benchmarks which include wired, wireless, multi-merge-cell, oriented, and distorted tables demonstrate the competitive performance of our model over other methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "10344582",
                        "name": "Pengyuan Lyu"
                    },
                    {
                        "authorId": "47121217",
                        "name": "Weihong Ma"
                    },
                    {
                        "authorId": "2109798334",
                        "name": "Hongyi Wang"
                    },
                    {
                        "authorId": "1631405123",
                        "name": "Yu Yu"
                    },
                    {
                        "authorId": "2248958848",
                        "name": "Chengquan Zhang"
                    },
                    {
                        "authorId": "2140371004",
                        "name": "Kun Yao"
                    },
                    {
                        "authorId": "2114922667",
                        "name": "Yang Xue"
                    },
                    {
                        "authorId": "1688516",
                        "name": "Jingdong Wang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "13de1c39dfe5733363ff1a8d4c6d577914f79618",
                "externalIds": {
                    "DBLP": "conf/ijcai/ShenGWQZLC23",
                    "DOI": "10.24963/ijcai.2023/152",
                    "CorpusId": 260853966
                },
                "corpusId": 260853966,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/13de1c39dfe5733363ff1a8d4c6d577914f79618",
                "title": "Divide Rows and Conquer Cells: Towards Structure Recognition for Large Tables",
                "abstract": "Recent advanced Table Structure Recognition (TSR) models adopt image-to-text solutions to parse table structure. These methods can be formulated as image caption problem, i.e., input a single-table image and output table structure description in a specific text format, e.g., HTML. With the impressive success of Transformer in text generation tasks, these methods use Transformer architecture to predict HTML table text in an autoregressive manner. However, tables always emerge with a large variety of shapes and sizes. Autoregressive models usually suffer from the error accumulation problem as the length of predicted text increases, which results in unsatisfactory performance for large tables. In this paper, we propose a novel image-to-text based TSR method that relieves error accumulation problems and improves performance noticeably. At the core of our method is a cascaded two-step decoder architecture with the former decoder predicting HTML table row tags non-autoregressively and the latter predicting HTML table cell tags of each row in a semi-autoregressive manner. Compared with existing methods that predict HTML text autoregressively, the superiority of our row-to-cell progressive table parsing is twofold: (1) it generates an HTML tag sequence with a vertical-and-horizontal two-step `scanning', which better fits the inherent 2D structure of image data, (2) it performs substantially better for large tables (long sequence prediction) since it alleviates error accumulation problem specific to autoregressive models. Extensive experiments demonstrate that our method achieves competitive performance on three public benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2230137426",
                        "name": "Huawen Shen"
                    },
                    {
                        "authorId": "2149397987",
                        "name": "Xiang Gao"
                    },
                    {
                        "authorId": "2111524263",
                        "name": "Jin Wei"
                    },
                    {
                        "authorId": "2065512194",
                        "name": "Liang Qiao"
                    },
                    {
                        "authorId": "49454803",
                        "name": "Yu Zhou"
                    },
                    {
                        "authorId": "2229647956",
                        "name": "Qiang Li"
                    },
                    {
                        "authorId": "2398015",
                        "name": "Zhanzhan Cheng"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Several studies have proposed detectors for detecting cells or their contents [28,31,30,49]."
            ],
            "citingPaper": {
                "paperId": "eca4dfc1703529bd87e1b4fea1fad1baa06e0ac9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-00630",
                    "ArXiv": "2305.00630",
                    "DOI": "10.48550/arXiv.2305.00630",
                    "CorpusId": 258427145
                },
                "corpusId": 258427145,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/eca4dfc1703529bd87e1b4fea1fad1baa06e0ac9",
                "title": "TRACE: Table Reconstruction Aligned to Corner and Edges",
                "abstract": "A table is an object that captures structured and informative content within a document, and recognizing a table in an image is challenging due to the complexity and variety of table layouts. Many previous works typically adopt a two-stage approach; (1) Table detection(TD) localizes the table region in an image and (2) Table Structure Recognition(TSR) identifies row- and column-wise adjacency relations between the cells. The use of a two-stage approach often entails the consequences of error propagation between the modules and raises training and inference inefficiency. In this work, we analyze the natural characteristics of a table, where a table is composed of cells and each cell is made up of borders consisting of edges. We propose a novel method to reconstruct the table in a bottom-up manner. Through a simple process, the proposed method separates cell boundaries from low-level features, such as corners and edges, and localizes table positions by combining the cells. A simple design makes the model easier to train and requires less computation than previous two-stage methods. We achieve state-of-the-art performance on the ICDAR2013 table competition benchmark and Wired Table in the Wild(WTW) dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2057310228",
                        "name": "Youngmin Baek"
                    },
                    {
                        "authorId": "2064808754",
                        "name": "Daehyun Nam"
                    },
                    {
                        "authorId": "10787779",
                        "name": "Jaeheung Surh"
                    },
                    {
                        "authorId": "2111068603",
                        "name": "Seung Shin"
                    },
                    {
                        "authorId": "2109603647",
                        "name": "Seonghyeon Kim"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "2fd312a5d5a259b585224aed1026b3c14be95c91",
                "externalIds": {
                    "DBLP": "journals/spic/Mishra23",
                    "DOI": "10.1016/j.image.2023.116986",
                    "CorpusId": 258600753
                },
                "corpusId": 258600753,
                "publicationVenue": {
                    "id": "5e329303-0790-4991-832f-dd8a737ec6fb",
                    "name": "Signal processing. Image communication",
                    "type": "journal",
                    "alternate_names": [
                        "Signal process Image commun",
                        "Signal Process Commun",
                        "Signal Processing-image Communication"
                    ],
                    "issn": "0923-5965",
                    "url": "https://www.journals.elsevier.com/signal-processing-image-communication"
                },
                "url": "https://www.semanticscholar.org/paper/2fd312a5d5a259b585224aed1026b3c14be95c91",
                "title": "Domain adaptive learning for document layout analysis and object detection using classifier alignment mechanism",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2068143981",
                        "name": "Prerna Mishra"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "df9045c28a2aa3e7fc76edb3620424ad19912265",
                "externalIds": {
                    "ArXiv": "2304.11810",
                    "DBLP": "journals/corr/abs-2304-11810",
                    "DOI": "10.48550/arXiv.2304.11810",
                    "CorpusId": 258298306
                },
                "corpusId": 258298306,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/df9045c28a2aa3e7fc76edb3620424ad19912265",
                "title": "PARAGRAPH2GRAPH: A GNN-based framework for layout paragraph analysis",
                "abstract": "Document layout analysis has a wide range of requirements across various domains, languages, and business scenarios. However, most current state-of-the-art algorithms are language-dependent, with architectures that rely on transformer encoders or language-specific text encoders, such as BERT, for feature extraction. These approaches are limited in their ability to handle very long documents due to input sequence length constraints and are closely tied to language-specific tokenizers. Additionally, training a cross-language text encoder can be challenging due to the lack of labeled multilingual document datasets that consider privacy. Furthermore, some layout tasks require a clean separation between different layout components without overlap, which can be difficult for image segmentation-based algorithms to achieve. In this paper, we present Paragraph2Graph, a language-independent graph neural network (GNN)-based model that achieves competitive results on common document layout datasets while being adaptable to business scenarios with strict separation. With only 19.95 million parameters, our model is suitable for industrial applications, particularly in multi-language scenarios.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2042743634",
                        "name": "Shuyong Wei"
                    },
                    {
                        "authorId": "73580202",
                        "name": "Nuo Xu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",
                "Raja et al.[34]6 2020 TabStruct Net ECCV SciTSR UNLV X X NR"
            ],
            "citingPaper": {
                "paperId": "50903f5f5e714e5746152b3e369c9329655e0018",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-10439",
                    "ArXiv": "2304.10439",
                    "DOI": "10.48550/arXiv.2304.10439",
                    "CorpusId": 258236507
                },
                "corpusId": 258236507,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/50903f5f5e714e5746152b3e369c9329655e0018",
                "title": "A Study on Reproducibility and Replicability of Table Structure Recognition Methods",
                "abstract": "Concerns about reproducibility in artificial intelligence (AI) have emerged, as researchers have reported unsuccessful attempts to directly reproduce published findings in the field. Replicability, the ability to affirm a finding using the same procedures on new data, has not been well studied. In this paper, we examine both reproducibility and replicability of a corpus of 16 papers on table structure recognition (TSR), an AI task aimed at identifying cell locations of tables in digital documents. We attempt to reproduce published results using codes and datasets provided by the original authors. We then examine replicability using a dataset similar to the original as well as a new dataset, GenTSR, consisting of 386 annotated tables extracted from scientific papers. Out of 16 papers studied, we reproduce results consistent with the original in only four. Two of the four papers are identified as replicable using the similar dataset under certain IoU values. No paper is identified as replicable using the new dataset. We offer observations on the causes of irreproducibility and irreplicability. All code and data are available on Codeocean at https://codeocean.com/capsule/6680116/tree.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "11359490",
                        "name": "Kehinde E. Ajayi"
                    },
                    {
                        "authorId": "2214808132",
                        "name": "Muntabhir Hasan Choudhury"
                    },
                    {
                        "authorId": "2528276",
                        "name": "S. Rajtmajer"
                    },
                    {
                        "authorId": "97569165",
                        "name": "Jian Wu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "TabStruct-Net [7] proposed an end-to-end network to detect cells and predict cell relations jointly.",
                "Some recent works [7, 8, 12] have proposed a modified TEDS metric named TEDS-Struct to evaluate table structure recognition accuracy only by ignoring OCR errors.",
                "To bypass this problem, the second group of methods [7, 8, 12, 45, 46] detects the bounding boxes of table cells directly and uses different methods to group them into rows and columns."
            ],
            "citingPaper": {
                "paperId": "3e0c97baa8e7b629a3d689e00aa21b94e2193766",
                "externalIds": {
                    "ArXiv": "2303.11615",
                    "DBLP": "journals/corr/abs-2303-11615",
                    "DOI": "10.48550/arXiv.2303.11615",
                    "CorpusId": 257636821
                },
                "corpusId": 257636821,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3e0c97baa8e7b629a3d689e00aa21b94e2193766",
                "title": "Robust Table Structure Recognition with Dynamic Queries Enhanced Detection Transformer",
                "abstract": "We present a new table structure recognition (TSR) approach, called TSRFormer, to robustly recognizing the structures of complex tables with geometrical distortions from various table images. Unlike previous methods, we formulate table separation line prediction as a line regression problem instead of an image segmentation problem and propose a new two-stage dynamic queries enhanced DETR based separation line regression approach, named DQ-DETR, to predict separation lines from table images directly. Compared to Vallina DETR, we propose three improvements in DQ-DETR to make the two-stage DETR framework work efficiently and effectively for the separation line prediction task: 1) A new query design, named Dynamic Query, to decouple single line query into separable point queries which could intuitively improve the localization accuracy for regression tasks; 2) A dynamic queries based progressive line regression approach to progressively regressing points on the line which further enhances localization accuracy for distorted tables; 3) A prior-enhanced matching strategy to solve the slow convergence issue of DETR. After separation line prediction, a simple relation network based cell merging module is used to recover spanning cells. With these new techniques, our TSRFormer achieves state-of-the-art performance on several benchmark datasets, including SciTSR, PubTabNet, WTW and FinTabNet. Furthermore, we have validated the robustness and high localization accuracy of our approach to tables with complex structures, borderless cells, large blank spaces, empty or spanning cells as well as distorted or even curved shapes on a more challenging real-world in-house dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2187553093",
                        "name": "Jiawei Wang"
                    },
                    {
                        "authorId": "2108811137",
                        "name": "Weihong Lin"
                    },
                    {
                        "authorId": "2894335",
                        "name": "Chixiang Ma"
                    },
                    {
                        "authorId": "2181111465",
                        "name": "Mingze Li"
                    },
                    {
                        "authorId": "2145130513",
                        "name": "Zhengmao Sun"
                    },
                    {
                        "authorId": "2110833051",
                        "name": "Lei Sun"
                    },
                    {
                        "authorId": "2316043",
                        "name": "Qiang Huo"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Also based on DGCNN, TabStructNet [36] is proposed for end-to-end training cell detection and structure recognition in a joint manner.",
                "With the fast-paced development of digital transformation, Table Structure Recognition (TSR) task, aiming at parsing table structure from a table image into machineinterpretable formats, which are often presented by both table cell physical coordinates [38, 31, 15, 41, 4, 34, 36, 45, 35, 23, 25] and their logical relationships [18, 47].",
                "Similar to [36], we randomly extract 80% of the data for training and others for testing.",
                "the filed, which can be mainly categorized into boundary extraction-based methods [38, 31, 15, 41, 25] and element relationship-based methods [23, 4, 34, 36] according to the component type leveraged.",
                "The first group are the single component-based methods, which rely on either boundary extraction [15, 25, 31, 38, 41] or element relationship [4, 23, 34, 36].",
                "To date, several pioneers works [18, 47, 38, 15, 41, 4, 34, 36, 45, 35, 23, 25] have achieved significant progress in"
            ],
            "citingPaper": {
                "paperId": "2c267f43aca9bfb2f01e5400fca14545c4aa14b3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-09174",
                    "ArXiv": "2303.09174",
                    "DOI": "10.48550/arXiv.2303.09174",
                    "CorpusId": 257557431
                },
                "corpusId": 257557431,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2c267f43aca9bfb2f01e5400fca14545c4aa14b3",
                "title": "Grab What You Need: Rethinking Complex Table Structure Recognition with Flexible Components Deliberation",
                "abstract": "Recently, Table Structure Recognition (TSR) task, aiming at identifying table structure into machine readable formats, has received increasing interest in the community. While impressive success, most single table component-based methods can not perform well on unregularized table cases distracted by not only complicated inner structure but also exterior capture distortion. In this paper, we raise it as Complex TSR problem, where the performance degeneration of existing methods is attributable to their inefficient component usage and redundant post-processing. To mitigate it, we shift our perspective from table component extraction towards the efficient multiple components leverage, which awaits further exploration in the field. Specifically, we propose a seminal method, termed GrabTab, equipped with newly proposed Component Deliberator. Thanks to its progressive deliberation mechanism, our GrabTab can flexibly accommodate to most complex tables with reasonable components selected but without complicated post-processing involved. Quantitative experimental results on public benchmarks demonstrate that our method significantly outperforms the state-of-the-arts, especially under more challenging scenes.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2216764712",
                        "name": "Hao Liu"
                    },
                    {
                        "authorId": "2153898418",
                        "name": "Xin Li"
                    },
                    {
                        "authorId": "2150155841",
                        "name": "Ming Gong"
                    },
                    {
                        "authorId": "47655556",
                        "name": "Bin Liu"
                    },
                    {
                        "authorId": "2164224877",
                        "name": "Yunfei Wu"
                    },
                    {
                        "authorId": "3336726",
                        "name": "Deqiang Jiang"
                    },
                    {
                        "authorId": "2136370566",
                        "name": "Yinsong Liu"
                    },
                    {
                        "authorId": "143900241",
                        "name": "Xing Sun"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "In recent years, inspired by the success of deep learning in various tasks, especially object detection and semantic segmentation, many deep learning-based methods (Raja et al., 2020; Schreiber et al., 2017) have been presented to recognize table structures.",
                "Sachin et al. (Raja et al., 2020) presented a table structure recognizer named TabStruct-Net that combines cell detection and interaction modules to localize the cells and predicts their row and column associations with other detected cells.",
                "(Raja et al., 2020) presented a table structure recognizer named TabStruct-Net that combines cell detection and interaction modules to localize the cells and predicts their row and column associations with other detected cells.",
                "(Raja et al., 2020; Schreiber et al., 2017) have been presented to recognize table structures."
            ],
            "citingPaper": {
                "paperId": "968b0d964e0639ae27a49b696cf11929313e9ff1",
                "externalIds": {
                    "ArXiv": "2303.08648",
                    "DBLP": "conf/visapp/LyT23",
                    "DOI": "10.5220/0011685000003417",
                    "CorpusId": 257360026
                },
                "corpusId": 257360026,
                "publicationVenue": {
                    "id": "3e53351c-7355-4159-a3f2-f3b03a3aa989",
                    "name": "VISIGRAPP",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Comput Vis Imaging Comput Graph Theory Appl",
                        "International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications"
                    ],
                    "issn": "2184-4321",
                    "alternate_issns": [
                        "2184-5921"
                    ],
                    "url": "http://www.visigrapp.org/"
                },
                "url": "https://www.semanticscholar.org/paper/968b0d964e0639ae27a49b696cf11929313e9ff1",
                "title": "An End-to-End Multi-Task Learning Model for Image-based Table Recognition",
                "abstract": "Image-based table recognition is a challenging task due to the diversity of table styles and the complexity of table structures. Most of the previous methods focus on a non-end-to-end approach which divides the problem into two separate sub-problems: table structure recognition; and cell-content recognition and then attempts to solve each sub-problem independently using two separate systems. In this paper, we propose an end-to-end multi-task learning model for image-based table recognition. The proposed model consists of one shared encoder, one shared decoder, and three separate decoders which are used for learning three sub-tasks of table recognition: table structure recognition, cell detection, and cell-content recognition. The whole system can be easily trained and inferred in an end-to-end approach. In the experiments, we evaluate the performance of the proposed model on two large-scale datasets: FinTabNet and PubTabNet. The experiment results show that the proposed model outperforms the state-of-the-art methods in all benchmark datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "40325274",
                        "name": "N. Ly"
                    },
                    {
                        "authorId": "144752372",
                        "name": "A. Takasu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "bc8fc30c2546979cfd7e1658b868fdbb02f9a22a",
                "externalIds": {
                    "ArXiv": "2303.07641",
                    "DBLP": "journals/corr/abs-2303-07641",
                    "DOI": "10.5220/0011682600003411",
                    "CorpusId": 257356700
                },
                "corpusId": 257356700,
                "publicationVenue": {
                    "id": "8ef5945c-5b25-4774-b55a-15cd5450f6e4",
                    "name": "International Conference on Pattern Recognition Applications and Methods",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Pattern Recognit Appl Method",
                        "ICPRAM"
                    ],
                    "url": "http://icpram.org/"
                },
                "url": "https://www.semanticscholar.org/paper/bc8fc30c2546979cfd7e1658b868fdbb02f9a22a",
                "title": "Rethinking Image-based Table Recognition Using Weakly Supervised Methods",
                "abstract": "Most of the previous methods for table recognition rely on training datasets containing many richly annotated table images. Detailed table image annotation, e.g., cell or text bounding box annotation, however, is costly and often subjective. In this paper, we propose a weakly supervised model named WSTabNet for table recognition that relies only on HTML (or LaTeX) code-level annotations of table images. The proposed model consists of three main parts: an encoder for feature extraction, a structure decoder for generating table structure, and a cell decoder for predicting the content of each cell in the table. Our system is trained end-to-end by stochastic gradient descent algorithms, requiring only table images and their ground-truth HTML (or LaTeX) representations. To facilitate table recognition with deep learning, we create and release WikiTableSet, the largest publicly available image-based table recognition dataset built from Wikipedia. WikiTableSet contains nearly 4 million English table images, 590K Japanese table images, and 640k French table images with corresponding HTML representation and cell bounding boxes. The extensive experiments on WikiTableSet and two large-scale datasets: FinTabNet and PubTabNet demonstrate that the proposed weakly supervised model achieves better, or similar accuracies compared to the state-of-the-art models on all benchmark datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "40325274",
                        "name": "N. Ly"
                    },
                    {
                        "authorId": "144752372",
                        "name": "A. Takasu"
                    },
                    {
                        "authorId": "2100790",
                        "name": "Phuc Nguyen"
                    },
                    {
                        "authorId": "2052440572",
                        "name": "H. Takeda"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "21 PubTabNet TabStructNet [37] SciTSR 90.",
                "TableStructNet [37] and FLAG-NET [24] both utilized Mask R-CNN [13] network to obtain the region of cells and cell visual features."
            ],
            "citingPaper": {
                "paperId": "5966cd3ac4460a97b27b4177a89c0d1041726881",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-06949",
                    "ArXiv": "2303.06949",
                    "DOI": "10.1109/CVPR52729.2023.01071",
                    "CorpusId": 257495840
                },
                "corpusId": 257495840,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5966cd3ac4460a97b27b4177a89c0d1041726881",
                "title": "Improving Table Structure Recognition with Visual-Alignment Sequential Coordinate Modeling",
                "abstract": "Table structure recognition aims to extract the logical and physical structure of unstructured table images into a machine-readable format. The latest end-to-end image-to-text approaches simultaneously predict the two structures by two decoders, where the prediction of the physical structure (the bounding boxes of the cells) is based on the representation of the logical structure. However, the previous methods struggle with imprecise bounding boxes as the logical representation lacks local visual information. To address this issue, we propose an end-to-end sequential modeling framework for table structure recognition called VAST. It contains a novel coordinate sequence decoder triggered by the representation of the non-empty cell from the logical structure decoder. In the coordinate sequence decoder, we model the bounding box coordinates as a language sequence, where the left, top, right and bottom coordinates are decoded sequentially to leverage the inter-coordinate dependency. Furthermore, we propose an auxiliary visual-alignment loss to enforce the logical representation of the non-empty cells to contain more local visual details, which helps produce better cell bounding boxes. Extensive experiments demonstrate that our proposed method can achieve state-of-the-art results in both logical and physical structure recognition. The ablation study also validates that the proposed coordinate sequence decoder and the visual-alignment loss are the keys to the success of our method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "145769099",
                        "name": "Yongshuai Huang"
                    },
                    {
                        "authorId": "2054645836",
                        "name": "Ning Lu"
                    },
                    {
                        "authorId": "1679279",
                        "name": "Dapeng Chen"
                    },
                    {
                        "authorId": "2110470261",
                        "name": "Yibo Li"
                    },
                    {
                        "authorId": "2002678",
                        "name": "Zecheng Xie"
                    },
                    {
                        "authorId": "2901597",
                        "name": "Shenggao Zhu"
                    },
                    {
                        "authorId": "1777642",
                        "name": "Liangcai Gao"
                    },
                    {
                        "authorId": "2187312795",
                        "name": "Wei Peng"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "To eliminate this assumption, another group of methods [25, 24] proposed to detect the bounding boxes of table cells directly.",
                "Due to the rapid development of deep learning in documents, many deep learning-based TSR approaches [37, 3, 35, 25] have been presented."
            ],
            "citingPaper": {
                "paperId": "c78daabab3666d08d945098bc462f882b78803fd",
                "externalIds": {
                    "ArXiv": "2303.04384",
                    "DBLP": "journals/corr/abs-2303-04384",
                    "DOI": "10.48550/arXiv.2303.04384",
                    "CorpusId": 257405340
                },
                "corpusId": 257405340,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c78daabab3666d08d945098bc462f882b78803fd",
                "title": "SEMv2: Table Separation Line Detection Based on Conditional Convolution",
                "abstract": "Table structure recognition is an indispensable element for enabling machines to comprehend tables. Its primary purpose is to identify the internal structure of a table. Nevertheless, due to the complexity and diversity of their structure and style, it is highly challenging to parse the tabular data into a structured format that machines can comprehend. In this work, we adhere to the principle of the split-and-merge based methods and propose an accurate table structure recognizer, termed SEMv2 (SEM: Split, Embed and Merge). Unlike the previous works in the ``split'' stage, we aim to address the table separation line instance-level discrimination problem and introduce a table separation line detection strategy based on conditional convolution. Specifically, we design the ``split'' in a top-down manner that detects the table separation line instance first and then dynamically predicts the table separation line mask for each instance. The final table separation line shape can be accurately obtained by processing the table separation line mask in a row-wise/column-wise manner. To comprehensively evaluate the SEMv2, we also present a more challenging dataset for table structure recognition, dubbed iFLYTAB, which encompasses multiple style tables in various scenarios such as photos, scanned documents, etc. Extensive experiments on publicly available datasets (e.g. SciTSR, PubTabNet and iFLYTAB) demonstrate the efficacy of our proposed approach. The code and iFLYTAB dataset will be made publicly available upon acceptance of this paper.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2128660562",
                        "name": "Zhenrong Zhang"
                    },
                    {
                        "authorId": "2067770685",
                        "name": "Pengfei Hu"
                    },
                    {
                        "authorId": "2143520841",
                        "name": "Jie Ma"
                    },
                    {
                        "authorId": "2149030934",
                        "name": "Jun Du"
                    },
                    {
                        "authorId": "39557762",
                        "name": "Jianshu Zhang"
                    },
                    {
                        "authorId": "2211065581",
                        "name": "Huihui Zhu"
                    },
                    {
                        "authorId": "2055464704",
                        "name": "Baocai Yin"
                    },
                    {
                        "authorId": "2185098372",
                        "name": "Bing Yin"
                    },
                    {
                        "authorId": "2108152462",
                        "name": "Cong Liu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Following this work, there are models devoted to improving the relationship classification by using elaborated neural networks and adding multi-modal features (Qasim, Mahmood, and Shafait 2019; Raja, Mondal, and Jawahar 2020, 2022; Liu et al. 2021, 2022).",
                "It should be noted that ICDAR-2013 provides no training data, so we extend it to the partial version for cross validation following previous works (Raja, Mondal, and Jawahar 2020; Liu et al. 2022, 2021).",
                "Then we compare LORE with models mining the adjacency of cells by relation-based metrics: TabStrNet (Raja, Mondal, and Jawahar 2020), LGPMA (Qiao et al. 2021), TOD (Raja, Mondal, and Jawahar 2022), FLAGNet (Liu et al. 2021) and NCGM (Liu et al. 2022).",
                "We also report the performance of cell spatial location prediction, using the F-1 score under the IoU threshold of 0.5, following recent works (Raja, Mondal, and Jawahar 2020; Xue et al. 2021)."
            ],
            "citingPaper": {
                "paperId": "a90a77893708ae5070e2ed4572ca9e20837e69c6",
                "externalIds": {
                    "DBLP": "conf/aaai/XingGLBZLYY23",
                    "ArXiv": "2303.03730",
                    "DOI": "10.48550/arXiv.2303.03730",
                    "CorpusId": 257378294
                },
                "corpusId": 257378294,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/a90a77893708ae5070e2ed4572ca9e20837e69c6",
                "title": "LORE: Logical Location Regression Network for Table Structure Recognition",
                "abstract": "Table structure recognition (TSR) aims at extracting tables in images into machine-understandable formats. Recent methods solve this problem by predicting the adjacency relations of detected cell boxes, or learning to generate the corresponding markup sequences from the table images. However, they either count on additional heuristic rules to recover the table structures, or require a huge amount of training data and time-consuming sequential decoders. In this paper, we propose an alternative paradigm. We model TSR as a logical location regression problem and propose a new TSR framework called LORE, standing for LOgical location REgression network, which for the first time combines logical location regression together with spatial location regression of table cells. Our proposed LORE is conceptually simpler, easier to train and more accurate than previous TSR models of other paradigms. Experiments on standard benchmarks demonstrate that LORE consistently outperforms prior arts. Code is available at https:// github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LORE-TSR.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2176894025",
                        "name": "Hangdi Xing"
                    },
                    {
                        "authorId": "2112256",
                        "name": "Feiyu Gao"
                    },
                    {
                        "authorId": "143799988",
                        "name": "Rujiao Long"
                    },
                    {
                        "authorId": "2064698184",
                        "name": "Jiajun Bu"
                    },
                    {
                        "authorId": "2114172383",
                        "name": "Qi Zheng"
                    },
                    {
                        "authorId": "2145730944",
                        "name": "Liangcheng Li"
                    },
                    {
                        "authorId": "2173739231",
                        "name": "Cong Yao"
                    },
                    {
                        "authorId": "2139424603",
                        "name": "Zhi Yu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "4f5414f9b2873d6e4de1158695d7b1c6fe9653cb",
                "externalIds": {
                    "DOI": "10.1016/j.oregeorev.2023.105383",
                    "CorpusId": 257566076
                },
                "corpusId": 257566076,
                "publicationVenue": {
                    "id": "75e57f78-3c41-4803-8f91-bf6a220e9a66",
                    "name": "Ore Geology Reviews",
                    "type": "journal",
                    "alternate_names": [
                        "Ore Geol Rev"
                    ],
                    "issn": "0169-1368",
                    "url": "https://www.journals.elsevier.com/ore-geology-reviews",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/01691368"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4f5414f9b2873d6e4de1158695d7b1c6fe9653cb",
                "title": "Understanding table content for mineral exploration reports using deep learning and natural language processing",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2210960579",
                        "name": "Jiahuizi Dong"
                    },
                    {
                        "authorId": "29847942",
                        "name": "Qinjun Qiu"
                    },
                    {
                        "authorId": "2153722665",
                        "name": "Zhong Xie"
                    },
                    {
                        "authorId": "1490932925",
                        "name": "K. Ma"
                    },
                    {
                        "authorId": "2056384890",
                        "name": "A. Hu"
                    },
                    {
                        "authorId": "2191360357",
                        "name": "Haitao Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "56 million, while the method in reference [22] uses the Resnet101 [10] network, and the parameter amount reaches 44."
            ],
            "citingPaper": {
                "paperId": "5c3c2ac444019a96edff6ac60329aea3ef43d359",
                "externalIds": {
                    "DOI": "10.3390/electronics12030673",
                    "CorpusId": 256454161
                },
                "corpusId": 256454161,
                "publicationVenue": {
                    "id": "ccd8e532-73c6-414f-bc91-271bbb2933e2",
                    "name": "Electronics",
                    "type": "journal",
                    "issn": "1450-5843",
                    "alternate_issns": [
                        "2079-9292",
                        "0883-4989"
                    ],
                    "url": "http://www.electronics.etfbl.net/",
                    "alternate_urls": [
                        "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-247562",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-247562",
                        "https://www.mdpi.com/journal/electronics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5c3c2ac444019a96edff6ac60329aea3ef43d359",
                "title": "Table Structure Recognition Method Based on Lightweight Network and Channel Attention",
                "abstract": "The table recognition model rows and columns aggregated network (RCANet) uses a semantic segmentation approach to recognize table structure, and achieves better performance in table row and column segmentation. However, this model uses ResNet18 as the backbone network, and the model has 11.35 million parameters and a volume of 45.5 M, which is inconvenient to deploy to lightweight servers or mobile terminals. Therefore, from the perspective of model compression, this paper proposes the lightweight rows and columns attention aggregated network (LRCAANet), which uses the lightweight network ShuffleNetv2 to replace the original RCANet backbone network ResNet18 to simplify the model size. Considering that the lightweight network reduces the number of feature channels, it has a certain impact on the performance of the model. In order to strengthen the learning between feature channels, the rows attention aggregated (RAA) module and the columns attention aggregated (CAA) module are proposed. The RAA module and the CAA module add the squeeze and excitation (SE) module to the original row and column aggregated modules, respectively. Adding the SE module means the model can learn the correlation between channels and improve the prediction effect of the lightweight model. The experimental results show that our method greatly reduces the model parameters and model volume while ensuring low-performance loss. In the end, the average F1 score of our model is only 1.77% lower than the original model, the parameters are only 0.17 million, and the volume is only 0.8 M. Compared with the original model, the parameter amount and volume are reduced by more than 95%.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "103245682",
                        "name": "T. Zhang"
                    },
                    {
                        "authorId": "48184603",
                        "name": "Yi Sui"
                    },
                    {
                        "authorId": "1821383",
                        "name": "Shunyao Wu"
                    },
                    {
                        "authorId": "2096258",
                        "name": "Fengjing Shao"
                    },
                    {
                        "authorId": "39447552",
                        "name": "Rencheng Sun"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Several deep learning-based methods and datasets from the literature (TabStructNet [17], TableNet [14], CDeCNet [1], UNLV [19], DeepDeSRT [18], TableBank [11], PubTabNet [23], ICDAR 2013 Table Competition [9], DeepFigures [20], PubLayNet [24]) explore solutions to table detection and table structure recognition tasks."
            ],
            "citingPaper": {
                "paperId": "380691f141c4392c6728fb3bf9be6c0d0ec9777b",
                "externalIds": {
                    "DBLP": "conf/comad/SripathyKS23",
                    "DOI": "10.1145/3570991.3571037",
                    "CorpusId": 255416707
                },
                "corpusId": 255416707,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/380691f141c4392c6728fb3bf9be6c0d0ec9777b",
                "title": "BUDDI Table Factory: A toolbox for generating synthetic documents with annotated tables and cells",
                "abstract": "Tables are the most convenient way to represent structured information in a document. Understanding the table structure is critical to understanding its contents. Several deep learning-based approaches from the literature have shown promising results in understanding table structures, but they require large amounts of annotated data. However, the availability of annotated datasets to train these methods are expensive, laborious, and very limited. Moreover, human-annotated data suffers from inconsistencies in table and cell annotations. We propose BUDDI Table Factory (BTF) for synthetically generating annotated documents with a wide range of variations in table structures. We propose a heuristics-based method to generate a variety of table structures from which we generate synthetic documents using LaTeX. We propose a computer vision-based approach to localize table and cell regions and automatically generate annotations in PASCAL VOC challenge format. We empirically illustrate the advantage of adding synthetic BTF documents with limited original documents to the model training, which can significantly improve the TEDS and IoU performance of the table structure recognition tasks in public and real-world healthcare datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2199253362",
                        "name": "Bharath Sripathy"
                    },
                    {
                        "authorId": "2176184223",
                        "name": "Harinath Krishnamoorthy"
                    },
                    {
                        "authorId": "35628253",
                        "name": "Sudarsun Santhiappan"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "GTE [39] PubTabNet-train PubTabNet-test 93."
            ],
            "citingPaper": {
                "paperId": "ca2fabed8604b296d713262794a427e5c4b51ffa",
                "externalIds": {
                    "DBLP": "journals/apin/WanZLZS23",
                    "DOI": "10.1007/s10489-022-04420-4",
                    "CorpusId": 255362168
                },
                "corpusId": 255362168,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ca2fabed8604b296d713262794a427e5c4b51ffa",
                "title": "Contextual transformer sequence-based recognition network for medical examination reports",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "152912519",
                        "name": "Honglin Wan"
                    },
                    {
                        "authorId": "2199057485",
                        "name": "Zongfeng Zhong"
                    },
                    {
                        "authorId": "2263987",
                        "name": "Tianping Li"
                    },
                    {
                        "authorId": "2856513",
                        "name": "Huaxiang Zhang"
                    },
                    {
                        "authorId": "51299154",
                        "name": "Jiande Sun"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "ae6e34d182fbc42bc99ba609369a3b7645d205cb",
                "externalIds": {
                    "DBLP": "journals/prl/WangXZJ23",
                    "DOI": "10.1016/j.patrec.2022.12.014",
                    "CorpusId": 255089449
                },
                "corpusId": 255089449,
                "publicationVenue": {
                    "id": "f35e3e87-9df4-497b-aa0d-bb8584197290",
                    "name": "Pattern Recognition Letters",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit Lett"
                    ],
                    "issn": "0167-8655",
                    "url": "https://www.journals.elsevier.com/pattern-recognition-letters/",
                    "alternate_urls": [
                        "http://www.journals.elsevier.com/pattern-recognition-letters/",
                        "http://www.sciencedirect.com/science/journal/01678655"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ae6e34d182fbc42bc99ba609369a3b7645d205cb",
                "title": "Scene table structure recognition with segmentation collaboration and alignment",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109799388",
                        "name": "Hongyi Wang"
                    },
                    {
                        "authorId": "46364544",
                        "name": "Yang Xue"
                    },
                    {
                        "authorId": "2118131879",
                        "name": "Jiaxin Zhang"
                    },
                    {
                        "authorId": "144838978",
                        "name": "Lianwen Jin"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "S Raja [116] describes a method for recognizing table structure that combines cell detection and interaction modules to locate the cells and forecast their relationships with other detected cells in terms of row and column.",
                "S Raja [116] Mask R-CNN + ResNet-101 based Net 1) An additional alignment loss is suggested for precise cell detection.",
                "S Raja [121] suggests a novel object-detection-based deep model that is tailored for quick optimization and captures the natural alignments of cells inside tables.",
                "com/doc-analysis/TableBank S Raja S Raja [116] TabStructNet 2020 tensorflow https://github.",
                "S Raja[116] ICDAR2013 Object Detection Methods Precision 92."
            ],
            "citingPaper": {
                "paperId": "a81f504a1a101b9c6fe4a88957dd9ec450cf389d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-08469",
                    "ArXiv": "2211.08469",
                    "DOI": "10.48550/arXiv.2211.08469",
                    "CorpusId": 253553399
                },
                "corpusId": 253553399,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a81f504a1a101b9c6fe4a88957dd9ec450cf389d",
                "title": "Deep learning for table detection and structure recognition: A survey",
                "abstract": "Tables are everywhere, from scientific journals, papers, websites, and newspapers all the way to items we buy at the supermarket. Detecting them is thus of utmost importance to automatically understanding the content of a document. The performance of table detection has substantially increased thanks to the rapid development of deep learning networks. The goals of this survey are to provide a profound comprehension of the major developments in the field of Table Detection, offer insight into the different methodologies, and provide a systematic taxonomy of the different approaches. Furthermore, we provide an analysis of both classic and new applications in the field. Lastly, the datasets and source code of the existing models are organized to provide the reader with a compass on this vast literature. Finally, we go over the architecture of utilizing various object detection and table structure recognition methods to create an effective and efficient system, as well as a set of development trends to keep up with state-of-the-art algorithms and future research. We have also set up a public GitHub repository where we will be updating the most recent publications, open data, and source code. The GitHub repository is available at https://github.com/abdoelsayed2016/ table-detection-structure-recognition. Preprint submitted to Elsevier November 17, 2022 ar X iv :2 21 1. 08 46 9v 1 [ cs .C V ] 1 5 N ov 2 02 2",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "87034581",
                        "name": "M. Kasem"
                    },
                    {
                        "authorId": "115665360",
                        "name": "Abdelrahman Abdallah"
                    },
                    {
                        "authorId": "2115948777",
                        "name": "Alexander Berendeyev"
                    },
                    {
                        "authorId": "2190955162",
                        "name": "Ebrahem Elkady"
                    },
                    {
                        "authorId": "2190955581",
                        "name": "Mahmoud Abdalla"
                    },
                    {
                        "authorId": "2163883464",
                        "name": "Mohamed Mahmoud"
                    },
                    {
                        "authorId": "2057870328",
                        "name": "Mohamed Hamada"
                    },
                    {
                        "authorId": "3253700",
                        "name": "D. Nurseitov"
                    },
                    {
                        "authorId": "1405340824",
                        "name": "I. Taj-Eddin"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "[12] proposed to use deep learning [13], [14] to identify the structure information of the table and extract the structure of the table through the text box in the cell, but this method has limitations in dealing with some complex cells."
            ],
            "citingPaper": {
                "paperId": "1981ecca49727d734f63ec17f418a00550b1cf0e",
                "externalIds": {
                    "DOI": "10.1109/CCISP55629.2022.9974564",
                    "CorpusId": 254902206
                },
                "corpusId": 254902206,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1981ecca49727d734f63ec17f418a00550b1cf0e",
                "title": "Invoice Recognition Method Based on Separation of Template and Content",
                "abstract": "It is a necessary task to extract and save structured information from invoices. The existing methods are all to detect and identify the duplication of invoices. Considering that there are a lot of duplicate contents and fixed table structure between invoices of the same type, this method proposes to separate the template and filled contents of invoices by pixel segmentation; The perceptual hash algorithm is used to match the template of the invoice to be tested with the invoice in the template database; After successful matching, use the improved template alignment module to align the new filled content with the template invoice, and then import the new invoice into Excel for saving. Experimental results show that compared with the original method, the text detection time, recognition time and prediction time of this method are reduced by 68%, 91.13% and 89.94% respectively, and the overall prediction time is reduced by 27.26 seconds.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2056571624",
                        "name": "R. Shi"
                    },
                    {
                        "authorId": "9402102",
                        "name": "Sanxin Jiang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[21] usedMask R-CNNwith ResNet-101 as a backbone network."
            ],
            "citingPaper": {
                "paperId": "bc8abf90ebc6d0e463bd0ad9952a437d5fea159b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-17246",
                    "ArXiv": "2210.17246",
                    "DOI": "10.1007/s10032-022-00420-9",
                    "CorpusId": 253193064
                },
                "corpusId": 253193064,
                "publicationVenue": {
                    "id": "46722266-4327-4a22-871d-5a9fe3c5ad0c",
                    "name": "International Journal on Document Analysis and Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Doc Anal Recognit"
                    ],
                    "issn": "1433-2825",
                    "url": "https://link.springer.com/journal/10032"
                },
                "url": "https://www.semanticscholar.org/paper/bc8abf90ebc6d0e463bd0ad9952a437d5fea159b",
                "title": "Tables to LaTeX: structure and content extraction from scientific tables",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "117769145",
                        "name": "Pratik Kayal"
                    },
                    {
                        "authorId": "2106415501",
                        "name": "Mrinal Anand"
                    },
                    {
                        "authorId": "73654757",
                        "name": "Harsh Desai"
                    },
                    {
                        "authorId": "145431050",
                        "name": "Mayank Singh"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[33], approaches table structure detection as a relationship problem between the row and column of the detected cell."
            ],
            "citingPaper": {
                "paperId": "4960e24f6cfab1afd36b7e89c5d88d107ba55863",
                "externalIds": {
                    "DOI": "10.3390/app122010578",
                    "CorpusId": 253075939
                },
                "corpusId": 253075939,
                "publicationVenue": {
                    "id": "136edf8d-0f88-4c2c-830f-461c6a9b842e",
                    "name": "Applied Sciences",
                    "type": "journal",
                    "alternate_names": [
                        "Appl Sci"
                    ],
                    "issn": "2076-3417",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-217814",
                    "alternate_urls": [
                        "http://www.mathem.pub.ro/apps/",
                        "https://www.mdpi.com/journal/applsci",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-217814"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4960e24f6cfab1afd36b7e89c5d88d107ba55863",
                "title": "Rethinking Learnable Proposals for Graphical Object Detection in Scanned Document Images",
                "abstract": "In the age of deep learning, researchers have looked at domain adaptation under the pre-training and fine-tuning paradigm to leverage the gains in the natural image domain. These backbones and subsequent networks are designed for object detection in the natural image domain. They do not consider some of the critical characteristics of document images. Document images are sparse in contextual information, and the graphical page objects are logically clustered. This paper investigates the effectiveness of deep and robust backbones in the document image domain. Further, it explores the idea of learnable object proposals through Sparse R-CNN. This paper shows that simple domain adaptation of top-performing object detectors to the document image domain does not lead to better results. Furthermore, empirically showing that detectors based on dense object priors like Faster R-CNN, Mask R-CNN, and Cascade Mask R-CNN are perhaps not best suited for graphical page object detection. Detectors that reduce the number of object candidates while making them learnable are a step towards a better approach. We formulate and evaluate the Sparse R-CNN (SR-CNN) model on the IIIT-AR-13k, PubLayNet, and DocBank datasets and hope to inspire a rethinking of object proposals in the domain of graphical page object detection.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1576277442",
                        "name": "Sankalp Sinha"
                    },
                    {
                        "authorId": "1403379889",
                        "name": "K. Hashmi"
                    },
                    {
                        "authorId": "1771057",
                        "name": "A. Pagani"
                    },
                    {
                        "authorId": "1743758",
                        "name": "M. Liwicki"
                    },
                    {
                        "authorId": "143749919",
                        "name": "D. Stricker"
                    },
                    {
                        "authorId": "145181206",
                        "name": "Muhammad Zeshan Afzal"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "Some recent works [(Raja, Mondal, and Jawahar 2020), (Qiao et al. 2021), (Zheng et al. 2021)] have proposed a modified TEDS metric named TEDS-Struct to\nevaluate table structure recognition accuracy only by ignoring OCR errors."
            ],
            "citingPaper": {
                "paperId": "0841e71068af40b77892a69378b45e0e1adf6aee",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-05391",
                    "ArXiv": "2210.05391",
                    "DOI": "10.48550/arXiv.2210.05391",
                    "CorpusId": 252816075
                },
                "corpusId": 252816075,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0841e71068af40b77892a69378b45e0e1adf6aee",
                "title": "PP-StructureV2: A Stronger Document Analysis System",
                "abstract": "A large amount of document data exists in unstructured form such as raw images without any text information. Designing a practical document image analysis system is a meaningful but challenging task. In previous work, we proposed an intelligent document analysis system PP-Structure. In order to further upgrade the function and performance of PP-Structure, we propose PP-StructureV2 in this work, which contains two subsystems: Layout Information Extraction and Key Information Extraction. Firstly, we integrate Image Direction Correction module and Layout Restoration module to enhance the functionality of the system. Secondly, 8 practical strategies are utilized in PP-StructureV2 for better performance. For Layout Analysis model, we introduce ultra light-weight detector PP-PicoDet and knowledge distillation algorithm FGD for model lightweighting, which increased the inference speed by 11 times with comparable mAP. For Table Recognition model, we utilize PP-LCNet, CSP-PAN and SLAHead to optimize the backbone module, feature fusion module and decoding module, respectively, which improved the table structure accuracy by 6\\% with comparable inference speed. For Key Information Extraction model, we introduce VI-LayoutXLM which is a visual-feature independent LayoutXLM architecture, TB-YX sorting algorithm and U-DML knowledge distillation algorithm, which brought 2.8\\% and 9.1\\% improvement respectively on the Hmean of Semantic Entity Recognition and Relation Extraction tasks. All the above mentioned models and code are open-sourced in the GitHub repository PaddleOCR.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109266729",
                        "name": "Chenxia Li"
                    },
                    {
                        "authorId": "108703727",
                        "name": "Ruoyu Guo"
                    },
                    {
                        "authorId": "2151548966",
                        "name": "Jun Zhou"
                    },
                    {
                        "authorId": "2187431479",
                        "name": "Mengtao An"
                    },
                    {
                        "authorId": "2867809",
                        "name": "Yuning Du"
                    },
                    {
                        "authorId": "2118940194",
                        "name": "Lingfeng Zhu"
                    },
                    {
                        "authorId": "2153629743",
                        "name": "Yi Liu"
                    },
                    {
                        "authorId": "2109752359",
                        "name": "Xiaoguang Hu"
                    },
                    {
                        "authorId": "3046102",
                        "name": "Dianhai Yu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "According to the underlying alignment information in the table, [38, 46, 47] aim to obtain more accurate aligned cells which can be effectively used to infer the final structure."
            ],
            "citingPaper": {
                "paperId": "4ebf44ebb9634cb5c60f5dc7fab0c0f84aed0939",
                "externalIds": {
                    "DBLP": "conf/mm/LiL0LCNPL22",
                    "DOI": "10.1145/3503161.3547885",
                    "CorpusId": 252782335
                },
                "corpusId": 252782335,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4ebf44ebb9634cb5c60f5dc7fab0c0f84aed0939",
                "title": "End-to-End Compound Table Understanding with Multi-Modal Modeling",
                "abstract": "Table is a widely used data form in webpages, spreadsheets, or PDFs to organize and present structural data. Although studies on table structure recognition have been successfully used to convert image-based tables into digital structural formats, solving many real problems still relies on further understanding of the table, such as cell relationship extraction. The current datasets related to table understanding are all based on the digit format. To boost research development, we release a new benchmark named ComFinTab with rich annotations that support both table recognition and understanding tasks. Unlike previous datasets containing the basic tables, ComFinTab contains a large ratio of compound tables, which is much more challenging and requires methods using multiple information sources. Based on the dataset, we also propose a uniform, concise task form with the evaluation metric to better evaluate the model's performance on the table understanding task in compound tables. Finally, a framework named CTUNet is proposed to integrate the compromised visual, semantic, and position features with a graph attention network, which can solve the table recognition task and the challenging table understanding task as a whole. Experimental results compared with some previous advanced table understanding methods demonstrate the effectiveness of our proposed model. Code and dataset are available at \\urlhttps://github.com/hikopensource/DAVAR-Lab-OCR.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109614687",
                        "name": "Zaisheng Li"
                    },
                    {
                        "authorId": "2187429408",
                        "name": "Yi Li"
                    },
                    {
                        "authorId": "2187308758",
                        "name": "Qiao Liang"
                    },
                    {
                        "authorId": "2144902872",
                        "name": "Pengfei Li"
                    },
                    {
                        "authorId": "2398015",
                        "name": "Zhanzhan Cheng"
                    },
                    {
                        "authorId": "1490934795",
                        "name": "Yi Niu"
                    },
                    {
                        "authorId": "3290437",
                        "name": "Shiliang Pu"
                    },
                    {
                        "authorId": "2116227961",
                        "name": "Xi Li"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "2% among all published methods for this widely studied dataset, TabStruct-Net [18] has low TEDs because it cannot handle the problem of unlined tables.",
                "TabStruct-Net [18] first detects individual cells and then links them to get table structure by graphs.",
                "As the table shows, the TRUST achieves the best Structure TEDs 97.1% and TEDs 96.2% among all published methods for this widely studied dataset, TabStruct-Net [18] has low TEDs because it cannot handle the problem of unlined tables.",
                "Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc.",
                "Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc. Unlike many state-of-the-art methods that perform evaluations only at TEDs, our method also test the Structure TEDs on PubTabNet."
            ],
            "citingPaper": {
                "paperId": "92132fb36fb3e470464551210926f256a1f37280",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-14687",
                    "ArXiv": "2208.14687",
                    "DOI": "10.48550/arXiv.2208.14687",
                    "CorpusId": 251953555
                },
                "corpusId": 251953555,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/92132fb36fb3e470464551210926f256a1f37280",
                "title": "TRUST: An Accurate and End-to-End Table structure Recognizer Using Splitting-based Transformers",
                "abstract": "Table structure recognition is a crucial part of document image analysis domain. Its difficulty lies in the need to parse the physical coordinates and logical indices of each cell at the same time. However, the existing methods are difficult to achieve both these goals, especially when the table splitting lines are blurred or tilted. In this paper, we propose an accurate and end-to-end transformer-based table structure recognition method, referred to as TRUST. Transformers are suitable for table structure recognition because of their global computations, perfect memory, and parallel computation. By introducing novel Transformer-based Query-based Splitting Module and Vertex-based Merging Module, the table structure recognition problem is decoupled into two joint optimization sub-tasks: multi-oriented table row/column splitting and table grid merging. The Query-based Splitting Module learns strong context information from long dependencies via Transformer networks, accurately predicts the multi-oriented table row/column separators, and obtains the basic grids of the table accordingly. The Vertex-based Merging Module is capable of aggregating local contextual information between adjacent basic grids, providing the ability to merge basic girds that belong to the same spanning cell accurately. We conduct experiments on several popular benchmarks including PubTabNet and SynthTable, our method achieves new state-of-the-art results. In particular, TRUST runs at 10 FPS on PubTabNet, surpassing the previous methods by a large margin.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109309324",
                        "name": "Zengyuan Guo"
                    },
                    {
                        "authorId": "2117164666",
                        "name": "Yuecheng Yu"
                    },
                    {
                        "authorId": "25604699",
                        "name": "Pengyuan Lv"
                    },
                    {
                        "authorId": "1979323",
                        "name": "Chengquan Zhang"
                    },
                    {
                        "authorId": "2579920",
                        "name": "Haojie Li"
                    },
                    {
                        "authorId": "47196393",
                        "name": "Zhihui Wang"
                    },
                    {
                        "authorId": "2140371004",
                        "name": "Kun Yao"
                    },
                    {
                        "authorId": "2272123",
                        "name": "Jingtuo Liu"
                    },
                    {
                        "authorId": "2109534192",
                        "name": "Jingdong Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Table detection [25,26], structure recognition [20,24] and extraction [9,30] in DLA gathered some special attention in recent years due to the high variability of layouts that make the both necessary to be solved and challenging to be tackled."
            ],
            "citingPaper": {
                "paperId": "6357238a07f0904f8279832b59f5b387a4e827f2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-11168",
                    "ArXiv": "2208.11168",
                    "DOI": "10.1007/978-3-031-25069-9_22",
                    "CorpusId": 251765056
                },
                "corpusId": 251765056,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/6357238a07f0904f8279832b59f5b387a4e827f2",
                "title": "Doc2Graph: a Task Agnostic Document Understanding Framework based on Graph Neural Networks",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2182515911",
                        "name": "Andrea Gemelli"
                    },
                    {
                        "authorId": "2150473007",
                        "name": "Sanket Biswas"
                    },
                    {
                        "authorId": "2122367862",
                        "name": "Enrico Civitelli"
                    },
                    {
                        "authorId": "2117637297",
                        "name": "Josep Llad'os"
                    },
                    {
                        "authorId": "3285734",
                        "name": "S. Marinai"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "fb6fcca5762b26f225313f86b1f33a1cf198bfd7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-04921",
                    "ArXiv": "2208.04921",
                    "DOI": "10.1145/3503161.3548038",
                    "CorpusId": 251442367
                },
                "corpusId": 251442367,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fb6fcca5762b26f225313f86b1f33a1cf198bfd7",
                "title": "TSRFormer: Table Structure Recognition with Transformers",
                "abstract": "We present a new table structure recognition (TSR) approach, called TSRFormer, to robustly recognizing the structures of complex tables with geometrical distortions from various table images. Unlike previous methods, we formulate table separation line prediction as a line regression problem instead of an image segmentation problem and propose a new two-stage DETR based separator prediction approach, dubbed Sep arator RE gression TR ansformer (SepRETR), to predict separation lines from table images directly. To make the two-stage DETR framework work efficiently and effectively for the separation line prediction task, we propose two improvements: 1) A prior-enhanced matching strategy to solve the slow convergence issue of DETR; 2) A new cross attention module to sample features from a high-resolution convolutional feature map directly so that high localization accuracy is achieved with low computational cost. After separation line prediction, a simple relation network based cell merging module is used to recover spanning cells. With these new techniques, our TSRFormer achieves state-of-the-art performance on several benchmark datasets, including SciTSR, PubTabNet and WTW. Furthermore, we have validated the robustness of our approach to tables with complex structures, borderless cells, large blank spaces, empty or spanning cells as well as distorted or even curved shapes on a more challenging real-world in-house dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108811137",
                        "name": "Weihong Lin"
                    },
                    {
                        "authorId": "2145130513",
                        "name": "Zhengmao Sun"
                    },
                    {
                        "authorId": "2894335",
                        "name": "Chixiang Ma"
                    },
                    {
                        "authorId": "2181111465",
                        "name": "Mingze Li"
                    },
                    {
                        "authorId": "2110132415",
                        "name": "Jiawei Wang"
                    },
                    {
                        "authorId": "2110833051",
                        "name": "Lei Sun"
                    },
                    {
                        "authorId": "2316043",
                        "name": "Qiang Huo"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Although the mentioned methods made progress toward understanding complex structured tables, several assumptions were made, such as that accurate word bounding boxes were available and that accurate document text could be used as additional inputs [66]."
            ],
            "citingPaper": {
                "paperId": "87cb212eeb40171b32a4411a6919e22c36822140",
                "externalIds": {
                    "DBLP": "journals/tmis/AmeriHSLP23",
                    "DOI": "10.1145/3546580",
                    "CorpusId": 250496865
                },
                "corpusId": 250496865,
                "publicationVenue": {
                    "id": "a0b9dfee-fbf4-4bea-835f-20d6db1ce53a",
                    "name": "ACM Transactions on Management Information Systems",
                    "alternate_names": [
                        "ACM Trans Manag Inf Syst"
                    ],
                    "issn": "2158-656X",
                    "url": "http://dl.acm.org/citation.cfm?CFID=72370079&CFTOKEN=39904203&id=J1320",
                    "alternate_urls": [
                        "http://portal.acm.org/tmis",
                        "http://portal.acm.org/citation.cfm?id=J1320&picked=prox",
                        "https://tmis.acm.org/",
                        "http://tmis.acm.org/index.html"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/87cb212eeb40171b32a4411a6919e22c36822140",
                "title": "Design of a Novel Information System for Semi-automated Management of Cybersecurity in Industrial Control Systems",
                "abstract": "There is an urgent need in many critical infrastructure sectors, including the energy sector, for attaining detailed insights into cybersecurity features and compliance with cybersecurity requirements related to their Operational Technology (OT) deployments. Frequent feature changes of OT devices interfere with this need, posing a great risk to customers. One effective way to address this challenge is via a semi-automated cyber-physical security assurance approach, which enables verification and validation of the OT device cybersecurity claims against actual capabilities, both pre- and post-deployment. To realize this approach, this article presents new methodology and algorithms to automatically identify cybersecurity-related claims expressed in natural language form in ICS device documents. We developed an identification process that employs natural language processing (NLP) techniques with the goal of semi-automated vetting of detected claims against their device implementation. We also present our novel NLP components for verifying feature claims against relevant cybersecurity requirements. The verification pipeline includes components such as automated vendor identification, device document curation, feature claim identification utilizing sentiment analysis for conflict resolution, and reporting of features that are claimed to be supported or indicated as unsupported. Our novel matching engine represents the first automated information system available in the cybersecurity domain that directly aids the generation of ICS compliance reports.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "134238540",
                        "name": "Kimia Ameri"
                    },
                    {
                        "authorId": "35380390",
                        "name": "M. Hempel"
                    },
                    {
                        "authorId": "145505074",
                        "name": "H. Sharif"
                    },
                    {
                        "authorId": "2150338498",
                        "name": "Juan Lopez"
                    },
                    {
                        "authorId": "1750770",
                        "name": "K. Perumalla"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "644b991959bf5fb036d28d67e9918d419b212e75",
                "externalIds": {
                    "DBLP": "journals/pr/LiYDL22",
                    "DOI": "10.1016/j.patcog.2022.108946",
                    "CorpusId": 251140530
                },
                "corpusId": 251140530,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/644b991959bf5fb036d28d67e9918d419b212e75",
                "title": "Table Structure Recognition and Form Parsing by End-to-End Object Detection and Relation Parsing",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118890077",
                        "name": "Xiaohui Li"
                    },
                    {
                        "authorId": "145820427",
                        "name": "Fei Yin"
                    },
                    {
                        "authorId": "2179477671",
                        "name": "He-Sen Dai"
                    },
                    {
                        "authorId": "1689269",
                        "name": "Cheng-Lin Liu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Certain relational understanding tasks already play the important role in building electronic archives and developing office automation, which include table structure recognition [24,25,27,31,33],",
                "Now mainstream relational understanding tasks like table structure recognition [24, 25, 27, 31, 33], key information extraction [16, 17, 46] and reading order detection [37] are born with entitylevel."
            ],
            "citingPaper": {
                "paperId": "db938b8742d3d91d8e3b11a161930f3b56a4bddd",
                "externalIds": {
                    "DBLP": "conf/mm/LiZHCWJLR22",
                    "ArXiv": "2205.02411",
                    "DOI": "10.1145/3503161.3547751",
                    "CorpusId": 248524962
                },
                "corpusId": 248524962,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/db938b8742d3d91d8e3b11a161930f3b56a4bddd",
                "title": "Relational Representation Learning in Visually-Rich Documents",
                "abstract": "Relational understanding is critical for a number of visually-rich documents (VRDs) understanding tasks. Through multi-modal pre-training, recent studies provide comprehensive contextual representations and exploit them as prior knowledge for downstream tasks. In spite of their impressive results, we observe that the widespread relational hints (e.g., relation of key/value fields on receipts) built upon contextual knowledge are not excavated yet. To mitigate this gap, we propose DocReL, a Document Relational Representation Learning framework. The major challenge of DocReL roots in the variety of relations. From the simplest pairwise relation to the complex global structure, it is infeasible to conduct supervised training due to the definition of relation varies and even conflicts in different tasks. To deal with the unpredictable definition of relations, we propose a novel contrastive learning task named Relational Consistency Modeling (RCM), which harnesses the fact that existing relations should be consistent in differently augmented positive views. RCM provides relational representations which are more compatible to the urgent need of downstream tasks, even without any knowledge about the exact definition of relation. DocReL achieves better performance on a wide variety of VRD relational understanding tasks, including table structure recognition, key information extraction and reading order detection.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2153901204",
                        "name": "Xin Li"
                    },
                    {
                        "authorId": "2111094840",
                        "name": "Yan Zheng"
                    },
                    {
                        "authorId": "2149298493",
                        "name": "Yiqing Hu"
                    },
                    {
                        "authorId": "50732729",
                        "name": "H. Cao"
                    },
                    {
                        "authorId": "2164224877",
                        "name": "Yunfei Wu"
                    },
                    {
                        "authorId": "3336726",
                        "name": "Deqiang Jiang"
                    },
                    {
                        "authorId": "2136370566",
                        "name": "Yinsong Liu"
                    },
                    {
                        "authorId": "2064646914",
                        "name": "Bo Ren"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Some recent works [8, 22, 23] have proposed a modified TEDS metric, denoted as TEDS-Struct, to evaluate table structure recognition accuracy only by ignoring OCR errors.",
                "To eliminate this assumption, another group of methods [8, 22, 23] proposed to detect the bounding boxes of",
                "[22] introduced a novel loss function that modeled the inherent alignment of cells in the cell detection",
                "Net [22] and LGPMA [23], typically use CNNbased object detection or segmentation models like Mask R-CNN to detect table cells first, then adopt some cell grouping/clustering algorithms to predict row/column relationships between the detected cells."
            ],
            "citingPaper": {
                "paperId": "29942b5588d9978af5da046ebfc642e4779b8597",
                "externalIds": {
                    "ArXiv": "2203.09056",
                    "DBLP": "journals/pr/MaLSH23",
                    "DOI": "10.1016/j.patcog.2022.109006",
                    "CorpusId": 247518554
                },
                "corpusId": 247518554,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/29942b5588d9978af5da046ebfc642e4779b8597",
                "title": "Robust Table Detection and Structure Recognition from Heterogeneous Document Images",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2894335",
                        "name": "Chixiang Ma"
                    },
                    {
                        "authorId": "2108811137",
                        "name": "Weihong Lin"
                    },
                    {
                        "authorId": "2110833051",
                        "name": "Lei Sun"
                    },
                    {
                        "authorId": "2316043",
                        "name": "Qiang Huo"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "result"
            ],
            "isInfluential": false,
            "contexts": [
                "Notably, the experimental results of Tabby, GraphTSR, DeepDeSRT on the ICDAR2013, SciTSR and SciTSR-COMP dataset come from the study [3], and the results of TableStrucNet and Split+Heur are from study [22].",
                "TableStrucNet [22] considers two experiment settings in their work."
            ],
            "citingPaper": {
                "paperId": "007f2dc393e363abcfd023c1a1b47f5b84d4b2ae",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-03819",
                    "ArXiv": "2203.03819",
                    "DOI": "10.48550/arXiv.2203.03819",
                    "CorpusId": 247315039
                },
                "corpusId": 247315039,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/007f2dc393e363abcfd023c1a1b47f5b84d4b2ae",
                "title": "Table Structure Recognition with Conditional Attention",
                "abstract": "Tabular data in digital documents is widely used to express compact and important information for readers. However, it is challenging to parse tables from unstructured digital documents, such as PDFs and images, into machine-readable format because of the complexity of table structures and the missing of meta-information. Table Structure Recognition (TSR) problem aims to recognize the structure of a table and transform the unstructured tables into a structured and machine-readable format so that the tabular data can be further analysed by the down-stream tasks, such as semantic modeling and information retrieval. In this study, we hypothesize that a complicated table structure can be represented by a graph whose vertices and edges represent the cells and association between cells, respectively. Then we define the table structure recognition problem as a cell association classification problem and propose a conditional attention network (CATT-Net). The experimental results demonstrate the superiority of our proposed method over the state-of-the-art methods on various datasets. Besides, we investigate whether the alignment of a cell bounding box or a text-focused approach has more impact on the model performance. Due to the lack of public dataset annotations based on these two approaches, we further annotate the ICDAR2013 dataset providing both types of bounding boxes, which can be a new benchmark dataset for evaluating the methods in this field. Experimental results show that the alignment of a cell bounding box can help improve the Micro-averaged F1 score from 0.915 to 0.963, and the Macro-average F1 score from 0.787 to 0.923.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "144025674",
                        "name": "Bin Xiao"
                    },
                    {
                        "authorId": "48778270",
                        "name": "Murat Simsek"
                    },
                    {
                        "authorId": "2497479",
                        "name": "B. Kantarci"
                    },
                    {
                        "authorId": "3082067",
                        "name": "A. A. Alkheir"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "a9e00a1c3de05e3d06a4287b8ef07096f0cfe609",
                "externalIds": {
                    "DBLP": "journals/pr/RibaGTRFL22",
                    "DOI": "10.1016/j.patcog.2022.108641",
                    "CorpusId": 247427729
                },
                "corpusId": 247427729,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a9e00a1c3de05e3d06a4287b8ef07096f0cfe609",
                "title": "Table detection in business document images by message passing networks",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40420775",
                        "name": "Pau Riba"
                    },
                    {
                        "authorId": "145029669",
                        "name": "Lutz Goldmann"
                    },
                    {
                        "authorId": "3045937",
                        "name": "O. R. Terrades"
                    },
                    {
                        "authorId": "1491424368",
                        "name": "Diede Rusticus"
                    },
                    {
                        "authorId": "1686569",
                        "name": "A. Forn\u00e9s"
                    },
                    {
                        "authorId": "143826881",
                        "name": "J. Llad\u00f3s"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Document Intelligence can be considered as an umbrella term covering problems of Key Information Extraction [10,54], Table Detection [41,38] and Structure Recognition [39,55], Document Layout Segmentation [5,4] Document Layout Generation [6,36,3,48], Document Visual Question Answering [51,50,32], Document Image Enhancement [49,22,47] which involves the understanding of visually rich semantic information and structure of different layout entities of a whole page."
            ],
            "citingPaper": {
                "paperId": "6289874e3b499593dddd51ae229062fe07d30b56",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2202-12985",
                    "ArXiv": "2202.12985",
                    "DOI": "10.1007/978-3-031-25069-9_16",
                    "CorpusId": 247158436
                },
                "corpusId": 247158436,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/6289874e3b499593dddd51ae229062fe07d30b56",
                "title": "OCR-IDL: OCR Annotations for Industry Document Library Dataset",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "35570245",
                        "name": "Ali Furkan Biten"
                    },
                    {
                        "authorId": "134682605",
                        "name": "Rub\u00e8n P\u00e9rez Tito"
                    },
                    {
                        "authorId": "51231577",
                        "name": "Llu\u00eds G\u00f3mez"
                    },
                    {
                        "authorId": "2864362",
                        "name": "Ernest Valveny"
                    },
                    {
                        "authorId": "1694974",
                        "name": "Dimosthenis Karatzas"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "We use four existing recognizers \u2014ocr [26], equation descriptor [19], table recognizer [23], and figure classifier [12] to recognize content from the segmented regions.",
                "We use TabStruct-Net [23] to recognize the physical structure of the table and then Tesseract [26] to recognize content."
            ],
            "citingPaper": {
                "paperId": "1761898205a967c7785baaf8846a63ee7261191e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-08574",
                    "ArXiv": "2201.08574",
                    "DOI": "10.1007/978-3-031-11349-9_12",
                    "CorpusId": 244797472
                },
                "corpusId": 244797472,
                "publicationVenue": {
                    "id": "73dc1b2c-812e-4118-be6b-501cf924387d",
                    "name": "International Conference on Computer Vision and Image Processing",
                    "type": "conference",
                    "alternate_names": [
                        "CVIP",
                        "Int Conf Comput Vis Image Process"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1761898205a967c7785baaf8846a63ee7261191e",
                "title": "Classroom Slide Narration System",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48225990",
                        "name": "K. V. Jobin"
                    },
                    {
                        "authorId": "2896521",
                        "name": "Ajoy Mondal"
                    },
                    {
                        "authorId": "1694502",
                        "name": "C. V. Jawahar"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "The success of DL has marked the revisiting of table structure parsing by [7], which inspired follow-up research [27, 1, 6, 2, 28, 29, 30, 19, 31, 18, 32, 17].",
                "In some best performing frameworks [17, 18, 19], they all jointly optimize the structure detection and entity relations in the structure, as in DocParser.",
                "We see from the previous works, the most effective methods [17, 18, 19] always jointly optimize the cell locations and cell relationships."
            ],
            "citingPaper": {
                "paperId": "10c3efc40e72674b615864c94a231e1f11913619",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-01654",
                    "ArXiv": "2201.01654",
                    "CorpusId": 245704311
                },
                "corpusId": 245704311,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/10c3efc40e72674b615864c94a231e1f11913619",
                "title": "TableParser: Automatic Table Parsing with Weak Supervision from Spreadsheets",
                "abstract": "Tables have been an ever-existing structure to store data. There exist now different approaches to store tabular data physically. PDFs, images, spreadsheets, and CSVs are leading examples. Being able to parse table structures and extract content bounded by these structures is of high importance in many applications. In this paper, we devise TableParser, a system capable of parsing tables in both native PDFs and scanned images with high precision. We have conducted extensive experiments to show the efficacy of domain adaptation in developing such a tool. Moreover, we create TableAnnotator and ExcelAnnotator, which constitute a spreadsheet-based weak supervision mechanism and a pipeline to enable table parsing. We share these resources with the research community to facilitate further research in this interesting direction.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1576005199",
                        "name": "Susie Xi Rao"
                    },
                    {
                        "authorId": "5185738",
                        "name": "Johannes Rausch"
                    },
                    {
                        "authorId": "2074406990",
                        "name": "P. Egger"
                    },
                    {
                        "authorId": "1776014",
                        "name": "Ce Zhang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "ea4fbbe4e89d22b29737aba19a1aae68ff1d29dd",
                "externalIds": {
                    "DBLP": "journals/mta/LeePKC22",
                    "DOI": "10.1007/s11042-021-11819-7",
                    "CorpusId": 245597780
                },
                "corpusId": 245597780,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ea4fbbe4e89d22b29737aba19a1aae68ff1d29dd",
                "title": "Deep-learning and graph-based approach to table structure recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2115242015",
                        "name": "Eunji Lee"
                    },
                    {
                        "authorId": "2370571",
                        "name": "Jaewoo Park"
                    },
                    {
                        "authorId": "2463454",
                        "name": "H. Koo"
                    },
                    {
                        "authorId": "1707645",
                        "name": "N. Cho"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "In order to visualize predicted structures, we have drawn blue cell boxes that belong to the same column and row to the selected red cells as [25].",
                "[25] also attempted to remove heuristics.",
                "TabStructNet [25] detected cell-level bounding boxes, not content-level bounding boxes.",
                "of parameters CascadeTabNet [23] 82,852,033 TabStructNet [25] 68,636,098 SPLERGE [32] 255,862 Ours 1,120,692",
                "Some authors attempted to replace the heuristics with machinelearning methods [24, 25].",
                "8 Examples of qualitative results on complex tables, the colored regions are the recognized cell regions: Table structure recognition results of (a) CascadeTabNet  [23], (b) TabStructNet  [25], (c) SPLERGE [32], and (d) the proposed method",
                "We compare the performance of our method with three coventional methods: CascadeTabNet [23], TabStructNet [25], and SPLERGE [32].",
                "Results of CascadeTabNet [23], TabStructNet [25], SPLERGE [32], and the proposed method, from top to bottom 5844 Multimedia Tools and Applications (2022) 81:5827\u20135848",
                "(a) Result from CascadeTabNet [23], (b) TabStructNet [25] with ground truth table locations, (c) SPLERGE [32] with ground truth table locations, and (d) result from the proposed method 5845 Multimedia Tools and Applications (2022) 81:5827\u20135848"
            ],
            "citingPaper": {
                "paperId": "d9c676eccdff80a7d1154660a09c4d2ea5164610",
                "externalIds": {
                    "DOI": "10.1007/s11042-021-11819-7",
                    "CorpusId": 254860167
                },
                "corpusId": 254860167,
                "publicationVenue": {
                    "id": "477368e9-7a8e-475a-8c93-6d623797fd06",
                    "name": "Multimedia tools and applications",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Tools and Applications",
                        "Multimedia Tool Appl",
                        "Multimedia tool appl"
                    ],
                    "issn": "1380-7501",
                    "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d9c676eccdff80a7d1154660a09c4d2ea5164610",
                "title": "Deep-learning and graph-based approach to table structure recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2115242015",
                        "name": "Eunji Lee"
                    },
                    {
                        "authorId": "2370571",
                        "name": "Jaewoo Park"
                    },
                    {
                        "authorId": "2463454",
                        "name": "H. Koo"
                    },
                    {
                        "authorId": "1707645",
                        "name": "N. Cho"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Therefore, recent methods [2, 30, 34] attempt to attack the problem via constructing visual cues of table elements as graphs and applying the deep graph model, such as Graph Convolutional Networks (GCN) [15] to reason their relationships.",
                "Compared with \u201cDGCNN\u201d, although \u201cTransformer\u201d can deploy the global information of nodes, it ignores the directed edge effects between nodes.",
                "With the development of deep learning, table structure recognition methods have recently advanced substantially on performance, which can be classified into three categories: boundary extractionbased [13, 22, 27, 35, 40], generative model-based [18, 46], and graph-based [2, 20, 30, 34] methods.",
                "For comparison, we also visualize\nthe multi-head self-attention maps from the last blocks of \u201cTransformer-Mixed\u201d [42] and KNN (K = 5) selection heatmaps of all layers in DGCNN [30], where a lighter color indicates a closer relationship.",
                "The method [30] introduces DGCNN to predict the relationship between words represented by the appearance and geometry features.",
                "For \u201cDGCNN\u201d, it only aggregates information from top K similar nodes of each node instead of all ones.",
                "Although many previous algorithms [2,13,18,20,22,30,31,34,35,40,45,46] have achieved impressive progress in the community, TSR is still a challenging task due to two factors of complicated tables.",
                "To compare in a unified protocol, we follow two different experimental setups in [34]: (a) SetupA where only table image is taken as input without additional information and (b) Setup-B where table image along with additional features such as cell/text segment bounding boxes and text contents.",
                "Also based on DGCNN, TabStruct-Net [34] proposes an end-to-end network training cell detection and structure recognition networks in a joint manner.",
                "It should be noted that there is no training set in ICDAR-2013 and UNLV datasets, so we extend the two datasets to the partial versions, which is similar to TabStruct-Net [34].",
                "Table structure recognition (TSR) aims to recognize the table internal structure to the machine readable data mainly presented in two formats: logical structure [18, 46] and physical structure [2, 13, 20, 22, 27, 30, 31, 34, 35, 40, 45].",
                "The KNN results of DGCNN show that the feature aggregation of one node only pays attention to the top K similar features of other nodes instead of all the nodes, and relies on the choice of K.",
                "In the similar spirit with works [30, 34], we adopt the following asymmetric edge function h\u0398(xi,xj) = xi\u2225(xi \u2212 xj) to combine graph edge features to each node, which can be denoted as H\u0398 \u2208 R \u00b7(N\u22121)/2)\u00d7d .",
                "To introduce richer table information, several methods [20, 30, 34] con-",
                "Besides, the DGCNN-based methods apply CNN to perform local context aggregation.",
                "In previous works using DGCNN [30, 34], only local context of each node is selected by k-Nearest Neighbors algorithm (KNN) to be aggregated into node feature.",
                "3 compares the effectiveness of various extractors, including DGCNN [30] and Transformer [42], with ECE in our method."
            ],
            "citingPaper": {
                "paperId": "9fb2744ef2b91033de39c121be25d3f86f759458",
                "externalIds": {
                    "DBLP": "conf/cvpr/0003LLJL022",
                    "ArXiv": "2111.13359",
                    "DOI": "10.1109/CVPR52688.2022.00449",
                    "CorpusId": 244709555
                },
                "corpusId": 244709555,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9fb2744ef2b91033de39c121be25d3f86f759458",
                "title": "Neural Collaborative Graph Machines for Table Structure Recognition",
                "abstract": "Recently, table structure recognition has achieved impressive progress with the help of deep graph models. Most of them exploit single visual cues of tabular elements or simply combine visual cues with other modalities via early fusion to reason their graph relationships. However, neither early fusion nor individually reasoning in terms of multiple modalities can be appropriate for all varieties of table structures with great diversity. Instead, different modalities are expected to collaborate with each other in different patterns for different table cases. In the community, the importance of intrainter modality interactions for table structure reasoning is still unexplored. In this paper, we define it as heterogeneous table structure recognition (HeteroTSR) problem. With the aim offilling this gap, we present a novel Neural Collaborative Graph Machines (NCGM) equipped with stacked collaborative blocks, which alternatively extracts intramodality context and models inter-modality interactions in a hierarchical way. It can represent the intrainter modality relationships of tabular elements more robustly, which significantly improves the recognition performance. We also show that the proposed NCGM can modulate collaborative pattern of different modalities conditioned on the context of intramodality cues, which is vital for diversified table cases. Experimental results on benchmarks demonstrate our proposed NCGM achieves state-of-the-art performance and beats other contemporary methods by a large margin especially under challenging scenarios.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "48446712",
                        "name": "Hao Liu"
                    },
                    {
                        "authorId": "2153898418",
                        "name": "Xin Li"
                    },
                    {
                        "authorId": "2149124539",
                        "name": "Bing Liu"
                    },
                    {
                        "authorId": "3336726",
                        "name": "Deqiang Jiang"
                    },
                    {
                        "authorId": "2136370566",
                        "name": "Yinsong Liu"
                    },
                    {
                        "authorId": "2064646914",
                        "name": "Bo Ren"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Contrarily, the TabStruct-Net [24] does not make any such assumptions and produces adjacency relations and cell locality information as the output.",
                "\u2022 Introduce channel attention [19] for table object detection and define two additional regularizers \u2014 continuity and overlapping loss between every pair of cells in addition to the alignment loss from [24].",
                "Our formulation uses rectilinear adjacencies instead of row/column adjacencies [22, 24].",
                "Table structure recognition generates a machine-interpretable output for a given table image, which encodes its layout according to a pre-defined standard [30, 17, 20, 42, 4, 39, 24].",
                "Not taking them into account might lead to false negatives and, in-turn, incorrect structure [24].",
                "Recently, many researchers have opted for a graph-based formulation of the problem as a graph is inherently an ideal data structure to model associations between entities [22, 4, 24].",
                "We further observe that empty cells account for an average of 12.3% across UNLV and ICDAR-2013 datasets, where our method outperforms TabStruct-Net by 4.2% F1 score.",
                "Inspired by human cognition, we say that table cells, in addition to completely encapsulating their content, should adhere to alignment [24], continuity and non-overlapping constraints, which in-turn makes it easier to locate table columns and rows as independent objects.",
                "In order to compare our method against others on TUCD dataset, we develop our implementation of DeepDeSRT [26], and use open source implementations of DGCNN (TIES) [22], SPLERGE [30], and TabStruct-Net [24].",
                "Cognitive methods in this space broadly classified into five categories \u2014 image-to-sequence models [17, 2, 14], segmentation networks [26, 18, 20, 23], graph formulations [22, 4, 24], conditional generative adversarial networks [16] and a recent multi-modal method by [40].",
                "Raja [24] proposed a first end-to-end object detection and graph based model for collective cells detection and structure recognition.",
                "To detect table cells, we propose TOD-Net, where we augment the cell detection network of TabStruct-Net [24] with additional loss components to further improve the table object performance (rows/columns/cells) detection."
            ],
            "citingPaper": {
                "paperId": "d499cd8a77e7fc4e12d1f5bd7875ce2e3f5465a4",
                "externalIds": {
                    "DBLP": "conf/wacv/RajaMV22",
                    "ArXiv": "2111.07129",
                    "DOI": "10.1109/WACV51458.2022.00260",
                    "CorpusId": 240285297
                },
                "corpusId": 240285297,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/d499cd8a77e7fc4e12d1f5bd7875ce2e3f5465a4",
                "title": "Visual Understanding of Complex Table Structures from Document Images",
                "abstract": "Table structure recognition is necessary for a comprehensive understanding of documents. Tables in unstructured business documents are tough to parse due to the high diversity of layouts, varying alignments of contents, and the presence of empty cells. The problem is particularly difficult because of challenges in identifying individual cells using visual or linguistic contexts or both. Accurate detection of table cells (including empty cells) simplifies structure extraction and hence, it becomes the prime focus of our work. We propose a novel object-detection-based deep model that captures the inherent alignments of cells within tables and is fine-tuned for fast optimization. Despite accurate detection of cells, recognizing structures for dense tables may still be challenging because of difficulties in capturing long-range row/column dependencies in presence of multi-row/column spanning cells. Therefore, we also aim to improve structure recognition by deducing a novel rectilinear graph-based formulation. From a semantics perspective, we highlight the significance of empty cells in a table. To take these cells into account, we suggest an enhancement to a popular evaluation criterion. Finally, we introduce a modestly sized evaluation dataset with an annotation style inspired by human cognition to encourage new approaches to the problem. Our framework improves the previous state-of-the-art performance by a 2.7% average F1-score on benchmark datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2053910624",
                        "name": "S. Raja"
                    },
                    {
                        "authorId": "2896521",
                        "name": "Ajoy Mondal"
                    },
                    {
                        "authorId": "2226828175",
                        "name": "Jawahar C V"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "4(c) shows our method can well handle the table including non-gridded cells, which may cause the \u201ccell boundary ambiguity\u201d problem to the cell detection-based methods [29, 31, 43].",
                "Furthermore, some methods [2, 19, 28, 31] attempt to construct the graphs of elements to reason the relationships.",
                "Different from previousworks [29, 31, 43], we adopt word bounding boxes rather than cells as table elements to avoid cell boundary ambiguity issue.",
                "Similar to previous works [28, 31] using DGCNN, only k nearest neighbours of each node are selected by k-Nearest Neighbors algorithm (KNN) to construct the local context which is applied by the CNN to aggregate the edge information into node feature Di \u2208 RN\u00d7 d h for i-th head.",
                "inference speed than the method [31] greedily employing large number of proposals with redundancy to model their relationships.",
                "To overcome this issue, Raja et al. [31] propose TabStruct-Net, which predicts the aligned cell regions and the localized cell relations in a joint manner.",
                "[31] propose TabStruct-Net, which predicts the aligned cell regions and the localized cell relations in a joint manner.",
                "For the relational reasoning aspect, recent mainstream algorithms [2, 19, 28, 31] construct table elements as contextual graphs and apply the graph-based aggregator, such as Graph Convolutional Networks (GCN) [14], to reason their relationships.",
                "To solve this problem, we randomly extract 80% of the data for training and others for testing, which is similar to [31].",
                "While on both ICDAR-2019 and UNLV, the F1 score of our approach can overtake that of TabStruct-Net as much as 4%.",
                "Although methods [29, 31, 43] achieve performance improvement by directly predicting cell boxes, they may suffer from \u201ccell boundary ambiguity\u201d problem, especially on those blank or non-gridded cell cases.",
                "In addition, our model is only trained on the training set of SciTSR for a fair comparison with TabStruct-Net [31].",
                "Compared with the strong baseline TabStruct-Net [31] greedily exploiting large numbers of proposals (round 2,000), our proposed FLAG-Net can achieve marginally better performance with less parameters and computational consumption, which thanks to the proposal filtering mechanism in our method."
            ],
            "citingPaper": {
                "paperId": "7b99f9995a4b086c0e6913a8d2f109a5dbaa5014",
                "externalIds": {
                    "DBLP": "conf/mm/LiuLLJLRJ21",
                    "DOI": "10.1145/3474085.3481534",
                    "CorpusId": 239011898
                },
                "corpusId": 239011898,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7b99f9995a4b086c0e6913a8d2f109a5dbaa5014",
                "title": "Show, Read and Reason: Table Structure Recognition with Flexible Context Aggregator",
                "abstract": "We investigate the challenging problem of table structure recognition in this work. Many recent methods adopt graph-based context aggregator with strong inductive bias to reason sparse contextual relationships of table elements. However, the strong constraints may be too restrictive to represent the complicated table relationships. In order to learn more appropriate inductive bias from data, we try to introduce Transformer as context aggregator in this work. Nevertheless, Transformer taking dense context as input requires larger scale data and may suffer from unstable training procedure due to the weakening of inductive bias. To overcome the above limitations, we in this paper design a FLAG (FLexible context AGgregator), which marries Transformer with graph-based context aggregator in an adaptive way. Based on FLAG, an end-to-end framework requiring no extra meta-data or OCR information, termed FLAG-Net, is proposed to flexibly modulate the aggregation of dense context and sparse one for the relational reasoning of table elements. We investigate the modulation pattern in FLAG and show what contextual information is focused, which is vital for recognizing table structure. Extensive experimental results on benchmarks demonstrate the performance of our proposed FLAG-Net surpasses other compared methods by a large margin.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "48446712",
                        "name": "Hao Liu"
                    },
                    {
                        "authorId": "2153898418",
                        "name": "Xin Li"
                    },
                    {
                        "authorId": "2149124539",
                        "name": "Bing Liu"
                    },
                    {
                        "authorId": "3336726",
                        "name": "Deqiang Jiang"
                    },
                    {
                        "authorId": "2136370566",
                        "name": "Yinsong Liu"
                    },
                    {
                        "authorId": "2064646914",
                        "name": "Bo Ren"
                    },
                    {
                        "authorId": "145592290",
                        "name": "R. Ji"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "b8bdf103e70e5bf962f85007462a4d14cfb22c78",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-02933",
                    "ArXiv": "2110.02933",
                    "DOI": "10.1016/j.neucom.2022.09.094",
                    "CorpusId": 238407904
                },
                "corpusId": 238407904,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b8bdf103e70e5bf962f85007462a4d14cfb22c78",
                "title": "On Cropped versus Uncropped Training Sets in Tabular Structure Detection",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2130012695",
                        "name": "Yakup Akkaya"
                    },
                    {
                        "authorId": "48778270",
                        "name": "Murat Simsek"
                    },
                    {
                        "authorId": "2497479",
                        "name": "B. Kantarci"
                    },
                    {
                        "authorId": "152235107",
                        "name": "Shahzad Khan"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "For a more practical requirement of parsing table structures from images taken by hand-held cameras in the wild, the existing state-of-the-art approaches [13, 14, 11, 16, 9, 23] are prone to fail as the commonly-used assumption of tabular images no longer holds.",
                "However, these methods mainly focuses on the well-conditioned document images, where the tables [16, 23, 12, 9, 23, 14] are well-aligned to the image axes.",
                "For instance, the non-rigid image deformation and complicated image background presented in natural images will challenge existing approaches [14] for document images on detecting and grouping the tabular cells."
            ],
            "citingPaper": {
                "paperId": "7a4c901e00fef01d66efb125bf0e2fdd773d8bc6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2109-02199",
                    "ArXiv": "2109.02199",
                    "DOI": "10.1109/ICCV48922.2021.00098",
                    "CorpusId": 237420694
                },
                "corpusId": 237420694,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/7a4c901e00fef01d66efb125bf0e2fdd773d8bc6",
                "title": "Parsing Table Structures in the Wild",
                "abstract": "This paper tackles the problem of table structure parsing (TSP) from images in the wild. In contrast to existing studies that mainly focus on parsing well-aligned tabular images with simple layouts from scanned PDF documents, we aim to establish a practical table structure parsing system for real-world scenarios where tabular input images are taken or scanned with severe deformation, bending or occlusions. For designing such a system, we propose an approach named Cycle-CenterNet on the top of CenterNet with a novel cycle-pairing module to simultaneously detect and group tabular cells into structured tables. In the cycle-pairing module, a new pairing loss function is proposed for the network training. Alongside with our Cycle-CenterNet, we also present a large-scale dataset, named Wired Table in the Wild (WTW), which includes well-annotated structure parsing of multiple style tables in several scenes like photo, scanning files, web pages, etc.. In experiments, we demonstrate that our Cycle-CenterNet consistently achieves the best accuracy of table structure parsing on the new WTW dataset by 24.6% absolute improvement evaluated by the TEDS metric. A more comprehensive experimental analysis also validates the advantages of our proposed methods for the TSP task.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "143799988",
                        "name": "Rujiao Long"
                    },
                    {
                        "authorId": "2119293226",
                        "name": "Wen Wang"
                    },
                    {
                        "authorId": "2685089",
                        "name": "Nan Xue"
                    },
                    {
                        "authorId": "2112256",
                        "name": "Feiyu Gao"
                    },
                    {
                        "authorId": "2109432908",
                        "name": "Zhibo Yang"
                    },
                    {
                        "authorId": "153709848",
                        "name": "Yongpan Wang"
                    },
                    {
                        "authorId": "39943835",
                        "name": "Gui-Song Xia"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "a0a97c129f1c8339b9fb4fd768cf9f52e64b2b0a",
                "externalIds": {
                    "ArXiv": "2107.05214",
                    "DBLP": "journals/corr/abs-2107-05214",
                    "DOI": "10.1016/j.patcog.2022.108565",
                    "CorpusId": 235795015
                },
                "corpusId": 235795015,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a0a97c129f1c8339b9fb4fd768cf9f52e64b2b0a",
                "title": "Split, embed and merge: An accurate table structure recognizer",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2128660562",
                        "name": "Zhenrong Zhang"
                    },
                    {
                        "authorId": "39557762",
                        "name": "Jianshu Zhang"
                    },
                    {
                        "authorId": "2149030934",
                        "name": "Jun Du"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "ea25282d27368d3d04db91b165b5003d63e335d6",
                "externalIds": {
                    "DBLP": "conf/icdar/QiaoLCZPNRT021",
                    "ArXiv": "2105.06224",
                    "DOI": "10.1007/978-3-030-86549-8_7",
                    "CorpusId": 234482682
                },
                "corpusId": 234482682,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/ea25282d27368d3d04db91b165b5003d63e335d6",
                "title": "LGPMA: Complicated Table Structure Recognition with Local and Global Pyramid Mask Alignment",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2065512194",
                        "name": "Liang Qiao"
                    },
                    {
                        "authorId": "2109614687",
                        "name": "Zaisheng Li"
                    },
                    {
                        "authorId": "2398015",
                        "name": "Zhanzhan Cheng"
                    },
                    {
                        "authorId": "2151333065",
                        "name": "Peng Zhang"
                    },
                    {
                        "authorId": "3290437",
                        "name": "Shiliang Pu"
                    },
                    {
                        "authorId": "1490934795",
                        "name": "Yi Niu"
                    },
                    {
                        "authorId": "144850642",
                        "name": "Wenqi Ren"
                    },
                    {
                        "authorId": "51151126",
                        "name": "Wenming Tan"
                    },
                    {
                        "authorId": "144894837",
                        "name": "Fei Wu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "\u2026for tabular data, as corrupt cell detection is actually a fundamental task in table structure decomposition pipelines such as (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicted row/column separators or cell boundaries can lead to corrupted cell text.",
                "\u2026of corrupt cell detection, which again is practically useful as a postprocessing step after table structure decomposition (Tensmeyer et al., 2019; Raja et al., 2020) because mistakes in predicting row/column/cell boundaries (sometimes compounded by OCR errors) can lead to inaccurate extraction.",
                "While this objective was originally motivated as enabling more efficient training compared to BERT\u2019s masked language modeling objective, it is especially suited for tabular data, as corrupt cell detection is actually a fundamental task in table structure decomposition pipelines such as (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicted row/column separators or cell boundaries can lead to corrupted cell text.",
                "We emphasize that this pretraining objective is a fundamental task in table structure decomposition pipelines (Nishida et al., 2017; Tensmeyer et al., 2019; Raja et al., 2020), in which incorrectly predicting row/column separators or cell boundaries leads to corrupted cell text.",
                "We first examine how TaBERT performs on TABBIE\u2019s pretraining task of corrupt cell detection, which again is practically useful as a postprocessing step after table structure decomposition (Tensmeyer et al., 2019; Raja et al., 2020) because mistakes in predicting row/column/cell boundaries (sometimes compounded by OCR errors) can lead to inaccurate extraction."
            ],
            "citingPaper": {
                "paperId": "386bfd0e411dee4f512a8737c55dd84846981182",
                "externalIds": {
                    "DBLP": "conf/naacl/IidaTMI21",
                    "ACL": "2021.naacl-main.270",
                    "ArXiv": "2105.02584",
                    "MAG": "3158303960",
                    "DOI": "10.18653/V1/2021.NAACL-MAIN.270",
                    "CorpusId": 233864627
                },
                "corpusId": 233864627,
                "publicationVenue": {
                    "id": "01103732-3808-4930-b8e4-7e9e68d5c68d",
                    "name": "North American Chapter of the Association for Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "North Am Chapter Assoc Comput Linguistics",
                        "NAACL"
                    ],
                    "url": "https://www.aclweb.org/portal/naacl"
                },
                "url": "https://www.semanticscholar.org/paper/386bfd0e411dee4f512a8737c55dd84846981182",
                "title": "TABBIE: Pretrained Representations of Tabular Data",
                "abstract": "Existing work on tabular representation-learning jointly models tables and associated text using self-supervised objective functions derived from pretrained language models such as BERT. While this joint pretraining improves tasks involving paired tables and text (e.g., answering questions about tables), we show that it underperforms on tasks that operate over tables without any associated text (e.g., populating missing cells). We devise a simple pretraining objective (corrupt cell detection) that learns exclusively from tabular data and reaches the state-of-the-art on a suite of table-based prediction tasks. Unlike competing approaches, our model (TABBIE) provides embeddings of all table substructures (cells, rows, and columns), and it also requires far less compute to train. A qualitative analysis of our model\u2019s learned cell, column, and row representations shows that it understands complex table semantics and numerical trends.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "49093685",
                        "name": "H. Iida"
                    },
                    {
                        "authorId": "2064894364",
                        "name": "Dung Ngoc Thai"
                    },
                    {
                        "authorId": "1977256",
                        "name": "Varun Manjunatha"
                    },
                    {
                        "authorId": "2136562",
                        "name": "Mohit Iyyer"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "works (trained on ImageNet [20] or COCO [43]) on the problem of table detection and table structure recognition in document images [44]\u2013[53].",
                "[53] introduced a table structure recognition method that directly regresses the cellular boundaries."
            ],
            "citingPaper": {
                "paperId": "bc8863440e26e48866a64f63438051d24880b793",
                "externalIds": {
                    "DBLP": "journals/access/HashmiLSAAA21",
                    "ArXiv": "2104.14272",
                    "DOI": "10.1109/ACCESS.2021.3087865",
                    "CorpusId": 233444247
                },
                "corpusId": 233444247,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/bc8863440e26e48866a64f63438051d24880b793",
                "title": "Current Status and Performance Analysis of Table Recognition in Document Images With Deep Neural Networks",
                "abstract": "The first phase of table recognition is to detect the tabular area in a document. Subsequently, the tabular structures are recognized in the second phase in order to extract information from the respective cells. Table detection and structural recognition are pivotal problems in the domain of table understanding. However, table analysis is a perplexing task due to the colossal amount of diversity and asymmetry in tables. Therefore, it is an active area of research in document image analysis. Recent advances in the computing capabilities of graphical processing units have enabled the deep neural networks to outperform traditional state-of-the-art machine learning methods. Table understanding has substantially benefited from the recent breakthroughs in deep neural networks. However, there has not been a consolidated description of the deep learning methods for table detection and table structure recognition. This review paper provides a thorough analysis of the modern methodologies that utilize deep neural networks. Moreover, it presents a comprehensive understanding of the current state-of-the-art and related challenges of table understanding in document images. The leading datasets and their intricacies have been elaborated along with the quantitative results. Furthermore, a brief overview is given regarding the promising directions that can further improve table analysis in document images.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1403379889",
                        "name": "K. Hashmi"
                    },
                    {
                        "authorId": "1743758",
                        "name": "M. Liwicki"
                    },
                    {
                        "authorId": "143749919",
                        "name": "D. Stricker"
                    },
                    {
                        "authorId": "2206035070",
                        "name": "Muhammad Adnan Afzal"
                    },
                    {
                        "authorId": "2206035072",
                        "name": "Muhammad Ahtsham Afzal"
                    },
                    {
                        "authorId": "145181206",
                        "name": "Muhammad Zeshan Afzal"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "6c411f52c151fe537ee76c310f45f0dd3da88e92",
                "externalIds": {
                    "DBLP": "series/sbcs/Bhowmik23",
                    "DOI": "10.1007/978-981-99-4277-0",
                    "CorpusId": 260337124
                },
                "corpusId": 260337124,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/6c411f52c151fe537ee76c310f45f0dd3da88e92",
                "title": "Document Layout Analysis",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3272848",
                        "name": "Showmik Bhowmik"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "The random splits are performed ten rounds for computing averaged performance, which is similar to TabStruct-Net [14].",
                "Compared with TabStructNet [14], NCGM can achieve better performance with less parameters and similar computational budgets.",
                "In particular, note that TabStruct-Net [14] and FLAG-Net [10] are only tested for structure recognition, so we do not count the parameters and operations of cell detection for a fair comparison."
            ],
            "citingPaper": {
                "paperId": "20156b441f90f8238181315b37dbccf5f5493882",
                "externalIds": {
                    "CorpusId": 250563732
                },
                "corpusId": 250563732,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/20156b441f90f8238181315b37dbccf5f5493882",
                "title": "Neural Collaborative Graph Machines for Table Structure Recognition - Supplementary Materials",
                "abstract": "Geometry embedding. We derive the geometry feature of each text segment bounding box as ( x W , y H , w W , h H )\u22a4 , where W and H are the width and height of the table image. (x, y) represents the center point of the box while height h and width w correspond to its short side and long side respectively. Then a d-dimension Fully-Connected (FC) layer is applied on the above vectors to obtain the geometry embeddings FG = {g1,g2, ...,gN} \u2208 RN\u00d7d.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2143856572",
                        "name": "Hao Liu"
                    },
                    {
                        "authorId": "2153898418",
                        "name": "Xin Li"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Bottom-up methods [5,26,27,40] first detect cells or text segments using detection models or OCR engines, then analyze the relations between neighbouring cells using GNN or LSTM.",
                "TabStruct-Net [27] extract cell regions in object detection manner and they can only predict rectangular cell bounding boxes."
            ],
            "citingPaper": {
                "paperId": "24dd39035349c38d0bff17bbe5203cfcfd0ad79a",
                "externalIds": {
                    "DBLP": "conf/icdar/LiYZL21",
                    "DOI": "10.1007/978-3-030-86549-8_6",
                    "CorpusId": 237458405
                },
                "corpusId": 237458405,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/24dd39035349c38d0bff17bbe5203cfcfd0ad79a",
                "title": "Adaptive Scaling for Archival Table Structure Recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118890804",
                        "name": "Xiaohe Li"
                    },
                    {
                        "authorId": "145820427",
                        "name": "Fei Yin"
                    },
                    {
                        "authorId": "2870877",
                        "name": "Xu-Yao Zhang"
                    },
                    {
                        "authorId": "1689269",
                        "name": "Cheng-Lin Liu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "a32304c9b2a0fd13bf744ba812c33624bb0553ea",
                "externalIds": {
                    "DBLP": "conf/icdar/Ichikawa21",
                    "DOI": "10.1007/978-3-030-86331-9_41",
                    "CorpusId": 237458330
                },
                "corpusId": 237458330,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/a32304c9b2a0fd13bf744ba812c33624bb0553ea",
                "title": "Image-Based Relation Classification Approach for Table Structure Recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "47148099",
                        "name": "Koji Ichikawa"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "aa2ccd8ad23e8388ad0e7c8eab5f12b529d29844",
                "externalIds": {
                    "DBLP": "conf/icdar/Li0ZPHDTG21",
                    "DOI": "10.1007/978-3-030-86331-9_35",
                    "CorpusId": 237458541
                },
                "corpusId": 237458541,
                "publicationVenue": {
                    "id": "991e8cbf-4a4a-4ac4-a273-63dd7a35c364",
                    "name": "IEEE International Conference on Document Analysis and Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Doc Anal Recognit",
                        "International Conference on Document Analysis and Recognition",
                        "Int Conf Doc Anal Recognit",
                        "ICDAR"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1327"
                },
                "url": "https://www.semanticscholar.org/paper/aa2ccd8ad23e8388ad0e7c8eab5f12b529d29844",
                "title": "Rethinking Table Structure Recognition Using Sequence Labeling Methods",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2110470261",
                        "name": "Yibo Li"
                    },
                    {
                        "authorId": "49866988",
                        "name": "Yilun Huang"
                    },
                    {
                        "authorId": "2133160525",
                        "name": "Ziyi Zhu"
                    },
                    {
                        "authorId": "3002363",
                        "name": "Lemeng Pan"
                    },
                    {
                        "authorId": "145769099",
                        "name": "Yongshuai Huang"
                    },
                    {
                        "authorId": "2088876699",
                        "name": "Lin Du"
                    },
                    {
                        "authorId": "143830636",
                        "name": "Zhi Tang"
                    },
                    {
                        "authorId": "1777642",
                        "name": "Liangcai Gao"
                    }
                ]
            }
        }
    ]
}