{
    "offset": 0,
    "data": [
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "99c5b4f38a2d92083141c8efccae9da580148aca",
                "externalIds": {
                    "DBLP": "conf/eScience/VitaMSCRLC23",
                    "DOI": "10.1109/e-Science58273.2023.10254866",
                    "CorpusId": 262964535
                },
                "corpusId": 262964535,
                "publicationVenue": {
                    "id": "34342fcb-3fe0-45c6-a017-6e65b73d030f",
                    "name": "IEEE International Conference on e-Science",
                    "type": "conference",
                    "alternate_names": [
                        "e-Science",
                        "Int Conf e-science",
                        "IEEE Int Conf e-science",
                        "E-Science",
                        "International Conference on e-Science"
                    ],
                    "url": "https://escience-conference.org/"
                },
                "url": "https://www.semanticscholar.org/paper/99c5b4f38a2d92083141c8efccae9da580148aca",
                "title": "Citizen Science for the Sea with Information Technologies: An Open Platform for Gathering Marine Data and Marine Litter Detection from Leisure Boat Instruments",
                "abstract": "Data crowdsourcing is an increasingly pervasive and lifestyle-changing technology due to the flywheel effect that results from the interaction between the Internet of Things and Cloud Computing. This paper presents the Citizen Science for the Sea with Information Technologies (C4Sea-IT) framework. It is an open platform for gathering marine data from leisure boat instruments. C4Sea-IT aims to provide a coastal marine data gathering, moving, processing, exchange, and sharing platform using the existing navigation instruments and sensors for today's leisure and professional vessels. In this work, a use case for the detection and tracking of marine litter is shown. The final goal is weather/ocean forecasts argumentation with Artificial Intelligence prediction models trained with crowdsourced data.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2192208226",
                        "name": "Ciro Giuseppe de Vita"
                    },
                    {
                        "authorId": "50661168",
                        "name": "Gennaro Mellone"
                    },
                    {
                        "authorId": "2233718045",
                        "name": "D. D. Sanchez-Gallegos"
                    },
                    {
                        "authorId": "2247837141",
                        "name": "Giuseppe Coviello"
                    },
                    {
                        "authorId": "2055734700",
                        "name": "Diego Romano"
                    },
                    {
                        "authorId": "1924810",
                        "name": "M. Lapegna"
                    },
                    {
                        "authorId": "2247837168",
                        "name": "Angelo Ciaramella"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "8c942faa8b9a0c2cb470215be35907300d324732",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-11369",
                    "ArXiv": "2308.11369",
                    "DOI": "10.48550/arXiv.2308.11369",
                    "CorpusId": 261064942
                },
                "corpusId": 261064942,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8c942faa8b9a0c2cb470215be35907300d324732",
                "title": "Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization",
                "abstract": "Object-centric representations using slots have shown the advances towards efficient, flexible and interpretable abstraction from low-level perceptual features in a compositional scene. Current approaches randomize the initial state of slots followed by an iterative refinement. As we show in this paper, the random slot initialization significantly affects the accuracy of the final slot prediction. Moreover, current approaches require a predetermined number of slots from prior knowledge of the data, which limits the applicability in the real world. In our work, we initialize the slot representations with clustering algorithms conditioned on the perceptual input features. This requires an additional layer in the architecture to initialize the slots given the identified clusters. We design permutation invariant and permutation equivariant versions of this layer to enable the exchangeable slot representations after clustering. Additionally, we employ mean-shift clustering to automatically identify the number of slots for a given scene. We evaluate our method on object discovery and novel view synthesis tasks with various datasets. The results show that our method outperforms prior works consistently, especially for complex scenes.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2068203954",
                        "name": "Ni Gao"
                    },
                    {
                        "authorId": "2232959312",
                        "name": "Bernard Hohmann"
                    },
                    {
                        "authorId": "26599977",
                        "name": "G. Neumann"
                    }
                ]
            }
        },
        {
            "contexts": [
                "On the other hand, intrinsic XAImethods such as [56] uses additional loss and attention modules during training and utilize this module to compute saliency maps."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "8e6926caddf71ba49a225bab0a0e725db7014aff",
                "externalIds": {
                    "DBLP": "journals/mva/SahaR23",
                    "DOI": "10.1007/s00138-023-01420-3",
                    "CorpusId": 259766880
                },
                "corpusId": 259766880,
                "publicationVenue": {
                    "id": "400d5e36-be35-4097-898f-753f4493156e",
                    "name": "Machine Vision and Applications",
                    "type": "journal",
                    "alternate_names": [
                        "Journal of Machine Vision and Applications",
                        "Mach Vis Appl",
                        "J Mach Vis Appl"
                    ],
                    "issn": "0932-8092",
                    "url": "https://www.springer.com/computer/image+processing/journal/138",
                    "alternate_urls": [
                        "https://link.springer.com/journal/138",
                        "https://www.springer.com/computer/image+processing/journal/138?changeHeader",
                        "http://www.springer.com/computer/image+processing/journal/138"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8e6926caddf71ba49a225bab0a0e725db7014aff",
                "title": "Online continual learning with saliency-guided experience replay using tiny episodic memory",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "145638130",
                        "name": "Gobinda Saha"
                    },
                    {
                        "authorId": "2091913080",
                        "name": "Kaushik Roy"
                    }
                ]
            }
        },
        {
            "contexts": [
                "According to [12], we update the slot T = 3 times, D is the dimension after the normalization operation, calculate the similarity of each vector by dot product, and then normalize it with sigmoid."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "b557de3f76389d70bf65d2f42feb89201450ac2e",
                "externalIds": {
                    "DBLP": "conf/icmcs/LiLLCDHH23",
                    "DOI": "10.1109/ICME55011.2023.00051",
                    "CorpusId": 261127119
                },
                "corpusId": 261127119,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b557de3f76389d70bf65d2f42feb89201450ac2e",
                "title": "A Visually Interpretable Convolutional-Transformer Model for Assessing Depression from Facial Images",
                "abstract": "The accuracy and availability are the most critical and challenging problems for major depressive disorder (MDD) diagnosis. Limited receptive field and inaccurate visual interpretation always weaken the clinical application of deep learning-based depression recognition model. Thus, we propose a visually interpretable depression monitoring model termed Transformer and Convolutional with slot-attention (TC-slot) to assess depression from facial images. Specifically, this approach stands upon the intersection of convolution and transformer, combines self-attention mechanism and deep convolution, and uses a well-designed stem structure to explore the global and local relationships. Moreover, in TC-slot, a classifier built on slot-attention mechanism directly involved in the decision-making process further localizes salient regions of facial depression patterns and provides precise and meaningful explanations. The results indicate that the proposed approach effectively improves the classification and recognition performance compared with other state-of-the-art approaches, with guaranteed favorable visual interpretability, providing clinical insights into the assessment of the assessing depression.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2130455601",
                        "name": "Yutong Li"
                    },
                    {
                        "authorId": "2109128603",
                        "name": "Zhenyu Liu"
                    },
                    {
                        "authorId": "2155120370",
                        "name": "Gang Li"
                    },
                    {
                        "authorId": "122440014",
                        "name": "Q. Chen"
                    },
                    {
                        "authorId": "48619440",
                        "name": "Zhijie Ding"
                    },
                    {
                        "authorId": "1718919",
                        "name": "Xiping Hu"
                    },
                    {
                        "authorId": "144010725",
                        "name": "B. Hu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Some other scholars have proposed to use additional modules to explain the working mechanisms inside the model [12], [13], such as the attention mechanism, but the explanatory results obtained in this way are one-sided and it is difficult to explain specifically the area of attention of the network for a specific target."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "b413c45a7e0bc2169ec83142e3af7a3467785538",
                "externalIds": {
                    "DBLP": "conf/ijcnn/BaoCWP23",
                    "DOI": "10.1109/IJCNN54540.2023.10191952",
                    "CorpusId": 260387188
                },
                "corpusId": 260387188,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/b413c45a7e0bc2169ec83142e3af7a3467785538",
                "title": "Causal Visual Feature Extraction for Image Classification Interpretation",
                "abstract": "Convolutional neural networks have achieved great success in the field of image recognition, however, their inherent black-box properties hinder their application in highly sensitive fields such as healthcare and autonomous driving. Therefore, interpretable artificial intelligence (XAI) has become a hot topic of academic research, which aims at exploring the working mechanism inside deep convolutional neural networks. Causality is an important means to explore the working mechanism of neural networks. For image classification, the image classification results depend on the causal features or background features of the input image. Grad-CAM is a popular interpretation method to visualize these features, and its visualization results in a deep integration of causal and context features. In this paper, we propose a background category-based feature integration method to estimate the context features, and then apply an ensemble theory approach to extract causal features from Grad-CAM. The experimental results show that our Grad-CAM-based extracted causal features not only have better causality in ResNet50, VGG16, and GoogleNet compared with Grad-CAM and Grad-CAM++, but also are similar to the visualization results of Grad-CAM ++ in terms of target object localization of visualization results. In addition, we verify that our method is applicable not only to high category fine-grained datasets but also to low fine-grained datasets through category fine-grained experiments.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2060106869",
                        "name": "Chen Bao"
                    },
                    {
                        "authorId": "2157902732",
                        "name": "Dehua Chen"
                    },
                    {
                        "authorId": "2118663332",
                        "name": "Mei Wang"
                    },
                    {
                        "authorId": "1953349",
                        "name": "Qiao Pan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[49] Liangzhi Li, Bowen Wang, Manisha Verma, Yuta Nakashima, Ryo Kawasaki, and Hajime Nagahara.",
                "There are several existing examples on leveraging slotbased methods in explainable models to extract semantic concepts [49, 84]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "76378e1d3694836503b1fd377c882e43b92f85ec",
                "externalIds": {
                    "ArXiv": "2305.15775",
                    "CorpusId": 261682570
                },
                "corpusId": 261682570,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/76378e1d3694836503b1fd377c882e43b92f85ec",
                "title": "Concept-Centric Transformers: Enhancing Model Interpretability through Object-Centric Concept Learning within a Shared Global Workspace",
                "abstract": "To explain\"black-box\"properties of AI models, many approaches, such as post hoc and intrinsically interpretable models, have been proposed to provide plausible explanations that identify human-understandable features/concepts that a trained model uses to make predictions, and attention mechanisms have been widely used to aid in model interpretability by visualizing that information. However, the problem of configuring an interpretable model that effectively communicates and coordinates among computational modules has received less attention. A recently proposed shared global workspace theory demonstrated that networks of distributed modules can benefit from sharing information with a bandwidth-limited working memory because the communication constraints encourage specialization, compositionality, and synchronization among the modules. Inspired by this, we consider how such shared working memories can be realized to build intrinsically interpretable models with better interpretability and performance. Toward this end, we propose Concept-Centric Transformers, a simple yet effective configuration of the shared global workspace for interpretability consisting of: i) an object-centric-based architecture for extracting semantic concepts from input features, ii) a cross-attention mechanism between the learned concept and input embeddings, and iii) standard classification and additional explanation losses to allow human analysts to directly assess an explanation for the model's classification reasoning. We test our approach against other existing concept-based methods on classification tasks for various datasets, including CIFAR100 (super-classes), CUB-200-2011 (bird species), and ImageNet, and we show that our model achieves better classification accuracy than all selected methods across all problems but also generates more consistent concept-based explanations of classification output.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "73688108",
                        "name": "Jinyung Hong"
                    },
                    {
                        "authorId": "2239065849",
                        "name": "Keun Hee Park"
                    },
                    {
                        "authorId": "48184163",
                        "name": "Theodore P. Pavlic"
                    }
                ]
            }
        },
        {
            "contexts": [
                "They can be used to explain predictions in diverse tasks, like image recognition (Li et al., 2021), authorship verification (Boenninghoff et al."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "737754c27be2ddb3c9404fbea492e47a0bfe53fb",
                "externalIds": {
                    "PubMedCentral": "10561255",
                    "DBLP": "journals/corr/abs-2304-14986",
                    "ArXiv": "2304.14986",
                    "DOI": "10.3389/frai.2023.1220476",
                    "CorpusId": 258418310
                },
                "corpusId": 258418310,
                "publicationVenue": {
                    "id": "6a8c0041-d0b7-4e32-b52c-33adef005c7e",
                    "name": "Frontiers in Artificial Intelligence",
                    "alternate_names": [
                        "Front Artif Intell"
                    ],
                    "issn": "2624-8212",
                    "url": "https://www.frontiersin.org/journals/artificial-intelligence#"
                },
                "url": "https://www.semanticscholar.org/paper/737754c27be2ddb3c9404fbea492e47a0bfe53fb",
                "title": "Interpreting vision and language generative models with semantic visual priors",
                "abstract": "When applied to Image-to-text models, explainability methods have two challenges. First, they often provide token-by-token explanations namely, they compute a visual explanation for each token of the generated sequence. This makes explanations expensive to compute and unable to comprehensively explain the model's output. Second, for models with visual inputs, explainability methods such as SHAP typically consider superpixels as features. Since superpixels do not correspond to semantically meaningful regions of an image, this makes explanations harder to interpret. We develop a framework based on SHAP, that allows for generating comprehensive, meaningful explanations leveraging the meaning representation of the output sequence as a whole. Moreover, by exploiting semantic priors in the visual backbone, we extract an arbitrary number of features that allows the efficient computation of Shapley values on large-scale models, generating at the same time highly meaningful visual explanations. We demonstrate that our method generates semantically more expressive explanations than traditional methods at a lower compute cost and that it can be generalized to a large family of vision-language models.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2127130978",
                        "name": "Michele Cafagna"
                    },
                    {
                        "authorId": "1388702112",
                        "name": "L. Rojas-Barahona"
                    },
                    {
                        "authorId": "10708829",
                        "name": "Kees van Deemter"
                    },
                    {
                        "authorId": "145464131",
                        "name": "Albert Gatt"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Concept extractor uses slot attention [26, 27]-based mechanism to discover visual concepts in D.",
                "We adopt a slot attention-based mechanism [26, 27] to spot the region in which each concept is found."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "4833b15d617ee2a44bfe326bb397e7424a0a8e21",
                "externalIds": {
                    "ArXiv": "2304.10131",
                    "DBLP": "journals/corr/abs-2304-10131",
                    "DOI": "10.48550/arXiv.2304.10131",
                    "CorpusId": 258236219
                },
                "corpusId": 258236219,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4833b15d617ee2a44bfe326bb397e7424a0a8e21",
                "title": "Learning Bottleneck Concepts in Image Classification",
                "abstract": "Interpreting and explaining the behavior of deep neural networks is critical for many tasks. Explainable AI provides a way to address this challenge, mostly by providing per-pixel relevance to the decision. Yet, interpreting such explanations may require expert knowledge. Some recent attempts toward interpretability adopt a concept-based framework, giving a higher-level relationship between some concepts and model decisions. This paper proposes Bottleneck Concept Learner (BotCL), which represents an image solely by the presence/absence of concepts learned through training over the target task without explicit supervision over the concepts. It uses self-supervision and tailored regularizers so that learned concepts can be human-understandable. Using some image classification tasks as our testbed, we demonstrate BotCL's potential to rebuild neural networks for better interpretability11Code is avaliable at https://github.com/wbw520/BotCL and a simple demo is available at https://botcl.liangzhili.com/.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2153213890",
                        "name": "Bowen Wang"
                    },
                    {
                        "authorId": "47681301",
                        "name": "Liangzhi Li"
                    },
                    {
                        "authorId": "2210102679",
                        "name": "Yuta Nakashima"
                    },
                    {
                        "authorId": "2124415764",
                        "name": "Hajime Nagahara"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "56ac99469b08321d60e3f3d8ed904cf20a27d3bd",
                "externalIds": {
                    "DBLP": "journals/cbm/ZhanSL23",
                    "DOI": "10.1016/j.compbiomed.2023.106932",
                    "CorpusId": 258154323,
                    "PubMed": "37230013"
                },
                "corpusId": 258154323,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/56ac99469b08321d60e3f3d8ed904cf20a27d3bd",
                "title": "FSA-Net: Rethinking the attention mechanisms in medical image segmentation from releasing global suppressed information",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1641734781",
                        "name": "Bangcheng Zhan"
                    },
                    {
                        "authorId": "123803451",
                        "name": "E. Song"
                    },
                    {
                        "authorId": "2118902798",
                        "name": "Hong Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In this study, we use a slot attention-based classifier SCOUTER (Li et al., 2021) to classify natural earthquakes and blasts.",
                "In this study, we combine an advanced classifier SCOUTER to achieve an automatic and effective discrimination between natural earthquakes and blasts.",
                "We adopt SCOUTER (Li et al., 2021), a classifier based\non slot attention, which involves the explanation to each category in the final confidence.",
                "The SCOUTER based the pre-trained model is trained on the training set for 50 epochs and the performance results are computed on the testing set with the trained model after the last epoch.",
                "Discrimination of seismic and non-seismic signal using SCOUTER.",
                "KEYWORDS quarry blasts, natural earthquakes, SCOUTER, seismology ACM Reference Format: Kang Wang, Ji Zhang, and Jie Zhang."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "660bcaf59cb77dd16c1c3846af06171b6a0709e5",
                "externalIds": {
                    "DBLP": "conf/cacml/WangZZ23",
                    "DOI": "10.1145/3590003.3590045",
                    "CorpusId": 258961561
                },
                "corpusId": 258961561,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/660bcaf59cb77dd16c1c3846af06171b6a0709e5",
                "title": "Discrimination of seismic and non-seismic signal using SCOUTER",
                "abstract": "Abstract\u2014 For areas with potential occurrence of blasting events, it is essential to distinguish them from natural earthquakes. An efficient processing method is needed to save manpower, especially under the current large amount of data records by seismic stations. We apply a SCOUTER algorithm to distinguish between the two types of events. The recognition precision of the trained model for natural earthquakes and blasts can reach 95% and 92.8%, respectively, and the recall can reach 93.4% and 94.6%, respectively. The testing results of data with different epicentral distances and SNR show that our method is stable, independent on regional waveform characteristics and insensitive to data of different SNR. The explanations for each classification at the final confidence also give us a profound enlightenment.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2188153012",
                        "name": "Kang Wang"
                    },
                    {
                        "authorId": "2116922952",
                        "name": "Ji Zhang"
                    },
                    {
                        "authorId": "40539618",
                        "name": "J. Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[11] propose a slot attentionbased classifier for transparent and accurate classification, offering intuitive interpretation and positive or negative explanations for each category controlled by a tailored loss.",
                "The proposed guided slot attention is conceptually similar to previous methods as it is inspired by previous methods [11, 14, 38]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "f37057c3208645a49783e165a6dd4130419363f0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-08314",
                    "ArXiv": "2303.08314",
                    "DOI": "10.48550/arXiv.2303.08314",
                    "CorpusId": 257532769
                },
                "corpusId": 257532769,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f37057c3208645a49783e165a6dd4130419363f0",
                "title": "Guided Slot Attention for Unsupervised Video Object Segmentation",
                "abstract": "Unsupervised video object segmentation aims to segment the most prominent object in a video sequence. However, the existence of complex backgrounds and multiple foreground objects make this task challenging. To address this issue, we propose a guided slot attention network to reinforce spatial structural information and obtain better foreground--background separation. The foreground and background slots, which are initialized with query guidance, are iteratively refined based on interactions with template information. Furthermore, to improve slot--template interaction and effectively fuse global and local features in the target and reference frames, K-nearest neighbors filtering and a feature aggregation transformer are introduced. The proposed model achieves state-of-the-art performance on two popular datasets. Additionally, we demonstrate the robustness of the proposed model in challenging scenes through various comparative experiments.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2109503396",
                        "name": "Minhyeok Lee"
                    },
                    {
                        "authorId": "9613506",
                        "name": "Suhwan Cho"
                    },
                    {
                        "authorId": "1720796700",
                        "name": "Dogyoon Lee"
                    },
                    {
                        "authorId": "2109124052",
                        "name": "Chaewon Park"
                    },
                    {
                        "authorId": "2118599108",
                        "name": "Jungho Lee"
                    },
                    {
                        "authorId": "39847092",
                        "name": "Sangyoun Lee"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "8b9b9db68ed03d1cff19acdb98420d5ece1d30e1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2301-13445",
                    "ArXiv": "2301.13445",
                    "DOI": "10.48550/arXiv.2301.13445",
                    "CorpusId": 256416377
                },
                "corpusId": 256416377,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8b9b9db68ed03d1cff19acdb98420d5ece1d30e1",
                "title": "A Survey of Explainable AI in Deep Visual Modeling: Methods and Metrics",
                "abstract": "Deep visual models have widespread applications in high-stake domains. Hence, their black-box nature is currently attracting a large interest of the research community. We present the first survey in Explainable AI that focuses on the methods and metrics for interpreting deep visual models. Covering the landmark contributions along the state-of-the-art, we not only provide a taxonomic organization of the existing techniques, but also excavate a range of evaluation metrics and collate them as measures of different properties of model explanations. Along the insightful discussion on the current trends, we also discuss the challenges and future avenues for this research direction.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47398812",
                        "name": "Naveed Akhtar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The resulting 192 object-centric inductive bias and the relative simplicity have allowed for wider adoption and success 193 of slot attention over iDSPN [13, 11, 14, 18], which makes our improvements to SA meaningful."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c15da5309b72a2c6966e2ddb65520a62458c98b3",
                "externalIds": {
                    "DBLP": "conf/icml/ZhangZLBS23",
                    "ArXiv": "2301.13197",
                    "DOI": "10.48550/arXiv.2301.13197",
                    "CorpusId": 253181041
                },
                "corpusId": 253181041,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/c15da5309b72a2c6966e2ddb65520a62458c98b3",
                "title": "Unlocking Slot Attention by Changing Optimal Transport Costs",
                "abstract": "Slot attention is a powerful method for object-centric modeling in images and videos. However, its set-equivariance limits its ability to handle videos with a dynamic number of objects because it cannot break ties. To overcome this limitation, we first establish a connection between slot attention and optimal transport. Based on this new perspective we propose MESH (Minimize Entropy of Sinkhorn): a cross-attention module that combines the tiebreaking properties of unregularized optimal transport with the speed of regularized optimal transport. We evaluate slot attention using MESH on multiple object-centric learning benchmarks and find significant improvements over slot attention in every setting.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "36124320",
                        "name": "Yan Zhang"
                    },
                    {
                        "authorId": "2127383427",
                        "name": "David W. Zhang"
                    },
                    {
                        "authorId": "1388317459",
                        "name": "S. Lacoste-Julien"
                    },
                    {
                        "authorId": "1909303",
                        "name": "G. Burghouts"
                    },
                    {
                        "authorId": "145404204",
                        "name": "Cees G. M. Snoek"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Different from the post-hoc method that provides explanations after the model training, the intrinsic paradigm [35,36]"
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "ee1e4dc529f2ea0798d5718f967d5a5fb74c7922",
                "externalIds": {
                    "DOI": "10.1080/00365521.2022.2163185",
                    "CorpusId": 255569306,
                    "PubMed": "36625026"
                },
                "corpusId": 255569306,
                "publicationVenue": {
                    "id": "66a9e0c4-d111-4ca4-8baa-a95a8a18e30c",
                    "name": "Scandinavian Journal of Gastroenterology",
                    "type": "journal",
                    "alternate_names": [
                        "Scand J Gastroenterol"
                    ],
                    "issn": "0036-5521",
                    "url": "http://www.informahealthcare.com/gastro",
                    "alternate_urls": [
                        "https://www.tandfonline.com/loi/igas",
                        "http://www.metapress.com/link.asp?id=101949",
                        "http://informahealthcare.com/loi/gas"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ee1e4dc529f2ea0798d5718f967d5a5fb74c7922",
                "title": "Using deep learning and explainable artificial intelligence to assess the severity of gastroesophageal reflux disease according to the Los Angeles Classification System",
                "abstract": "Abstract Objectives Gastroesophageal reflux disease (GERD) is a complex disease with a high worldwide prevalence. The Los Angeles classification (LA-grade) system is meaningful for assessing the endoscopic severity of GERD. Deep learning (DL) methods have been widely used in the field of endoscopy. However, few DL-assisted researches have concentrated on the diagnosis of GERD. This study is the first to develop a five-category classification DL model based on the LA-grade using explainable artificial intelligence (XAI). Materials and methods A total of 2081 endoscopic images were used for the development of a DL model, and the classification accuracy of the models and endoscopists with different levels of experience was compared. Results Some mainstream DL models were utilized, of which DenseNet-121 outperformed. The area under the curve (AUC) of the DenseNet-121 was 0.968, and its classification accuracy (86.7%) was significantly higher than that of junior (71.5%) and experienced (77.4%) endoscopists. An XAI evaluation was also performed to explore the perception consistency between the DL model and endoscopists, which showed meaningful results for real-world applications. Conclusions The DL model showed a potential in improving the accuracy of endoscopists in LA-grading of GERD, and it has noticeable clinical application prospects and is worthy of further promotion.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2053288041",
                        "name": "Zhenyang Ge"
                    },
                    {
                        "authorId": "2153213890",
                        "name": "Bowen Wang"
                    },
                    {
                        "authorId": "2157705848",
                        "name": "Jiuyang Chang"
                    },
                    {
                        "authorId": "2180149194",
                        "name": "Ze-Kuan Yu"
                    },
                    {
                        "authorId": "2199905458",
                        "name": "Zhenyuan Zhou"
                    },
                    {
                        "authorId": "2199914548",
                        "name": "Jing Zhang"
                    },
                    {
                        "authorId": "102696788",
                        "name": "Zhi-Bing Duan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In addition, it is possible to generate adversarial masks [1,11] which solely rely on breaking the input features in order to reduce output confidence \u2013 which are easier to locate but do not necessarily explain the decisionmaking of visual recognition models.",
                "Later on, sanity check procedures have shown that most of the gradient-based explanation methods are independent of the model predictions and mainly work as edge detectors which greatly undermined their credibility [1,17].",
                "Next, we turn our attention to attribution maps (saliency maps), which is a very popular line of research in explanation but also controversial in that many of the algorithms have shown to be unreliable [1]."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "5f5f3c43383ccd346c7b76854277b37b633a26c0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-06872",
                    "ArXiv": "2212.06872",
                    "DOI": "10.48550/arXiv.2212.06872",
                    "CorpusId": 254636274
                },
                "corpusId": 254636274,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5f5f3c43383ccd346c7b76854277b37b633a26c0",
                "title": "Examining the Difference Among Transformers and CNNs with Explanation Methods",
                "abstract": "We propose a methodology that systematically applies deep explanation algorithms on a dataset-wide basis, to compare different types of visual recognition backbones, such as convolutional networks (CNNs), global attention networks, and local attention networks. Examination of both qualitative visualizations and quantitative statistics across the dataset helps us to gain intuitions that are not just anecdotal, but are supported by the statistics computed on the entire dataset. Specifically, we propose two methods. The first one, sub-explanation counting, systematically searches for minimally-sufficient explanations of all images and count the amount of sub-explanations for each network. The second one, called cross-testing, computes salient regions using one network and then evaluates the performance by only showing these regions as an image to other networks. Through a combination of qualitative insights and quantitative statistics, we illustrate that 1) there are significant differences between the salient features of CNNs and attention models; 2) the occlusion-robustness in local attention models and global attention models may come from different decision-making mechanisms.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51236240",
                        "name": "Ming-Xiu Jiang"
                    },
                    {
                        "authorId": "33353193",
                        "name": "S. Khorram"
                    },
                    {
                        "authorId": "66262000",
                        "name": "L. Fuxin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In addition, we adopt the method proposed in the literature [9] to visualize the results of all models.",
                "For the feature vectors Fc and Fr from Branch C and Branch R, they not only need to be sent to the classifier [9] to obtain the classification probability pc and pr, but also need to be fed into the auxiliary attention guidance module that guides the model\u2019s attention tendency (See Section III-D) to get Segmentation map p c and p seg r ."
            ],
            "isInfluential": false,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "3baf8635279b3935f90c64f59357fdf0f3517ecb",
                "externalIds": {
                    "DBLP": "conf/bibm/YaoTYLLWCW22",
                    "DOI": "10.1109/BIBM55620.2022.9995268",
                    "CorpusId": 255417726
                },
                "corpusId": 255417726,
                "publicationVenue": {
                    "id": "6363ebc9-706a-4203-b804-148cbf8810ce",
                    "name": "IEEE International Conference on Bioinformatics and Biomedicine",
                    "type": "conference",
                    "alternate_names": [
                        "Bioinform Biomed",
                        "BIBM",
                        "IEEE Int Conf Bioinform Biomed",
                        "Bioinformatics and Biomedicine"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=283"
                },
                "url": "https://www.semanticscholar.org/paper/3baf8635279b3935f90c64f59357fdf0f3517ecb",
                "title": "MBH-Net: Multi-branch Hybrid Network with Auxiliary Attention Guidance for Large Vessel Occlusion Detection",
                "abstract": "Acute ischemic stroke (AIS) caused by large vessel occlusion (LVO) has high disability and mortality. However, due to the individual differences of physiological structure and pathological changes between patients, it will be difficult to detect the occluded vessels, so as to delay the treatment timing. Therefore, it is of great significance to a ssist d octors to locate occluded vessels quickly and accurately in clinical practice. In this paper, we present a novel multi-branch hybrid network (MBH-Net) with auxiliary attention guidance to detect occluded vessels. The proposed network consists of three branches for universal representation learning, patient representation learning and classifier learning, respectively. Furthermore, we propose a semantic feature enhancement module to extract more robust semantic information. Particularly, we introduce an auxiliary attention guidance module to guide the attention tendency of MBH-Net, which can make the network give a more reasonable visual interpretation. Extensive experiments show that our MBH-Net can achieve satisfactory accuracy and give a reasonable visual interpretation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2131382130",
                        "name": "Rui Yao"
                    },
                    {
                        "authorId": "2142585244",
                        "name": "Duo Tan"
                    },
                    {
                        "authorId": "2152719477",
                        "name": "Ye Yang"
                    },
                    {
                        "authorId": "2165084836",
                        "name": "Yongmei Li"
                    },
                    {
                        "authorId": "2108357570",
                        "name": "Jiayang Liu"
                    },
                    {
                        "authorId": "2142503556",
                        "name": "Jiajing Wu"
                    },
                    {
                        "authorId": "2161825911",
                        "name": "Shanxiong Chen"
                    },
                    {
                        "authorId": "51226051",
                        "name": "Jingjie Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "c71b83fac93c1735f8e19e5a1205a71f860f59aa",
                "externalIds": {
                    "ArXiv": "2211.08249",
                    "DBLP": "journals/corr/abs-2211-08249",
                    "DOI": "10.1145/3623399",
                    "CorpusId": 253523507
                },
                "corpusId": 253523507,
                "publicationVenue": {
                    "id": "bb2eb372-4df2-4181-9988-71aecb1dcc5e",
                    "name": "ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP)",
                    "type": "journal",
                    "alternate_names": [
                        "ACM Trans Multimedia Comput Commun Appl (TOMCCAP",
                        "ACM Transactions on Multimedia Computing, Communications, and Applications",
                        "ACM Trans Multimedia Comput Commun Appl"
                    ],
                    "issn": "1551-6857",
                    "url": "http://www.acm.org/tomccap/",
                    "alternate_urls": [
                        "http://tomccap.acm.org/",
                        "http://tomm.acm.org/",
                        "http://portal.acm.org/tomccap/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c71b83fac93c1735f8e19e5a1205a71f860f59aa",
                "title": "Explaining Cross-Domain Recognition with Interpretable Deep Classifier",
                "abstract": "The recent advances in deep learning predominantly construct models in their internal representations, and it is opaque to explain the rationale behind and decisions to human users. Such explainability is especially essential for domain adaptation, whose challenges require developing more adaptive models across different domains. In this paper, we ask the question: how much each sample in source domain contributes to the network\u2019s prediction on the samples from target domain. To address this, we devise a novel Interpretable Deep Classifier (IDC) that learns the nearest source samples of a target sample as evidence upon which the classifier makes the decision. Technically, IDC maintains a differentiable memory bank for each category and the memory slot derives a form of key-value pair. The key records the features of discriminative source samples and the value stores the corresponding properties, e.g., representative scores of the features for describing the category. IDC computes the loss between the output of IDC and the labels of source samples to back-propagate to adjust the representative scores and update the memory banks. Extensive experiments on Office-Home and VisDA-2017 datasets demonstrate that our IDC leads to a more explainable model with almost no accuracy degradation and effectively calibrates classification for optimum reject options. More remarkably, when taking IDC as a prior interpreter, capitalizing on 0.1% source training data selected by IDC still yields superior results than that uses full training set on VisDA-2017 for unsupervised domain adaptation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108058646",
                        "name": "Yiheng Zhang"
                    },
                    {
                        "authorId": "145690248",
                        "name": "Ting Yao"
                    },
                    {
                        "authorId": "3430743",
                        "name": "Zhaofan Qiu"
                    },
                    {
                        "authorId": "2070183551",
                        "name": "Tao Mei"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Attentive models include attention modules into their structure, making the elements on which the model is focusing more evident [43, 89]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "2cecb1447ac78d5f85c08dd4ad745c9ff27f8122",
                "externalIds": {
                    "DBLP": "journals/apin/RosaCN23",
                    "DOI": "10.1007/s10489-022-03886-6",
                    "CorpusId": 251416914
                },
                "corpusId": 251416914,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2cecb1447ac78d5f85c08dd4ad745c9ff27f8122",
                "title": "A self-interpretable module for deep image classification on small data",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2180935785",
                        "name": "B. La Rosa"
                    },
                    {
                        "authorId": "2709822",
                        "name": "R. Capobianco"
                    },
                    {
                        "authorId": "144143750",
                        "name": "D. Nardi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The authors in [69] also employ an iterative attention mechanism to update the slots, where the number of iterations T=3 just like in capsule routing and vanilla slot attention.",
                "Indeed, the evidence for a certain category in SCOUTER can be thought of as its support in capsule networks, i.e. using an attention mechanism to find support in the image that directly correlates to a certain output category.",
                "The main difference between SCOUTER and vanilla slot attention is that the slots are now associated to single categories like in capsule networks.",
                "Figure from [70].\nthe explainability insights from SCOUTER are applicable to capsule networks.",
                "We can think of SCOUTER as a capsule network with restricted inductive biases and fewer parameters, thus\nFig.",
                "More recently, the authors in [69] proposed SCOUTER, a slot-attention based classifier for transparent, explainable and accurate classification (see Figure 26).",
                "26: Positive and negative explanations given by SCOUTER [69]: a variant of slot-attention with specialised slots that bind to class categories like in capsule networks."
            ],
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "0e18343fe7710064034457ba26e3792b4e94d9f3",
                "externalIds": {
                    "ArXiv": "2206.02664",
                    "DBLP": "journals/corr/abs-2206-02664",
                    "DOI": "10.48550/arXiv.2206.02664",
                    "CorpusId": 249394871
                },
                "corpusId": 249394871,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0e18343fe7710064034457ba26e3792b4e94d9f3",
                "title": "Learning with Capsules: A Survey",
                "abstract": "Capsule networks were proposed as an alternative approach to Convolutional Neural Networks (CNNs) for learning object-centric representations, which can be leveraged for improved generalization and sample complexity. Unlike CNNs, capsule networks are designed to explicitly model part-whole hierarchical relationships by using groups of neurons to encode visual entities, and learn the relationships between those entities. Promising early results achieved by capsule networks have motivated the deep learning community to continue trying to improve their performance and scalability across several application areas. However, a major hurdle for capsule network research has been the lack of a reliable point of reference for understanding their foundational ideas and motivations. The aim of this survey is to provide a comprehensive overview of the capsule network research landscape, which will serve as a valuable resource for the community going forward. To that end, we start with an introduction to the fundamental concepts and motivations behind capsule networks, such as equivariant inference in computer vision. We then cover the technical advances in the capsule routing mechanisms and the various formulations of capsule networks, e.g. generative and geometric. Additionally, we provide a detailed explanation of how capsule networks relate to the popular attention mechanism in Transformers, and highlight non-trivial conceptual similarities between them in the context of representation learning. Afterwards, we explore the extensive applications of capsule networks in computer vision, video and motion, graph representation learning, natural language processing, medical imaging and many others. To conclude, we provide an in-depth discussion regarding the main hurdles in capsule network research, and highlight promising research directions for future work.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47841458",
                        "name": "Fabio De Sousa Ribeiro"
                    },
                    {
                        "authorId": "2064921899",
                        "name": "Kevin Duarte"
                    },
                    {
                        "authorId": "2168256426",
                        "name": "Miles Everett"
                    },
                    {
                        "authorId": "2042765174",
                        "name": "G. Leontidis"
                    },
                    {
                        "authorId": "2111863589",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "developed an explainable classifier based on slot attentions [90].",
                "[90] proposed slot attention, an attention mechanism that learns the objects\u2019 representations in a scene."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "af04a53668817026de8a21c1160005d49d21351b",
                "externalIds": {
                    "ArXiv": "2204.07756",
                    "DBLP": "journals/corr/abs-2204-07756",
                    "DOI": "10.48550/arXiv.2204.07756",
                    "CorpusId": 248227935
                },
                "corpusId": 248227935,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/af04a53668817026de8a21c1160005d49d21351b",
                "title": "Visual Attention Methods in Deep Learning: An In-Depth Survey",
                "abstract": "Inspired by the human cognitive system, attention is a mechanism that imitates the human cognitive awareness about specific information, amplifying critical details to focus more on the essential aspects of data. Deep learning has employed attention to boost performance for many applications. Interestingly, the same attention design can suit processing different data modalities and can easily be incorporated into large networks. Furthermore, multiple complementary attention mechanisms can be incorporated in one network. Hence, attention techniques have become extremely attractive. However, the literature lacks a comprehensive survey specific to attention techniques to guide researchers in employing attention in their deep models. Note that, besides being demanding in terms of training data and computational resources, transformers only cover a single category in self-attention out of the many categories available. We fill this gap and provide an in-depth survey of 50 attention techniques categorizing them by their most prominent features. We initiate our discussion by introducing the fundamental concepts behind the success of attention mechanism. Next, we furnish some essentials such as the strengths and limitations of each attention category, describe their fundamental building blocks, basic formulations with primary usage, and applications specifically for computer vision. We also discuss the challenges and open questions related to attention mechanism in general. Finally, we recommend possible future research directions for deep attention.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145867132",
                        "name": "Mohammed Hassanin"
                    },
                    {
                        "authorId": "49053414",
                        "name": "Saeed Anwar"
                    },
                    {
                        "authorId": "144380582",
                        "name": "Ibrahim Radwan"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "1747500",
                        "name": "A. Mian"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[26] presents SCOUTER loss, defining how large the attention area should be through the formula:",
                "The slot attention, however, will have a low resolution due to the poor resolution of the DNN\u2019s latent features [26].",
                "The negative explanation is especially informative in classification problems with high similarities between classes, such as in agricultural datasets [26].",
                "Moreover, the negative explanation maps support the model\u2019s classification, particularly during the mature growth stages, where the dissimilarities between species are substantial [26].",
                "A comprehensive description of the negative explanation and Equation (2) is provided in the study of [26]."
            ],
            "isInfluential": true,
            "intents": [
                "result",
                "background"
            ],
            "citingPaper": {
                "paperId": "b63b47dee300793cd8522cc77b3286bd6e358c37",
                "externalIds": {
                    "PubMedCentral": "8538865",
                    "DOI": "10.3390/s21206705",
                    "CorpusId": 239616827,
                    "PubMed": "34695919"
                },
                "corpusId": 239616827,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b63b47dee300793cd8522cc77b3286bd6e358c37",
                "title": "Weed Classification Using Explainable Multi-Resolution Slot Attention",
                "abstract": "In agriculture, explainable deep neural networks (DNNs) can be used to pinpoint the discriminative part of weeds for an imagery classification task, albeit at a low resolution, to control the weed population. This paper proposes the use of a multi-layer attention procedure based on a transformer combined with a fusion rule to present an interpretation of the DNN decision through a high-resolution attention map. The fusion rule is a weighted average method that is used to combine attention maps from different layers based on saliency. Attention maps with an explanation for why a weed is or is not classified as a certain class help agronomists to shape the high-resolution weed identification keys (WIK) that the model perceives. The model is trained and evaluated on two agricultural datasets that contain plants grown under different conditions: the Plant Seedlings Dataset (PSD) and the Open Plant Phenotyping Dataset (OPPD). The model represents attention maps with highlighted requirements and information about misclassification to enable cross-dataset evaluations. State-of-the-art comparisons represent classification developments after applying attention maps. Average accuracies of 95.42% and 96% are gained for the negative and positive explanations of the PSD test sets, respectively. In OPPD evaluations, accuracies of 97.78% and 97.83% are obtained for negative and positive explanations, respectively. The visual comparison between attention maps also shows high-resolution information.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51170243",
                        "name": "Sadaf Farkhani"
                    },
                    {
                        "authorId": "21122733",
                        "name": "S. Skovsen"
                    },
                    {
                        "authorId": "28941395",
                        "name": "M. Dyrmann"
                    },
                    {
                        "authorId": "1403488792",
                        "name": "R. J\u00f8rgensen"
                    },
                    {
                        "authorId": "2550309",
                        "name": "H. Karstoft"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Existing researches mainly focus on answering the following three questions: [15]\u2013[17].",
                "[17] propose a slot attention-based classifier for transparent yet accurate classification, which provide positive or negative explanation for a certain category."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4f5a87dd110555ff6414ea9131b292f097253108",
                "externalIds": {
                    "ArXiv": "2107.00296",
                    "DBLP": "journals/titb/NiuGZL22",
                    "DOI": "10.1109/JBHI.2021.3110593",
                    "CorpusId": 235694695,
                    "PubMed": "34495852"
                },
                "corpusId": 235694695,
                "publicationVenue": {
                    "id": "eac74c9c-a5c0-417d-8088-8164a6a8bfb3",
                    "name": "IEEE journal of biomedical and health informatics",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Journal of Biomedical and Health Informatics",
                        "IEEE j biomed health informatics",
                        "IEEE J Biomed Health Informatics"
                    ],
                    "issn": "2168-2194",
                    "url": "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6221020",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4f5a87dd110555ff6414ea9131b292f097253108",
                "title": "Explainable Diabetic Retinopathy Detection and Retinal Image Generation",
                "abstract": "Though deep learning has shown successful performance in classifying the label and severity stage of certain diseases, most of them give few explanations on how to make predictions. Inspired by Koch's Postulates, the foundation in evidence-based medicine (EBM) to identify the pathogen, we propose to exploit the interpretability of deep learning application in medical diagnosis. By isolating neuron activation patterns from a diabetic retinopathy (DR) detector and visualizing them, we can determine the symptoms that the DR detector identifies as evidence to make prediction. To be specific, we first define novel pathological descriptors using activated neurons of the DR detector to encode both spatial and appearance information of lesions. Then, to visualize the symptom encoded in the descriptor, we propose Patho-GAN, a new network to synthesize medically plausible retinal images. By manipulating these descriptors, we could even arbitrarily control the position, quantity, and categories of generated lesions. We also show that our synthesized images carry the symptoms directly related to diabetic retinopathy diagnosis. Our generated images are both qualitatively and quantitatively superior to the ones by previous methods. Besides, compared to existing methods that take hours to generate an image, our second level speed endows the potential to be an effective solution for data augmentation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "40492421",
                        "name": "Yuhao Niu"
                    },
                    {
                        "authorId": "2069591119",
                        "name": "Lin Gu"
                    },
                    {
                        "authorId": "1956017",
                        "name": "Yitian Zhao"
                    },
                    {
                        "authorId": "1388864077",
                        "name": "Feng Lu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We adopt a recently-emerged explainable classifier, called SCOUTER [11], and propose a new FSL method, named match-them-up network (MTUNet).",
                "SCOUTER normalizes the attention map only over the flattened spatial dimensions, i.e.,\nA(t) = \u03c3(A\u0304(t)).",
                "(5)\nPE adopts a different normalization strategy from SCOUTER.",
                "For pre-training of PE module, we used the same parameter setting as [11].",
                "To maintain the spatial information, position embedding P [25, 13, 11] is added to the features, i."
            ],
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "919cb84e6d19505625d2df763ae267c4a0cb6334",
                "externalIds": {
                    "DBLP": "conf/cvpr/WangLVNKN21",
                    "DOI": "10.1109/CVPRW53098.2021.00259",
                    "CorpusId": 235692972
                },
                "corpusId": 235692972,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/919cb84e6d19505625d2df763ae267c4a0cb6334",
                "title": "MTUNet: Few-shot Image Classification with Visual Explanations",
                "abstract": "Few-shot learning (FSL) approaches, mostly neural network-based, are assuming that the pre-trained knowledge can be obtained from base (seen) categories and transferred to novel (unseen) categories. However, the black-box nature of neural networks makes it difficult to understand what is actually transferred, which may hamper its application in some risk-sensitive areas. In this paper, we reveal a new way to perform explainable FSL for image classification, using discriminative patterns and pairwise matching. Experimental results prove that the proposed method can achieve satisfactory explainability on two mainstream datasets. Code is available*.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2153213890",
                        "name": "Bowen Wang"
                    },
                    {
                        "authorId": "47681301",
                        "name": "Liangzhi Li"
                    },
                    {
                        "authorId": "1840437995",
                        "name": "Manisha Verma"
                    },
                    {
                        "authorId": "1789677",
                        "name": "Yuta Nakashima"
                    },
                    {
                        "authorId": "1738501775",
                        "name": "R. Kawasaki"
                    },
                    {
                        "authorId": "144829054",
                        "name": "H. Nagahara"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "8b1a09189acaa09e3a3da8507800ce5ed44a61f6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2011-12527",
                    "ArXiv": "2011.12527",
                    "MAG": "3108049163",
                    "DOI": "10.1007/s10489-022-04072-4",
                    "CorpusId": 227162430
                },
                "corpusId": 227162430,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/8b1a09189acaa09e3a3da8507800ce5ed44a61f6",
                "title": "Match them up: visually explainable few-shot image classification",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2153213890",
                        "name": "Bowen Wang"
                    },
                    {
                        "authorId": "47681301",
                        "name": "Liangzhi Li"
                    },
                    {
                        "authorId": "1840437995",
                        "name": "Manisha Verma"
                    },
                    {
                        "authorId": "1789677",
                        "name": "Yuta Nakashima"
                    },
                    {
                        "authorId": "1738501775",
                        "name": "R. Kawasaki"
                    },
                    {
                        "authorId": "144829054",
                        "name": "H. Nagahara"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Work by Zunino et al. (2021) and Li et al. (2021) are very recently published.",
                "have been recently gaining impetus (Zunino et al., 2021; Li et al., 2021; Petsiuk et al., 2021).",
                "Another stream of literature that deals with the task of improving the visual explanations from CNN for various tasks such as domain generalization, robustness to image\nperturbations, etc. have been recently gaining impetus (Zunino et al., 2021; Li et al., 2021; Petsiuk et al., 2021).",
                "The method presented by Li et al. (2021) is attention based explainable AI (XAI) method while the one presented by Zunino et al. (2021) proposes to utilize the saliency maps generated using Grad-CAM to directly influence the intermediate activation maps during model training and make them end to\u2026"
            ],
            "isInfluential": true,
            "intents": [
                "methodology",
                "background"
            ],
            "citingPaper": {
                "paperId": "a84c30be9eb503e65427cc145f377b3b94203414",
                "externalIds": {
                    "DBLP": "conf/acml/BhosaleD22",
                    "CorpusId": 259093280
                },
                "corpusId": 259093280,
                "publicationVenue": {
                    "id": "2486528b-036c-4f3c-953f-c574eb381d12",
                    "name": "Asian Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "Asian Conf Mach Learn",
                        "ACML"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=40"
                },
                "url": "https://www.semanticscholar.org/paper/a84c30be9eb503e65427cc145f377b3b94203414",
                "title": "Learning with Domain Knowledge to Develop Justifiable Convolutional Networks",
                "abstract": "The inherent structure of the Convolutional Neural Networks (CNN) allows them to extract features that are highly correlated with the classes while performing image classi\ufb01cation. However, it may happen that the extracted features are merely coincidental and may not be justi\ufb01able from a human perspective. For example, from a set of images of cows on grassland, CNN can erroneously extract grass as the feature of the class cow. There are two main limitations to this kind of learning: \ufb01rstly, in many false-negative cases, correct features will not be used, and secondly, in false-positive cases the system will lack accountability. There is no implicit way to inform CNN to learn the features that are justi\ufb01able from a human perspective to resolve these issues. In this paper, we argue that if we provide domain knowledge to guide the learning process of CNN, it is possible to reliably learn the justi\ufb01able features. We propose a systematic yet simple mechanism to incorporate domain knowledge to guide the learning process of the CNNs to extract justi\ufb01able features. The \ufb02ip side is that it needs additional input. However, we have shown that even with minimal additional input our method can e\ufb00ectively propagate the knowledge within a class during training. We demonstrate that justi\ufb01able features not only enhance accuracy but also de-mand less amount of data and training time. Moreover, we also show that the proposed method is more robust against perturbational changes in the input images.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2219508752",
                        "name": "Rimmon Bhosale"
                    },
                    {
                        "authorId": "2067611182",
                        "name": "Mrinal Das"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Similar explanations that are learnt via optimising a loss function are SCOUTER [15] and the work by Schulz et al.",
                "Similar explanations that are learnt via optimising a loss function are SCOUTER [15] and the work by Schulz et al. [22]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "e4071bdfd6dd2c330fbe4e3a0f934cb0d7aa7a4d",
                "externalIds": {
                    "DBLP": "conf/bmvc/HartleySWM21",
                    "CorpusId": 249892501
                },
                "corpusId": 249892501,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/e4071bdfd6dd2c330fbe4e3a0f934cb0d7aa7a4d",
                "title": "Jitter-CAM: Improving the Spatial Resolution of CAM-Based Explanations",
                "abstract": "Class Activation Mappings (CAMs) are a popular group of methods for creating visual explanations of the reasons behind a network\u2019s prediction. These techniques create explanations by weighting and visualising the output of the \ufb01nal convolution layer. Recent CAM techniques have sought to improve these explanations by intro-ducing methods that aim to produce weights that more accurately represent how the network informs its prediction. However, none of these methods address the low spatial resolution of the \ufb01nal convolutional layer, leading to coarse explanations. In this paper, we propose Jitter-CAM, a method for producing and combining multiple CAM explanations that allow us to create explanations with a higher spatial resolution than previous comparable methods. We use ImageNet and a number of well known architectures to show that our technique produces explanations that are both more accurate and better at localising the target object. Code for Jitter-CAM is available at https://github.com/HartleyTW/Jitter-CAM .",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2067215178",
                        "name": "Thomas Hartley"
                    },
                    {
                        "authorId": "47703950",
                        "name": "K. Sidorov"
                    },
                    {
                        "authorId": "2154626275",
                        "name": "Christopher Willis"
                    },
                    {
                        "authorId": "144353457",
                        "name": "A. D. Marshall"
                    }
                ]
            }
        }
    ]
}