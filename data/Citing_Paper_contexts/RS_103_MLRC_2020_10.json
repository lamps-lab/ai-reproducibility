{
    "offset": 0,
    "data": [
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Merge multiple teachers FedDF [141] addresses the quality loss issue[87] of BN, break the knowledge barriers among heterogeneous client models END(2) [157] distilling the distribution of the predictions from an ensemble instead of the average prediction AE-KD [47] regard the ensemble knowledge distillation as a multi-objective optimization problem FedFTG [258] a data-free knowledge distillation method, which relieves the issue of direct model aggregation Merge multiple students Batch Ensemble [235] mini-batch friendly, parallelizable within a device, minor memory overhead Hydra [220] improve distillation performance while capturing the uncertainty behavior of the original ensemble LatentBE [163] average a student with multiple subnetworks, giving a single student network with no additional inference cost",
                "Ensemble distillation (ED) [141, 157] distills the average output of multiple teachers to a student model, which can make up for the shortcomings of a single teacher model and provide more diversified and comprehensive information to the student model."
            ],
            "citingPaper": {
                "paperId": "128217c0d1e99912ebc727c84686cc97a913b55f",
                "externalIds": {
                    "ArXiv": "2309.15698",
                    "CorpusId": 262942062
                },
                "corpusId": 262942062,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/128217c0d1e99912ebc727c84686cc97a913b55f",
                "title": "Deep Model Fusion: A Survey",
                "abstract": "Deep model fusion/merging is an emerging technique that merges the parameters or predictions of multiple deep learning models into a single one. It combines the abilities of different models to make up for the biases and errors of a single model to achieve better performance. However, deep model fusion on large-scale deep learning models (e.g., LLMs and foundation models) faces several challenges, including high computational cost, high-dimensional parameter space, interference between different heterogeneous models, etc. Although model fusion has attracted widespread attention due to its potential to solve complex real-world tasks, there is still a lack of complete and detailed survey research on this technique. Accordingly, in order to understand the model fusion method better and promote its development, we present a comprehensive survey to summarize the recent progress. Specifically, we categorize existing deep model fusion methods as four-fold: (1)\"Mode connectivity\", which connects the solutions in weight space via a path of non-increasing loss, in order to obtain better initialization for model fusion; (2)\"Alignment\"matches units between neural networks to create better conditions for fusion; (3)\"Weight average\", a classical model fusion method, averages the weights of multiple models to obtain more accurate results closer to the optimal solution; (4)\"Ensemble learning\"combines the outputs of diverse models, which is a foundational technique for improving the accuracy and robustness of the final model. In addition, we analyze the challenges faced by deep model fusion and propose possible research directions for model fusion in the future. Our review is helpful in deeply understanding the correlation between different model fusion methods and practical application methods, which can enlighten the research in the field of deep model fusion.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2243322582",
                        "name": "Weishi Li"
                    },
                    {
                        "authorId": "2243387143",
                        "name": "Yong Peng"
                    },
                    {
                        "authorId": "2243404565",
                        "name": "Miao Zhang"
                    },
                    {
                        "authorId": "2248323871",
                        "name": "Liang Ding"
                    },
                    {
                        "authorId": "2247556302",
                        "name": "Han Hu"
                    },
                    {
                        "authorId": "2248152216",
                        "name": "Li Shen"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "Therefore, Uep = H( 1 M \u2211M i=1 p ) \u2212 1 M \u2211M i=1 H(p ) [13]."
            ],
            "citingPaper": {
                "paperId": "949876067df8878cfda9005646cddc5d1dc7e95a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-12445",
                    "ArXiv": "2309.12445",
                    "DOI": "10.36001/phmap.2023.v4i1.3611",
                    "CorpusId": 262217465
                },
                "corpusId": 262217465,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/949876067df8878cfda9005646cddc5d1dc7e95a",
                "title": "Ensemble Neural Networks for Remaining Useful Life (RUL) Prediction",
                "abstract": "A core part of maintenance planning is a monitoring system that provides a good prognosis on health and degradation, often expressed as remaining useful life (RUL). Most of the current data-driven approaches for RUL prediction focus on single-point prediction. These point prediction approaches do not include the probabilistic nature of the failure. The few probabilistic approaches to date either include the aleatoric uncertainty (which originates from the system), or the epistemic uncertainty (which originates from the model parameters), or both simultaneously as a total uncertainty. Here, we propose ensemble neural networks for probabilistic RUL predictions which considers both uncertainties and decouples these two uncertainties. These decoupled uncertainties are vital in knowing and interpreting the confidence of the predictions. This method is tested on NASA's turbofan jet engine CMAPSS data-set. Our results show how these uncertainties can be modeled and how to disentangle the contribution of aleatoric and epistemic uncertainty. Additionally, our approach is evaluated on different metrics and compared against the current state-of-the-art methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2244623619",
                        "name": "Ahbishek Srinivasan"
                    },
                    {
                        "authorId": "4639904",
                        "name": "J. C. Andresen"
                    },
                    {
                        "authorId": "2244622603",
                        "name": "Anders Holst"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "4783219d2ab75955f580d10b387aeb38cc92330d",
                "externalIds": {
                    "ArXiv": "2308.16561",
                    "DBLP": "journals/corr/abs-2308-16561",
                    "DOI": "10.48550/arXiv.2308.16561",
                    "CorpusId": 261397213
                },
                "corpusId": 261397213,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4783219d2ab75955f580d10b387aeb38cc92330d",
                "title": "MoMA: Momentum Contrastive Learning with Multi-head Attention-based Knowledge Distillation for Histopathology Image Analysis",
                "abstract": "There is no doubt that advanced artificial intelligence models and high quality data are the keys to success in developing computational pathology tools. Although the overall volume of pathology data keeps increasing, a lack of quality data is a common issue when it comes to a specific task due to several reasons including privacy and ethical issues with patient data. In this work, we propose to exploit knowledge distillation, i.e., utilize the existing model to learn a new, target model, to overcome such issues in computational pathology. Specifically, we employ a student-teacher framework to learn a target model from a pre-trained, teacher model without direct access to source data and distill relevant knowledge via momentum contrastive learning with multi-head attention mechanism, which provides consistent and context-aware feature representations. This enables the target model to assimilate informative representations of the teacher model while seamlessly adapting to the unique nuances of the target data. The proposed method is rigorously evaluated across different scenarios where the teacher model was trained on the same, relevant, and irrelevant classification tasks with the target model. Experimental results demonstrate the accuracy and robustness of our approach in transferring knowledge to different domains and tasks, outperforming other related methods. Moreover, the results provide a guideline on the learning strategy for different types of tasks and scenarios in computational pathology. Code is available at: \\url{https://github.com/trinhvg/MoMA}.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2123471573",
                        "name": "T. Vuong"
                    },
                    {
                        "authorId": "2089681",
                        "name": "J. T. Kwak"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "According to the variational Dirichlet, the uncertainty can be estimated by differential entropy, which is regarded as a more effective estimation method in various uncertainty scenarios (data and knowledge uncertainties) [24].",
                "The non-Bayesian uncertainty estimation method utilizes the model\u2019s output as variational Dirichlet parameters [24, 25, 26] and depicts the predicted probability distribution based on its prior conjugate properties of the multinomial distribution.",
                "As shown in Figure 1, this work makes each sub-model estimate the uncertainty through Dirichlet prior [24, 25, 26] in the learning phase and combines the diversity constraints to obtain the sub-model space for selection."
            ],
            "citingPaper": {
                "paperId": "57bc8dee18940526c6c5058fcf178a34c96db494",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-00346",
                    "ArXiv": "2308.00346",
                    "DOI": "10.48550/arXiv.2308.00346",
                    "CorpusId": 260350890
                },
                "corpusId": 260350890,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/57bc8dee18940526c6c5058fcf178a34c96db494",
                "title": "Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness",
                "abstract": "The deep neural network has attained significant efficiency in image recognition. However, it has vulnerable recognition robustness under extensive data uncertainty in practical applications. The uncertainty is attributed to the inevitable ambient noise and, more importantly, the possible adversarial attack. Dynamic methods can effectively improve the defense initiative in the arms race of attack and defense of adversarial examples. Different from the previous dynamic method depend on input or decision, this work explore the dynamic attributes in model level through dynamic ensemble selection technology to further protect the model from white-box attacks and improve the robustness. Specifically, in training phase the Dirichlet distribution is apply as prior of sub-models' predictive distribution, and the diversity constraint in parameter space is introduced under the lightweight sub-models to construct alternative ensembel model spaces. In test phase, the certain sub-models are dynamically selected based on their rank of uncertainty value for the final prediction to ensure the majority accurate principle in ensemble robustness and accuracy. Compared with the previous dynamic method and staic adversarial traning model, the presented approach can achieve significant robustness results without damaging accuracy by combining dynamics and diversity property.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "9574521",
                        "name": "Ruoxi Qin"
                    },
                    {
                        "authorId": "82527663",
                        "name": "Linyuan Wang"
                    },
                    {
                        "authorId": "2302388",
                        "name": "Xuehui Du"
                    },
                    {
                        "authorId": "49794079",
                        "name": "Xing-yuan Chen"
                    },
                    {
                        "authorId": "35841257",
                        "name": "Binghai Yan"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Various prior work which uses the Dirichlet distribution and function-space regularization (Malinin and Gales, 2018; Malinin et al., 2020; Joo et al., 2020; Sensoy et al., 2018, 2021) can be viewed as a special case of fVI.",
                "They can be used to distill a trained ensemble into a single model (Malinin et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "a4c9ed3b6e371c083a056d732365b3713276b841",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-06055",
                    "ArXiv": "2307.06055",
                    "DOI": "10.48550/arXiv.2307.06055",
                    "CorpusId": 259836798
                },
                "corpusId": 259836798,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a4c9ed3b6e371c083a056d732365b3713276b841",
                "title": "Function-Space Regularization for Deep Bayesian Classification",
                "abstract": "Bayesian deep learning approaches assume model parameters to be latent random variables and infer posterior distributions to quantify uncertainty, increase safety and trust, and prevent overconfident and unpredictable behavior. However, weight-space priors are model-specific, can be difficult to interpret and are hard to specify. Instead, we apply a Dirichlet prior in predictive space and perform approximate function-space variational inference. To this end, we interpret conventional categorical predictions from stochastic neural network classifiers as samples from an implicit Dirichlet distribution. By adapting the inference, the same function-space prior can be combined with different models without affecting model architecture or size. We illustrate the flexibility and efficacy of such a prior with toy experiments and demonstrate scalability, improved uncertainty quantification and adversarial robustness with large-scale image classification experiments.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2026844393",
                        "name": "J. Lin"
                    },
                    {
                        "authorId": "31349388",
                        "name": "Joe Watson"
                    },
                    {
                        "authorId": "1389560206",
                        "name": "Pascal Klink"
                    },
                    {
                        "authorId": "2107720654",
                        "name": "Jan Peters"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "In addition, EnD2-H and EnD2-S are able to outperform EnD2 on both benchmarks, indicating the effectiveness of the unification operations.",
                "Type (a) covers EnD [24] and EnD(2) [31].",
                "For Type (b), the unification operators are applied to EnD and EnD2 to enhance their robustness against the certainty inconsistency issue.",
                "To satisfy such a need, the concept of ensemble-distillation [23], [24], [25], [26], [27], [28], [29], [30], [31] can be leveraged since it provides a flexible platform for com-",
                "These variants can be classified into three main types: type (a), type (b), and type (c), as shown in Table I. Type (a) covers EnD [24] and EnD2 [31].",
                "This category includes EnD-H, EnD-S, EnD2-H, and EnD2-S.",
                "(1), while EnD2 is a variant of EnD elaborated in Section A1 of the appendix, available online."
            ],
            "citingPaper": {
                "paperId": "af54b730d31d3941043abde92565b30ace9e702b",
                "externalIds": {
                    "DBLP": "journals/pami/ChaoCWLL23",
                    "DOI": "10.1109/TPAMI.2023.3289308",
                    "CorpusId": 259261696,
                    "PubMed": "37363837"
                },
                "corpusId": 259261696,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/af54b730d31d3941043abde92565b30ace9e702b",
                "title": "Rainbow UDA: Combining Domain Adaptive Models for Semantic Segmentation Tasks",
                "abstract": "In this paper, we propose Rainbow UDA, a framework designed to address the drawbacks of the previous ensemble-distillation frameworks when combining multiple unsupervised domain adaptation (UDA) models for semantic segmentation tasks. Such drawbacks are mainly caused by overlooking the magnitudes of the output certainties of different members in an ensemble as well as their individual performance in the target domain, causing the distillation process to suffer from certainty inconsistency and performance variation issues. These issues may hinder the effectiveness of an ensemble that includes members with either biased certainty distributions or have poor performance in the target domain. To mitigate such a deficiency, Rainbow UDA introduces two operations: the unification and the channel-wise fusion operations, to address the above two issues. In order to validate the designs of Rainbow UDA, we leverage the GTA5 <inline-formula><tex-math notation=\"LaTeX\">$\\to$</tex-math><alternatives><mml:math><mml:mo>\u2192</mml:mo></mml:math><inline-graphic xlink:href=\"chao-ieq1-3289308.gif\"/></alternatives></inline-formula> Cityscapes and SYNTHIA <inline-formula><tex-math notation=\"LaTeX\">$\\to$</tex-math><alternatives><mml:math><mml:mo>\u2192</mml:mo></mml:math><inline-graphic xlink:href=\"chao-ieq2-3289308.gif\"/></alternatives></inline-formula> Cityscapes benchmarks to examine the effectiveness of the two operations, and compare Rainbow UDA against a wide variety of baseline approaches. We also provide a set of analyses to show that Rainbow UDA is effective, robust, and can evolve with time as the ensemble grows.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2086829087",
                        "name": "Chen-Hao Chao"
                    },
                    {
                        "authorId": "9939828",
                        "name": "Bo Wun Cheng"
                    },
                    {
                        "authorId": "2158321519",
                        "name": "Tzu-Wen Wang"
                    },
                    {
                        "authorId": "2158171667",
                        "name": "Huang-ru Liao"
                    },
                    {
                        "authorId": "2149791622",
                        "name": "Chun-Yi Lee"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "(a) SensorNet [14] \u2713 \u2713 \u2717 \u2717 (b) EnD2 [15] \u2713 \u2713 \u2713 \u2717 (c) CLUE \u2713 \u2713 \u2713 \u2713",
                "TABLE I SOURCES OF TASK UNCERTAINTY THAT CAN BE DETECTED BY SENSORNET [14], END2 [15], AND CLUE",
                "Detection of Unreliable Task under Various Sources We compare the predictions of CLUE with another sampling-free uncertainty estimator, EnD2 [15].",
                "Additionally, Ensemble distribution distillation (EnD2) is proposed to explicitly model a distribution over output distribution of deep ensemble [15].",
                "CLUE learns to explicitly parameterize this distribution by adopting the concept of distilling distribution from a DNN ensemble [15]."
            ],
            "citingPaper": {
                "paperId": "5e106727a4c385203d4a0bf6168464825dec9c0f",
                "externalIds": {
                    "DBLP": "conf/ijcnn/LeeLMYM23",
                    "DOI": "10.1109/IJCNN54540.2023.10191612",
                    "CorpusId": 260385611
                },
                "corpusId": 260385611,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/5e106727a4c385203d4a0bf6168464825dec9c0f",
                "title": "CLUE: Cross-Layer Uncertainty Estimator for Reliable Neural Perception using Processing-in-Memory Accelerators",
                "abstract": "One of the primary challenges of deploying deep neural networks (DNNs) is ensuring their reliable performance in unpredictable edge environments, which are often disrupted by a variety of uncertainties and variations. Estimating uncertainty is crucial in order to understand the reliability of task predictions and prevent system failures. However, quantifying uncertainty stemming from non-ideal properties of processing hardware has not yet been thoroughly studied. To address this, we present Cross-Layer Uncertainty Estimator (CLUE), which quantifies task uncertainty originating from both sensing/processing hardware variations and DNN algorithm uncertainty. Our experimental results demonstrate that CLUE provides uncertainty with up to 80.4% less calibration error and only 12% of energy overheads compared to using task DNN solely. Furthermore, CLUE is able to detect unreliable tasks that stem from processing hardware variations, which prior uncertainty estimators were unable to achieve. Finally, we demonstrate an adaptive control of processing hardware using CLUE, which allows a dynamic trade-off control between task accuracy and energy consumption.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2109448257",
                        "name": "Minah Lee"
                    },
                    {
                        "authorId": "1563347162",
                        "name": "A. Lu"
                    },
                    {
                        "authorId": "153631826",
                        "name": "Mandovi Mukherjee"
                    },
                    {
                        "authorId": "2152831909",
                        "name": "Shimeng Yu"
                    },
                    {
                        "authorId": "144192725",
                        "name": "S. Mukhopadhyay"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "single DNN to explicitly model a distribution over the outputs [31], [46].",
                "Predictive Uncertainty considers misclassifications that occur randomly and typically close to samples inside the generalization area [1], [6], [31], [46]."
            ],
            "citingPaper": {
                "paperId": "e8a1762d335d690efcef72e8f7429c10f250d78e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-02672",
                    "ArXiv": "2307.02672",
                    "DOI": "10.1109/IJCNN54540.2023.10191233",
                    "CorpusId": 259360532
                },
                "corpusId": 259360532,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/e8a1762d335d690efcef72e8f7429c10f250d78e",
                "title": "GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations",
                "abstract": "Deep neural networks tend to make overconfident predictions and often require additional detectors for misclassifi-cations, particularly for safety-critical applications. Existing detection methods usually only focus on adversarial attacks or out-of-distribution samples as reasons for false predictions. However, generalization errors occur due to diverse reasons often related to poorly learning relevant invariances. We therefore propose GIT, a holistic approach for the detection of generalization errors that combines the usage of gradient information and invariance transformations. The invariance transformations are designed to shift misclassified samples back into the generalization area of the neural network, while the gradient information measures the contradiction between the initial prediction and the corre-sponding inherent computations of the neural network using the transformed sample. Our experiments demonstrate the superior performance of GIT compared to the state-of-the-art on a variety of network architectures, problem setups and perturbation types.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1643682364",
                        "name": "Julia Lust"
                    },
                    {
                        "authorId": "2063161",
                        "name": "A. Condurache"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "Most existing ensemble methods [30, 24, 11] average the output of each model, which neglects the diversity."
            ],
            "citingPaper": {
                "paperId": "86f86a831c551eef9d7bed628ab9dff5ac19832e",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiL23",
                    "DOI": "10.1109/CVPRW59228.2023.00221",
                    "CorpusId": 250086800
                },
                "corpusId": 250086800,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/86f86a831c551eef9d7bed628ab9dff5ac19832e",
                "title": "A2-Aug: Adaptive Automated Data Augmentation",
                "abstract": "Data augmentation is a promising way to enhance the generalization ability of deep learning models. Many proxy-free and proxy-based automated augmentation methods are proposed to search for the best augmentation for target datasets. However, the proxy-free methods require lots of searching overhead, while the proxy-based methods introduce optimization gaps with the actual task. In this paper, we explore a new proxy-free approach that only needs a small number of searches (~ 5 vs 100 of RandAugment) to alleviate these issues. Specifically, we propose Adaptive Automated Augmentation (A2 -Aug), a simple and effective proxy-free framework, which seeks to mine the adaptive ensemble knowledge of multiple augmentations to further improve the adaptability of each candidate augmentation. Firstly, A2 -Aug automatically learns the ensemble logit from multiple candidate augmentations, which is jointly optimized and adaptive to target tasks. Secondly, the adaptive ensemble logit is used to distill each logit of input augmentation via KL divergence. In this way, these a few candidate augmentations can implicitly learn strong adaptability for the target datasets, which enjoy similar effects with many searches of RandAugment. Finally, equipped with joint training via separate BatchNorm and normalized distillation, A2-Aug obtains state-of-the-art performance with less training budget. In experiments, our A2 -Aug achieves 4% performance gain on CIFAR-100, which substantially outperforms other methods. On ImageNet, we obtain a top-1 accuracy of 79.2% for ResNet-50, a 1.6% boosting over the AutoAugment with at least 25\u00d7 faster training speed.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "9747208",
                        "name": "Lujun Li"
                    },
                    {
                        "authorId": "46637795",
                        "name": "Zheng Hua Zhu"
                    },
                    {
                        "authorId": "143986385",
                        "name": "Guan Huang"
                    },
                    {
                        "authorId": "40359161",
                        "name": "Dalong Du"
                    },
                    {
                        "authorId": "1697700",
                        "name": "Jiwen Lu"
                    },
                    {
                        "authorId": "48128428",
                        "name": "Jie Zhou"
                    },
                    {
                        "authorId": "47384812",
                        "name": "Qingyi Gu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Furthermore, some works attempt to address specific challenges in KD, such as distilling from ensembles of teachers [56, 57] and investigating the impact of different teachers on student performance [58, 38]."
            ],
            "citingPaper": {
                "paperId": "da1946bb4220e743e8f46946397a9b31e609df74",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-15781",
                    "ArXiv": "2305.15781",
                    "DOI": "10.48550/arXiv.2305.15781",
                    "CorpusId": 258887757
                },
                "corpusId": 258887757,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/da1946bb4220e743e8f46946397a9b31e609df74",
                "title": "VanillaKD: Revisit the Power of Vanilla Knowledge Distillation from Small Scale to Large Scale",
                "abstract": "The tremendous success of large models trained on extensive datasets demonstrates that scale is a key ingredient in achieving superior results. Therefore, the reflection on the rationality of designing knowledge distillation (KD) approaches for limited-capacity architectures solely based on small-scale datasets is now deemed imperative. In this paper, we identify the \\emph{small data pitfall} that presents in previous KD methods, which results in the underestimation of the power of vanilla KD framework on large-scale datasets such as ImageNet-1K. Specifically, we show that employing stronger data augmentation techniques and using larger datasets can directly decrease the gap between vanilla KD and other meticulously designed KD variants. This highlights the necessity of designing and evaluating KD approaches in the context of practical scenarios, casting off the limitations of small-scale datasets. Our investigation of the vanilla KD and its variants in more complex schemes, including stronger training strategies and different model capacities, demonstrates that vanilla KD is elegantly simple but astonishingly effective in large-scale scenarios. Without bells and whistles, we obtain state-of-the-art ResNet-50, ViT-S, and ConvNeXtV2-T models for ImageNet, which achieve 83.1\\%, 84.3\\%, and 85.0\\% top-1 accuracy, respectively. PyTorch code and checkpoints can be found at https://github.com/Hao840/vanillaKD.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2147215540",
                        "name": "Zhiwei Hao"
                    },
                    {
                        "authorId": "2148899357",
                        "name": "Jianyuan Guo"
                    },
                    {
                        "authorId": "3826388",
                        "name": "Kai Han"
                    },
                    {
                        "authorId": "145030939",
                        "name": "Han Hu"
                    },
                    {
                        "authorId": "9196284",
                        "name": "Chang Xu"
                    },
                    {
                        "authorId": "2108702980",
                        "name": "Yunhe Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "\u2026feature selection (Heo et al., 2019a;b; Chen et al., 2021b), distribution learning (Ahn et al., 2019; Huang & Wang, 2017; Passalis & Tefas, 2018; Malinin et al., 2020; Yang et al., 2021), attention rephrasing (Kim et al., 2018; Ji et al., 2021), and reuse of teacher classifier (Chen et al.,\u2026",
                ", 2021b), distribution learning (Ahn et al., 2019; Huang & Wang, 2017; Passalis & Tefas, 2018; Malinin et al., 2020; Yang et al., 2021), attention rephrasing (Kim et al.",
                "Many one-stage KD variants have been presented recently, including but not limited to (Guo et al., 2020a; Chung et al., 2020; Malinin et al., 2020; Wu & Gong, 2021)."
            ],
            "citingPaper": {
                "paperId": "71c2cf9a7348f435eb68633594f66892a5c999b8",
                "externalIds": {
                    "DBLP": "conf/iclr/LiuLLY23",
                    "ArXiv": "2305.13803",
                    "DOI": "10.48550/arXiv.2305.13803",
                    "CorpusId": 258841675
                },
                "corpusId": 258841675,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/71c2cf9a7348f435eb68633594f66892a5c999b8",
                "title": "NORM: Knowledge Distillation via N-to-One Representation Matching",
                "abstract": "Existing feature distillation methods commonly adopt the One-to-one Representation Matching between any pre-selected teacher-student layer pair. In this paper, we present N-to-One Representation (NORM), a new two-stage knowledge distillation method, which relies on a simple Feature Transform (FT) module consisting of two linear layers. In view of preserving the intact information learnt by the teacher network, during training, our FT module is merely inserted after the last convolutional layer of the student network. The first linear layer projects the student representation to a feature space having N times feature channels than the teacher representation from the last convolutional layer, and the second linear layer contracts the expanded output back to the original feature space. By sequentially splitting the expanded student representation into N non-overlapping feature segments having the same number of feature channels as the teacher's, they can be readily forced to approximate the intact teacher representation simultaneously, formulating a novel many-to-one representation matching mechanism conditioned on a single teacher-student layer pair. After training, such an FT module will be naturally merged into the subsequent fully connected layer thanks to its linear property, introducing no extra parameters or architectural modifications to the student network at inference. Extensive experiments on different visual recognition benchmarks demonstrate the leading performance of our method. For instance, the ResNet18|MobileNet|ResNet50-1/4 model trained by NORM reaches 72.14%|74.26%|68.03% top-1 accuracy on the ImageNet dataset when using a pre-trained ResNet34|ResNet50|ResNet50 model as the teacher, achieving an absolute improvement of 2.01%|4.63%|3.03% against the individually trained counterpart. Code is available at https://github.com/OSVAI/NORM",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2160110069",
                        "name": "Xiaolong Liu"
                    },
                    {
                        "authorId": "9747208",
                        "name": "Lujun Li"
                    },
                    {
                        "authorId": "82511570",
                        "name": "Chao Li"
                    },
                    {
                        "authorId": "2021251",
                        "name": "Anbang Yao"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "febf10dc1bff691005e837383c33be78530783f5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-10384",
                    "ArXiv": "2305.10384",
                    "DOI": "10.48550/arXiv.2305.10384",
                    "CorpusId": 258741024
                },
                "corpusId": 258741024,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/febf10dc1bff691005e837383c33be78530783f5",
                "title": "Logit-Based Ensemble Distribution Distillation for Robust Autoregressive Sequence Uncertainties",
                "abstract": "Efficiently and reliably estimating uncertainty is an important objective in deep learning. It is especially pertinent to autoregressive sequence tasks, where training and inference costs are typically very high. However, existing research has predominantly focused on tasks with static data such as image classification. In this work, we investigate Ensemble Distribution Distillation (EDD) applied to large-scale natural language sequence-to-sequence data. EDD aims to compress the superior uncertainty performance of an expensive (teacher) ensemble into a cheaper (student) single model. Importantly, the ability to separate knowledge (epistemic) and data (aleatoric) uncertainty is retained. Existing probability-space approaches to EDD, however, are difficult to scale to large vocabularies. We show, for modern transformer architectures on large-scale translation tasks, that modelling the ensemble logits, instead of softmax probabilities, leads to significantly better students. Moreover, the students surprisingly even outperform Deep Ensembles by up to ~10% AUROC on out-of-distribution detection, whilst matching them at in-distribution translation.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1400414048",
                        "name": "Yassir Fathullah"
                    },
                    {
                        "authorId": "2142129559",
                        "name": "Guoxuan Xia"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "There are methods including Knowledge Distillation (KD) [43, 21] and Ensemble Distribution Distillation (EDD) [34, 13] that attempt to distil the knowledge",
                "We also investigate if Knowledge Distillation (KD) [21] and Ensemble Distribution Distillation (EDD) [34, 44] are able to imitate the uncertainties produced by a single or ensemble systems respectively.",
                "There are methods including Knowledge Distillation (KD) [43, 21] and Ensemble Distribution Distillation (EDD) [34, 13] that attempt to distil the knowledge\nar X\niv :2\n30 5.",
                "The performance of the proxies is compared to two baseline systems: KD when capturing confidence or entropy of a single model, and EDD in capturing mutual information from an ensemble.",
                "Finally, we perform downstream out-of-distribution detection using confidence, entropy, and MI scores from T5 Large ensemble, EDD (T5 Large), and Proxy Large."
            ],
            "citingPaper": {
                "paperId": "a7917e0392887144772c18fc3fc6cb19bdca521b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-05098",
                    "ArXiv": "2305.05098",
                    "DOI": "10.48550/arXiv.2305.05098",
                    "CorpusId": 258564366
                },
                "corpusId": 258564366,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a7917e0392887144772c18fc3fc6cb19bdca521b",
                "title": "Who Needs Decoders? Efficient Estimation of Sequence-level Attributes",
                "abstract": "State-of-the-art sequence-to-sequence models often require autoregressive decoding, which can be highly expensive. However, for some downstream tasks such as out-of-distribution (OOD) detection and resource allocation, the actual decoding output is not needed just a scalar attribute of this sequence. In these scenarios, where for example knowing the quality of a system's output to predict poor performance prevails over knowing the output itself, is it possible to bypass the autoregressive decoding? We propose Non-Autoregressive Proxy (NAP) models that can efficiently predict general scalar-valued sequence-level attributes. Importantly, NAPs predict these metrics directly from the encodings, avoiding the expensive autoregressive decoding stage. We consider two sequence-to-sequence task: Machine Translation (MT); and Automatic Speech Recognition (ASR). In OOD for MT, NAPs outperform a deep ensemble while being significantly faster. NAPs are also shown to be able to predict performance metrics such as BERTScore (MT) or word error rate (ASR). For downstream tasks, such as data filtering and resource optimization, NAPs generate performance predictions that outperform predictive uncertainty while being highly inference efficient.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1400414048",
                        "name": "Yassir Fathullah"
                    },
                    {
                        "authorId": "2121301573",
                        "name": "Puria Radmard"
                    },
                    {
                        "authorId": "2190750613",
                        "name": "Adian Liusie"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "One of the common practices in knowledge distillation is employing ensembles as a teacher model (Malinin et al., 2020; Ryabinin et al., 2021) based on the superior performance of the ensemble of deep neural networks (Lakshminarayanan et al., 2017; Ovadia et al., 2019), and several works already\u2026",
                "One of the common practices in knowledge distillation is employing ensembles as a teacher model (Malinin et al., 2020; Ryabinin et al., 2021) based on the superior performance of the ensemble of deep neural networks (Lakshminarayanan et al."
            ],
            "citingPaper": {
                "paperId": "12c14868a38fd7f4cefe4007474e3139f9065586",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-09426",
                    "ArXiv": "2304.09426",
                    "DOI": "10.48550/arXiv.2304.09426",
                    "CorpusId": 258212652
                },
                "corpusId": 258212652,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/12c14868a38fd7f4cefe4007474e3139f9065586",
                "title": "Decoupled Training for Long-Tailed Classification With Stochastic Representations",
                "abstract": "Decoupling representation learning and classifier learning has been shown to be effective in classification with long-tailed data. There are two main ingredients in constructing a decoupled learning scheme; 1) how to train the feature extractor for representation learning so that it provides generalizable representations and 2) how to re-train the classifier that constructs proper decision boundaries by handling class imbalances in long-tailed data. In this work, we first apply Stochastic Weight Averaging (SWA), an optimization technique for improving the generalization of deep neural networks, to obtain better generalizing feature extractors for long-tailed classification. We then propose a novel classifier re-training algorithm based on stochastic representation obtained from the SWA-Gaussian, a Gaussian perturbed SWA, and a self-distillation strategy that can harness the diverse stochastic representations based on uncertainty estimates to build more robust classifiers. Extensive experiments on CIFAR10/100-LT, ImageNet-LT, and iNaturalist-2018 benchmarks show that our proposed method improves upon previous methods both in terms of prediction accuracy and uncertainty estimation.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2065197138",
                        "name": "G. Nam"
                    },
                    {
                        "authorId": "2214771780",
                        "name": "Sunguk Jang"
                    },
                    {
                        "authorId": "2124954802",
                        "name": "Juho Lee"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Malinin et al.[20] argued that using the averaging operation for combination harmed the diversity of the models in an ensemble."
            ],
            "citingPaper": {
                "paperId": "6126da434308e7241ed4cdc18b923e54be84f61a",
                "externalIds": {
                    "ArXiv": "2304.07123",
                    "DBLP": "journals/corr/abs-2304-07123",
                    "DOI": "10.48550/arXiv.2304.07123",
                    "CorpusId": 258170182,
                    "PubMed": "37725849"
                },
                "corpusId": 258170182,
                "publicationVenue": {
                    "id": "dca681d7-2e9b-4f13-905a-b59dfd692525",
                    "name": "Computers in Biology and Medicine",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Biology Med"
                    ],
                    "issn": "0010-4825",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/351/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/computers-in-biology-and-medicine/",
                        "http://www.sciencedirect.com/science/journal/00104825"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6126da434308e7241ed4cdc18b923e54be84f61a",
                "title": "Tailored Multi-Organ Segmentation with Model Adaptation and Ensemble",
                "abstract": "Multi-organ segmentation, which identifies and separates different organs in medical images, is a fundamental task in medical image analysis. Recently, the immense success of deep learning motivated its wide adoption in multi-organ segmentation tasks. However, due to expensive labor costs and expertise, the availability of multi-organ annotations is usually limited and hence poses a challenge in obtaining sufficient training data for deep learning-based methods. In this paper, we aim to address this issue by combining off-the-shelf single-organ segmentation models to develop a multi-organ segmentation model on the target dataset, which helps get rid of the dependence on annotated data for multi-organ segmentation. To this end, we propose a novel dual-stage method that consists of a Model Adaptation stage and a Model Ensemble stage. The first stage enhances the generalization of each off-the-shelf segmentation model on the target domain, while the second stage distills and integrates knowledge from multiple adapted single-organ segmentation models. Extensive experiments on four abdomen datasets demonstrate that our proposed method can effectively leverage off-the-shelf single-organ segmentation models to obtain a tailored model for multi-organ segmentation with high accuracy.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46436215",
                        "name": "Jiahua Dong"
                    },
                    {
                        "authorId": "1612996576",
                        "name": "Guohua Cheng"
                    },
                    {
                        "authorId": "1992911032",
                        "name": "Yue Zhang"
                    },
                    {
                        "authorId": "4067024",
                        "name": "Chengtao Peng"
                    },
                    {
                        "authorId": "2152603808",
                        "name": "Yu Song"
                    },
                    {
                        "authorId": "3128157",
                        "name": "Ruofeng Tong"
                    },
                    {
                        "authorId": "2940227",
                        "name": "Lanfen Lin"
                    },
                    {
                        "authorId": "2156086562",
                        "name": "Yen-Wei Chen"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "1, 2, 3, 22 [31] Andrey Malinin, Bruno Mlodozeniec, and Mark Gales.",
                "[31] and normalize the area under the curve by that of an oracle and subtracts a baseline score with randomly sorted samples."
            ],
            "citingPaper": {
                "paperId": "e925e0211bc260dad9946592ee1698be279f26d9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-11298",
                    "ArXiv": "2303.11298",
                    "DOI": "10.1109/CVPR52729.2023.00693",
                    "CorpusId": 257632387
                },
                "corpusId": 257632387,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e925e0211bc260dad9946592ee1698be279f26d9",
                "title": "Reliability in Semantic Segmentation: Are we on the Right Track?",
                "abstract": "Motivated by the increasing popularity of transformers in computer vision, in recent times there has been a rapid development of novel architectures. While in-domain performance follows a constant, upward trend, properties like robustness or uncertainty estimation are less explored-leaving doubts about advances in model reliability. Studies along these axes exist, but they are mainly limited to classification models. In contrast, we carry out a study on semantic segmentation, a relevant task for many real-world applications where model reliability is paramount. We analyze a broad variety of models, spanning from older ResNet-based architectures to novel transformers and assess their reliability based on four metrics: robustness, calibration, misclassification detection and out-of-distribution (OOD) detection. We find that while recent models are significantly more robust, they are not overall more reliable in terms of uncertainty estimation. We further explore methods that can come to the rescue and show that improving calibration can also help with other uncertainty metrics such as misclassification or OOD detection. This is the first study on modern segmentation models focused on both robustness and uncertainty estimation and we hope it will help practitioners and researchers interested in this fundamental vision task11Code available at https://github.com/naver/relis.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "66320600",
                        "name": "Pau de Jorge"
                    },
                    {
                        "authorId": "39268286",
                        "name": "Riccardo Volpi"
                    },
                    {
                        "authorId": "143635540",
                        "name": "Philip H. S. Torr"
                    },
                    {
                        "authorId": "3321919",
                        "name": "Gr\u00e9gory Rogez"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "(2015), condensing the knowledge from a possibly complex teacher model into a simpler student surrogate has been an active research topic (e.g. Vadera et al., 2020; Malinin et al., 2020; Ryabinin et al., 2021; Zhou et al., 2022; Hen et al., 2021).",
                "Since the pivotal work of Hinton et al. (2015), condensing the knowledge from a possibly complex teacher model into a simpler student surrogate has been an active research topic (e.g. Vadera et al., 2020; Malinin et al., 2020; Ryabinin et al., 2021; Zhou et al., 2022; Hen et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "f945b6788d4042c950e57e6032c0ad122566661e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-10139",
                    "ArXiv": "2303.10139",
                    "DOI": "10.48550/arXiv.2303.10139",
                    "CorpusId": 257622939
                },
                "corpusId": 257622939,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f945b6788d4042c950e57e6032c0ad122566661e",
                "title": "Distill n' Explain: explaining graph neural networks using simple surrogates",
                "abstract": "Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n' Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faithfulness of explanations.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2061161328",
                        "name": "Tamara A. Pereira"
                    },
                    {
                        "authorId": "2211967383",
                        "name": "Erik Nasciment"
                    },
                    {
                        "authorId": "2164014168",
                        "name": "Lucas Emanuel Resck"
                    },
                    {
                        "authorId": "144128644",
                        "name": "Diego Mesquita"
                    },
                    {
                        "authorId": "3383481",
                        "name": "A. Souza"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "By incorporating the knowledge learned by a more complex model, the student\u2019s performance can be enhanced [15, 26, 33]."
            ],
            "citingPaper": {
                "paperId": "a4437441fdc5aad44b84307f2a7ca3dde0a98fac",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-09843",
                    "ArXiv": "2303.09843",
                    "DOI": "10.48550/arXiv.2303.09843",
                    "CorpusId": 257623097
                },
                "corpusId": 257623097,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a4437441fdc5aad44b84307f2a7ca3dde0a98fac",
                "title": "DUDES: Deep Uncertainty Distillation using Ensembles for Semantic Segmentation",
                "abstract": "Deep neural networks lack interpretability and tend to be overconfident, which poses a serious problem in safety-critical applications like autonomous driving, medical imaging, or machine vision tasks with high demands on reliability. Quantifying the predictive uncertainty is a promising endeavour to open up the use of deep neural networks for such applications. Unfortunately, current available methods are computationally expensive. In this work, we present a novel approach for efficient and reliable uncertainty estimation which we call Deep Uncertainty Distillation using Ensembles for Segmentation (DUDES). DUDES applies student-teacher distillation with a Deep Ensemble to accurately approximate predictive uncertainties with a single forward pass while maintaining simplicity and adaptability. Experimentally, DUDES accurately captures predictive uncertainties without sacrificing performance on the segmentation task and indicates impressive capabilities of identifying wrongly classified pixels and out-of-domain samples on the Cityscapes dataset. With DUDES, we manage to simultaneously simplify and outperform previous work on Deep Ensemble-based Uncertainty Distillation.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "119151932",
                        "name": "S. Landgraf"
                    },
                    {
                        "authorId": "2211968239",
                        "name": "Kira Wursthorn"
                    },
                    {
                        "authorId": "100588507",
                        "name": "M. Hillemann"
                    },
                    {
                        "authorId": "2151274355",
                        "name": "M. Ulrich"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Ensemble models on the other hand, have been shown to be promising teachers from the early work of [9] until recent works in various domains [10, 67, 53, 55] and with techniques to boost the their performance [51, 17, 41]."
            ],
            "citingPaper": {
                "paperId": "01cd6565acfe7b32290fc87980f469489135a6b0",
                "externalIds": {
                    "ArXiv": "2303.08983",
                    "DBLP": "journals/corr/abs-2303-08983",
                    "DOI": "10.48550/arXiv.2303.08983",
                    "CorpusId": 257557702
                },
                "corpusId": 257557702,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/01cd6565acfe7b32290fc87980f469489135a6b0",
                "title": "Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement",
                "abstract": "We propose Dataset Reinforcement, a strategy to improve a dataset once such that the accuracy of any model architecture trained on the reinforced dataset is improved at no additional training cost for users. We propose a Dataset Reinforcement strategy based on data augmentation and knowledge distillation. Our generic strategy is designed based on extensive analysis across CNN- and transformer-based models and performing large-scale study of distillation with state-of-the-art models with various data augmentations. We create a reinforced version of the ImageNet training dataset, called ImageNet+, as well as reinforced datasets CIFAR-100+, Flowers-102+, and Food-101+. Models trained with ImageNet+ are more accurate, robust, and calibrated, and transfer well to downstream tasks (e.g., segmentation and detection). As an example, the accuracy of ResNet-50 improves by 1.7% on the ImageNet validation set, 3.5% on ImageNetV2, and 10.0% on ImageNet-R. Expected Calibration Error (ECE) on the ImageNet validation set is also reduced by 9.9%. Using this backbone with Mask-RCNN for object detection on MS-COCO, the mean average precision improves by 0.8%. We reach similar gains for MobileNets, ViTs, and Swin-Transformers. For MobileNetV3 and Swin-Tiny, we observe significant improvements on ImageNet-R/A/C of up to 20% improved robustness. Models pretrained on ImageNet+ and fine-tuned on CIFAR-100+, Flowers-102+, and Food-101+, reach up to 3.4% improved accuracy. The code, datasets, and pretrained models are available at https://github.com/apple/ml-dr.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2978170",
                        "name": "Fartash Faghri"
                    },
                    {
                        "authorId": "1842915",
                        "name": "H. Pouransari"
                    },
                    {
                        "authorId": "144839857",
                        "name": "Sachin Mehta"
                    },
                    {
                        "authorId": "1682124",
                        "name": "Mehrdad Farajtabar"
                    },
                    {
                        "authorId": "143787583",
                        "name": "Ali Farhadi"
                    },
                    {
                        "authorId": "32371083",
                        "name": "Mohammad Rastegari"
                    },
                    {
                        "authorId": "2577513",
                        "name": "Oncel Tuzel"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "A common criticism of Deep Ensembles is that they are expensive to deploy [14, 25, 50], as the cost scales linearly with the ensemble size."
            ],
            "citingPaper": {
                "paperId": "f70535ca323a471cce13b5724f932197f9bf61bd",
                "externalIds": {
                    "ArXiv": "2303.08010",
                    "DBLP": "journals/corr/abs-2303-08010",
                    "DOI": "10.48550/arXiv.2303.08010",
                    "CorpusId": 257505258
                },
                "corpusId": 257505258,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f70535ca323a471cce13b5724f932197f9bf61bd",
                "title": "Window-Based Early-Exit Cascades for Uncertainty Estimation: When Deep Ensembles are More Efficient than Single Models",
                "abstract": "Deep Ensembles are a simple, reliable, and effective method of improving both the predictive performance and uncertainty estimates of deep learning approaches. However, they are widely criticised as being computationally expensive, due to the need to deploy multiple independent models. Recent work has challenged this view, showing that for predictive accuracy, ensembles can be more computationally efficient (at inference) than scaling single models within an architecture family. This is achieved by cascading ensemble members via an early-exit approach. In this work, we investigate extending these efficiency gains to tasks related to uncertainty estimation. As many such tasks, e.g. selective classification, are binary classification, our key novel insight is to only pass samples within a window close to the binary decision boundary to later cascade stages. Experiments on ImageNet-scale data across a number of network architectures and uncertainty tasks show that the proposed window-based early-exit approach is able to achieve a superior uncertainty-computation trade-off compared to scaling single models. For example, a cascaded EfficientNet-B2 ensemble is able to achieve similar coverage at 5% risk as a single EfficientNet-B4 with<30% the number of MACs. We also find that cascades/ensembles give more reliable improvements on OOD data vs scaling models up. Code for this work is available at: https://github.com/Guoxoug/window-early-exit.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2142129559",
                        "name": "Guoxuan Xia"
                    },
                    {
                        "authorId": "4408876",
                        "name": "C. Bouganis"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "There are various methods (Pearce et al., 2018; Malinin et al., 2019; Abdar et al., 2021) (both Bayesian and non-Bayesian) to combine with model ensembling to estimate confidence."
            ],
            "citingPaper": {
                "paperId": "061f307f1e668977afe309796e87850e5e523f3d",
                "externalIds": {
                    "DOI": "10.3389/frwa.2023.1137110",
                    "CorpusId": 257546352
                },
                "corpusId": 257546352,
                "publicationVenue": {
                    "id": "c6888b3b-68a0-4442-baf9-35708988e0e9",
                    "name": "Frontiers in Water",
                    "alternate_names": [
                        "Front Water"
                    ],
                    "issn": "2624-9375",
                    "url": "https://www.frontiersin.org/journals/water#"
                },
                "url": "https://www.semanticscholar.org/paper/061f307f1e668977afe309796e87850e5e523f3d",
                "title": "Super-resolution and uncertainty estimation from sparse sensors of dynamical physical systems",
                "abstract": "The goal of this study is to leverage emerging machine learning (ML) techniques to develop a framework for the global reconstruction of system variables from potentially scarce and noisy observations and to explore the epistemic uncertainty of these models. This work demonstrates the utility of exploiting the stochasticity of dropout and batch normalization schemes to infer uncertainty estimates of super-resolved field reconstruction from sparse sensor measurements. A Voronoi tessellation strategy is used to obtain a structured-grid representation from sensor observations, thus enabling the use of fully convolutional neural networks (FCNN) for global field estimation. An ensemble-based approach is developed using Monte-Carlo batch normalization (MCBN) and Monte-Carlo dropout (MCD) methods in order to perform approximate Bayesian inference over the neural network parameters, which facilitates the estimation of the epistemic uncertainty of predicted field values. We demonstrate these capabilities through numerical experiments that include sea-surface temperature, soil moisture, and incompressible near-surface flows over a wide range of parameterized flow configurations.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2146719755",
                        "name": "Adam M. Collins"
                    },
                    {
                        "authorId": "1470998618",
                        "name": "Peter Rivera-Casillas"
                    },
                    {
                        "authorId": "2152323186",
                        "name": "Sourav Dutta"
                    },
                    {
                        "authorId": "93830417",
                        "name": "Orie M. Cecil"
                    },
                    {
                        "authorId": "12945504",
                        "name": "A. Trautz"
                    },
                    {
                        "authorId": "35028239",
                        "name": "M. Farthing"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "[15] proposed an ensemble approach to improve the calibration of the model by using the prior networks [14] in the distillation framework."
            ],
            "citingPaper": {
                "paperId": "3662f2dfd415823e2cd97d40dd03a18f15c003a9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-11472",
                    "ArXiv": "2302.11472",
                    "DOI": "10.48550/arXiv.2302.11472",
                    "CorpusId": 257079238
                },
                "corpusId": 257079238,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3662f2dfd415823e2cd97d40dd03a18f15c003a9",
                "title": "Distilling Calibrated Student from an Uncalibrated Teacher",
                "abstract": "Knowledge distillation is a common technique for improving the performance of a shallow student network by transferring information from a teacher network, which in general, is comparatively large and deep. These teacher networks are pre-trained and often uncalibrated, as no calibration technique is applied to the teacher model while training. Calibration of a network measures the probability of correctness for any of its predictions, which is critical in high-risk domains. In this paper, we study how to obtain a calibrated student from an uncalibrated teacher. Our approach relies on the fusion of the data-augmentation techniques, including but not limited to cutout, mixup, and CutMix, with knowledge distillation. We extend our approach beyond traditional knowledge distillation and find it suitable for Relational Knowledge Distillation and Contrastive Representation Distillation as well. The novelty of the work is that it provides a framework to distill a calibrated student from an uncalibrated teacher model without compromising the accuracy of the distilled student. We perform extensive experiments to validate our approach on various datasets, including CIFAR-10, CIFAR-100, CINIC-10 and TinyImageNet, and obtained calibrated student models. We also observe robust performance of our approach while evaluating it on corrupted CIFAR-100C data.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2192863598",
                        "name": "Ishan Mishra"
                    },
                    {
                        "authorId": "2209211723",
                        "name": "Sethu Vamsi Krishna"
                    },
                    {
                        "authorId": "2082316146",
                        "name": "Deepak Mishra"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "\u2026(first-order) categorical distributions P1(\u0398), where\n\u0398 = { \u03b8 = (\u03b81, . . . , \u03b8K) \u2208 [0, 1]K | \u2225\u03b8\u22251 = 1 } (see (Sensoy et al., 2018; Malinin & Gales, 2018; 2019; Malinin et al., 2020b; Charpentier et al., 2020; Huseljic et al., 2020; Kopetzki et al., 2021; Tsiligkaridis, 2021; Bao et al., 2021;\u2026",
                "\u20262019; Malinin et al., 2020b; Charpentier et al., 2020; Huseljic et al., 2020; Kopetzki et al., 2021; Tsiligkaridis, 2021; Bao et al., 2021; Hammam et al., 2022) and regression (Amini et al., 2020; Ma et al., 2021; Malinin et al., 2020a; Charpentier et al., 2022; Oh & Shin, 2022; Pandey & Yu, 2022).",
                "Different loss functions of this kind have been proposed for classification (Sensoy et al., 2018; Malinin & Gales, 2018; 2019; Malinin et al., 2020b; Charpentier et al., 2020; Huseljic et al., 2020; Kopetzki et al., 2021; Tsiligkaridis, 2021; Bao et al., 2021; Hammam et al., 2022) and regression (Amini et al., 2020; Ma et al., 2021; Malinin et al., 2020a; Charpentier et al., 2022; Oh & Shin, 2022; Pandey & Yu, 2022).",
                "Here, the most commonly used\nparameterised class of second-order distributions P2(M) is the set of Dirichlet distributions with parameter space\nM = { m = (m1, . . . ,mK) |mi > 0, i = 1, . . . ,K } having support on the (first-order) categorical distributions P1(\u0398), where\n\u0398 = { \u03b8 = (\u03b81, . . . , \u03b8K) \u2208 [0, 1]K | \u2225\u03b8\u22251 = 1 } (see (Sensoy et al., 2018; Malinin & Gales, 2018; 2019; Malinin et al., 2020b; Charpentier et al., 2020; Huseljic et al., 2020; Kopetzki et al., 2021; Tsiligkaridis, 2021; Bao et al., 2021; Hammam et al., 2022)).",
                "Different loss functions of this kind have been proposed for classification (Sensoy et al., 2018; Malinin & Gales, 2018; 2019; Malinin et al., 2020b; Charpentier et al., 2020; Huseljic et al., 2020; Kopetzki et al., 2021; Tsiligkaridis, 2021; Bao et al., 2021; Hammam et al., 2022) and regression\u2026",
                "Another line of research modifies (8) to the regression setting (Malinin et al., 2020a; Charpentier et al., 2022)."
            ],
            "citingPaper": {
                "paperId": "a55bfa1b4bd4542851b693d4d495392f8f7a681e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2301-12736",
                    "ArXiv": "2301.12736",
                    "DOI": "10.48550/arXiv.2301.12736",
                    "CorpusId": 256389725
                },
                "corpusId": 256389725,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a55bfa1b4bd4542851b693d4d495392f8f7a681e",
                "title": "On Second-Order Scoring Rules for Epistemic Uncertainty Quantification",
                "abstract": "It is well known that accurate probabilistic predictors can be trained through empirical risk minimisation with proper scoring rules as loss functions. While such learners capture so-called aleatoric uncertainty of predictions, various machine learning methods have recently been developed with the goal to let the learner also represent its epistemic uncertainty, i.e., the uncertainty caused by a lack of knowledge and data. An emerging branch of the literature proposes the use of a second-order learner that provides predictions in terms of distributions on probability distributions. However, recent work has revealed serious theoretical shortcomings for second-order predictors based on loss minimisation. In this paper, we generalise these findings and prove a more fundamental result: There seems to be no loss function that provides an incentive for a second-order learner to faithfully represent its epistemic uncertainty in the same manner as proper scoring rules do for standard (first-order) learners. As a main mathematical tool to prove this result, we introduce the generalised notion of second-order scoring rules.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2126870500",
                        "name": "Viktor Bengs"
                    },
                    {
                        "authorId": "1691955",
                        "name": "E. H\u00fcllermeier"
                    },
                    {
                        "authorId": "3249834",
                        "name": "W. Waegeman"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "In general, more models yield better ensemble gains (Malinin, Mlodozeniec, and Gales 2019)."
            ],
            "citingPaper": {
                "paperId": "8e9931c561dbba7227baba58f7b487a5e2b5c676",
                "externalIds": {
                    "ArXiv": "2301.12378",
                    "DBLP": "conf/aaai/LiRYJY023",
                    "DOI": "10.48550/arXiv.2301.12378",
                    "CorpusId": 256390550
                },
                "corpusId": 256390550,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/8e9931c561dbba7227baba58f7b487a5e2b5c676",
                "title": "Towards Inference Efficient Deep Ensemble Learning",
                "abstract": "Ensemble methods can deliver surprising performance gains but also bring significantly higher computational costs, e.g., can be up to 2048X in large-scale ensemble tasks. However, we found that the majority of computations in ensemble methods are redundant. For instance, over 77% of samples in CIFAR-100 dataset can be correctly classified with only a single ResNet-18 model, which indicates that only around 23% of the samples need an ensemble of extra models. To this end, we propose an inference efficient ensemble learning method, to simultaneously optimize for effectiveness and efficiency in ensemble learning. More specifically, we regard ensemble of models as a sequential inference process and learn the optimal halting event for inference on a specific sample. At each timestep of the inference process, a common selector judges if the current ensemble has reached ensemble effectiveness and halt further inference, otherwise filters this challenging sample for the subsequent models to conduct more powerful ensemble. Both the base models and common selector are jointly optimized to dynamically adjust ensemble inference for different samples with various hardness, through the novel optimization goals including sequential ensemble boosting and computation saving. The experiments with different backbones on real-world datasets illustrate our method can bring up to 56% inference cost reduction while maintaining comparable performance to full ensemble, achieving significantly better ensemble utility than other baselines. Code and supplemental materials are available at https://seqml.github.io/irene.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2051629352",
                        "name": "Ziyue Li"
                    },
                    {
                        "authorId": "144931569",
                        "name": "Kan Ren"
                    },
                    {
                        "authorId": "2135622500",
                        "name": "Yifan Yang"
                    },
                    {
                        "authorId": "2046022",
                        "name": "Xinyang Jiang"
                    },
                    {
                        "authorId": "2108623481",
                        "name": "Yuqing Yang"
                    },
                    {
                        "authorId": "2181524288",
                        "name": "Dongsheng Li"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Some methods estimate uncertainty using Bayesian methods [15, 18, 47] and deep ensemble [21,26]."
            ],
            "citingPaper": {
                "paperId": "fa2238778e9f591aa057a82ce64103073b7d3ad4",
                "externalIds": {
                    "DBLP": "conf/cvpr/WangGW23",
                    "ArXiv": "2212.12053",
                    "DOI": "10.1109/CVPR52729.2023.02265",
                    "CorpusId": 255096562
                },
                "corpusId": 255096562,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fa2238778e9f591aa057a82ce64103073b7d3ad4",
                "title": "On Calibrating Semantic Segmentation Models: Analyses and An Algorithm",
                "abstract": "We study the problem of semantic segmentation calibration. Lots of solutions have been proposed to approach model miscalibration of confidence in image classification. However, to date, confidence calibration research on se-mantic segmentation is still limited. We provide a system-atic study on the calibration of semantic segmentation models and propose a simple yet effective approach. First, we find that model capacity, crop size, multi-scale testing, and prediction correctness have impact on calibration. Among them, prediction correctness, especially misprediction, is more important to miscalibration due to over-confidence. Next, we propose a simple, unifying, and effective approach, namely selective scaling, by separating correct/incorrect prediction for scaling and more focusing on misprediction logit smoothing. Then, we study popular existing cali-bration methods and compare them with selective scaling on semantic segmentation calibration. We conduct exten-sive experiments with a variety of benchmarks on both in-domain and domain-shift calibration and show that selective scaling consistently outperforms other methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "49370795",
                        "name": "Dongdong Wang"
                    },
                    {
                        "authorId": "40206014",
                        "name": "Boqing Gong"
                    },
                    {
                        "authorId": "49681507",
                        "name": "Liqiang Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Malinin & Gales (2018); Malinin et al. (2020); Sensoy et al. (2018); Charpentier et al. (2020) assume the classifier outputs are sampled from a latent Dirichlet distribution and treat low-likelihood samples as misclassified samples."
            ],
            "citingPaper": {
                "paperId": "2cc2864b2ee3b5cd34bb73be79619ff4cff906cd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-16466",
                    "ArXiv": "2211.16466",
                    "DOI": "10.48550/arXiv.2211.16466",
                    "CorpusId": 251793313
                },
                "corpusId": 251793313,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2cc2864b2ee3b5cd34bb73be79619ff4cff906cd",
                "title": "Birds of a Feather Trust Together: Knowing When to Trust a Classifier via Adaptive Neighborhood Aggregation",
                "abstract": "How do we know when the predictions made by a classifier can be trusted? This is a fundamental problem that also has immense practical applicability, especially in safety-critical areas such as medicine and autonomous driving. The de facto approach of using the classifier's softmax outputs as a proxy for trustworthiness suffers from the over-confidence issue; while the most recent works incur problems such as additional retraining cost and accuracy versus trustworthiness trade-off. In this work, we argue that the trustworthiness of a classifier's prediction for a sample is highly associated with two factors: the sample's neighborhood information and the classifier's output. To combine the best of both worlds, we design a model-agnostic post-hoc approach NeighborAgg to leverage the two essential information via an adaptive neighborhood aggregation. Theoretically, we show that NeighborAgg is a generalized version of a one-hop graph convolutional network, inheriting the powerful modeling ability to capture the varying similarity between samples within each class. We also extend our approach to the closely related task of mislabel detection and provide a theoretical coverage guarantee to bound the false negative. Empirically, extensive experiments on image and tabular benchmarks verify our theory and suggest that NeighborAgg outperforms other methods, achieving state-of-the-art trustworthiness performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "38827926",
                        "name": "Miao Xiong"
                    },
                    {
                        "authorId": "2153699643",
                        "name": "Shen Li"
                    },
                    {
                        "authorId": "145948356",
                        "name": "Wenjie Feng"
                    },
                    {
                        "authorId": "2063950812",
                        "name": "Ailin Deng"
                    },
                    {
                        "authorId": "2154499886",
                        "name": "Jihai Zhang"
                    },
                    {
                        "authorId": "2019961",
                        "name": "Bryan Hooi"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Some of the works also explore training a single Student model from an ensemble of networks to achieve higher performance with fewer computations [26], [27], [28], [29]."
            ],
            "citingPaper": {
                "paperId": "2feb0ba48e157cad5fe88be487bbbd16f249823e",
                "externalIds": {
                    "DBLP": "journals/pami/YeB23",
                    "DOI": "10.1109/TPAMI.2022.3220928",
                    "CorpusId": 253445548,
                    "PubMed": "36355745"
                },
                "corpusId": 253445548,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2feb0ba48e157cad5fe88be487bbbd16f249823e",
                "title": "Dynamic Self-Supervised Teacher-Student Network Learning",
                "abstract": "Lifelong learning (LLL) represents the ability of an artificial intelligence system to learn successively a sequence of different databases. In this paper we introduce the Dynamic Self-Supervised Teacher-Student Network (D-TS), representing a more general LLL framework, where the Teacher is implemented as a dynamically expanding mixture model which automatically increases its capacity to deal with a growing number of tasks. We propose the Knowledge Discrepancy Score (KDS) criterion for measuring the relevance of the incoming information characterizing a new task when compared to the existing knowledge accumulated by the Teacher module from its previous training. The KDS ensures a light Teacher architecture while also enabling to reuse the learned knowledge whenever appropriate, accelerating the learning of given tasks. The Student module is implemented as a lightweight probabilistic generative model. We introduce a novel self-supervised learning procedure for the Student that allows to capture cross-domain latent representations from the entire knowledge accumulated by the Teacher as well as from novel data. We perform several experiments which show that D-TS can achieve the state of the art results in LLL while requiring fewer parameters than other methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145371423",
                        "name": "Fei Ye"
                    },
                    {
                        "authorId": "1707271",
                        "name": "A. Bors"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "5f6a5f319aca3f3d3f7a3c7c1ef0b8fc97ee1458",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-00683",
                    "ArXiv": "2211.00683",
                    "DOI": "10.48550/arXiv.2211.00683",
                    "CorpusId": 253254911
                },
                "corpusId": 253254911,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5f6a5f319aca3f3d3f7a3c7c1ef0b8fc97ee1458",
                "title": "Reduce, Reuse, Recycle: Improving Training Efficiency with Distillation",
                "abstract": "Methods for improving the ef\ufb01ciency of deep network training (i.e. the resources required to achieve a given level of model quality) are of immediate bene\ufb01t to deep learning practitioners. Distillation is typically used to compress models or improve model quality, but it\u2019s unclear if distillation actually improves training ef\ufb01ciency . Can the quality improvements of distillation be converted into training speed-ups, or do they simply increase \ufb01nal model quality with no resource savings? We conducted a series of experiments to investigate whether and how distillation can be used to accelerate training using ResNet-50 trained on ImageNet and BERT trained on C4 with a masked language modeling objective and evaluated on GLUE, using common enterprise hardware (8x NVIDIA A100). We found that distillation can speed up training by up to 1.96x in ResNet-50 trained on ImageNet and up to 1.42x on BERT when evaluated on GLUE. Furthermore, distillation for BERT yields optimal results when it is only performed for the \ufb01rst 20-50% of training. We also observed that training with distillation is almost always more ef\ufb01cient than training without distillation, even when using the poorest-quality model as a teacher, in both ResNet-50 and BERT. Finally, we found that it\u2019s possible to gain the bene\ufb01t of distilling from an ensemble of teacher models, which has O ( n ) runtime cost, by randomly sampling a single teacher from the pool of teacher models on each step, which only has a O (1) runtime cost. Taken together, these results show that distillation can substantially improve training ef\ufb01ciency in both image classi\ufb01cation and language modeling, and that a few simple optimizations to distillation protocols can further enhance these ef\ufb01ciency improvements.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "73066558",
                        "name": "Cody Blakeney"
                    },
                    {
                        "authorId": "39774809",
                        "name": "J. Forde"
                    },
                    {
                        "authorId": "25581960",
                        "name": "Jonathan Frankle"
                    },
                    {
                        "authorId": "36491005",
                        "name": "Ziliang Zong"
                    },
                    {
                        "authorId": "2028252288",
                        "name": "Matthew L. Leavitt"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "f512915070e5f3c51dae4148d90931bf33f2d4bc",
                "externalIds": {
                    "DBLP": "journals/symmetry/WangLZY22",
                    "DOI": "10.3390/sym14112285",
                    "CorpusId": 253322846
                },
                "corpusId": 253322846,
                "publicationVenue": {
                    "id": "1620da87-4387-4b9a-9bf4-22fdf74d4dc3",
                    "name": "Symmetry",
                    "type": "journal",
                    "issn": "2073-8994",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-172134",
                    "alternate_urls": [
                        "https://www.mdpi.com/journal/symmetry",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-172134"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f512915070e5f3c51dae4148d90931bf33f2d4bc",
                "title": "Speech Enhancement Model Synthesis Based on Federal Learning for Industrial CPS in Multiple Noise Conditions",
                "abstract": "Real-time acquisition of industrial production data and rapid response to changes in the external environment are key to ensuring the symmetry of a CPS. However, during industrial production, the collected data are inevitably disturbed by environmental noise, which has a huge impact on the subsequent data processing of a CPS. The types of noise vary greatly in different work scenarios in a factory. Meanwhile, barriers such as data privacy protection and copyright restrictions create great difficulties for model synthesis in the information space. A speech enhancement model with teacher\u2013student architecture based on federal knowledge distillation is proposed to alleviate this problem. (1) We pre-train teacher models under different noise conditions to create multiple teacher models with symmetry and excelling in the suppression of a priori noise. (2) We construct a symmetric model\u2013student model of the physical space of the teacher model trained on public data and transfer the knowledge of the teacher model to the student model. The student model can suppress multiple types of noise. Notably, with the TIMIT dataset and the NoiseX92 noise set, the accuracy of the proposed method improved by an average of 1.00% over the randomly specified teacher method in the PESQ metric and 0.17% for STOI.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2119044714",
                        "name": "Kunpeng Wang"
                    },
                    {
                        "authorId": "2154002583",
                        "name": "Wenjing Lu"
                    },
                    {
                        "authorId": "2190037208",
                        "name": "Hao Zhou"
                    },
                    {
                        "authorId": "2109802953",
                        "name": "Juan Yao"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "dbbe6620b9dd63911f0720416239e8ec56a12105",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-09767",
                    "ArXiv": "2210.09767",
                    "DOI": "10.1088/1742-6596/2438/1/012088",
                    "CorpusId": 252968084
                },
                "corpusId": 252968084,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/dbbe6620b9dd63911f0720416239e8ec56a12105",
                "title": "Generative models uncertainty estimation",
                "abstract": "In recent years fully-parametric fast simulation methods based on generative models have been proposed for a variety of high-energy physics detectors. By their nature, the quality of data-driven models degrades in the regions of the phase space where the data are sparse. Since machine-learning models are hard to analyse from the physical principles, the commonly used testing procedures are performed in a data-driven way and can\u2019t be reliably used in such regions. In our work we propose three methods to estimate the uncertainty of generative models inside and outside of the training phase space region, along with data-driven calibration techniques. A test of the proposed methods on the LHCb RICH fast simulation is also presented.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "7723787",
                        "name": "L. Anderlini"
                    },
                    {
                        "authorId": "2188051672",
                        "name": "Constantine Chimpoesh"
                    },
                    {
                        "authorId": "3258069",
                        "name": "N. Kazeev"
                    },
                    {
                        "authorId": "2188056826",
                        "name": "Agata Shishigina"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "As a result, over the past several years the area of knowledge distillation has gained increasing attention (Hinton et al., 2015; Freitag et al., 2017; Malinin et al., 2019; Lin et al., 2020; Park et al., 2021; Zhao et al., 2022)."
            ],
            "citingPaper": {
                "paperId": "c244894409078405fedf4b42a4ee7e556362bfb3",
                "externalIds": {
                    "ArXiv": "2210.01973",
                    "DBLP": "journals/corr/abs-2210-01973",
                    "DOI": "10.48550/arXiv.2210.01973",
                    "CorpusId": 252715943
                },
                "corpusId": 252715943,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c244894409078405fedf4b42a4ee7e556362bfb3",
                "title": "Meta-Ensemble Parameter Learning",
                "abstract": "Ensemble of machine learning models yields improved performance as well as robustness. However, their memory requirements and inference costs can be prohibitively high. Knowledge distillation is an approach that allows a single model to efficiently capture the approximate performance of an ensemble while showing poor scalability as demand for re-training when introducing new teacher models. In this paper, we study if we can utilize the meta-learning strategy to directly predict the parameters of a single model with comparable performance of an ensemble. Hereto, we introduce WeightFormer, a Transformer-based model that can predict student network weights layer by layer in a forward pass, according to the teacher model parameters. The proprieties of WeightFormer are investigated on the CIFAR-10, CIFAR-100, and ImageNet datasets for model structures of VGGNet-11, ResNet-50, and ViT-B/32, where it demonstrates that our method can achieve approximate classification performance of an ensemble and outperforms both the single network and standard knowledge distillation. More encouragingly, we show that WeightFormer results can further exceeds average ensemble with minor fine-tuning. Importantly, our task along with the model and results can potentially lead to a new, more efficient, and scalable paradigm of ensemble networks parameter learning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2066415714",
                        "name": "Zhengcong Fei"
                    },
                    {
                        "authorId": "23115478",
                        "name": "Shuman Tian"
                    },
                    {
                        "authorId": "1753492",
                        "name": "Junshi Huang"
                    },
                    {
                        "authorId": "50652918",
                        "name": "Xiaoming Wei"
                    },
                    {
                        "authorId": "49141839",
                        "name": "Xiaolin Wei"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "e70b0125850fede5729421ea58c08b3afbc81d5a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-05522",
                    "ArXiv": "2209.05522",
                    "DOI": "10.48550/arXiv.2209.05522",
                    "CorpusId": 252211985
                },
                "corpusId": 252211985,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e70b0125850fede5729421ea58c08b3afbc81d5a",
                "title": "TEDL: A Two-stage Evidential Deep Learning Method for Classification Uncertainty Quantification",
                "abstract": "In this paper, we propose TEDL, a two-stage learning approach to quantify uncertainty for deep learning models in classification tasks, inspired by our findings in experimenting with Evidential Deep Learning (EDL) method, a recently proposed uncertainty quantification approach based on the Dempster-Shafer theory. More specifically, we observe that EDL tends to yield inferior AUC compared with models learnt by cross-entropy loss and is highly sensitive in training. Such sensitivity is likely to cause unreliable uncertainty estimation, making it risky for practical applications. To mitigate both limitations, we propose a simple yet effective two-stage learning approach based on our analysis on the likely reasons causing such sensitivity, with the first stage learning from cross-entropy loss, followed by a second stage learning from EDL loss. We also re-formulate the EDL loss by replacing ReLU with ELU to avoid the Dying ReLU issue. Extensive experiments are carried out on varied sized training corpus collected from a large-scale commercial search engine, demonstrating that the proposed two-stage learning framework can increase AUC significantly and greatly improve training robustness.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48569160",
                        "name": "Xue Li"
                    },
                    {
                        "authorId": null,
                        "name": "Wei Shen"
                    },
                    {
                        "authorId": "36730993",
                        "name": "Denis Xavier Charles"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "7113113fcecb6eded2d2f88a698e04cf4b28b0fd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-03302",
                    "ArXiv": "2209.03302",
                    "DOI": "10.48550/arXiv.2209.03302",
                    "CorpusId": 252111030
                },
                "corpusId": 252111030,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/7113113fcecb6eded2d2f88a698e04cf4b28b0fd",
                "title": "Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning: Are Conditional Entropy and Mutual Information Appropriate Measures?",
                "abstract": "The quantification of aleatoric and epistemic uncertainty in terms of conditional entropy and mutual information, respectively, has recently become quite common in machine learning. While the properties of these measures, which are rooted in information theory, seem appealing at first glance, we identify various incoherencies that call their appropriateness into question. In addition to the measures themselves, we critically discuss the idea of an additive decomposition of total uncertainty into its aleatoric and epistemic constituents. Experiments across different computer vision tasks support our theoretical findings and raise concerns about current practice in uncertainty quantification.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1691955",
                        "name": "E. H\u00fcllermeier"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "From the literature on Bayesian networks we can borrow a more informative metric: the mutual information (MI) between the model distribution and the output distribution [44]."
            ],
            "citingPaper": {
                "paperId": "ec8ec9ae0d515e3abbbe0f020adabc732694bb0c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-14195",
                    "ArXiv": "2208.14195",
                    "DOI": "10.48550/arXiv.2208.14195",
                    "CorpusId": 251692050
                },
                "corpusId": 251692050,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ec8ec9ae0d515e3abbbe0f020adabc732694bb0c",
                "title": "Probing Contextual Diversity for Dense Out-of-Distribution Detection",
                "abstract": "Detection of out-of-distribution (OoD) samples in the context of image classification has recently become an area of interest and active study, along with the topic of uncertainty estimation, to which it is closely related. In this paper we explore the task of OoD segmentation, which has been studied less than its classification counterpart and presents additional challenges. Segmentation is a dense prediction task for which the model's outcome for each pixel depends on its surroundings. The receptive field and the reliance on context play a role for distinguishing different classes and, correspondingly, for spotting OoD entities. We introduce MOoSe, an efficient strategy to leverage the various levels of context represented within semantic segmentation models and show that even a simple aggregation of multi-scale representations has consistently positive effects on OoD detection and uncertainty estimation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "36011789",
                        "name": "Silvio Galesso"
                    },
                    {
                        "authorId": "31693758",
                        "name": "M. A. Bravo"
                    },
                    {
                        "authorId": "2101627469",
                        "name": "Mehdi Naouar"
                    },
                    {
                        "authorId": "1710872",
                        "name": "T. Brox"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "This problem can be well handled by using an additional assistant model [39], distilling intermediate features [33], multiple teacher models [49], and the ensemble of distributions [36]."
            ],
            "citingPaper": {
                "paperId": "c72c32f55577fe497261b54ac982641ef4de27a2",
                "externalIds": {
                    "ArXiv": "2208.12464",
                    "DBLP": "journals/corr/abs-2208-12464",
                    "DOI": "10.48550/arXiv.2208.12464",
                    "CorpusId": 251881704
                },
                "corpusId": 251881704,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c72c32f55577fe497261b54ac982641ef4de27a2",
                "title": "Data-free Dense Depth Distillation",
                "abstract": "We study data-free knowledge distillation (KD) for monocular depth estimation (MDE), which learns a lightweight model for real-world depth perception tasks by compressing it from a trained teacher model while lacking training data in the target domain. Owing to the essential difference between image classification and dense regression, previous methods of data-free KD are not applicable to MDE. To strengthen its applicability in real-world tasks, in this paper, we propose to apply KD with out-of-distribution simulated images. The major challenges to be resolved are i) lacking prior information about object distribution of real-world training data, and ii) domain shift between simulated and real-world images. To cope with these difficulties, we propose a tailored framework for depth distillation. The framework generates new training samples for maximally covering distributed patterns of objects in the target domain and utilizes a transformation network to efficiently adapt them to the feature statistics preserved in the teacher model. Through extensive experiments on various depth estimation models and two different datasets, we show that our method outperforms the baseline KD by a good margin and even achieves slightly better performance with as few as 1/6 of training images, demonstrating a clear superiority.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1409846329",
                        "name": "Junjie Hu"
                    },
                    {
                        "authorId": "2047692",
                        "name": "Chenyou Fan"
                    },
                    {
                        "authorId": "2159942",
                        "name": "M. Ozay"
                    },
                    {
                        "authorId": "1490773707",
                        "name": "Hualie Jiang"
                    },
                    {
                        "authorId": "35337770",
                        "name": "Tin Lun Lam"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "The idea of distillation from the ensemble of model for uncertainty estimation is also investigated [8, 26, 29, 30]."
            ],
            "citingPaper": {
                "paperId": "9556d2d5d8178265c576662f342adca2e4cac14e",
                "externalIds": {
                    "DBLP": "journals/cviu/LeePSK23",
                    "ArXiv": "2208.05642",
                    "DOI": "10.48550/arXiv.2208.05642",
                    "CorpusId": 251493147
                },
                "corpusId": 251493147,
                "publicationVenue": {
                    "id": "5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                    "name": "Computer Vision and Image Understanding",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Vis Image Underst"
                    ],
                    "issn": "1077-3142",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/10773142",
                        "http://www.idealibrary.com/links/toc/cviu",
                        "https://www.journals.elsevier.com/computer-vision-and-image-understanding"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9556d2d5d8178265c576662f342adca2e4cac14e",
                "title": "Self-Knowledge Distillation via Dropout",
                "abstract": "To boost the performance, deep neural networks require deeper or wider network structures that involve massive computational and memory costs. To alleviate this issue, the self-knowledge distillation method regularizes the model by distilling the internal knowledge of the model itself. Conventional self-knowledge distillation methods require additional trainable parameters or are dependent on the data. In this paper, we propose a simple and effective self-knowledge distillation method using a dropout (SD-Dropout). SD-Dropout distills the posterior distributions of multiple models through a dropout sampling. Our method does not require any additional trainable modules, does not rely on data, and requires only simple operations. Furthermore, this simple method can be easily combined with various self-knowledge distillation approaches. We provide a theoretical and experimental analysis of the effect of forward and reverse KL-divergences in our work. Extensive experiments on various vision tasks, i.e., image classification, object detection, and distribution shift, demonstrate that the proposed method can effectively improve the generalization of a single network. Further experiments show that the proposed method also improves calibration performance, adversarial robustness, and out-of-distribution detection ability.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2181205795",
                        "name": "Hyoje Lee"
                    },
                    {
                        "authorId": "1388732668",
                        "name": "Yeachan Park"
                    },
                    {
                        "authorId": "2065450823",
                        "name": "Hyun Seo"
                    },
                    {
                        "authorId": "2259103",
                        "name": "Myung-joo Kang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "metrics based on ROC [18] or Rejection-Accuracy curves [10, 14]), however, it has already been observed that these metrics favour models that have higher test accuracy [4, 21].",
                "A recently proposed metric that allows comparison of different models in this aspect, agnostic to their individual accuracy, is Prediction Rejection Ratio (PRR) [21].",
                "The PRR ranges from -1 to 1.",
                "On ImageNet-R, the only model with positive PRR is Swin-L, and the models with highest negative PRR are ConvNeXt-XL and L, followed by BiT-R50x1 and 101x1.",
                "\u25e6 The fact that several models are severely overconfident and wrong on\nImageNet-R (PRR) while showing low calibration errors indicate that the calibration analysis should be complemented with experiments such as misclassification detection to understand their reliability.",
                "This is captured by the sign of PRR (reported in %)."
            ],
            "citingPaper": {
                "paperId": "6f48988fd4237f599bf158a5210c70b3c15f1a16",
                "externalIds": {
                    "ArXiv": "2207.11347",
                    "DBLP": "journals/corr/abs-2207-11347",
                    "DOI": "10.48550/arXiv.2207.11347",
                    "CorpusId": 251040759
                },
                "corpusId": 251040759,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/6f48988fd4237f599bf158a5210c70b3c15f1a16",
                "title": "An Impartial Take to the CNN vs Transformer Robustness Contest",
                "abstract": "Following the surge of popularity of Transformers in Computer Vision, several studies have attempted to determine whether they could be more robust to distribution shifts and provide better uncertainty estimates than Convolutional Neural Networks (CNNs). The almost unanimous conclusion is that they are, and it is often conjectured more or less explicitly that the reason of this supposed superiority is to be attributed to the self-attention mechanism. In this paper we perform extensive empirical analyses showing that recent state-of-the-art CNNs (particularly, ConvNeXt) can be as robust and reliable or even sometimes more than the current state-of-the-art Transformers. However, there is no clear winner. Therefore, although it is tempting to state the definitive superiority of one family of architectures over another, they seem to enjoy similar extraordinary performances on a variety of tasks while also suffering from similar vulnerabilities such as texture, background, and simplicity biases.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2088918572",
                        "name": "Francesco Pinto"
                    },
                    {
                        "authorId": "143635540",
                        "name": "Philip H. S. Torr"
                    },
                    {
                        "authorId": "144679302",
                        "name": "P. Dokania"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Disentangling these two sources of uncertainty is generally non-trivial [56] and ensemble methods are usually superior [23,52].",
                "Yet, the best performing approaches are computationally expensive [45], while faster variants struggle to disentangle different types of uncertainty [23,52,56]."
            ],
            "citingPaper": {
                "paperId": "036e538d7b5a0711612eeebbeec2c132e66da538",
                "externalIds": {
                    "ArXiv": "2207.10130",
                    "DBLP": "journals/corr/abs-2207-10130",
                    "DOI": "10.48550/arXiv.2207.10130",
                    "CorpusId": 250921065
                },
                "corpusId": 250921065,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/036e538d7b5a0711612eeebbeec2c132e66da538",
                "title": "Latent Discriminant deterministic Uncertainty",
                "abstract": "Predictive uncertainty estimation is essential for deploying Deep Neural Networks in real-world autonomous systems. However, most successful approaches are computationally intensive. In this work, we attempt to address these challenges in the context of autonomous driving perception tasks. Recently proposed Deterministic Uncertainty Methods (DUM) can only partially meet such requirements as their scalability to complex computer vision tasks is not obvious. In this work we advance a scalable and effective DUM for high-resolution semantic segmentation, that relaxes the Lipschitz constraint typically hindering practicality of such architectures. We learn a discriminant latent space by leveraging a distinction maximization layer over an arbitrarily-sized set of trainable prototypes. Our approach achieves competitive results over Deep Ensembles, the state-of-the-art for uncertainty prediction, on image classification, segmentation and monocular depth estimation tasks. Our code is available at https://github.com/ENSTA-U2IS/LDU",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "31664866",
                        "name": "G. Franchi"
                    },
                    {
                        "authorId": "2151681175",
                        "name": "Xuanlong Yu"
                    },
                    {
                        "authorId": "3056236",
                        "name": "Andrei Bursuc"
                    },
                    {
                        "authorId": "2486147",
                        "name": "Emanuel Aldea"
                    },
                    {
                        "authorId": "1701986",
                        "name": "S\u00e9verine Dubuisson"
                    },
                    {
                        "authorId": "2057090949",
                        "name": "David Filliat"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "The knowledge of stochastic DNNs such as ensemble networks or MC dropout is distilled to a deterministic DNN [22], [23].",
                "In this paper, we present ModelNet, a deterministic sampling-free DNN that distills the knowledge of a stochastic DNN and estimates model uncertainty of object detection, both spatial and semantic uncertainty, with small computational cost.",
                "This paper makes following key contributions:\n\u2022 We propose ModelNet, a deterministic sampling-free DNN that distills the predictive distribution of a stochastic DNN and allows to quantify spatial/semantic model uncertainty of an object detector.",
                "We are considering ModelNet in SSD Mobilenet-v1 which provides both detection and uncertainty predictions (IV-D1) in this section, but task DNN with ModelNet as uncertainty assistant (IV-D2) also can be employed.",
                "Bayesian inference using dropout in neural networks (MC dropout) [16], [17] has been suggested to model epistemic uncertainty through a standard DNN training procedures and expanded to object detection in [18], [19].",
                "The distribution over predictive distribution of stochastic DNNs is approximated to maintain the information of diversity in stochastic DNNs and estimate model uncertainty [24], [27].",
                "Monte Carlo based dropout [16] is suggested to approximate the Bayesian inference through a standard DNN training procedures.",
                "This paper proposes ModelNet that estimates model uncertainty of a complex DNN based object detection without storing N models or running N forward passes.",
                "1, we first implement a stochastic DNN, MC dropout model specifically, from a target task model to quantify the model uncertainty of the task.",
                "Some prior works adopt knowledge distillation [21] and achieve model uncertainty estimation with low complexity [22]\u2013[24], but these works are limited on classification tasks or semantic uncertainty estimation.",
                "Therefore, many other efforts seek to reduce the computational cost and utilize existing DNN framework [10], [11], [13].",
                "ModelNet adopts the concept of distilling predictive distribution of stochastic DNN [24], [27], and extends it for object detection to estimate the spatial and semantic uncertainties of multiple objects.",
                "However, it requires a significant modification of training procedures, excessive computational cost, and also not scalable to existing DNN architecture with largescale dataset."
            ],
            "citingPaper": {
                "paperId": "8c58f674ddd3ad0f13fbabfa0dc4235205bbf096",
                "externalIds": {
                    "DBLP": "conf/ijcnn/LeeMM22",
                    "DOI": "10.1109/IJCNN55064.2022.9892795",
                    "CorpusId": 252626162
                },
                "corpusId": 252626162,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/8c58f674ddd3ad0f13fbabfa0dc4235205bbf096",
                "title": "Lightweight Model Uncertainty Estimation for Deep Neural Object Detection",
                "abstract": "Quantifying model uncertainty of Deep Neural Network (DNN) is important to understand the reliability of the model prediction and avoid risks in safety critical applications. Various approaches, including Bayesian neural networks, Monte-Carlo dropout, and ensembles, are suggested to measure the model uncertainty; but with huge computational cost. We present ModelNet, an Artificial Neural Network (ANN) that can estimate spatial/semantic model uncertainties of a DNN based object detection with less computation overhead. ModelNet is a deterministic ANN that distills the predictive distribution of stochastic DNN. Experimental results show that ModelNet can learn the uncertainty estimation from stochastic DNN in various architectures. ModelNet can perform as a probabilistic object detector with 39x-179x less number of operations, or as an uncertainty assistant to a task network with 1.4x more parameters and 38x less number of operations compared to stochastic DNN. Moreover, a case study of uncertainty driven adaptive sensor using ModelNet is presented.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109448257",
                        "name": "Minah Lee"
                    },
                    {
                        "authorId": "2167197",
                        "name": "B. Mudassar"
                    },
                    {
                        "authorId": "144192725",
                        "name": "S. Mukhopadhyay"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "gence metric for distillation is forward KL (FKL) divergence in Equation (2), while reverse KL divergence (RKL), which exchanges the two distributions in Equation (2), is recommended in prior work in dealing with out-of-distribution data [3], [27]."
            ],
            "citingPaper": {
                "paperId": "ff337a373bdfa6a5c900bbf27d3499e28e048469",
                "externalIds": {
                    "DBLP": "conf/ijcnn/SunZ22",
                    "DOI": "10.1109/IJCNN55064.2022.9892503",
                    "CorpusId": 252625336
                },
                "corpusId": 252625336,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/ff337a373bdfa6a5c900bbf27d3499e28e048469",
                "title": "Ensemble Policy Distillation with Reduced Data Distribution Mismatch",
                "abstract": "Policy distillation is a method for model compression for deep reinforcement learning, which is typically applied onto mobile devices to reduce power consumption and inference time. However, achieving full and stable distilled policies is challenging, which impedes higher compression ratios. In this work, we develop two policy distillation algorithms to address this problem. Our first algorithm, Ensemble Policy Distillation (EPD), incorporates the idea from supervised learning distillation that uses an ensemble of teacher networks to provide diverse supervision for a compact student policy network. In the Deep Q-Network (DQN) framework, our experiments verify that highly compressed student networks distilled using EPD even outperform teachers for numerous Atari games. Additionally, we analyze how the issue of data distribution mismatch caused by the teacher ensemble in EPD negatively impacts teachers' learning, and introduce the second algorithm, Double Policy Distillation (DPD), as a novel method to mitigate the distribution mismatch. Empirical results show that DPD improves both the teachers' learning and the student's distillation in Atari games and continuous control tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2156048697",
                        "name": "Yuxiang Sun"
                    },
                    {
                        "authorId": "49346854",
                        "name": "Qi Zhang"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "This intuition tends to be demonstrated on toy, low-dimensional data [24, 26].",
                "Deep Ensembles [19] are ensembles of DNNs trained on the same dataset with different random parameter initialisations and data shuffling, \u0398={\u03b8(m)}Mm=1.",
                "com/Guoxoug/ens-div-ood-detect diversity of a Deep Ensemble is an intrinsic indicator of input distributional shift, as the members will disagree more on data that are further away from training data [24, 26].",
                "Deep Ensembles [19] have been shown to reliably be superior for OOD detection compared to single models [17, 24, 31].",
                "They have been shown to be a reliable and scalable approach for improving both the predictive performance and quality of uncertainty estimates of DNNs [19, 24, 28, 31].",
                "Thus, uncertainty scores U directly derived from diversity should be useful for OOD detection [24, 26, 31].",
                "Note that we will avoid the discussion of epistemic and aleatoric uncertainty [14,24,26,29] in this work and instead directly focus the discussion on the task of OOD detection."
            ],
            "citingPaper": {
                "paperId": "abda2ee2e89b2e9734e7b29bbadce9c8952b8e43",
                "externalIds": {
                    "ArXiv": "2207.07517",
                    "DBLP": "journals/corr/abs-2207-07517",
                    "DOI": "10.48550/arXiv.2207.07517",
                    "CorpusId": 250607825
                },
                "corpusId": 250607825,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/abda2ee2e89b2e9734e7b29bbadce9c8952b8e43",
                "title": "On the Usefulness of Deep Ensemble Diversity for Out-of-Distribution Detection",
                "abstract": "The ability to detect Out-of-Distribution (OOD) data is important in safety-critical applications of deep learning. The aim is to separate In-Distribution (ID) data drawn from the training distribution from OOD data using a measure of uncertainty extracted from a deep neural network. Deep Ensembles are a well-established method of improving the quality of uncertainty estimates produced by deep neural networks, and have been shown to have superior OOD detection performance compared to single models. An existing intuition in the literature is that the diversity of Deep Ensemble predictions indicates distributional shift, and so measures of diversity such as Mutual Information (MI) should be used for OOD detection. We show experimentally that this intuition is not valid on ImageNet-scale OOD detection -- using MI leads to 30-40% worse %FPR@95 compared to single-model entropy on some OOD datasets. We suggest an alternative explanation for Deep Ensembles' better OOD detection performance -- OOD detection is binary classification and we are ensembling diverse classifiers. As such we show that practically, even better OOD detection performance can be achieved for Deep Ensembles by averaging task-specific detection scores such as Energy over the ensemble.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2142129559",
                        "name": "Guoxuan Xia"
                    },
                    {
                        "authorId": "4408876",
                        "name": "C. Bouganis"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "35cc22754293d678dc94cd5148c9f446c9f7e54f",
                "externalIds": {
                    "DBLP": "conf/accv/XiaB22",
                    "ArXiv": "2207.07506",
                    "DOI": "10.48550/arXiv.2207.07506",
                    "CorpusId": 250607832
                },
                "corpusId": 250607832,
                "publicationVenue": {
                    "id": "a8f26d13-e373-4e48-b57b-ef89bf48f4db",
                    "name": "Asian Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Asian Conf Comput Vis",
                        "ACCV"
                    ],
                    "url": "http://www.cvl.iis.u-tokyo.ac.jp/afcv/"
                },
                "url": "https://www.semanticscholar.org/paper/35cc22754293d678dc94cd5148c9f446c9f7e54f",
                "title": "Augmenting Softmax Information for Selective Classification with Out-of-Distribution Data",
                "abstract": "Detecting out-of-distribution (OOD) data is a task that is receiving an increasing amount of research attention in the domain of deep learning for computer vision. However, the performance of detection methods is generally evaluated on the task in isolation, rather than also considering potential downstream tasks in tandem. In this work, we examine selective classification in the presence of OOD data (SCOD). That is to say, the motivation for detecting OOD samples is to reject them so their impact on the quality of predictions is reduced. We show under this task specification, that existing post-hoc methods perform quite differently compared to when evaluated only on OOD detection. This is because it is no longer an issue to conflate in-distribution (ID) data with OOD data if the ID data is going to be misclassified. However, the conflation within ID data of correct and incorrect predictions becomes undesirable. We also propose a novel method for SCOD, Softmax Information Retaining Combination (SIRC), that augments softmax-based confidence scores with feature-agnostic information such that their ability to identify OOD samples is improved without sacrificing separation between correct and incorrect ID predictions. Experiments on a wide variety of ImageNet-scale datasets and convolutional neural network architectures show that SIRC is able to consistently match or outperform the baseline for SCOD, whilst existing OOD detection methods fail to do so.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2142129559",
                        "name": "Guoxuan Xia"
                    },
                    {
                        "authorId": "4408876",
                        "name": "C. Bouganis"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", 2020), or treating predictions from teachers as a set of samples from an implicit distribution (Malinin et al., 2020; Ryabinin et al., 2021), or amplifying the diversity via input perturbations (Nam et al.",
                "\u2026inside the ensemble teacher, e.g., dynamically assign weights to teachers (Du et al., 2020), or treating predictions from teachers as a set of samples from an implicit distribution (Malinin et al., 2020; Ryabinin et al., 2021), or amplifying the diversity via input perturbations (Nam et al., 2021)."
            ],
            "citingPaper": {
                "paperId": "073fd972ead074b9898ecb443670edc233f78cec",
                "externalIds": {
                    "ArXiv": "2206.15047",
                    "DBLP": "conf/icml/NamLH022",
                    "DOI": "10.48550/arXiv.2206.15047",
                    "CorpusId": 250144631
                },
                "corpusId": 250144631,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/073fd972ead074b9898ecb443670edc233f78cec",
                "title": "Improving Ensemble Distillation With Weight Averaging and Diversifying Perturbation",
                "abstract": "Ensembles of deep neural networks have demonstrated superior performance, but their heavy computational cost hinders applying them for resource-limited environments. It motivates distilling knowledge from the ensemble teacher into a smaller student network, and there are two important design choices for this ensemble distillation: 1) how to construct the student network, and 2) what data should be shown during training. In this paper, we propose a weight averaging technique where a student with multiple subnetworks is trained to absorb the functional diversity of ensemble teachers, but then those subnetworks are properly averaged for inference, giving a single student network with no additional inference cost. We also propose a perturbation strategy that seeks inputs from which the diversities of teachers can be better transferred to the student. Combining these two, our method significantly improves upon previous methods on various image classification tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2065197138",
                        "name": "G. Nam"
                    },
                    {
                        "authorId": "2110211216",
                        "name": "Hyungi Lee"
                    },
                    {
                        "authorId": "3086596",
                        "name": "Byeongho Heo"
                    },
                    {
                        "authorId": "2124954802",
                        "name": "Juho Lee"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[10] Andrey Malinin, Bruno Mlodozeniec, and Mark JF Gales, \u201cEnsemble distribution distillation,\u201d in International Conference on Learning Representations, 2020.",
                "The main downside of ensembles is their computational and memory cost, but there has been work on overcoming this limitation [10, 34, 35].",
                "Until recently most work on uncertainty estimation[10, 6, 11, 12, 13, 14, 15] and robust generalisation has focused on small- and medium-scale image and text classification tasks, such as MNIST [16], SVHN [17], and CIFAR10/100 [18]."
            ],
            "citingPaper": {
                "paperId": "018d5734d36372d4f60eb8129da9fa90c549fd42",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-15407",
                    "ArXiv": "2206.15407",
                    "DOI": "10.48550/arXiv.2206.15407",
                    "CorpusId": 250144845
                },
                "corpusId": 250144845,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/018d5734d36372d4f60eb8129da9fa90c549fd42",
                "title": "Shifts 2.0: Extending The Dataset of Real Distributional Shifts",
                "abstract": "Distributional shift, or the mismatch between training and deployment data, is a significant obstacle to the usage of machine learning in high-stakes industrial applications, such as autonomous driving and medicine. This creates a need to be able to assess how robustly ML models generalize as well as the quality of their uncertainty estimates. Standard ML baseline datasets do not allow these properties to be assessed, as the training, validation and test data are often identically distributed. Recently, a range of dedicated benchmarks have appeared, featuring both distributionally matched and shifted data. Among these benchmarks, the Shifts dataset stands out in terms of the diversity of tasks as well as the data modalities it features. While most of the benchmarks are heavily dominated by 2D image classification tasks, Shifts contains tabular weather forecasting, machine translation, and vehicle motion prediction tasks. This enables the robustness properties of models to be assessed on a diverse set of industrial-scale tasks and either universal or directly applicable task-specific conclusions to be reached. In this paper, we extend the Shifts Dataset with two datasets sourced from industrial, high-risk applications of high societal importance. Specifically, we consider the tasks of segmentation of white matter Multiple Sclerosis lesions in 3D magnetic resonance brain images and the estimation of power consumption in marine cargo vessels. Both tasks feature ubiquitous distributional shifts and a strict safety requirement due to the high cost of errors. These new datasets will allow researchers to further explore robust generalization and uncertainty estimation in new situations. In this work, we provide a description of the dataset and baseline results for both tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    },
                    {
                        "authorId": "46176323",
                        "name": "A. Athanasopoulos"
                    },
                    {
                        "authorId": "3129878",
                        "name": "M. Barakovic"
                    },
                    {
                        "authorId": "6466939",
                        "name": "M. Cuadra"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    },
                    {
                        "authorId": "2829265",
                        "name": "C. Granziera"
                    },
                    {
                        "authorId": "35228947",
                        "name": "Mara Graziani"
                    },
                    {
                        "authorId": "1680575764",
                        "name": "N. Kartashev"
                    },
                    {
                        "authorId": "2423002",
                        "name": "K. Kyriakopoulos"
                    },
                    {
                        "authorId": "1739134502",
                        "name": "Po-Jui Lu"
                    },
                    {
                        "authorId": "2072760044",
                        "name": "N. Molchanova"
                    },
                    {
                        "authorId": "2553217",
                        "name": "A. Nikitakis"
                    },
                    {
                        "authorId": "2119533381",
                        "name": "Vatsal Raina"
                    },
                    {
                        "authorId": "145784381",
                        "name": "F. Rosa"
                    },
                    {
                        "authorId": "2174178247",
                        "name": "Eli Sivena"
                    },
                    {
                        "authorId": "30650342",
                        "name": "V. Tsarsitalidis"
                    },
                    {
                        "authorId": "2174179618",
                        "name": "Efi Tsompopoulou"
                    },
                    {
                        "authorId": "98703333",
                        "name": "E. Volf"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Table 1: Predictive performance, RMSE\nDataset Single EnsembleSGB SGLB KGB SGB SGLB KGB Boston 3.06 3.12 2.81 3.04 3.10 2.82 Concrete 5.21 5.11 4.36 5.21 5.10 4.30 Energy 0.57 0.54 0.33 0.57 0.54 0.33 Kin8nm 0.14 0.14 0.11 0.14 0.14 0.10 Naval 0.00 0.00 0.00 0.00 0.00 0.00 Power 3.55 3.56 3.48 3.52 3.54 3.43 Protein 3.99 3.99 3.79 3.99 3.99 3.76 Wine 0.63 0.63 0.61 0.63 0.63 0.60 Yacht 0.82 0.84 0.52 0.83 0.84 0.50 Year 8.99 8.96 8.97 8.97 8.93 8.94\nTable 2: Error and OOD detection\nDataset PRR AUCSGB SGLB KGB SGB SGLB KGB Boston 36 37 43 80 80 88 Concrete 29 29 37 92 92 93 Energy 36 31 60 100 100 99 Kin8nm 18 19 20 45 45 41 Naval 55 56 35 100 100 100 Power 8 9 31 72 73 76 Protein 30 29 35 99 99 100 Wine 25 19 37 74 72 87 Yacht 74 78 86 62 60 69 Year 30 30 32 67 57 71\nExperiment on real datasets Uncertainty estimates for GBDTs have been previously analyzed by Malinin et al. (2021).",
                "PRR measures how well uncertainty estimates correlate with errors and rank-order them.",
                "Detecting errors can be evaluated via the Prediction-Rejection Ratio (PRR) (Malinin, 2019; Malinin et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "0136cc23c0f6e6c1f2647f1190a9978b3b7396b5",
                "externalIds": {
                    "DBLP": "conf/iclr/UstimenkoBP23",
                    "ArXiv": "2206.05608",
                    "CorpusId": 252873695
                },
                "corpusId": 252873695,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0136cc23c0f6e6c1f2647f1190a9978b3b7396b5",
                "title": "Gradient Boosting Performs Gaussian Process Inference",
                "abstract": "This paper shows that gradient boosting based on symmetric decision trees can be equivalently reformulated as a kernel method that converges to the solution of a certain Kernel Ridge Regression problem. Thus, we obtain the convergence to a Gaussian Process' posterior mean, which, in turn, allows us to easily transform gradient boosting into a sampler from the posterior to provide better knowledge uncertainty estimates through Monte-Carlo estimation of the posterior variance. We show that the proposed sampler allows for better knowledge uncertainty estimates leading to improved out-of-domain detection.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "146211662",
                        "name": "Aleksei Ustimenko"
                    },
                    {
                        "authorId": "2170076216",
                        "name": "Artem Beliakov"
                    },
                    {
                        "authorId": "51270819",
                        "name": "L. Prokhorenkova"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "In [25] the authors address this by using an auxiliary unsupervised dataset, as we can get diverse ensemble predictions on this dataset and use it to train our distilled model.",
                "While some previous works tried to address this issue [25, 28], they either depended on additional unsupervised data that might not be readily available, e.",
                "We compare our method against the following baselines: (1) EnDD [25], Ensemble Distribution Distillation framework, trained with the same train data used to capture the ensemble.",
                "While this was done in [9, 25], there are several limitations with these approaches.",
                "We show that for our method the mixup adds a significant boost to performance, and also for EnDD on two out of three datasets.",
                "(2) EnDDAUX [25], Ensemble Distribution Distillation framework, trained with the train data and an auxiliary dataset.",
                "It is interesting to note that while EnDDAUX uses additional unlabeled examples from the training distribution (between 50k and 100k), FED is on par and often outperforms this baseline across all metrics.",
                "EnDD builds on the method in [24] which tries to emulate the behaviour of an ensemble with a Dirichlet distribution parameterized by a NN.",
                "Ensemble Distribution Distillation (EnDD) [25] was the first to propose such an approach.",
                "We propose an ensemble distillation [15, 25] method that mimics an ensemble of models using a lightweight model.",
                "We take a similar approach to [9, 25] where we treat the ensemble distillation as a conditional generative model.",
                "We also show results for out-of-distribution (OOD) detection in Figure 3 using ROC curves (EnDD was excluded due to poor performance), To score the examples we used the knowledge uncertainty which is obtained by subtracting the aleatoric uncertainty from the total uncertainty [10, 25].",
                "We also see that even when EnDD is trained with mixup, our approach returns better accuracy, ECE and also has greater diversity.",
                "Thus, we show results for both FED and EnDD trained on the training set and on the mixup dataset as the auxiliary dataset.",
                "Both [25, 9] are suitable for classification tasks only and assume a Dirichlet distribution behaviour which may be too restrictive."
            ],
            "citingPaper": {
                "paperId": "02dcaa744d3d96d68b85b2e89758276d94747ea5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-02183",
                    "ArXiv": "2206.02183",
                    "DOI": "10.48550/arXiv.2206.02183",
                    "CorpusId": 249395304
                },
                "corpusId": 249395304,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/02dcaa744d3d96d68b85b2e89758276d94747ea5",
                "title": "Functional Ensemble Distillation",
                "abstract": "Bayesian models have many desirable properties, most notable is their ability to generalize from limited data and to properly estimate the uncertainty in their predictions. However, these benefits come at a steep computational cost as Bayesian inference, in most cases, is computationally intractable. One popular approach to alleviate this problem is using a Monte-Carlo estimation with an ensemble of models sampled from the posterior. However, this approach still comes at a significant computational cost, as one needs to store and run multiple models at test time. In this work, we investigate how to best distill an ensemble's predictions using an efficient model. First, we argue that current approaches that simply return distribution over predictions cannot compute important properties, such as the covariance between predictions, which can be valuable for further processing. Second, in many limited data settings, all ensemble members achieve nearly zero training loss, namely, they produce near-identical predictions on the training set which results in sub-optimal distilled models. To address both problems, we propose a novel and general distillation approach, named Functional Ensemble Distillation (FED), and we investigate how to best distill an ensemble in this setting. We find that learning the distilled model via a simple augmentation scheme in the form of mixup augmentation significantly boosts the performance. We evaluated our method on several tasks and showed that it achieves superior results in both accuracy and uncertainty estimation compared to current approaches.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2168254973",
                        "name": "Coby Penso"
                    },
                    {
                        "authorId": "1452343136",
                        "name": "Idan Achituve"
                    },
                    {
                        "authorId": "2645055",
                        "name": "Ethan Fetaya"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "145d23a93534102089ea0db477a848214f6940c7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-00774",
                    "ArXiv": "2206.00774",
                    "DOI": "10.1109/ICDCS54860.2022.00062",
                    "CorpusId": 249282214
                },
                "corpusId": 249282214,
                "publicationVenue": {
                    "id": "ffe5bb5c-04ed-488e-985d-d3a7b39542cf",
                    "name": "IEEE International Conference on Distributed Computing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Distributed Computing Systems",
                        "IEEE Int Conf Distrib Comput Syst",
                        "Int Conf Device Circuit Syst",
                        "ICDCS",
                        "Int Conf Distrib Comput Syst",
                        "International Conference on Devices, Circuits and Systems"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000213/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/145d23a93534102089ea0db477a848214f6940c7",
                "title": "Distributed Training for Deep Learning Models On An Edge Computing Network Using Shielded Reinforcement Learning",
                "abstract": "With the emergence of edge devices along with their local computation advantage over the cloud, distributed deep learning (DL) training on edge nodes becomes promising. In such a method, the cluster head of a cluster of edge nodes schedules all the DL training jobs from the cluster nodes. Using such a centralized scheduling method, the cluster head knows all the loads of the cluster nodes, which can avoid overloading the cluster nodes, but the head itself may become overloaded. To handle this problem, we first propose a multi-agent RL (MARL) system that enables each edge node to schedule its own jobs using RL. However, without the coordination between the nodes, action collision may occur, in which multiple nodes may schedule tasks to the same node and make it overloaded. To avoid these problems, we propose a system called Shielded ReinfOrcement learning (RL) based DL training on Edges (SROLE). In SROLE, each edge node schedules its own jobs using multi-agent RL. The shield deployed in a node checks action collisions and provides alternative actions to avoid the collisions. As the central shield node for the entire cluster may become a bottleneck, we further propose a decentralized shielding method, in which different shields are responsible for different regions in the cluster and they coordinate to avoid action collisions on the region boundaries. Our container-based emulation experiments show that SROLE reduces training time by up to 59% with 29% lower median resource utilization and reduces the number of action collisions by up to 48% compared to multi-agent RL and the centralized RL. Our real device experiments show that SROLE still reduces the training time by up to 53% with 28% lower median resource utilization than multi-agent RL and the centralized RL.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "144303062",
                        "name": "Tanmoy Sen"
                    },
                    {
                        "authorId": "37217705",
                        "name": "Haiying Shen"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "In distillation of uncertainty, Malinin et al. (2019) propose EnDD by using a prior network (Malinin & Gales, 2018) as the student, however, their approach requires further finetuning on auxiliary data to fully capture the ensemble\u2019s uncertainty and it works only for classification problems."
            ],
            "citingPaper": {
                "paperId": "e0a34688fe15ebbf792fbb995ead1bb00536804b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-09526",
                    "ArXiv": "2205.09526",
                    "DOI": "10.48550/arXiv.2205.09526",
                    "CorpusId": 248887455
                },
                "corpusId": 248887455,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e0a34688fe15ebbf792fbb995ead1bb00536804b",
                "title": "Simple Regularisation for Uncertainty-Aware Knowledge Distillation",
                "abstract": "Considering uncertainty estimation of modern neural networks (NNs) is one of the most important steps towards deploying machine learning systems to meaningful real-world applications such as in medicine, finance or autonomous systems. At the moment, ensembles of different NNs constitute the state-of-the-art in both accuracy and uncertainty estimation in different tasks. However, ensembles of NNs are unpractical under real-world constraints, since their computation and memory consumption scale linearly with the size of the ensemble, which increase their latency and deployment cost. In this work, we examine a simple regularisation approach for distribution-free knowledge distillation of ensemble of machine learning models into a single NN. The aim of the regularisation is to preserve the diversity, accuracy and uncertainty estimation characteristics of the original ensemble without any intricacies, such as fine-tuning. We demonstrate the generality of the approach on combinations of toy data, SVHN/CIFAR-10, simple to complex NN architectures and different tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "100998451",
                        "name": "Martin Ferianc"
                    },
                    {
                        "authorId": "2087097383",
                        "name": "Miguel L. Rodrigues"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Ensemble distillation uses multiple teachers to improve accuracy in vision and other applications [3, 17, 34, 36, 40]."
            ],
            "citingPaper": {
                "paperId": "f7c14da93c099ef54c47bd122064a653c3e7d320",
                "externalIds": {
                    "ArXiv": "2205.06265",
                    "DBLP": "journals/corr/abs-2205-06265",
                    "DOI": "10.48550/arXiv.2205.06265",
                    "CorpusId": 248722029
                },
                "corpusId": 248722029,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f7c14da93c099ef54c47bd122064a653c3e7d320",
                "title": "ELODI: Ensemble Logit Difference Inhibition for Positive-Congruent Training",
                "abstract": "Negative flips are errors introduced in a classification system when a legacy model is replaced with a new one. Existing methods to reduce the negative flip rate (NFR) either do so at the expense of overall accuracy using model distillation, or use ensembles, which multiply inference cost prohibitively. We present a method to train a classification system that achieves paragon performance in both error rate and NFR, at the inference cost of a single model. Our method introduces a generalized distillation objective, Logit Difference Inhibition (LDI), that penalizes changes in the logits between the new and old model, without forcing them to coincide as in ordinary distillation. LDI affords the model flexibility to reduce error rate along with NFR. The method uses a homogeneous ensemble as the reference model for LDI, hence the name Ensemble LDI, or ELODI. The reference model can then be substituted with a single model at inference time. The method leverages the observation that negative flips are typically not close to the decision boundary, but often exhibit large deviations in the distance among their logits, which are reduced by ELODI.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2116810910",
                        "name": "Yue Zhao"
                    },
                    {
                        "authorId": "49746184",
                        "name": "Yantao Shen"
                    },
                    {
                        "authorId": "3331521",
                        "name": "Yuanjun Xiong"
                    },
                    {
                        "authorId": "123363188",
                        "name": "Shuo Yang"
                    },
                    {
                        "authorId": "2150080071",
                        "name": "Wei Xia"
                    },
                    {
                        "authorId": "144035504",
                        "name": "Z. Tu"
                    },
                    {
                        "authorId": "2164988951",
                        "name": "Bernt Shiele"
                    },
                    {
                        "authorId": "2075295257",
                        "name": "S. Soatto"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", distillation of an ensemble into a single model [28])."
            ],
            "citingPaper": {
                "paperId": "42f6f95393850bc6fa2346423444fee4c5e400ef",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-01982",
                    "ArXiv": "2205.01982",
                    "DOI": "10.48550/arXiv.2205.01982",
                    "CorpusId": 248512552
                },
                "corpusId": 248512552,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/42f6f95393850bc6fa2346423444fee4c5e400ef",
                "title": "Lifelong Ensemble Learning based on Multiple Representations for Few-Shot Object Recognition",
                "abstract": "Service robots are integrating more and more into our daily lives to help us with various tasks. In such environments, robots frequently face new objects while working in the environment and need to learn them in an open-ended fashion. Furthermore, such robots must be able to recognize a wide range of object categories. In this paper, we present a lifelong ensemble learning approach based on multiple representations to address the few-shot object recognition problem. In particular, we form ensemble methods based on deep representations and handcrafted 3D shape descriptors. To facilitate lifelong learning, each approach is equipped with a memory unit for storing and retrieving object information instantly. The proposed model is suitable for open-ended learning scenarios where the number of 3D object categories is not fixed and can grow over time. We have performed extensive sets of experiments to assess the performance of the proposed approach in offline, and open-ended scenarios. For the evaluation purpose, in addition to real object datasets, we generate a large synthetic household objects dataset consisting of 27000 views of 90 objects. Experimental results demonstrate the effectiveness of the proposed method on online few-shot 3D object recognition tasks, as well as its superior performance over the state-of-the-art open-ended learning approaches. Furthermore, our results show that while ensemble learning is modestly beneficial in offline settings, it is significantly beneficial in lifelong few-shot learning situations. Additionally, we demonstrated the effectiveness of our approach in both simulated and real-robot settings, where the robot rapidly learned new categories from limited examples.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "69533920",
                        "name": "H. Kasaei"
                    },
                    {
                        "authorId": "2057611300",
                        "name": "Songsong Xiong"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "Typical examples of Dirichlet distribution [69], [82] and subjective opinion.",
                "alleviate overconfidence problem [33], [69], [82].",
                "Ensemble distribution distillation [69] obtains the Dirichlet distribution by distillation from the predictions of multiple models.",
                "To capture the predictive uncertainty for single view, the Dirichlet distribution is considered to provide more trusted predictions [33], [69],",
                "Recently, uncertainty estimation algorithms based on Dirichlet distribution [22], [33], [68], [69], [70] have been proposed."
            ],
            "citingPaper": {
                "paperId": "c9a5eda332c49b5490a03da4b25fa8c1a9882e0c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-11423",
                    "ArXiv": "2204.11423",
                    "DOI": "10.1109/TPAMI.2022.3171983",
                    "CorpusId": 248377660,
                    "PubMed": "35503823"
                },
                "corpusId": 248377660,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c9a5eda332c49b5490a03da4b25fa8c1a9882e0c",
                "title": "Trusted Multi-View Classification With Dynamic Evidential Fusion",
                "abstract": "Existing multi-view classification algorithms focus on promoting accuracy by exploiting different views, typically integrating them into common representations for follow-up tasks. Although effective, it is also crucial to ensure the reliability of both the multi-view integration and the final decision, especially for noisy, corrupted and out-of-distribution data. Dynamically assessing the trustworthiness of each view for different samples could provide reliable integration. This can be achieved through uncertainty estimation. With this in mind, we propose a novel multi-view classification algorithm, termed trusted multi-view classification (TMC), providing a new paradigm for multi-view learning by dynamically integrating different views at an evidence level. The proposed TMC can promote classification reliability by considering evidence from each view. Specifically, we introduce the variational Dirichlet to characterize the distribution of the class probabilities, parameterized with evidence from different views and integrated with the Dempster-Shafer theory. The unified learning framework induces accurate uncertainty and accordingly endows the model with both reliability and robustness against possible noise or corruption. Both theoretical and experimental results validate the effectiveness of the proposed model in accuracy, robustness and trustworthiness.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1396788118",
                        "name": "Zongbo Han"
                    },
                    {
                        "authorId": "144704038",
                        "name": "Changqing Zhang"
                    },
                    {
                        "authorId": "1929093",
                        "name": "H. Fu"
                    },
                    {
                        "authorId": "10638646",
                        "name": "Joey Tianyi Zhou"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "It is observed that in case of ensemble models PRR due to total uncertainty is higher than knowledge uncertainty which is consistent with the observations in other studies.(12,21)",
                "Epistemic (knowledge) uncertainty is estimated as dispersion or \u201cdisagreement\u201d level of the model within the ensemble.(21)",
                "A higher value of PRR suggests that the model can recognize and reject inaccurate predictions based upon uncertainty measures.(21)",
                "The error can be evaluated by Prediction-Rejection-Ratio (PRR) which ranks the uncertainty estimation values with error margins.(21) A higher value of PRR suggests that the model can recognize and reject inaccurate predictions based upon uncertainty measures."
            ],
            "citingPaper": {
                "paperId": "e33d2074be09ce336b5ddf259eb97a6322e8a09f",
                "externalIds": {
                    "DOI": "10.1117/12.2612621",
                    "CorpusId": 247883640
                },
                "corpusId": 247883640,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e33d2074be09ce336b5ddf259eb97a6322e8a09f",
                "title": "Uncertainty estimation in classification of MGMT using radiogenomics for glioblastoma patients",
                "abstract": "Glioblastoma Multiforme (GBM) is one of the most malignant brain tumors among all high-grade brain cancers. Temozolomide (TMZ) is the first-line chemotherapeutic regimen for glioblastoma patients. The methylation status of the O6-methylguanine-DNA-methyltransferase (MGMT) gene is a prognostic biomarker for tumor sensitivity to TMZ chemotherapy. However, the standardized procedure for assessing the methylation status of MGMT is an invasive surgical biopsy, and accuracy is susceptible to resection sample and heterogeneity of the tumor. Recently, radio-genomics which associates radiological image phenotype with genetic or molecular mutations has shown promise in the non-invasive assessment of radiotherapeutic treatment. This study proposes a machine-learning framework for MGMT classification with uncertainty analysis utilizing imaging features extracted from multimodal magnetic resonance imaging (mMRI). The imaging features include conventional texture, volumetric, and sophisticated fractal, and multi-resolution fractal texture features. The proposed method is evaluated with publicly available BraTS-TCIA-GBM pre-operative scans and TCGA datasets with 114 patients. The experiment with 10-fold cross-validation suggests that the fractal and multi-resolution fractal texture features offer an improved prediction of MGMT status. The uncertainty analysis using an ensemble of Stochastic Gradient Langevin Boosting models along with multi-resolution fractal features offers an accuracy of 71.74% and area under the curve of 0.76. Finally, analysis shows that our proposed method with uncertainty analysis offers improved predictive performance when compared with different well-known methods in the literature.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "97664738",
                        "name": "W. Farzana"
                    },
                    {
                        "authorId": "19175431",
                        "name": "Z. A. Shboul"
                    },
                    {
                        "authorId": "3234383",
                        "name": "A. Temtam"
                    },
                    {
                        "authorId": "1759819",
                        "name": "K. Iftekharuddin"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "Ensemble distillation Recently, there has been a growing interest in approximating the probabilistic output of an ensemble by a single model [2, 15, 18, 21].",
                "The computational challenges have prompted work on producing a single model to approximate the output of an ensemble; so called \u201censemble distillation\u201d [2, 15, 18, 21].",
                "Most of the focus has been on classification [15, 18], where the goal is to predict the class of the image.",
                "Lack of structure in distillation methods Previous methods focus on: classification problems [15, 18], approximating only the mean of the ensemble [2], or modelling independent per-pixel variance [21]."
            ],
            "citingPaper": {
                "paperId": "b68af3efab24cfb6b113f2452f9928ecd86ca2eb",
                "externalIds": {
                    "ArXiv": "2203.15485",
                    "DBLP": "conf/cvpr/SimpsonVC22",
                    "DOI": "10.1109/CVPR52688.2022.00046",
                    "CorpusId": 247778380
                },
                "corpusId": 247778380,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b68af3efab24cfb6b113f2452f9928ecd86ca2eb",
                "title": "Learning Structured Gaussians to Approximate Deep Ensembles",
                "abstract": "This paper proposes using a sparse-structured multivari-ate Gaussian to provide a closed-form approximator for the output of probabilistic ensemble models used for dense im-age prediction tasks. This is achieved through a convolutional neural network that predicts the mean and covari-ance of the distribution, where the inverse covariance is parameterised by a sparsely structured Cholesky matrix. Similarly to distillation approaches, our single network is trained to maximise the probability of samples from pre-trained probabilistic models, in this work we use a fixed en-semble of networks. Once trained, our compact represen-tation can be used to efficiently draw spatially correlated samples from the approximated output distribution. Impor-tantly, this approach captures the uncertainty and struc-tured correlations in the predictions explicitly in a formal distribution, rather than implicitly through sampling alone. This allows direct introspection of the model, enabling vi-sualisation of the learned structure. Moreover, this formu-lation provides two further benefits: estimation of a sample probability, and the introduction of arbitrary spatial conditioning at test time. We demonstrate the merits of our approach on monocular depth estimation and show that the advantages of our approach are obtained with comparable quantitative performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "144377239",
                        "name": "Ivor J. A. Simpson"
                    },
                    {
                        "authorId": "144773105",
                        "name": "S. Vicente"
                    },
                    {
                        "authorId": "2036351",
                        "name": "N. Campbell"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "To tackle this issue ensemble distribution distillation (En2D) was developed [Malinin et al., 2020].",
                "This integrated training allows the user to bypass training a separate expensive teacher ensemble while distribution distillation [Malinin et al., 2020] allows the student to capture the diversity and model a distribution over ensemble member predictions.",
                "Furthermore, since the Dirichlet distribution has bounded ability to represent diverse ensemble predictions [Malinin et al., 2020], simply generating multiple teacher prediction by propagating through the last layer will not be the limiting factor in this model."
            ],
            "citingPaper": {
                "paperId": "f9a7eeb6f477e0b6d137c3c73f36b59af064e773",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-08295",
                    "ArXiv": "2203.08295",
                    "DOI": "10.48550/arXiv.2203.08295",
                    "CorpusId": 247476304
                },
                "corpusId": 247476304,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/f9a7eeb6f477e0b6d137c3c73f36b59af064e773",
                "title": "Self-Distribution Distillation: Efficient Uncertainty Estimation",
                "abstract": "Deep learning is increasingly being applied in safety-critical domains. For these scenarios it is important to know the level of uncertainty in a model's prediction to ensure appropriate decisions are made by the system. Deep ensembles are the de-facto standard approach to obtaining various measures of uncertainty. However, ensembles often significantly increase the resources required in the training and/or deployment phases. Approaches have been developed that typically address the costs in one of these phases. In this work we propose a novel training approach, self-distribution distillation (S2D), which is able to efficiently train a single model that can estimate uncertainties. Furthermore it is possible to build ensembles of these models and apply hierarchical ensemble distillation approaches. Experiments on CIFAR-100 showed that S2D models outperformed standard models and Monte-Carlo dropout. Additional out-of-distribution detection experiments on LSUN, Tiny ImageNet, SVHN showed that even a standard deep ensemble can be outperformed using S2D based ensembles and novel distilled models.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1400414048",
                        "name": "Yassir Fathullah"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "L2 : \u2206 (2) K \u00d7 Y \u2212\u2192 R+ (5) comparing level-2 predictions Q(x) with level-0 observations y, so that minimising L2 on the training data D yields a \u201cgood\u201d level-2 predictor? This is the basic idea of direct epistemic uncertainty prediction [22, 18, 19, 20, 3, 11, 15].",
                "Yet another quite popular idea is to estimate uncertainty in a more direct way, and to let the learner itself predict, not only the target variable, but also its own uncertainty about the prediction [22, 18, 19, 20, 3, 11, 15]."
            ],
            "citingPaper": {
                "paperId": "4e70f6cb2bed6fb67d15d088df4399aee008a58d",
                "externalIds": {
                    "DBLP": "conf/nips/BengsHW22",
                    "ArXiv": "2203.06102",
                    "CorpusId": 252873697
                },
                "corpusId": 252873697,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/4e70f6cb2bed6fb67d15d088df4399aee008a58d",
                "title": "Pitfalls of Epistemic Uncertainty Quantification through Loss Minimisation",
                "abstract": "Uncertainty quantification has received increasing attention in machine learning in the recent past. In particular, a distinction between aleatoric and epistemic uncertainty has been found useful in this regard. The latter refers to the learner's (lack of) knowledge and appears to be especially difficult to measure and quantify. In this paper, we analyse a recent proposal based on the idea of a second-order learner, which yields predictions in the form of distributions over probability distributions. While standard (first-order) learners can be trained to predict accurate probabilities, namely by minimising suitable loss functions on sample data, we show that loss minimisation does not work for second-order predictors: The loss functions proposed for inducing such predictors do not incentivise the learner to represent its epistemic uncertainty in a faithful way.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2126870500",
                        "name": "Viktor Bengs"
                    },
                    {
                        "authorId": "1691955",
                        "name": "E. H\u00fcllermeier"
                    },
                    {
                        "authorId": "3249834",
                        "name": "W. Waegeman"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "These key and challenging requirements have stimulated numerous solutions and research directions leading to significant progress in the estimation of DNNs uncertainty [4, 15, 17, 25, 27, 30, 31, 32, 50]."
            ],
            "citingPaper": {
                "paperId": "597502527f507ad2a07aba4d6061b7620e449dac",
                "externalIds": {
                    "DBLP": "conf/bmvc/FranchiYBTKDAF22",
                    "ArXiv": "2203.01437",
                    "DOI": "10.48550/arXiv.2203.01437",
                    "CorpusId": 247223083
                },
                "corpusId": 247223083,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/597502527f507ad2a07aba4d6061b7620e449dac",
                "title": "MUAD: Multiple Uncertainties for Autonomous Driving benchmark for multiple uncertainty types and tasks",
                "abstract": "Predictive uncertainty estimation is essential for safe deployment of Deep Neural Networks in real-world autonomous systems. However, disentangling the different types and sources of uncertainty is non trivial for most datasets, especially since there is no ground truth for uncertainty. In addition, while adverse weather conditions of varying intensities can disrupt neural network predictions, they are usually under-represented in both training and test sets in public datasets.We attempt to mitigate these setbacks and introduce the MUAD dataset (Multiple Uncertainties for Autonomous Driving), consisting of 10,413 realistic synthetic images with diverse adverse weather conditions (night, fog, rain, snow), out-of-distribution objects, and annotations for semantic segmentation, depth estimation, object, and instance detection. MUAD allows to better assess the impact of different sources of uncertainty on model performance. We conduct a thorough experimental study of this impact on several baseline Deep Neural Networks across multiple tasks, and release our dataset to allow researchers to benchmark their algorithm methodically in adverse conditions. More visualizations and the download link for MUAD are available at https://muad-dataset.github.io/.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "31664866",
                        "name": "G. Franchi"
                    },
                    {
                        "authorId": "2151681175",
                        "name": "Xuanlong Yu"
                    },
                    {
                        "authorId": "3056236",
                        "name": "Andrei Bursuc"
                    },
                    {
                        "authorId": "2154764884",
                        "name": "R'emi Kazmierczak"
                    },
                    {
                        "authorId": "1701986",
                        "name": "S\u00e9verine Dubuisson"
                    },
                    {
                        "authorId": "2486147",
                        "name": "Emanuel Aldea"
                    },
                    {
                        "authorId": "2057090949",
                        "name": "David Filliat"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "\u2026prediction over multiple base predictors through Bayesian neural network (Mackay, 1992; Gal and Ghahramani, 2016; Kendall and Gal, 2017; Malinin and Gales, 2018; Maddox et al., 2019) or ensemble methods (Lakshminarayanan et al., 2016; Ovadia et al., 2019; Huang et al., 2017; Malinin et al., 2019)."
            ],
            "citingPaper": {
                "paperId": "5d0fab8771f3f564ba7f081ad8d597eb8d7d028d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2202-11091",
                    "ArXiv": "2202.11091",
                    "CorpusId": 247025626
                },
                "corpusId": 247025626,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/5d0fab8771f3f564ba7f081ad8d597eb8d7d028d",
                "title": "Efficient and Differentiable Conformal Prediction with General Function Classes",
                "abstract": "Quantifying the data uncertainty in learning tasks is often done by learning a prediction interval or prediction set of the label given the input. Two commonly desired properties for learned prediction sets are \\emph{valid coverage} and \\emph{good efficiency} (such as low length or low cardinality). Conformal prediction is a powerful technique for learning prediction sets with valid coverage, yet by default its conformalization step only learns a single parameter, and does not optimize the efficiency over more expressive function classes. In this paper, we propose a generalization of conformal prediction to multiple learnable parameters, by considering the constrained empirical risk minimization (ERM) problem of finding the most efficient prediction set subject to valid empirical coverage. This meta-algorithm generalizes existing conformal prediction algorithms, and we show that it achieves approximate valid population coverage and near-optimal efficiency within class, whenever the function class in the conformalization step is low-capacity in a certain sense. Next, this ERM problem is challenging to optimize as it involves a non-differentiable coverage constraint. We develop a gradient-based algorithm for it by approximating the original constrained ERM using differentiable surrogate losses and Lagrangians. Experiments show that our algorithm is able to learn valid prediction sets and improve the efficiency significantly over existing approaches in several applications such as prediction intervals with improved length, minimum-volume prediction sets for multi-output regression, and label prediction sets for image classification.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "8681368",
                        "name": "Yu Bai"
                    },
                    {
                        "authorId": "2068869988",
                        "name": "Song Mei"
                    },
                    {
                        "authorId": "46507194",
                        "name": "Haiquan Wang"
                    },
                    {
                        "authorId": "2118860628",
                        "name": "Yingbo Zhou"
                    },
                    {
                        "authorId": "2228109",
                        "name": "Caiming Xiong"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "In recent years, many methods [15]\u2013[19] have been studied to quantify aleatoric uncertainty."
            ],
            "citingPaper": {
                "paperId": "54a195d54691a9ea7200b701703f2ec63b98e1f0",
                "externalIds": {
                    "ArXiv": "2202.06596",
                    "DBLP": "conf/ijcnn/ZhengYGZZJ22",
                    "DOI": "10.1109/IJCNN55064.2022.9892767",
                    "CorpusId": 246822733
                },
                "corpusId": 246822733,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/54a195d54691a9ea7200b701703f2ec63b98e1f0",
                "title": "Deep Monte Carlo Quantile Regression for Quantifying Aleatoric Uncertainty in Physics-informed Temperature Field Reconstruction",
                "abstract": "For the temperature field reconstruction (TFR), a complex image-to-image regression problem, the convolutional neural network (CNN) is a powerful surrogate model due to the convolutional layer's good image feature extraction ability. However, a lot of labeled data is needed to train CNN, and the common CNN can not quantify the aleatoric uncertainty caused by data noise. In actual engineering, the noiseless and labeled training data is hardly obtained for the TFR. To solve these two problems, this paper proposes a deep Monte Carlo quantile regression (Deep MC-QR) method for reconstructing the temperature field and quantifying aleatoric uncertainty caused by data noise. On the one hand, the Deep MC-QR method uses physical knowledge to guide the training of CNN. Thereby, the Deep MC-QR method can reconstruct an accurate TFR surrogate model without any labeled training data. On the other hand, the Deep MC-QR method constructs a quantile level image for each input in each training epoch. Then, the trained CNN model can quantify aleatoric uncertainty by quantile level image sampling during the prediction stage. Finally, the effectiveness of the proposed Deep MC-QR method is validated by many experiments, and the influence of data noise on TFR is analyzed.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "151482819",
                        "name": "Xiaohu Zheng"
                    },
                    {
                        "authorId": "2114975709",
                        "name": "W. Yao"
                    },
                    {
                        "authorId": "2063906333",
                        "name": "Zhiqiang Gong"
                    },
                    {
                        "authorId": "2130605234",
                        "name": "Yunyang Zhang"
                    },
                    {
                        "authorId": "2111230551",
                        "name": "Xiaoyu Zhao"
                    },
                    {
                        "authorId": "2114745862",
                        "name": "Tingsong Jiang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "However, ensemble models come with large memory and computational cost (Malinin et al., 2019).",
                "Ensemble models have been shown to give robust measures of uncertainty as they provide a probabilistic framework allowing knowledge uncertainty to be linked to Bayesian or non-Bayesian model uncertainty (Malinin et al., 2019)."
            ],
            "citingPaper": {
                "paperId": "c35f53f7e4a2b219cf7fce7b16fa2704d86ff1db",
                "externalIds": {
                    "DBLP": "journals/es/MogesZQ22",
                    "DOI": "10.1111/exsy.12945",
                    "CorpusId": 246796917
                },
                "corpusId": 246796917,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c35f53f7e4a2b219cf7fce7b16fa2704d86ff1db",
                "title": "Sequential multi\u2010headed attention for entity\u2010based relational neural networks",
                "abstract": "The capacity of relational interaction between high\u2010level information and reason is the defining characteristic of human intelligence. Regardless of the remarkable progress in artificial intelligence, recent machine reading comprehension models still heavily rely on high\u2010dimensional word\u2010based distributed representations. Since these models employ statistical means to answer questions of complex textual corpus and employ an accuracy\u2010based metric system, their learning capacity of the required skills is not guaranteed. To ensure the capacity of MRC models to learn the desired skills, explainability has become an emerging requirement. In this paper, we propose an end\u2010to\u2010end natural language reasoning model that is based on sets of high\u2010level aggregated representations which promote operational explainability. To this end, sequential multi\u2010head attention, and a loss regularization function is proposed. We show analysis of the proposed approach on two natural language reasoning oriented question and answering datasets (bAbI and NewsQA).",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51065291",
                        "name": "Dagmawi Moges"
                    },
                    {
                        "authorId": "1481819499",
                        "name": "Jiaxu Zhao"
                    },
                    {
                        "authorId": "2064923494",
                        "name": "Hong Qu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "This includes popular methods such as Bayesian dropout [21, 33], deep ensembles [35, 37, 44] and variational inference [55], Laplace approximation [18, 34] and tempered posteriors [2, 3, 32] to cite a few."
            ],
            "citingPaper": {
                "paperId": "c8d42b2311e2fd7faee1d7a7c5280840de0cad56",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2202-03295",
                    "ArXiv": "2202.03295",
                    "DOI": "10.1088/2632-2153/acd749",
                    "CorpusId": 246634119
                },
                "corpusId": 246634119,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c8d42b2311e2fd7faee1d7a7c5280840de0cad56",
                "title": "Theoretical characterization of uncertainty in high-dimensional linear classification",
                "abstract": "Being able to reliably assess not only the accuracy but also the uncertainty of models\u2019 predictions is an important endeavor in modern machine learning. Even if the model generating the data and labels is known, computing the intrinsic uncertainty after learning the model from a limited number of samples amounts to sampling the corresponding posterior probability measure. Such sampling is computationally challenging in high-dimensional problems and theoretical results on heuristic uncertainty estimators in high-dimensions are thus scarce. In this manuscript, we characterize uncertainty for learning from a limited number of samples of high-dimensional Gaussian input data and labels generated by the probit model. In this setting, the Bayesian uncertainty (i.e. the posterior marginals) can be asymptotically obtained by the approximate message passing algorithm, bypassing the canonical but costly Monte Carlo sampling of the posterior. We then provide a closed-form formula for the joint statistics between the logistic classifier, the uncertainty of the statistically optimal Bayesian classifier and the ground-truth probit uncertainty. The formula allows us to investigate the calibration of the logistic classifier learning from a limited amount of samples. We discuss how over-confidence can be mitigated by appropriately regularizing.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2153463900",
                        "name": "Lucas Clart'e"
                    },
                    {
                        "authorId": "143616600",
                        "name": "Bruno Loureiro"
                    },
                    {
                        "authorId": "2909402",
                        "name": "F. Krzakala"
                    },
                    {
                        "authorId": "2107086291",
                        "name": "Lenka Zdeborov'a"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "A series of papers developed ways of approximating the distribution obtained using an ensemble of models by a single probabilistic model [49, 50, 66].",
                "[50] Andrey Malinin, Bruno Mlodozeniec, et al."
            ],
            "citingPaper": {
                "paperId": "b3a084b7c56af9e9bd0c23367d28bd3e500759b0",
                "externalIds": {
                    "ArXiv": "2202.03101",
                    "DBLP": "conf/nips/KotelevskiiAFNF22",
                    "CorpusId": 253224056
                },
                "corpusId": 253224056,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b3a084b7c56af9e9bd0c23367d28bd3e500759b0",
                "title": "Nonparametric Uncertainty Quantification for Single Deterministic Neural Network",
                "abstract": "This paper proposes a fast and scalable method for uncertainty quantification of machine learning models' predictions. First, we show the principled way to measure the uncertainty of predictions for a classifier based on Nadaraya-Watson's nonparametric estimate of the conditional label distribution. Importantly, the proposed approach allows to disentangle explicitly aleatoric and epistemic uncertainties. The resulting method works directly in the feature space. However, one can apply it to any neural network by considering an embedding of the data induced by the network. We demonstrate the strong performance of the method in uncertainty estimation tasks on text classification problems and a variety of real-world image datasets, such as MNIST, SVHN, CIFAR-100 and several versions of ImageNet.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1509418352",
                        "name": "Nikita Kotelevskii"
                    },
                    {
                        "authorId": "1491040769",
                        "name": "A. Artemenkov"
                    },
                    {
                        "authorId": "1490644954",
                        "name": "Kirill Fedyanin"
                    },
                    {
                        "authorId": "2083750450",
                        "name": "Fedor Noskov"
                    },
                    {
                        "authorId": "102894500",
                        "name": "A. Fishkov"
                    },
                    {
                        "authorId": "1967424",
                        "name": "Artem Shelmanov"
                    },
                    {
                        "authorId": "2165225340",
                        "name": "Artem Vazhentsev"
                    },
                    {
                        "authorId": "1380315305",
                        "name": "Aleksandr Petiushko"
                    },
                    {
                        "authorId": "144180694",
                        "name": "Maxim Panov"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "efb56c3e37890796aed10b46a7044b95cfedad35",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-05938",
                    "ArXiv": "2201.05938",
                    "CorpusId": 246016265
                },
                "corpusId": 246016265,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/efb56c3e37890796aed10b46a7044b95cfedad35",
                "title": "GradTail: Learning Long-Tailed Data Using Gradient-based Sample Weighting",
                "abstract": "We propose GradTail, an algorithm that uses gradients to improve model performance on the fly in the face of long-tailed training data distributions. Unlike conventional long-tail classifiers which operate on converged - and possibly overfit - models, we demonstrate that an approach based on gradient dot product agreement can isolate long-tailed data early on during model training and improve performance by dynamically picking higher sample weights for that data. We show that such upweighting leads to model improvements for both classification and regression models, the latter of which are relatively unexplored in the long-tail literature, and that the long-tail examples found by gradient alignment are consistent with our semantic expectations.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2119258071",
                        "name": "Zhao Chen"
                    },
                    {
                        "authorId": "24026083",
                        "name": "Vincent Casser"
                    },
                    {
                        "authorId": "34699489",
                        "name": "Henrik Kretzschmar"
                    },
                    {
                        "authorId": "1838674",
                        "name": "Dragomir Anguelov"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Ensemble distribution distillation (EnD(2)) is a closely related approach that aims to distill the collective predictive distribution outputs of the models in an ensemble into a neural network that predicts the parameters of a Dirichlet distribution [18]."
            ],
            "citingPaper": {
                "paperId": "564ef14d8b08a2b99f9a82f48af21a0df7495d49",
                "externalIds": {
                    "ArXiv": "2112.01675",
                    "DBLP": "conf/cogmi/VaderaM21",
                    "DOI": "10.1109/CogMI52975.2021.00040",
                    "CorpusId": 244896394
                },
                "corpusId": 244896394,
                "publicationVenue": {
                    "id": "4cd48fc0-b1c9-4a7d-9cf5-805613612f5b",
                    "name": "International Conference on Cognitive Machine Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "CogMI",
                        "Int Conf Cogn Mach Intell"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/564ef14d8b08a2b99f9a82f48af21a0df7495d49",
                "title": "Challenges and Opportunities in Approximate Bayesian Deep Learning for Intelligent IoT Systems",
                "abstract": "Approximate Bayesian deep learning methods hold significant promise for addressing several issues that occur when deploying deep learning components in intelligent systems, including mitigating the occurrence of over-confident errors and providing enhanced robustness to out of distribution examples. However, the computational requirements of existing approxi-mate Bayesian inference methods can make them ill-suited for deployment in intelligent IoT systems that include lower-powered edge devices. In this paper, we present a range of approximate Bayesian inference methods for supervised deep learning and highlight the challenges and opportunities when applying these methods on current edge hardware. We highlight several potential solutions to decreasing model storage requirements and improving computational scalability, including model pruning and distillation methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "71008399",
                        "name": "Meet P. Vadera"
                    },
                    {
                        "authorId": "1805742",
                        "name": "Benjamin M Marlin"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Furthermore, modifications to the standard KD objective allow one to distill the knowledge in an ensemble of teachers into one student network while preserving the benefits in uncertainty estimation of ensembles [Malinin et al., 2020, Tran et al., 2020]."
            ],
            "citingPaper": {
                "paperId": "c6e11fcfd2f2a74f9bb9e540996b4ec4f159b5bf",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-14149",
                    "ArXiv": "2110.14149",
                    "CorpusId": 239998136
                },
                "corpusId": 239998136,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/c6e11fcfd2f2a74f9bb9e540996b4ec4f159b5bf",
                "title": "Diversity Matters When Learning From Ensembles",
                "abstract": "Deep ensembles excel in large-scale image classification tasks both in terms of prediction accuracy and calibration. Despite being simple to train, the computation and memory cost of deep ensembles limits their practicability. While some recent works propose to distill an ensemble model into a single model to reduce such costs, there is still a performance gap between the ensemble and distilled models. We propose a simple approach for reducing this gap, i.e., making the distilled performance close to the full ensemble. Our key assumption is that a distilled model should absorb as much function diversity inside the ensemble as possible. We first empirically show that the typical distillation procedure does not effectively transfer such diversity, especially for complex models that achieve near-zero training error. To fix this, we propose a perturbation strategy for distillation that reveals diversity by seeking inputs for which ensemble member outputs disagree. We empirically show that a model distilled with such perturbed samples indeed exhibits enhanced diversity, leading to improved performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2065197138",
                        "name": "G. Nam"
                    },
                    {
                        "authorId": "2116003214",
                        "name": "Jongmin Yoon"
                    },
                    {
                        "authorId": "2110392124",
                        "name": "Yoonho Lee"
                    },
                    {
                        "authorId": "2124954802",
                        "name": "Juho Lee"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "To this end, we use the Area Under Receiving Operator Characteristics Curve (AUC-ROC) with aleatoric scores u alea (Alea) and epistemic scores u (v) epist (Epist) similarly to [14, 102, 60, 63, 61, 57].",
                "Important examples explicitly parameterize prior distributions [86, 63, 60, 61, 6] or posterior distributions [14, 15]."
            ],
            "citingPaper": {
                "paperId": "66ee16c1a274f1c9205b0ef4fbda0b4a8a481f81",
                "externalIds": {
                    "ArXiv": "2110.14012",
                    "DBLP": "journals/corr/abs-2110-14012",
                    "CorpusId": 239998097
                },
                "corpusId": 239998097,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/66ee16c1a274f1c9205b0ef4fbda0b4a8a481f81",
                "title": "Graph Posterior Network: Bayesian Predictive Uncertainty for Node Classification",
                "abstract": "The interdependence between nodes in graphs is key to improve class predictions on nodes and utilized in approaches like Label Propagation (LP) or in Graph Neural Networks (GNN). Nonetheless, uncertainty estimation for non-independent node-level predictions is under-explored. In this work, we explore uncertainty quantification for node classification in three ways: (1) We derive three axioms explicitly characterizing the expected predictive uncertainty behavior in homophilic attributed graphs. (2) We propose a new model Graph Posterior Network (GPN) which explicitly performs Bayesian posterior updates for predictions on interdependent nodes. GPN provably obeys the proposed axioms. (3) We extensively evaluate GPN and a strong set of baselines on semi-supervised node classification including detection of anomalous features, and detection of left-out classes. GPN outperforms existing approaches for uncertainty estimation in the experiments.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2135022667",
                        "name": "Maximilian Stadler"
                    },
                    {
                        "authorId": "50997190",
                        "name": "Bertrand Charpentier"
                    },
                    {
                        "authorId": "79462643",
                        "name": "Simon Geisler"
                    },
                    {
                        "authorId": "73775589",
                        "name": "D. Zugner"
                    },
                    {
                        "authorId": "51249380",
                        "name": "Stephan Gunnemann"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[17] distilled distribution of the prediction from multiple teachers to a student rather than distilled the averaged prediction directly."
            ],
            "citingPaper": {
                "paperId": "0d8277950a9d0f4ed8216479cb512e40f0631b72",
                "externalIds": {
                    "DBLP": "conf/mm/HaoL0A021",
                    "DOI": "10.1145/3474085.3475329",
                    "CorpusId": 239012132
                },
                "corpusId": 239012132,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0d8277950a9d0f4ed8216479cb512e40f0631b72",
                "title": "Data-Free Ensemble Knowledge Distillation for Privacy-conscious Multimedia Model Compression",
                "abstract": "Recent advances in deep learning bring impressive performance for multimedia applications. Hence, compressing and deploying these applications on resource-limited edge devices via model compression becomes attractive. Knowledge distillation (KD) is one of the most popular model compression techniques. However, most well-behaved KD approaches require the original dataset, which is usually unavailable due to privacy issues, while existing data-free KD methods perform much worse than data-required counterparts. In this paper, we analyze previous data-free KD methods from the data perspective and point out that using a single pre-trained model limits the performance of these approaches. We then propose a Data-Free Ensemble knowledge Distillation (DFED) framework, which contains a student network, a generator network, and multiple pre-trained teacher networks. During training, the student mimics behaviors of the ensemble of teachers using samples synthesized by a generator, which aims to enlarge the prediction discrepancy between the student and teachers. A moment matching loss term assists the generator training by minimizing the distance between activations of synthesized samples and real samples. We evaluate DFED on three popular image classification datasets. Results demonstrate that our method achieves significant performance improvements compared with previous works. We also design an ablation study to verify the effectiveness of each component of the proposed framework.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2147215540",
                        "name": "Zhiwei Hao"
                    },
                    {
                        "authorId": "143610445",
                        "name": "Yong Luo"
                    },
                    {
                        "authorId": "46177189",
                        "name": "Han Hu"
                    },
                    {
                        "authorId": "2151864031",
                        "name": "Jianping An"
                    },
                    {
                        "authorId": "145868454",
                        "name": "Yonggang Wen"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "961ba6302926bbfc0524b27c8db80cc485b8e0f6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-06427",
                    "ArXiv": "2110.06427",
                    "CorpusId": 238744030
                },
                "corpusId": 238744030,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/961ba6302926bbfc0524b27c8db80cc485b8e0f6",
                "title": "Dense Uncertainty Estimation",
                "abstract": "Deep neural networks can be roughly divided into deterministic neural networks and stochastic neural networks.The former is usually trained to achieve a mapping from input space to output space via maximum likelihood estimation for the weights, which leads to deterministic predictions during testing. In this way, a specific weights set is estimated while ignoring any uncertainty that may occur in the proper weight space. The latter introduces randomness into the framework, either by assuming a prior distribution over model parameters (i.e. Bayesian Neural Networks) or including latent variables (i.e. generative models) to explore the contribution of latent variables for model predictions, leading to stochastic predictions during testing. Different from the former that achieves point estimation, the latter aims to estimate the prediction distribution, making it possible to estimate uncertainty, representing model ignorance about its predictions. We claim that conventional deterministic neural network based dense prediction tasks are prone to overfitting, leading to over-confident predictions, which is undesirable for decision making. In this paper, we investigate stochastic neural networks and uncertainty estimation techniques to achieve both accurate deterministic prediction and reliable uncertainty estimation. Specifically, we work on two types of uncertainty estimations solutions, namely ensemble based methods and generative model based methods, and explain their pros and cons while using them in fully/semi/weakly-supervised framework. Due to the close connection between uncertainty estimation and model calibration, we also introduce how uncertainty estimation can be used for deep model calibration to achieve well-calibrated models, namely dense model calibration. Code and data are available at https://github.com/JingZhang617/UncertaintyEstimation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2155698491",
                        "name": "Jing Zhang"
                    },
                    {
                        "authorId": "2116916030",
                        "name": "Yuchao Dai"
                    },
                    {
                        "authorId": "2114879963",
                        "name": "Mochu Xiang"
                    },
                    {
                        "authorId": "23999143",
                        "name": "Deng-Ping Fan"
                    },
                    {
                        "authorId": "145136889",
                        "name": "Peyman Moghadam"
                    },
                    {
                        "authorId": "40214723",
                        "name": "Mingyi He"
                    },
                    {
                        "authorId": "3093246",
                        "name": "Christian J. Walder"
                    },
                    {
                        "authorId": "3397429",
                        "name": "Kaihao Zhang"
                    },
                    {
                        "authorId": "23911916",
                        "name": "Mehrtash Harandi"
                    },
                    {
                        "authorId": "1712576",
                        "name": "N. Barnes"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "Many researchers have studied reducing the cost to estimate ensemble PU [1, 6, 33, 47, 50]."
            ],
            "citingPaper": {
                "paperId": "328796c69ba042ea4735f1ba1c090379740cf584",
                "externalIds": {
                    "ArXiv": "2110.06435",
                    "CorpusId": 249848300
                },
                "corpusId": 249848300,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/328796c69ba042ea4735f1ba1c090379740cf584",
                "title": "Dropout Prediction Uncertainty Estimation Using Neuron Activation Strength",
                "abstract": "Dropout has been commonly used to quantify prediction uncertainty, i.e, the variations of model predictions on a given input example. However, using dropout in practice can be expensive as it requires running dropout inferences many times. In this paper, we study how to estimate dropout prediction uncertainty in a resource-efficient manner. We demonstrate that we can use neuron activation strengths to estimate dropout prediction uncertainty under different dropout settings and on a variety of tasks using three large datasets, MovieLens, Criteo, and EMNIST. Our approach provides an inference-once method to estimate dropout prediction uncertainty as a cheap auxiliary task. We also demonstrate that using activation features from a subset of the neural network layers can be sufficient to achieve uncertainty estimation performance almost comparable to that of using activation features from all layers, thus reducing resources even further for uncertainty estimation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2119315730",
                        "name": "Haichao Yu"
                    },
                    {
                        "authorId": "2117037227",
                        "name": "Zhe Chen"
                    },
                    {
                        "authorId": "2116442426",
                        "name": "Dong Lin"
                    },
                    {
                        "authorId": "1743255",
                        "name": "G. Shamir"
                    },
                    {
                        "authorId": "2111717256",
                        "name": "Jie Han"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "For training purposes, they apply two different training objectives using the equivalent of the reverse KL objective of Malinin & Gales (2019) as well as of the knowledge distillation objective of Malinin et al. (2020b), which does not require OOD data for regularization purposes.",
                "Multivariate evidential regression There are also some works offering solutions for multivariate regression problems: Malinin et al. (2020a) can be seen as a multivariate generalization of the work of Amini et al. (2020), where a combined Normal-Wishart prior is formed to fit the now Multivariate\u2026",
                "Alternatively, Malinin et al. (2020b); Stadler et al. (2021); Amini et al. (2020) show or measure the area under the prediction / rejection curve, graphing how task performance varies as predictions on increasingly uncertain inputs is suspended.",
                "Malinin et al. (2020b) exploit this idea and show that prior networks can also be distilled using an ensemble of classifiers and their predicted Categorical distributions (akin to learning Figure 4e from Figure 4a), which does not require regularization at all, but comes at the cost of having to\u2026",
                "\u2026(Malinin & Gales, 2018; 2019; Nandy et al., 2020; Zhao et al., 2019; Hu et al., 2020; Charpentier et al., 2020; 2022), spiral data (Malinin et al., 2020b) or polynomials for regression (Amini et al., 2020; Oh & Shin, 2022; Meinert & Lavin, 2021; Malinin et al., 2020a; Charpentier et al., 2022).",
                "Instead of training an ensemble, diverse predictions are obtained from the teacher network through the use of Gaussian dropout, which are distilled into a Dirichlet distribution as in Malinin et al. (2020b).",
                "Furthermore, some approaches (Malinin & Gales, 2018; 2019; Nandy et al., 2020; Malinin et al., 2020a) require out-of-distribution data points during training.",
                "Additional cost is mostly only produced when using knowledge distillation (Malinin et al., 2020b; Fathullah & Gales, 2022), adding normalizing flow components like for posterior networks (Charpentier et al., 2020; 2022; Stadler et al., 2021) or using generative models to produce synthetic OOD data\u2026",
                "\u2026using Gaussians (Malinin & Gales, 2018; 2019; Nandy et al., 2020; Zhao et al., 2019; Hu et al., 2020; Charpentier et al., 2020; 2022), spiral data (Malinin et al., 2020b) or polynomials for regression (Amini et al., 2020; Oh & Shin, 2022; Meinert & Lavin, 2021; Malinin et al., 2020a; Charpentier\u2026",
                "\u20262019; Nandy et al., 2020; Shen et al., 2020; Chen et al., 2018; Zhao et al., 2019; Hu et al., 2021; Sensoy et al., 2020), knowledge distillation (Malinin et al., 2020b;a) or the incorporation of density estimation (Charpentier et al., 2020; 2022; Stadler et al., 2021), which we discuss in more\u2026",
                "The methods listed in Table 3 either choose the Normal-Inverse Gamma distribution (Amini et al., 2020; Charpentier et al., 2022), inducing a scaled inverse-\u03c72 posterior (Gelman et al., 1995),13 or a Normal-Wishart prior (Malinin et al., 2020a)."
            ],
            "citingPaper": {
                "paperId": "f9a522bae646c7d3a1b33e16a595f4c938558068",
                "externalIds": {
                    "DBLP": "journals/tmlr/UlmerHF23",
                    "ArXiv": "2110.03051",
                    "CorpusId": 257378675
                },
                "corpusId": 257378675,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f9a522bae646c7d3a1b33e16a595f4c938558068",
                "title": "Prior and Posterior Networks: A Survey on Evidential Deep Learning Methods For Uncertainty Estimation",
                "abstract": "Popular approaches for quantifying predictive uncertainty in deep neural networks often involve distributions over weights or multiple models, for instance via Markov Chain sampling, ensembling, or Monte Carlo dropout. These techniques usually incur overhead by having to train multiple model instances or do not produce very diverse predictions. This comprehensive and extensive survey aims to familiarize the reader with an alternative class of models based on the concept of Evidential Deep Learning: For unfamiliar data, they aim to admit\"what they don't know\", and fall back onto a prior belief. Furthermore, they allow uncertainty estimation in a single model and forward pass by parameterizing distributions over distributions. This survey recapitulates existing works, focusing on the implementation in a classification setting, before surveying the application of the same paradigm to regression. We also reflect on the strengths and weaknesses compared to other existing methods and provide the most fundamental derivations using a unified notation to aid future research.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "133864309",
                        "name": "Dennis Ulmer"
                    },
                    {
                        "authorId": "2579449",
                        "name": "Christian Hardmeier"
                    },
                    {
                        "authorId": "3010230",
                        "name": "J. Frellsen"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "There are however some ideas to make them less expensive by distilling their uncertainties into simpler models (Malinin et al., 2019; Tran et al., 2020; Havasi et al., 2020; Antor\u00e1n et al., 2020).",
                "\u2026to use a hierarchical output distribution, for instance a Dirichlet distribution (Milios et al., 2018; Sensoy et al., 2018; Malinin & Gales, 2018; Malinin et al., 2019; Malinin & Gales, 2019; Hobbhahn et al., 2020; Nandy et al., 2020), such that the model uncertainty can be encoded in the\u2026",
                "There are however some ideas to make them less expensive by distilling their uncertainties into simpler models [39, 55, 26, 3].",
                "Another popular idea is to use a hierarchical output distribution, for instance a Dirichlet distribution [40, 50, 38, 39, 30], such that the model uncertainty can be encoded in the Dirichlet and the data uncertainty in its Categorical distribution samples."
            ],
            "citingPaper": {
                "paperId": "79f5b56d6a3fc65949b2a48d8530c29828464cc7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-02609",
                    "ArXiv": "2110.02609",
                    "CorpusId": 238407806
                },
                "corpusId": 238407806,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/79f5b56d6a3fc65949b2a48d8530c29828464cc7",
                "title": "Deep Classifiers with Label Noise Modeling and Distance Awareness",
                "abstract": "Uncertainty estimation in deep learning has recently emerged as a crucial area of interest to advance reliability and robustness in safety-critical applications. While there have been many proposed methods that either focus on distance-aware model uncertainties for out-of-distribution detection or on input-dependent label uncertainties for in-distribution calibration, both of these types of uncertainty are often necessary. In this work, we propose the HetSNGP method for jointly modeling the model and data uncertainty. We show that our proposed model affords a favorable combination between these two types of uncertainty and thus outperforms the baseline methods on some challenging out-of-distribution datasets, including CIFAR-100C, ImageNet-C, and ImageNet-A. Moreover, we propose HetSNGP Ensemble, an ensembled version of our method which additionally models uncertainty over the network parameters and outperforms other ensemble baselines.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "41031794",
                        "name": "Vincent Fortuin"
                    },
                    {
                        "authorId": "153247100",
                        "name": "Mark Collier"
                    },
                    {
                        "authorId": "39798982",
                        "name": "F. Wenzel"
                    },
                    {
                        "authorId": "1491706991",
                        "name": "J. Allingham"
                    },
                    {
                        "authorId": "2108345570",
                        "name": "J. Liu"
                    },
                    {
                        "authorId": "47497262",
                        "name": "Dustin Tran"
                    },
                    {
                        "authorId": "40627523",
                        "name": "Balaji Lakshminarayanan"
                    },
                    {
                        "authorId": "6367313",
                        "name": "Jesse Berent"
                    },
                    {
                        "authorId": "2068720",
                        "name": "Rodolphe Jenatton"
                    },
                    {
                        "authorId": "11133195",
                        "name": "E. Kokiopoulou"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Some works study the knowledge transfer process on multi-teacher KD approaches, such as multiple heterogeneous teachers [28] or homogeneous teachers [7, 23]."
            ],
            "citingPaper": {
                "paperId": "93290d5b08a1f3f2b4615c5dce252c3d5880a04a",
                "externalIds": {
                    "DBLP": "conf/iccv/ZhuW21a",
                    "DOI": "10.1109/ICCV48922.2021.00501",
                    "CorpusId": 244680427
                },
                "corpusId": 244680427,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/93290d5b08a1f3f2b4615c5dce252c3d5880a04a",
                "title": "Student Customized Knowledge Distillation: Bridging the Gap Between Student and Teacher",
                "abstract": "Knowledge distillation (KD) transfers the dark knowledge from cumbersome networks (teacher) to lightweight (student) networks and expects the student to achieve more promising performance than training without the teacher\u2019s knowledge. However, a counter-intuitive argument is that better teachers do not make better students due to the capacity mismatch. To this end, we present a novel adaptive knowledge distillation method to complement traditional approaches. The proposed method, named as Student Customized Knowledge Distillation (SCKD), examines the capacity mismatch between teacher and student from the perspective of gradient similarity. We formulate the knowledge distillation as a multi-task learning problem so that the teacher transfers knowledge to the student only if the student can benefit from learning such knowledge. We validate our methods on multiple datasets with various teacher-student configurations on image classification, object detection, and semantic segmentation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "143737000",
                        "name": "Yichen Zhu"
                    },
                    {
                        "authorId": "2154459998",
                        "name": "Yi Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Distillation of ensemble models [41] could be an interesting avenue to explore in this regards.",
                "Distillation of ensembles is a good direction to explore in this context [41]."
            ],
            "citingPaper": {
                "paperId": "6d36d7ffed3a743535ad7d458bb203f9e1546427",
                "externalIds": {
                    "DBLP": "journals/sensors/RoyGS21",
                    "PubMedCentral": "8512601",
                    "DOI": "10.3390/s21196566",
                    "CorpusId": 238745414,
                    "PubMed": "34640886"
                },
                "corpusId": 238745414,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6d36d7ffed3a743535ad7d458bb203f9e1546427",
                "title": "Confidence-Calibrated Human Activity Recognition",
                "abstract": "Wearable sensors are widely used in activity recognition (AR) tasks with broad applicability in health and well-being, sports, geriatric care, etc. Deep learning (DL) has been at the forefront of progress in activity classification with wearable sensors. However, most state-of-the-art DL models used for AR are trained to discriminate different activity classes at high accuracy, not considering the confidence calibration of predictive output of those models. This results in probabilistic estimates that might not capture the true likelihood and is thus unreliable. In practice, it tends to produce overconfident estimates. In this paper, the problem is addressed by proposing deep time ensembles, a novel ensembling method capable of producing calibrated confidence estimates from neural network architectures. In particular, the method trains an ensemble of network models with temporal sequences extracted by varying the window size over the input time series and averaging the predictive output. The method is evaluated on four different benchmark HAR datasets and three different neural network architectures. Across all the datasets and architectures, our method shows an improvement in calibration by reducing the expected calibration error (ECE)by at least 40%, thereby providing superior likelihood estimates. In addition to providing reliable predictions our method also outperforms the state-of-the-art classification results in the WISDM, UCI HAR, and PAMAP2 datasets and performs as good as the state-of-the-art in the Skoda dataset.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2283107",
                        "name": "Debaditya Roy"
                    },
                    {
                        "authorId": "69947993",
                        "name": "Sarunas Girdzijauskas"
                    },
                    {
                        "authorId": "2132460262",
                        "name": "Serghei Socolovschi"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Recently Malinin et al. (2019) and Ryabinin et al. (2021) proposed ensemble distribution distillation (EnD2) - an approach to distill an ensemble into a single model which preserves both the ensemble\u2019s improved performance and full set of uncertainty measures at low inference cost.",
                "(5)\nOriginally, Malinin et al. (2019) implemented EnD2 on the CIFAR10, CIFAR100 and TinyImageNet datasets.",
                "Recently, Malinin et al. (2019) proposed ensemble distribution distillation (EnD2) as an approach to distill an ensemble into a single prior network model (Malinin and Gales, 2018), such that the model retains information about ensemble diversity."
            ],
            "citingPaper": {
                "paperId": "d150bce3bc29c506f690b4131ac37dd9051e31ba",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2109-04349",
                    "ACL": "2021.emnlp-main.623",
                    "ArXiv": "2109.04349",
                    "DOI": "10.18653/v1/2021.emnlp-main.623",
                    "CorpusId": 237451171
                },
                "corpusId": 237451171,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/d150bce3bc29c506f690b4131ac37dd9051e31ba",
                "title": "Uncertainty Measures in Neural Belief Tracking and the Effects on Dialogue Policy Performance",
                "abstract": "The ability to identify and resolve uncertainty is crucial for the robustness of a dialogue system. Indeed, this has been confirmed empirically on systems that utilise Bayesian approaches to dialogue belief tracking. However, such systems consider only confidence estimates and have difficulty scaling to more complex settings. Neural dialogue systems, on the other hand, rarely take uncertainties into account. They are therefore overconfident in their decisions and less robust. Moreover, the performance of the tracking task is often evaluated in isolation, without consideration of its effect on the downstream policy optimisation. We propose the use of different uncertainty measures in neural belief tracking. The effects of these measures on the downstream task of policy optimisation are evaluated by adding selected measures of uncertainty to the feature space of the policy and training policies through interaction with a user simulator. Both human and simulated user results show that incorporating these measures leads to improvements both of the performance and of the robustness of the downstream dialogue policy. This highlights the importance of developing neural dialogue belief trackers that take uncertainty into account.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "113869710",
                        "name": "Carel van Niekerk"
                    },
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    },
                    {
                        "authorId": "1676966139",
                        "name": "Christian Geishauser"
                    },
                    {
                        "authorId": "113469882",
                        "name": "Michael Heck"
                    },
                    {
                        "authorId": "2116102483",
                        "name": "Hsien-chin Lin"
                    },
                    {
                        "authorId": "143604111",
                        "name": "Nurul Lubis"
                    },
                    {
                        "authorId": "2113511651",
                        "name": "Shutong Feng"
                    },
                    {
                        "authorId": "1676892968",
                        "name": "Milica Gavsi'c"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "through distillation into a single model [65, 94]).",
                "[65] Andrey Malinin, Bruno Mlodozeniec, and Mark Gales."
            ],
            "citingPaper": {
                "paperId": "9289826beb6206eeaf500105f7329d6d5a495d8a",
                "externalIds": {
                    "DBLP": "conf/cvpr/WortsmanIKLKRLH22",
                    "ArXiv": "2109.01903",
                    "DOI": "10.1109/CVPR52688.2022.00780",
                    "CorpusId": 237420687
                },
                "corpusId": 237420687,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9289826beb6206eeaf500105f7329d6d5a495d8a",
                "title": "Robust fine-tuning of zero-shot models",
                "abstract": "Large pre-trained models such as CLIP or ALIGN offer consistent accuracy across a range of data distributions when performing zero-shot inference (i.e., without fine-tuning on a specific dataset). Although existing fine-tuning methods substantially improve accuracy on a given target distribution, they often reduce robustness to distribution shifts. We address this tension by introducing a simple and effective method for improving robustness while fine-tuning: ensembling the weights of the zero-shot and fine-tuned models (WiSE-FT). Compared to standard fine-tuning, WiSE-FT provides large accuracy improvements under distribution shift, while preserving high accuracy on the target distribution. On ImageNet and five derived distribution shifts, WiSE-FT improves accuracy under distribution shift by 4 to 6 percentage points (pp) over prior work while increasing ImageNet accuracy by 1.6 pp. WiSE-FT achieves similarly large robustness gains (2 to 23 pp) on a diverse set of six further distribution shifts, and accuracy gains of 0.8 to 3.3 pp compared to standard fine-tuning on commonly used transfer learning datasets. These improvements come at no additional computational cost during fine-tuning or inference.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "52193502",
                        "name": "Mitchell Wortsman"
                    },
                    {
                        "authorId": "2123694087",
                        "name": "Gabriel Ilharco"
                    },
                    {
                        "authorId": "2145962396",
                        "name": "Mike Li"
                    },
                    {
                        "authorId": "2110935237",
                        "name": "Jong Wook Kim"
                    },
                    {
                        "authorId": "2548384",
                        "name": "Hannaneh Hajishirzi"
                    },
                    {
                        "authorId": "143787583",
                        "name": "Ali Farhadi"
                    },
                    {
                        "authorId": "40281109",
                        "name": "Hongseok Namkoong"
                    },
                    {
                        "authorId": "152772922",
                        "name": "Ludwig Schmidt"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Following [9] and [26], we compute the two types of uncertainty as follows:"
            ],
            "citingPaper": {
                "paperId": "b4c2be1d7581a0fda0d12ddaa4d83ffd2f820ea5",
                "externalIds": {
                    "DBLP": "conf/iccvw/DengWS21",
                    "ArXiv": "2108.04228",
                    "DOI": "10.1109/ICCVW54120.2021.00396",
                    "CorpusId": 239015814
                },
                "corpusId": 239015814,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b4c2be1d7581a0fda0d12ddaa4d83ffd2f820ea5",
                "title": "Iterative Distillation for Better Uncertainty Estimates in Multitask Emotion Recognition",
                "abstract": "When recognizing emotions, subtle nuances in displays of emotion generate ambiguity or uncertainty in emotion perception. Emotion uncertainty has been previously interpreted as inter-rater disagreement among multiple annotators. In this paper, we consider a more common and challenging scenario: modeling emotion uncertainty when only single emotion labels are available. From a Bayesian perspective, we propose to use deep ensembles to capture uncertainty for multiple emotion descriptors, i.e., action units, discrete expression labels and continuous descriptors. We further apply iterative self-distillation. Iterative distillation over multiple generations significantly improves performance in both emotion recognition and uncertainty estimation. Our method generates single student models that provide accurate estimates of uncertainty for in-domain samples and a student ensemble that can detect out-of-domain samples. Our experiments on emotion recognition and uncertainty estimation using the Aff-wild2 dataset demonstrate that our algorithm gives more reliable uncertainty estimates than both Temperature Scaling and Monte Carol Dropout.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "46203817",
                        "name": "Didan Deng"
                    },
                    {
                        "authorId": "2148952330",
                        "name": "Liang Wu"
                    },
                    {
                        "authorId": "2075335081",
                        "name": "Bertram E. Shi"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Prior Networks have also been used for Ensemble Distribution Distillation [34, 33, 35] \u2014 a distillation approach through which the predictive performance and uncertainty estimates of an ensemble are captured within a single Prior Network, reducing the inference cost to that of a single model."
            ],
            "citingPaper": {
                "paperId": "3397f25209666d30a8b797932e3197cc826fba18",
                "externalIds": {
                    "ArXiv": "2107.07455",
                    "DBLP": "journals/corr/abs-2107-07455",
                    "CorpusId": 235899139
                },
                "corpusId": 235899139,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3397f25209666d30a8b797932e3197cc826fba18",
                "title": "Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks",
                "abstract": "There has been significant research done on developing methods for improving robustness to distributional shift and uncertainty estimation. In contrast, only limited work has examined developing standard datasets and benchmarks for assessing these approaches. Additionally, most work on uncertainty estimation and robustness has developed new techniques based on small-scale regression or image classification tasks. However, many tasks of practical interest have different modalities, such as tabular data, audio, text, or sensor data, which offer significant challenges involving regression and discrete or continuous structured prediction. Thus, given the current state of the field, a standardized large-scale dataset of tasks across a range of modalities affected by distributional shifts is necessary. This will enable researchers to meaningfully evaluate the plethora of recently developed uncertainty quantification methods, as well as assessment criteria and state-of-the-art baselines. In this work, we propose the Shifts Dataset for evaluation of uncertainty estimates and robustness to distributional shift. The dataset, which has been collected from industrial sources and services, is composed of three tasks, with each corresponding to a particular data modality: tabular weather prediction, machine translation, and self-driving car (SDC) vehicle motion prediction. All of these data modalities and tasks are affected by real,\"in-the-wild\"distributional shifts and pose interesting challenges with respect to uncertainty estimation. In this work we provide a description of the dataset and baseline results for all tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    },
                    {
                        "authorId": "1726096678",
                        "name": "Neil Band"
                    },
                    {
                        "authorId": "2119553176",
                        "name": "German Chesnokov"
                    },
                    {
                        "authorId": "2681954",
                        "name": "Y. Gal"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    },
                    {
                        "authorId": "47565007",
                        "name": "A. Noskov"
                    },
                    {
                        "authorId": "2028023764",
                        "name": "Andrey Ploskonosov"
                    },
                    {
                        "authorId": "51270819",
                        "name": "L. Prokhorenkova"
                    },
                    {
                        "authorId": "1390051629",
                        "name": "Ivan Provilkov"
                    },
                    {
                        "authorId": "2119533381",
                        "name": "Vatsal Raina"
                    },
                    {
                        "authorId": "2007545675",
                        "name": "Vyas Raina"
                    },
                    {
                        "authorId": "2052363",
                        "name": "Mariya Shmatova"
                    },
                    {
                        "authorId": "2119618091",
                        "name": "Panos Tigas"
                    },
                    {
                        "authorId": "2171060",
                        "name": "Boris Yangel"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "instead of directly predicting the output [90], [45].",
                "5) Making Ensemble Methods more Efficient: Compared to single model methods, ensemble methods come along with a significantly increased computational effort and memory consumption [217], [45].",
                "1 [71], [72] 2 [46] 3 [36], [35] 4 [32] 5 [44] 7 [35] 8 [73], [74], 9 [75], [30] 10 [76], [77] 11 [20] 12 [78], [79], [80] 13 [81] 14 [82] 15 [83] 16 [63] 17 [84] 18 [31] 19 [85] 20 [86] 21 [87], [88], [89] 22 [90], [45] 23 [39] 24 [40] 25 [91]",
                "[45] modelled ensemble members and the distilled network as prior networks",
                "This limits the deployment of ensemble methods in many practical applications where the computation power or memory is limited, the application is time-critical, or very large networks with high inference time are included [45].",
                "it has been shown that they are capable of delivering good and for some experiments even comparable results [90], [45], [247]."
            ],
            "citingPaper": {
                "paperId": "fc70db46738fff97d9ee3d66c6f9c57794d7b4fa",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2107-03342",
                    "ArXiv": "2107.03342",
                    "DOI": "10.1007/s10462-023-10562-9",
                    "CorpusId": 235755082
                },
                "corpusId": 235755082,
                "publicationVenue": {
                    "id": "ea8553fe-2467-4367-afee-c4deb3754820",
                    "name": "Artificial Intelligence Review",
                    "type": "journal",
                    "alternate_names": [
                        "Artif Intell Rev"
                    ],
                    "issn": "0269-2821",
                    "url": "https://link.springer.com/journal/10462"
                },
                "url": "https://www.semanticscholar.org/paper/fc70db46738fff97d9ee3d66c6f9c57794d7b4fa",
                "title": "A Survey of Uncertainty in Deep Neural Networks",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2051292610",
                        "name": "J. Gawlikowski"
                    },
                    {
                        "authorId": "1486494981",
                        "name": "Cedrique Rovile Njieutcheu Tassi"
                    },
                    {
                        "authorId": "2051285705",
                        "name": "Mohsin Ali"
                    },
                    {
                        "authorId": "2329051",
                        "name": "Jongseo Lee"
                    },
                    {
                        "authorId": "1753619041",
                        "name": "Matthias Humt"
                    },
                    {
                        "authorId": "2118032380",
                        "name": "Jianxiang Feng"
                    },
                    {
                        "authorId": "2124880868",
                        "name": "Anna M. Kruspe"
                    },
                    {
                        "authorId": "1453548521",
                        "name": "Rudolph Triebel"
                    },
                    {
                        "authorId": "2054660189",
                        "name": "P. Jung"
                    },
                    {
                        "authorId": "46525320",
                        "name": "R. Roscher"
                    },
                    {
                        "authorId": "1380493607",
                        "name": "M. Shahzad"
                    },
                    {
                        "authorId": "2121300248",
                        "name": "Wen Yang"
                    },
                    {
                        "authorId": "1740759",
                        "name": "R. Bamler"
                    },
                    {
                        "authorId": "46875441",
                        "name": "Xiaoxiang Zhu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "af309f8dc435151f3f70fdbb23e67dd5ba3e518f",
                "externalIds": {
                    "ArXiv": "2106.11642",
                    "DBLP": "conf/nips/DAngeloF21",
                    "CorpusId": 235593134
                },
                "corpusId": 235593134,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/af309f8dc435151f3f70fdbb23e67dd5ba3e518f",
                "title": "Repulsive Deep Ensembles are Bayesian",
                "abstract": "Deep ensembles have recently gained popularity in the deep learning community for their conceptual simplicity and efficiency. However, maintaining functional diversity between ensemble members that are independently trained with gradient descent is challenging. This can lead to pathologies when adding more ensemble members, such as a saturation of the ensemble performance, which converges to the performance of a single model. Moreover, this does not only affect the quality of its predictions, but even more so the uncertainty estimates of the ensemble, and thus its performance on out-of-distribution data. We hypothesize that this limitation can be overcome by discouraging different ensemble members from collapsing to the same function. To this end, we introduce a kernelized repulsive term in the update rule of the deep ensembles. We show that this simple modification not only enforces and maintains diversity among the members but, even more importantly, transforms the maximum a posteriori inference into proper Bayesian inference. Namely, we show that the training dynamics of our proposed repulsive ensembles follow a Wasserstein gradient flow of the KL divergence with the true posterior. We study repulsive terms in weight and function space and empirically compare their performance to standard ensembles and Bayesian baselines on synthetic and real-world prediction tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1422504701",
                        "name": "Francesco D'Angelo"
                    },
                    {
                        "authorId": "41031794",
                        "name": "Vincent Fortuin"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "906cdb21abeddfdf08108a72989db0dc8fb0db56",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-10760",
                    "ArXiv": "2106.10760",
                    "CorpusId": 235490493
                },
                "corpusId": 235490493,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/906cdb21abeddfdf08108a72989db0dc8fb0db56",
                "title": "On Stein Variational Neural Network Ensembles",
                "abstract": "Ensembles of deep neural networks have achieved great success recently, but they do not offer a proper Bayesian justification. Moreover, while they allow for averaging of predictions over several hypotheses, they do not provide any guarantees for their diversity, leading to redundant solutions in function space. In contrast, particle-based inference methods, such as Stein variational gradient descent (SVGD), offer a Bayesian framework, but rely on the choice of a kernel to measure the similarity between ensemble members. In this work, we study different SVGD methods operating in the weight space, function space, and in a hybrid setting. We compare the SVGD approaches to other ensembling-based methods in terms of their theoretical properties and assess their empirical performance on synthetic and real-world tasks. We find that SVGD using functional and hybrid kernels can overcome the limitations of deep ensembles. It improves on functional diversity and uncertainty estimation and approaches the true Bayesian posterior more closely. Moreover, we show that using stochastic SVGD updates, as opposed to the standard deterministic ones, can further improve the performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1422504701",
                        "name": "Francesco D'Angelo"
                    },
                    {
                        "authorId": "41031794",
                        "name": "Vincent Fortuin"
                    },
                    {
                        "authorId": "39798982",
                        "name": "F. Wenzel"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Quantiles and prediction intervals can also be obtained by aggregating multiple predictors, such as using Bayesian neural networks [41, 24, 32, 44, 42] or ensembles [37, 49, 28, 45]."
            ],
            "citingPaper": {
                "paperId": "66462bfd498cd8b1ea0883674114db2e528f02b8",
                "externalIds": {
                    "DBLP": "conf/nips/BaiMWX21",
                    "ArXiv": "2106.05515",
                    "CorpusId": 235390419
                },
                "corpusId": 235390419,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/66462bfd498cd8b1ea0883674114db2e528f02b8",
                "title": "Understanding the Under-Coverage Bias in Uncertainty Estimation",
                "abstract": "Estimating the data uncertainty in regression tasks is often done by learning a quantile function or a prediction interval of the true label conditioned on the input. It is frequently observed that quantile regression -- a vanilla algorithm for learning quantiles with asymptotic guarantees -- tends to \\emph{under-cover} than the desired coverage level in reality. While various fixes have been proposed, a more fundamental understanding of why this under-coverage bias happens in the first place remains elusive. In this paper, we present a rigorous theoretical study on the coverage of uncertainty estimation algorithms in learning quantiles. We prove that quantile regression suffers from an inherent under-coverage bias, in a vanilla setting where we learn a realizable linear quantile function and there is more data than parameters. More quantitatively, for $\\alpha>0.5$ and small $d/n$, the $\\alpha$-quantile learned by quantile regression roughly achieves coverage $\\alpha - (\\alpha-1/2)\\cdot d/n$ regardless of the noise distribution, where $d$ is the input dimension and $n$ is the number of training data. Our theory reveals that this under-coverage bias stems from a certain high-dimensional parameter estimation error that is not implied by existing theories on quantile regression. Experiments on simulated and real data verify our theory and further illustrate the effect of various factors such as sample size and model capacity on the under-coverage bias in more practical setups.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1491626939",
                        "name": "Yu Bai"
                    },
                    {
                        "authorId": "2068869988",
                        "name": "Song Mei"
                    },
                    {
                        "authorId": "2197900626",
                        "name": "Huan Wang"
                    },
                    {
                        "authorId": "2228109",
                        "name": "Caiming Xiong"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "[28] proposed a method to model the implicit distribution over predictive distributions from which the ensemble component predictive distributions are drawn, rather than just the ensemble model average."
            ],
            "citingPaper": {
                "paperId": "5f0f4a3fa3cff7ffcedabbc9ed0dad2dd71f7028",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-05945",
                    "ArXiv": "2106.05945",
                    "CorpusId": 235390933
                },
                "corpusId": 235390933,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/5f0f4a3fa3cff7ffcedabbc9ed0dad2dd71f7028",
                "title": "Does Knowledge Distillation Really Work?",
                "abstract": "Knowledge distillation is a popular technique for training a small student network to emulate a larger teacher model, such as an ensemble of networks. We show that while knowledge distillation can improve student generalization, it does not typically work as it is commonly understood: there often remains a surprisingly large discrepancy between the predictive distributions of the teacher and the student, even in cases when the student has the capacity to perfectly match the teacher. We identify difficulties in optimization as a key reason for why the student is unable to match the teacher. We also show how the details of the dataset used for distillation play a role in how closely the student matches the teacher -- and that more closely matching the teacher paradoxically does not always lead to better student generalization.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2067201658",
                        "name": "S. Stanton"
                    },
                    {
                        "authorId": "7991830",
                        "name": "Pavel Izmailov"
                    },
                    {
                        "authorId": "67146006",
                        "name": "P. Kirichenko"
                    },
                    {
                        "authorId": "122113652",
                        "name": "Alexander A. Alemi"
                    },
                    {
                        "authorId": "145771261",
                        "name": "A. Wilson"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "504f0aa3808009aa61ed67894bb27243dd6a8608",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2105-14275",
                    "ArXiv": "2105.14275",
                    "CorpusId": 235254707
                },
                "corpusId": 235254707,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/504f0aa3808009aa61ed67894bb27243dd6a8608",
                "title": "Greedy Bayesian Posterior Approximation with Deep Ensembles",
                "abstract": "Ensembles of independently trained neural networks are a state-of-the-art approach to estimate predictive uncertainty in Deep Learning, and can be interpreted as an approximation of the posterior distribution via a mixture of delta functions. The training of ensembles relies on non-convexity of the loss landscape and random initialization of their individual members, making the resulting posterior approximation uncontrolled. This paper proposes a novel and principled method to tackle this limitation, minimizing an $f$-divergence between the true posterior and a kernel density estimator (KDE) in a function space. We analyze this objective from a combinatorial point of view, and show that it is submodular with respect to mixture components for any $f$. Subsequently, we consider the problem of greedy ensemble construction. From the marginal gain on the negative $f$-divergence, which quantifies an improvement in posterior approximation yielded by adding a new component into the KDE, we derive a novel diversity term for ensemble methods. The performance of our approach is demonstrated on computer vision out-of-distribution detection benchmarks in a range of architectures trained on multiple datasets. The source code of our method is made publicly available at https://github.com/Oulu-IMEDS/greedy_ensembles_training.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "8796283",
                        "name": "A. Tiulpin"
                    },
                    {
                        "authorId": "1758219",
                        "name": "Matthew B. Blaschko"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "In order to avoid the computational cost of the multiple forwards, [17] and [18] proposes to use distillation."
            ],
            "citingPaper": {
                "paperId": "d47356f650db0917a126871b8683545506858a55",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2105-13688",
                    "MAG": "3193973800",
                    "ArXiv": "2105.13688",
                    "DOI": "10.1109/ICIP42928.2021.9506719",
                    "CorpusId": 235247926
                },
                "corpusId": 235247926,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d47356f650db0917a126871b8683545506858a55",
                "title": "Learning Uncertainty for Safety-Oriented Semantic Segmentation in Autonomous Driving",
                "abstract": "In this paper, we show how uncertainty estimation can be leveraged to enable safety critical image segmentation in autonomous driving, by triggering a fallback behavior if a target accuracy cannot be guaranteed. We introduce a new uncertainty measure based on disagreeing predictions as measured by a dissimilarity function. We propose to estimate this dissimilarity by training a deep neural architecture in parallel to the task-specific network. It allows this observer to be dedicated to the uncertainty estimation, and let the task-specific network make predictions. We propose to use self-supervision to train the observer, which implies that our method does not require additional training data. We show experimentally that our proposed approach is much less computationally intensive at inference time than competing methods (e.g., MC Dropout), while delivering better results on safety-oriented evaluation metrics on the CamVid dataset, especially in the case of glare artifacts.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1400349847",
                        "name": "Victor Besnier"
                    },
                    {
                        "authorId": "145897899",
                        "name": "David Picard"
                    },
                    {
                        "authorId": "50711387",
                        "name": "Alexandre Briot"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "Consequently, it is no longer possible to obtain estimates of knowledge uncertainty which is particularly useful for anomaly detection [5, 10].",
                "Ensemble Distribution Distillation offers a straightforward way to model the ensemble predictions [10, 13].",
                "[10] recently proposed a class of distillation techniques called Ensemble Distribution Distillation (EnD(2)), where the goal is to capture both the mean and the diversity of an ensemble within a single model.",
                "Recently, several works have proposed distillation procedures that capture information about both the mean as well as the distribution of ensemble predictions within a single model [10, 11, 12, 13]."
            ],
            "citingPaper": {
                "paperId": "cb85e2b1cd5ef3619348edba4ff169b45e177f94",
                "externalIds": {
                    "ArXiv": "2105.06987",
                    "DBLP": "journals/corr/abs-2105-06987",
                    "CorpusId": 234681293
                },
                "corpusId": 234681293,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/cb85e2b1cd5ef3619348edba4ff169b45e177f94",
                "title": "Scaling Ensemble Distribution Distillation to Many Classes with Proxy Targets",
                "abstract": "Ensembles of machine learning models yield improved system performance as well as robust and interpretable uncertainty estimates; however, their inference costs may often be prohibitively high. \\emph{Ensemble Distribution Distillation} is an approach that allows a single model to efficiently capture both the predictive performance and uncertainty estimates of an ensemble. For classification, this is achieved by training a Dirichlet distribution over the ensemble members' output distributions via the maximum likelihood criterion. Although theoretically principled, this criterion exhibits poor convergence when applied to large-scale tasks where the number of classes is very high. In our work, we analyze this effect and show that the Dirichlet log-likelihood criterion classes with low probability induce larger gradients than high-probability classes. This forces the model to focus on the distribution of the ensemble tail-class probabilities. We propose a new training objective that minimizes the reverse KL-divergence to a \\emph{Proxy-Dirichlet} target derived from the ensemble. This loss resolves the gradient issues of Ensemble Distribution Distillation, as we demonstrate both theoretically and empirically on the ImageNet and WMT17 En-De datasets containing 1000 and 40,000 classes, respectively.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1491753352",
                        "name": "Max Ryabinin"
                    },
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "For classification, we compare NatPN to Reverse KL divergence Prior Networks (R-PriorNet) (Malinin & Gales, 2019), Ensemble Distribution Distillation (EnD2) (Malinin et al., 2020b) and Posterior Networks (PostNet) (Charpentier et al., 2020).",
                "However, only two works (Amini et al., 2020; Malinin et al., 2020a) have focused on regression by learning parameters of a Normal Inverse-Gamma (NIG) distribution as conjugate prior."
            ],
            "citingPaper": {
                "paperId": "37281bf86ac8a81fc0d705b17502fd7a842c601f",
                "externalIds": {
                    "ArXiv": "2105.04471",
                    "CorpusId": 247476226
                },
                "corpusId": 247476226,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/37281bf86ac8a81fc0d705b17502fd7a842c601f",
                "title": "Natural Posterior Network: Deep Bayesian Uncertainty for Exponential Family Distributions",
                "abstract": "the perform a Bayesian the far away from our extensive experiments on calibration and detection show that delivers highly competitive performance for classi\ufb01cation, regression and count prediction tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "50997190",
                        "name": "Bertrand Charpentier"
                    },
                    {
                        "authorId": "2101840120",
                        "name": "Oliver Borchert"
                    },
                    {
                        "authorId": "73775589",
                        "name": "D. Zugner"
                    },
                    {
                        "authorId": "79462643",
                        "name": "Simon Geisler"
                    },
                    {
                        "authorId": "51249380",
                        "name": "Stephan Gunnemann"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Rejection curves are summarised using the Prediction Rejection Ratio (PRR) (Malinin, 2019; Malinin et al., 2020), describe in appendix D."
            ],
            "citingPaper": {
                "paperId": "0921322cf6ea34d1852f13cb67eeac9d1f863518",
                "externalIds": {
                    "DBLP": "conf/iclr/MalininG21",
                    "MAG": "3123791752",
                    "DOI": "10.17863/CAM.63497",
                    "CorpusId": 231895728
                },
                "corpusId": 231895728,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0921322cf6ea34d1852f13cb67eeac9d1f863518",
                "title": "Uncertainty Estimation in Autoregressive Structured Prediction",
                "abstract": "Uncertainty estimation is important for ensuring safety and robustness of AI systems. While most research in the area has focused on un-structured prediction tasks, limited work has investigated general uncertainty estimation approaches for structured prediction. Thus, this work aims to investigate uncertainty estimation for structured prediction tasks within a single unified and interpretable probabilistic ensemble-based framework. We consider: uncertainty estimation for sequence data at the token-level and complete sequence-level; interpretations for, and applications of, various measures of uncertainty; and discuss both the theoretical and practical challenges associated with obtaining them. This work also provides baselines for token-level and sequence-level error detection, and sequence-level out-of-domain input detection on the WMT\u201914 English-French and WMT\u201917 English-German translation and LibriSpeech speech recognition datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "The ensemble-distillation schemes include EnD [43] and its recent revision EnD(2) [50].",
                "It is observed that the student models trained under our proposed framework with fChannel (i.e., \u2018Ours (Channel)\u2019) is able to outperform the previous ensemble-distillation baselines, i.e., EnD [43] and EnD2 [50], by a margin of 6.64% mIoU and 6.02% mIoU on GTA5\u2192Cityscapes, and 6.41% mIoU and 4.57% mIoU on SYNTHIA\u2192Cityscapes, respectively.",
                "The authors in [50] aimed at resolving the diversity collapse issue in the ensemble-distillation problem.",
                ", EnD [43] and EnD(2) [50], by a margin of 6.",
                "The evaluation results of EnD [43] and EnD(2) [50] are obtained from our self-implemented models, while those of the remaining baselines are directly obtained from their original papers.",
                "The ensemble-distillation schemes include EnD [43] and its recent revision EnD2 [50].",
                "It is observed that the performance of the students trained with \u2018Ours (Pixel)\u2019, EnD, and EnD2 all degrade when the number of under-performing members increases.",
                "89 Ours (Channel) Ours (Pixel) EnD[43] EnD [50] 2"
            ],
            "citingPaper": {
                "paperId": "cc02a26214343b4d540354b9fd3b2b85f64ccc66",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2104-14203",
                    "ArXiv": "2104.14203",
                    "DOI": "10.1109/CVPRW53098.2021.00295",
                    "CorpusId": 233444162
                },
                "corpusId": 233444162,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/cc02a26214343b4d540354b9fd3b2b85f64ccc66",
                "title": "Rethinking Ensemble-Distillation for Semantic Segmentation Based Unsupervised Domain Adaption",
                "abstract": "Recent researches on unsupervised domain adaptation (UDA) have demonstrated that end-to-end ensemble learning frameworks serve as a compelling option for UDA tasks. Nevertheless, these end-to-end ensemble learning methods often lack flexibility as any modification to the ensemble requires retraining of their frameworks. To address this problem, we propose a flexible ensemble-distillation framework for performing semantic segmentation based UDA, allowing any arbitrary composition of the members in the ensemble while still maintaining its superior performance. To achieve such flexibility, our framework is designed to be robust against the output inconsistency and the performance variation of the members within the ensemble. To examine the effectiveness and the robustness of our method, we perform an extensive set of experiments on both GTA5\u2192Cityscapes and SYNTHIA\u2192Cityscapes benchmarks to quantitatively inspect the improvements achievable by our method. We further provide detailed analyses to validate that our design choices are practical and beneficial. The experimental evidence validates that the proposed method indeed offer superior performance, robustness and flexibility in semantic segmentation based UDA tasks against contemporary baseline methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2086829087",
                        "name": "Chen-Hao Chao"
                    },
                    {
                        "authorId": "9939828",
                        "name": "Bo Wun Cheng"
                    },
                    {
                        "authorId": "1492122970",
                        "name": "Chun-Yi Lee"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[27] distilled an ensemble into the prior network [28], which models a conditional distribution over categorical distributions by parameterizing a Dirichlet distribution to disentangle the total uncertainty into data uncertainty and knowledge uncertainty."
            ],
            "citingPaper": {
                "paperId": "e46f2796f370e2e00225dc40796e20cb33034d64",
                "externalIds": {
                    "DBLP": "journals/computers/DorjsembeLCS21",
                    "MAG": "3154270017",
                    "DOI": "10.3390/computers10040054",
                    "CorpusId": 234785821
                },
                "corpusId": 234785821,
                "publicationVenue": {
                    "id": "38e26272-f1d7-470a-a99f-0b5884c9df6e",
                    "name": "De Computis",
                    "alternate_names": [
                        "Comput"
                    ],
                    "issn": "1886-1881",
                    "url": "https://dialnet.unirioja.es/servlet/revista?clave_revista=6205&tipo_busqueda=CODIGO",
                    "alternate_urls": [
                        "http://decomputis.org/ojs/",
                        "https://ideas.repec.org/s/dec/articl.html",
                        "http://www.decomputis.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e46f2796f370e2e00225dc40796e20cb33034d64",
                "title": "Sparsity Increases Uncertainty Estimation in Deep Ensemble",
                "abstract": "Deep neural networks have achieved almost human-level results in various tasks and have become popular in the broad artificial intelligence domains. Uncertainty estimation is an on-demand task caused by the black-box point estimation behavior of deep learning. The deep ensemble provides increased accuracy and estimated uncertainty; however, linearly increasing the size makes the deep ensemble unfeasible for memory-intensive tasks. To address this problem, we used model pruning and quantization with a deep ensemble and analyzed the effect in the context of uncertainty metrics. We empirically showed that the ensemble members\u2019 disagreement increases with pruning, making models sparser by zeroing irrelevant parameters. Increased disagreement im-plies increased uncertainty, which helps in making more robust predictions. Accordingly, an energy-efficient compressed deep ensemble is appropriate for memory-intensive and uncertainty-aware tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2098809523",
                        "name": "Uyanga Dorjsembe"
                    },
                    {
                        "authorId": "2108550762",
                        "name": "Ju-hong Lee"
                    },
                    {
                        "authorId": "2464385",
                        "name": "Bumghi Choi"
                    },
                    {
                        "authorId": "2112793701",
                        "name": "Jae-Won Song"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Knowledge distillation aims to transfer the knowledge from one deep learning model (the teacher) to another (the student), such as distilling a large network into a smaller one [19, 49, 2, 48, 12] or ensembling a collection of models into a single model [29, 37, 27, 45]."
            ],
            "citingPaper": {
                "paperId": "fdc369b826bafb1eb0c4e1ff03dff3517896f80b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-16367",
                    "MAG": "3144033074",
                    "ArXiv": "2103.16367",
                    "DOI": "10.1109/CVPR46437.2021.00914",
                    "CorpusId": 232417071
                },
                "corpusId": 232417071,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fdc369b826bafb1eb0c4e1ff03dff3517896f80b",
                "title": "Complementary Relation Contrastive Distillation",
                "abstract": "Knowledge distillation aims to transfer representation ability from a teacher model to a student model. Previous approaches focus on either individual representation distillation or inter-sample similarity preservation. While we argue that the inter-sample relation conveys abundant information and needs to be distilled in a more effective way. In this paper, we propose a novel knowledge distillation method, namely Complementary Relation Contrastive Distillation (CRCD), to transfer the structural knowledge from the teacher to the student. Specifically, we estimate the mutual relation in an anchor-based way and distill the anchor-student relation under the supervision of its corresponding anchor-teacher relation. To make it more robust, mutual relations are modeled by two complementary elements: the feature and its gradient. Furthermore, the low bound of mutual information between the anchor-teacher relation distribution and the anchor-student relation distribution is maximized via relation contrastive loss, which can distill both the sample representation and the inter-sample relations. Experiments on different benchmarks demonstrate the effectiveness of our proposed CRCD.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "150167730",
                        "name": "Jinguo Zhu"
                    },
                    {
                        "authorId": "9084688",
                        "name": "Shixiang Tang"
                    },
                    {
                        "authorId": "143982372",
                        "name": "Dapeng Chen"
                    },
                    {
                        "authorId": "2112273099",
                        "name": "Shijie Yu"
                    },
                    {
                        "authorId": "2108079753",
                        "name": "Yakun Liu"
                    },
                    {
                        "authorId": "49911554",
                        "name": "A. Yang"
                    },
                    {
                        "authorId": "143860804",
                        "name": "M. Rong"
                    },
                    {
                        "authorId": "50141428",
                        "name": "Xiaohua Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Due to the nature of using multiple networks, it is also effective in various problem settings such as adversarial attack and out-of-distribution detection [13, 6, 5, 17].",
                "Due to the nature of ensembles that use multiple networks, they are also effective in various problem settings such as adversarial attack and out-of-distribution detection [13, 5, 17]."
            ],
            "citingPaper": {
                "paperId": "0974545e9cdb9dd0fb2762ef6b6dbe1fdb59af93",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-14845",
                    "ArXiv": "2103.14845",
                    "CorpusId": 232404008
                },
                "corpusId": 232404008,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0974545e9cdb9dd0fb2762ef6b6dbe1fdb59af93",
                "title": "Deep Ensemble Collaborative Learning by using Knowledge-transfer Graph for Fine-grained Object Classification",
                "abstract": "Mutual learning, in which multiple networks learn by sharing their knowledge, improves the performance of each network. However, the performance of ensembles of networks that have undergone mutual learning does not improve significantly from that of normal ensembles without mutual learning, even though the performance of each network has improved significantly. This may be due to the relationship between the knowledge in mutual learning and the individuality of the networks in the ensemble. In this study, we propose an ensemble method using knowledge transfer to improve the accuracy of ensembles by introducing a loss design that promotes diversity among networks in mutual learning. We use an attention map as knowledge, which represents the probability distribution and information in the middle layer of a network. There are many ways to combine networks and loss designs for knowledge transfer methods. Therefore, we use the automatic optimization of knowledge-transfer graphs to consider a variety of knowledge-transfer methods by graphically representing conventional mutual-learning and distillation methods and optimizing each element through hyperparameter search. The proposed method consists of a mechanism for constructing an ensemble in a knowledge-transfer graph, attention loss, and a loss design that promotes diversity among networks. We explore optimal ensemble learning by optimizing a knowledge-transfer graph to maximize ensemble accuracy. From exploration of graphs and evaluation experiments using the datasets of Stanford Dogs, Stanford Cars, and CUB-200-2011, we confirm that the proposed method is more accurate than a conventional ensemble method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2072385680",
                        "name": "Naoki Okamoto"
                    },
                    {
                        "authorId": "2052965790",
                        "name": "Soma Minami"
                    },
                    {
                        "authorId": "134790239",
                        "name": "Tsubasa Hirakawa"
                    },
                    {
                        "authorId": "1687819",
                        "name": "Takayoshi Yamashita"
                    },
                    {
                        "authorId": "1687968",
                        "name": "H. Fujiyoshi"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "EnD2 [41] distilled the distribution of the predictions of the ensemble into a single model.",
                "Similarly, EnD2 [41] also distills the prediction distribution from an ensemble into a single model.",
                "Following EnD2 [41], we compare FFSD with EnD2 on VGG-16 [59]."
            ],
            "citingPaper": {
                "paperId": "14e8f3c72fc07b793fe18c2e116d84ee4a83ff6e",
                "externalIds": {
                    "ArXiv": "2103.14473",
                    "DBLP": "journals/corr/abs-2103-14473",
                    "DOI": "10.1109/TNNLS.2022.3152732",
                    "CorpusId": 232380330,
                    "PubMed": "35254994"
                },
                "corpusId": 232380330,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/14e8f3c72fc07b793fe18c2e116d84ee4a83ff6e",
                "title": "Distilling a Powerful Student Model via Online Knowledge Distillation",
                "abstract": "Existing online knowledge distillation approaches either adopt the student with the best performance or construct an ensemble model for better holistic performance. However, the former strategy ignores other students' information, while the latter increases the computational complexity during deployment. In this article, we propose a novel method for online knowledge distillation, termed feature fusion and self-distillation (FFSD), which comprises two key components: FFSD, toward solving the above problems in a unified framework. Different from previous works, where all students are treated equally, the proposed FFSD splits them into a leader student set and a common student set. Then, the feature fusion module converts the concatenation of feature maps from all common students into a fused feature map. The fused representation is used to assist the learning of the leader student. To enable the leader student to absorb more diverse information, we design an enhancement strategy to increase the diversity among students. Besides, a self-distillation module is adopted to convert the feature map of deeper layers into a shallower one. Then, the shallower layers are encouraged to mimic the transformed feature maps of the deeper layers, which helps the students to generalize better. After training, we simply adopt the leader student, which achieves superior performance, over the common students, without increasing the storage or inference cost. Extensive experiments on CIFAR-100 and ImageNet demonstrate the superiority of our FFSD over existing works. The code is available at https://github.com/SJLeo/FFSD.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145904937",
                        "name": "Shaojie Li"
                    },
                    {
                        "authorId": "49352079",
                        "name": "Mingbao Lin"
                    },
                    {
                        "authorId": "2152543905",
                        "name": "Yan Wang"
                    },
                    {
                        "authorId": "1835006",
                        "name": "Feiyue Huang"
                    },
                    {
                        "authorId": "47096329",
                        "name": "Yongjian Wu"
                    },
                    {
                        "authorId": "40161651",
                        "name": "Yonghong Tian"
                    },
                    {
                        "authorId": "144082425",
                        "name": "Ling Shao"
                    },
                    {
                        "authorId": "1572139630",
                        "name": "Rongrong Ji"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "b01ff6ee7c3153456056ce9570eae4d08f868ab7",
                "externalIds": {
                    "PubMedCentral": "8041280",
                    "DBLP": "journals/jcisd/YildirimC21",
                    "DOI": "10.1021/acs.jcim.0c01455",
                    "CorpusId": 232142319,
                    "PubMed": "33682402"
                },
                "corpusId": 232142319,
                "publicationVenue": {
                    "id": "3f16aef5-6b9f-4f87-baca-cbf8147e352f",
                    "name": "Journal of Chemical Information and Modeling",
                    "type": "journal",
                    "alternate_names": [
                        "J Chem Inf Model"
                    ],
                    "issn": "1549-9596",
                    "url": "http://pubs.acs.org/jcim",
                    "alternate_urls": [
                        "http://pubs.acs.org/journals/jcisd8/index.html",
                        "https://pubs.acs.org/journal/jcisd8"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b01ff6ee7c3153456056ce9570eae4d08f868ab7",
                "title": "Bayesian Particle Instance Segmentation for Electron Microscopy Image Quantification",
                "abstract": "Automating the analysis portion of materials characterization by electron microscopy (EM) has the potential to accelerate the process of scientific discovery. To this end, we present a Bayesian deep-learning model for semantic segmentation and localization of particle instances in EM images. These segmentations can subsequently be used to compute quantitative measures such as particle-size distributions, radial- distribution functions, average sizes, and aspect ratios of the particles in an image. Moreover, by making use of the epistemic uncertainty of our model, we obtain uncertainty estimates of its outputs and use these to filter out false-positive predictions and hence produce more accurate quantitative measures. We incorporate our method into the ImageDataExtractor package, as ImageDataExtractor 2.0, which affords a full pipeline to automatically extract particle information for large-scale data-driven materials discovery. Finally, we present and make publicly available the Electron Microscopy Particle Segmentation (EMPS) data set. This is the first human-labeled particle instance segmentation data set, consisting of 465 EM images and their corresponding semantic instance segmentation maps.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1404140592",
                        "name": "Batuhan Yildirim"
                    },
                    {
                        "authorId": "4145599",
                        "name": "J. Cole"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Therefore, the distillation of both dropout sampling and ensemble techniques into a single network has been proposed in [14], [15]."
            ],
            "citingPaper": {
                "paperId": "0e9268131f720bb5d64521e8e29839f3185ed178",
                "externalIds": {
                    "DBLP": "conf/icra/WilliamsGMN21",
                    "ArXiv": "2103.00869",
                    "DOI": "10.1109/ICRA48506.2021.9561165",
                    "CorpusId": 232076482
                },
                "corpusId": 232076482,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0e9268131f720bb5d64521e8e29839f3185ed178",
                "title": "Fool Me Once: Robust Selective Segmentation via Out-of-Distribution Detection with Contrastive Learning",
                "abstract": "In this work, a neural network is trained to simultaneously perform segmentation and pixel-wise Out-of-Distribution (OoD) detection, such that the segmentation of unknown regions of scenes can be rejected. This is made possible by leveraging an OoD dataset with a novel contrastive objective and data augmentation scheme. By including unknown classes in the training data, a more robust feature representation is learned with known classes represented distinctly from those unknown. In comparison, when presented with unknown classes or conditions, many current approaches for segmentation frequently exhibit high confidence in their inaccurate segmentations and cannot be trusted in many operational environments. We validate our system on a real-world dataset of unusual driving scenes, and show that by selectively segmenting scenes based on what is predicted as OoD, we can increase the segmentation accuracy by an IoU of 0.2 with respect to alternative techniques.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152728183",
                        "name": "David Williams"
                    },
                    {
                        "authorId": "2346231",
                        "name": "Matthew Gadd"
                    },
                    {
                        "authorId": "7764753",
                        "name": "D. Martini"
                    },
                    {
                        "authorId": "144214578",
                        "name": "P. Newman"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "6dca98ebce5cbdeedd1911dde18e66771b855506",
                "externalIds": {
                    "DBLP": "conf/nips/HenningCDOTEKGS21",
                    "ArXiv": "2103.01133",
                    "MAG": "3133620575",
                    "CorpusId": 232092717
                },
                "corpusId": 232092717,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/6dca98ebce5cbdeedd1911dde18e66771b855506",
                "title": "Posterior Meta-Replay for Continual Learning",
                "abstract": "Continual Learning (CL) algorithms have recently received a lot of attention as they attempt to overcome the need to train with an i.i.d. sample from some unknown target data distribution. Building on prior work, we study principled ways to tackle the CL problem by adopting a Bayesian perspective and focus on continually learning a task-specific posterior distribution via a shared meta-model, a task-conditioned hypernetwork. This approach, which we term Posterior-replay CL, is in sharp contrast to most Bayesian CL approaches that focus on the recursive update of a single posterior distribution. The benefits of our approach are (1) an increased flexibility to model solutions in weight space and therewith less susceptibility to task dissimilarity, (2) access to principled task-specific predictive uncertainty estimates, that can be used to infer task identity during test time and to detect task boundaries during training, and (3) the ability to revisit and update task-specific posteriors in a principled manner without requiring access to past data. The proposed framework is versatile, which we demonstrate using simple posterior approximations (such as Gaussians) as well as powerful, implicit distributions modelled via a neural network. We illustrate the conceptual advance of our framework on low-dimensional problems and show performance gains on computer vision benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2364999",
                        "name": "Christian Henning"
                    },
                    {
                        "authorId": "108382994",
                        "name": "Maria R. Cervera"
                    },
                    {
                        "authorId": "1422504701",
                        "name": "Francesco D'Angelo"
                    },
                    {
                        "authorId": "145167136",
                        "name": "J. Oswald"
                    },
                    {
                        "authorId": "2051804554",
                        "name": "Regina Traber"
                    },
                    {
                        "authorId": "1753618772",
                        "name": "Benjamin Ehret"
                    },
                    {
                        "authorId": "51194506",
                        "name": "Seijin Kobayashi"
                    },
                    {
                        "authorId": "3105061",
                        "name": "J. Sacramento"
                    },
                    {
                        "authorId": "48117063",
                        "name": "B. Grewe"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "Malinin et al. (2020a)\u2019s approach focuses on estimating both model and data noise uncertainty.",
                "This enables optimizing the upper UB as acquisition function without the need for further approximation via ensemble distillations[25].",
                "In a recent working paper (and concurrent to our work), Malinin et al. (2020a) report on progress extending their idea to regression.",
                "In this Section, we highlight several differences of NOMU compared to prior regression networks that were recently introduced in a working paper by Malinin et al. (2020a).",
                "[25] Andrey Malinin, Bruno Mlodozeniec, and Mark Gales.",
                "See also Kuleshov et al. (2018) for a non-linear calibration method.\nfunction without the need for further approximation via ensemble distillations(Malinin et al., 2020b).",
                "By OOD they refer to input training points only far away from the training data, e.g., in (Malinin et al., 2020a, Section 3) \u00b5OOD only has support far away from the convex hull of the input training points."
            ],
            "citingPaper": {
                "paperId": "0649119bd08f28138723f6f32b71e2c00f3e5a74",
                "externalIds": {
                    "ArXiv": "2102.13640",
                    "DBLP": "conf/icml/HeissWWST22",
                    "CorpusId": 232069012
                },
                "corpusId": 232069012,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0649119bd08f28138723f6f32b71e2c00f3e5a74",
                "title": "NOMU: Neural Optimization-based Model Uncertainty",
                "abstract": "We study methods for estimating model uncertainty for neural networks (NNs) in regression. To isolate the effect of model uncertainty, we focus on a noiseless setting with scarce training data. We introduce five important desiderata regarding model uncertainty that any method should satisfy. However, we find that established benchmarks often fail to reliably capture some of these desiderata, even those that are required by Bayesian theory. To address this, we introduce a new approach for capturing model uncertainty for NNs, which we call Neural Optimization-based Model Uncertainty (NOMU). The main idea of NOMU is to design a network architecture consisting of two connected sub-NNs, one for model prediction and one for model uncertainty, and to train it using a carefully-designed loss function. Importantly, our design enforces that NOMU satisfies our five desiderata. Due to its modular architecture, NOMU can provide model uncertainty for any given (previously trained) NN if given access to its training data. We evaluate NOMU in various regressions tasks and noiseless Bayesian optimization (BO) with costly evaluations. In regression, NOMU performs at least as well as state-of-the-art methods. In BO, NOMU even outperforms all considered benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1398510796",
                        "name": "Jakob Heiss"
                    },
                    {
                        "authorId": "1388019274",
                        "name": "Jakob Weissteiner"
                    },
                    {
                        "authorId": "1400367226",
                        "name": "Hanna Wutte"
                    },
                    {
                        "authorId": "1884044",
                        "name": "Sven Seuken"
                    },
                    {
                        "authorId": "34274314",
                        "name": "J. Teichmann"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Some work using Bayesian epistemic uncertainty for OOD detection explicitly rejects the use of aleatoric uncertainty (Malinin & Gales, 2018; Malinin et al., 2020; Wen et al., 2019; Choi et al., 2018; Postels et al., 2020), while other work implicitly combines aleatoric and epistemic uncertainty by looking at the overall predictive entropy (Lakshminarayanan et al.",
                "The most typical approach to Bayesian OOD distribution detection uses epistemic uncertainty (Lakshminarayanan et al., 2017; Malinin & Gales, 2018; Choi et al., 2018; Wen et al., 2019; Malinin et al., 2020; Postels et al., 2020).",
                "Some work using Bayesian epistemic uncertainty for OOD detection explicitly rejects the use of aleatoric uncertainty (Malinin & Gales, 2018; Malinin et al., 2020; Wen et al., 2019; Choi et al., 2018; Postels et al., 2020), while other work implicitly combines aleatoric and epistemic uncertainty by\u2026"
            ],
            "citingPaper": {
                "paperId": "271f06215b6500c8a25c2f61b5316d037fe3a9ec",
                "externalIds": {
                    "ArXiv": "2102.12959",
                    "CorpusId": 240070800
                },
                "corpusId": 240070800,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/271f06215b6500c8a25c2f61b5316d037fe3a9ec",
                "title": "Bayesian OOD detection with aleatoric uncertainty and outlier exposure",
                "abstract": "Typical Bayesian approaches to OOD detection use epistemic uncertainty. Surprisingly from the Bayesian perspective, there are a number of methods that successfully use aleatoric uncertainty to detect OOD points (e.g. Hendryks et al. 2018). In addition, it is difficult to use outlier exposure to improve a Bayesian OOD detection model, as it is not clear whether it is possible or desirable to increase posterior (epistemic) uncertainty at outlier points. We show that a generative model of data curation provides a principled account of aleatoric uncertainty for OOD detection. In particular, aleatoric uncertainty signals a specific type of OOD point: one without a well-defined class-label, and our model of data curation gives a likelihood for these points, giving us a mechanism for conditioning on outlier points and thus performing principled Bayesian outlier exposure. Our principled Bayesian approach, combining aleatoric and epistemic uncertainty with outlier exposure performs better than methods using aleatoric or epistemic alone.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2144728385",
                        "name": "Xi Wang"
                    },
                    {
                        "authorId": "2724259",
                        "name": "L. Aitchison"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "6e84d6788bdd1f99a0ed322cf35ae7b2fb81aa66",
                "externalIds": {
                    "DBLP": "conf/cvpr/Mukhoti0ATG23",
                    "ArXiv": "2102.11582",
                    "DOI": "10.1109/CVPR52729.2023.02336",
                    "CorpusId": 246411740
                },
                "corpusId": 246411740,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6e84d6788bdd1f99a0ed322cf35ae7b2fb81aa66",
                "title": "Deep Deterministic Uncertainty: A New Simple Baseline",
                "abstract": "Reliable uncertainty from deterministic single-forward pass models is sought after because conventional methods of uncertainty quantification are computationally expensive. We take two complex single-forward-pass uncertainty approaches, DUQ and SNGP, and examine whether they mainly rely on a well-regularized feature space. Crucially, without using their more complex methods for estimating uncertainty, we find that a single softmax neural net with such a regularized feature-space, achieved via residual connections and spectral normalization, outperforms DUQ and SNGP's epistemic uncertainty predictions using simple Gaussian Discriminant Analysis post-training as a separate feature-space density estimator-without fine-tuning on OoD data, feature ensembling, or input pre-procressing. Our conceptually simple Deep Deterministic Uncertainty (DDU) baseline can also be used to disentangle aleatoric and epistemic uncertainty and performs as well as Deep Ensembles, the state-of-the art for uncertainty prediction, on several OoD bench-marks (CIFAR-10/100 vs SVHN/Tiny-ImageNet, ImageNet vs ImageNet-O), active learning settings across different model architectures, as well as in large scale vision tasks like semantic segmentation, while being computationally cheaper.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "7438962",
                        "name": "Jishnu Mukhoti"
                    },
                    {
                        "authorId": "145408381",
                        "name": "Andreas Kirsch"
                    },
                    {
                        "authorId": "3038326",
                        "name": "Joost R. van Amersfoort"
                    },
                    {
                        "authorId": "143635540",
                        "name": "Philip H. S. Torr"
                    },
                    {
                        "authorId": "2681954",
                        "name": "Y. Gal"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "472b231723be01d6e8c02edd31bd497810f4d7af",
                "externalIds": {
                    "DBLP": "conf/uai/LuoBBZWXSESP22",
                    "ArXiv": "2102.10809",
                    "CorpusId": 245144954
                },
                "corpusId": 245144954,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/472b231723be01d6e8c02edd31bd497810f4d7af",
                "title": "Local calibration: metrics and recalibration",
                "abstract": "Probabilistic classifiers output confidence scores along with their predictions, and these confidence scores should be calibrated, i.e., they should reflect the reliability of the prediction. Confidence scores that minimize standard metrics such as the expected calibration error (ECE) accurately measure the reliability on average across the entire population. However, it is in general impossible to measure the reliability of an individual prediction. In this work, we propose the local calibration error (LCE) to span the gap between average and individual reliability. For each individual prediction, the LCE measures the average reliability of a set of similar predictions, where similarity is quantified by a kernel function on a pretrained feature space and by a binning scheme over predicted model confidences. We show theoretically that the LCE can be estimated sample-efficiently from data, and empirically find that it reveals miscalibration modes that are more fine-grained than the ECE can detect. Our key result is a novel local recalibration method LoRe, to improve confidence scores for individual predictions and decrease the LCE. Experimentally, we show that our recalibration method produces more accurate confidence scores, which improves downstream fairness and decision making on classification tasks with both image and tabular data.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "39109324",
                        "name": "Rachel Luo"
                    },
                    {
                        "authorId": "31553879",
                        "name": "Aadyot Bhatnagar"
                    },
                    {
                        "authorId": "1491626939",
                        "name": "Yu Bai"
                    },
                    {
                        "authorId": "3303970",
                        "name": "Shengjia Zhao"
                    },
                    {
                        "authorId": "2197900626",
                        "name": "Huan Wang"
                    },
                    {
                        "authorId": "2054594326",
                        "name": "Caiming Xiong"
                    },
                    {
                        "authorId": "1702137",
                        "name": "S. Savarese"
                    },
                    {
                        "authorId": "2490652",
                        "name": "Stefano Ermon"
                    },
                    {
                        "authorId": "1868195",
                        "name": "E. Schmerling"
                    },
                    {
                        "authorId": "1696085",
                        "name": "M. Pavone"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "8a4a90a925d0376e740df508ac307613c647e5c3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-08501",
                    "ArXiv": "2102.08501",
                    "CorpusId": 231942346
                },
                "corpusId": 231942346,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/8a4a90a925d0376e740df508ac307613c647e5c3",
                "title": "DEUP: Direct Epistemic Uncertainty Prediction",
                "abstract": "Epistemic Uncertainty is a measure of the lack of knowledge of a learner which diminishes with more evidence. While existing work focuses on using the variance of the Bayesian posterior due to parameter uncertainty as a measure of epistemic uncertainty, we argue that this does not capture the part of lack of knowledge induced by model misspecification. We discuss how the excess risk, which is the gap between the generalization error of a predictor and the Bayes predictor, is a sound measure of epistemic uncertainty which captures the effect of model misspecification. We thus propose a principled framework for directly estimating the excess risk by learning a secondary predictor for the generalization error and subtracting an estimate of aleatoric uncertainty, i.e., intrinsic unpredictability. We discuss the merits of this novel measure of epistemic uncertainty, and highlight how it differs from variance-based measures of epistemic uncertainty and addresses its major pitfall. Our framework, Direct Epistemic Uncertainty Prediction (DEUP) is particularly interesting in interactive learning environments, where the learner is allowed to acquire novel examples in each round. Through a wide set of experiments, we illustrate how existing methods in sequential model optimization can be improved with epistemic uncertainty estimates from DEUP, and how DEUP can be used to drive exploration in reinforcement learning. We also evaluate the quality of uncertainty estimates from DEUP for probabilistic image classification and predicting synergies of drug combinations.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1383135665",
                        "name": "Moksh Jain"
                    },
                    {
                        "authorId": "51474466",
                        "name": "Salem Lahlou"
                    },
                    {
                        "authorId": "1796300361",
                        "name": "Hadi Nekoei"
                    },
                    {
                        "authorId": "2051130214",
                        "name": "V. Butoi"
                    },
                    {
                        "authorId": "46787626",
                        "name": "Paul Bertin"
                    },
                    {
                        "authorId": "1416982829",
                        "name": "Jarrid Rector-Brooks"
                    },
                    {
                        "authorId": "41018927",
                        "name": "Maksym Korablyov"
                    },
                    {
                        "authorId": "1751762",
                        "name": "Yoshua Bengio"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Another line of work improves calibration by aggregating the probabilisitic predictions over multiple models, using either an ensemble of models (Lakshminarayanan et al., 2016; Malinin et al., 2019; Wen et al., 2020; Tran et al., 2020), or randomized predictions such as Bayesian neural networks (Gal & Ghahramani, 2016; Gal et al.",
                "\u2026calibration by aggregating the probabilisitic predictions over multiple models, using either an ensemble of models (Lakshminarayanan et al., 2016; Malinin et al., 2019; Wen et al., 2020; Tran et al., 2020), or randomized predictions such as Bayesian neural networks (Gal & Ghahramani, 2016; Gal\u2026"
            ],
            "citingPaper": {
                "paperId": "62cf516ff55454a0d3ed2f380fcf74837209ba08",
                "externalIds": {
                    "DBLP": "conf/icml/BaiMWX21",
                    "ArXiv": "2102.07856",
                    "CorpusId": 231933881
                },
                "corpusId": 231933881,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/62cf516ff55454a0d3ed2f380fcf74837209ba08",
                "title": "Don't Just Blame Over-parametrization for Over-confidence: Theoretical Analysis of Calibration in Binary Classification",
                "abstract": "Modern machine learning models with high accuracy are often miscalibrated -- the predicted top probability does not reflect the actual accuracy, and tends to be over-confident. It is commonly believed that such over-confidence is mainly due to over-parametrization, in particular when the model is large enough to memorize the training data and maximize the confidence. In this paper, we show theoretically that over-parametrization is not the only reason for over-confidence. We prove that logistic regression is inherently over-confident, in the realizable, under-parametrized setting where the data is generated from the logistic model, and the sample size is much larger than the number of parameters. Further, this over-confidence happens for general well-specified binary classification problems as long as the activation is symmetric and concave on the positive part. Perhaps surprisingly, we also show that over-confidence is not always the case -- there exists another activation function (and a suitable loss function) under which the learned classifier is under-confident at some probability values. Overall, our theory provides a precise characterization of calibration in realizable binary classification, which we verify on simulations and real data experiments.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1491626939",
                        "name": "Yu Bai"
                    },
                    {
                        "authorId": "2068869988",
                        "name": "Song Mei"
                    },
                    {
                        "authorId": "46507194",
                        "name": "Haiquan Wang"
                    },
                    {
                        "authorId": "2228109",
                        "name": "Caiming Xiong"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Recent deep CNNs have also been shown to benefit from this strategy (Geiger et al. 2020; Ilg et al. 2018; Lan, Zhu, and Gong 2018; Lee and Chung 2020; Lee et al. 2015; Malinin, Mlodozeniec, and Gales 2020)."
            ],
            "citingPaper": {
                "paperId": "2a8e72636abda540afdfe1925ba6cfdc612b920a",
                "externalIds": {
                    "MAG": "3111394625",
                    "DBLP": "conf/aaai/RuizV21",
                    "DOI": "10.1609/aaai.v35i11.17140",
                    "CorpusId": 229171502
                },
                "corpusId": 229171502,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/2a8e72636abda540afdfe1925ba6cfdc612b920a",
                "title": "Anytime Inference with Distilled Hierarchical Neural Ensembles",
                "abstract": "Inference in deep neural networks can be computationally expensive, and networks capable of anytime inference are important in scenarios where the amount of compute or input data varies over time. In such networks the inference process can interrupted to provide a result faster, or continued to obtain a more accurate result. \nWe propose Hierarchical Neural Ensembles (HNE), a novel framework to embed an ensemble of multiple networks in a hierarchical tree structure, sharing intermediate layers. In HNE we control the complexity of inference on-the-fly by evaluating more or less models in the ensemble. Our second contribution is a novel hierarchical distillation method to boost the predictions of small ensembles. This approach leverages the nested structure of our ensembles, to optimally allocate accuracy and diversity across the individual models. Our experiments show that, compared to previous anytime inference models, HNE provides state-of-the-art accuracy-computation trade-offs on the CIFAR-10/100 and ImageNet datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "40097226",
                        "name": "Adria Ruiz"
                    },
                    {
                        "authorId": "1721683",
                        "name": "J. Verbeek"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "cdb2903a4fba7183e7328aeae18c5c5797a31aa5",
                "externalIds": {
                    "ArXiv": "2012.07535",
                    "MAG": "3113190817",
                    "DBLP": "conf/icassp/FathullahGM21",
                    "DOI": "10.1109/ICASSP39728.2021.9413385",
                    "CorpusId": 229156194
                },
                "corpusId": 229156194,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/cdb2903a4fba7183e7328aeae18c5c5797a31aa5",
                "title": "Ensemble Distillation Approaches for Grammatical Error Correction",
                "abstract": "Ensemble approaches are commonly used techniques to improving a system by combining multiple model predictions. Additionally these schemes allow the uncertainty, as well as the source of the uncertainty, to be derived for the prediction. Unfortunately these benefits come at a computational and memory cost. To address this problem ensemble distillation (EnD) and more recently ensemble distribution distillation (EnDD) have been proposed that compress the ensemble into a single model, representing either the ensemble average prediction or prediction distribution respectively. This paper examines the application of both these distillation approaches to a sequence prediction task, grammatical error correction (GEC). This is an important application area for language learning tasks as it can yield highly useful feedback to the learner. It is, however, more challenging than the standard tasks investigated for distillation as the prediction of any grammatical correction to a word will be highly dependent on both the input sequence and the generated output history for the word. The performance of both EnD and EnDD are evaluated on both publicly available GEC tasks as well as a spoken language task.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1400414048",
                        "name": "Yassir Fathullah"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    },
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "In many resource-constrained settings it is important to be able to use a representative neural-network to make predictions, rather than needing to run the inputs through many samples from a posterior (e.g. Malinin et al., 2019)."
            ],
            "citingPaper": {
                "paperId": "0a867ae18ea6c6b85311628b4f758b8e75adbb56",
                "externalIds": {
                    "ArXiv": "2103.00222",
                    "DBLP": "journals/corr/abs-2103-00222",
                    "CorpusId": 232075937
                },
                "corpusId": 232075937,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0a867ae18ea6c6b85311628b4f758b8e75adbb56",
                "title": "Variational Laplace for Bayesian neural networks",
                "abstract": "We develop variational Laplace for Bayesian neural networks (BNNs) which exploits a local approximation of the curvature of the likelihood to estimate the ELBO without the need for stochastic sampling of the neural-network weights. The Variational Laplace objective is simple to evaluate, as it is (in essence) the log-likelihood, plus weight-decay, plus a squared-gradient regularizer. Variational Laplace gave better test performance and expected calibration errors than maximum a-posteriori inference and standard sampling-based variational inference, despite using the same variational approximate posterior. Finally, we emphasise care needed in benchmarking standard VI as there is a risk of stopping before the variance parameters have converged. We show that early-stopping can be avoided by increasing the learning rate for the variance parameters.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2065133666",
                        "name": "Ali Unlu"
                    },
                    {
                        "authorId": "2724259",
                        "name": "L. Aitchison"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "Ensembles involve memory and computational cost which is not acceptable in many application [197].",
                "[197] Image Neural Networks Ensemble Distribution Distillation (EnD2) L(\u03c6,Dens) = \u2212 1 N \u2211N",
                "Let us consider from the posterior sampled ensemble of models {P (y|x, \u03b8)}m=1 as follows [197]:"
            ],
            "citingPaper": {
                "paperId": "172b266f190d89ec6e2164560eba3707e8936e6e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2011-06225",
                    "ArXiv": "2011.06225",
                    "MAG": "3102100346",
                    "DOI": "10.1016/j.inffus.2021.05.008",
                    "CorpusId": 226307260
                },
                "corpusId": 226307260,
                "publicationVenue": {
                    "id": "06afdd0b-0d85-413f-af8a-c3045c12c561",
                    "name": "Information Fusion",
                    "type": "journal",
                    "alternate_names": [
                        "Inf Fusion"
                    ],
                    "issn": "1566-2535",
                    "url": "https://www.journals.elsevier.com/information-fusion",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/15662535"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/172b266f190d89ec6e2164560eba3707e8936e6e",
                "title": "A Review of Uncertainty Quantification in Deep Learning: Techniques, Applications and Challenges",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "7412048",
                        "name": "Moloud Abdar"
                    },
                    {
                        "authorId": "1866603",
                        "name": "Farhad Pourpanah"
                    },
                    {
                        "authorId": "1833049320",
                        "name": "Sadiq Hussain"
                    },
                    {
                        "authorId": "1404229235",
                        "name": "Dana Rezazadegan"
                    },
                    {
                        "authorId": "2150977916",
                        "name": "Li Liu"
                    },
                    {
                        "authorId": "1678622",
                        "name": "M. Ghavamzadeh"
                    },
                    {
                        "authorId": "1731709",
                        "name": "P. Fieguth"
                    },
                    {
                        "authorId": "1719250",
                        "name": "Xiaochun Cao"
                    },
                    {
                        "authorId": "145434108",
                        "name": "A. Khosravi"
                    },
                    {
                        "authorId": "2066217301",
                        "name": "U. Acharya"
                    },
                    {
                        "authorId": "144531494",
                        "name": "V. Makarenkov"
                    },
                    {
                        "authorId": "1743136",
                        "name": "S. Nahavandi"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "An important, quickly growing family of models is the Dirichlet-based uncertainty (DBU) family (Malinin & Gales, 2018a; 2019; Sensoy et al., 2018; Malinin et al., 2019; Charpentier et al., 2020; Zhao et al., 2020; Nandy et al., 2020; Shi et al., 2020; Sensoy et al., 2020).",
                "\u2026a loss that computes the sum of squares between the on-hot encoded true label y\u2217(i) and the predicted categorical p(i) under the Dirichlet distribution:\nLEvNet = 1\nN \u2211 i Ep(i)\u223cDir(\u03b1(i))||y \u2217(i) \u2212p(i)||2 (3)\nEnsemble Distribution Distillation (DDNet) (Malinin et al., 2019) is trained in two steps.",
                "Ensemble Distribution Distillation (DDNet) (Malinin et al., 2019) is trained in two steps."
            ],
            "citingPaper": {
                "paperId": "9149047232049b40a32d837707c06b497d6dcd27",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2010-14986",
                    "ArXiv": "2010.14986",
                    "MAG": "3097528668",
                    "CorpusId": 225094449
                },
                "corpusId": 225094449,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/9149047232049b40a32d837707c06b497d6dcd27",
                "title": "Evaluating Robustness of Predictive Uncertainty Estimation: Are Dirichlet-based Models Reliable?",
                "abstract": "Robustness to adversarial perturbations and accurate uncertainty estimation are crucial for reliable application of deep learning in real world settings. Dirichlet-based uncertainty (DBU) models are a family of models that predict the parameters of a Dirichlet distribution (instead of a categorical one) and promise to signal when not to trust their predictions. Untrustworthy predictions are obtained on unknown or ambiguous samples and marked with a high uncertainty by the models. In this work, we show that DBU models with standard training are not robust w.r.t. three important tasks in the field of uncertainty estimation. In particular, we evaluate how useful the uncertainty estimates are to (1) indicate correctly classified samples, and (2) to detect adversarial examples that try to fool classification. We further evaluate the reliability of DBU models on the task of (3) distinguishing between in-distribution (ID) and out-of-distribution (OOD) data. To this end, we present the first study of certifiable robustness for DBU models. Furthermore, we propose novel uncertainty attacks that fool models into assigning high confidence to OOD data and low confidence to ID data, respectively. Based on our results, we explore the first approaches to make DBU models more robust. We use adversarial training procedures based on label attacks, uncertainty attacks, or random noise and demonstrate how they affect robustness of DBU models on ID data and OOD data.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "35704776",
                        "name": "Anna-Kathrin Kopetzki"
                    },
                    {
                        "authorId": "50997190",
                        "name": "Bertrand Charpentier"
                    },
                    {
                        "authorId": "3156540",
                        "name": "Daniel Z\u00fcgner"
                    },
                    {
                        "authorId": "73188858",
                        "name": "Sandhya Giri"
                    },
                    {
                        "authorId": "3075189",
                        "name": "Stephan G\u00fcnnemann"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "One possible solution is to distill the ensemble into a single model [14, 15]."
            ],
            "citingPaper": {
                "paperId": "106a86b3c808db59de0f80b0d6c654797d7572a2",
                "externalIds": {
                    "DBLP": "conf/interspeech/WuKGM20",
                    "MAG": "3096582851",
                    "DOI": "10.21437/interspeech.2020-2238",
                    "CorpusId": 226200370
                },
                "corpusId": 226200370,
                "publicationVenue": {
                    "id": "af90489e-312f-4514-bea2-bcb399cb8ece",
                    "name": "Interspeech",
                    "type": "conference",
                    "alternate_names": [
                        "Conf Int Speech Commun Assoc",
                        "INTERSPEECH",
                        "Conference of the International Speech Communication Association"
                    ],
                    "issn": "2308-457X",
                    "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech",
                    "alternate_urls": [
                        "http://www.isca-speech.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/106a86b3c808db59de0f80b0d6c654797d7572a2",
                "title": "Ensemble Approaches for Uncertainty in Spoken Language Assessment",
                "abstract": "Deep learning has dramatically improved the performance of automated systems on a range of tasks including spoken language assessment. One of the issues with these deep learning approaches is that they tend to be overconfident in the decisions that they make, with potentially serious implications for deployment of systems for high-stakes examinations. This paper examines the use of ensemble approaches to improve both the reliability of the scores that are generated, and the ability to detect where the system has made predictions beyond acceptable errors. In this work assessment is treated as a regression problem. Deep density networks, and ensembles of these models, are used as the predictive models. Given an ensemble of models measures of uncertainty, for example the variance of the predicted distributions, can be obtained and used for detecting outlier predictions. However, these ensemble approaches increase the computational and memory requirements of the system. To address this problem the ensemble is distilled into a single mixture density network. The performance of the systems is evaluated on a free speaking prompt-response style spoken language assessment test. Experiments show that the ensembles and the distilled model yield performance gains over a single model, and have the ability to detect outliers.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1847260",
                        "name": "Xixin Wu"
                    },
                    {
                        "authorId": "145962472",
                        "name": "K. Knill"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    },
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "623155f9768d46065d3d4f9639854bbb2f09ae61",
                "externalIds": {
                    "MAG": "3092772963",
                    "DBLP": "conf/uai/CobbJ21",
                    "ArXiv": "2010.06772",
                    "CorpusId": 222341465
                },
                "corpusId": 222341465,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/623155f9768d46065d3d4f9639854bbb2f09ae61",
                "title": "Scaling Hamiltonian Monte Carlo Inference for Bayesian Neural Networks with Symmetric Splitting",
                "abstract": "Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) approach that exhibits favourable exploration properties in high-dimensional models such as neural networks. Unfortunately, HMC has limited use in large-data regimes and little work has explored suitable approaches that aim to preserve the entire Hamiltonian. In our work, we introduce a new symmetric integration scheme for split HMC that does not rely on stochastic gradients. We show that our new formulation is more efficient than previous approaches and is easy to implement with a single GPU. As a result, we are able to perform full HMC over common deep learning architectures using entire data sets. In addition, when we compare with stochastic gradient MCMC, we show that our method achieves better performance in both accuracy and uncertainty quantification. Our approach demonstrates HMC as a feasible option when considering inference schemes for large-scale machine learning problems.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "36119737",
                        "name": "Adam D. Cobb"
                    },
                    {
                        "authorId": "50039334",
                        "name": "Brian Jalaian"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Recently Malinin et al. (2020) showed that by instead distilling the distribution over the ensemble into a prior network (Malinin and Gales, 2018), the student can learn to model both the epistemic and aleatory uncertainty of the ensemble."
            ],
            "citingPaper": {
                "paperId": "038e28a5e121ee3c7508dee329b3af9ba79fa818",
                "externalIds": {
                    "ACL": "2020.emnlp-main.450",
                    "MAG": "3092653948",
                    "DBLP": "journals/corr/abs-2010-06721",
                    "ArXiv": "2010.06721",
                    "DOI": "10.18653/v1/2020.emnlp-main.450",
                    "CorpusId": 222341831
                },
                "corpusId": 222341831,
                "publicationVenue": {
                    "id": "41bf9ed3-85b3-4c90-b015-150e31690253",
                    "name": "Conference on Empirical Methods in Natural Language Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Empir Method Nat Lang Process",
                        "Empirical Methods in Natural Language Processing",
                        "Conf Empir Method Nat Lang Process",
                        "EMNLP"
                    ],
                    "url": "https://www.aclweb.org/portal/emnlp"
                },
                "url": "https://www.semanticscholar.org/paper/038e28a5e121ee3c7508dee329b3af9ba79fa818",
                "title": "Ensemble Distillation for Structured Prediction: Calibrated, Accurate, Fast\u2014Choose Three",
                "abstract": "Modern neural networks do not always produce well-calibrated predictions, even when trained with a proper scoring function such as cross-entropy. In classification settings, simple methods such as isotonic regression or temperature scaling may be used in conjunction with a held-out dataset to calibrate model outputs. However, extending these methods to structured prediction is not always straightforward or effective; furthermore, a held-out calibration set may not always be available. In this paper, we study ensemble distillation as a general framework for producing well-calibrated structured prediction models while avoiding the prohibitive inference-time cost of ensembles. We validate this framework on two tasks: named-entity recognition and machine translation. We find that, across both tasks, ensemble distillation produces models which retain much of, and occasionally improve upon, the performance and calibration benefits of ensembles, while only requiring a single model during test-time.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "145653742",
                        "name": "Steven Reich"
                    },
                    {
                        "authorId": "1476810451",
                        "name": "David Mueller"
                    },
                    {
                        "authorId": "145580321",
                        "name": "Nicholas Andrews"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "Ensemble Distribution Distillation [15] proposes a way to both preserve the distributional information of an ensemble and improve the performance of a Prior Network."
            ],
            "citingPaper": {
                "paperId": "6d714602498eea7c17cdb15a1f5625880fe06d8b",
                "externalIds": {
                    "MAG": "3092886549",
                    "DBLP": "conf/mm/LiangZZJTW20",
                    "DOI": "10.1145/3394171.3414069",
                    "CorpusId": 222277920
                },
                "corpusId": 222277920,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6d714602498eea7c17cdb15a1f5625880fe06d8b",
                "title": "Task Decoupled Knowledge Distillation For Lightweight Face Detectors",
                "abstract": "Face detection is a hot topic in computer vision. The face detection methods usually consist of two subtasks, i.e. the classification subtask and the regression subtask, which are trained with different samples. However, current face detection knowledge distillation methods usually couple the two subtasks, and use the same set of samples in the distillation task. In this paper, we propose a task decoupled knowledge distillation method, which decouples the detection distillation task into two subtasks and uses different samples in distilling the features of different subtasks. We firstly propose a feature decoupling method to decouple the classification features and the regression features, without introducing any extra calculations at inference time. Specifically, we generate the corresponding features by adding task-specific convolutions in the teacher network and adding adaption convolutions on the feature maps of the student network. Then we select different samples for different subtasks to imitate. Moreover, we also propose an effective probability distillation method to joint boost the accuracy of the student network. We apply our distillation method on a lightweight face detector, EagleEye. Experimental results show that the proposed method effectively improves the student detector's accuracy by 5.1%, 5.1%, and 2.8% AP in Easy, Medium, Hard subsets respectively.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "34142560",
                        "name": "Xiaoqing Liang"
                    },
                    {
                        "authorId": "2118489444",
                        "name": "Xu Zhao"
                    },
                    {
                        "authorId": "34127238",
                        "name": "Chaoyang Zhao"
                    },
                    {
                        "authorId": "1993566746",
                        "name": "Nanfei Jiang"
                    },
                    {
                        "authorId": "2113727378",
                        "name": "Ming Tang"
                    },
                    {
                        "authorId": "49606029",
                        "name": "Jinqiao Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "This distribution could be seen as the ensemble estimate of the posterior, p(\u03b8|D), (Malinin et al., 2019; Malinin and Gales, 2020)."
            ],
            "citingPaper": {
                "paperId": "11a85815235ed7d634d90818aa9e81356bb151c1",
                "externalIds": {
                    "DBLP": "conf/emnlp/NiekerkHGLLMG20",
                    "ACL": "2020.findings-emnlp.277",
                    "MAG": "3103996868",
                    "ArXiv": "2010.02586",
                    "DOI": "10.18653/v1/2020.findings-emnlp.277",
                    "CorpusId": 222141613
                },
                "corpusId": 222141613,
                "publicationVenue": {
                    "id": "479d5605-51be-4346-b1d6-4334084504df",
                    "name": "Findings",
                    "type": "journal",
                    "issn": "2652-8800",
                    "url": "https://findingspress.org/"
                },
                "url": "https://www.semanticscholar.org/paper/11a85815235ed7d634d90818aa9e81356bb151c1",
                "title": "Knowing What You Know: Calibrating Dialogue Belief State Distributions via Ensembles",
                "abstract": "The ability to accurately track what happens during a conversation is essential for the performance of a dialogue system. Current state-of-the-art multi-domain dialogue state trackers achieve just over 55% accuracy on the current go-to benchmark, which means that in almost every second dialogue turn they place full confidence in an incorrect dialogue state. Belief trackers, on the other hand, maintain a distribution over possible dialogue states. However, they lack in performance compared to dialogue state trackers, and do not produce well calibrated distributions. In this work we present state-of-the-art performance in calibration for multi-domain dialogue belief trackers using a calibrated ensemble of models. Our resulting dialogue belief tracker also outperforms previous dialogue belief tracking models in terms of accuracy.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "113869710",
                        "name": "Carel van Niekerk"
                    },
                    {
                        "authorId": "113469882",
                        "name": "Michael Heck"
                    },
                    {
                        "authorId": "1676966139",
                        "name": "Christian Geishauser"
                    },
                    {
                        "authorId": "21149156",
                        "name": "Hsien-Chin Lin"
                    },
                    {
                        "authorId": "143604111",
                        "name": "Nurul Lubis"
                    },
                    {
                        "authorId": "34990682",
                        "name": "M. Moresi"
                    },
                    {
                        "authorId": "1676892968",
                        "name": "Milica Gavsi'c"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Recently, there have been ensemblebased attempts [4, 41, 38, 22] to train a student network based on many peers or students without considering the single teacher network, which is a slight lack of considerar X iv :2 00 9."
            ],
            "citingPaper": {
                "paperId": "5e1b76361163a2a61b8652d8769109b1fe1cd4b2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2009-08825",
                    "ArXiv": "2009.08825",
                    "MAG": "3087455515",
                    "DOI": "10.1109/ICCV48922.2021.00926",
                    "CorpusId": 221802641
                },
                "corpusId": 221802641,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/5e1b76361163a2a61b8652d8769109b1fe1cd4b2",
                "title": "Densely Guided Knowledge Distillation using Multiple Teacher Assistants",
                "abstract": "With the success of deep neural networks, knowledge distillation which guides the learning of a small student network from a large teacher network is being actively studied for model compression and transfer learning. However, few studies have been performed to resolve the poor learning issue of the student network when the student and teacher model sizes significantly differ. In this paper, we propose a densely guided knowledge distillation using multiple teacher assistants that gradually decreases the model size to efficiently bridge the large gap between the teacher and student networks. To stimulate more efficient learning of the student network, we guide each teacher assistant to every other smaller teacher assistants iteratively. Specifically, when teaching a smaller teacher assistant at the next step, the existing larger teacher assistants from the previous step are used as well as the teacher network. Moreover, we design stochastic teaching where, for each mini-batch, a teacher or teacher assistants are randomly dropped. This acts as a regularizer to improve the efficiency of teaching of the student network. Thus, the student can always learn salient distilled knowledge from the multiple sources. We verified the effectiveness of the proposed method for a classification task using CIFAR-10, CIFAR-100, and ImageNet. We also achieved significant performance improvements with various backbone architectures such as ResNet, WideResNet, and VGG.1",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1557388434",
                        "name": "Wonchul Son"
                    },
                    {
                        "authorId": "107598106",
                        "name": "Jaemin Na"
                    },
                    {
                        "authorId": "34600044",
                        "name": "Wonjun Hwang"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "To examine the effectiveness of using deep ensembles as teachers [32], we train an ensemble of deterministic neural networks with aleatoric uncertainty [25].",
                "Most similar to our method is [32], which uses the Dirichlet distribution to approximate predictive distribution of an ensemble of networks.",
                "Dirichlet distribution is not used to approximate teacher\u2019s predictive distribution for classification as in [32] because we empirically found it very numerically unstable and led to failure of convergence."
            ],
            "citingPaper": {
                "paperId": "fb65b94fbfd522e3a4c9c26c62610b43fc389e44",
                "externalIds": {
                    "MAG": "3099665946",
                    "DBLP": "conf/wacv/ShenZSS21",
                    "DOI": "10.1109/WACV48630.2021.00075",
                    "CorpusId": 226278009
                },
                "corpusId": 226278009,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/fb65b94fbfd522e3a4c9c26c62610b43fc389e44",
                "title": "Real-Time Uncertainty Estimation in Computer Vision via Uncertainty-Aware Distribution Distillation",
                "abstract": "Calibrated estimates of uncertainty are critical for many real-world computer vision applications of deep learning. While there are several widely-used uncertainty estimation methods, dropout inference [11] stands out for its simplicity and efficacy. This technique, however, requires multiple forward passes through the network during inference and therefore can be too resource-intensive to be deployed in real-time applications. We propose a simple, easy-to-optimize distillation method for learning the conditional predictive distribution of a pre-trained dropout model for fast, sample-free uncertainty estimation in computer vision tasks. We empirically test the effectiveness of the proposed method on both semantic segmentation and depth estimation tasks, and demonstrate our method can significantly reduce the inference time, enabling real-time uncertainty quantification, while achieving improved quality of both the uncertainty estimates and predictive performance over the regular dropout model.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2115383854",
                        "name": "Yichen Shen"
                    },
                    {
                        "authorId": "1491240545",
                        "name": "Zhilu Zhang"
                    },
                    {
                        "authorId": "2369409",
                        "name": "M. Sabuncu"
                    },
                    {
                        "authorId": "2145127186",
                        "name": "Lin Sun"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[32] proposed a similar distillation approach from an ensemble of networks."
            ],
            "citingPaper": {
                "paperId": "0cf620c82149380acfab4aafb439f0a3f5b918f1",
                "externalIds": {
                    "ArXiv": "2007.15857",
                    "MAG": "3046504055",
                    "DBLP": "journals/corr/abs-2007-15857",
                    "CorpusId": 220919747
                },
                "corpusId": 220919747,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0cf620c82149380acfab4aafb439f0a3f5b918f1",
                "title": "Learning the Distribution: A Unified Distillation Paradigm for Fast Uncertainty Estimation in Computer Vision",
                "abstract": "Calibrated estimates of uncertainty are critical for many real-world computer vision applications of deep learning. While there are several widely-used uncertainty estimation methods, dropout inference stands out for its simplicity and efficacy. This technique, however, requires multiple forward passes through the network during inference and therefore can be too resource-intensive to be deployed in real-time applications. To tackle this issue, we propose a unified distillation paradigm for learning the conditional predictive distribution of a pre-trained dropout model for fast uncertainty estimation of both aleatoric and epistemic uncertainty at the same time. We empirically test the effectiveness of the proposed method on both semantic segmentation and depth estimation tasks, and observe that the student model can well approximate the probability distribution generated by the teacher model, i.e the pre-trained dropout model. In addition to a significant boost in speed, we demonstrate the quality of uncertainty estimates and the overall predictive performance can also be improved with the proposed method.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2115383854",
                        "name": "Yichen Shen"
                    },
                    {
                        "authorId": "1491240545",
                        "name": "Zhilu Zhang"
                    },
                    {
                        "authorId": "2369409",
                        "name": "M. Sabuncu"
                    },
                    {
                        "authorId": "2145127186",
                        "name": "Lin Sun"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "(2018), Malinin et al. (2020) and Vadera et al.",
                "In recent work, Wang et al. (2018), Malinin et al. (2020) and Vadera et al. (2020a) have leveraged this decomposition to explore a range of down-stream tasks that rely on uncertainty quantification and decomposition.",
                "For example, Depeweg et al. (2017) and Malinin et al. (2020) describe the decomposition of the entropy of the posterior predictive distribution (the total uncertainty) into expected data uncertainty and knowledge uncertainty."
            ],
            "citingPaper": {
                "paperId": "64ec522e9f1c4d9b23b9aff4d829e9893373dff5",
                "externalIds": {
                    "ArXiv": "2007.04466",
                    "DBLP": "journals/corr/abs-2007-04466",
                    "MAG": "3042018560",
                    "CorpusId": 220424461
                },
                "corpusId": 220424461,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/64ec522e9f1c4d9b23b9aff4d829e9893373dff5",
                "title": "URSABench: Comprehensive Benchmarking of Approximate Bayesian Inference Methods for Deep Neural Networks",
                "abstract": "While deep learning methods continue to improve in predictive accuracy on a wide range of application domains, significant issues remain with other aspects of their performance including their ability to quantify uncertainty and their robustness. Recent advances in approximate Bayesian inference hold significant promise for addressing these concerns, but the computational scalability of these methods can be problematic when applied to large-scale models. In this paper, we describe initial work on the development ofURSABench(the Uncertainty, Robustness, Scalability, and Accu-racy Benchmark), an open-source suite of bench-marking tools for comprehensive assessment of approximate Bayesian inference methods with a focus on deep learning-based classification tasks",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "71008399",
                        "name": "Meet P. Vadera"
                    },
                    {
                        "authorId": "36119737",
                        "name": "Adam D. Cobb"
                    },
                    {
                        "authorId": "3116427",
                        "name": "B. Jalaeian"
                    },
                    {
                        "authorId": "1805742",
                        "name": "Benjamin M Marlin"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "KD has been used to provide a fast approximation to Bayesian Neural Networks [4, 38, 16].",
                "Bayesian Neural Networks implicitly estimate the uncertainty via MonteCarlo sampling of the network parameters."
            ],
            "citingPaper": {
                "paperId": "007c24576b4a2f58d50c79047008283252cc27d7",
                "externalIds": {
                    "MAG": "3039562825",
                    "DBLP": "conf/cvpr/PouransariJST21",
                    "ArXiv": "2007.00051",
                    "DOI": "10.1109/CVPRW53098.2021.00338",
                    "CorpusId": 220280430
                },
                "corpusId": 220280430,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/007c24576b4a2f58d50c79047008283252cc27d7",
                "title": "Extracurricular Learning: Knowledge Transfer Beyond Empirical Distribution",
                "abstract": "Knowledge distillation has been used to transfer knowledge learned by a sophisticated model (teacher) to a simpler model (student). This technique is widely used to compress model complexity. However, in most applications the compressed student model suffers from an accuracy gap with its teacher. We propose extracurricular learning, a novel knowledge distillation method, that bridges this gap by (1) modeling student and teacher output distributions; (2) sampling examples from an approximation to the underlying data distribution; and (3) matching student and teacher output distributions over this extended set including uncertain samples. We conduct rigorous evaluations on regression and classification tasks and show that compared to the standard knowledge distillation, extracurricular learning reduces the gap by 46% to 68%. This leads to major accuracy improvements compared to the empirical risk minimization-based training for various recent neural network architectures: 16% regression error reduction on the MPIIGaze dataset, +3.4% to +9.1% improvement in top-1 classification accuracy on the CIFAR100 dataset, and +2.9% top-1 improvement on the ImageNet dataset.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1842915",
                        "name": "H. Pouransari"
                    },
                    {
                        "authorId": "2577513",
                        "name": "Oncel Tuzel"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", 2020) and ensemble distribution distillation (Malinin et al., 2020).",
                "\u2026et al., 2018), scalable Gaussian processes (Milios et al., 2018), sampling-free uncertainty estimation (Postels et al., 2019), data augmentation (Patel et al., 2019; Thulasidasan et al., 2019; Yun et al., 2019; Hendrycks et al., 2020) and ensemble distribution distillation (Malinin et al., 2020)."
            ],
            "citingPaper": {
                "paperId": "ecafa739f42dea74c23d7a3bb4ab613aeb86d1aa",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2006-13092",
                    "ArXiv": "2006.13092",
                    "MAG": "3036157921",
                    "CorpusId": 219981345
                },
                "corpusId": 219981345,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/ecafa739f42dea74c23d7a3bb4ab613aeb86d1aa",
                "title": "Multi-Class Uncertainty Calibration via Mutual Information Maximization-based Binning",
                "abstract": "Post-hoc calibration is a common approach for providing high-quality confidence estimates of deep neural network predictions. Recent work has shown that widely used scaling methods underestimate their calibration error, while alternative Histogram Binning (HB) methods with verifiable calibration performance often fail to preserve classification accuracy. In the case of multi-class calibration with a large number of classes K, HB also faces the issue of severe sample-inefficiency due to a large class imbalance resulting from the conversion into K one-vs-rest class-wise calibration problems. The goal of this paper is to resolve the identified issues of HB in order to provide verified and calibrated confidence estimates using only a small holdout calibration dataset for bin optimization while preserving multi-class ranking accuracy. From an information-theoretic perspective, we derive the I-Max concept for binning, which maximizes the mutual information between labels and binned (quantized) logits. This concept mitigates potential loss in ranking performance due to lossy quantization, and by disentangling the optimization of bin edges and representatives allows simultaneous improvement of ranking and calibration performance. In addition, we propose a shared class-wise (sCW) binning strategy that fits a single calibrator on the merged training sets of all K class-wise problems, yielding reliable estimates from a small calibration set. The combination of sCW and I-Max binning outperforms the state of the art calibration methods on various evaluation metrics across different benchmark datasets and models, even when using only a small set of calibration data, e.g. 1k samples for ImageNet.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "51290549",
                        "name": "Kanil Patel"
                    },
                    {
                        "authorId": "52020792",
                        "name": "William H. Beluch"
                    },
                    {
                        "authorId": "49188662",
                        "name": "Binh Yang"
                    },
                    {
                        "authorId": "144578436",
                        "name": "Michael Pfeiffer"
                    },
                    {
                        "authorId": "2109979241",
                        "name": "Dan Zhang"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "This suggests that the curriculum learning introduced by temperature annealing is useful, but not as critical as it is for classification EnD(2) [21].",
                "Curiously, standard ensemble distillation (EnD) does much worse than even a single model, which was an effect that was also observed for classification models in [21].",
                "In Table 2 we compare uncertainty measures derived from all models on the tasks of error detection and OOD detection, which are evaluated using Prediction Rejection Ratio (PRR) [21, 15] and AUCROC [28], respectively.",
                "Table 7 shows the error detection peformane of all models in terms of prediction-rejection ratio (% PRR) [15].",
                "An interesting task which Prior Networks can solve is Ensemble Distribution Distillation (EnD(2)) [21], where the distribution of an ensemble\u2019s predictions is distilled into a single model.",
                "Similarly to [21] we propose a temperature-annealing trick to make the optimization process easier.",
                "This can be overcome via Ensemble Distribution Distillation (EnD(2)) [21], which is an approach that allows distilling ensembles into Prior Networks such that measures of ensemble diversity are"
            ],
            "citingPaper": {
                "paperId": "04a06ddf19f3a466a6f775d3e879bb412a563aab",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2006-11590",
                    "ArXiv": "2006.11590",
                    "MAG": "3036729765",
                    "CorpusId": 219966872
                },
                "corpusId": 219966872,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/04a06ddf19f3a466a6f775d3e879bb412a563aab",
                "title": "Regression Prior Networks",
                "abstract": "Prior Networks are a recently developed class of models which yield interpretable measures of uncertainty and have been shown to outperform state-of-the-art ensemble approaches on a range of tasks. They can also be used to distill an ensemble of models via Ensemble Distribution Distillation (EnD$^2$), such that its accuracy, calibration and uncertainty estimates are retained within a single model. However, Prior Networks have so far been developed only for classification tasks. This work extends Prior Networks and EnD$^2$ to regression tasks by considering the Normal-Wishart distribution. The properties of Regression Prior Networks are demonstrated on synthetic data, selected UCI datasets and a monocular depth estimation task, where they yield performance competitive with ensemble approaches.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    },
                    {
                        "authorId": "1753629179",
                        "name": "Sergey Chervontsev"
                    },
                    {
                        "authorId": "1390051629",
                        "name": "Ivan Provilkov"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "To reduce inference time of ensembles, one could use a single network to mimic behavior of ensembles as pioneered by born-again tree [6] and knowledge distillation [5, 7, 19, 32]."
            ],
            "citingPaper": {
                "paperId": "a6b499136aa70dfad66fca5efaaaead5c616d59b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2006-11487",
                    "ArXiv": "2006.11487",
                    "MAG": "3035804116",
                    "CorpusId": 219966170
                },
                "corpusId": 219966170,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/a6b499136aa70dfad66fca5efaaaead5c616d59b",
                "title": "Paying more Attention to Snapshots of Iterative Pruning: Improving Model Compression via Ensemble Distillation",
                "abstract": "Network pruning is one of the most dominant methods for reducing the heavy inference cost of deep neural networks. Existing methods often iteratively prune networks to attain high compression ratio without incurring significant loss in performance. However, we argue that conventional methods for retraining pruned networks (i.e., using small, fixed learning rate) are inadequate as they completely ignore the benefits from snapshots of iterative pruning. In this work, we show that strong ensembles can be constructed from snapshots of iterative pruning, which achieve competitive performance and vary in network structure. Furthermore, we present simple, general and effective pipeline that generates strong ensembles of networks during pruning with large learning rate restarting, and utilizes knowledge distillation with those ensembles to improve the predictive power of compact models. In standard image classification benchmarks such as CIFAR and Tiny-Imagenet, we advance state-of-the-art pruning ratio of structured pruning by integrating simple l1-norm filters pruning into our pipeline. Specifically, we reduce 75-80% of total parameters and 65-70% MACs of numerous variants of ResNet architectures while having comparable or better performance than that of original networks. Code associate with this paper is made publicly available at this https URL.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2059393417",
                        "name": "Duong H. Le"
                    },
                    {
                        "authorId": "1753622419",
                        "name": "Vo Trung Nhan"
                    },
                    {
                        "authorId": "145189320",
                        "name": "N. Thoai"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "Table 2 shows that measures of knowledge uncertainty yield superior OOD detection performance compared to total uncertainty in terms of AUC-ROC, which is consistent with results for non-GBDT models [10, 26, 24].",
                "Test errors can occur due to both data and knowledge uncertainty, so we expect that ranking elements by total uncertainty would give better values of PRR. Table 2 shows that measures of total uncertainty consistently yield better PPR results across all classification and regression datasets.",
                "This is consistent with results obtained for ensembles of neural networks models [14, 10, 26, 24].",
                "For PRR and AUC-ROC results (for classification and Years) we highlight the best value.",
                "Error detection and rejection based on measures of uncertainty is assessed via the Prediction-Rejection Ratio (PRR) [10, 24], which measures how well uncertainty estimates correlate with errors and rank-order them."
            ],
            "citingPaper": {
                "paperId": "4528b9f6eb57cb7f180060150877616c956a63fd",
                "externalIds": {
                    "ArXiv": "2006.10562",
                    "MAG": "3036496056",
                    "DBLP": "journals/corr/abs-2006-10562",
                    "CorpusId": 219792740
                },
                "corpusId": 219792740,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/4528b9f6eb57cb7f180060150877616c956a63fd",
                "title": "Uncertainty in Gradient Boosting via Ensembles",
                "abstract": "Gradient boosting is a powerful machine learning technique that is particularly successful for tasks containing heterogeneous features and noisy data. While gradient boosting classification models return a distribution over class labels, regressions models typically yield only point predictions. However, for many practical, high-risk applications, it is also important to be able to quantify uncertainty in the predictions to avoid costly mistakes. In this work, we examine a probabilistic ensemble-based framework for deriving uncertainty estimates in the predictions of gradient boosting classification and regression models. Crucially, the proposed approach allows the total uncertainty to be decomposed into \\textit{data uncertainty}, which comes from the complexity and noise in data distribution, and \\textit{knowledge uncertainty}, coming from the lack of information about a given region of the feature space. Two approaches for generating ensembles are considered: Stochastic Gradient Boosting (SGB) and Stochastic Gradient Langevin Boosting (SGLB). Notably, SGLB also enables the generation of a \\emph{virtual} ensemble via only one gradient boosting model, which significantly reduces complexity. Experiments on a range of regression and classification datasets show that ensembles of gradient boosting models yield improved predictive performance, and measures of uncertainty successfully enable detection of out-of-domain inputs.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "146211662",
                        "name": "Aleksei Ustimenko"
                    },
                    {
                        "authorId": "51270819",
                        "name": "L. Prokhorenkova"
                    },
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "cb8bb50e4b84739b9d3477eead0707d8c3a84cd8",
                "externalIds": {
                    "MAG": "3034212248",
                    "ArXiv": "2006.07006",
                    "DBLP": "journals/corr/abs-2006-07006",
                    "CorpusId": 219635994
                },
                "corpusId": 219635994,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/cb8bb50e4b84739b9d3477eead0707d8c3a84cd8",
                "title": "Background Modeling via Uncertainty Estimation for Weakly-supervised Action Localization",
                "abstract": "Weakly-supervised temporal action localization aims to detect intervals of action instances with only video-level action labels for training. A crucial challenge is to separate frames of action classes from remaining, denoted as background frames (i.e., frames not belonging to any action class). Previous methods attempt background modeling by either synthesizing pseudo background videos with static frames or introducing an auxiliary class for background. However, they overlook an essential fact that background frames could be dynamic and inconsistent. Accordingly, we cast the problem of identifying background frames as out-of-distribution detection and isolate it from conventional action classification. Beyond our base action localization network, we propose a module to estimate the probability of being background (i.e., uncertainty [20]), which allows us to learn uncertainty given only video-level labels via multiple instance learning. A background entropy loss is further designed to reject background frames by forcing them to have uniform probability distribution for action classes. Extensive experiments verify the effectiveness of our background modeling and show that our method significantly outperforms state-of-the-art methods on the standard benchmarks - THUMOS'14 and ActivityNet (1.2 and 1.3). Our code and the trained model are available at this https URL.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1429148175",
                        "name": "Pilhyeon Lee"
                    },
                    {
                        "authorId": "2110107884",
                        "name": "Jinglu Wang"
                    },
                    {
                        "authorId": "2146557916",
                        "name": "Yan Lu"
                    },
                    {
                        "authorId": "144036125",
                        "name": "H. Byun"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "More recently, there has also been work on the importance of distillation from an ensemble of model [24], which provides a complementary view on the role of predictive diversity."
            ],
            "citingPaper": {
                "paperId": "2bdfc6d8f6d03b38b80b8aa4112088323b6b552f",
                "externalIds": {
                    "MAG": "3035409869",
                    "ArXiv": "2006.05065",
                    "DBLP": "conf/nips/ZhangS20",
                    "CorpusId": 219558831
                },
                "corpusId": 219558831,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2bdfc6d8f6d03b38b80b8aa4112088323b6b552f",
                "title": "Self-Distillation as Instance-Specific Label Smoothing",
                "abstract": "It has been recently demonstrated that multi-generational self-distillation can improve generalization. Despite this intriguing observation, reasons for the enhancement remain poorly understood. In this paper, we first demonstrate experimentally that the improved performance of multi-generational self-distillation is in part associated with the increasing diversity in teacher predictions. With this in mind, we offer a new interpretation for teacher-student training as amortized MAP estimation, such that teacher predictions enable instance-specific regularization. Our framework allows us to theoretically relate self-distillation to label smoothing, a commonly used technique that regularizes predictive uncertainty, and suggests the importance of predictive diversity in addition to predictive uncertainty. We present experimental results using multiple datasets and neural network architectures that, overall, demonstrate the utility of predictive diversity. Finally, we propose a novel instance-specific label smoothing technique that promotes predictive diversity without the need for a separately trained teacher model. We provide an empirical evaluation of the proposed method, which, we find, often outperforms classical label smoothing.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1491240545",
                        "name": "Zhilu Zhang"
                    },
                    {
                        "authorId": "2369409",
                        "name": "M. Sabuncu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ") [26], which learns Dirichlet distributions with maximum likelihood by using soft-labels from an ensemble of networks."
            ],
            "citingPaper": {
                "paperId": "88ad2dcaf79cccfdafbbfa2d2152cc44f61eef98",
                "externalIds": {
                    "MAG": "3035478617",
                    "DBLP": "journals/corr/abs-2006-09239",
                    "ArXiv": "2006.09239",
                    "CorpusId": 219708927
                },
                "corpusId": 219708927,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/88ad2dcaf79cccfdafbbfa2d2152cc44f61eef98",
                "title": "Posterior Network: Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts",
                "abstract": "Accurate estimation of aleatoric and epistemic uncertainty is crucial to build safe and reliable systems. Traditional approaches, such as dropout and ensemble methods, estimate uncertainty by sampling probability predictions from different submodels, which leads to slow uncertainty estimation at inference time. Recent works address this drawback by directly predicting parameters of prior distributions over the probability predictions with a neural network. While this approach has demonstrated accurate uncertainty estimation, it requires defining arbitrary target parameters for in-distribution data and makes the unrealistic assumption that out-of-distribution (OOD) data is known at training time. \nIn this work we propose the Posterior Network (PostNet), which uses Normalizing Flows to predict an individual closed-form posterior distribution over predicted probabilites for any input sample. The posterior distributions learned by PostNet accurately reflect uncertainty for in- and out-of-distribution data -- without requiring access to OOD data at training time. PostNet achieves state-of-the art results in OOD detection and in uncertainty calibration under dataset shifts.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "50997190",
                        "name": "Bertrand Charpentier"
                    },
                    {
                        "authorId": "3156540",
                        "name": "Daniel Z\u00fcgner"
                    },
                    {
                        "authorId": "3075189",
                        "name": "Stephan G\u00fcnnemann"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "For example, Depeweg et al. (2017) and Malinin et al. (2020) describe the decomposition of the entropy of the posterior predictive distribution (the total uncertainty) into expected data uncertainty and knowledge uncertainty.",
                "(2018) and Malinin et al. (2020) has investigated leveraging multiple statistics of ensembles (both general ensembles and Monte Carlo representations of Bayesian posteriors) for performing tasks that leverage uncertainty quantification and uncertainty decomposition including out-ofdistribution detection and uncertainty-based ranking.",
                "In recent work, Wang et al. (2018) and Malinin et al. (2020) have leveraged this decomposition to explore a range of down-stream tasks that rely on uncertainty quantification and decomposition.",
                "Ensemble distribution distillation (EnD2) is a closely related approach that aims to distill the collective outputs of the models in an ensemble into a neural network that predicts the parameters of a Dirichlet distribution (Malinin et al., 2020).",
                "We compare the GPED framework to the full Monte Carlo ensemble as well as to an adaptation of Ensemble Distribution Distillation (EnD2) (Malinin et al., 2020).",
                "We further show that our direct generalized posterior distillation framework outperforms an adaptation of the approach of Malinin et al. (2020) both on terms of distillation performance and in terms of several downstream tasks that leverage uncertainty quantification.",
                "Our goal in this paper is broadly similar, although we focus specifically on distilling much larger Monte Carlo posterior ensembles and we avoid the parametric distribution assumptions of (Malinin et al., 2020) by directly distilling posterior expectations of interest.",
                "Indeed, recent work including Wang et al. (2018) and Malinin et al. (2020) has investigated leveraging multiple statistics of ensembles (both general ensembles and Monte Carlo representations of Bayesian posteriors) for performing tasks that leverage uncertainty quantification and uncertainty\u2026",
                "We instead use Algorithm 1 with the Dirichlet log likelihood distillation loss used by Malinin et al. (2020) (see Appendix A.3 for EnD2 implementation details).",
                "We compare the GPED framework to the full Monte Carlo ensemble as well as to an adaptation of Ensemble Distribution Distillation (EnD2) (Malinin et al., 2020). In particular, Malinin et al. (2020) materialize a complete ensemble, which is not feasible in our case due to the large number of samples in the Bayesian ensemble (\u21e0 105 samples).",
                "We compare the GPED framework to the full Monte Carlo ensemble as well as to an adaptation of Ensemble Distribution Distillation (EnD2) (Malinin et al., 2020). In particular, Malinin et al. (2020) materialize a complete ensemble, which is not feasible in our case due to the large number of samples in the Bayesian ensemble (\u21e0 105 samples). We instead use Algorithm 1 with the Dirichlet log likelihood distillation loss used by Malinin et al. (2020) (see Appendix A.",
                "In particular, Malinin et al. (2020) materialize a complete ensemble, which is not feasible in our case due to the large number of samples in the Bayesian ensemble (\u21e0 105 samples).",
                "(2018) and Malinin et al. (2020) have leveraged this decomposition to explore a range of down-stream tasks that rely on uncertainty quantification and decomposition."
            ],
            "citingPaper": {
                "paperId": "1eceac42e6227d37600c145f4bb10911e845d6dc",
                "externalIds": {
                    "ArXiv": "2005.08110",
                    "DBLP": "conf/uai/VaderaJM20",
                    "MAG": "2998352186",
                    "CorpusId": 213491882
                },
                "corpusId": 213491882,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/1eceac42e6227d37600c145f4bb10911e845d6dc",
                "title": "Generalized Bayesian Posterior Expectation Distillation for Deep Neural Networks",
                "abstract": "In this paper, we present a general framework for distilling expectations with respect to the Bayesian posterior distribution of a deep neural network classifier, extending prior work on the Bayesian Dark Knowledge framework. The proposed framework takes as input \"teacher\" and student model architectures and a general posterior expectation of interest. The distillation method performs an online compression of the selected posterior expectation using iteratively generated Monte Carlo samples. We focus on the posterior predictive distribution and expected entropy as distillation targets. We investigate several aspects of this framework including the impact of uncertainty and the choice of student model architecture. We study methods for student model architecture search from a speed-storage-accuracy perspective and evaluate down-stream tasks leveraging entropy distillation including uncertainty ranking and out-of-distribution detection.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "71008399",
                        "name": "Meet P. Vadera"
                    },
                    {
                        "authorId": "3116427",
                        "name": "B. Jalaeian"
                    },
                    {
                        "authorId": "1805742",
                        "name": "Benjamin M Marlin"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[151] point out that estimating the model\u2019s uncertainty is crucial since it ensures more reliable knowledge to be transferred.",
                "Although various methods have been proposed to extract knowledge from logits, some works [37], [151], [161], [267] show that KD is not always practical due to knowledge uncertainty."
            ],
            "citingPaper": {
                "paperId": "2528a82dd2266600d4ee2b54165556a984de94d4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2004-05937",
                    "ArXiv": "2004.05937",
                    "MAG": "3015735225",
                    "DOI": "10.1109/TPAMI.2021.3055564",
                    "CorpusId": 215745611,
                    "PubMed": "33513099"
                },
                "corpusId": 215745611,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2528a82dd2266600d4ee2b54165556a984de94d4",
                "title": "Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks",
                "abstract": "Deep neural models, in recent years, have been successful in almost every field, even solving the most complex problem statements. However, these models are huge in size with millions (and even billions) of parameters, demanding heavy computation power and failing to be deployed on edge devices. Besides, the performance boost is highly dependent on redundant labeled data. To achieve faster speeds and to handle the problems caused by the lack of labeled data, knowledge distillation (KD) has been proposed to transfer information learned from one model to another. KD is often characterized by the so-called \u2018Student-Teacher\u2019 (S-T) learning framework and has been broadly applied in model compression and knowledge transfer. This paper is about KD and S-T learning, which are being actively studied in recent years. First, we aim to provide explanations of what KD is and how/why it works. Then, we provide a comprehensive survey on the recent progress of KD methods together with S-T frameworks typically used for vision tasks. In general, we investigate some fundamental questions that have been driving this research area and thoroughly generalize the research progress and technical details. Additionally, we systematically analyze the research status of KD in vision applications. Finally, we discuss the potentials and open challenges of existing methods and prospect the future directions of KD and S-T learning.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2144734901",
                        "name": "Lin Wang"
                    },
                    {
                        "authorId": "51182421",
                        "name": "Kuk-Jin Yoon"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "[59] combined KD with ensemble learning and proposed ensemble distribution distillation to improved classification performance."
            ],
            "citingPaper": {
                "paperId": "5cfccc8ae1b7f6cb9bb4510b807289ed49b46359",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2004-03303",
                    "ArXiv": "2004.03303",
                    "MAG": "3016001163",
                    "CorpusId": 215238308
                },
                "corpusId": 215238308,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5cfccc8ae1b7f6cb9bb4510b807289ed49b46359",
                "title": "Towards Efficient Unconstrained Palmprint Recognition via Deep Distillation Hashing",
                "abstract": "Deep palmprint recognition has become an emerging issue with great potential for personal authentication on handheld and wearable consumer devices. Previous studies of palmprint recognition are mainly based on constrained datasets collected by dedicated devices in controlled environments, which has to reduce the flexibility and convenience. In addition, general deep palmprint recognition algorithms are often too heavy to meet the real-time requirements of embedded system. In this paper, a new palmprint benchmark is established, which consists of more than 20,000 images collected by 5 brands of smart phones in an unconstrained manner. Each image has been manually labeled with 14 key points for region of interest (ROI) extraction. Further, the approach called Deep Distillation Hashing (DDH) is proposed as benchmark for efficient deep palmprint recognition. Palmprint images are converted to binary codes to improve the efficiency of feature matching. Derived from knowledge distillation, novel distillation loss functions are constructed to compress deep model to further improve the efficiency of feature extraction on light network. Comprehensive experiments are conducted on both constrained and unconstrained palmprint databases. Using DDH, the accuracy of palmprint identification can be increased by up to 11.37%, and the Equal Error Rate (EER) of palmprint verification can be reduced by up to 3.11%. The results indicate the feasibility of our database, and DDH can outperform other baselines to achieve the state-of-the-art performance. The collected dataset and related source codes are publicly available at this http URL.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "151503040",
                        "name": "Huikai Shao"
                    },
                    {
                        "authorId": "2751350",
                        "name": "Dexing Zhong"
                    },
                    {
                        "authorId": "151480429",
                        "name": "Xuefeng Du"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                ", 2015), increase their robustness to label noise (Lee & Chung, 2020), and estimate outputs uncertainty (Malinin et al., 2020; Ilg et al., 2018)."
            ],
            "citingPaper": {
                "paperId": "5fb83cd39f2e0caede64424c4a81bee635d6bba9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2003-01474",
                    "MAG": "3009704096",
                    "ArXiv": "2003.01474",
                    "CorpusId": 211818341
                },
                "corpusId": 211818341,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5fb83cd39f2e0caede64424c4a81bee635d6bba9",
                "title": "Distilled Hierarchical Neural Ensembles with Adaptive Inference Cost",
                "abstract": "Deep neural networks form the basis of state-of-the-art models across a variety of application domains. Moreover, networks that are able to dynamically adapt the computational cost of inference are important in scenarios where the amount of compute or input data varies over time. In this paper, we propose Hierarchical Neural Ensembles (HNE), a novel framework to embed an ensemble of multiple networks by sharing intermediate layers using a hierarchical structure. In HNE we control the inference cost by evaluating only a subset of models, which are organized in a nested manner. Our second contribution is a novel co-distillation method to boost the performance of ensemble predictions with low inference cost. This approach leverages the nested structure of our ensembles, to optimally allocate accuracy and diversity across the ensemble members. Comprehensive experiments over the CIFAR and Ima-geNet datasets confirm the effectiveness of HNE in building deep networks with adaptive inference cost for image classification.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "40097226",
                        "name": "Adria Ruiz"
                    },
                    {
                        "authorId": "1721683",
                        "name": "J. Verbeek"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Additionally, different work on Distillation [Malinin et al., 2019, Vadera et al., 2020] takes larger models and distills them into a smaller one."
            ],
            "citingPaper": {
                "paperId": "0d4d19ca244ccf4febf4e0c5e915e9368c221fdc",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2003-01227",
                    "ArXiv": "2003.01227",
                    "MAG": "3009733954",
                    "CorpusId": 211818022
                },
                "corpusId": 211818022,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/0d4d19ca244ccf4febf4e0c5e915e9368c221fdc",
                "title": "Fast Predictive Uncertainty for Classification with Bayesian Deep Networks",
                "abstract": "In Bayesian Deep Learning, distributions over the output of classification neural networks are approximated by first constructing a Gaussian distribution over the weights, then sampling from it to receive a distribution over the categorical output distribution. This is costly. We reconsider old work to construct a Dirichlet approximation of this output distribution, which yields an analytic map between Gaussian distributions in logit space and Dirichlet distributions (the conjugate prior to the categorical) in the output space. We argue that the resulting Dirichlet distribution has theoretical and practical advantages, in particular more efficient computation of the uncertainty estimate, scaling to large datasets and networks like ImageNet and DenseNet. We demonstrate the use of this Dirichlet approximation by using it to construct a lightweight uncertainty-aware output ranking for the ImageNet setup.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1518267319",
                        "name": "Marius Hobbhahn"
                    },
                    {
                        "authorId": "36037289",
                        "name": "Agustinus Kristiadi"
                    },
                    {
                        "authorId": "2517795",
                        "name": "Philipp Hennig"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "We discuss the differences between our proposed framework and the method by Malinin et al. (2019) in more detail in section 3.2 and section 5.",
                "This particular choice of distributions recovers the method proposed by Malinin et al. (2019).",
                "Malinin et al. (2019) notes that increasing ensemble size have quickly diminishing returns for a Dirichlet distribution but it is not clear if this is a general property.",
                "Similarly to what was noted in Malinin et al. (2019), the behaviour of the ensemble might differ outside of the in-distribution data, making need of a more flexible representation of the ensemble than the one chosen.",
                "This decomposition of uncertainty with ensembles has been extensiveley explored, e.g., by Kendall and Gal (2017); Lakshminarayanan et al. (2017); Malinin and Gales (2018); Malinin et al. (2019).",
                ", 2015) and for distribution distillation (Malinin et al., 2019).",
                "A special case of this has recently\nbeen proposed by Malinin et al. (2019) for classification problems, using a Dirichlet distribution to model the ensemble predictions.",
                "Recently, there has been a surge of effort in modelling and estimating the uncertainty in deep neural networks (e.g. Malinin et al., 2019; Kendall and Gal, 2017; Guo et al., 2017; Widmann et al., 2019).",
                "This tweak of the original distribution is expressly used in order to more easily distinguish differences in logit space, both for ordinary distillation (Hinton et al., 2015) and for distribution distillation (Malinin et al., 2019).",
                "This is in contrast with the recent work by Malinin et al. (2019), who also consider distribution distillation."
            ],
            "citingPaper": {
                "paperId": "c4c3642a375aa1af0fcd406001c33af6b6552a21",
                "externalIds": {
                    "MAG": "3094329645",
                    "DBLP": "conf/mlsp/LindqvistOLS20",
                    "ArXiv": "2002.11531",
                    "DOI": "10.1109/MLSP49062.2020.9231703",
                    "CorpusId": 211505902
                },
                "corpusId": 211505902,
                "publicationVenue": {
                    "id": "78349a2e-69b4-4113-adce-ac454d2fefdf",
                    "name": "International Workshop on Machine Learning for Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Workshop Mach Learn Signal Process",
                        "MLSP"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c4c3642a375aa1af0fcd406001c33af6b6552a21",
                "title": "A General Framework for Ensemble Distribution Distillation",
                "abstract": "Ensembles of neural networks have shown to give better predictive performance and more reliable uncertainty estimates than individual networks. Additionally, ensembles allow the uncertainty to be decomposed into aleatoric (data) and epistemic (model) components, giving a more complete picture of the predictive uncertainty. Ensemble distillation is the process of compressing an ensemble into a single model, often resulting in a leaner model that still outperforms the individual ensemble members. Unfortunately, standard distillation erases the natural uncertainty decomposition of the ensemble. We present a general framework for distilling both regression and classification ensembles in a way that preserves the decomposition. We demonstrate the desired behaviour of our framework and show that its predictive performance is on par with standard distillation.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "72453193",
                        "name": "Jakob Lindqvist"
                    },
                    {
                        "authorId": "91642132",
                        "name": "Amanda Olmin"
                    },
                    {
                        "authorId": "1759780",
                        "name": "F. Lindsten"
                    },
                    {
                        "authorId": "145652111",
                        "name": "L. Svensson"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "This problem has been studied for many years [12] and has been discussed in several views such as rejection [8, 5], anomaly detection [1], open set recognition [2], and uncertainty estimation [22, 23, 24]."
            ],
            "citingPaper": {
                "paperId": "ae9bf201f128cabaa4350b54ff6607525c736cd5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2002-11297",
                    "MAG": "3034230713",
                    "ArXiv": "2002.11297",
                    "DOI": "10.1109/cvpr42600.2020.01096",
                    "CorpusId": 211506988
                },
                "corpusId": 211506988,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ae9bf201f128cabaa4350b54ff6607525c736cd5",
                "title": "Generalized ODIN: Detecting Out-of-Distribution Image Without Learning From Out-of-Distribution Data",
                "abstract": "Deep neural networks have attained remarkable performance when applied to data that comes from the same distribution as that of the training set, but can significantly degrade otherwise. Therefore, detecting whether an example is out-of-distribution (OoD) is crucial to enable a system that can reject such samples or alert users. Recent works have made significant progress on OoD benchmarks consisting of small image datasets. However, many recent methods based on neural networks rely on training or tuning with both in-distribution and out-of-distribution data. The latter is generally hard to define a-priori, and its selection can easily bias the learning. We base our work on a popular method ODIN, proposing two strategies for freeing it from the needs of tuning with OoD data, while improving its OoD detection performance. We specifically propose to decompose confidence scoring as well as a modified input pre-processing method. We show that both of these significantly help in detection performance. Our further analysis on a larger scale image dataset shows that the two types of distribution shifts, specifically semantic shift and non-semantic shift, present a significant difference in the difficulty of the problem, providing an analysis of when ODIN-like strategies do or do not work.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1912720",
                        "name": "Yen-Chang Hsu"
                    },
                    {
                        "authorId": "1774780",
                        "name": "Yilin Shen"
                    },
                    {
                        "authorId": "1705713",
                        "name": "Hongxia Jin"
                    },
                    {
                        "authorId": "145276578",
                        "name": "Z. Kira"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "contexts": [
                "Results in table 12 show that score-based measures of uncertainty derived using a product-of-expectation consistently yield a higher PRR for sequence-level error detection.",
                "This yields the prediction rejection area ratio PRR:\nPRR = ARuns ARorc\n(24)\nA rejection area ratio of 1.0 indicates optimal rejection, a ratio of 0.0 indicates \u2018random\u2019 rejection.",
                "This will negatively impact the PRR.",
                "Rejection curves are summarised using the Prediction Rejection Ratio (PRR) (Malinin, 2019; Malinin et al., 2020), which is 100% if the measures of uncertainty perfectly correlate with sentence level measure of \u2019error\u2019 (BLEU/WER), and 0% if they are completely uninformative.",
                "If PRR is negative, then the measures of uncertainty are inversely related to sentence-level \u2019error\u2019.",
                "Additionally, the results show that uncertainty-based rejection works better for ASR models than for NMT models, as they achieve a higher PRR."
            ],
            "citingPaper": {
                "paperId": "edf9271da64b90ac85138c4628307dc74e6654ac",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2002-07650",
                    "ArXiv": "2002.07650",
                    "MAG": "3006532545",
                    "CorpusId": 211146491
                },
                "corpusId": 211146491,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/edf9271da64b90ac85138c4628307dc74e6654ac",
                "title": "Uncertainty in Structured Prediction",
                "abstract": "Uncertainty estimation is important for ensuring safety and robustness of AI systems. While most research in the area has focused on un-structured prediction tasks, limited work has investigated general uncertainty estimation approaches for structured prediction. Thus, this work aims to investigate uncertainty estimation for structured prediction tasks within a single unified and interpretable probabilistic ensemble-based framework. We consider: uncertainty estimation for sequence data at the token-level and complete sequence-level; interpretations for, and applications of, various measures of uncertainty; and discuss both the theoretical and practical challenges associated with obtaining them. This work also provides baselines for token-level and sequence-level error detection, and sequence-level out-of-domain input detection on the WMT14 English-French and WMT17 English-German translation and LibriSpeech speech recognition datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "One way to quantify uncertainty is through model uncertainty (Depeweg et al., 2017; Malinin et al., 2019) which measures the spread or disagreement of an ensemble.",
                "As discussed in (Hinton et al., 2015; Malinin et al., 2019) the distribution of the teacher network is often \u201csharp\", which can limit the common support between the output distribution of the model and the target empirical distribution.",
                "However, the uncertainty scales of Prior Networks is larger than the ones of both the ensemble and Hydra, leading to an overall better model uncertainty.",
                "This retains the diversity of ensemble member predictions which is otherwise lost in knowledge distillation.\ndistillation makes it impossible to estimate measures of uncertainty such as model uncertainty (Depeweg et al., 2017; Malinin et al., 2019).",
                "Here Prior Networks are not applicable because for the case of probabilistic regression we cannot take averages of distributions.3 For regression Hydra outperforms knowledge distillation in terms of predictive performance (NLL) because Hydra produces a more flexible output in the form of a Gaussian mixture model with one Gaussian component per head, whereas Knowledge Distillation can produce only a single Gaussian component.",
                "To overcome this limitation, Malinin et al. (2019) proposed to model the entire distribution of an ensemble using a Dirichlet distribution parametrized by a neural network, referred to as a prior network (Malinin & Gales, 2018).",
                "In-distribution model uncertainty (MU) is comparable for both Prior Networks (0.0280) and Hydra (0.0074) but quite a bit smaller compared to target ensemble MU of 0.1055, meaning it is possible to improve uncertainty quantification in all distillation methods tested.",
                "Model uncertainty, introduced by Depeweg et al. (2017); Malinin et al. (2019), is a measure of the spread or disagreement of an ensemble based on mutual information.",
                "We compare our work with two core distillation approaches, Knowledge Distillation (Hinton et al., 2015) and Prior Networks (Malinin et al., 2019; Malinin & Gales, 2018)."
            ],
            "citingPaper": {
                "paperId": "22e8361f6bd05bb4d7fe17919acd91b54c82a7af",
                "externalIds": {
                    "MAG": "3000462134",
                    "DBLP": "journals/corr/abs-2001-04694",
                    "ArXiv": "2001.04694",
                    "CorpusId": 210472531
                },
                "corpusId": 210472531,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/22e8361f6bd05bb4d7fe17919acd91b54c82a7af",
                "title": "Hydra: Preserving Ensemble Diversity for Model Distillation",
                "abstract": "Ensembles of models have been empirically shown to improve predictive performance and to yield robust measures of uncertainty. However, they are expensive in computation and memory. Therefore, recent research has focused on distilling ensembles into a single compact model, reducing the computational and memory burden of the ensemble while trying to preserve its predictive behavior. Most existing distillation formulations summarize the ensemble by capturing its average predictions. As a result, the diversity of the ensemble predictions, stemming from each individual member, is lost. Thus, the distilled model cannot provide a measure of uncertainty comparable to that of the original ensemble. To retain more faithfully the diversity of the ensemble, we propose a distillation method based on a single multi-headed neural network, which we refer to as Hydra. The shared body network learns a joint feature representation that enables each head to capture the predictive behavior of each ensemble member. We demonstrate that with a slight increase in parameter count, Hydra improves distillation performance on classification and regression settings while capturing the uncertainty behaviour of the original ensemble over both in-domain and out-of-distribution tasks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "10017688",
                        "name": "L. Tran"
                    },
                    {
                        "authorId": "46221215",
                        "name": "Bastiaan S. Veeling"
                    },
                    {
                        "authorId": "144030564",
                        "name": "Kevin Roth"
                    },
                    {
                        "authorId": "35976082",
                        "name": "J. Swiatkowski"
                    },
                    {
                        "authorId": "2403637",
                        "name": "Joshua V. Dillon"
                    },
                    {
                        "authorId": "144108062",
                        "name": "Jasper Snoek"
                    },
                    {
                        "authorId": "1783468",
                        "name": "S. Mandt"
                    },
                    {
                        "authorId": "2887364",
                        "name": "Tim Salimans"
                    },
                    {
                        "authorId": "2388416",
                        "name": "Sebastian Nowozin"
                    },
                    {
                        "authorId": "2068720",
                        "name": "Rodolphe Jenatton"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "result"
            ],
            "isInfluential": false,
            "contexts": [
                "After having finished the experiment for this chapter, we found several similar published works on arXiv [60, 11], published at around the same time we were working on this project.",
                "We found several similar published works on arXiv [60, 11] at around the same time we were working on this idea."
            ],
            "citingPaper": {
                "paperId": "829b914f3fe7d203be2986e5ec0dc0a2a456665d",
                "externalIds": {
                    "MAG": "2979687938",
                    "CorpusId": 204914679
                },
                "corpusId": 204914679,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/829b914f3fe7d203be2986e5ec0dc0a2a456665d",
                "title": "Bayesian Deep Learning and Uncertainty in Computer Vision",
                "abstract": "Visual data contains rich information about the operating environment of an intelligent robotic system. Extracting this information allows intelligent systems to reason and decide their future actions. Erroneous visual information, therefore, can lead to poor decisions, causing accidents and casualties, especially in a safety-critical application such as automated driving. One way to prevent this is by measuring the level of uncertainty in the visual information interpretation, so that the system knows the reliability degree of the extracted information. Deep neural networks are now being used in many vision tasks due to their superior accuracy compared to traditional machine learning methods. However, their estimated uncertainties have been shown to be unreliable. To mitigate this issue, researchers have developed methods and tools to apply Bayesian modeling to deep neural networks. This results in a class of models known as Bayesian neural networks, whose uncertainty estimates are more reliable and informative. In this thesis, we make the following contributions in the context of Bayesian Neural Network applied to vision tasks. In particular: \u2022 We improve the understanding of visual uncertainty estimates from Bayesian deep models. Specifically, we study the behavior of Bayesian deep models applied to roadscene image segmentation under different factors, such as varying weather, depth, and occlusion levels. \u2022 We show the importance of model calibration technique in the context of autonomous driving, which strengthens the reliability of the estimated uncertainty. We demonstrate its effectiveness in a simple object localization task. \u2022 We address the high run-time cost of the current Bayesian deep learning techniques. We develop a distillation technique based on the Dirichlet distribution, which allows us to estimate the uncertainties in real-time. We found several similar published works on arXiv [60, 11] at around the same time we were working on this idea.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "51280131",
                        "name": "Buu Phan"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "52b9199ae9fd0ffee0d412ed4c95087dfb9d2d17",
                "externalIds": {
                    "ArXiv": "1905.13472",
                    "MAG": "2970961383",
                    "DBLP": "conf/nips/MalininG19",
                    "DOI": "10.17863/CAM.45323",
                    "CorpusId": 173188734
                },
                "corpusId": 173188734,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/52b9199ae9fd0ffee0d412ed4c95087dfb9d2d17",
                "title": "Reverse KL-Divergence Training of Prior Networks: Improved Uncertainty and Adversarial Robustness",
                "abstract": "Ensemble approaches for uncertainty estimation have recently been applied to the tasks of misclassification detection, out-of-distribution input detection and adversarial attack detection. Prior Networks have been proposed as an approach to efficiently \\emph{emulate} an ensemble of models for classification by parameterising a Dirichlet prior distribution over output distributions. These models have been shown to outperform alternative ensemble approaches, such as Monte-Carlo Dropout, on the task of out-of-distribution input detection. However, scaling Prior Networks to complex datasets with many classes is difficult using the training criteria originally proposed. This paper makes two contributions. First, we show that the appropriate training criterion for Prior Networks is the \\emph{reverse} KL-divergence between Dirichlet distributions. This addresses issues in the nature of the training data target distributions, enabling prior networks to be successfully trained on classification tasks with arbitrarily many classes, as well as improving out-of-distribution detection performance. Second, taking advantage of this new training criterion, this paper investigates using Prior Networks to detect adversarial attacks and proposes a generalized form of adversarial training. It is shown that the construction of successful \\emph{adaptive} whitebox attacks, which affect the prediction and evade detection, against Prior Networks trained on CIFAR-10 and CIFAR-100 using the proposed approach requires a greater amount of computational effort than against networks defended using standard adversarial training or MC-dropout.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "145275970",
                        "name": "A. Malinin"
                    },
                    {
                        "authorId": "1740397",
                        "name": "M. Gales"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "e1714ec4d2548ede7cd7146fe1f5e6d3452d0623",
                "externalIds": {
                    "CorpusId": 259840678
                },
                "corpusId": 259840678,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e1714ec4d2548ede7cd7146fe1f5e6d3452d0623",
                "title": "BAYES-MIL: A NEW PROBABILISTIC PERSPECTIVE",
                "abstract": "Multiple instance learning (MIL) is a popular weakly-supervised learning model on the whole slide image (WSI) for AI-assisted pathology diagnosis. The recent advance in attention-based MIL allows the model to find its region-of-interest (ROI) for interpretation by learning the attention weights for image patches of WSI slides. However, we empirically find that the interpretability of some related methods is either untrustworthy as the principle of MIL is violated or unsatisfactory as the high-attention regions are not consistent with experts\u2019 annotations. In this paper, we propose Bayes-MIL to address the problem from a probabilistic perspective. The induced patch-level uncertainty is proposed as a new measure of MIL interpretability, which outperforms previous methods in matching doctors annotations. We design a slide-dependent patch regularizer (SDPR) for the attention, imposing constraints derived from the MIL assumption, on the attention distribution. SDPR explicitly constrains the model to generate correct attention values. The spatial information is further encoded by an approximate convolutional conditional random field (CRF), for better interpretability. Experimental results show Bayes-MIL outperforms the related methods in patch-level and slide-level metrics and provides much better interpretable ROI on several large-scale WSI datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47333032",
                        "name": "Yufei Cui"
                    },
                    {
                        "authorId": "1470634297",
                        "name": "Ziquan Liu"
                    },
                    {
                        "authorId": "2223484600",
                        "name": "Xiangyu Liu"
                    },
                    {
                        "authorId": "120280976",
                        "name": "Xue Liu"
                    },
                    {
                        "authorId": "2193145649",
                        "name": "Cong Wang"
                    },
                    {
                        "authorId": "145348862",
                        "name": "Tei-Wei Kuo"
                    },
                    {
                        "authorId": "2163131646",
                        "name": "Chun Jason Xue"
                    },
                    {
                        "authorId": "3651407",
                        "name": "Antoni B. Chan"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "One of the common practices in knowledge distillation is employing ensembles as a teacher model (Malinin et al., 2020; Ryabinin et al., 2021) based on the superior performance of the ensemble of deep neural networks (Lakshminarayanan et al., 2017; Ovadia et al., 2019), and several works already\u2026",
                "One of the common practices in knowledge distillation is employing ensembles as a teacher model (Malinin et al., 2020; Ryabinin et al., 2021) based on the superior performance of the ensemble of deep neural networks (Lakshminarayanan et al."
            ],
            "citingPaper": {
                "paperId": "b194362a53a86b700b0e929cc525e0de809703c5",
                "externalIds": {
                    "CorpusId": 259841594
                },
                "corpusId": 259841594,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b194362a53a86b700b0e929cc525e0de809703c5",
                "title": "CATION WITH STOCHASTIC REPRESENTATIONS",
                "abstract": "Decoupling representation learning and classifier learning has been shown to be effective in classification with long-tailed data. There are two main ingredients in constructing a decoupled learning scheme; 1) how to train the feature extractor for representation learning so that it provides generalizable representations and 2) how to re-train the classifier that constructs proper decision boundaries by handling class imbalances in long-tailed data. In this work, we first apply Stochastic Weight Averaging (SWA), an optimization technique for improving the generalization of deep neural networks, to obtain better generalizing feature extractors for long-tailed classification. We then propose a novel classifier re-training algorithm based on stochastic representation obtained from the SWA-Gaussian, a Gaussian perturbed SWA, and a self-distillation strategy that can harness the diverse stochastic representations based on uncertainty estimates to build more robust classifiers. Extensive experiments on CIFAR10/100-LT, ImageNet-LT, and iNaturalist-2018 benchmarks show that our proposed method improves upon previous methods both in terms of prediction accuracy and uncertainty estimation.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2065197138",
                        "name": "G. Nam"
                    },
                    {
                        "authorId": "2214771780",
                        "name": "Sunguk Jang"
                    },
                    {
                        "authorId": "2124954802",
                        "name": "Juho Lee"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "However, existing ensemble combination methods apply deterministic point estimation techniques that are ineffective in capturing the underlying ensemble member diversity and robustly represent the combined model predictive uncertainty [21], [26]\u2013[28].",
                "Accordingly, the ensemble models are well suited for developing robust FD applications due to the ability to obtain improved predictive performance [12]\u2013[18], protect against adversarial attacks [19], [20], and decompose the total predictive uncertainty into epistemic and aleatoric uncertainty [21]\u2013[25]."
            ],
            "citingPaper": {
                "paperId": "bf9145d8e68e79dfcabfe1022c982cd9d768bcd9",
                "externalIds": {
                    "DOI": "10.1109/tii.2023.3280566",
                    "CorpusId": 259806188
                },
                "corpusId": 259806188,
                "publicationVenue": {
                    "id": "2135230a-3b24-4b71-9583-60624389377a",
                    "name": "IEEE Transactions on Industrial Informatics",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Ind Informatics"
                    ],
                    "issn": "1551-3203",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=9424",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=9424"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/bf9145d8e68e79dfcabfe1022c982cd9d768bcd9",
                "title": "Uncertainty-Aware Ensemble Combination Method for Quality Monitoring Fault Diagnosis in Safety-Related Products",
                "abstract": "\u2014With the advent of Industry 4.0 (I4.0) leading to the proliferation of industrial process data, deep learning (DL) techniques have become instrumental in developing intelligent fault diagnosis (FD) applications. However, despite their potentially superior process monitoring capabilities, DL-based FD models are poorly calibrated and generate point estimate predictions without the associated uncertainty estimates. For DL-based FD models, accurate predictive uncertainty estimates from well-calibrated models are essential in ensuring industrial process safety and reliability. This paper proposes Ensemble-to-Distribution (E2D), an uncertainty-aware combination method for quality monitoring FD based on an ensemble of deep neural networks (DNNs). First, E2D addresses safety by providing accurate uncertainty estimates on model predictions, enabling informed decision-making to minimize operational risks. Second, E2D improves model performance on out-of-distribution (OOD) detection tasks to facilitate deployments in the real world. Third, E2D is a post hoc application, implementable at inference time, and compatible with diverse pre-trained models. Finally, to demonstrate the effectiveness of E2D, we explore the problem of monitoring the stability of industrial processes and product quality using case studies on the steel plates faults and APS failure at Scania trucks datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2141964019",
                        "name": "Jefkine Kafunah"
                    },
                    {
                        "authorId": "2111291040",
                        "name": "M. Ali"
                    },
                    {
                        "authorId": "1707342",
                        "name": "J. Breslin"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Proposed methods rely on adapted loss functions (Kendall & Gal, 2017), quantile regression (Tagasovska & Lopez-Paz, 2019), or ensemble distillation (Malinin et al., 2019) and try to capture the uncertainty induced by noisy trainable data points at inference time."
            ],
            "citingPaper": {
                "paperId": "d741651e627bae4b8bbd27cf526658e1a06aa1f5",
                "externalIds": {
                    "DBLP": "conf/icml/MonchotCPMPF23",
                    "CorpusId": 260927426
                },
                "corpusId": 260927426,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/d741651e627bae4b8bbd27cf526658e1a06aa1f5",
                "title": "Input uncertainty propagation through trained neural networks",
                "abstract": "When physical sensors are involved, such as image sensors, the uncertainty over the input data is often a major component of the output uncertainty of machine learning models. In this work, we address the problem of input uncertainty propagation through trained neural networks. We do not rely on a Gaussian distribution assumption of the output or of any intermediate layer. We propagate instead a Gaussian Mixture Model (GMM) that offers much more flexibility using the Split&Merge algorithm. This paper\u2019s main contribution is the computation of a Wasserstein criterion to control the Gaussian splitting procedure for which theoretical guarantees of convergence on the output distribution estimates are derived. The methodology is tested against a wide range of datasets and networks. It shows robustness, and genericity and offers highly accurate output probability density function estimation while maintaining a reasonable computational cost compared with the standard Monte Carlo (MC) approach. 1",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2084561906",
                        "name": "Paul Monchot"
                    },
                    {
                        "authorId": "49322098",
                        "name": "L. Coquelin"
                    },
                    {
                        "authorId": "2070708872",
                        "name": "S. Petit"
                    },
                    {
                        "authorId": "2540195",
                        "name": "S\u00e9bastien Marmin"
                    },
                    {
                        "authorId": "1845031",
                        "name": "E. L. Pennec"
                    },
                    {
                        "authorId": "152656976",
                        "name": "N. Fischer"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "contexts": [
                "[Malinin et al., 2020], modified EWM can be regarded as the reflection of data uncertainty to each augmented data, focusing more on less uncertain augmentation and vice versa.",
                "Considering the definition of the data uncertainty by Malinin et al. [Malinin et al., 2020], modified EWM can be regarded as the reflection of data uncertainty to each augmented data, focusing more on less uncertain augmentation and vice versa.",
                "[Malinin et al., 2020], considering the entropy from softmax output could represent the data uncertainty (with a difference in that we only use a single network prediction to calculate the data uncertainty).",
                "For uncertainty estimation, we refer to the well-stated definition of the uncertainty by Malinin et al. [Malinin et al., 2020], considering the entropy from\nsoftmax output could represent the data uncertainty (with a difference in that we only use a single network prediction to calculate the data\u2026",
                "From another point of view, according to the previous study [Malinin et al., 2020], overall uncertainty measurement from neural network prediction can be divided into knowledge uncertainty and data uncertainty.",
                "Considering the data uncertainty should be extracted from multiple number of the target network predictions [Malinin et al., 2020], it is possible that the calculated entropy could not have reflected the data uncertainty to an accurate level."
            ],
            "citingPaper": {
                "paperId": "decd8b021274aa9022863692b9b640578eaef7ef",
                "externalIds": {
                    "DBLP": "conf/uai/ChunLK22",
                    "CorpusId": 252898901
                },
                "corpusId": 252898901,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/decd8b021274aa9022863692b9b640578eaef7ef",
                "title": "Cyclic test time augmentation with entropy weight method",
                "abstract": "In the recent studies of data augmentation of neural networks, the application of test time augmentation has been studied to extract optimal transformation policies to enhance performance with minimum cost. The policy search method with the best level of input data dependency involves training a loss predictor network to estimate suitable transformations for each of the given input image in indepen-dent manner, resulting in instance-level transformation extraction. In this work, we propose a method to utilize and modify the loss prediction pipeline to further improve the performance with the cyclic search for suitable transformations and the use of the entropy weight method. The cyclic usage of the loss predictor allows refining each input image with multiple transformations with a more flexible transformation magnitude. For cases where multiple augmentations are generated, we implement the entropy weight method to reflect the data uncertainty of each augmentation to force the final result to focus on augmentations with low uncertainty. The experimental results show convincing qualitative outcomes and robust performance for the corrupted conditions of data.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "98616958",
                        "name": "S. Chun"
                    },
                    {
                        "authorId": "2155775124",
                        "name": "Jae Young Lee"
                    },
                    {
                        "authorId": "1769295",
                        "name": "Junmo Kim"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "For classification, we compare NatPN to Reverse KL divergence Prior Networks (R-PriorNet) [45], Ensemble Distribution Distillation (EnD(2)) [46] and Posterior Networks (PostNet) [9]."
            ],
            "citingPaper": {
                "paperId": "b5ad8e8d9ab0ea57f448fe58847d5bce3ce5cb0c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2105-04471",
                    "CorpusId": 234336125
                },
                "corpusId": 234336125,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b5ad8e8d9ab0ea57f448fe58847d5bce3ce5cb0c",
                "title": "Natural Posterior Network: Deep Bayesian Predictive Uncertainty for Exponential Family Distributions",
                "abstract": "Uncertainty awareness is crucial to develop reliable machine learning models. In this work, we propose the Natural Posterior Network (NatPN) for fast and highquality uncertainty estimation for any task where the target distribution belongs to the exponential family. Thus, NatPN finds application for both classification and general regression settings. Unlike many previous approaches, NatPN does not require out-of-distribution (OOD) data at training time. Instead, it leverages Normalizing Flows to fit a single density on a learned low-dimensional and taskdependent latent space. For any input sample, NatPN uses the predicted likelihood to perform a Bayesian update over the target distribution. Theoretically, NatPN assigns high uncertainty far away from training data. Empirically, our extensive experiments on calibration and OOD detection show that NatPN delivers highly competitive performance for classification, regression and count prediction tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "50997190",
                        "name": "Bertrand Charpentier"
                    },
                    {
                        "authorId": "2101840120",
                        "name": "Oliver Borchert"
                    },
                    {
                        "authorId": "73775589",
                        "name": "D. Zugner"
                    },
                    {
                        "authorId": "79462643",
                        "name": "Simon Geisler"
                    },
                    {
                        "authorId": "51249380",
                        "name": "Stephan Gunnemann"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "d43d9a8347761b5d2d78d4776130bd682d8a29c4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2202-03101",
                    "CorpusId": 246633998
                },
                "corpusId": 246633998,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d43d9a8347761b5d2d78d4776130bd682d8a29c4",
                "title": "NUQ: Nonparametric Uncertainty Quantification for Deterministic Neural Networks",
                "abstract": "This paper proposes a fast and scalable method for uncertainty quanti\ufb01cation of machine learning models\u2019 predictions. First, we show the principled way to measure the uncertainty of predictions for a classi\ufb01er based on Nadaraya-Watson\u2019s nonparametric estimate of the conditional label distribution. Importantly, the approach allows to disentangle explicitly aleatoric and epistemic uncertainties. The resulting method works directly in the feature space. However, one can apply it to any neural network by considering an embedding of the data induced by the network. We demonstrate the strong performance of the method in uncertainty estimation tasks on a variety of real-world image datasets, such as MNIST, SVHN, CIFAR-100 and several versions of ImageNet.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1509418352",
                        "name": "Nikita Kotelevskii"
                    },
                    {
                        "authorId": "1491040769",
                        "name": "A. Artemenkov"
                    },
                    {
                        "authorId": "1490644954",
                        "name": "Kirill Fedyanin"
                    },
                    {
                        "authorId": "2083750450",
                        "name": "Fedor Noskov"
                    },
                    {
                        "authorId": "102894500",
                        "name": "A. Fishkov"
                    },
                    {
                        "authorId": "1380315305",
                        "name": "Aleksandr Petiushko"
                    },
                    {
                        "authorId": "144180694",
                        "name": "Maxim Panov"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "\u2026in a more direct way, and to let the learner itself predict, not only the target variable, but also its own uncertainty about the prediction [Sensoy et al., 2018, Malinin and Gales, 2018, 2019, Malinin et al., 2020, Charpentier et al., 2020, Huseljic et al., 2020, Kopetzki et al., 2021].",
                "This is the basic idea of direct epistemic uncertainty prediction [Sensoy et al., 2018, Malinin and Gales, 2018, 2019, Malinin et al., 2020, Charpentier et al., 2020, Huseljic et al., 2020, Kopetzki et al., 2021]."
            ],
            "citingPaper": {
                "paperId": "2b9bb71b6f2655fc3ce17bd71fa409489236cf4e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-06102",
                    "DOI": "10.48550/arXiv.2203.06102",
                    "CorpusId": 247411346
                },
                "corpusId": 247411346,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2b9bb71b6f2655fc3ce17bd71fa409489236cf4e",
                "title": "On the Difficulty of Epistemic Uncertainty Quantification in Machine Learning: The Case of Direct Uncertainty Estimation through Loss Minimisation",
                "abstract": "Uncertainty quantification has received increasing attention in machine learning in the recent past. In particular, a distinction between aleatoric and epistemic uncertainty has been found useful in this regard. The latter refers to the learner\u2019s (lack of) knowledge and appears to be especially difficult to measure and quantify. In this paper, we analyse a recent proposal based on the idea of a second-order learner, which yields predictions in the form of distributions over probability distributions. While standard (first-order) learners can be trained to predict accurate probabilities, namely by minimising suitable loss functions on sample data, we show that loss minimisation does not work for secondorder predictors: The loss functions proposed for inducing such predictors do not incentivise the learner to represent its epistemic uncertainty in a faithful way.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2126870500",
                        "name": "Viktor Bengs"
                    },
                    {
                        "authorId": "1691955",
                        "name": "E. H\u00fcllermeier"
                    },
                    {
                        "authorId": "3249834",
                        "name": "W. Waegeman"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "0aa34445ec0474534fed0674c3d20eb144a94bf6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-05608",
                    "DOI": "10.48550/arXiv.2206.05608",
                    "CorpusId": 249626441
                },
                "corpusId": 249626441,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0aa34445ec0474534fed0674c3d20eb144a94bf6",
                "title": "Gradient Boosting Performs Low-Rank Gaussian Process Inference",
                "abstract": "This paper shows that gradient boosting based on symmetric decision trees can be equivalently reformulated as a kernel method that converges to the solution of a certain Kernel Ridgeless Regression problem. Thus, for low-rank kernels, we obtain the convergence to a Gaussian Process\u2019 posterior mean, which, in turn, allows us to easily transform gradient boosting into a sampler from the posterior to provide better knowledge uncertainty estimates through Monte-Carlo estimation of the posterior variance. We show that the proposed sampler allows for better knowledge uncertainty estimates leading to improved out-of-domain detection.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Aleksei Ustimenko"
                    },
                    {
                        "authorId": "2170076216",
                        "name": "Artem Beliakov"
                    },
                    {
                        "authorId": "51270819",
                        "name": "L. Prokhorenkova"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Next to predictive variance, Mutual Information (MI) [76] has been proposed as a measure of epistemic uncertainty, as intuitively it captures the amount of information that would be gained about model parameters through \u2018\u2018knowledge\u2019\u2019 of the true outcome [77]."
            ],
            "citingPaper": {
                "paperId": "c6012511844d810a900c0d1c8e61730dbccd3ea9",
                "externalIds": {
                    "DBLP": "journals/access/LandeghemBAM22",
                    "DOI": "10.1109/ACCESS.2022.3168734",
                    "CorpusId": 248335524
                },
                "corpusId": 248335524,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c6012511844d810a900c0d1c8e61730dbccd3ea9",
                "title": "Benchmarking Scalable Predictive Uncertainty in Text Classification",
                "abstract": "This paper explores the question of how predictive uncertainty methods perform in practice in Natural Language Processing, specifically multi-class and multi-label text classification. We conduct benchmarking experiments with 1-D convolutional neural networks and pre-trained transformers on six real-world text classification datasets in which we empirically investigate why popular scalable uncertainty estimation strategies (Monte-Carlo Dropout, Deep Ensemble) and notable extensions (Heteroscedastic, Concrete Dropout) underestimate uncertainty. We motivate that uncertainty estimation benefits from combining posterior approximation procedures, linking it to recent research on how ensembles and variational Bayesian methods navigate the loss landscape. We find that our proposed method combination of Deep Ensemble with Concrete Dropout, by analysis of in- domain calibration, cross-domain classification, and novel class robustness, demonstrates superior performance, even at a smaller ensemble size. Our results corroborate the importance of fine-tuning dropout rate to the text classification task at hand, which individually and as an ensemble impacts model robustness. We observe in ablation that pre-trained transformers severely underperform in novelty detection, limiting the applicability of transfer learning when distribution shift from novel classes can be expected.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2163247833",
                        "name": "Jordy Van Landeghem"
                    },
                    {
                        "authorId": "1758219",
                        "name": "Matthew B. Blaschko"
                    },
                    {
                        "authorId": "2340028",
                        "name": "Bertrand Anckaert"
                    },
                    {
                        "authorId": "100781843",
                        "name": "Marie-Francine Moens"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "e42cbda08cc404e6ba215bce2643efd32e192862",
                "externalIds": {
                    "DBLP": "journals/tgrs/QuanWWLDLHJ22",
                    "DOI": "10.1109/TGRS.2022.3173476",
                    "CorpusId": 248683189
                },
                "corpusId": 248683189,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e42cbda08cc404e6ba215bce2643efd32e192862",
                "title": "Self-Distillation Feature Learning Network for Optical and SAR Image Registration",
                "abstract": "Optical and synthetic aperture radar (SAR) image registration is important for multimodal remote sensing image information fusion. Recently, deep matching networks have shown better performances than traditional methods of image matching. However, due to significant differences between optical and SAR images, the performances of existing deep learning methods still need to be further improved. This article proposes a self-distillation feature learning network (SDNet) for optical and SAR image registration, improving performance from network structure and network optimization. First, we explore the impact of different weight-sharing strategies on optical and SAR image matching. Then, we design a partially unshared feature learning network for multimodal image feature learning. It has fewer parameters than the fully unshared network and has more flexibility than the fully shared network. In addition, the limited binary supervised information (matching or nonmatching) is insufficient to train the deep matching networks for optical-SAR image registration. Thus, we propose a self-distillation feature learning method to exploit more similarity information for deep network optimization enhancement, such as the similarity ordering between a series of nonmatching patch pairs. The exploited rich similarity information will significantly enhance network training and improve matching accuracy. Finally, existing deep learning methods brute-force make the matching features of the optical and SAR image patches similar, which will lead to the loss of discriminative information and degeneration of the matching performances. Thus, we build an auxiliary task reconstruction learning to optimize the feature learning network to keep more discriminative information. Extensive experiments demonstrate the effectiveness of our proposed method on multimodal image registration.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "38965976",
                        "name": "Dou Quan"
                    },
                    {
                        "authorId": "2164893701",
                        "name": "Huiyuan Wei"
                    },
                    {
                        "authorId": "2118511269",
                        "name": "Shuang Wang"
                    },
                    {
                        "authorId": "2132046283",
                        "name": "Ruiqi Lei"
                    },
                    {
                        "authorId": "2133281404",
                        "name": "Baorui Duan"
                    },
                    {
                        "authorId": "2153683768",
                        "name": "Yi Li"
                    },
                    {
                        "authorId": "1940528",
                        "name": "B. Hou"
                    },
                    {
                        "authorId": "2143819911",
                        "name": "Licheng Jiao"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "\u2026not explored in this work is how to incorporate uncertainty decomposition within the proposed method in order to improve the OOD detection, as was done in Bayesian neural networks and/or ensemble approaches [Vadera et al., 2020b, Malinin et al., 2019, Vadera et al., 2020a, Depeweg et al., 2018]."
            ],
            "citingPaper": {
                "paperId": "7c59eac8ccfb63f7a58cb98ca8f3b7f2b836f266",
                "externalIds": {
                    "DBLP": "conf/uai/DinariF22",
                    "CorpusId": 252898943
                },
                "corpusId": 252898943,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/7c59eac8ccfb63f7a58cb98ca8f3b7f2b836f266",
                "title": "Variational- and metric-based deep latent space for out-of-distribution detection",
                "abstract": "One popular deep-learning approach for the task of Out-Of-Distribution (OOD) detection is based on thresholding the values of per-class Gaussian likelihood of deep features. However, two issues arise with that approach: first, the distributions are often far from being Gaussian; second, many OOD data points fall within the effective support of the known classes\u2019 Gaussians. Thus, either way it is hard to find a good threshold. In contrast, our proposed solution for OOD detection is based on a new latent space where: 1) each known class is well captured by a nearly-isotropic Gaussian; 2) those Gaussians are far from each other and from the origin of the space (together, these properties effectively leave the area around the origin free for OOD data). Concretely, given a (possibly-trained) backbone deep net of choice, we use it to train a conditional variational model via a Kullback Leibler loss, a triplet loss, and a new distancing loss that pushes classes away from each other. During inference, the class-dependent log-likelihood values of a deep feature ensemble of the test point are also weighted based on reconstruction errors, improving further the decision rule. Experiments on popular benchmarks show that our method yields state-of-the-art results, a feat achieved de-spite the fact that, unlike some competitors, we make no use of OOD data for training or hyperparameter tuning. Our code is available at https: //github.com/BGU-CS-VIL/vmdls .",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "150253006",
                        "name": "Or Dinari"
                    },
                    {
                        "authorId": "2546556",
                        "name": "O. Freifeld"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "03005885846c1efc771ae1727a35e8bc99612663",
                "externalIds": {
                    "DBLP": "conf/eccv/Li22",
                    "DOI": "10.1007/978-3-031-19809-0_20",
                    "CorpusId": 253270253
                },
                "corpusId": 253270253,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/03005885846c1efc771ae1727a35e8bc99612663",
                "title": "Self-Regulated Feature Learning via Teacher-free Feature Distillation",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "9747208",
                        "name": "Lujun Li"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "It is also effective against problems such as adversarial attack and out-of-distribution detection due to the nature of using multiple networks [15,6,5,21,26].",
                "Ensemble is also effective against problems such as adversarial attack and out-of-distribution detection due to it using multiple networks [6,15,5,21,26]."
            ],
            "citingPaper": {
                "paperId": "584e60c1764b2a9d06edc5e957d057f1739d9bd9",
                "externalIds": {
                    "DBLP": "conf/eccv/OkamotoHYF22",
                    "DOI": "10.1007/978-3-031-20083-0_30",
                    "CorpusId": 253448759
                },
                "corpusId": 253448759,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/584e60c1764b2a9d06edc5e957d057f1739d9bd9",
                "title": "Deep Ensemble Learning by Diverse Knowledge Distillation for Fine-Grained Object Classification",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2072385680",
                        "name": "Naoki Okamoto"
                    },
                    {
                        "authorId": "134790239",
                        "name": "Tsubasa Hirakawa"
                    },
                    {
                        "authorId": "1687819",
                        "name": "Takayoshi Yamashita"
                    },
                    {
                        "authorId": "1687968",
                        "name": "H. Fujiyoshi"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Ensembling is proposed to solve medical image segmentation uncertainty prediction Mehrtash et al. (2020). It carries out calibration improvement with simple average of ensemble model, a simplified version of Bayesian inference Wilson & Izmailov (2020). Also, deep ensemble is a strong baseline for image classification calibration Lakshminarayanan et al.",
                "Ensembling is proposed to solve medical image segmentation uncertainty prediction Mehrtash et al. (2020). It carries out calibration improvement with simple average of ensemble model, a simplified version of Bayesian inference Wilson & Izmailov (2020)."
            ],
            "citingPaper": {
                "paperId": "796847348e51960d697f511a56dc9a191ff1f275",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-12053",
                    "DOI": "10.48550/arXiv.2212.12053",
                    "CorpusId": 261092306
                },
                "corpusId": 261092306,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/796847348e51960d697f511a56dc9a191ff1f275",
                "title": "On Calibrating Semantic Segmentation Models: Analysis and An Algorithm",
                "abstract": "We study the problem of semantic segmentation calibration. For image classi\ufb01cation, lots of existing solutions are proposed to alleviate model miscalibration of con\ufb01dence. However, to date, con\ufb01dence calibration research on semantic segmentation is still limited. We provide a systematic study on the calibration of semantic segmentation models and propose a simple yet effective approach. First, we \ufb01nd that model capacity, crop size, multi-scale testing, and prediction correctness have impact on calibration. Among them, prediction correctness, especially misprediction, is more important to miscalibration due to over-con\ufb01dence. Next, we propose a simple, unifying, and effective approach, namely selective scaling, by separating correct/incorrect prediction for scaling and more focusing on misprediction logit smoothing. Then, we study popular existing calibration methods and compare them with selective scaling on semantic segmentation calibration. We conduct extensive experiments with a variety of benchmarks on both in-domain and domain-shift calibration, and show that selective scaling consistently outperforms other methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2111219938",
                        "name": "Dongdong Wang"
                    },
                    {
                        "authorId": "40206014",
                        "name": "Boqing Gong"
                    },
                    {
                        "authorId": "49681507",
                        "name": "Liqiang Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "We refer to the well-stated definition of the uncertainty (Malinin et al., 2020), considering the entropy from softmax output could represent the data uncertainty with a difference in that we only use a single network to calculate the data uncertainty.",
                "Considering the data uncertainty should be extracted from multiple number of the target network predictions (Malinin et al., 2020), it is possible that the calculated entropy could not have reflected the data uncertainty to an accurate level.",
                "Considering the definition of the data uncertainty by Malinin et al. (2020), modified EWM can be regarded as a reflection of data uncertainty to each augmented data, focusing more on less uncertain augmentation and vice versa.",
                "From another point of view, according to the previous work by Malinin et al. (2020), overall uncertainty measurement from neural network prediction can be divided into knowledge uncertainty and data uncertainty."
            ],
            "citingPaper": {
                "paperId": "3cde044504ca5f21b02001a0abdd60790af3c25a",
                "externalIds": {
                    "CorpusId": 252973497
                },
                "corpusId": 252973497,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3cde044504ca5f21b02001a0abdd60790af3c25a",
                "title": "C YCLIC T EST T IME A UGMENTATION WITH E NTROPY W EIGHT M ETHOD",
                "abstract": "In the recent studies of data augmentation of neural networks, the application of test time augmentation has been studied to extract optimal transformation policies to enhance performance with minimum cost. The policy search method with the best level of input data dependency involves training a loss predictor network to estimate suitable transformations for each of the given input image in independent manner, resulting in instance-level transformation extraction. In this work, we propose a method to utilize and modify the loss prediction pipeline to further improve the performance with the cyclic search for suitable transformations and the use of the entropy weight method. The cyclic usage of the loss predictor allows refining each input image with multiple transformations with a more flexible transformation magnitude. For cases where multiple augmentations are generated, we implement the entropy weight method to reflect the data uncertainty of each augmentation to force the final result to focus on augmentations with low uncertainty. The experimental result shows convincing qualitative outcome and robust performance for the corrupted conditions of data.",
                "year": 2021,
                "authors": []
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "Lastly, Malinin et al. (2020b) show that prior networks can also be distilled using an ensemble of classifiers and their predicted categorical distributions (akin to learning Figure 2e from Figure 2a), which does not require regularization at all (but training the ensemble).",
                "The methods listed in Table 3 either choose the NormalInverse Gamma distribution (Amini et al., 2020; Charpentier et al., 2021), inducing a scaled inverse\u03c72 posterior (Gelman et al., 1995),9 as well as a Normal-Wishart prior (Malinin et al., 2020a).",
                "For training purposes, they apply the reverse KL objective of Malinin & Gales (2019) as well as the knowledge distillation objective of Malinin et al. (2020b).",
                "Malinin et al. (2020a) can be seen as the multivariate generalization of the work of Amini et al. (2020), where a combined Normal-Wishart prior is formed to fit the now multivariate normal likelihood.",
                "\u2026weaknesses of Dirichlet networks as well: In order to achieve the right behavior of the distribution and thus guarantee sensible uncertainty estimates, some approaches Malinin & Gales (2018; 2019); Nandy et al. (2020); Malinin et al. (2020a) require out-of-distribution data points during training."
            ],
            "citingPaper": {
                "paperId": "89e0295ee183caa4411aafe5e72f6ef34822bed2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-03051",
                    "CorpusId": 238419452
                },
                "corpusId": 238419452,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/89e0295ee183caa4411aafe5e72f6ef34822bed2",
                "title": "A Survey on Evidential Deep Learning For Single-Pass Uncertainty Estimation",
                "abstract": "Popular approaches for quantifying predictive uncertainty in deep neural networks often involve a set of weights or models, for instance via ensembling or Monte Carlo Dropout. These techniques usually produce overhead by having to train multiple model instances or do not produce very diverse predictions. This survey aims to familiarize the reader with an alternative class of models based on the concept of Evidential Deep Learning: For unfamiliar data, they admit \u201cwhat they don\u2019t know\u201d and fall back onto a prior belief. Furthermore, they allow uncertainty estimation in a single model and forward pass by parameterizing distributions over distributions. This survey recapitulates existing works, focusing on the implementation in a classification setting. Finally, we survey the application of the same paradigm to regression problems. We also provide a reflection on the strengths and weaknesses of the mentioned approaches compared to existing ones and provide the most central theoretical results in order to inform future research.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "133864309",
                        "name": "Dennis Ulmer"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "The authors of Ensemble Distribution 40 Distillation (EnD(2)) [2] address this issue by using the output of an ensemble to train a so-called Prior Network (PN) [3], 41 distilling the ensemble down to a single model while also preserving its uncertainty decomposition abilities.",
                "PRR is the prediction rejection 97 area ratio introduced in Appendix B of [2].",
                "73 \u2022 EnD(2): A single model distribution-distilling ENSM trained according to [2]."
            ],
            "citingPaper": {
                "paperId": "dcd710b1e77ef7e4c7a0eff20ef6689d6c3af92e",
                "externalIds": {
                    "CorpusId": 231895453
                },
                "corpusId": 231895453,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/dcd710b1e77ef7e4c7a0eff20ef6689d6c3af92e",
                "title": "A Reproduction of Ensemble Distribution Distillation",
                "abstract": "The authors claim that their proposed method is able to, given an ensemble of deep neural networks, capture the 3 uncertainty estimation and decomposition capabilities of the ensemble into a single model. The authors also claim that 4 this only results in a small reduction in classification performance compared to the ensemble. Most of the authors\u2019 5 experiments on the CIFAR-10 dataset were reproduced. 6",
                "year": 2021,
                "authors": []
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "1ca5b84e579e8fb363fc7e7eac79adda83fd6df0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-10809",
                    "CorpusId": 231985655
                },
                "corpusId": 231985655,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1ca5b84e579e8fb363fc7e7eac79adda83fd6df0",
                "title": "Localized Calibration: Metrics and Recalibration",
                "abstract": "Probabilistic classi\ufb01ers output con\ufb01dence scores along with their predictions, and these con\ufb01dence scores must be well-calibrated (i.e. re\ufb02ect the true probability of an event) to be meaningful and useful for downstream tasks. However, existing metrics for measuring calibration are insu\ufb03cient. Commonly used metrics such as the expected calibration error (ECE) only measure global trends, making them ine\ufb00ective for measuring the calibration of a particular sample or subgroup. At the other end of the spectrum, a fully individualized calibration error is in general in-tractable to estimate from \ufb01nite samples. In this work, we propose the local calibration error (LCE), a \ufb01ne-grained calibration metric that spans the gap between fully global and fully individualized calibration. The LCE leverages learned features to automatically capture rich subgroups, and it measures the calibration error around each individual example via a similarity function. We then introduce a localized recalibration method, LoRe, that improves the LCE better than existing recalibration methods. Finally, we show that applying our recalibration method improves decision-making on downstream tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "39109324",
                        "name": "Rachel Luo"
                    },
                    {
                        "authorId": "31553879",
                        "name": "Aadyot Bhatnagar"
                    },
                    {
                        "authorId": "46507194",
                        "name": "Haiquan Wang"
                    },
                    {
                        "authorId": "2228109",
                        "name": "Caiming Xiong"
                    },
                    {
                        "authorId": "1702137",
                        "name": "S. Savarese"
                    },
                    {
                        "authorId": "1491626939",
                        "name": "Yu Bai"
                    },
                    {
                        "authorId": "3303970",
                        "name": "Shengjia Zhao"
                    },
                    {
                        "authorId": "2490652",
                        "name": "Stefano Ermon"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "d0a32588a03a51be508b65f45edd62fa2e8e680b",
                "externalIds": {
                    "DBLP": "journals/iacr/ZaidBHV21",
                    "DOI": "10.46586/tches.v2021.i3.60-96",
                    "CorpusId": 235753917
                },
                "corpusId": 235753917,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d0a32588a03a51be508b65f45edd62fa2e8e680b",
                "title": "Efficiency through Diversity in Ensemble Models applied to Side-Channel Attacks - A Case Study on Public-Key Algorithms -",
                "abstract": "Deep Learning based Side-Channel Attacks (DL-SCA) are considered as fundamental threats against secure cryptographic implementations. Side-channel attacks aim to recover a secret key using the least number of leakage traces. In DL-SCA, this often translates in having a model with the highest possible accuracy. Increasing an attack\u2019s accuracy is particularly important when an attacker targets public-key cryptographic implementations where the recovery of each secret key bits is directly related to the model\u2019s accuracy. Commonly used in the deep learning field, ensemble models are a well suited method that combine the predictions of multiple models to increase the ensemble accuracy by reducing the correlation between their errors. Linked to this correlation, the diversity is considered as an indicator of the ensemble model performance. In this paper, we propose a new loss, namely Ensembling Loss (EL), that generates an ensemble model which increases the diversity between the members. Based on the mutual information between the ensemble model and its related label, we theoretically demonstrate how the ensemble members interact during the training process. We also study how an attack\u2019s accuracy gain translates to a drastic reduction of the remaining time complexity of a side-channel attacks through multiple scenarios on public-key implementations. Finally, we experimentally evaluate the benefits of our new learning metric on RSA and ECC secure implementations. The Ensembling Loss increases by up to 6.8% the performance of the ensemble model while the remaining brute-force is reduced by up to 222 operations depending on the attack scenario.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2074300964",
                        "name": "Gabriel Zaid"
                    },
                    {
                        "authorId": "1786543",
                        "name": "L. Bossuet"
                    },
                    {
                        "authorId": "1749327",
                        "name": "Amaury Habrard"
                    },
                    {
                        "authorId": "2830893",
                        "name": "Alexandre Venelli"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Following [8] and [25], we compute the two types of uncertainties as follows:"
            ],
            "citingPaper": {
                "paperId": "2103fe2b78029bc9a20dd891b20cb7f5875fe7f0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-04228",
                    "CorpusId": 236956456
                },
                "corpusId": 236956456,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2103fe2b78029bc9a20dd891b20cb7f5875fe7f0",
                "title": "Towards Better Uncertainty: Iterative Training of Efficient Networks for Multitask Emotion Recognition",
                "abstract": "When recognizing emotions, subtle nuances of emotion displays often cause ambiguity or uncertainty in emotion perception. Unfortunately, the ambiguity or uncertainty cannot be reflected in hard emotion labels. Emotion predictions with uncertainty can be useful for risk controlling, but they are relatively scarce in current deep models for emotion recognition. To address this issue, we propose to apply the multi-generational self-distillation algorithm to emotion recognition task towards better uncertainty estimation performance. We firstly use deep ensembles to capture uncertainty, as an approximation to Bayesian methods. Secondly, the deep ensemble provides soft labels to its student models, while the student models can learn from the uncertainty embedded in those soft labels. Thirdly, we iteratively train deep ensembles to further improve the performance of emotion recognition and uncertainty estimation. In the end, our algorithm results in a single student model that can estimate indomain uncertainty and a student ensemble that can detect out-of-domain samples. We trained our Efficient Multitask Emotion Networks (EMENet) on the Aff-wild2 dataset, and conducted extensive experiments on emotion recognition and uncertainty estimation. Our algorithm gives more reliable uncertainty estimates than Temperature Scaling and Monte Carol Dropout.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "46203817",
                        "name": "Didan Deng"
                    },
                    {
                        "authorId": "2148952330",
                        "name": "Liang Wu"
                    },
                    {
                        "authorId": "2075335081",
                        "name": "Bertram E. Shi"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [
                "Many researchers have studied reducing the cost to estimate ensemble based prediction variation [1, 6, 34, 49, 52]."
            ],
            "citingPaper": {
                "paperId": "1c18418f062039e31bc9dc145c1f07b041c1a3fd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-06435",
                    "CorpusId": 238744013
                },
                "corpusId": 238744013,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1c18418f062039e31bc9dc145c1f07b041c1a3fd",
                "title": "Dropout Prediction Variation Estimation Using Neuron Activation Strength",
                "abstract": "It is well-known DNNs would generate different prediction results even given the same model configuration and training dataset. As a result, it becomes more and more important to study prediction variation, i.e. the variation of the predictions on a given input example, in neural network models. Dropout has been commonly used in various applications to quantify prediction variations. However, using dropout in practice can be expensive as it requires running dropout inference many times to estimate prediction variation. In this paper, we study how to estimate dropout prediction variation in a resource-efficient manner. In particular, we demonstrate that we can use neuron activation strength to estimate dropout prediction variation under different dropout settings and on a variety of tasks using three large datasets, MovieLens, Criteo, and EMNIST. Our approach provides an inference-once alternative to estimate dropout prediction variation as an auxiliary task when the main prediction model is served. Moreover, we show that using activation strength features from a subset of neural network layers can be sufficient to achieve similar variation estimation performance compared to using activation features from all layers. This can provide further resource reduction for variation estimation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2119315730",
                        "name": "Haichao Yu"
                    },
                    {
                        "authorId": "2117037227",
                        "name": "Zhe Chen"
                    },
                    {
                        "authorId": "2116442426",
                        "name": "Dong Lin"
                    },
                    {
                        "authorId": "1743255",
                        "name": "G. Shamir"
                    },
                    {
                        "authorId": "2111717256",
                        "name": "Jie Han"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "The authors ofEnsembleDistributionDistillation (EnD(2)) [2] address this issue by using the output of an ensemble to train a so-called Prior Network (PN) [3], distilling the ensemble down to a single model while also preserving its uncertainty decomposition abilities.",
                "PRR is the prediction rejection area ratio introduced in Appendix B of [2].",
                "\u2022 EnD(2): A single model distribution-distilling ENSM trained according to [2]."
            ],
            "citingPaper": {
                "paperId": "50880841e70688f7f2782c27997871487cabf21c",
                "externalIds": {
                    "CorpusId": 250050899
                },
                "corpusId": 250050899,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/50880841e70688f7f2782c27997871487cabf21c",
                "title": "[Re] A Reproduction of Ensemble Distribution Distillation",
                "abstract": "The authors claim that their proposed method is able to, given an ensemble of deep neural networks, capture the uncertainty estimation and decomposition capabilities of the ensemble into a singlemodel. The authors also claim that this only results in a small reduction in classification performance compared to the ensemble. We examine these claims by reproducing most of the authors\u02bc experiments on the CIFAR-10 dataset.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "30555785",
                        "name": "T. Liiv"
                    },
                    {
                        "authorId": "2173556768",
                        "name": "Einar Lennel\u00f6v"
                    },
                    {
                        "authorId": "2165806025",
                        "name": "Aron Nor\u00e9n"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "f8ae6b9127fba62c20513322157b7b6f46e3a813",
                "externalIds": {
                    "CorpusId": 259367992
                },
                "corpusId": 259367992,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f8ae6b9127fba62c20513322157b7b6f46e3a813",
                "title": "Machine Learning Methods for Enhanced Reliable Perception of Autonomous Systems",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "72096057",
                        "name": "J. Gansloser"
                    },
                    {
                        "authorId": "151473517",
                        "name": "A. Schwaiger"
                    },
                    {
                        "authorId": "144799183",
                        "name": "Gerhard Weiss"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "contexts": [
                "Most existing ensemble methods [34, 28, 13] average the output of each model, which neglects the diversity."
            ],
            "citingPaper": {
                "paperId": "fb4a37f1bd038637a8e6c54f5cf98fc2a686dbbc",
                "externalIds": {
                    "CorpusId": 260917341
                },
                "corpusId": 260917341,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/fb4a37f1bd038637a8e6c54f5cf98fc2a686dbbc",
                "title": "A 2 -Aug: Adaptive Automated Data Augmentation",
                "abstract": "Data augmentation is a promising way to enhance the generalization ability of deep learning models. Many proxy-free and proxy-based automated augmentation methods are proposed to search for the best augmentation for target datasets. However, the proxy-free methods require lots of searching overhead, while the proxy-based methods introduce optimization gaps with the actual task. In this paper, we explore a new proxy-free approach that only needs a small number of searches ( \u223c 5 vs 100 of RandAugment) to alleviate these issues. Specifically, we propose A daptive A utomated Aug mentation ( A 2 -Aug), a simple and effective proxy-free framework, which seeks to mine the adaptive ensemble knowledge of multiple augmentations to further improve the adaptability of each candidate augmentation. Firstly, A 2 -Aug automatically learns the ensemble logit from multiple candidate augmentations, which is jointly optimized and adaptive to target tasks. Sec-ondly, the adaptive ensemble logit is used to distill each logit of input augmentation via KL divergence. In this way, these a few candidate augmentations can implicitly learn strong adaptability for the target datasets, which enjoy similar effects with many searches of RandAugment. Fi-nally, equipped with joint training via separate BatchNorm and normalized distillation, A 2 -Aug obtains state-of-the-art performance with less training budget. In experiments, our A 2 -Aug achieves 4% performance gain on CIFAR-100,",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "9747208",
                        "name": "Lujun Li"
                    },
                    {
                        "authorId": "1490318512",
                        "name": "Zhengbiao Zhu"
                    },
                    {
                        "authorId": "143986385",
                        "name": "Guan Huang"
                    },
                    {
                        "authorId": "40359161",
                        "name": "Dalong Du"
                    },
                    {
                        "authorId": "1697700",
                        "name": "Jiwen Lu"
                    },
                    {
                        "authorId": "48128428",
                        "name": "Jie Zhou"
                    },
                    {
                        "authorId": "47384812",
                        "name": "Qingyi Gu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "contexts": [
                "While classical game theory assumes that all players make rational decisions EGT replaces it by biologically inspired notions, such as natural selection [10].",
                "To name a few, BorderlineSMOTE [10] was introduced to strengthen the decision boundaries of classifiers, by replacing SMOTE\u2019s random selection of minority samples with a directed selection of examples that are close to the class border.",
                "In [10] (the most similar contribution) authors provide an evaluation of synthetic datasets under utility perspectives related to machine learning, leaving room for improvements.",
                "In [10], exploratory SR are also utilized along with trophallaxis (i.",
                "LM-GAN is a modification of Conditional Generative Adversarial Nets [10], which is a modification of the traditional Generative Adversarial Nets (GAN) [6].",
                "[10] applied a convolutional neural networks to extract features from text data by sequentially filtering features from training and test sets (AUC = 0.",
                "Arguably, purposes for which SR can unleash their full potential relate mostly to exploration: localization [7], disaster rescue missions [8], or scenery mapping [9,10].",
                "The most successful application of GAN is computer vision, including image translation [8], image super-resolution [10], image synthesis [29], video generation [26], face aging [2], 3D object generation [23] or detection of small objects [30].",
                "We compare our proposal, SMOTE-BFT, with popular oversampling techniques: the original SMOTE [1], Borderline-SMOTE [10] and ADASYN [12].",
                ", based on industrial machinery \u2013 to the concept of digital manufacturing [10]."
            ],
            "citingPaper": {
                "paperId": "309156bed205db8aa2dccefee040e3bf234fcf32",
                "externalIds": {
                    "DBLP": "conf/ideal/2020-2",
                    "DOI": "10.1007/978-3-030-62365-4",
                    "CorpusId": 225097414
                },
                "corpusId": 225097414,
                "publicationVenue": {
                    "id": "a05ec0dc-bf3e-40e2-9d44-60532d08353a",
                    "name": "Ideal",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Intelligent Data Engineering and Automated Learning",
                        "IDEAL",
                        "Int Conf Intell Data Eng Autom Learn",
                        "Intelligent Data Engineering and Automated Learning",
                        "Intell Data Eng Autom Learn"
                    ],
                    "issn": "0046-8533",
                    "url": "http://www.wikicfp.com/cfp/program?id=1524"
                },
                "url": "https://www.semanticscholar.org/paper/309156bed205db8aa2dccefee040e3bf234fcf32",
                "title": "Intelligent Data Engineering and Automated Learning \u2013 IDEAL 2020: 21st International Conference, Guimaraes, Portugal, November 4\u20136, 2020, Proceedings, Part II",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "145158355",
                        "name": "Cesar Analide"
                    },
                    {
                        "authorId": "145302989",
                        "name": "P. Novais"
                    },
                    {
                        "authorId": "143869061",
                        "name": "David Camacho"
                    },
                    {
                        "authorId": "1709042",
                        "name": "Hujun Yin"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "contexts": [
                "Malinin et al. (2020) distill ensembles by leveraging prior networks (Malinin and Gales, 2018), which model a conditional distribution over outputs.",
                "We investigate the particular setting in which both teacher and student models are ensembles (Lan et al., 2018; Malinin et al., 2020; Tran et al., 2020); our hope is that the more precise modeling the teacher deep ensemble can be inherited by the student batch ensemble, despite the student\u2019s\u2026",
                "We investigate the particular setting in which both teacher and student models are ensembles (Lan et al., 2018; Malinin et al., 2020; Tran et al., 2020); our hope is that the more precise modeling the teacher deep ensemble can be inherited by the student batch ensemble, despite the student\u2019s significantly reduced parameter space."
            ],
            "citingPaper": {
                "paperId": "43d5441fe70c0fd1708fcaf5191ea023ae41c558",
                "externalIds": {
                    "CorpusId": 228095675
                },
                "corpusId": 228095675,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/43d5441fe70c0fd1708fcaf5191ea023ae41c558",
                "title": "Distilling Ensembles Improves Uncertainty Estimates",
                "abstract": "We seek to bridge the performance gap between batch ensembles (ensembles of deep networks with shared parameters) and deep ensembles on tasks which require not only predictions, but also uncertainty estimates for these predictions. We obtain negative theoretical results on the possibility of approximating deep ensemble weights by batch ensemble weights, and so turn to distillation. Training a batch ensemble on the outputs of deep ensembles improves accuracy and uncertainty estimates, without requiring hyper-parameter tuning. This result is specific to the choice of batch ensemble architectures: distilling deep ensembles to a single network is unsuccessful, despite single networks having only marginally fewer parameters than batch ensembles.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1867856",
                        "name": "Zelda E. Mariet"
                    },
                    {
                        "authorId": "2068720",
                        "name": "Rodolphe Jenatton"
                    },
                    {
                        "authorId": "39798982",
                        "name": "F. Wenzel"
                    },
                    {
                        "authorId": "47497262",
                        "name": "Dustin Tran"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": "7461e45276db845d40dcf8301e69dffd9fbe851a",
                "externalIds": {
                    "MAG": "3095363275",
                    "DBLP": "conf/ideal/PereiraSMNZL20",
                    "DOI": "10.1007/978-3-030-62365-4_20",
                    "CorpusId": 226202627
                },
                "corpusId": 226202627,
                "publicationVenue": {
                    "id": "a05ec0dc-bf3e-40e2-9d44-60532d08353a",
                    "name": "Ideal",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Intelligent Data Engineering and Automated Learning",
                        "IDEAL",
                        "Int Conf Intell Data Eng Autom Learn",
                        "Intelligent Data Engineering and Automated Learning",
                        "Intell Data Eng Autom Learn"
                    ],
                    "issn": "0046-8533",
                    "url": "http://www.wikicfp.com/cfp/program?id=1524"
                },
                "url": "https://www.semanticscholar.org/paper/7461e45276db845d40dcf8301e69dffd9fbe851a",
                "title": "On Analysing Similarity Knowledge Transfer by Ensembles",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "19273851",
                        "name": "Danilo Pereira"
                    },
                    {
                        "authorId": "2111869483",
                        "name": "F. Santos"
                    },
                    {
                        "authorId": "145254176",
                        "name": "L. Matos"
                    },
                    {
                        "authorId": "145302989",
                        "name": "P. Novais"
                    },
                    {
                        "authorId": "2948325",
                        "name": "C. Zanchettin"
                    },
                    {
                        "authorId": "1746612",
                        "name": "Teresa B Ludermir"
                    }
                ]
            }
        },
        {
            "intents": [],
            "isInfluential": false,
            "contexts": [],
            "citingPaper": {
                "paperId": null,
                "externalIds": null,
                "corpusId": "259841026",
                "publicationVenue": null,
                "url": null,
                "title": "D ECOUPLED T RAINING FOR L ONG -T AILED C LASSIFI - CATION W ITH S TOCHASTIC R EPRESENTATIONS",
                "abstract": null,
                "year": null,
                "authors": []
            }
        }
    ]
}