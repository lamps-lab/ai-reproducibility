{
    "offset": 0,
    "data": [
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Several existing methods try to generalize vehicle trajectory prediction ideas to human trajectory prediction by representing humans as 2D bounding boxes [5], [6], [7], [8], [9]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ef051ec45ab87f17d03cf594b335de019a6c6021",
                "externalIds": {
                    "ArXiv": "2309.17209",
                    "DOI": "10.1109/LRA.2023.3312035",
                    "CorpusId": 261574077
                },
                "corpusId": 261574077,
                "publicationVenue": {
                    "id": "93c335b7-edf4-45f5-8ddc-7c5835154945",
                    "name": "IEEE Robotics and Automation Letters",
                    "alternate_names": [
                        "IEEE Robot Autom Lett"
                    ],
                    "issn": "2377-3766",
                    "url": "https://www.ieee.org/membership-catalog/productdetail/showProductDetailPage.html?product=PER481-ELE",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=7083369"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ef051ec45ab87f17d03cf594b335de019a6c6021",
                "title": "Robots That Can See: Leveraging Human Pose for Trajectory Prediction",
                "abstract": "Anticipating the motion of all humans in dynamic environments such as homes and offices is critical to enable safe and effective robot navigation. Such spaces remain challenging as humans do not follow strict rules of motion and there are often multiple occluded entry points such as corners and doors that create opportunities for sudden encounters. In this work, we present a Transformer based architecture to predict human future trajectories in human-centric environments from input features including human positions, head orientations, and 3D skeletal keypoints from onboard in-the-wild sensory information. The resulting model captures the inherent uncertainty for future human trajectory prediction and achieves state-of-the-art performance on common prediction benchmarks and a human tracking dataset captured from a mobile robot adapted for the prediction task. Furthermore, we identify new agents with limited historical data as a major contributor to error and demonstrate the complementary nature of 3D skeletal poses in reducing prediction error in such challenging scenarios.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "52186541",
                        "name": "Tim Salzmann"
                    },
                    {
                        "authorId": "2238114609",
                        "name": "Hao-Tien Lewis Chiang"
                    },
                    {
                        "authorId": "2360966",
                        "name": "Markus Ryll"
                    },
                    {
                        "authorId": "1779671",
                        "name": "Dorsa Sadigh"
                    },
                    {
                        "authorId": "2238125998",
                        "name": "Carolina Parada"
                    },
                    {
                        "authorId": "2238127835",
                        "name": "Alex Bewley"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "We also chose models that largely leverage pedestrian positional data and can work independently without image patch inputs [39] or semantic segmentation [26]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "33604bf6db7efa5c9fd602a66835e36f28ae6f75",
                "externalIds": {
                    "ArXiv": "2309.17187",
                    "CorpusId": 263310935
                },
                "corpusId": 263310935,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/33604bf6db7efa5c9fd602a66835e36f28ae6f75",
                "title": "TBD Pedestrian Data Collection: Towards Rich, Portable, and Large-Scale Natural Pedestrian Data",
                "abstract": "Social navigation and pedestrian behavior research has shifted towards machine learning-based methods and converged on the topic of modeling inter-pedestrian interactions and pedestrian-robot interactions. For this, large-scale datasets that contain rich information are needed. We describe a portable data collection system, coupled with a semi-autonomous labeling pipeline. As part of the pipeline, we designed a label correction web app that facilitates human verification of automated pedestrian tracking outcomes. Our system enables large-scale data collection in diverse environments and fast trajectory label production. Compared with existing pedestrian data collection methods, our system contains three components: a combination of top-down and ego-centric views, natural human behavior in the presence of a socially appropriate\"robot\", and human-verified labels grounded in the metric space. To the best of our knowledge, no prior data collection system has a combination of all three components. We further introduce our ever-expanding dataset from the ongoing data collection effort -- the TBD Pedestrian Dataset and show that our collected data is larger in scale, contains richer information when compared to prior datasets with human-verified labels, and supports new research opportunities.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "50013630",
                        "name": "Allan Wang"
                    },
                    {
                        "authorId": "2249535095",
                        "name": "Daisuke Sato"
                    },
                    {
                        "authorId": "2249536783",
                        "name": "Yasser Corzo"
                    },
                    {
                        "authorId": "2249535135",
                        "name": "Sonya Simkin"
                    },
                    {
                        "authorId": "2249529247",
                        "name": "Aaron Steinfeld"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7ee5ab6085d0099f41a5a609091d33e978c45fb7",
                "externalIds": {
                    "ArXiv": "2309.17338",
                    "CorpusId": 263310488
                },
                "corpusId": 263310488,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/7ee5ab6085d0099f41a5a609091d33e978c45fb7",
                "title": "Improving Trajectory Prediction in Dynamic Multi-Agent Environment by Dropping Waypoints",
                "abstract": "The inherently diverse and uncertain nature of trajectories presents a formidable challenge in accurately modeling them. Motion prediction systems must effectively learn spatial and temporal information from the past to forecast the future trajectories of the agent. Many existing methods learn temporal motion via separate components within stacked models to capture temporal features. This paper introduces a novel framework, called Temporal Waypoint Dropping (TWD), that promotes explicit temporal learning through the waypoint dropping technique. Learning through waypoint dropping can compel the model to improve its understanding of temporal correlations among agents, thus leading to a significant enhancement in trajectory prediction. Trajectory prediction methods often operate under the assumption that observed trajectory waypoint sequences are complete, disregarding real-world scenarios where missing values may occur, which can influence their performance. Moreover, these models frequently exhibit a bias towards particular waypoint sequences when making predictions. Our TWD is capable of effectively addressing these issues. It incorporates stochastic and fixed processes that regularize projected past trajectories by strategically dropping waypoints based on temporal sequences. Through extensive experiments, we demonstrate the effectiveness of TWD in forcing the model to learn complex temporal correlations among agents. Our approach can complement existing trajectory prediction methods to enhance prediction accuracy. We also evaluate our proposed method across three datasets: NBA Sports VU, ETH-UCY, and TrajNet++.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2210867055",
                        "name": "Pranav Singh Chib"
                    },
                    {
                        "authorId": "144377059",
                        "name": "Pravendra Singh"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Currently, most existing trajectory prediction methods[37, 22, 4, 23, 30] train models on one specific dataset to predict agent trajectory.",
                "Y-net[22] structures trajectory predictions across long prediction horizons by modeling the epistemic and aleatoric uncertainty.",
                "We chose representative trajectory prediction methods with different base network architectures (LSTM, CNN, GCN), including Social-LSTM[2], STGAT[13], Y-net[22], and Social-STGCNN[23]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "49ca796420fa5074bf7d425f8e3cf1aee4bcfb10",
                "externalIds": {
                    "ArXiv": "2309.05683",
                    "DBLP": "journals/corr/abs-2309-05683",
                    "DOI": "10.48550/arXiv.2309.05683",
                    "CorpusId": 261696731
                },
                "corpusId": 261696731,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/49ca796420fa5074bf7d425f8e3cf1aee4bcfb10",
                "title": "EANet: Expert Attention Network for Online Trajectory Prediction",
                "abstract": "Trajectory prediction plays a crucial role in autonomous driving. Existing mainstream research and continuoual learning-based methods all require training on complete datasets, leading to poor prediction accuracy when sudden changes in scenarios occur and failing to promptly respond and update the model. Whether these methods can make a prediction in real-time and use data instances to update the model immediately(i.e., online learning settings) remains a question. The problem of gradient explosion or vanishing caused by data instance streams also needs to be addressed. Inspired by Hedge Propagation algorithm, we propose Expert Attention Network, a complete online learning framework for trajectory prediction. We introduce expert attention, which adjusts the weights of different depths of network layers, avoiding the model updated slowly due to gradient problem and enabling fast learning of new scenario's knowledge to restore prediction accuracy. Furthermore, we propose a short-term motion trend kernel function which is sensitive to scenario change, allowing the model to respond quickly. To the best of our knowledge, this work is the first attempt to address the online learning problem in trajectory prediction. The experimental results indicate that traditional methods suffer from gradient problems and that our method can quickly reduce prediction errors and reach the state-of-the-art prediction accuracy.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2239102996",
                        "name": "Pengfei Yao"
                    },
                    {
                        "authorId": "1715575",
                        "name": "Tianlu Mao"
                    },
                    {
                        "authorId": "2113795319",
                        "name": "Min Shi"
                    },
                    {
                        "authorId": "2156016843",
                        "name": "Jingkai Sun"
                    },
                    {
                        "authorId": "2239325830",
                        "name": "Zhaoqi Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "information [12], [24], [26], [32], [41].",
                "For SDD dataset with different scenarios in university campus, the comparable methods are categorized as trajectoryimage (SimAug [28], EvolveGraph [26], Y-net [32], and Trajectorn++ [46]) and trajectory-only (PECnet [33], LB-",
                "In addition, comparing with Y-net [32] with the lowest error in trajectory-image methods, the performance of our method is still increased by 3.83% on ADE, and which obtains the second-lowest error on FDE.",
                "In addition, comparing with Y-net [32] with the lowest error in trajectory-image methods, the performance of our method is still increased by 3.",
                "For SDD dataset with different scenarios in university campus, the comparable methods are categorized as trajectoryimage (SimAug [28], EvolveGraph [26], Y-net [32], and Trajectorn++ [46]) and trajectory-only (PECnet [33], LBEBM [39], and DESIRE [24]) as shown in Table II."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "d4550b1e60ced4f8660c5b3fee63ce06550e3424",
                "externalIds": {
                    "DBLP": "journals/tits/ZhangGSLX23",
                    "DOI": "10.1109/TITS.2023.3271953",
                    "CorpusId": 258650090
                },
                "corpusId": 258650090,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d4550b1e60ced4f8660c5b3fee63ce06550e3424",
                "title": "BIP-Tree: Tree Variant With Behavioral Intention Perception for Heterogeneous Trajectory Prediction",
                "abstract": "An insightful understanding and relational reasoning of motion behavior are typical components for trajectory prediction to achieve safe planning when navigating in complex scenarios. Due to the differences in behavioral responses of heterogeneous agents and the existence of chain effect in message passing, an effective prediction method is desired to better acquire potential behavioral intention and model motion behavior. In this paper, we construct a trajectory prediction method to represent and encode the behavioral interactions among heterogeneous agents, called as Tree variant with Behavioral Intention Perception (BIP-Tree). Specifically, a dual-behavior interaction module is presented to deeply understand behavioral intention by simultaneously considering the behavioral perception and behavioral response in spatial interaction. The behavioral perception means that individual acquires behavioral features from interactive objects located in its perception range, while the behavioral response means that each agent makes distinctive reactions to different categories of agents (for example, due to different collision risks caused by pedestrian and vehicle, a pedestrian will respond differently to the interactive agents at the same distance). Meanwhile, we also introduce one new tree variant in message passing stage to enhance the acquisition of potential motion feature, denoting traffic agents as nodes and the interactions among them as tree trunks. The interaction message can be delivered along tree trunks from leaf nodes to root node, to further achieves the chain effect of high-order interactions beyond adjacent entities. Our method is evaluated on several public datasets, such as Apolloscape, nuScenes, Argoverse, SDD, INTERACTION, inD, and Waymo. The extensive experimental results demonstrate that our method can predict more plausible and realistic trajectories with multi-modality. Among them, the best performance is achieved on three datasets. More remarkably, compared with state-of-the-arts, our method achieves significant performance and decreases by at least 13.04% on average ADE and 19.42% on average FDE on inD dataset with four intersections. The dataset and code are available at: htpps://github.com/VTP-TL/BIP-Tree.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2143184771",
                        "name": "Yuzhen Zhang"
                    },
                    {
                        "authorId": "26992326",
                        "name": "Weizhi Guo"
                    },
                    {
                        "authorId": "2217750310",
                        "name": "Junning Su"
                    },
                    {
                        "authorId": "144470801",
                        "name": "Pei Lv"
                    },
                    {
                        "authorId": "2285442",
                        "name": "Mingliang Xu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "There are increasing studies that use deep learning to make these motion predictions [18], [19], [20]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "16db7d7a62775eb4d4911afc89c4ad7ed2cdaab5",
                "externalIds": {
                    "DBLP": "journals/ral/ZhangHDA23",
                    "DOI": "10.1109/LRA.2023.3296333",
                    "CorpusId": 259960422
                },
                "corpusId": 259960422,
                "publicationVenue": {
                    "id": "93c335b7-edf4-45f5-8ddc-7c5835154945",
                    "name": "IEEE Robotics and Automation Letters",
                    "alternate_names": [
                        "IEEE Robot Autom Lett"
                    ],
                    "issn": "2377-3766",
                    "url": "https://www.ieee.org/membership-catalog/productdetail/showProductDetailPage.html?product=PER481-ELE",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=7083369"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/16db7d7a62775eb4d4911afc89c4ad7ed2cdaab5",
                "title": "Prescient Collision-Free Navigation of Mobile Robots With Iterative Multimodal Motion Prediction of Dynamic Obstacles",
                "abstract": "To explore safe interactions between a mobile robot and dynamic obstacles, this letter presents a comprehensive approach to collision-free navigation in dynamic indoor environments. The approach integrates Multimodal Motion Predictions (MMPs) of dynamic obstacles with predictive control for obstacle avoidance. MMP is achieved by a deep-learning method that predicts multiple plausible future positions. By repeating the MMP for each time offset in the future, multi-time-step MMPs are obtained. A nonlinear Model Predictive Control (MPC) solver uses the prediction outcomes to achieve collision-free trajectory tracking for the mobile robot. The proposed integration of multimodal motion prediction and trajectory tracking outperforms other non-deep-learning methods in complex scenarios. The approach enables safe interaction between the mobile robot and stochastic dynamic obstacles.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2118689678",
                        "name": "Ze Zhang"
                    },
                    {
                        "authorId": "1814561",
                        "name": "Hadi Hajieghrary"
                    },
                    {
                        "authorId": "38137167",
                        "name": "Emmanuel Dean"
                    },
                    {
                        "authorId": "1708969",
                        "name": "K. \u00c5kesson"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Y-Net [22] proposes a scene-compliant trajectory forecasting network by factorizing"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "002ba4591e3300421ef43c90c30f17a219e0a2e7",
                "externalIds": {
                    "DBLP": "journals/tits/ZhongYYHJLW23",
                    "DOI": "10.1109/TITS.2023.3266762",
                    "CorpusId": 258208666
                },
                "corpusId": 258208666,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/002ba4591e3300421ef43c90c30f17a219e0a2e7",
                "title": "Visual Exposes You: Pedestrian Trajectory Prediction Meets Visual Intention",
                "abstract": "Pedestrian trajectory prediction in multiple scenarios is of immense importance in autonomous driving and disentanglement of human behavior but is limited in catching human intention and initiative. Most previous works tend to predict the trajectory using only 2D coordinates, which generally cause two common problems: a) Overlooking the subjective initiative, including sudden swerve and erratic movement; b) A potential challenge called abnormal collision caused by unlabeled pedestrians on dataset is not being identified and resolved, which would ruin the model prediction. To break those limitations, we introduce visual localization and orientation as Visual Intention Knowledge to help the trajectory prediction, which is learned directly from visual scenarios. It benefits to comprehend human intention and formulates decision-making processes. Moreover, by learning from the visual information and decision-making policy, we construct the Visual Intention Knowledge associated spatio-temporal Transformer (VIKT) to predict human trajectory by combining the intention knowledge with the novel Transformer. Extensive experimental results demonstrate that our VIKT model could achieve competitive performance by the Visual Intention Knowledge through optimizing the model prediction compared with state-of-the-art methods in terms of prediction accuracy on ETH/UCY and SDD benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46812609",
                        "name": "X. Zhong"
                    },
                    {
                        "authorId": "2156497547",
                        "name": "Xu Yan"
                    },
                    {
                        "authorId": "2149232317",
                        "name": "Zhengwei Yang"
                    },
                    {
                        "authorId": "1500393994",
                        "name": "Wenxin Huang"
                    },
                    {
                        "authorId": "51360637",
                        "name": "Kui Jiang"
                    },
                    {
                        "authorId": "2124017717",
                        "name": "R. Liu"
                    },
                    {
                        "authorId": "50219447",
                        "name": "Zheng Wang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4fbbdbf883bdf7d726545cfd9e0d72cbf5c5a150",
                "externalIds": {
                    "PubMedCentral": "10534871",
                    "DOI": "10.3390/s23187830",
                    "CorpusId": 261844269,
                    "PubMed": "37765886"
                },
                "corpusId": 261844269,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4fbbdbf883bdf7d726545cfd9e0d72cbf5c5a150",
                "title": "Traffic Agents Trajectory Prediction Based on Spatial\u2013Temporal Interaction Attention",
                "abstract": "Trajectory prediction aims to predict the movement intention of traffic participants in the future based on the historical observation trajectories. For traffic scenarios, pedestrians, vehicles and other traffic participants have social interaction of surrounding traffic participants in both time and spatial dimensions. Most previous studies only use pooling methods to simulate the interaction process between participants and cannot fully capture the spatio-temporal dependence, possibly accumulating errors with the increase in prediction time. To overcome these problems, we propose the Spatial\u2013Temporal Interaction Attention-based Trajectory Prediction Network (STIA-TPNet), which can effectively model the spatial\u2013temporal interaction information. Based on trajectory feature extraction, the novel Spatial\u2013Temporal Interaction Attention Module (STIA Module) is proposed to extract the interaction relationships between traffic participants, including temporal interaction attention, spatial interaction attention, and spatio-temporal attention fusion. By adaptive allocation of attention weights, temporal interaction attention is a temporal attention mechanism used to capture the movement pattern of each traffic participant in the scene, which can learn the importance of historical trajectories at different moments to future behaviors. Since the participants number in recent traffic scenes dynamically changes, the spatial interaction attention is designed to abstract the traffic participants in the scene into graph nodes, and abstract the social interaction between participants into graph edges. Coupling the temporal and spatial interaction attentions can adaptively model the temporal\u2013spatial information and achieve accurate trajectory prediction. By performing experiments on the INTERACTION dataset and the UTP (Unmanned Aerial Vehicle-based Trajectory Prediction) dataset, the experimental results show that the proposed method significantly improves the accuracy of trajectory prediction and outperforms the representative methods in comparison.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2107681838",
                        "name": "Jincan Xie"
                    },
                    {
                        "authorId": "2133436769",
                        "name": "Shuang Li"
                    },
                    {
                        "authorId": "2237982307",
                        "name": "Chunsheng Liu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2eba0907523eb240b6d7a5ecafbcc2c19a74a1b5",
                "externalIds": {
                    "DBLP": "journals/jair/ThuremellaK23",
                    "DOI": "10.1613/jair.1.14749",
                    "CorpusId": 261400335
                },
                "corpusId": 261400335,
                "publicationVenue": {
                    "id": "aef12dca-60a0-4ca3-819b-cad26d309d4e",
                    "name": "Journal of Artificial Intelligence Research",
                    "type": "journal",
                    "alternate_names": [
                        "JAIR",
                        "J Artif Intell Res",
                        "The Journal of Artificial Intelligence Research"
                    ],
                    "issn": "1076-9757",
                    "url": "http://www.jair.org/"
                },
                "url": "https://www.semanticscholar.org/paper/2eba0907523eb240b6d7a5ecafbcc2c19a74a1b5",
                "title": "Prediction of Social Dynamic Agents and Long-Tailed Learning Challenges: A Survey",
                "abstract": "Autonomous robots that can perform common tasks like driving, surveillance, and chores have the biggest potential for impact due to frequency of usage, and the biggest potential for risk due to direct interaction with humans. These tasks take place in openended environments where humans socially interact and pursue their goals in complex and diverse ways. To operate in such environments, such systems must predict this behaviour, especially when the behavior is unexpected and potentially dangerous. Therefore, we summarize trends in various types of tasks, modeling methods, datasets, and social interaction modules aimed at predicting the future location of dynamic, socially interactive agents. Furthermore, we describe long-tailed learning techniques from classification and regression problems that can be applied to prediction problems. To our knowledge this is the first work that reviews social interaction modeling within prediction, and long-tailed learning techniques within regression and prediction.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2082483646",
                        "name": "Divya Thuremella"
                    },
                    {
                        "authorId": "121364177",
                        "name": "L. Kunze"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "89ddc12a6c77184dfe151de6691a8c408d6209c2",
                "externalIds": {
                    "ArXiv": "2308.08824",
                    "DBLP": "journals/corr/abs-2308-08824",
                    "DOI": "10.48550/arXiv.2308.08824",
                    "CorpusId": 261031698
                },
                "corpusId": 261031698,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/89ddc12a6c77184dfe151de6691a8c408d6209c2",
                "title": "Fast Inference and Update of Probabilistic Density Estimation on Trajectory Prediction",
                "abstract": "Safety-critical applications such as autonomous vehicles and social robots require fast computation and accurate probability density estimation on trajectory prediction. To address both requirements, this paper presents a new normalizing flow-based trajectory prediction model named FlowChain. FlowChain is a stack of conditional continuously-indexed flows (CIFs) that are expressive and allow analytical probability density computation. This analytical computation is faster than the generative models that need additional approximations such as kernel density estimation. Moreover, FlowChain is more accurate than the Gaussian mixture-based models due to fewer assumptions on the estimated density. FlowChain also allows a rapid update of estimated probability densities. This update is achieved by adopting the \\textit{newest observed position} and reusing the flow transformations and its log-det-jacobians that represent the \\textit{motion trend}. This update is completed in less than one millisecond because this reuse greatly omits the computational cost. Experimental results showed our FlowChain achieved state-of-the-art trajectory prediction accuracy compared to previous methods. Furthermore, our FlowChain demonstrated superiority in the accuracy and speed of density estimation. Our code is available at \\url{https://github.com/meaten/FlowChain-ICCV2023}",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2105610280",
                        "name": "Takahiro Maeda"
                    },
                    {
                        "authorId": "3081689",
                        "name": "N. Ukita"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "20a4e63b758461f40ea2a101e977e85bb44884de",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-05194",
                    "ArXiv": "2308.05194",
                    "DOI": "10.48550/arXiv.2308.05194",
                    "CorpusId": 260775999
                },
                "corpusId": 260775999,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/20a4e63b758461f40ea2a101e977e85bb44884de",
                "title": "Evaluating Pedestrian Trajectory Prediction Methods for the Application in Autonomous Driving",
                "abstract": "In this paper, the state of the art in the field of pedestrian trajectory prediction is evaluated alongside the constant velocity model (CVM) with respect to its applicability in autonomous vehicles. The evaluation is conducted on the widely-used ETH/UCY dataset where the Average Displacement Error (ADE) and the Final Displacement Error (FDE) are reported. To align with requirements in real-world applications, modifications are made to the input features of the initially proposed models. An ablation study is conducted to examine the influence of the observed motion history on the prediction performance, thereby establishing a better understanding of its impact. Additionally, the inference time of each model is measured to evaluate the scalability of each model when confronted with varying amounts of agents. The results demonstrate that simple models remain competitive when generating single trajectories, and certain features commonly thought of as useful have little impact on the overall performance across different architectures. Based on these findings, recommendations are proposed to guide the future development of trajectory prediction algorithms.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2231124473",
                        "name": "Nico Uhlemann"
                    },
                    {
                        "authorId": "146704593",
                        "name": "F. Fent"
                    },
                    {
                        "authorId": "2717687",
                        "name": "M. Lienkamp"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e3ca29a9c97d28880a49bf8308bea68d858c55f6",
                "externalIds": {
                    "ArXiv": "2308.04589",
                    "DBLP": "journals/corr/abs-2308-04589",
                    "DOI": "10.48550/arXiv.2308.04589",
                    "CorpusId": 260735901
                },
                "corpusId": 260735901,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e3ca29a9c97d28880a49bf8308bea68d858c55f6",
                "title": "Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction",
                "abstract": "The emerging field of action prediction plays a vital role in various computer vision applications such as autonomous driving, activity analysis and human-computer interaction. Despite significant advancements, accurately predicting future actions remains a challenging problem due to high dimensionality, complex dynamics and uncertainties inherent in video data. Traditional supervised approaches require large amounts of labelled data, which is expensive and time-consuming to obtain. This paper introduces a novel self-supervised video strategy for enhancing action prediction inspired by DINO (self-distillation with no labels). The Temporal-DINO approach employs two models; a 'student' processing past frames; and a 'teacher' processing both past and future frames, enabling a broader temporal context. During training, the teacher guides the student to learn future context by only observing past frames. The strategy is evaluated on ROAD dataset for the action prediction downstream task using 3D-ResNet, Transformer, and LSTM architectures. The experimental results showcase significant improvements in prediction performance across these architectures, with our method achieving an average enhancement of 9.9% Precision Points (PP), highlighting its effectiveness in enhancing the backbones' capabilities of capturing long-term dependencies. Furthermore, our approach demonstrates efficiency regarding the pretraining dataset size and the number of epochs required. This method overcomes limitations present in other approaches, including considering various backbone architectures, addressing multiple prediction horizons, reducing reliance on hand-crafted augmentations, and streamlining the pretraining process into a single stage. These findings highlight the potential of our approach in diverse video-based tasks such as activity recognition, motion planning, and scene understanding.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2149408834",
                        "name": "Izzeddin Teeti"
                    },
                    {
                        "authorId": "2230682186",
                        "name": "Rongali Sai Bhargav"
                    },
                    {
                        "authorId": "2229458323",
                        "name": "Vivek Singh"
                    },
                    {
                        "authorId": "144463467",
                        "name": "Andrew Bradley"
                    },
                    {
                        "authorId": "49124777",
                        "name": "Biplab Banerjee"
                    },
                    {
                        "authorId": "1754181",
                        "name": "Fabio Cuzzolin"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Other methods use variational autoencoders [Mangalam et al. 2021; Salzmann et al. 2020]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ec1ebd4e41d458c4d80afa38fbf18c31b50a3c42",
                "externalIds": {
                    "DBLP": "journals/tog/CharalambousPVCP23",
                    "DOI": "10.1145/3592459",
                    "CorpusId": 260167829
                },
                "corpusId": 260167829,
                "publicationVenue": {
                    "id": "aab03e41-f80d-48b3-89bd-60eeeceafc7d",
                    "name": "ACM Transactions on Graphics",
                    "type": "journal",
                    "alternate_names": [
                        "ACM Trans Graph"
                    ],
                    "issn": "0730-0301",
                    "url": "http://www.acm.org/tog/",
                    "alternate_urls": [
                        "http://portal.acm.org/tog",
                        "https://tog.acm.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ec1ebd4e41d458c4d80afa38fbf18c31b50a3c42",
                "title": "GREIL-Crowds: Crowd Simulation with Deep Reinforcement Learning and Examples",
                "abstract": "Simulating crowds with realistic behaviors is a difficult but very important task for a variety of applications. Quantifying how a person balances between different conflicting criteria such as goal seeking, collision avoidance and moving within a group is not intuitive, especially if we consider that behaviors differ largely between people. Inspired by recent advances in Deep Reinforcement Learning, we propose Guided REinforcement Learning (GREIL) Crowds, a method that learns a model for pedestrian behaviors which is guided by reference crowd data. The model successfully captures behaviors such as goal seeking, being part of consistent groups without the need to define explicit relationships and wandering around seemingly without a specific purpose. Two fundamental concepts are important in achieving these results: (a) the per agent state representation and (b) the reward function. The agent state is a temporal representation of the situation around each agent. The reward function is based on the idea that people try to move in situations/states in which they feel comfortable in. Therefore, in order for agents to stay in a comfortable state space, we first obtain a distribution of states extracted from real crowd data; then we evaluate states based on how much of an outlier they are compared to such a distribution. We demonstrate that our system can capture and simulate many complex and subtle crowd interactions in varied scenarios. Additionally, the proposed method generalizes to unseen situations, generates consistent behaviors and does not suffer from the limitations of other data-driven and reinforcement learning approaches.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "39066972",
                        "name": "Panayiotis Charalambous"
                    },
                    {
                        "authorId": "2235773",
                        "name": "J. Pettr\u00e9"
                    },
                    {
                        "authorId": "143874876",
                        "name": "Vassilis Vassiliades"
                    },
                    {
                        "authorId": "1706408",
                        "name": "Y. Chrysanthou"
                    },
                    {
                        "authorId": "1746484",
                        "name": "N. Pelechano"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b5d799b1f3aebd7549d2945f42691346418192f0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-09306",
                    "ArXiv": "2307.09306",
                    "DOI": "10.48550/arXiv.2307.09306",
                    "CorpusId": 259950884
                },
                "corpusId": 259950884,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b5d799b1f3aebd7549d2945f42691346418192f0",
                "title": "EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory Forecasting",
                "abstract": "Capturing high-dimensional social interactions and feasible futures is essential for predicting trajectories. To address this complex nature, several attempts have been devoted to reducing the dimensionality of the output variables via parametric curve fitting such as the B\\'ezier curve and B-spline function. However, these functions, which originate in computer graphics fields, are not suitable to account for socially acceptable human dynamics. In this paper, we present EigenTrajectory ($\\mathbb{ET}$), a trajectory prediction approach that uses a novel trajectory descriptor to form a compact space, known here as $\\mathbb{ET}$ space, in place of Euclidean space, for representing pedestrian movements. We first reduce the complexity of the trajectory descriptor via a low-rank approximation. We transform the pedestrians' history paths into our $\\mathbb{ET}$ space represented by spatio-temporal principle components, and feed them into off-the-shelf trajectory forecasting models. The inputs and outputs of the models as well as social interactions are all gathered and aggregated in the corresponding $\\mathbb{ET}$ space. Lastly, we propose a trajectory anchor-based refinement method to cover all possible futures in the proposed $\\mathbb{ET}$ space. Extensive experiments demonstrate that our EigenTrajectory predictor can significantly improve both the prediction accuracy and reliability of existing trajectory forecasting models on public benchmarks, indicating that the proposed descriptor is suited to represent pedestrian behaviors. Code is publicly available at https://github.com/inhwanbae/EigenTrajectory .",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2064764883",
                        "name": "Inhwan Bae"
                    },
                    {
                        "authorId": "143904954",
                        "name": "Jean Oh"
                    },
                    {
                        "authorId": "39060641",
                        "name": "Hae-Gon Jeon"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "The output settings are in line with the data format of YNet [2].",
                "We have made some improvements on the basis of Y-Net, adding FairMOT [3] for pedestrian tracking, which combines object detection, tracking, and trajectory prediction.",
                "The data alignment results are processed by YNet, which are shown as video in Fig.",
                "To prevent YNet from processing too much data and slowing down the prediction process, we introduce a frame rule, which limit the distance between the frames and the tracked objects.",
                "However, SGNet [1] and Y-Net [2] achieved good results in pedestrian trajectory prediction."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0e75d821438be6e7a14f4069769506e4b20ee5bc",
                "externalIds": {
                    "DBLP": "conf/icce-tw/FadillahLWL23",
                    "DOI": "10.1109/ICCE-Taiwan58799.2023.10226764",
                    "CorpusId": 261434584
                },
                "corpusId": 261434584,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0e75d821438be6e7a14f4069769506e4b20ee5bc",
                "title": "Egocentric Pedestrian Trajectory Prediction",
                "abstract": "Pedestrian trajectory prediction is one of the important research topics for autonomous vehicles. Many factors such as Pedestrians\u2019 actions and waypoints in the scene can affect the pedestrians\u2019 routes. Currently, most researches focus on predicting trajectories in Bird\u2019s Eye View (BEV), which limits the application in monocular cameras. In this paper, we propose to combine BEV trajectory prediction with deterministic tracking method and create a new egocentric algorithm for predicting pedestrian trajectories. Experiment results showed that our method can accurately predict pedestrian trajectories in egocentric scenes.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2236937395",
                        "name": "Amar Fadillah"
                    },
                    {
                        "authorId": "2237313927",
                        "name": "Ching-Lin Lee"
                    },
                    {
                        "authorId": "2237088343",
                        "name": "Zhi-Xuan Wang"
                    },
                    {
                        "authorId": "3220269",
                        "name": "Kuan-Ting Lai"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Later in [16], scene segmentation maps along with past trajectory heatmaps were used as inputs to an encoder-decoder Convolutional Neural Network (CNN), to predict trajectory endpoint heatmaps, followed by complete trajectories."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "31acada39e42b061a02ab61953fe5942be87836e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-03786",
                    "ArXiv": "2307.03786",
                    "DOI": "10.48550/arXiv.2307.03786",
                    "CorpusId": 259501655
                },
                "corpusId": 259501655,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/31acada39e42b061a02ab61953fe5942be87836e",
                "title": "Context-aware Pedestrian Trajectory Prediction with Multimodal Transformer",
                "abstract": "We propose a novel solution for predicting future trajectories of pedestrians. Our method uses a multimodal encoder-decoder transformer architecture, which takes as input both pedestrian locations and ego-vehicle speeds. Notably, our decoder predicts the entire future trajectory in a single-pass and does not perform one-step-ahead prediction, which makes the method effective for embedded edge deployment. We perform detailed experiments and evaluate our method on two popular datasets, PIE and JAAD. Quantitative results demonstrate the superiority of our proposed model over the current state-of-the-art, which consistently achieves the lowest error for 3 time horizons of 0.5, 1.0 and 1.5 seconds. Moreover, the proposed method is significantly faster than the state-of-the-art for the two datasets of PIE and JAAD. Lastly, ablation experiments demonstrate the impact of the key multimodal configuration of our method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2029679966",
                        "name": "Haleh Damirchi"
                    },
                    {
                        "authorId": "2129027683",
                        "name": "Michael A. Greenspan"
                    },
                    {
                        "authorId": "1379982213",
                        "name": "A. Etemad"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Therefore, we convert the world coordinates into pixel coordinates using\nthe homography matrices from Y-net (Mangalam et al., 2021).",
                "On average, Y-net, S-CSR, and NSP-SFM are 1400%, 300%, and 66.67% worse than BNSP-SFM.",
                "When people are indeed close to each other, NSP-SFM and BNSP-SFM outperform Y-net and S-CSR.",
                "The performance of Y-net drops severely from 7.85/11.85 (when it\u2019s trained also on SDD) to 30.59/51.43.",
                "NSPSFM and BNSP-SFM perform slightly worse than when they are also trained on SDD, but considerably better than Y-net.",
                "\u2026Niebles, Hauptmann, & Fei-Fei, 2019), P2TIRL (Deo & Trivedi, 2020), SimAug (Liang, Jiang, & Hauptmann, 2020), PECNet (Mangalam et al., 2020), Y-Net (Mangalam et al., 2021), S-CSR (Zhou, Ren, Yang, Fan, & Huang, 2021), SocialVAE (Xu et al., 2022), V2Net (Wong et al., 2022), and NSP-SFM (Yue et al.,\u2026",
                "Y-net performs poorly in all three time intervals.",
                "For comparison, we choose Y-net and NSP-SFM as baselines and show the results in Tab.",
                "We use NSP-SFM, Y-net, and S-CSR as baselines.",
                "Following (Mangalam et al., 2021), we extract trajectories with a time step 0.4 seconds and obtain 20-frame samples for an 8/12 setting, i.e., given the first 8 frames (3.2 seconds, th = 7), we aim to predict the future 12 frame trajectories (4.8 seconds, tf = 12).",
                "Following the standard leave-one-out evaluation protocol (Gupta et al., 2018; Mangalam et al., 2021, 2020), we train our model on four subdatasets and test it on the remaining one in turn.",
                "We compare our BNSP-SFM in both standard-sampling and ultra-sampling with a wide range of baselines: Social GAN (S-GAN) (Gupta\net al., 2018), Sophie (Sadeghian et al., 2019), NEXT (Liang, Jiang, Niebles, Hauptmann, & Fei-Fei, 2019), P2TIRL (Deo & Trivedi, 2020), SimAug (Liang, Jiang, & Hauptmann, 2020), PECNet (Mangalam et al., 2020), Y-Net (Mangalam et al., 2021), S-CSR (Zhou, Ren, Yang, Fan, & Huang, 2021), SocialVAE (Xu et al., 2022), V2Net (Wong et al., 2022), and NSP-SFM (Yue et al., 2022)."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "4891844a910c25507f432f3d435930c57fa6c196",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-01817",
                    "ArXiv": "2307.01817",
                    "DOI": "10.48550/arXiv.2307.01817",
                    "CorpusId": 259342722
                },
                "corpusId": 259342722,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4891844a910c25507f432f3d435930c57fa6c196",
                "title": "Human Trajectory Forecasting with Explainable Behavioral Uncertainty",
                "abstract": "Human trajectory forecasting helps to understand and predict human behaviors, enabling applications from social robots to self-driving cars, and therefore has been heavily investigated. Most existing methods can be divided into model-free and model-based methods. Model-free methods offer superior prediction accuracy but lack explainability, while model-based methods provide explainability but cannot predict well. Combining both methodologies, we propose a new Bayesian Neural Stochastic Differential Equation model BNSP-SFM, where a behavior SDE model is combined with Bayesian neural networks (BNNs). While the NNs provide superior predictive power, the SDE offers strong explainability with quantifiable uncertainty in behavior and observation. We show that BNSP-SFM achieves up to a 50% improvement in prediction accuracy, compared with 11 state-of-the-art methods. BNSP-SFM also generalizes better to drastically different scenes with different environments and crowd densities (~ 20 times higher than the testing data). Finally, BNSP-SFM can provide predictions with confidence to better explain potential causes of behaviors. The code will be released upon acceptance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2178356020",
                        "name": "Jiangbei Yue"
                    },
                    {
                        "authorId": "1699159",
                        "name": "Dinesh Manocha"
                    },
                    {
                        "authorId": "2149698569",
                        "name": "He Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Ynet (a scene compliant trajectory forecasting network) [36] uses multimodal input to input a semantic map, RGB map and other information into the model."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "299feaa73b2f9be3c3c063a686f6d87389e29d67",
                "externalIds": {
                    "PubMedCentral": "10378629",
                    "DOI": "10.3390/e25071100",
                    "CorpusId": 260210879,
                    "PubMed": "37510047"
                },
                "corpusId": 260210879,
                "publicationVenue": {
                    "id": "8270cfe1-3713-4325-a7bd-c6a87eed889e",
                    "name": "Entropy",
                    "type": "journal",
                    "issn": "1099-4300",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-155606",
                    "alternate_urls": [
                        "http://www.mdpi.com/journal/entropy/",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-155606",
                        "https://www.mdpi.com/journal/entropy"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/299feaa73b2f9be3c3c063a686f6d87389e29d67",
                "title": "A Novel Trajectory Feature-Boosting Network for Trajectory Prediction",
                "abstract": "Trajectory prediction is an essential task in many applications, including autonomous driving, robotics, and surveillance systems. In this paper, we propose a novel trajectory prediction network, called TFBNet (trajectory feature-boosting network), that utilizes trajectory feature boosting to enhance prediction accuracy. TFBNet operates by mapping the original trajectory data to a high-dimensional space, analyzing the change rules of the trajectory in this space, and finally aggregating the trajectory goals to generate the final trajectory. Our approach presents a new perspective on trajectory prediction. We evaluate TFBNet on five real-world datasets and compare it to state-of-the-art methods. Our results demonstrate that TFBNet achieves significant improvements in the ADE (average displacement error) and FDE (final displacement error) indicators, with increases of 46% and 52%, respectively. These results validate the effectiveness of our proposed approach and its potential to improve the performance of trajectory prediction models in various applications.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "39333823",
                        "name": "Qingjian Ni"
                    },
                    {
                        "authorId": "143601789",
                        "name": "Wenqiang Peng"
                    },
                    {
                        "authorId": "2218879735",
                        "name": "Yuntian Zhu"
                    },
                    {
                        "authorId": "2218189927",
                        "name": "Ruotian Ye"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8c6eef90065c8c35e6051e80478c993b48a783e8",
                "externalIds": {
                    "DBLP": "conf/aaai/BaeJ23",
                    "DOI": "10.1609/aaai.v37i5.25759",
                    "CorpusId": 259697264
                },
                "corpusId": 259697264,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/8c6eef90065c8c35e6051e80478c993b48a783e8",
                "title": "A Set of Control Points Conditioned Pedestrian Trajectory Prediction",
                "abstract": "Predicting the trajectories of pedestrians in crowded conditions is an important task for applications like autonomous navigation systems. Previous studies have tackled this problem using two strategies. They (1) infer all future steps recursively, or (2) predict the potential destinations of pedestrians at once and interpolate the intermediate steps to arrive there. However, these strategies often suffer from the accumulated errors of the recursive inference, or restrictive assumptions about social relations in the intermediate path. In this paper, we present a graph convolutional network-based trajectory prediction. Firstly, we propose a control point prediction that divides the future path into three sections and infers the intermediate destinations of pedestrians to reduce the accumulated error. To do this, we construct multi-relational weighted graphs to account for their physical and complex social relations. We then introduce a trajectory refinement step based on a spatio-temporal and multi-relational graph. By considering the social interactions between neighbors, better prediction results are achievable. In experiments, the proposed network achieves state-of-the-art performance on various real-world trajectory prediction benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2064764883",
                        "name": "Inhwan Bae"
                    },
                    {
                        "authorId": "39060641",
                        "name": "Hae-Gon Jeon"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e6312493eab2c9d27a8cc384d48abd89955b84fc",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-12244",
                    "ArXiv": "2306.12244",
                    "DOI": "10.48550/arXiv.2306.12244",
                    "CorpusId": 259212467
                },
                "corpusId": 259212467,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e6312493eab2c9d27a8cc384d48abd89955b84fc",
                "title": "Discovering Intrinsic Spatial-Temporal Logic Rules to Explain Human Actions",
                "abstract": "We propose a logic-informed knowledge-driven modeling framework for human movements by analyzing their trajectories. Our approach is inspired by the fact that human actions are usually driven by their intentions or desires, and are influenced by environmental factors such as the spatial relationships with surrounding objects. In this paper, we introduce a set of spatial-temporal logic rules as knowledge to explain human actions. These rules will be automatically discovered from observational data. To learn the model parameters and the rule content, we design an expectation-maximization (EM) algorithm, which treats the rule content as latent variables. The EM algorithm alternates between the E-step and M-step: in the E-step, the posterior distribution over the latent rule content is evaluated; in the M-step, the rule generator and model parameters are jointly optimized by maximizing the current expected log-likelihood. Our model may have a wide range of applications in areas such as sports analytics, robotics, and autonomous cars, where understanding human movements are essential. We demonstrate the model's superior interpretability and prediction performance on pedestrian and NBA basketball player datasets, both achieving promising results.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2187312488",
                        "name": "Chengzhi Cao"
                    },
                    {
                        "authorId": "2220433094",
                        "name": "Chao Yang"
                    },
                    {
                        "authorId": "145015904",
                        "name": "Shuang Li"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f31a4c56e0430abe1181af7a8a20e8773451f6d3",
                "externalIds": {
                    "DBLP": "journals/nn/LiLSY23",
                    "DOI": "10.1016/j.neunet.2023.06.007",
                    "CorpusId": 259295685,
                    "PubMed": "37385022"
                },
                "corpusId": 259295685,
                "publicationVenue": {
                    "id": "a13f3cb8-2492-4ccb-9329-73a5ddcaab9b",
                    "name": "Neural Networks",
                    "type": "journal",
                    "alternate_names": [
                        "Neural Netw"
                    ],
                    "issn": "0893-6080",
                    "url": "http://www.elsevier.com/locate/neunet",
                    "alternate_urls": [
                        "http://www.elsevier.com/wps/find/journaldescription.cws_home/841/description",
                        "http://www.sciencedirect.com/science/journal/08936080"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f31a4c56e0430abe1181af7a8a20e8773451f6d3",
                "title": "Predictive hierarchical reinforcement learning for path-efficient mapless navigation with moving target",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46381746",
                        "name": "Hanxiao Li"
                    },
                    {
                        "authorId": "36735407",
                        "name": "Biao Luo"
                    },
                    {
                        "authorId": "2118725036",
                        "name": "Wei Song"
                    },
                    {
                        "authorId": "121587613",
                        "name": "Chun-Pei Yang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b377404996a334e6f1c6548c80d58b3f40960e88",
                "externalIds": {
                    "DBLP": "journals/tcsv/ChenYXDSZ23",
                    "DOI": "10.1109/TCSVT.2022.3229694",
                    "CorpusId": 254775164
                },
                "corpusId": 254775164,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b377404996a334e6f1c6548c80d58b3f40960e88",
                "title": "Multimodal Pedestrian Trajectory Prediction Using Probabilistic Proposal Network",
                "abstract": "Forecasting multiple pedestrian trajectories is a challenging task for real-world applications, as the motion patterns of pedestrian are essentially stochastic and uncertain. Previous works have demonstrated that predicting diverse goals in advance can effectively improve the performance of pedestrian trajectory prediction. However, these methods are either unable to perform probabilistic and high-efficiency trajectory prediction, or mainly rely on the predefined template trajectories which are not high-performance and insufficient to represent the possible pedestrian behaviors. In this paper, we propose a new Probabilistic Proposal Network (PPNet) to concentrate on the generation of goals and the utilization of goal guidance. PPNet firstly generates multiple weighted goals based on the diverse latent intentions automatically obtained by unsupervised learning, and then designs the goal-conditioned Transformer networks to predict probabilistic proposals as the final trajectories. Extensive experimental results on ETH/UCY datasets and Stanford Drone Dataset indicate that PPNet achieves both state-of-the-art performance and high efficiency on pedestrian trajectory prediction.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2283009",
                        "name": "Wei Chen"
                    },
                    {
                        "authorId": "2109740775",
                        "name": "Zhi-Xiang Yang"
                    },
                    {
                        "authorId": "2196210716",
                        "name": "Lingyang Xue"
                    },
                    {
                        "authorId": "2174865153",
                        "name": "Jinghai Duan"
                    },
                    {
                        "authorId": "47217841",
                        "name": "Hongbin Sun"
                    },
                    {
                        "authorId": "145608731",
                        "name": "Nanning Zheng"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Autonomous agent planning critically depends on anticipating the future of the scene in various forms such as trajectory prediction [22, 23, 57, 58], action forecasting [19, 25, 80] or future scene This CVPR paper is the Open Access version, provided by the Computer Vision Foundation."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7e55408ab2b3ffd7dca5109375058bac96f6e89c",
                "externalIds": {
                    "DBLP": "conf/cvpr/GiraseACM23",
                    "DOI": "10.1109/CVPR52729.2023.01799",
                    "CorpusId": 260055082
                },
                "corpusId": 260055082,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7e55408ab2b3ffd7dca5109375058bac96f6e89c",
                "title": "Latency Matters: Real-Time Action Forecasting Transformer",
                "abstract": "We present RAFTformer, a realtime action forecasting transformer for latency-aware realworld action forecasting. RAFTformer is a two-stage fully transformer based architecture comprising of a video transformer backbone that operates on high resolution, short-range clips, and a head transformer encoder that temporally aggregates information from multiple short-range clips to span a long-term horizon. Additionally, we propose a novel self-supervised shuffled causal masking scheme as a model level augmentation to improve forecasting fidelity. Finally, we also propose a novel realtime evaluation setting for action fore-casting that directly couples model inference latency to overall forecasting performance and brings forth a hith-erto overlooked trade-off between latency and action fore-casting performance. Our parsimonious network design fa-cilitates RAFTformer inference latency to be 9x smaller than prior works at the same forecasting accuracy. Owing to its two-staged design, RAFTformer uses 94% less training compute and 90% lesser training parameters to outperform prior state-of-the-art baselines by 4.9 points on EGTEA Gaze+ and by 1.4 points on EPIC-Kitchens-100 validation set, as measured by Top-5 recall (T5R) in the offline setting. In the realtime setting, RAFTformer outperforms prior works by an even greater margin of upto 4.4 T5R points on the EPIC-Kitchens-100 dataset. Project Webpage: https://karttikeya.github.io/publication/RAFTformer/.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1612131148",
                        "name": "Harshayu Girase"
                    },
                    {
                        "authorId": "40930518",
                        "name": "Nakul Agarwal"
                    },
                    {
                        "authorId": "37435569",
                        "name": "Chiho Choi"
                    },
                    {
                        "authorId": "11379939",
                        "name": "K. Mangalam"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "The global pedestrian motion is simulated using Y-net and executed in parallel to future state simulation.",
                "al [25] have proposed Y-net, which predicts and generates pedestrian trajectories considering the map information.",
                "Mangalam et. al [25] have proposed Y-net, which predicts and generates pedestrian trajectories considering the map information.",
                "pedestrians follow the path prediction result obtained through Y-net [25] running in parallel to MCTS.",
                "In this paper, Y-net is used for modeling global motion, while the social force model and Boids are used for modeling local motion to synthesize realistic pedestrian motions.",
                "The pedestrians follow the path prediction result obtained through Y-net [25] running in parallel to MCTS.",
                "In SCAN, we only use a neural network, namely Y-net [25], for global pedestrian trajectory prediction.",
                "We have implemented a crowd navigation environment as shown in Figure 2, where each pedestrian tries to follow its global trajectory generated by Y-Net [25]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "e9d0199b6030ce969a777158dbf99f626b5e3b4c",
                "externalIds": {
                    "DBLP": "conf/icra/OhHLLKPO23",
                    "DOI": "10.1109/ICRA48891.2023.10160270",
                    "CorpusId": 259338100
                },
                "corpusId": 259338100,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e9d0199b6030ce969a777158dbf99f626b5e3b4c",
                "title": "SCAN: Socially-Aware Navigation Using Monte Carlo Tree Search",
                "abstract": "Designing a socially-aware navigation method for crowded environments has become a critical issue in robotics. In order to perform navigation in a crowded environment without causing discomfort to nearby pedestrians, it is necessary to design a global planner that is able to consider both human-robot interaction (HRI) and prediction of future states. In this paper, we propose a socially-aware global planner called SCAN, which is a global planner that generates appropriate local goals considering HRI and prediction of future states. Our method simulates future states considering the effects of the robot's actions on the future intentions of pedestrians using Monte Carlo tree search (MCTS), which estimates the quality of local goals. For fast simulation, we execute pedestrian motion prediction using Y-net and future state simulation using MCTS in parallel. Neural networks are only used in Y-net and not in MCTS, which enables fast simulation and prediction of a long horizon of future states. We evaluate the proposed method based on the proposed socially-aware navigation metric using realistic pedestrian simulation and real-world experiments. The results show that the proposed method outperforms existing methods significantly, indicating the importance of considering human-robot interaction for socially-aware navigation.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2148408776",
                        "name": "Jeongwoo Oh"
                    },
                    {
                        "authorId": "2053277299",
                        "name": "Jaeseok Heo"
                    },
                    {
                        "authorId": "2202231577",
                        "name": "Junseo Lee"
                    },
                    {
                        "authorId": "2049018111",
                        "name": "Gunmin Lee"
                    },
                    {
                        "authorId": "49594789",
                        "name": "Minjae Kang"
                    },
                    {
                        "authorId": "48490857",
                        "name": "Jeongho Park"
                    },
                    {
                        "authorId": "66867723",
                        "name": "Songhwai Oh"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Whereas, in the long-term prediction setting [16], a 10 times longer prediction horizon, up to a minute, is considered.",
                "There are very few approaches, made by the researchers to tackle this, such as estimating multi-modal long-term goals of the agents first, and then randomness is further reduced by sampling intermediate waypoints, conditioned on the final goal [16].",
                "4, we studied the prediction capability of the Di-Long model on longer time horizons than t f = 30 sec, and compared to Goal-SAR and Y-Net.",
                "We sample only a single waypoint, conditioned on the final predicted goal, in the same manner as proposed in Y-Net [16].",
                "As shown in the figure, our Di-Long model consistently outperforms Y-Net and Goal-SAR, and interestingly, at shorter time horizons, the performances of the models are comparable, Optimal Teacher Observation Length.",
                "of-the-art Y-Net [16] model, despite having a much simpler architecture.",
                "However, long-term human trajectory forecasting [16], which involves predicting human motion over a much longer period, remains a challenging task due to the complexity of human behavior and the uncertainty of future events.",
                "Many methods have been proposed for this task, including recurrent neural networks (RNNs) [1, 27], convolutional neural networks (CNNs) [16], and graph neural networks (GNNs) [23].",
                "In this scenario, our Di-Long model outperforms Goal-SAR and Y-Net by a considerable margin in terms of ADE ( \u2212 0 .",
                "We compare our increasingly improving Di-Long model with Goal-SAR and Y-Net.",
                "32 w.r.t. Y-Net) and KDE-NLL ( \u2212 0 .",
                "3 w.r.t. Y-Net), FDE ( \u2212 3 .",
                "In recent years, deep learning models such as recurrent neural networks (RNNs) [1, 27], convolutional neural networks (CNNs) [16], and graph neural networks (GNNs) [23] have been widely used for human trajectory forecasting."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "22f2f7c7416c42bb1c31475628689506101c6814",
                "externalIds": {
                    "ArXiv": "2305.08553",
                    "DBLP": "journals/corr/abs-2305-08553",
                    "DOI": "10.48550/arXiv.2305.08553",
                    "CorpusId": 258686342
                },
                "corpusId": 258686342,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/22f2f7c7416c42bb1c31475628689506101c6814",
                "title": "Distilling Knowledge for Short-to-Long Term Trajectory Prediction",
                "abstract": "Long-term trajectory forecasting is an important and challenging problem in the fields of computer vision, machine learning, and robotics. One fundamental difficulty stands in the evolution of the trajectory that becomes more and more uncertain and unpredictable as the time horizon grows, subsequently increasing the complexity of the problem. To overcome this issue, in this paper, we propose Di-Long, a new method that employs the distillation of a short-term trajectory model forecaster that guides a student network for long-term trajectory prediction during the training process. Given a total sequence length that comprehends the allowed observation for the student network and the complementary target sequence, we let the student and the teacher solve two different related tasks defined over the same full trajectory: the student observes a short sequence and predicts a long trajectory, whereas the teacher observes a longer sequence and predicts the remaining short target trajectory. The teacher's task is less uncertain, and we use its accurate predictions to guide the student through our knowledge distillation framework, reducing long-term future uncertainty. Our experiments show that our proposed Di-Long method is effective for long-term forecasting and achieves state-of-the-art performance on the Intersection Drone Dataset (inD) and the Stanford Drone Dataset (SDD).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2109605310",
                        "name": "Sourav Das"
                    },
                    {
                        "authorId": "1637242169",
                        "name": "Guglielmo Camporese"
                    },
                    {
                        "authorId": "1795847",
                        "name": "Lamberto Ballan"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Multi-agent trajectory prediction has various applications, such as automated driving [Zhao et al., 2021, Salzmann et al., 2020, Mangalam et al., 2020, Leon and Gavrilescu, 2021], robot planning [Kretzschmar et al., 2014, Schmerling et al., 2018], sports analysis [Felsen et al., 2017], and is being\u2026"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7b168371131495f4fc2e84957dec20bfa3d0b426",
                "externalIds": {
                    "ArXiv": "2305.08073",
                    "DBLP": "journals/corr/abs-2305-08073",
                    "DOI": "10.48550/arXiv.2305.08073",
                    "CorpusId": 258685634
                },
                "corpusId": 258685634,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7b168371131495f4fc2e84957dec20bfa3d0b426",
                "title": "HiPerformer: Hierarchically Permutation-Equivariant Transformer for Time Series Forecasting",
                "abstract": "It is imperative to discern the relationships between multiple time series for accurate forecasting. In particular, for stock prices, components are often divided into groups with the same characteristics, and a model that extracts relationships consistent with this group structure should be effective. Thus, we propose the concept of hierarchical permutation-equivariance, focusing on index swapping of components within and among groups, to design a model that considers this group structure. When the prediction model has hierarchical permutation-equivariance, the prediction is consistent with the group relationships of the components. Therefore, we propose a hierarchically permutation-equivariant model that considers both the relationship among components in the same group and the relationship among groups. The experiments conducted on real-world data demonstrate that the proposed method outperforms existing state-of-the-art methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2217249294",
                        "name": "Ryo Umagami"
                    },
                    {
                        "authorId": "2052827906",
                        "name": "Yusuke Ono"
                    },
                    {
                        "authorId": "2374364",
                        "name": "Yusuke Mukuta"
                    },
                    {
                        "authorId": "2075436077",
                        "name": "Tatsuya Harada"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Following [1, 16, 60, 34, 35, 45], we use the leave-one-out training and evaluation setup, where we train on all but one of the 5 environment scenes, and evaluate on the left-out scene.",
                "Net [34], and AgentFormer [60]; and other standard baselines from recent years: Trajectron++ [45], PECNet [35], and S-GAN [16].",
                "SOTA methods have employed a variety of techniques for better modeling, such as using waypoints and goals to break the forecasting problem into a series of hierarchical steps [11, 34, 63, 7, 8, 61, 64, 54, 52], mathematical and physical modeling techniques such as social forces [17] alongside deep architectures [61, 52, 31], and other paradigms and techniques such as memory retrieval [53], contrastive learning [33], and causal disentanglement [32].",
                "View Vertically used a different sample rate on the eth scene and a slightly different split of the hotel scene in the ETH dataset; thus, we retrain and reevaluate it on the standard split used by most other methods ([45, 35, 34, 53, 16, 60])."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "b0cd566b562eff918d9b9c8dd897672ac26cd9b2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-06292",
                    "ArXiv": "2305.06292",
                    "DOI": "10.48550/arXiv.2305.06292",
                    "CorpusId": 258588337
                },
                "corpusId": 258588337,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b0cd566b562eff918d9b9c8dd897672ac26cd9b2",
                "title": "Joint Metrics Matter: A Better Standard for Trajectory Forecasting",
                "abstract": "Multi-modal trajectory forecasting methods commonly evaluate using single-agent metrics (marginal metrics), such as minimum Average Displacement Error (ADE) and Final Displacement Error (FDE), which fail to capture joint performance of multiple interacting agents. Only focusing on marginal metrics can lead to unnatural predictions, such as colliding trajectories or diverging trajectories for people who are clearly walking together as a group. Consequently, methods optimized for marginal metrics lead to overly-optimistic estimations of performance, which is detrimental to progress in trajectory forecasting research. In response to the limitations of marginal metrics, we present the first comprehensive evaluation of state-of-the-art (SOTA) trajectory forecasting methods with respect to multi-agent metrics (joint metrics): JADE, JFDE, and collision rate. We demonstrate the importance of joint metrics as opposed to marginal metrics with quantitative evidence and qualitative examples drawn from the ETH / UCY and Stanford Drone datasets. We introduce a new loss function incorporating joint metrics that, when applied to a SOTA trajectory forecasting method, achieves a 7% improvement in JADE / JFDE on the ETH / UCY datasets with respect to the previous SOTA. Our results also indicate that optimizing for joint metrics naturally leads to an improvement in interaction modeling, as evidenced by a 16% decrease in mean collision rate on the ETH / UCY datasets with respect to the previous SOTA.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1403697181",
                        "name": "Erica Weng"
                    },
                    {
                        "authorId": "47379300",
                        "name": "Hanako Hoshino"
                    },
                    {
                        "authorId": "1770537",
                        "name": "Deva Ramanan"
                    },
                    {
                        "authorId": "37991449",
                        "name": "Kris M. Kitani"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dcb051ce8825ae82bde44f43938c070d18394f1f",
                "externalIds": {
                    "DBLP": "conf/cvpr/JiaWCXHYL23",
                    "ArXiv": "2305.06242",
                    "DOI": "10.1109/CVPR52729.2023.02105",
                    "CorpusId": 258587978
                },
                "corpusId": 258587978,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dcb051ce8825ae82bde44f43938c070d18394f1f",
                "title": "Think Twice before Driving: Towards Scalable Decoders for End-to-End Autonomous Driving",
                "abstract": "End-to-end autonomous driving has made impressive progress in recent years. Existing methods usually adopt the decoupled encoder-decoder paradigm, where the encoder extracts hidden features from raw sensor data, and the decoder outputs the ego-vehicle's future trajectories or actions. Under such a paradigm, the encoder does not have access to the intended behavior of the ego agent, leaving the burden of finding out safety-critical regions from the massive receptive field and inferring about future situations to the decoder. Even worse, the decoder is usually composed of several simple multi-layer perceptrons (MLP) or GRUs while the encoder is delicately designed (e.g., a combination of heavy ResNets or Transformer). Such an imbalanced resource-task division hampers the learning process. In this work, we aim to alleviate the aforementioned problem by two principles: (1) fully utilizing the capacity of the encoder; (2) increasing the capacity of the decoder. Concretely, we first predict a coarse-grained future position and action based on the encoder features. Then, conditioned on the position and action, the future scene is imagined to check the ramification if we drive accordingly. We also retrieve the encoder features around the predicted coordinate to obtain fine-grained information about the safety-critical region. Finally, based on the predicted future and the retrieved salient feature, we refine the coarse-grained position and action by predicting its offset from ground-truth. The above refinement module could be stacked in a cascaded fashion, which extends the capacity of the decoder with spatial-temporal prior knowledge about the conditioned future. We conduct experiments on the CARLA simulator and achieve state-of-the-art performance in closed-loop benchmarks. Extensive ablation studies demonstrate the effectiveness of each proposed module.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1958998899",
                        "name": "Xiaosong Jia"
                    },
                    {
                        "authorId": "2111194450",
                        "name": "Peng Wu"
                    },
                    {
                        "authorId": "2170764701",
                        "name": "Li Chen"
                    },
                    {
                        "authorId": "82346802",
                        "name": "Jiangwei Xie"
                    },
                    {
                        "authorId": "3486481",
                        "name": "Conghui He"
                    },
                    {
                        "authorId": "3063894",
                        "name": "Junchi Yan"
                    },
                    {
                        "authorId": "46381640",
                        "name": "Hongyang Li"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Most of them only focus on multi-future path prediction [43, 63, 70, 73] (k=5, 8, 15, 20, .",
                "Most works in this context predict multiple future trajectories and choose the best to assess their accuracy and performance [43, 63, 70]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7cd64f60802b6d447d709351a38a73b8641a1e3f",
                "externalIds": {
                    "DBLP": "conf/iccps/NoghreKPNT23",
                    "DOI": "10.1145/3576841.3585933",
                    "CorpusId": 258486799
                },
                "corpusId": 258486799,
                "publicationVenue": {
                    "id": "7e4ed95a-56b0-4c31-9460-2cee8bf99394",
                    "name": "International Conference on Cyber-Physical Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Cyber-physical Syst",
                        "International Conference Ceramic Processing Science",
                        "ICCPS",
                        "Int Conf Ceram Process Sci"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1319"
                },
                "url": "https://www.semanticscholar.org/paper/7cd64f60802b6d447d709351a38a73b8641a1e3f",
                "title": "Pishgu: Universal Path Prediction Network Architecture for Real-time Cyber-physical Edge Systems",
                "abstract": "Path prediction is an essential task for many real-world Cyber-Physical Systems (CPS) applications, from autonomous driving and traffic monitoring/management to pedestrian/worker safety. These real-world CPS applications need a robust, lightweight path prediction that can provide a universal network architecture for multiple subjects (e.g., pedestrians and vehicles) from different perspectives. However, most existing algorithms are tailor-made for a unique subject with a specific camera perspective and scenario. This article presents Pishgu, a universal lightweight network architecture, as a robust and holistic solution for path prediction. Pishgu's architecture can adapt to multiple path prediction domains with different subjects (vehicles, pedestrians), perspectives (bird's-eye, high-angle), and scenes (sidewalk, highway). Our proposed architecture captures the inter-dependencies within the subjects in each frame by taking advantage of Graph Isomorphism Networks and the attention module. We separately train and evaluate the efficacy of our architecture on three different CPS domains across multiple perspectives (vehicle bird's-eye view, pedestrian bird's-eye view, and human high-angle view). Pishgu outperforms state-of-the-art solutions in the vehicle bird's-eye view domain by 42% and 61% and pedestrian high-angle view domain by 23% and 22% in terms of ADE and FDE, respectively. Additionally, we analyze the domain-specific details for various datasets to understand their effect on path prediction and model interpretation. Finally, we report the latency and throughput for all three domains on multiple embedded platforms showcasing the robustness and adaptability of Pishgu for real-world integration into CPS applications.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2216225343",
                        "name": "Ghazal Alinezhad Noghre"
                    },
                    {
                        "authorId": "79354862",
                        "name": "Vinit Katariya"
                    },
                    {
                        "authorId": "2216225328",
                        "name": "Armin Danesh Pazho"
                    },
                    {
                        "authorId": "2059566339",
                        "name": "Christopher Neff"
                    },
                    {
                        "authorId": "2163459201",
                        "name": "Hamed Tabkhi"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Interaction between agents is represented using social pooling [1], global scene information [2], and spatio-temporal features of all agents [3], [4], [5]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "45d30f9ec3917a7f470c948e0cd05209d78742c8",
                "externalIds": {
                    "DBLP": "journals/ral/VishnuARMB23",
                    "DOI": "10.1109/LRA.2023.3258685",
                    "CorpusId": 257606929
                },
                "corpusId": 257606929,
                "publicationVenue": {
                    "id": "93c335b7-edf4-45f5-8ddc-7c5835154945",
                    "name": "IEEE Robotics and Automation Letters",
                    "alternate_names": [
                        "IEEE Robot Autom Lett"
                    ],
                    "issn": "2377-3766",
                    "url": "https://www.ieee.org/membership-catalog/productdetail/showProductDetailPage.html?product=PER481-ELE",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=7083369"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/45d30f9ec3917a7f470c948e0cd05209d78742c8",
                "title": "Improving Multi-Agent Trajectory Prediction Using Traffic States on Interactive Driving Scenarios",
                "abstract": "Predicting trajectories of multiple agents in interactive driving scenarios such as intersections, and roundabouts are challenging due to the high density of agents, varying speeds, and environmental obstacles. Existing approaches use relative distance and semantic maps of intersections to improve trajectory prediction. However, drivers base their driving decision on the overall traffic state of the intersection and the surrounding vehicles. So, we propose to use traffic states that denote changing spatio-temporal interaction between neighboring vehicles, to improve trajectory prediction. An example of a traffic state is a clump state which denotes that the vehicles are moving close to each other, i.e., congestion is forming. We develop three prediction models with different architectures, namely, Transformer-based (TS-Transformer), Generative Adversarial Network-based (TS-GAN), and Conditional Variational Autoencoder-based (TS-CVAE). We show that traffic state-based models consistently predict better future trajectories than the vanilla models. TS-Transformer produces state-of-the-art results on two challenging interactive trajectory prediction datasets, namely, Eye-on-Traffic (EOT), and INTERACTION. Our qualitative analysis shows that traffic state-based models have better aligned trajectories to the ground truth.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2070209317",
                        "name": "Vishnu Chalavadi"
                    },
                    {
                        "authorId": "2212274237",
                        "name": "Vineel Abhinav"
                    },
                    {
                        "authorId": "1443776158",
                        "name": "Debaditya Roy"
                    },
                    {
                        "authorId": "34358756",
                        "name": "C. Mohan"
                    },
                    {
                        "authorId": "33677822",
                        "name": "C. Babu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "daab2b56ae46cd7aabc7d62a6a8aca88d28c7ece",
                "externalIds": {
                    "DBLP": "journals/kbs/NaK023",
                    "DOI": "10.1016/j.knosys.2023.110637",
                    "CorpusId": 258793118
                },
                "corpusId": 258793118,
                "publicationVenue": {
                    "id": "12fff95b-d469-49a0-84a5-4fd4696c3f28",
                    "name": "Knowledge-Based Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Knowl Based Syst",
                        "Knowledge Based Systems",
                        "Knowledge-based Syst"
                    ],
                    "issn": "0950-7051",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525448/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/knowledge-based-systems",
                        "http://www.sciencedirect.com/science/journal/09507051"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/daab2b56ae46cd7aabc7d62a6a8aca88d28c7ece",
                "title": "SPU-BERT: Faster human multi-trajectory prediction from socio-physical understanding of BERT",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2056318141",
                        "name": "Ki-In Na"
                    },
                    {
                        "authorId": "8130549",
                        "name": "Ue-Hwan Kim"
                    },
                    {
                        "authorId": "102361170",
                        "name": "Jong-Hwan Kim"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [
                ", where pedestrians often change direction) [48]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b663f62ed7620ebddc86ba6b38f628a72cade78f",
                "externalIds": {
                    "PubMedCentral": "10221920",
                    "DBLP": "journals/sensors/LuiCH23",
                    "DOI": "10.3390/s23104882",
                    "CorpusId": 258813468,
                    "PubMed": "37430795"
                },
                "corpusId": 258813468,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b663f62ed7620ebddc86ba6b38f628a72cade78f",
                "title": "Functional Objects in Urban Walking Environments and Pedestrian Trajectory Modelling",
                "abstract": "Functional objects are large and small physical entities installed in urban environments to offer specific functionalities to visitors, such as shops, escalators, and information kiosks. Instances of the novel notion are focal points of human activities and are significant in pedestrian movement. Pedestrian trajectory modelling in an urban scene is a challenging problem because of the complex patterns resulting from social interactions of the crowds and the diverse relation between pedestrians and functional objects. Many data-driven methods have been proposed to explain the complex movements in urban scenes. However, the methods considering functional objects in their formulation are rare. This study aims to reduce the knowledge gap by demonstrating the importance of pedestrian\u2013object relations in the modelling task. The proposed modelling method, called pedestrian\u2013object relation guided trajectory prediction (PORTP), uses a dual-layer architecture that includes a predictor of pedestrian\u2013object relation and a series of relation-specific specialized pedestrian trajectory prediction models. The experiment findings indicate that the inclusion of pedestrian\u2013object relation results in more accurate predictions. This study provides an empirical foundation for the novel notion and a strong baseline for future work on this topic.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47867329",
                        "name": "A. Lui"
                    },
                    {
                        "authorId": "51027757",
                        "name": "Y. Chan"
                    },
                    {
                        "authorId": "2105517747",
                        "name": "Kevin Hung"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "More recently, a method named Y-Net is presented in [8] by Mangalam et al.",
                "In order to make such predictions, multiple solutions have been studied in the state-of-the-art for pedestrians that can be classified into solutions relying on Gaussian Processes [2], on Long Short Term Memory (LSTM) neural networks [3][4], on encoders and decoders [5][6], on Convolutional Neural Network (CNN) [7][8] and on Generative Adversarial Network [9]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c12e3372da902202919be2048a703cf8f5544c96",
                "externalIds": {
                    "DBLP": "conf/plans/KaiserBZR23",
                    "DOI": "10.1109/PLANS53410.2023.10139946",
                    "CorpusId": 259122552
                },
                "corpusId": 259122552,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c12e3372da902202919be2048a703cf8f5544c96",
                "title": "Investigations on pedestrian long-term trajectory prediction based on AI and environmental maps",
                "abstract": "In highly shared urban traffic environments, it is essential to protect Vulnerable Road Users (VRU) to avoid collisions with motorized transport. One approach is to predict the intention or the future trajectories of the VRU from their previous path in order to send warnings in case of danger, or even to brake the cars in case of using driver assistance systems. The main objective of this paper is to investigate the short-term and particularly long-term prediction abilities of the AI-based predictors assisted with environmental maps, if applicable. By comparing and evaluating the performance of Polynomial Regression (PR), Gaussian Process Regression (GPR), Convolutional Neural Network (CNN), and Sequence-to-sequence neural networks (SeqToSeq) applied on an open access data set (i.e., Stanford Drone Dataset (SDD)) as well as some simulated data, we can conclude that the SeqToSeq generally performs better than other methods (Average Displacement Error is 25% lower and Final Displacement Error is 20% lower compared to a first order PR). By adding the environmental maps (navigation map and diffusion map), the pedestrian's turnings are better predicted despite the fact that there is little improvement on other metrics. This can be explained by an insufficient amount of training data involving environmental maps in this research work. Thus it is still promising by adding more training data with environmental maps in the future.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2184701",
                        "name": "S. Kaiser"
                    },
                    {
                        "authorId": "2192057539",
                        "name": "Pierre Baudet"
                    },
                    {
                        "authorId": "1830554912",
                        "name": "Ni Zhu"
                    },
                    {
                        "authorId": "1689765",
                        "name": "V. Renaudin"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "In addition, several works [30], [31], [32], [33], [34] leverage the visual features of the scene to improve the spatio-temporal features."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "421be5b0cbe58dc453828e569bf9a88928d4d4ad",
                "externalIds": {
                    "DBLP": "journals/pami/ShiWLZTZH23",
                    "DOI": "10.1109/TPAMI.2023.3268110",
                    "CorpusId": 258214905,
                    "PubMed": "37074900"
                },
                "corpusId": 258214905,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/421be5b0cbe58dc453828e569bf9a88928d4d4ad",
                "title": "Representing Multimodal Behaviors With Mean Location for Pedestrian Trajectory Prediction",
                "abstract": "Representing multimodal behaviors is a critical challenge for pedestrian trajectory prediction. Previous methods commonly represent this multimodality with multiple latent variables repeatedly sampled from a latent space, encountering difficulties in interpretable trajectory prediction. Moreover, the latent space is usually built by encoding global interaction into future trajectory, which inevitably introduces superfluous interactions and thus leads to performance reduction. To tackle these issues, we propose a novel Interpretable Multimodality Predictor (IMP) for pedestrian trajectory prediction, whose core is to represent a specific mode by its mean location. We model the distribution of mean location as a Gaussian Mixture Model (GMM) conditioned on sparse spatio-temporal features, and sample multiple mean locations from the decoupled components of GMM to encourage multimodality. Our IMP brings four-fold benefits: 1) Interpretable prediction to provide semantics about the motion behavior of a specific mode; 2) Friendly visualization to present multimodal behaviors; 3) Well theoretical feasibility to estimate the distribution of mean locations supported by the central-limit theorem; 4) Effective sparse spatio-temporal features to reduce superfluous interactions and model temporal continuity of interaction. Extensive experiments validate that our IMP not only outperforms state-of-the-art methods but also can achieve a controllable prediction by customizing the corresponding mean location.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2153002505",
                        "name": "Liushuai Shi"
                    },
                    {
                        "authorId": "2108571702",
                        "name": "Le Wang"
                    },
                    {
                        "authorId": "48015811",
                        "name": "Chengjiang Long"
                    },
                    {
                        "authorId": "3373601",
                        "name": "Sanping Zhou"
                    },
                    {
                        "authorId": "2021307128",
                        "name": "Wei Tang"
                    },
                    {
                        "authorId": "2144620206",
                        "name": "Nanning Zheng"
                    },
                    {
                        "authorId": "144988571",
                        "name": "G. Hua"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Recently, a series of end-points-based methods [52], [53], [54] have been proposed that first predict agents\u2019 destinations and then interpolate the complete trajectories under the chosen destinations.",
                "Others like [53] also introduce several \u201cwaypoints\u201d to help better predict agents\u2019 potential future intentions rather than the only destination points.",
                "Unlike the split of the SDD in TrajNet [88] (which includes only pedestrians), the SDD we use includes all categories of annotations.\nlines, including Linear Least Square4, SoPhie [20], S-BiGAT [19], E-SR-LSTM [85], Multiverse [87], MANTRA [89], TF [28], PECNet [52], STAR [29], Trajectron++ [67], SimAug [86], TPNMS [90], Introvert [91], LB-EBM [92], Agentformer [44], Y-net [53], STC-Net [93], SpecTGNN [77], CSCNet [83], MSN [33], MID [94], SHENet [95], SEEM [96], Social-SSL [66], P-LSTM [40], Zero-Vel [97] , and PV-LSTM [40].",
                "Compared with the current state-ofthe-art method Y-net, E-V2-Net-DFT achieves about 16.3% and 11.5% improvement in ADE and FDE, respectively.",
                "As shown in TABLE 2, E-V2-Nets, including E-V2-Net-DFT and E-V2-Net-Haar, perform at the same level as the state-of-theart works like Agentformer and Y-net, especially on the univ sub-dataset with a maximum improvement of 23.1% and 26.1% for ADE and FDE, demonstrating their unique advantages for handling different prediction scenes.",
                "It means that the proposed methods, which firstly forecast \u201ckeypoint spectrums\u201d, could cover more information than the previous \u201cwaypoints\u201d-based methods like Y-net [53].",
                "lines, including Linear Least Square4, SoPhie [20], S-BiGAT [19], E-SR-LSTM [85], Multiverse [87], MANTRA [89], TF [28], PECNet [52], STAR [29], Trajectron++ [67], SimAug [86], TPNMS [90], Introvert [91], LB-EBM [92], Agentformer [44], Y-net [53], STC-Net [93], SpecTGNN [77], CSCNet [83], MSN [33], MID [94], SHENet [95], SEEM [96], Social-SSL [66], P-LSTM [40], Zero-Vel [97] , and PV-LSTM [40]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "36585c165c91ee704151c2776e2f37458433f2a2",
                "externalIds": {
                    "ArXiv": "2304.05106",
                    "DBLP": "journals/corr/abs-2304-05106",
                    "DOI": "10.48550/arXiv.2304.05106",
                    "CorpusId": 258059739
                },
                "corpusId": 258059739,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/36585c165c91ee704151c2776e2f37458433f2a2",
                "title": "Another Vertical View: A Hierarchical Network for Heterogeneous Trajectory Prediction via Spectrums",
                "abstract": "With the fast development of AI-related techniques, the applications of trajectory prediction are no longer limited to easier scenes and trajectories. More and more heterogeneous trajectories with different representation forms, such as 2D or 3D coordinates, 2D or 3D bounding boxes, and even high-dimensional human skeletons, need to be analyzed and forecasted. Among these heterogeneous trajectories, interactions between different elements within a frame of trajectory, which we call the ``Dimension-Wise Interactions'', would be more complex and challenging. However, most previous approaches focus mainly on a specific form of trajectories, which means these methods could not be used to forecast heterogeneous trajectories, not to mention the dimension-wise interaction. Besides, previous methods mostly treat trajectory prediction as a normal time sequence generation task, indicating that these methods may require more work to directly analyze agents' behaviors and social interactions at different temporal scales. In this paper, we bring a new ``view'' for trajectory prediction to model and forecast trajectories hierarchically according to different frequency portions from the spectral domain to learn to forecast trajectories by considering their frequency responses. Moreover, we try to expand the current trajectory prediction task by introducing the dimension $M$ from ``another view'', thus extending its application scenarios to heterogeneous trajectories vertically. Finally, we adopt the bilinear structure to fuse two factors, including the frequency response and the dimension-wise interaction, to forecast heterogeneous trajectories via spectrums hierarchically in a generic way. Experiments show that the proposed model outperforms most state-of-the-art methods on ETH-UCY, Stanford Drone Dataset and nuScenes with heterogeneous trajectories, including 2D coordinates, 2D and 3D bounding boxes.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1991582869",
                        "name": "Conghao Wong"
                    },
                    {
                        "authorId": "1561145507",
                        "name": "Beihao Xia"
                    },
                    {
                        "authorId": "2647338",
                        "name": "Qinmu Peng"
                    },
                    {
                        "authorId": "2143616967",
                        "name": "Xinge You"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "It requires human trajectory forecasting systems to formulate humans\u2019 multimodality nature and infer not a single future state but the full range of plausible ones [16, 32].",
                "Besides, some methods explicitly use the endpoint [14, 15, 32, 33, 64, 65] to model the possible destinations or learn the grid-based location encoder [11, 17, 29] generate acceptable paths."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ecff6ecf349f3b2ea36bc666acf5671f836f4e7d",
                "externalIds": {
                    "DBLP": "conf/cvpr/ChenCFZ23",
                    "ArXiv": "2304.04298",
                    "DOI": "10.1109/CVPR52729.2023.01714",
                    "CorpusId": 258048886
                },
                "corpusId": 258048886,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ecff6ecf349f3b2ea36bc666acf5671f836f4e7d",
                "title": "Unsupervised Sampling Promoting for Stochastic Human Trajectory Prediction",
                "abstract": "The indeterminate nature of human motion requires trajectory prediction systems to use a probabilistic model to formulate the multi-modality phenomenon and infer a finite set of future trajectories. However, the inference processes of most existing methods rely on Monte Carlo random sampling, which is insufficient to cover the realistic paths with finite samples, due to the long tail effect of the predicted distribution. To promote the sampling process of stochastic prediction, we propose a novel method, called BOsampler, to adaptively mine potential paths with Bayesian optimization in an unsupervised manner, as a sequential design strategy in which new prediction is dependent on the previously drawn samples. Specifically, we model the trajectory sampling as a Gaussian process and construct an acquisition function to measure the potential sampling value. This acquisition function applies the original distribution as prior and encourages exploring paths in the long-tail region. This sampling method can be integrated with existing stochastic predictive models without retraining. Experimental results on various baseline methods demonstrate the effectiveness of our method. The source code is released in this link.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2155315836",
                        "name": "Guan-Hong Chen"
                    },
                    {
                        "authorId": "2144321586",
                        "name": "Zhe Chen"
                    },
                    {
                        "authorId": "2213753651",
                        "name": "Shunxing Fan"
                    },
                    {
                        "authorId": "2175349484",
                        "name": "Kun Zhang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b1f4c923dccaf62b13555c20814cb03974c2c8e8",
                "externalIds": {
                    "DBLP": "conf/cvpr/RagusaFF23",
                    "ArXiv": "2304.03959",
                    "DOI": "10.1109/CVPRW59228.2023.00371",
                    "CorpusId": 258048960
                },
                "corpusId": 258048960,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b1f4c923dccaf62b13555c20814cb03974c2c8e8",
                "title": "StillFast: An End-to-End Approach for Short-Term Object Interaction Anticipation",
                "abstract": "Anticipation problem has been studied considering different aspects such as predicting humans\u2019 locations, predicting hands and objects trajectories, and forecasting actions and human-object interactions. In this paper, we studied the short-term object interaction anticipation problem from the egocentric point of view, proposing a new end-to-end architecture named StillFast. Our approach simultaneously processes a still image and a video detecting and localizing next-active objects, predicting the verb which describes the future interaction and determining when the interaction will start. Experiments on the large-scale egocentric dataset EGO4D [17] show that our method outperformed state-of-the-art approaches on the considered task. Our method is ranked first in the public leaderboard of the EGO4D short term object interaction anticipation challenge 2022 and it is the official baseline for the 2023 one. Please see the project web page for code and additional details: https://iplab.dmi.unict.it/stillfast/.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2210764448",
                        "name": "F. Ragusa"
                    },
                    {
                        "authorId": "1729739",
                        "name": "G. Farinella"
                    },
                    {
                        "authorId": "1792681",
                        "name": "Antonino Furnari"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "However, the ability to control these models is limited to sampling from an output trajectory distribution [37, 66] or using an expensive latent space traversal [49].",
                "Some works decompose forecasting into goal prediction followed by trajectory prediction based on goals [7, 37].",
                "[37] Karttikeya Mangalam, Yang An, Harshayu Girase, and Jiten-"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5ed27de050c7c31769af6e15ceae2dfcf0830c3f",
                "externalIds": {
                    "DBLP": "conf/cvpr/Rempe0P0KKFL23",
                    "ArXiv": "2304.01893",
                    "DOI": "10.1109/CVPR52729.2023.01322",
                    "CorpusId": 257921535
                },
                "corpusId": 257921535,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5ed27de050c7c31769af6e15ceae2dfcf0830c3f",
                "title": "Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory Diffusion",
                "abstract": "We introduce a method for generating realistic pedestrian trajectories and full-body animations that can be controlled to meet user-defined goals. We draw on recent advances in guided diffusion modeling to achieve test-time controllability of trajectories, which is normally only associated with rule-based systems. Our guided diffusion model allows users to constrain trajectories through target waypoints, speed, and specified social groups while accounting for the surrounding environment context. This trajectory diffusion model is integrated with a novel physics-based humanoid controller to form a closed-loop, full-body pedestrian animation system capable of placing large crowds in a simulated environment with varying terrains. We further propose utilizing the value function learned during RL training of the animation controller to guide diffusion to produce trajectories better suited for particular scenarios such as collision avoidance and traversing uneven terrain. Video results are available on the project page.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "40084473",
                        "name": "Davis Rempe"
                    },
                    {
                        "authorId": "2566332",
                        "name": "Zhengyi Luo"
                    },
                    {
                        "authorId": "32200465",
                        "name": "X. B. Peng"
                    },
                    {
                        "authorId": "145412874",
                        "name": "Ye Yuan"
                    },
                    {
                        "authorId": "144040368",
                        "name": "Kris Kitani"
                    },
                    {
                        "authorId": "32113848",
                        "name": "Karsten Kreis"
                    },
                    {
                        "authorId": "37895334",
                        "name": "S. Fidler"
                    },
                    {
                        "authorId": "2528439",
                        "name": "O. Litany"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "* means the results are reproduced using the official released code of [30].",
                "To train Y-Net, we follow [22] to make the encoded feature with shape (C,H,W ) average pooled in the spatial dimension to get a C dimensional vector, and perform PCL on it.",
                "We reproduced the results of Y-Net using the official released code of [30] with 42 as the random seed, since the original method does not have a fix seed.",
                "Strong baselines [30, 38, 40, 47] have been brought up.",
                "We use ETH-UCY and Nuscenes in the way same as our backbone Traj++ EWTA [28] and SDD in the way same as our backbone Y-Net [30].",
                "Another strong baseline we experiment on is Y-Net [30], which uses a U-Net backbone and achieves state-of-the-art results on SDD.",
                "We also plug our module into Y-Net, the results are shown in Table 3.",
                "Quantitative comparisons on Y-Net on SDD."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0acce07a83281dfae981c3230e224e8c9eb6c015",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-16574",
                    "ArXiv": "2303.16574",
                    "DOI": "10.1109/CVPR52729.2023.00141",
                    "CorpusId": 257804547
                },
                "corpusId": 257804547,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0acce07a83281dfae981c3230e224e8c9eb6c015",
                "title": "FEND: A Future Enhanced Distribution-Aware Contrastive Learning Framework for Long-Tail Trajectory Prediction",
                "abstract": "Predicting the future trajectories of the traffic agents is a gordian technique in autonomous driving. However, trajectory prediction suffers from data imbalance in the prevalent datasets, and the tailed data is often more complicated and safety-critical. In this paper, we focus on dealing with the long-tail phenomenon in trajectory prediction. Previous methods dealing with long-tail data did not take into account the variety of motion patterns in the tailed data. In this paper, we put forward a future enhanced contrastive learning framework to recognize tail trajectory patterns and form a feature space with separate pattern clusters. Furthermore, a distribution aware hyper predictor is brought up to better utilize the shaped feature space. Our method is a model-agnostic framework and can be plugged into many well-known baselines. Experimental results show that our framework outperforms the state-of-the-art long-tail prediction method on tailed samples by 9.5% on ADE and 8.5% on FDE, while maintaining or slightly improving the averaged performance. Our method also surpasses many long-tail techniques on trajectory prediction task.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2107924952",
                        "name": "Yuning Wang"
                    },
                    {
                        "authorId": "2110106505",
                        "name": "Pu Zhang"
                    },
                    {
                        "authorId": "50010487",
                        "name": "Lei Bai"
                    },
                    {
                        "authorId": "2189422900",
                        "name": "Jianru Xue"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                ", goal-driven idea [13, 40, 60,81], long-tail situation [39], interpretability [32], robustness [9, 66, 70, 80], counterfactual analysis [11], planningdriven [12], generalization ability to new environment [6, 27, 72], and knowledge distillation [44]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "34aa5546668fa15e9582cc422b7384536001dc98",
                "externalIds": {
                    "ArXiv": "2303.16005",
                    "DBLP": "conf/cvpr/XuBCCF23",
                    "DOI": "10.1109/CVPR52729.2023.00929",
                    "CorpusId": 257771376
                },
                "corpusId": 257771376,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/34aa5546668fa15e9582cc422b7384536001dc98",
                "title": "Uncovering the Missing Pattern: Unified Framework Towards Trajectory Imputation and Prediction",
                "abstract": "Trajectory prediction is a crucial undertaking in understanding entity movement or human behavior from observed sequences. However, current methods often assume that the observed sequences are complete while ignoring the potential for missing values caused by object occlusion, scope limitation, sensor failure, etc. This limitation inevitably hinders the accuracy of trajectory prediction. To address this issue, our paper presents a unified framework, the Graph-based Conditional Variational Recurrent Neural Network (GC-VRNN), which can perform trajectory imputation and prediction simultaneously. Specifically, we introduce a novel Multi-Space Graph Neural Network (MS-GNN) that can extract spatial features from incomplete observations and leverage missing patterns. Additionally, we employ a Conditional VRNN with a specifically designed Temporal Decay (TD) module to capture temporal dependencies and temporal missing patterns in incomplete trajectories. The inclusion of the TD module allows for valuable information to be conveyed through the temporal flow. We also curate and benchmark three practical datasets for the joint problem of trajectory imputation and prediction. Extensive experiments verify the exceptional performance of our proposed method. As far as we know, this is the first work to address the lack of benchmarks and techniques for trajectory imputation and prediction in a unified manner.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2143970051",
                        "name": "Yi Xu"
                    },
                    {
                        "authorId": "2212885702",
                        "name": "Armin Bazarjani"
                    },
                    {
                        "authorId": "1379494960",
                        "name": "Hyung-gun Chi"
                    },
                    {
                        "authorId": "37435569",
                        "name": "Chiho Choi"
                    },
                    {
                        "authorId": "46956675",
                        "name": "Y. Fu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Heatmap [12,13,27] is used for modeling future trajectories\u2019 distribution on rasterized images.",
                "many aspects, including temporal encoding [7, 14, 47, 54], interaction modeling [1, 16, 19, 44, 50], and rasterized prediction [12, 13, 27, 49, 55]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4500f038684d573d3f414ad6f94a6e7d73a596f9",
                "externalIds": {
                    "ArXiv": "2303.10895",
                    "DBLP": "conf/cvpr/MaoXZCW23",
                    "DOI": "10.1109/CVPR52729.2023.00534",
                    "CorpusId": 257631504
                },
                "corpusId": 257631504,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4500f038684d573d3f414ad6f94a6e7d73a596f9",
                "title": "Leapfrog Diffusion Model for Stochastic Trajectory Prediction",
                "abstract": "To model the indeterminacy of human behaviors, stochastic trajectory prediction requires a sophisticated multi-modal distribution of future trajectories. Emerging diffusion models have revealed their tremendous representation capacities in numerous generation tasks, showing potential for stochastic trajectory prediction. However, expensive time consumption prevents diffusion models from real-time prediction, since a large number of denoising steps are required to assure sufficient representation ability. To resolve the dilemma, we present LEapfrog Diffusion model (LED), a novel diffusion-based trajectory prediction model, which provides real-time, precise, and diverse predictions. The core of the proposed LED is to leverage a trainable leapfrog initializer to directly learn an expressive multi-modal distribution of future trajectories, which skips a large number of denoising steps, significantly accelerating inference speed. Moreover, the leapfrog initializer is trained to appropriately allocate correlated samples to provide a diversity of predicted future trajectories, significantly improving prediction performances. Extensive experiments on four real-world datasets, including NBA/NFL/SDD/ETH-UCY, show that LED consistently improves performance and achieves 23.7%/21.9% ADE/FDE improvement on NFL. The proposed LED also speeds up the inference 19.3/30.8/24.3/25.1 times compared to the standard diffusion model on NBA/NFL/SDD/ETH-UCY, satisfying real-time inference needs. Code is available at https://github.com/MediaBrain-SJTU/LED.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1500397758",
                        "name": "Wei Mao"
                    },
                    {
                        "authorId": "2153077302",
                        "name": "Chenxin Xu"
                    },
                    {
                        "authorId": "1476704317",
                        "name": "Qi Zhu"
                    },
                    {
                        "authorId": "145552439",
                        "name": "Siheng Chen"
                    },
                    {
                        "authorId": "2130359703",
                        "name": "Yanfeng Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Recent works have used a variety of architectures including recurrent [1, 8, 45, 46] and convolutional [27] neural networks, spatiotemporal graphs [21, 31, 34], state-refinement modules [35], explicit probability maps [23], normalizing flows [2], and Gaussian processes [37, 38].",
                "Inducing structure through interaction representations [23, 31, 37] might improve transfer across a wider range of behavior.",
                "Other approaches use pedestrian datasets to train and validate models for crowd motion prediction [23, 37]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f4e901ae9d388f72fc97ece0127a5fada98903d3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-01424",
                    "ArXiv": "2303.01424",
                    "DOI": "10.48550/arXiv.2303.01424",
                    "CorpusId": 257280177
                },
                "corpusId": 257280177,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f4e901ae9d388f72fc97ece0127a5fada98903d3",
                "title": "From Crowd Motion Prediction to Robot Navigation in Crowds",
                "abstract": "We focus on robot navigation in crowded environments. To navigate safely and efficiently within crowds, robots need models for crowd motion prediction. Building such models is hard due to the high dimensionality of multiagent domains and the challenge of collecting or simulating interaction-rich crowd-robot demonstrations. While there has been important progress on models for offline pedestrian motion forecasting, transferring their performance on real robots is nontrivial due to close interaction settings and novelty effects on users. In this paper, we investigate the utility of a recent state-of-the-art motion prediction model (S-GAN) for crowd navigation tasks. We incorporate this model into a model predictive controller (MPC) and deploy it on a self-balancing robot which we subject to a diverse range of crowd behaviors in the lab. We demonstrate that while S-GAN motion prediction accuracy transfers to the real world, its value is not reflected on navigation performance, measured with respect to safety and efficiency; in fact, the MPC performs indistinguishably even when using a simple constant-velocity prediction model, suggesting that substantial model improvements might be needed to yield significant gains for crowd navigation tasks. Footage from our experiments can be found at https://youtu.be/mzFiXg8KsZ0.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1886278778",
                        "name": "S. Poddar"
                    },
                    {
                        "authorId": "34531831",
                        "name": "Christoforos Mavrogiannis"
                    },
                    {
                        "authorId": "1752197",
                        "name": "S. Srinivasa"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Moreover, some trajectory prediction models such as YNet [Mangalam et al., 2021] use convolutional decoders to generate heatmaps and encourage scenecompliant predictions.",
                "For example, TNT [Zhao et al., 2021] and DenseTNT [Gu et al., 2021] predict vehicles\u2019 endpoints by sampling positions on center lanes while YNet [Mangalam et al., 2021] and Goal-GAN [Dendorfer et al., 2020] directly predict an endpoint heatmap by integrating the observed trajectory and the scene\u2026",
                "\u2026social and physical features [Xue et al., 2018; Sadeghian et al., 2019; Dendorfer et al., 2021]; (2) a CNN-based encoding module on raster HD maps [Wang et al., 2020] or heatmaps [Mangalam et al., 2021]; or (3) a\ngraph neural network-based encoding module on vectorised HD maps [Gao et al., 2020].",
                ", 2021] predict vehicles\u2019 endpoints by sampling positions on center lanes while YNet [Mangalam et al., 2021] and Goal-GAN [Dendorfer et al.",
                ", 2020] or heatmaps [Mangalam et al., 2021]; or (3) a graph neural network-based encoding module on vectorised HD maps [Gao et al.",
                "\u20262019] firstly introduces KDE-NLL as one of the evaluation metrics in MTP, which computes the mean log-likelihood of the ground truth trajectory for each future timestep:\nKDE-NLL = \u2212Ei,t\u2208\u03c4 logP(Y ti |KDE(Y\u0302 ti,K)), (5) and is further used in subsequent studies such as [Mangalam et al., 2020, 2021].",
                "For example, TNT [Zhao et al., 2021] and DenseTNT [Gu et al., 2021] predict vehicles\u2019 endpoints by sampling positions on center lanes while YNet [Mangalam et al., 2021] and Goal-GAN [Dendorfer et al., 2020] directly predict an endpoint heatmap by integrating the observed trajectory and the scene segmentation image.",
                "Advanced Sampling Tricks TTST [Mangalam et al., 2021]; LDS [Ma et al.",
                "Moreover, the PEC framework can help the long-term prediction by conditioning on the endpoint and middle waypoints [Mangalam et al., 2021; Wang et al., 2022]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "003206a18e0cf57b9b653fb280d8ef011221af6c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-10463",
                    "ArXiv": "2302.10463",
                    "DOI": "10.48550/arXiv.2302.10463",
                    "CorpusId": 257050705
                },
                "corpusId": 257050705,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/003206a18e0cf57b9b653fb280d8ef011221af6c",
                "title": "Multimodal Trajectory Prediction: A Survey",
                "abstract": "Trajectory prediction is an important task to support safe and intelligent behaviours in autonomous systems. Many advanced approaches have been proposed over the years with improved spatial and temporal feature extraction. However, human behaviour is naturally multimodal and uncertain: given the past trajectory and surrounding environment information, an agent can have multiple plausible trajectories in the future. To tackle this problem, an essential task named multimodal trajectory prediction (MTP) has recently been studied, which aims to generate a diverse, acceptable and explainable distribution of future predictions for each agent. In this paper, we present the first survey for MTP with our unique taxonomies and comprehensive analysis of frameworks, datasets and evaluation metrics. In addition, we discuss multiple future directions that can help researchers develop novel multimodal trajectory prediction systems.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2052101365",
                        "name": "Renhao Huang"
                    },
                    {
                        "authorId": "1560895396",
                        "name": "Hao Xue"
                    },
                    {
                        "authorId": "1783801",
                        "name": "M. Pagnucco"
                    },
                    {
                        "authorId": "144954586",
                        "name": "Flora D. Salim"
                    },
                    {
                        "authorId": "2157995570",
                        "name": "Yang Song"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "high uncertainty behavior can be limited through the goal information [14].",
                "To circumvent this issue, we utilize a goal-estimation [14] module for estimating the goals in the inference time.",
                "is extracted from bird\u2019s-eye view RGB images to consider scene context, such as obstacles, pavement and terrain, using an off-the-shelf pre-trained semantic segmentation network [14].",
                "a goal-estimation module [14], [13] is applied.",
                "Y-net [14] combines scene information with goals and waypoints for",
                "Following the previous goal-conditioned trajectory prediction models [39], [11], [14], we evaluate all potential K goals against the ground truth and choose the one with the smallest L2 error as the estimated goal position in the test phase.",
                "Because multiple samples are required, the Test-Time-Sampling-Trick (TTST) proposed in [14] is used.",
                "We adopt the goal module proposed in [14], [13] for this purpose."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "ae67dcba7c3ef0fb995a6b68b09b031295c8a9e2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-07583",
                    "ArXiv": "2302.07583",
                    "DOI": "10.1109/IV55152.2023.10186643",
                    "CorpusId": 256868420
                },
                "corpusId": 256868420,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ae67dcba7c3ef0fb995a6b68b09b031295c8a9e2",
                "title": "ForceFormer: Exploring Social Force and Transformer for Pedestrian Trajectory Prediction",
                "abstract": "Predicting trajectories of pedestrians based on goal information in highly interactive scenes is a crucial step toward Intelligent Transportation Systems and Autonomous Driving. The challenges of this task come from two key sources: (1) complex social interactions in high pedestrian density scenarios and (2) limited utilization of goal information to effectively associate with past motion information. To address these difficulties, we integrate social forces into a Transformer-based stochastic generative model backbone and propose a new goal-based trajectory predictor called ForceFormer. Differentiating from most prior works that simply use the destination position as an input feature, we leverage the driving force from the destination to efficiently simulate the guidance of a target on a pedestrian. Additionally, repulsive forces are used as another input feature to describe the avoidance action among neighboring pedestrians. Extensive experiments show that our proposed method achieves on-par performance measured by distance errors with the state-of-the-art models but evidently decreases collisions, especially in dense pedestrian scenarios on widely used pedestrian datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "50550291",
                        "name": "Wei-chao Zhang"
                    },
                    {
                        "authorId": "145242715",
                        "name": "Hao Cheng"
                    },
                    {
                        "authorId": "9453474",
                        "name": "F. T. Johora"
                    },
                    {
                        "authorId": "34946374",
                        "name": "Monika Sester"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Y-net [35] models the uncertainty of trajectories through"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3e5d6643cfbaa1e38b12b297f72066867e429fa6",
                "externalIds": {
                    "DBLP": "journals/ral/ZhouHSLH23",
                    "DOI": "10.1109/LRA.2022.3231531",
                    "CorpusId": 255267727
                },
                "corpusId": 255267727,
                "publicationVenue": {
                    "id": "93c335b7-edf4-45f5-8ddc-7c5835154945",
                    "name": "IEEE Robotics and Automation Letters",
                    "alternate_names": [
                        "IEEE Robot Autom Lett"
                    ],
                    "issn": "2377-3766",
                    "url": "https://www.ieee.org/membership-catalog/productdetail/showProductDetailPage.html?product=PER481-ELE",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=7083369"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3e5d6643cfbaa1e38b12b297f72066867e429fa6",
                "title": "Dynamic Attention-Based CVAE-GAN for Pedestrian Trajectory Prediction",
                "abstract": "Predicting pedestrian trajectories is crucial for human-interactive systems. This task is compounded by the inherently multimodal nature of human motions and complex external and internal factors such as social interactions and intentions. In this letter, we propose a dynamic attention-based CVAE-GAN method that simultaneously models time-varying social interactions and human intentions while generating multimodal trajectory predictions. Herein, CVAE is used to account for the multimodality of trajectories explicitly, and GAN is used for adversarial training. A spatio-temporal graph with dynamic attention is leveraged to encode pedestrian interactions, which are further fed into a recurrent neural network to capture the temporal dependencies of evolving patterns. Moreover, we aggregate all potential sub-goals from current position to the destination with another dynamic attention module to shape the predicted trajectories. Experiments on widely used ETH and UCY benchmarks will verify the effectiveness of the proposed method. In particular, the proposed method could outperform the state-of-the-art by approximately 10% in terms of prediction errors and 40% considering collision avoidance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2186729985",
                        "name": "Zhou Zhou"
                    },
                    {
                        "authorId": "2125119625",
                        "name": "Gang Huang"
                    },
                    {
                        "authorId": "2153420841",
                        "name": "Zhaoxin Su"
                    },
                    {
                        "authorId": "2135307244",
                        "name": "Yongfu Li"
                    },
                    {
                        "authorId": "2052830834",
                        "name": "Wei Hua"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "\u2022 Y-Net [29]: Takes into account a semantic map (UNet), trajectory heat maps and additional information of pedestrian\u2019s destinations and way points to predict future motion \u2022 P2T-IRL [31]:Utilized a reinforcement learning approach to learn a reward function from trajectories and output predicted trajectories conditioned on end goals.",
                "The current state-of-the-art methods\u2014Y-Net [29], PECNet [30], P2TI RL [31]\u2014use a two-stage modeling approach where first goals (destinations) are estimated and then trajectories are predicted conditioned on these final positions."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d5b9c9002092438b93596acc580730aff4042cd6",
                "externalIds": {
                    "DBLP": "journals/mva/SyedM23",
                    "PubMedCentral": "9870204",
                    "DOI": "10.1007/s00138-022-01357-z",
                    "CorpusId": 256214694,
                    "PubMed": "36712952"
                },
                "corpusId": 256214694,
                "publicationVenue": {
                    "id": "400d5e36-be35-4097-898f-753f4493156e",
                    "name": "Machine Vision and Applications",
                    "type": "journal",
                    "alternate_names": [
                        "Journal of Machine Vision and Applications",
                        "Mach Vis Appl",
                        "J Mach Vis Appl"
                    ],
                    "issn": "0932-8092",
                    "url": "https://www.springer.com/computer/image+processing/journal/138",
                    "alternate_urls": [
                        "https://link.springer.com/journal/138",
                        "https://www.springer.com/computer/image+processing/journal/138?changeHeader",
                        "http://www.springer.com/computer/image+processing/journal/138"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d5b9c9002092438b93596acc580730aff4042cd6",
                "title": "Semantic scene upgrades for trajectory prediction",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "8034411",
                        "name": "Arsal Syed"
                    },
                    {
                        "authorId": "1737830",
                        "name": "B. Morris"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Recent online goal inference approaches generally fall into two categories \u2013 (1) feedforward prediction that directly maps observed past trajectories to possible goals, typically enabled by goal prediction networks [27, 5, 20, 23, 8, 39, 38, 34, 22], or (2) generative approaches such as inverse planning [6, 28, 32, 3, 35, 40, 24, 33] and inverse reinforcement learning [1, 12, 15, 37]"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "65422006c040947afac35bb2fcf05d2b8f702827",
                "externalIds": {
                    "DBLP": "conf/icra/PuigSTT23",
                    "ArXiv": "2301.05223",
                    "DOI": "10.1109/ICRA48891.2023.10161352",
                    "CorpusId": 254587469
                },
                "corpusId": 254587469,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/65422006c040947afac35bb2fcf05d2b8f702827",
                "title": "NOPA: Neurally-guided Online Probabilistic Assistance for Building Socially Intelligent Home Assistants",
                "abstract": "In this work, we study how to build socially intelligent robots to assist people in their homes. In particular, we focus on assistance with online goal inference, where robots must simultaneously infer humans' goals and how to help them achieve those goals. Prior assistance methods either lack the adaptivity to adjust helping strategies (i.e., when and how to help) in response to uncertainty about goals or the scalability to conduct fast inference in a large goal space. Our NOPA (Neurally-guided Online Probabilistic Assistance) method addresses both of these challenges. NOPA consists of (1) an online goal inference module combining neural goal proposals with inverse planning and particle filtering for robust inference under uncertainty, and (2) a helping planner that discovers valuable subgoals to help with and is aware of the uncertainty in goal inference. We compare NOPA against multiple baselines in a new embodied AI assistance challenge: Online Watch-And-Help, in which a helper agent needs to simultaneously watch a main agent's action, infer its goal, and help perform a common household task faster in realistic virtual home environments. Experiments show that our helper agent robustly updates its goal inference and adapts its helping plans to the changing level of uncertainty.11Code and a supplementary video are available at https://www.tshu.io/online_watch_and_help.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "143872936",
                        "name": "Xavier Puig"
                    },
                    {
                        "authorId": "1844358",
                        "name": "Tianmin Shu"
                    },
                    {
                        "authorId": "1763295",
                        "name": "J. Tenenbaum"
                    },
                    {
                        "authorId": "143805211",
                        "name": "A. Torralba"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "In addition, an improved a trajectory prediction model named Y-Net was proposed in [18], this model can exploit the pro-posed epistemic & aleatoric structure for diverse trajectory predictions across long prediction horizons."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3018d0b74d46abbfc0be19fad4f00c7b63451df8",
                "externalIds": {
                    "DBLP": "conf/msn/WeiHZF22",
                    "DOI": "10.1109/MSN57253.2022.00106",
                    "CorpusId": 257808718
                },
                "corpusId": 257808718,
                "publicationVenue": {
                    "id": "72a6d50c-86ae-47c7-9a0e-54e5746aacee",
                    "name": "International Conference on Mobile Ad-hoc and Sensor Networks",
                    "type": "conference",
                    "alternate_names": [
                        "MSN",
                        "Mobile Ad-hoc and Sensor Networks",
                        "Int Conf Mob Ad-hoc Sens Netw",
                        "Mob Ad-hoc Sens Netw"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3018d0b74d46abbfc0be19fad4f00c7b63451df8",
                "title": "Real-time Simulation and Testing of a Neural Network-based Autonomous Vehicle Trajectory Prediction Model",
                "abstract": "Autonomous vehicle trajectory prediction is an important component of autonomous driving assistance algorithms (ADAAs), which can help autonomous driving systems (ADSs) better understand the traffic environment, assess critical tasks in advance thus improve traffic safety and traffic efficiency. However, some existing neural network-based trajectory prediction models focus on theoretical numerical analysis and are not tested in real time, leading to doubts about the practical usability of these trajectory prediction models. To address the above limitations, this study first proposes a collaborative simulation environment integrating traffic scenario construction, driving environment perception, and neural network modeling, afterwards used the co-simulation environment for trajectory data and driving environment data collection. In addition, based on the characteristics of the collected data, a trajectory prediction model based on Bi-Encoder-Decoder and deep neural network (DNN) is proposed and pre-trained. Finally, the pre-trained completed model is embedded in the co-simulation environment and tested in real-time with different batches of data. The simulation results show that the proposed trajectory prediction model can predict trajectories well under specific training data batches, and the best performing trajectory prediction model has a prospective time of 4.9 s and a prediction accuracy of 91.55%.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2143999947",
                        "name": "Cheng Wei"
                    },
                    {
                        "authorId": "47806584",
                        "name": "F. Hui"
                    },
                    {
                        "authorId": "2031134",
                        "name": "Xiangmo Zhao"
                    },
                    {
                        "authorId": "2111805073",
                        "name": "Shan Fang"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "487cadf93a8cfe959bcc6f7a3f586f5e4f898066",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-11220",
                    "ArXiv": "2211.11220",
                    "DOI": "10.1109/TNNLS.2023.3294998",
                    "CorpusId": 253735000,
                    "PubMed": "37494176"
                },
                "corpusId": 253735000,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/487cadf93a8cfe959bcc6f7a3f586f5e4f898066",
                "title": "STGlow: A Flow-based Generative Framework with Dual Graphormer for Pedestrian Trajectory Prediction",
                "abstract": "The pedestrian trajectory prediction task is an essential component of intelligent systems. Its applications include but are not limited to autonomous driving, robot navigation, and anomaly detection of monitoring systems. Due to the diversity of motion behaviors and the complex social interactions among pedestrians, accurately forecasting their future trajectory is challenging. Existing approaches commonly adopt generative adversarial networks (GANs) or conditional variational autoencoders (CVAEs) to generate diverse trajectories. However, GAN-based methods do not directly model data in a latent space, which may make them fail to have full support over the underlying data distribution. CVAE-based methods optimize a lower bound on the log-likelihood of observations, which may cause the learned distribution to deviate from the underlying distribution. The above limitations make existing approaches often generate highly biased or inaccurate trajectories. In this article, we propose a novel generative flow-based framework with a dual-graphormer for pedestrian trajectory prediction (STGlow). Different from previous approaches, our method can more precisely model the underlying data distribution by optimizing the exact log-likelihood of motion behaviors. Besides, our method has clear physical meanings for simulating the evolution of human motion behaviors. The forward process of the flow gradually degrades complex motion behavior into simple behavior, while its reverse process represents the evolution of simple behavior into complex motion behavior. Furthermore, we introduce a dual-graphormer combined with the graph structure to more adequately model the temporal dependencies and the mutual spatial interactions. Experimental results on several benchmarks demonstrate that our method achieves much better performance compared to previous state-of-the-art approaches.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2030972031",
                        "name": "Rongqin Liang"
                    },
                    {
                        "authorId": "3259148",
                        "name": "Yuanman Li"
                    },
                    {
                        "authorId": "2125555913",
                        "name": "Jiantao Zhou"
                    },
                    {
                        "authorId": "2155382374",
                        "name": "Xia Li"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "394ed1b3c98419ab0f4f8371ba83ae198c127c5b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-08701",
                    "ArXiv": "2211.08701",
                    "DOI": "10.48550/arXiv.2211.08701",
                    "CorpusId": 253553693
                },
                "corpusId": 253553693,
                "publicationVenue": {
                    "id": "fbfbf10a-faa4-4d2a-85be-3ac660454ce3",
                    "name": "Conference on Robot Learning",
                    "type": "conference",
                    "alternate_names": [
                        "CoRL",
                        "Conf Robot Learn"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/394ed1b3c98419ab0f4f8371ba83ae198c127c5b",
                "title": "Interpretable Self-Aware Neural Networks for Robust Trajectory Prediction",
                "abstract": "Although neural networks have seen tremendous success as predictive models in a variety of domains, they can be overly confident in their predictions on out-of-distribution (OOD) data. To be viable for safety-critical applications, like autonomous vehicles, neural networks must accurately estimate their epistemic or model uncertainty, achieving a level of system self-awareness. Techniques for epistemic uncertainty quantification often require OOD data during training or multiple neural network forward passes during inference. These approaches may not be suitable for real-time performance on high-dimensional inputs. Furthermore, existing methods lack interpretability of the estimated uncertainty, which limits their usefulness both to engineers for further system development and to downstream modules in the autonomy stack. We propose the use of evidential deep learning to estimate the epistemic uncertainty over a low-dimensional, interpretable latent space in a trajectory prediction setting. We introduce an interpretable paradigm for trajectory prediction that distributes the uncertainty among the semantic concepts: past agent behavior, road structure, and social context. We validate our approach on real-world autonomous driving data, demonstrating superior performance over state-of-the-art baselines. Our code is available at: https://github.com/sisl/InterpretableSelfAwarePrediction.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "30112153",
                        "name": "Masha Itkina"
                    },
                    {
                        "authorId": "79262652",
                        "name": "Mykel J. Kochenderfer"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "We empirically demonstrate the efficiency of MoSA on the state-of-the-art model Y-Net [2] on the heterogenous SDD [14] and inD [15] datasets in various style transfer setups.",
                "Owing to the success of deep neural networks on large-scale datasets, learning prediction models in a data-driven manner has become a de-facto approach for motion forecasting and has shown impressive results [1, 2, 3, 4]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f258807dd9e9d7ab26bba8d821780a6ea399a089",
                "externalIds": {
                    "DBLP": "conf/corl/KothariLLA22",
                    "ArXiv": "2211.03165",
                    "DOI": "10.48550/arXiv.2211.03165",
                    "CorpusId": 253384604
                },
                "corpusId": 253384604,
                "publicationVenue": {
                    "id": "fbfbf10a-faa4-4d2a-85be-3ac660454ce3",
                    "name": "Conference on Robot Learning",
                    "type": "conference",
                    "alternate_names": [
                        "CoRL",
                        "Conf Robot Learn"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f258807dd9e9d7ab26bba8d821780a6ea399a089",
                "title": "Motion Style Transfer: Modular Low-Rank Adaptation for Deep Motion Forecasting",
                "abstract": "Deep motion forecasting models have achieved great success when trained on a massive amount of data. Yet, they often perform poorly when training data is limited. To address this challenge, we propose a transfer learning approach for efficiently adapting pre-trained forecasting models to new domains, such as unseen agent types and scene contexts. Unlike the conventional fine-tuning approach that updates the whole encoder, our main idea is to reduce the amount of tunable parameters that can precisely account for the target domain-specific motion style. To this end, we introduce two components that exploit our prior knowledge of motion style shifts: (i) a low-rank motion style adapter that projects and adjusts the style features at a low-dimensional bottleneck; and (ii) a modular adapter strategy that disentangles the features of scene context and motion history to facilitate a fine-grained choice of adaptation layers. Through extensive experimentation, we show that our proposed adapter design, coined MoSA, outperforms prior methods on several forecasting benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "81029804",
                        "name": "Parth Kothari"
                    },
                    {
                        "authorId": "2187698193",
                        "name": "Danyang Li"
                    },
                    {
                        "authorId": "14772333",
                        "name": "Yuejiang Liu"
                    },
                    {
                        "authorId": "3304525",
                        "name": "Alexandre Alahi"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [
                "]\nDecision Trajectory Prediction NSP-SFM[101], Y-Net[102],Trajectron++[103],Social\nGAN[104],SoPhie[105] Motion Forecasting VI LaneIter[106], Wayformer[107]\nDeep Reinforcement Learning Deep Q-Learning[108]),Deep recurrent q-learning[49],Deep attention recurrent\nQ-network[50],Double Q-learning[109],A3C/A2C[51] Imitation Learning Generative adversarial imitation learning[110],\nConditional Imitation Learning[46, 111], Self-Imitation Learning[112], Chauffeurnet[47]\nV2X Federated Learning FedAvg[113]\nto be misled.",
                "Decision Trajectory Prediction NSP-SFM[101], Y-Net[102],Trajectron++[103],Social"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1ce19d8c5778a1dc938306ce69d74631d824f174",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-11237",
                    "ArXiv": "2210.11237",
                    "DOI": "10.48550/arXiv.2210.11237",
                    "CorpusId": 253018467
                },
                "corpusId": 253018467,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1ce19d8c5778a1dc938306ce69d74631d824f174",
                "title": "Emerging Threats in Deep Learning-Based Autonomous Driving: A Comprehensive Survey",
                "abstract": "Since the 2004 DARPA Grand Challenge, the autonomous driving technology has witnessed nearly two decades of rapid development. Particularly, in recent years, with the application of new sensors and deep learning technologies extending to the autonomous field, the development of autonomous driving technology has continued to make breakthroughs. Thus, many carmakers and high-tech giants dedicated to research and system development of autonomous driving. However, as the foundation of autonomous driving, the deep learning technology faces many new security risks. The academic community has proposed deep learning countermeasures against the adversarial examples and AI backdoor, and has introduced them into the autonomous driving field for verification. Deep learning security matters to autonomous driving system security, and then matters to personal safety, which is an issue that deserves attention and research.This paper provides an summary of the concepts, developments and recent research in deep learning security technologies in autonomous driving. Firstly, we briefly introduce the deep learning framework and pipeline in the autonomous driving system, which mainly include the deep learning technologies and algorithms commonly used in this field. Moreover, we focus on the potential security threats of the deep learning based autonomous driving system in each functional layer in turn. We reviews the development of deep learning attack technologies to autonomous driving, investigates the State-of-the-Art algorithms, and reveals the potential risks. At last, we provides an outlook on deep learning security in the autonomous driving field and proposes recommendations for building a safe and trustworthy autonomous driving system.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2162920565",
                        "name": "Huiyun Cao"
                    },
                    {
                        "authorId": "2188348119",
                        "name": "Wenlong Zou"
                    },
                    {
                        "authorId": "2188351261",
                        "name": "Yinkun Wang"
                    },
                    {
                        "authorId": "2188345846",
                        "name": "Ting Song"
                    },
                    {
                        "authorId": null,
                        "name": "Mengjun Liu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Following [19], we use past 8 frames to predict future 12 frames.",
                "Most attempts [16, 19, 27, 35] explore only individual-surroundings interaction, where tremendous efforts are spent on modeling the individual trajectory, the semantic information of environment information, and the relationship between them.",
                "On ETH/UCY datasets, we compare our model with the state-of-the-art methods: SS-LSTM [35], Social-STGCN [22], MANTRA [20], AgentFormer [37], YNet [19].",
                "Following the existing works [1, 19, 20, 35], we calculate the mean squared error (MSE) between the predicted trajectory and the ground-truth trajectory on ETH/UCY datasets: Ltra = 1 Tfut \u2211Tfut t=1 \u2016y p \u2212 \u0177 p\u2016(2)2.",
                "performance compared with previous HTP methods: SS-LSTM [35], Social-STGCN [22], Next [16], MANTRA [20], YNet [19].",
                "Human trajectory prediction (HTP) aims to predict a target person\u2019s future path from a video clip [5, 9, 19, 20]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "6c468d3c6720feeaa12ae70c7e6f625f6e3a90f8",
                "externalIds": {
                    "DBLP": "conf/nips/MengWCCZYS22",
                    "ArXiv": "2210.08732",
                    "DOI": "10.48550/arXiv.2210.08732",
                    "CorpusId": 252918497
                },
                "corpusId": 252918497,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/6c468d3c6720feeaa12ae70c7e6f625f6e3a90f8",
                "title": "Forecasting Human Trajectory from Scene History",
                "abstract": "Predicting the future trajectory of a person remains a challenging problem, due to randomness and subjectivity of human movement. However, the moving patterns of human in a constrained scenario typically conform to a limited number of regularities to a certain extent, because of the scenario restrictions and person-person or person-object interactivity. Thus, an individual person in this scenario should follow one of the regularities as well. In other words, a person's subsequent trajectory has likely been traveled by others. Based on this hypothesis, we propose to forecast a person's future trajectory by learning from the implicit scene regularities. We call the regularities, inherently derived from the past dynamics of the people and the environment in the scene, scene history. We categorize scene history information into two types: historical group trajectory and individual-surroundings interaction. To exploit these two types of information for trajectory prediction, we propose a novel framework Scene History Excavating Network (SHENet), where the scene history is leveraged in a simple yet effective approach. In particular, we design two components: the group trajectory bank module to extract representative group trajectories as the candidate for future path, and the cross-modal interaction module to model the interaction between individual past trajectory and its surroundings for trajectory refinement. In addition, to mitigate the uncertainty in ground-truth trajectory, caused by the aforementioned randomness and subjectivity of human movement, we propose to include smoothness into the training process and evaluation metrics. We conduct extensive evaluations to validate the efficacy of our proposed framework on ETH, UCY, as well as a new, challenging benchmark dataset PAV, demonstrating superior performance compared to state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2163626812",
                        "name": "Mancheng Meng"
                    },
                    {
                        "authorId": "2109685046",
                        "name": "Ziyan Wu"
                    },
                    {
                        "authorId": "1846624",
                        "name": "Terrence Chen"
                    },
                    {
                        "authorId": "2109921",
                        "name": "Xiran Cai"
                    },
                    {
                        "authorId": "40403107",
                        "name": "X. Zhou"
                    },
                    {
                        "authorId": "2158030450",
                        "name": "Fan Yang"
                    },
                    {
                        "authorId": "2112477074",
                        "name": "Dinggang Shen"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [
                "[27,26] use goal-based methods that propose possible endpoints for each pedestrians and then generate multiple trajectories based on these endpoints.",
                "the effectiveness of different interaction modeling, goal-based methods [27,26] are not included in this comparison."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4936f9a1385a5585ed385b5e58c4a0c48ecaceaa",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-08793",
                    "ArXiv": "2210.08793",
                    "DOI": "10.48550/arXiv.2210.08793",
                    "CorpusId": 252918205
                },
                "corpusId": 252918205,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4936f9a1385a5585ed385b5e58c4a0c48ecaceaa",
                "title": "Rethinking Trajectory Prediction via \"Team Game\"",
                "abstract": "To accurately predict trajectories in multi-agent settings, e.g. team games, it is important to effectively model the interactions among agents. Whereas a number of methods have been developed for this purpose, existing methods implicitly model these interactions as part of the deep net architecture. However, in the real world, interactions often exist at multiple levels, e.g. individuals may form groups, where interactions among groups and those among the individuals in the same group often follow significantly different patterns. In this paper, we present a novel formulation for multi-agent trajectory prediction, which explicitly introduces the concept of interactive group consensus via an interactive hierarchical latent space. This formulation allows group-level and individual-level interactions to be captured jointly, thus substantially improving the capability of modeling complex dynamics. On two multi-agent settings, i.e. team sports and pedestrians, the proposed framework consistently achieves superior performance compared to existing methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115491440",
                        "name": "Zikai Wei"
                    },
                    {
                        "authorId": "22689408",
                        "name": "Xinge Zhu"
                    },
                    {
                        "authorId": "144445937",
                        "name": "Bo Dai"
                    },
                    {
                        "authorId": "1807606",
                        "name": "Dahua Lin"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Most of them only focus on multi-future path prediction [43, 63, 70, 73] (k=5, 8, 15, 20, .",
                "Most works in this context predict multiple future trajectories and choose the best to assess their accuracy and performance [43, 63, 70]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "27a1d1e0ad6bd3f9a332c66ec317044623262f52",
                "externalIds": {
                    "ArXiv": "2210.08057",
                    "DBLP": "conf/iccps/NoghreKPNT23a",
                    "DOI": "10.1145/3576841.3589619",
                    "CorpusId": 254564013
                },
                "corpusId": 254564013,
                "publicationVenue": {
                    "id": "7e4ed95a-56b0-4c31-9460-2cee8bf99394",
                    "name": "International Conference on Cyber-Physical Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Cyber-physical Syst",
                        "International Conference Ceramic Processing Science",
                        "ICCPS",
                        "Int Conf Ceram Process Sci"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1319"
                },
                "url": "https://www.semanticscholar.org/paper/27a1d1e0ad6bd3f9a332c66ec317044623262f52",
                "title": "Demonstration of Pishgu: Universal Path Prediction Network Architecture for Real-time Cyber-physical Edge Systems",
                "abstract": "Pishgu is a universal lightweight network architecture for path prediction in Cyber-Physical Systems (CPS) applications, adaptable to multiple subjects, perspectives, and scenes. Our proposed architecture captures inter-dependencies within the subjects in each frame using Graph Isomorphism Networks and attention. In our demonstration, we will show how Pishgu can predict trajectories for pedestrians and vehicles in different real-world scenarios. We will use video data from various sources, such as surveillance cameras, drones, etc., to illustrate the diversity of subjects, perspectives, and scenes that Pishgu can handle. The goal of our demonstration is to showcase the adaptability and robustness of Pishgu in various CPS applications. We will highlight how Pishgu can capture inter-dependencies within the subjects in each frame using Graph Isomorphism Networks (GINs) and attention mechanisms. We will also compare Pishgu with existing solutions on different metrics such as ADE and FDE. We hope that our demonstration will inspire attendees to explore new possibilities for path prediction in CPS applications using Pishgu. In addition, The demonstration will also consist of a poster to highlight the main features of Pishgu and the improvements achieved over the recent trajectory prediction methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2152021044",
                        "name": "Ghazal Alinezhad Noghre"
                    },
                    {
                        "authorId": "79354862",
                        "name": "Vinit Katariya"
                    },
                    {
                        "authorId": "2152020939",
                        "name": "Armin Danesh Pazho"
                    },
                    {
                        "authorId": "2059566339",
                        "name": "Christopher Neff"
                    },
                    {
                        "authorId": "1808141",
                        "name": "H. Tabkhi"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Recent efforts have been explicitly focusing on conditioning forecasting on estimated pedestrian goal/intent [14, 43, 42] and estimating multimodal posterior distributions [38, 13] that yield diverse trajectories that cover different plausible directions."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3c6a8e5aa6296b0f29cd2b50b67d0f01943711d7",
                "externalIds": {
                    "ArXiv": "2210.07681",
                    "DBLP": "conf/nips/DendorferYOL22",
                    "DOI": "10.48550/arXiv.2210.07681",
                    "CorpusId": 252907600
                },
                "corpusId": 252907600,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/3c6a8e5aa6296b0f29cd2b50b67d0f01943711d7",
                "title": "Quo Vadis: Is Trajectory Forecasting the Key Towards Long-Term Multi-Object Tracking?",
                "abstract": "Recent developments in monocular multi-object tracking have been very successful in tracking visible objects and bridging short occlusion gaps, mainly relying on data-driven appearance models. While we have significantly advanced short-term tracking performance, bridging longer occlusion gaps remains elusive: state-of-the-art object trackers only bridge less than 10% of occlusions longer than three seconds. We suggest that the missing key is reasoning about future trajectories over a longer time horizon. Intuitively, the longer the occlusion gap, the larger the search space for possible associations. In this paper, we show that even a small yet diverse set of trajectory predictions for moving agents will significantly reduce this search space and thus improve long-term tracking robustness. Our experiments suggest that the crucial components of our approach are reasoning in a bird's-eye view space and generating a small yet diverse set of forecasts while accounting for their localization uncertainty. This way, we can advance state-of-the-art trackers on the MOTChallenge dataset and significantly improve their long-term tracking performance. This paper's source code and experimental data are available at https://github.com/dendorferpatrick/QuoVadis.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1416750021",
                        "name": "Patrick Dendorfer"
                    },
                    {
                        "authorId": "2133128386",
                        "name": "V. Yugay"
                    },
                    {
                        "authorId": "3331304",
                        "name": "Aljosa Osep"
                    },
                    {
                        "authorId": "2186405350",
                        "name": "Laura Leal-Taix'e"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "There has also been recent interest in human motion forecasting [26, 34], which focuses on predicting human movement trajectories from a distant, top-down perspective."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "425b428b9804afb42fc07f810393170241be6a29",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-04366",
                    "ArXiv": "2210.04366",
                    "DOI": "10.48550/arXiv.2210.04366",
                    "CorpusId": 252780514
                },
                "corpusId": 252780514,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/425b428b9804afb42fc07f810393170241be6a29",
                "title": "Computational Choreography using Human Motion Synthesis",
                "abstract": "Should deep learning models be trained to analyze human performance art? To help answer this question, we explore an application of deep neural networks to synthesize artistic human motion. Problem tasks in human motion synthesis can include predicting the motions of humans in-the-wild, as well as generating new sequences of motions based on said predictions. We will discuss the potential of a less traditional application, where learning models are applied to predicting dance movements. There have been notable, recent efforts to analyze dance movements in a computational light, such as the Everybody Dance Now (EDN) learning model and a Cal Poly master's thesis, Take The Lead (TTL). We have effectively combined these two works along with our own deep neural network to produce a new system for dance motion prediction, image-to-image translation, and video generation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2187298790",
                        "name": "Patrick Perrine"
                    },
                    {
                        "authorId": "2187300134",
                        "name": "Trevor Kirkby"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "In [13], the map information is used to generate diverse goals and middle waypoints through Unet architecture."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "33031c292fc1102372a105b3e096c06fdf98ff6d",
                "externalIds": {
                    "DBLP": "conf/itsc/ChenZSZSZ22",
                    "DOI": "10.1109/ITSC55140.2022.9922118",
                    "CorpusId": 253250449
                },
                "corpusId": 253250449,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/33031c292fc1102372a105b3e096c06fdf98ff6d",
                "title": "Multiple Goals Network for Pedestrian Trajectory Prediction in Autonomous Driving",
                "abstract": "As the most vulnerable traffic participants, pedestrians have always received considerable attention from autonomous driving. However, predicting the future behavior of pedestrians is challenging due to the intentions of pedestrian are potentially stochastic and difficult to be captured accurately through only a single trajectory. In order to solve these problems, we propose a multiple goals network (MGNet) for pedestrian trajectory prediction to generate a set of plausible trajectories in the crowds. The multimodality is achieved by sampling various goals from the parametric distribution which can sufficiently represent the stochastic intentions of pedestrian. The parametric distribution is obtained from the observations by a simple and effective multilayer perceptrons module. Finally, the whole future trajectories are generated by a Transformer-based encoder-decoder module with a new goal-visible masking mechanism. Experimental results on the most widely used datasets, i.e., the ETH-UCY datasets, demonstrate that MGNet is capable of achieving competitive performance compared with state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2283009",
                        "name": "Wei Chen"
                    },
                    {
                        "authorId": "2146483745",
                        "name": "Fang Zheng"
                    },
                    {
                        "authorId": "2153002505",
                        "name": "Liushuai Shi"
                    },
                    {
                        "authorId": "2116513096",
                        "name": "Yongdong Zhu"
                    },
                    {
                        "authorId": "47217841",
                        "name": "Hongbin Sun"
                    },
                    {
                        "authorId": "145608731",
                        "name": "Nanning Zheng"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Large improvements in trajectory forecasting came with endpoint-conditioned models, which try to estimate the final goal of the moving agent and then its trajectory [37,36]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2e9e2929cf21f229aa3fab8e14337e7445d51995",
                "externalIds": {
                    "ArXiv": "2209.11770",
                    "DBLP": "journals/corr/abs-2209-11770",
                    "DOI": "10.48550/arXiv.2209.11770",
                    "CorpusId": 252531949
                },
                "corpusId": 252531949,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2e9e2929cf21f229aa3fab8e14337e7445d51995",
                "title": "Toward Smart Doors: A Position Paper",
                "abstract": "Conventional automatic doors cannot distinguish between people wishing to pass through the door and people passing by the door, so they often open unnecessarily. This leads to the need to adopt new systems in both commercial and non-commercial environments: smart doors. In particular, a smart door system predicts the intention of people near the door based on the social context of the surrounding environment and then makes rational decisions about whether or not to open the door. This work proposes the first position paper related to smart doors, without bells and whistles. We first point out that the problem not only concerns reliability, climate control, safety, and mode of operation. Indeed, a system to predict the intention of people near the door also involves a deeper understanding of the social context of the scene through a complex combined analysis of proxemics and scene reasoning. Furthermore, we conduct an exhaustive literature review about automatic doors, providing a novel system formulation. Also, we present an analysis of the possible future application of smart doors, a description of the ethical shortcomings, and legislative issues.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2135267479",
                        "name": "Luigi Capogrosso"
                    },
                    {
                        "authorId": "2127600715",
                        "name": "Geri Skenderi"
                    },
                    {
                        "authorId": "2186115407",
                        "name": "Federico Girella"
                    },
                    {
                        "authorId": "1684932",
                        "name": "F. Fummi"
                    },
                    {
                        "authorId": "1723008",
                        "name": "M. Cristani"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Several works also leverage top-down images explicitly, whether in an RGB form or with added semantic segmentation [5], [28], [29]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "592c5d96384f03127ad812025f36c752203bef83",
                "externalIds": {
                    "ArXiv": "2209.11294",
                    "CorpusId": 257279754
                },
                "corpusId": 257279754,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/592c5d96384f03127ad812025f36c752203bef83",
                "title": "T2FPV: Dataset and Method for Correcting First-Person View Errors in Pedestrian Trajectory Prediction",
                "abstract": "Predicting pedestrian motion is essential for developing socially-aware robots that interact in a crowded environment. While the natural visual perspective for a social interaction setting is an egocentric view, the majority of existing work in trajectory prediction therein has been investigated purely in the top-down trajectory space. To support first-person view trajectory prediction research, we present T2FPV, a method for constructing high-fidelity first-person view (FPV) datasets given a real-world, top-down trajectory dataset; we showcase our approach on the ETH/UCY pedestrian dataset to generate the egocentric visual data of all interacting pedestrians, creating the T2FPV-ETH dataset. In this setting, FPV-specific errors arise due to imperfect detection and tracking, occlusions, and field-of-view (FOV) limitations of the camera. To address these errors, we propose CoFE, a module that further refines the imputation of missing data in an end-to-end manner with trajectory forecasting algorithms. Our method reduces the impact of such FPV errors on downstream prediction performance, decreasing displacement error by more than 10% on average. To facilitate research engagement, we release our T2FPV-ETH dataset and software tools.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2037889761",
                        "name": "Ben Stoler"
                    },
                    {
                        "authorId": "1470729020",
                        "name": "Meghdeep Jana"
                    },
                    {
                        "authorId": "2806202",
                        "name": "Soonmin Hwang"
                    },
                    {
                        "authorId": "143904954",
                        "name": "Jean Oh"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7fcd8bdd6fb1d8738b351b4fa90c526cb98a96d7",
                "externalIds": {
                    "DBLP": "journals/pr/ZhouRYFH23",
                    "DOI": "10.1016/j.patcog.2022.109030",
                    "CorpusId": 252133272
                },
                "corpusId": 252133272,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7fcd8bdd6fb1d8738b351b4fa90c526cb98a96d7",
                "title": "CSR: Cascade Conditional Variational Auto Encoder with Socially-aware Regression for Pedestrian Trajectory Prediction",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2111825091",
                        "name": "Hao Zhou"
                    },
                    {
                        "authorId": "2983017",
                        "name": "Dongchun Ren"
                    },
                    {
                        "authorId": "2184563494",
                        "name": "Xu Yang"
                    },
                    {
                        "authorId": "7821599",
                        "name": "Mingyu Fan"
                    },
                    {
                        "authorId": "2184559481",
                        "name": "Hai Huang"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "For pose sequence generation, previous methods either condition on the beginning of a sequence of pose [46], [47], [48], [49] or on some predefined labels like human actions [50], [51], [52]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b550ac280abfe57ae7adb636394d387c9907dbcc",
                "externalIds": {
                    "DBLP": "journals/pami/BaradelBGWKR23",
                    "ArXiv": "2208.10211",
                    "DOI": "10.1109/TPAMI.2022.3216899",
                    "CorpusId": 251719562,
                    "PubMed": "37015699"
                },
                "corpusId": 251719562,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b550ac280abfe57ae7adb636394d387c9907dbcc",
                "title": "PoseBERT: A Generic Transformer Module for Temporal 3D Human Modeling",
                "abstract": "Training state-of-the-art models for human pose estimation in videos requires datasets with annotations that are really hard and expensive to obtain. Although transformers have been recently utilized for body pose sequence modeling, related methods rely on pseudo-ground truth to augment the currently limited training data available for learning such models. In this paper, we introduce PoseBERT, a transformer module that is fully trained on 3D Motion Capture (MoCap) data via masked modeling. It is simple, generic and versatile, as it can be plugged on top of any image-based model to transform it in a video-based model leveraging temporal information. We showcase variants of PoseBERT with different inputs varying from 3D skeleton keypoints to rotations of a 3D parametric model for either the full body (SMPL) or just the hands (MANO). Since PoseBERT training is task agnostic, the model can be applied to several tasks such as pose refinement, future pose prediction or motion completion without finetuning. Our experimental results validate that adding PoseBERT on top of various state-of-the-art pose estimation methods consistently improves their performances, while its low computational cost allows us to use it in a real-time demo for smoothly animating a robotic hand via a webcam. Test code and models are available at https://github.com/naver/posebert.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "9943923",
                        "name": "Fabien Baradel"
                    },
                    {
                        "authorId": "2066273005",
                        "name": "Romain Br'egier"
                    },
                    {
                        "authorId": "2255827641",
                        "name": "Thibault Groueix"
                    },
                    {
                        "authorId": "2492127",
                        "name": "Philippe Weinzaepfel"
                    },
                    {
                        "authorId": "1944225",
                        "name": "Yannis Kalantidis"
                    },
                    {
                        "authorId": "3321919",
                        "name": "Gr\u00e9gory Rogez"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "In [16], a multimodal trajectory forecasting approach based on semantic segmentation networks is introduced, where two semantic segmentation networks are used to predict the waypoints first and the trajectory accordingly."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a54f6be5c343a179ae5157fcc164ba1a71496b43",
                "externalIds": {
                    "DBLP": "conf/case/ZhangDKA22",
                    "DOI": "10.1109/CASE49997.2022.9926544",
                    "CorpusId": 253186287
                },
                "corpusId": 253186287,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a54f6be5c343a179ae5157fcc164ba1a71496b43",
                "title": "Multimodal Motion Prediction Based on Adaptive and Swarm Sampling Loss Functions for Reactive Mobile Robots",
                "abstract": "Making accurate predictions about the dynamic environment is crucial for the trajectory planning of mobile robots. Predictions are by nature uncertain, and for motion prediction multiple futures are possible for the same historic behavior. In this work, the objective is to predict possible future positions of the target object for the collision avoidance purpose for mobile robots by considering different uncertainty by combining a sampling-based idea with data-driven methods. More specifically, we propose a major improvement on a loss function for multiple hypotheses and test it with convolutional neural networks on motion prediction problems. We implement post-processing heuristics that produce multiple Gaussian distribution estimations, and show that the result is suitable for trajectory planning for mobile robots. The method is also evaluated with the Stanford Drone Dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118689678",
                        "name": "Ze Zhang"
                    },
                    {
                        "authorId": "38137167",
                        "name": "Emmanuel Dean"
                    },
                    {
                        "authorId": "1778250",
                        "name": "Y. Karayiannidis"
                    },
                    {
                        "authorId": "1708969",
                        "name": "K. \u00c5kesson"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Since our goal sampling network and Fenv need to work in the pixel space, we project the world coordinates in ETH/UCY into the pixel space using the homography matrices provided in Y-net [37].",
                "We compare our NSP-SFM with an extensive list of baselines, including published papers and unpublished technical reports: Social GAN (S-GAN) [18], Sophie [49], Conditional Flow VAE (CF-VAE) [9], Conditional Generative Neural System (CGNS) [29], NEXT [33], P2TIRL [14], SimAug [31], PECNet [38], Traj++ [50], Multiverse [32], Y-Net [37], SIT [56], S-CSR [77], Social-DualCVAE [16] and CSCNet [71].",
                "Finally, for SDD and ETH/UCY, we follow previous work [37,48] to segment trajectories into 20-frame samples and split the dataset for training/testing.",
                "We demonstrate that our NSP model outperforms the state-of-the-art methods [18,49,9,29,33,14,31,38,50,32,37,56,77,16,71] in standard trajectory prediction tasks across various benchmark datasets [46,43,28] and metrics.",
                "More recently, model-free methods based on deep learning have also been explored, and these demonstrate surprising trajectory prediction capability [1,18,49,9,29,33,14,31,38,50,32,37,56,77,16,71].",
                "The GSN is similar to a part of Y-net [37] and pre-trained, and detailed in the supplementary materials.",
                "Following previous research [37,38], we adopt the standard leave-one-out evaluation protocol, where the model is trained on four sub-datasets and evaluated one.",
                "Average Displacement Error (ADE) and Final Displacement Error (FDE) are employed as previous research [1,18,38,37]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "a4e3dd8af9fe7982b5599ce32e96371b15a3aa43",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-10435",
                    "ArXiv": "2207.10435",
                    "DOI": "10.48550/arXiv.2207.10435",
                    "CorpusId": 250919939
                },
                "corpusId": 250919939,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/a4e3dd8af9fe7982b5599ce32e96371b15a3aa43",
                "title": "Human Trajectory Prediction via Neural Social Physics",
                "abstract": "Trajectory prediction has been widely pursued in many fields, and many model-based and model-free methods have been explored. The former include rule-based, geometric or optimization-based models, and the latter are mainly comprised of deep learning approaches. In this paper, we propose a new method combining both methodologies based on a new Neural Differential Equation model. Our new model (Neural Social Physics or NSP) is a deep neural network within which we use an explicit physics model with learnable parameters. The explicit physics model serves as a strong inductive bias in modeling pedestrian behaviors, while the rest of the network provides a strong data-fitting capability in terms of system parameter estimation and dynamics stochasticity modeling. We compare NSP with 15 recent deep learning methods on 6 datasets and improve the state-of-the-art performance by 5.56%-70%. Besides, we show that NSP has better generalizability in predicting plausible trajectories in drastically different scenarios where the density is 2-5 times as high as the testing data. Finally, we show that the physics model in NSP can provide plausible explanations for pedestrian behaviors, as opposed to black-box deep learning. Code is available: https://github.com/realcrane/Human-Trajectory-Prediction-via-Neural-Social-Physics.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2178356020",
                        "name": "Jiangbei Yue"
                    },
                    {
                        "authorId": "1699159",
                        "name": "Dinesh Manocha"
                    },
                    {
                        "authorId": "2149698569",
                        "name": "He Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "The first is termed epistemic, and seeks the goals of each agent or answers the question \u2018where are the agents going?\u2019 The second is called aleatoric and solves for the trajectory that will carry the agent to the calculated goal, answering the question \u2018how is this agent going to reach its goal?\u2019 Methods may do that explicitly [Girase et al., 2021; Mangalam et al., 2021; Pang et al., 2021] or implicitly [Gilles et al.",
                "Studies in neuroscience [Valentin et al., 2007] and computer vision [Gilles et al., 2021; Mangalam et al., 2021] suggest that humans are goal-directed agents.",
                "[Rasouli et al., 2021; Mangalam et al., 2021] use semantic segmentation to extract the visual features of different classes, then find the relationship between them using attention.",
                ", 2007] and computer vision [Gilles et al., 2021; Mangalam et al., 2021] suggest that humans are goal-directed agents.",
                "Methods may do that explicitly [Girase et al., 2021; Mangalam et al., 2021; Pang et al., 2021] or implicitly [Gilles et al., 2021], often conditioning the generated trajectories on the calculated goals."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "831b823b2bf4a536fbd4a396f62053b2123a1eaf",
                "externalIds": {
                    "DBLP": "conf/ijcai/TeetiKSBC22",
                    "DOI": "10.24963/ijcai.2022/785",
                    "CorpusId": 250635696
                },
                "corpusId": 250635696,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/831b823b2bf4a536fbd4a396f62053b2123a1eaf",
                "title": "Vision-based Intention and Trajectory Prediction in Autonomous Vehicles: A Survey",
                "abstract": "This survey targets intention and trajectory prediction in Autonomous Vehicles (AV), as AV companies compete to create dedicated prediction pipelines to avoid collisions. The survey starts with a formal definition of the prediction problem and highlights its challenges, to then critically compare the models proposed in the last 2-3 years in terms of how they overcome these challenges. Further, it lists the latest methodological and technical trends in the field and comments on the efficacy of different machine learning blocks in modelling various aspects of the prediction problem. It also summarises the popular datasets and metrics used to evaluate prediction models, before concluding with the possible research gaps and future directions.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2149408834",
                        "name": "Izzeddin Teeti"
                    },
                    {
                        "authorId": "2111182172",
                        "name": "Salman Khan"
                    },
                    {
                        "authorId": "2643302",
                        "name": "Ajmal Shahbaz"
                    },
                    {
                        "authorId": "144463467",
                        "name": "Andrew Bradley"
                    },
                    {
                        "authorId": "1754181",
                        "name": "Fabio Cuzzolin"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a4724c3322b424e2388abaa986cbc7681f78a0b3",
                "externalIds": {
                    "DBLP": "journals/ijon/KangFZZZ22",
                    "DOI": "10.1016/j.neucom.2022.06.115",
                    "CorpusId": 250269517
                },
                "corpusId": 250269517,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a4724c3322b424e2388abaa986cbc7681f78a0b3",
                "title": "Learning to predict diverse trajectory from human motion patterns",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "39917719",
                        "name": "Miao Kang"
                    },
                    {
                        "authorId": "152315096",
                        "name": "Jingwen Fu"
                    },
                    {
                        "authorId": "3373601",
                        "name": "Sanping Zhou"
                    },
                    {
                        "authorId": "29677226",
                        "name": "Songyi Zhang"
                    },
                    {
                        "authorId": "2144620206",
                        "name": "Nanning Zheng"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "In the future, we intend to examine the integration of environmental features [21] into our Multiclass-SGCN model to further improve prediction accuracy."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "882074b79086f59ea0d40d9fbf1b12e43e18679d",
                "externalIds": {
                    "DBLP": "conf/icip/LiKS22",
                    "ArXiv": "2206.15275",
                    "DOI": "10.1109/ICIP46576.2022.9897644",
                    "CorpusId": 250144219
                },
                "corpusId": 250144219,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/882074b79086f59ea0d40d9fbf1b12e43e18679d",
                "title": "Multiclass-SGCN: Sparse Graph-Based Trajectory Prediction with Agent Class Embedding",
                "abstract": "Trajectory prediction of road users in real-world scenarios is challenging because their movement patterns are stochastic and complex. Previous pedestrian-oriented works have been successful in modelling the complex interactions among pedestrians, but fail in predicting trajectories when other types of road users are involved (e.g., cars, cyclists, etc.), because they ignore user types. Although a few recent works construct densely connected graphs with user label information, they suffer from superfluous spatial interactions and temporal dependencies. To address these issues, we propose Multiclass-SGCN, a sparse graph convolution network based approach for multi-class trajectory prediction that takes into consideration velocity and agent label information and uses a novel interaction mask to adaptively decide the spatial and temporal connections of agents based on their interaction scores. The proposed approach significantly outperformed state-of-the-art approaches on the Stanford Drone Dataset, providing more realistic and plausible trajectory predictions.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2112080094",
                        "name": "Ruochen Li"
                    },
                    {
                        "authorId": "2067851",
                        "name": "Stamos Katsigiannis"
                    },
                    {
                        "authorId": "2840036",
                        "name": "Hubert P. H. Shum"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "For example, [4, 23] are raised for long term trajectory prediction and achieve great performance."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5135c10a47ee362fa86b16a85f221c5d9bd11b32",
                "externalIds": {
                    "DBLP": "conf/cvpr/0003LCFLL22",
                    "DOI": "10.1109/CVPR52688.2022.00636",
                    "CorpusId": 250616026
                },
                "corpusId": 250616026,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5135c10a47ee362fa86b16a85f221c5d9bd11b32",
                "title": "Human Trajectory Prediction with Momentary Observation",
                "abstract": "Human trajectory prediction task aims to analyze human future movements given their past status, which is a crucial step for many autonomous systems such as self-driving cars and social robots. In real-world scenarios, it is unlikely to obtain sufficiently long observations at all times for prediction, considering inevitable factors such as tracking losses and sudden events. However, the problem of trajectory pre-diction with limited observations has not drawn much at-tention in previous work. In this paper, we study a task named momentary trajectory prediction, which reduces the observed history from a long time sequence to an extreme situation of two frames, one frame for social and scene contexts and both frames for the velocity of agents. We perform a rigorous study of existing state-of-the-art approaches in this challenging setting on two widely used benchmarks. We further propose a unified feature extractor, along with a novel pre-training mechanism, to capture effective infor-mation within the momentary observation. Our extractor can be adopted in existing prediction models and substan-tially boost their performance of momentary trajectory pre-diction. We hope our work will pave the way for more re-sponsive, precise and robust prediction approaches, an important step toward real-world autonomous systems.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2152148778",
                        "name": "Jianhua Sun"
                    },
                    {
                        "authorId": "2144435556",
                        "name": "Yuxuan Li"
                    },
                    {
                        "authorId": "2034068458",
                        "name": "Liangyu Chai"
                    },
                    {
                        "authorId": "122851212",
                        "name": "Haoshu Fang"
                    },
                    {
                        "authorId": "2110436501",
                        "name": "Yong-Lu Li"
                    },
                    {
                        "authorId": "1830034",
                        "name": "Cewu Lu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "62b169cc0995c3fe7045c9eeddb5703ee287382f",
                "externalIds": {
                    "DBLP": "conf/icra/AgandTLC22",
                    "DOI": "10.1109/icra46639.2022.9811883",
                    "CorpusId": 249651471
                },
                "corpusId": 249651471,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/62b169cc0995c3fe7045c9eeddb5703ee287382f",
                "title": "Human Navigational Intent Inference with Probabilistic and Optimal Approaches",
                "abstract": "Although human navigational intent inference has been studied in the literature, none have adequately considered both the dynamics that describe human motion and internal human parameters that may affect human navigational behaviour. In this paper, we propose a general probabilistic framework to infer the probability distribution over future navigational states of a human. Our framework incorporates an extended Dubins car dynamics to model human movement, which captures differences in human navigational behaviour depending on their position, heading, and movement speed. We assume a noisily rational model of human behaviour that incorporates a) human navigational intent that may change over time, b) how optimal a person's actions are given the navigational intent, and c) how far ahead in time a person considers when choosing navigational actions. These parameters are recursively and continuously updated in a Bayesian fashion. To make the Bayesian update and inference tractable, we exploit properties of the time-to-reach value function from optimal control and the extended Dubins car dynamics to construct a utility function on which the human policy is based, and employ particle representations of probability distributions where necessary. We demonstrate the effectiveness of our method by comparing our results with a recent approach using synthetic data and validate it on real world data.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "9336334",
                        "name": "Pedram Agand"
                    },
                    {
                        "authorId": "13952334",
                        "name": "Mahdi Taherahmadi"
                    },
                    {
                        "authorId": "46261444",
                        "name": "Angelica Lim"
                    },
                    {
                        "authorId": "2144423918",
                        "name": "Mo Chen"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c29d681d248872a0847dc597da5ee8c3a7e1f68e",
                "externalIds": {
                    "ArXiv": "2205.07310",
                    "DBLP": "journals/corr/abs-2205-07310",
                    "DOI": "10.48550/arXiv.2205.07310",
                    "CorpusId": 248811567
                },
                "corpusId": 248811567,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c29d681d248872a0847dc597da5ee8c3a7e1f68e",
                "title": "Uncertainty estimation for Cross-dataset performance in Trajectory prediction",
                "abstract": "While a lot of work has been carried on developing trajectory prediction methods, and various datasets have been proposed for benchmarking this task, little study has been done so far on the generalizability and the transferability of these methods across dataset. In this paper, we observe the performance of two of the latest state-of-the-art trajectory prediction methods across four different datasets (Argoverse, NuScenes, Interaction, Shifts). This analysis allows to gain some insights on the generalizability proprieties of most recent trajectory prediction models and to analyze which dataset is more representative of real driving scenes and therefore enables better transferability. Furthermore we present a novel method to estimate prediction uncertainty and show how it could be used to achieve better performance across datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "15023249",
                        "name": "Thomas Gilles"
                    },
                    {
                        "authorId": "2070460335",
                        "name": "S. Sabatini"
                    },
                    {
                        "authorId": "47102249",
                        "name": "D. Tsishkou"
                    },
                    {
                        "authorId": "2593406",
                        "name": "B. Stanciulescu"
                    },
                    {
                        "authorId": "1748488",
                        "name": "F. Moutarde"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Furthermore, for the goal module we use L = 5 down- and up-sampling blocks with number of channels (32, 32, 64, 64, 64) and (64, 64, 64, 32, 32) for the encoder and decoder, respectively, as in the standard implementation [25].",
                "[25] propose a convolutionalbased approach where positions are treated as heat-maps and final positions are sampled from 2D probability distribution maps.",
                "[25], slightly modifying its pre-processing steps and output format.",
                "[25], where 10, 000 goals are initially sampled and then clustered with K-means to obtain the 20 output modalities.",
                "Recent methods explicitly model this aspect in terms of goal prediction [9, 10, 25, 26, 46]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "eb4e042dfd21fcd080d80970c7247f68740b2bb7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-11561",
                    "ArXiv": "2204.11561",
                    "DOI": "10.1109/CVPRW56347.2022.00282",
                    "CorpusId": 248377731
                },
                "corpusId": 248377731,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/eb4e042dfd21fcd080d80970c7247f68740b2bb7",
                "title": "Goal-driven Self-Attentive Recurrent Networks for Trajectory Prediction",
                "abstract": "Human trajectory forecasting is a key component of autonomous vehicles, social-aware robots and advanced video-surveillance applications. This challenging task typically requires knowledge about past motion, the environment and likely destination areas. In this context, multi-modality is a fundamental aspect and its effective modeling can be beneficial to any architecture. Inferring accurate trajectories is nevertheless challenging, due to the inherently uncertain nature of the future. To overcome these difficulties, recent models use different inputs and propose to model human intentions using complex fusion mechanisms. In this respect, we propose a lightweight attention-based recurrent backbone that acts solely on past observed positions. Although this backbone already provides promising results, we demonstrate that its prediction accuracy can be improved considerably when combined with a scene-aware goal-estimation module. To this end, we employ a common goal module, based on a U-Net architecture, which additionally extracts semantic information to predict scene-compliant destinations. We conduct extensive experiments on publicly-available datasets (i.e. SDD, inD, ETH/UCY) and show that our approach performs on par with state-of-the-art techniques while reducing model complexity.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2163452124",
                        "name": "Luigi Filippo Chiara"
                    },
                    {
                        "authorId": "29776698",
                        "name": "Pasquale Coscia"
                    },
                    {
                        "authorId": "2109605310",
                        "name": "Sourav Das"
                    },
                    {
                        "authorId": "2175529",
                        "name": "S. Calderara"
                    },
                    {
                        "authorId": "1741922",
                        "name": "R. Cucchiara"
                    },
                    {
                        "authorId": "1795847",
                        "name": "Lamberto Ballan"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "95833e22c1ef49bb65e49c01d75dfd269603a621",
                "externalIds": {
                    "ArXiv": "2204.01696",
                    "DBLP": "journals/corr/abs-2204-01696",
                    "DOI": "10.1109/CVPR52688.2022.00328",
                    "CorpusId": 247939501
                },
                "corpusId": 247939501,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/95833e22c1ef49bb65e49c01d75dfd269603a621",
                "title": "Joint Hand Motion and Interaction Hotspots Prediction from Egocentric Videos",
                "abstract": "We propose to forecast future hand-object interactions given an egocentric video. Instead of predicting action labels or pixels, we directly predict the hand motion trajectory and the future contact points on the next active object (i.e., interaction hotspots). This relatively low-dimensional representation provides a con-crete description of future interactions. To tackle this task, we first provide an automatic way to collect trajectory and hotspots labels on large-scale data. We then use this data to train an Object-Centric Transformer (OCT) model for prediction. Our model performs hand and object interaction reasoning via the self-attention mechanism in Transformers. OCT also provides a probabilistic framework to sample the future trajectory and hotspots to handle uncertainty in prediction. We perform experi-ments on the Epic-Kitchens-55, Epic-Kitchens-100 and EGTEA Gaze+ datasets, and show that OCT significantly outperforms state-of the-art approaches by a large margin. Project page is available at https://stevenlsw.github.io/hoi-forecast.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48641958",
                        "name": "Shao-Wei Liu"
                    },
                    {
                        "authorId": "2906509",
                        "name": "Subarna Tripathi"
                    },
                    {
                        "authorId": "2413238",
                        "name": "Somdeb Majumdar"
                    },
                    {
                        "authorId": "1709719",
                        "name": "Xiaolong Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "In addition, P2T [6], PGP [7] and Y-net [27] use K-means to cluster samples while CoverNet [36] employs a greedy approximation algorithm to create a diverse set.",
                "Y-Net [27] models the future position\u2019s multimodality with heatmaps and samples a trajectory from the heatmap conditioned on sampled goal and waypoints.",
                "To evaluate our method\u2019s longterm forecasting performance, we use data in [27], including 1222 training and 174 test trajectories with 5-second history and 30-second future with the 1Hz sampling rate.",
                "Y-net [27] samples intermediate positions conditioned on the sampled goal and waypoints.",
                "Y-net [27] yields the OGM at each future step directly from different channels of the feature map output by a CNN.",
                "Y-net [27] yields the OGM at each future step directly from different channels of the feature map output by a CNN. Similarly, in MP3 [4], the feature map at each channel is embedded into the temporal motion fields at each future step, which obtains the probability transition flow between consecutive OGMs by bilinear interpolation of motion vectors on the field.",
                "Our results are again achieved without the manually annotated semantic maps in Y-net [27].",
                "Notably, our results are achieved without manually labeled semantic maps in YNet [27] or simulation data in SimAug [22]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "cb478a65d489ce7901e9b6b91233902cb456a913",
                "externalIds": {
                    "DBLP": "conf/cvpr/GuoLP22",
                    "ArXiv": "2203.16910",
                    "DOI": "10.1109/CVPR52688.2022.00228",
                    "CorpusId": 247839677
                },
                "corpusId": 247839677,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/cb478a65d489ce7901e9b6b91233902cb456a913",
                "title": "End-to-End Trajectory Distribution Prediction Based on Occupancy Grid Maps",
                "abstract": "In this paper, we aim to forecast a future trajectory distribution of a moving agent in the real world, given the social scene images and historical trajectories. Yet, it is a challenging task because the ground-truth distribution is unknown and unobservable, while only one of its samples can be applied for supervising model learning, which is prone to bias. Most recent works focus on predicting diverse trajectories in order to cover all modes of the real distribution, but they may despise the precision and thus give too much credit to unrealistic predictions. To address the issue, we learn the distribution with symmetric cross-entropy using occupancy grid maps as an explicit and scene-compliant approximation to the ground-truth distribution, which can effectively penalize unlikely predictions. In specific, we present an inverse reinforcement learning based multi-modal trajectory distribution forecasting framework that learns to plan by an approximate value iteration network in an end-to-end manner. Besides, based on the predicted distribution, we generate a small set of representative trajectories through a differentiable Transformer-based network, whose attention mechanism helps to model the relations of trajectories. In experiments, our method achieves state-of-the-art performance on the Stanford Drone Dataset and Intersection Drone Dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2077526303",
                        "name": "Ke Guo"
                    },
                    {
                        "authorId": "143800486",
                        "name": "Wenxi Liu"
                    },
                    {
                        "authorId": "1943594",
                        "name": "Jia-Yu Pan"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Note that our method did not use the image data and apply any post-processing such as the TestTime Sampling Trick (TTST) [28].",
                "Although significant progresses have been achieved over past few years [6,28,29,32,38,45,49,53], predicting the future trajectories of pedestrians remains challenging due to the multi-modality of human motion.",
                "Input Sampling ETH HOTEL UNIV ZARA1 ZARA2 AVG ADE FDE ADE FDE ADE FDE ADE FDE ADE FDE ADE FDE\nSoPhie [37] T + I 20 0.70 1.43 0.76 1.67 0.54 1.24 0.30 0.63 0.38 0.78 0.54 1.15 CGNS [22] T + I 20 0.62 1.40 0.70 0.93 0.48 1.22 0.32 0.59 0.35 0.71 0.49 0.97 Social-BiGAT [19] T + I 20 0.69 1.29 0.49 1.01 0.55 1.32 0.30 0.62 0.36 0.75 0.48 1.00 MG-GAN [6] T + I 20 0.47 0.91 0.14 0.24 0.54 1.07 0.36 0.73 0.29 0.60 0.36 0.71 Y-Net [28] + TTST T + I 10000 0.28 0.33 0.10 0.14 0.24 0.41 0.17 0.27 0.13 0.22 0.18 0.27 Social-GAN [12] T 20 0.81 1.52 0.72 1.61 0.60 1.26 0.34 0.69 0.42 0.84 0.58 1.18 Causal-STGCNN [2] T 20 0.64 1.00 0.38 0.45 0.49 0.81 0.34 0.53 0.32 0.49 0.43 0.66 PECNet [29] T 20 0.54 0.87 0.18 0.24 0.35 0.60 0.22 0.39 0.17 0.30 0.29 0.48 STAR [49] T 20 0.36 0.65 0.17 0.36 0.31 0.62 0.26 0.55 0.22 0.46 0.26 0.53 Trajectron++ [38] T 20 0.39 0.83 0.12 0.21 0.20 0.44 0.15 0.33 0.11 0.25 0.19 0.41 LB-EBM [32] T 20 0.30 0.52 0.13 0.20 0.27 0.52 0.20 0.37 0.15 0.29 0.21 0.38 PCCSNET [45] T 20 0.28 0.54 0.11 0.19 0.29 0.60 0.21 0.44 0.15 0.34 0.21 0.42 \u2020Expert [53] T 20 0.37 0.65 0.11 0.15 0.20 0.44 0.15 0.31 0.12 0.26 0.19 0.36 \u2020Expert [53]+GMM T 20\u00d720 0.29 0.65 0.08 0.15 0.15 0.44 0.11 0.31 0.09 0.26 0.14 0.36 MID T 20 0.39 0.66 0.13 0.22 0.22 0.45 0.17 0.30 0.13 0.27 0.21 0.38\nthe comparison between our method and existing methods on the Stanford Drone dataset.",
                "Specifically, our MID outperforms the current state-of-the-art T+I method Y-Net+TTST on the ADE metric.",
                "Beyond social interactions, many methods incorporate the physical environment interactions by introducing the map images [6, 19, 20, 28, 37].",
                "Recently, the goals of pedestrians [28,29,52,53] are introduced in the trajectory prediction system as condition to analyze the probability of multiple plausible endpoints."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "13b5aae86ac2a4daae35ce31de726e55dd77e0ba",
                "externalIds": {
                    "ArXiv": "2203.13777",
                    "DBLP": "conf/cvpr/Gu0LLR0L22",
                    "DOI": "10.1109/CVPR52688.2022.01660",
                    "CorpusId": 247748591
                },
                "corpusId": 247748591,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/13b5aae86ac2a4daae35ce31de726e55dd77e0ba",
                "title": "Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion",
                "abstract": "Human behavior has the nature of indeterminacy, which requires the pedestrian trajectory prediction system to model the multi-modality of future motion states. Unlike existing stochastic trajectory prediction methods which usually use a latent variable to represent multi-modality, we explicitly simulate the process of human motion variation from indeterminate to determinate. In this paper, we present a new framework to formulate the trajectory prediction task as a reverse process of motion indeterminacy diffusion (MID), in which we progressively discard indeterminacy from all the walkable areas until reaching the desired trajectory. This process is learned with a parameterized Markov chain conditioned by the observed trajectories. We can adjust the length of the chain to control the degree of indeterminacy and balance the diversity and determinacy of the predictions. Specifically, we encode the history behavior information and the social interactions as a state embedding and devise a Transformer-based diffusion model to capture the temporal dependencies of trajectories. Extensive experiments on the human trajectory prediction benchmarks including the Stanford Drone and ETH/UCY datasets demonstrate the superiority of our method. Code is available at https://github.com/gutianpei/MID.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2124439724",
                        "name": "Tianpei Gu"
                    },
                    {
                        "authorId": "1734615",
                        "name": "Guangyi Chen"
                    },
                    {
                        "authorId": null,
                        "name": "Junlong Li"
                    },
                    {
                        "authorId": "51510731",
                        "name": "Chunze Lin"
                    },
                    {
                        "authorId": "39358728",
                        "name": "Yongming Rao"
                    },
                    {
                        "authorId": "48128428",
                        "name": "Jie Zhou"
                    },
                    {
                        "authorId": "1697700",
                        "name": "Jiwen Lu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7ab2105008d1e0eec32798aad69ea62ff2da8c78",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-11743",
                    "ArXiv": "2203.11743",
                    "DOI": "10.1109/TIV.2022.3166642",
                    "CorpusId": 247596716
                },
                "corpusId": 247596716,
                "publicationVenue": {
                    "id": "c2eeb1be-38e9-4a0a-a89d-957f4fd71ea1",
                    "name": "IEEE Transactions on Intelligent Vehicles",
                    "alternate_names": [
                        "IEEE Trans Intell Veh"
                    ],
                    "issn": "2379-8858",
                    "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7274857"
                },
                "url": "https://www.semanticscholar.org/paper/7ab2105008d1e0eec32798aad69ea62ff2da8c78",
                "title": "The Stanford Drone Dataset Is More Complex Than We Think: An Analysis of Key Characteristics",
                "abstract": "Several datasets exist which contain annotated information of individuals\u2019 trajectories. Such datasets are vital for many real-world applications, including trajectory prediction and autonomous navigation. One prominent dataset currently in use is the Stanford Drone Dataset (SDD) (Robicquet et al., 2016). Despite its prominence, discussion surrounding the characteristics of this dataset is insufficient. We demonstrate how this insufficiency reduces the information available to users and can impact performance. Our contributions include the outlining of key characteristics in the SDD, employment of an information-theoretic measure and custom metric to clearly visualize those characteristics, the implementation of the PECNet (Mangalam et al., 2020) and Y-Net (Mangalam et al., 2021) trajectory prediction models to demonstrate the outlined characteristics\u2019 impact on predictive performance, and lastly we provide a comparison between the SDD and Intersection Drone (inD) Dataset. Our analysis of the SDD\u2019s key characteristics is important because without adequate information about available datasets a user\u2019s ability to select the most suitable dataset for their methods, to reproduce one another\u2019s results, and to interpret their own results are hindered. The observations we make through this analysis provide a readily accessible and interpretable source of information for those planning to use the SDD. Our intention is to increase the performance and reproducibility of methods applied to this dataset going forward, while also clearly detailing less obvious features of the dataset for new users.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1394125040",
                        "name": "Joshua Andle"
                    },
                    {
                        "authorId": "1620413243",
                        "name": "Nicholas Soucy"
                    },
                    {
                        "authorId": "2159553767",
                        "name": "Simon Socolow"
                    },
                    {
                        "authorId": "1759505",
                        "name": "S. Y. Sekeh"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bb589b301dc538cad83fb47f3cdfa705a52dac1e",
                "externalIds": {
                    "DBLP": "journals/pr/FrancoPGHCG23",
                    "ArXiv": "2203.11878",
                    "DOI": "10.48550/arXiv.2203.11878",
                    "CorpusId": 247596756
                },
                "corpusId": 247596756,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/bb589b301dc538cad83fb47f3cdfa705a52dac1e",
                "title": "Under the Hood of Transformer Networks for Trajectory Forecasting",
                "abstract": "Transformer Networks have established themselves as the de-facto state-of-the-art for trajectory forecasting but there is currently no systematic study on their capability to model the motion patterns of people, without interactions with other individuals nor the social context. This paper proposes the first in-depth study of Transformer Networks (TF) and Bidirectional Transformers (BERT) for the forecasting of the individual motion of people, without bells and whistles. We conduct an exhaustive evaluation of input/output representations, problem formulations and sequence modeling, including a novel analysis of their capability to predict multi-modal futures. Out of comparative evaluation on the ETH+UCY benchmark, both TF and BERT are top performers in predicting individual motions, definitely overcoming RNNs and LSTMs. Furthermore, they remain within a narrow margin wrt more complex techniques, which include both social interactions and scene contexts. Source code will be released for all conducted experiments.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2055268823",
                        "name": "Luca Franco"
                    },
                    {
                        "authorId": "2159554408",
                        "name": "Leonardo Placidi"
                    },
                    {
                        "authorId": "51299776",
                        "name": "Francesco Giuliari"
                    },
                    {
                        "authorId": "38163772",
                        "name": "Irtiza Hasan"
                    },
                    {
                        "authorId": "1723008",
                        "name": "M. Cristani"
                    },
                    {
                        "authorId": "1787725",
                        "name": "Fabio Galasso"
                    }
                ]
            }
        },
        {
            "intents": [
                "result"
            ],
            "contexts": [
                "FPC is similar to the test-time sampling trick proposed in YNet [26]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2121ce812d6172bdf821ef907e09e7153db2ba23",
                "externalIds": {
                    "ArXiv": "2203.08207",
                    "DBLP": "journals/corr/abs-2203-08207",
                    "DOI": "10.1007/978-3-031-19772-7_30",
                    "CorpusId": 247476178
                },
                "corpusId": 247476178,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/2121ce812d6172bdf821ef907e09e7153db2ba23",
                "title": "SocialVAE: Human Trajectory Prediction using Timewise Latents",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2087067124",
                        "name": "Pei Xu"
                    },
                    {
                        "authorId": "1807691",
                        "name": "J. Hayet"
                    },
                    {
                        "authorId": "2478994",
                        "name": "Ioannis Karamouzas"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "For the past two years, some works [48, 67, 85] have been proposed to explore the goal-driven trajectory prediction."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1cd0147d075dc8a4d8029a7ed575d5c1e553d39e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-05046",
                    "ArXiv": "2203.05046",
                    "DOI": "10.1109/CVPR52688.2022.00641",
                    "CorpusId": 247362656
                },
                "corpusId": 247362656,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1cd0147d075dc8a4d8029a7ed575d5c1e553d39e",
                "title": "Adaptive Trajectory Prediction via Transferable GNN",
                "abstract": "Pedestrian trajectory prediction is an essential component in a wide range of AI applications such as autonomous driving and robotics. Existing methods usually assume the training and testing motions follow the same pattern while ignoring the potential distribution differences (e.g., shopping mall and street). This issue results in inevitable performance decrease. To address this issue, we propose a novel Transferable Graph Neural Network (TGNN) frame-work, which jointly conducts trajectory prediction as well as domain alignment in a unified framework. Specifically, a domain-invariant GNN is proposed to explore the structural motion knowledge where the domain-specific knowledge is reduced. Moreover, an attention-based adaptive knowledge learning module is further proposed to explore fine-grained individual-level feature representations for knowledge transfer. By this way, disparities across different trajectory domains will be better alleviated. More challenging while practical trajectory prediction experiments are designed, and the experimental results verify the superior performance of our proposed model. To the best of our knowledge, our work is the pioneer which fills the gap in benchmarks and techniques for practical pedestrian trajectory prediction across different domains.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2143970051",
                        "name": "Yi Xu"
                    },
                    {
                        "authorId": "1491247995",
                        "name": "Lichen Wang"
                    },
                    {
                        "authorId": "1717863",
                        "name": "Yizhou Wang"
                    },
                    {
                        "authorId": "46956675",
                        "name": "Y. Fu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Another issue we noticed that the recent models [36,43,26,23] which are state-of-the-art based on the ADE/FDE metric only differ by 1cm ADE and few centimeters FDE on the ETH [29] and UCY [16] datasets, one of the most commonly used datasets in this area."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6dd962e9199082880e653ad512704cc97871798d",
                "externalIds": {
                    "DBLP": "conf/eccv/MohamedZVEC22",
                    "ArXiv": "2203.03057",
                    "DOI": "10.48550/arXiv.2203.03057",
                    "CorpusId": 247292580
                },
                "corpusId": 247292580,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/6dd962e9199082880e653ad512704cc97871798d",
                "title": "Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation",
                "abstract": "Best-of-N (BoN) Average Displacement Error (ADE)/ Final Displacement Error (FDE) is the most used metric for evaluating trajectory prediction models. Yet, the BoN does not quantify the whole generated samples, resulting in an incomplete view of the model's prediction quality and performance. We propose a new metric, Average Mahalanobis Distance (AMD) to tackle this issue. AMD is a metric that quantifies how close the whole generated samples are to the ground truth. We also introduce the Average Maximum Eigenvalue (AMV) metric that quantifies the overall spread of the predictions. Our metrics are validated empirically by showing that the ADE/FDE is not sensitive to distribution shifts, giving a biased sense of accuracy, unlike the AMD/AMV metrics. We introduce the usage of Implicit Maximum Likelihood Estimation (IMLE) as a replacement for traditional generative models to train our model, Social-Implicit. IMLE training mechanism aligns with AMD/AMV objective of predicting trajectories that are close to the ground truth with a tight spread. Social-Implicit is a memory efficient deep model with only 5.8K parameters that runs in real time of about 580Hz and achieves competitive results. Interactive demo of the problem can be seen at https://www.abduallahmohamed.com/social-implicit-amdamv-adefde-demo . Code is available at https://github.com/abduallahmohamed/Social-Implicit .",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51210562",
                        "name": "Abduallah A. Mohamed"
                    },
                    {
                        "authorId": "1388731230",
                        "name": "Deyao Zhu"
                    },
                    {
                        "authorId": "2157863363",
                        "name": "Warren Vu"
                    },
                    {
                        "authorId": "1712479",
                        "name": "Mohamed Elhoseiny"
                    },
                    {
                        "authorId": "1678595",
                        "name": "C. Claudel"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "In the context of trajectory prediction, scene information can be represented in various formats, such as rasterized maps [10, 25, 36], vectorized maps [14, 26], instance-level representations [19], 2D scene images [11,28,45] and drivable areas [34].",
                "There is a large body of works on this topic designed to predict behavior of pedestrians [21, 28, 37, 45, 50] and vehicles [1, 10, 11, 13, 19, 36].",
                "Scene-based methods mainly rely on the semantic map of the environment alongside the agents\u2019 positional information represented as a point-cloud map [6, 10, 36, 53], or 2D representations of trajectories [13, 28, 29]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7ced9429909bed7fee635a7db872931e17c3ae95",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-01880",
                    "ArXiv": "2203.01880",
                    "DOI": "10.48550/arXiv.2203.01880",
                    "CorpusId": 247223143
                },
                "corpusId": 247223143,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7ced9429909bed7fee635a7db872931e17c3ae95",
                "title": "LatentFormer: Multi-Agent Transformer-Based Interaction Modeling and Trajectory Prediction",
                "abstract": "Multi-agent trajectory prediction is a fundamental problem in autonomous driving. The key challenges in prediction are accurately anticipating the behavior of surrounding agents and understanding the scene context. To address these problems, we propose LatentFormer, a transformer-based model for predicting future vehicle trajectories. The proposed method leverages a novel technique for modeling interactions among dynamic objects in the scene. Contrary to many existing approaches which model cross-agent interactions during the observation time, our method additionally exploits the future states of the agents. This is accomplished using a hierarchical attention mechanism where the evolving states of the agents autoregressively control the contributions of past trajectories and scene encodings in the final prediction. Furthermore, we propose a multi-resolution map encoding scheme that relies on a vision transformer module to effectively capture both local and global scene context to guide the generation of more admissible future trajectories. We evaluate the proposed method on the nuScenes benchmark dataset and show that our approach achieves state-of-the-art performance and improves upon trajectory metrics by up to 40%. We further investigate the contributions of various components of the proposed technique via extensive ablation studies.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2042629798",
                        "name": "Elmira Amirloo"
                    },
                    {
                        "authorId": "26902477",
                        "name": "Amir Rasouli"
                    },
                    {
                        "authorId": "2913485",
                        "name": "P. Lakner"
                    },
                    {
                        "authorId": "145367501",
                        "name": "Mohsen Rohani"
                    },
                    {
                        "authorId": "1491232654",
                        "name": "Jun Luo"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Appendix F shows the limitation of the SDD segmentation provided by Y-net [29] to explain the low ECFL discussed in Sec.",
                "The Stanford Drone Dataset (SDD) [34] is used in the TrajNet challenge [36] and prior works [29, 37].",
                "Moreover, the models frequently struggle to account for the diversity of the forecast goals and trajectories [29], which are driven by the uncertain, multi-modal nature of the problem.",
                "Ynet [29] addresses this issue by aligning the semantic map with the trajectory heatmap spatially and processing them as a whole.",
                "1 and compare the performance of MUSE-VAE with Trajectron++ (T++) [38], Y-net [29], and AgentFormer (AF) [50] baselines, using their public code.",
                "State-of-the-Art (SOTA) methods [29, 48, 51] leverage this intuition to propose goal-conditioned prediction model.",
                "Some prior works [29, 33, 48, 51] encourage the multimodality by proposing a goal-conditioned forecasting model under the assumption that one\u2019s movement depends primarily on the final goal position.",
                "Y-net [29] utilizes K-means clustering of predictive discrete density maps at test time to achieve diverse prediction; however, the model does not explicitly learn the resolution-free multimodal trajectory density.",
                "Ynet [29] solves the sequential trajectory learning problem with only convolution layers.",
                "For alignment between trajectories and the semantic map, trajectories x are also represented in the pixel space as suggested in Y-net [29], using a Gaussian heatmap, denoted by Ix."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "ea18da464c737fb74942846f0401091c5eade67c",
                "externalIds": {
                    "ArXiv": "2201.07189",
                    "DBLP": "conf/cvpr/LeeSMYKP22",
                    "DOI": "10.1109/CVPR52688.2022.00226",
                    "CorpusId": 246035517
                },
                "corpusId": 246035517,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ea18da464c737fb74942846f0401091c5eade67c",
                "title": "MUSE-VAE: Multi-Scale VAE for Environment-Aware Long Term Trajectory Prediction",
                "abstract": "Accurate long-term trajectory prediction in complex scenes, where multiple agents (e.g., pedestrians or vehicles) interact with each other and the environment while attempting to accomplish diverse and often unknown goals, is a challenging stochastic forecasting problem. In this work, we propose MUSEVAE, a new probabilistic modeling framework based on a cascade of Conditional VAEs, which tackles the long-term, uncertain trajectory prediction task using a coarse-to-fine multi-factor forecasting architecture. In its Macro stage, the model learns a joint pixel-space representation of two key factors, the underlying environment and the agent movements, to predict the long and short term motion goals. Conditioned on them, the Micro stage learns a fine-grained spatio-temporal representation for the prediction of individual agent trajectories. The VAE backbones across the two stages make it possible to naturally account for the joint uncertainty at both levels of granularity. As a result, MUSEVAE offers diverse and simultaneously more accurate predictions compared to the current state-of-the-art. We demonstrate these assertions through a comprehensive set of experiments on nuScenes and SDD benchmarks as well as PFSD, a new synthetic dataset, which challenges the forecasting ability of models on complex agent-environment interaction scenarios.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47803967",
                        "name": "Mihee Lee"
                    },
                    {
                        "authorId": "51118484",
                        "name": "Samuel S. Sohn"
                    },
                    {
                        "authorId": "2113901568",
                        "name": "Seonghyeon Moon"
                    },
                    {
                        "authorId": "2244969",
                        "name": "Sejong Yoon"
                    },
                    {
                        "authorId": "143980997",
                        "name": "M. Kapadia"
                    },
                    {
                        "authorId": "144658464",
                        "name": "V. Pavlovic"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Other work has used VAEs to model the distribution of predicted future goals and then predict the many paths taken to solve them in a two-phase approach [57]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "cadba12b17a89512e9553801b0ed2f640f832f67",
                "externalIds": {
                    "DBLP": "journals/tvcg/HuHBPFK23",
                    "DOI": "10.1109/TVCG.2021.3139031",
                    "CorpusId": 245566720,
                    "PubMed": "34965213"
                },
                "corpusId": 245566720,
                "publicationVenue": {
                    "id": "5e1f6444-5d03-48c7-b202-7f47d492aeae",
                    "name": "IEEE Transactions on Visualization and Computer Graphics",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Vis Comput Graph"
                    ],
                    "issn": "1077-2626",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=2945"
                },
                "url": "https://www.semanticscholar.org/paper/cadba12b17a89512e9553801b0ed2f640f832f67",
                "title": "Heterogeneous Crowd Simulation Using Parametric Reinforcement Learning",
                "abstract": "Agent-based synthetic crowd simulation affords the cost-effective large-scale simulation and animation of interacting digital humans. Model-based approaches have successfully generated a plethora of simulators with a variety of foundations. However, prior approaches have been based on statically defined models predicated on simplifying assumptions, limited video-based datasets, or homogeneous policies. Recent works have applied reinforcement learning to learn policies for navigation. However, these approaches may learn static homogeneous rules, are typically limited in their generalization to trained scenarios, and limited in their usability in synthetic crowd domains. In this article, we present a multi-agent reinforcement learning-based approach that learns a parametric predictive collision avoidance and steering policy. We show that training over a parameter space produces a flexible model across crowd configurations. That is, our goal-conditioned approach learns a parametric policy that affords heterogeneous synthetic crowds. We propose a model-free approach without centralization of internal agent information, control signals, or agent communication. The model is extensively evaluated. The results show policy generalization across unseen scenarios, agent parameters, and out-of-distribution parameterizations. The learned model has comparable computational performance to traditional methods. Qualitatively the model produces both expected (laminar flow, shuffling, bottleneck) and unexpected (side-stepping) emergent qualitative behaviours, and quantitatively the approach is performant across measures of movement quality.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "50726531",
                        "name": "Kaidong Hu"
                    },
                    {
                        "authorId": "38590145",
                        "name": "M. B. Haworth"
                    },
                    {
                        "authorId": "2994035",
                        "name": "G. Berseth"
                    },
                    {
                        "authorId": "144658464",
                        "name": "V. Pavlovic"
                    },
                    {
                        "authorId": "1737527",
                        "name": "P. Faloutsos"
                    },
                    {
                        "authorId": "143980996",
                        "name": "Mubbasir Kapadia"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "43acf2392f300b286c94a8e29c4a3413cfc546d2",
                "externalIds": {
                    "ArXiv": "2112.02459",
                    "DBLP": "journals/corr/abs-2112-02459",
                    "DOI": "10.1109/tnnls.2023.3250485",
                    "CorpusId": 244909345,
                    "PubMed": "37028327"
                },
                "corpusId": 244909345,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/43acf2392f300b286c94a8e29c4a3413cfc546d2",
                "title": "SSAGCN: Social Soft Attention Graph Convolution Network for Pedestrian Trajectory Prediction",
                "abstract": "Pedestrian trajectory prediction is an important technique of autonomous driving. In order to accurately predict the reasonable future trajectory of pedestrians, it is inevitable to consider social interactions among pedestrians and the influence of surrounding scene simultaneously, which can fully represent the complex behavior information and ensure the rationality of predicted trajectories obeyed realistic rules. In this article, we propose one new prediction model named social soft attention graph convolution network (SSAGCN), which aims to simultaneously handle social interactions among pedestrians and scene interactions between pedestrians and environments. In detail, when modeling social interaction, we propose a new social soft attention function, which fully considers various interaction factors among pedestrians. Also, it can distinguish the influence of pedestrians around the agent based on different factors under various situations. For the scene interaction, we propose one new sequential scene sharing mechanism. The influence of the scene on one agent at each moment can be shared with other neighbors through social soft attention; therefore, the influence of the scene is expanded both in spatial and temporal dimensions. With the help of these improvements, we successfully obtain socially and physically acceptable predicted trajectories. The experiments on public available datasets prove the effectiveness of SSAGCN and have achieved state-of-the-art results. The project code is available at.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "144470801",
                        "name": "Pei Lv"
                    },
                    {
                        "authorId": "51207898",
                        "name": "Wentong Wang"
                    },
                    {
                        "authorId": "2125063579",
                        "name": "Yunxin Wang"
                    },
                    {
                        "authorId": "2143184771",
                        "name": "Yuzhen Zhang"
                    },
                    {
                        "authorId": "2285442",
                        "name": "Mingliang Xu"
                    },
                    {
                        "authorId": "145194969",
                        "name": "Changsheng Xu"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "We apply our method on top of the Y-Net [50], and compare our modular adaptation strategy against the standard fine-tuning of the entire model for lowshot transfer."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1632e0ce53261e1e6ef7a0edea359b6569af0aa0",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiuCSBA22",
                    "ArXiv": "2111.14820",
                    "DOI": "10.1109/CVPR52688.2022.01657",
                    "CorpusId": 244714689
                },
                "corpusId": 244714689,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1632e0ce53261e1e6ef7a0edea359b6569af0aa0",
                "title": "Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective",
                "abstract": "Learning behavioral patterns from observational data has been a de-facto approach to motion forecasting. Yet, the current paradigm suffers from two shortcomings: brittle under distribution shifts and inefficient for knowledge transfer. In this work, we propose to address these challenges from a causal representation perspective. We first introduce a causal formalism of motion forecasting, which casts the problem as a dynamic process with three groups of latent variables, namely invariant variables, style confounders, and spurious features. We then introduce a learning framework that treats each group separately: (i) unlike the common practice mixing datasets collected from different locations, we exploit their subtle distinctions by means of an invariance loss encouraging the model to suppress spurious correlations; (ii) we devise a modular architecture that factorizes the representations of invariant mechanisms and style confounders to approximate a sparse causal graph; (iii) we introduce a style contrastive loss that not only enforces the structure of style representations but also serves as a self-supervisory signal for test-time refinement on the fly. Experiments on synthetic and real datasets show that our proposed method improves the robustness and reusability of learned motion representations, significantly outperforming prior state-of-the-art motion forecasting models for out-of-distribution generalization and low-shot transfer.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "14772333",
                        "name": "Yuejiang Liu"
                    },
                    {
                        "authorId": "2122899467",
                        "name": "Riccardo Cadei"
                    },
                    {
                        "authorId": "2142457296",
                        "name": "Jonas Schweizer"
                    },
                    {
                        "authorId": "2142454988",
                        "name": "Sherwin Bahmani"
                    },
                    {
                        "authorId": "3304525",
                        "name": "Alexandre Alahi"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Recent state-of-the-art works [8-10, 48] use goalconditioned approaches which are regarded as inverse planning or prediction by planning.",
                "A large body of works, including the state-of-the-art methods [4, 8-11], build on Seq2Seq [12] (the encoderdecoder framework)."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2f3ccb8b8af5efcce2bdc5635ee43b390f525366",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-13324",
                    "ArXiv": "2111.13324",
                    "CorpusId": 244709077
                },
                "corpusId": 244709077,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2f3ccb8b8af5efcce2bdc5635ee43b390f525366",
                "title": "Hierarchical Motion Encoder-Decoder Network for Trajectory Forecasting",
                "abstract": "Trajectory forecasting plays a pivotal role in the field of intelligent vehicles or social robots. Recent works focus on modeling spatial social impacts or temporal motion attentions, but neglect inherent properties of motions, i.e. moving trends and driving intentions. This paper proposes a context-free Hierarchical Motion Encoder-Decoder Network (HMNet) for vehicle trajectory prediction. HMNet first infers the hierarchical difference on motions to encode physically compliant patterns with high expressivity of moving trends and driving intentions. Then, a goal (endpoint)-embedded decoder hierarchically constructs multimodal predictions depending on the locationvelocity-acceleration-related patterns. Besides, we present a modified social pooling module which considers certain motion properties to represent social interactions. HMNet enables to make the accurate, unimodal/multimodal and physically-socially-compliant prediction. Experiments on three public trajectory prediction datasets, i.e. NGSIM, HighD and Interaction show that our model achieves the state-of-the-art performance both quantitatively and qualitatively. We will release our code here: https://github.com/xuedashuai/HMNet.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2055030524",
                        "name": "Qifan Xue"
                    },
                    {
                        "authorId": "2156106857",
                        "name": "Shen Li"
                    },
                    {
                        "authorId": "2626073",
                        "name": "Xuanpeng Li"
                    },
                    {
                        "authorId": "2145802156",
                        "name": "Jingwen Zhao"
                    },
                    {
                        "authorId": "2154822943",
                        "name": "Weigong Zhang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology",
                "result"
            ],
            "contexts": [
                "In particular, we have selected (1) Social GAN (SGAN) [Gupta et al. 2018], one of the earliest models; (2) Trajectron++ (T++) [Salzmann et al. 2020], a SOTA model for short-term trajectory prediction; and (3) PECNet (PECN) [Mangalam et al. 2020b], a SOTA model for long-term trajectory prediction.",
                "PECNet [Mangalam et al. 2020b] solves the trajectory prediction problem by first modeling the future goal position distribution using a Variational Autoencoder (VAE) [Kingma and Welling 2014], and then predict the future positions by interpolating the observed positions and the estimated goal\u2026",
                "\u2026discriminative models [Alahi et al. 2016] that predict a single future trajectory to using multimodal, generative models [Gupta et al. 2018; Mangalam et al. 2020b; Salzmann et al. 2020] that predict a distribution of future trajectories, which captures the inherent uncertainty in human\u2026",
                "Recent studies [Gupta et al. 2018; Ivanovic and Pavone 2019; Mangalam et al. 2020a,b; Salzmann et al. 2020; Zhao et al.\n2019] assume the multi-modalities in the future human behavior and predict its distribution to embody the uncertainty.",
                "In this paper, we focus on three SOTAmethodologies to showcase our benchmark dataset: SocialGAN [Gupta et al. 2018], PECNet [Mangalam et al. 2020b], and Trajectron++ [Salzmann et al. 2020].",
                "We choose them because PECNet [Mangalam et al. 2020b] shows an outstanding performance on the long-term trajectory while the short-term trajectory is most well predicted in Trajectron++ [Salzmann et al. 2020].",
                "Recent 59 studies [7, 18, 24, 36, 12, 17] assume the multi-modalities in the future human behavior and predict 60 its distribution to embody the uncertainty."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "dd5b4a624cf78a8564c014ce79380026f7c7e02a",
                "externalIds": {
                    "DBLP": "conf/mig/SohnLMQ0YPK21",
                    "DOI": "10.1145/3487983.3488302",
                    "CorpusId": 237250545
                },
                "corpusId": 237250545,
                "publicationVenue": {
                    "id": "b8f59d7a-6967-4545-9bff-d154d6f94bd4",
                    "name": "Motion in Games",
                    "type": "conference",
                    "alternate_names": [
                        "MIG",
                        "Motion Game"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dd5b4a624cf78a8564c014ce79380026f7c7e02a",
                "title": "A2X: An Agent and Environment Interaction Benchmark for Multimodal Human Trajectory Prediction",
                "abstract": "In recent years, human trajectory prediction (HTP) has garnered attention in computer vision literature. Although this task has much in common with the longstanding task of crowd simulation, there is little from crowd simulation that has been borrowed, especially in terms of evaluation protocols. The key difference between the two tasks is that HTP is concerned with forecasting multiple steps at a time and capturing the multimodality of real human trajectories. A majority of HTP models are trained on the same few datasets, which feature small, transient interactions between real people and little to no interaction between people and the environment. Unsurprisingly, when tested on crowd egress scenarios, these models produce erroneous trajectories that accelerate too quickly and collide too frequently, but the metrics used in HTP literature cannot convey these particular issues. To address these challenges, we propose (1) the A2X dataset, which has simulated crowd egress and complex navigation scenarios that compensate for the lack of agent-to-environment interaction in existing real datasets, and (2) evaluation metrics that convey model performance with more reliability and nuance. A subset of these metrics are novel multiverse metrics, which are better-suited for multimodal models than existing metrics. The dataset is available at: https://mubbasir.github.io/HTP-benchmark/.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51118484",
                        "name": "Samuel S. Sohn"
                    },
                    {
                        "authorId": "47803967",
                        "name": "Mihee Lee"
                    },
                    {
                        "authorId": "2113901568",
                        "name": "Seonghyeon Moon"
                    },
                    {
                        "authorId": "2057159150",
                        "name": "Gang Qiao"
                    },
                    {
                        "authorId": "145274939",
                        "name": "Muhammad Usman"
                    },
                    {
                        "authorId": "2244969",
                        "name": "Sejong Yoon"
                    },
                    {
                        "authorId": "144658464",
                        "name": "V. Pavlovic"
                    },
                    {
                        "authorId": "143980996",
                        "name": "Mubbasir Kapadia"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "To cope with the uncertainty problem, numerous methods [7]\u2013[9] have been proposed in recent years.",
                "Y-net [9] further improves PECNet by iteratively predicting intermediate waypoints and trajectories."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7eabde2dadfae1a1b799a3f2d26b4036d4dd9ee3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-15016",
                    "ArXiv": "2110.15016",
                    "CorpusId": 240070639
                },
                "corpusId": 240070639,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7eabde2dadfae1a1b799a3f2d26b4036d4dd9ee3",
                "title": "Sliding Sequential CVAE with Time Variant Socially-aware Rethinking for Trajectory Prediction",
                "abstract": "Pedestrian trajectory prediction is a key technology in many applications such as video surveillance, social robot navigation, and autonomous driving, and significant progress has been made in this research topic. However, there remain two limitations of previous studies. First, with the continuation of time, the prediction error at each time step increases significantly, causing the final displacement error to be impossible to ignore. Second, the prediction results of multiple pedestrians might be impractical in the prediction horizon, i.e., the predicted trajectories might collide with each other. To overcome these limitations, this work proposes a novel trajectory prediction method called CSR, which consists of a cascaded conditional variational autoencoder (CVAE) module and a socially-aware regression module. The cascaded CVAE module first estimates the future trajectories in a sequential pattern. Specifically, each CVAE concatenates the past trajectories and the predicted points so far as the input and predicts the location at the following time step. Then, the socially-aware regression module generates offsets from the estimated future trajectories to produce the socially compliant final predictions, which are more reasonable and accurate results than the estimated trajectories. Moreover, considering the large model parameters of the cascaded CVAE module, a slide CVAE module is further exploited to improve the model efficiency using one shared CVAE, in a slidable manner. Experiments results demonstrate that the proposed method exhibits improvements over state-of-the-art method on the Stanford Drone Dataset (SDD) and ETH/UCY of approximately 38.0% and 22.2%, respectively.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2111825091",
                        "name": "Hao Zhou"
                    },
                    {
                        "authorId": "2983017",
                        "name": "Dongchun Ren"
                    },
                    {
                        "authorId": "144262997",
                        "name": "Xu Yang"
                    },
                    {
                        "authorId": "7821599",
                        "name": "Mingyu Fan"
                    },
                    {
                        "authorId": "1416632768",
                        "name": "Hai Huang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "The first approach is to model the distribution explicitly with conditional variational autoencoders [5, 7] ."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "93880b7bdd3667e05c88ab710cd838d02f0f9ea8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-11401",
                    "ArXiv": "2110.11401",
                    "CorpusId": 239616296
                },
                "corpusId": 239616296,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/93880b7bdd3667e05c88ab710cd838d02f0f9ea8",
                "title": "Trajectory Prediction using Generative Adversarial Network in Multi-Class Scenarios",
                "abstract": "Predicting traffic agents' trajectories is an important task for auto-piloting. Most previous work on trajectory prediction only considers a single class of road agents. We use a sequence-to-sequence model to predict future paths from observed paths and we incorporate class information into the model by concatenating extracted label representations with traditional location inputs. We experiment with both LSTM and transformer encoders and we use generative adversarial network as introduced in Social GAN to learn the multi-modal behavior of traffic agents. We train our model on Stanford Drone dataset which includes 6 classes of road agents and evaluate the impact of different model components on the prediction performance in multi-class scenes.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2135810404",
                        "name": "Shilun Li"
                    },
                    {
                        "authorId": "2121406708",
                        "name": "Tracy Cai"
                    },
                    {
                        "authorId": "2109012556",
                        "name": "Jiayi Li"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Others like [28] also introduce several \u201cwaypoints\u201d to help better predict agents\u2019 potential future intentions rather than the only destination points.",
                "We choose several methods as our baselines, including S-GAN [14], SoPhie [42], Social-BiGAT [21], E-SR-LSTM [60], MANTRA [33], Multiverse [26], SimAug [25], PECNet [29], STAR [57], TPNMS [27], TF [13], Trajectron++ [44], Introvert [45], LB-EBM [37], Agentformer [58], Y-net [28], and SpecTGNN [3].",
                "[28] introduces several \u201cwaypoints\u201d to help predict agents\u2019 potential intentions rather than the only destination point."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f15a7ab18637b1ec5ad16e5d739a67f4b76ec874",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-07288",
                    "ArXiv": "2110.07288",
                    "DOI": "10.1007/978-3-031-20047-2_39",
                    "CorpusId": 238856860
                },
                "corpusId": 238856860,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/f15a7ab18637b1ec5ad16e5d739a67f4b76ec874",
                "title": "View Vertically: A Hierarchical Network for Trajectory Prediction via Fourier Spectrums",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1991582869",
                        "name": "Conghao Wong"
                    },
                    {
                        "authorId": "1561145507",
                        "name": "Beihao Xia"
                    },
                    {
                        "authorId": "100965035",
                        "name": "Ziming Hong"
                    },
                    {
                        "authorId": "2647338",
                        "name": "Qinmu Peng"
                    },
                    {
                        "authorId": "1744228",
                        "name": "Xinge You"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "including driving maneuvers [4], [22], [23], goal locations or waypoints [6], [8], [24], [25], [26], [27], and target lanes [7], [28], [29], [30], etc."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9865e77fb1a08566d8f3578e88bf6196d0b2c010",
                "externalIds": {
                    "DBLP": "conf/icra/HuangRGJMLW22",
                    "ArXiv": "2110.02344",
                    "DOI": "10.1109/icra46639.2022.9812254",
                    "CorpusId": 238407734
                },
                "corpusId": 238407734,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9865e77fb1a08566d8f3578e88bf6196d0b2c010",
                "title": "HYPER: Learned Hybrid Trajectory Prediction via Factored Inference and Adaptive Sampling",
                "abstract": "Modeling multi-modal high-level intent is important for ensuring diversity in trajectory prediction. Existing approaches explore the discrete nature of human intent before predicting continuous trajectories, to improve accuracy and support explainability. However, these approaches often assume the intent to remain fixed over the prediction horizon, which is problematic in practice, especially over longer horizons. To overcome this limitation, we introduce HYPER, a general and expressive hybrid prediction framework that models evolving human intent. By modeling traffic agents as a hybrid discrete-continuous system, our approach is capable of predicting discrete intent changes over time. We learn the probabilistic hybrid model via a maximum likelihood estimation problem and leverage neural proposal distributions to sample adaptively from the exponentially growing discrete space. The overall approach affords a better trade-off between accuracy and coverage. We train and validate our model on the Argoverse dataset, and demonstrate its effectiveness through comprehensive ablation studies and comparisons with state-of-the-art models.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152661970",
                        "name": "Xin Huang"
                    },
                    {
                        "authorId": "2116952",
                        "name": "G. Rosman"
                    },
                    {
                        "authorId": "2072248",
                        "name": "Igor Gilitschenski"
                    },
                    {
                        "authorId": "145423972",
                        "name": "A. Jasour"
                    },
                    {
                        "authorId": "2474287",
                        "name": "Stephen G. McGill"
                    },
                    {
                        "authorId": "7136913",
                        "name": "J. Leonard"
                    },
                    {
                        "authorId": "31343933",
                        "name": "B. Williams"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Motion forecasting can also be tackled through the use of a heatmap output representing the final trajectory point location distribution [10], [11].",
                "[11] models both long-term goals and intermediary waypoints in the two-dimensional space as an image for pedestrian trajectory forecasting, combined with random sampling and Kmeans clustering."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dbe41b7715078917c2f65dfda316c34d47afe697",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2109-01827",
                    "ArXiv": "2109.01827",
                    "DOI": "10.1109/icra46639.2022.9812253",
                    "CorpusId": 237263205
                },
                "corpusId": 237263205,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dbe41b7715078917c2f65dfda316c34d47afe697",
                "title": "GOHOME: Graph-Oriented Heatmap Output for future Motion Estimation",
                "abstract": "In this paper, we propose GOHOME, a method leveraging graph representations of the High Definition Map and sparse projections to generate a heatmap output representing the future position probability distribution for a given agent in a traffic scene. This heatmap output yields an unconstrained 2D grid representation of agent future possible locations, allowing inherent multimodality and a measure of the uncertainty of the prediction. Our graph-oriented model avoids the high computation burden of representing the surrounding context as squared images and processing it with classical CNNs, but focuses instead only on the most probable lanes where the agent could end up in the immediate future. GOHOME reaches 2nd on Argoverse Motion Forecasting Benchmark on the Misskate6metric while achieving significant speed-up and memory burden diminution compared to Argoverse 1st place method HOME. We also highlight that heatmap output enables multimodal ensembling and improve 1st place MissRate6by more than 15% with our best ensemble on Argoverse. Finally, we evaluate and reach state-of-the-art performance on the other trajectory prediction datasets nuScenes and Interaction, demonstrating the generalizability of our method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "15023249",
                        "name": "Thomas Gilles"
                    },
                    {
                        "authorId": "2070460335",
                        "name": "S. Sabatini"
                    },
                    {
                        "authorId": "47102249",
                        "name": "D. Tsishkou"
                    },
                    {
                        "authorId": "2593406",
                        "name": "B. Stanciulescu"
                    },
                    {
                        "authorId": "1748488",
                        "name": "F. Moutarde"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "We propose an architecture that considers long-term goals similar to [9, 5, 3, 4] but adds a key component of frame-wise intention estimation which is used to condition the trajectory prediction module.",
                "There have been numerous subtopics of interest within the trajectory prediction community including compliant trajectory prediction, multi-modal trajectory prediction, and goal-oriented prediction [21, 22, 23, 24, 25, 3, 9, 26, 4, 27, 28, 29, 30, 7, 31, 5].",
                "The study of human behavior as goal-directed entities has a long and rich interdisciplinary history across the subfields of psychology [1], neuroscience [2] and computer vision [3].",
                "Second, we see a similar trend in multi-shot prediction setting as well with our model outperforming PECNet by 33% in ADE and 9% in FDE for pedestrians and a delta of 26% in ADE and 13% in FDE for moving vehicles.",
                "We benchmark against PECNet [3], a strong scene agnostic trajectory prediction method with state-of-the-art performance on standard intention agnostic prediction datasets.",
                "Because humans are not completely stochastic agents and have a predilection towards certain actions, very recent trajectory forecasting studies have shown the effectiveness of goalconditioned predictions [38, 28, 9, 3, 39, 7, 40, 4, 5, 41].",
                "Many recent goal-directed works have focused on modeling this through estimating final \u201dendpoint\u201d or \u201dgoal state\u201d distributions as done in [9, 3, 5, 28, 4].",
                "Recent works have showed that explicitly reasoning about long-term goals [3, 4, 5] and short-term intents [6, 7, 8] can assist with tra-"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2899f5a1a706028b44dd6fdeaf67367d2c3bd3c0",
                "externalIds": {
                    "DBLP": "conf/iccv/GiraseGM0KMC21",
                    "ArXiv": "2108.08236",
                    "DOI": "10.1109/ICCV48922.2021.00966",
                    "CorpusId": 237194689
                },
                "corpusId": 237194689,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/2899f5a1a706028b44dd6fdeaf67367d2c3bd3c0",
                "title": "LOKI: Long Term and Key Intentions for Trajectory Prediction",
                "abstract": "Recent advances in trajectory prediction have shown that explicit reasoning about agents\u2019 intent is important to accurately forecast their motion. However, the current research activities are not directly applicable to intelligent and safety critical systems. This is mainly because very few public datasets are available, and they only consider pedestrian-specific intents for a short temporal horizon from a restricted egocentric view. To this end, we propose LOKI (LOng term and Key Intentions), a novel large-scale dataset that is designed to tackle joint trajectory and intention prediction for heterogeneous traffic agents (pedestrians and vehicles) in an autonomous driving setting. The LOKI dataset is created to discover several factors that may affect intention, including i) agent\u2019s own will, ii) social interactions, iii) environmental constraints, and iv) contextual information. We also propose a model that jointly performs trajectory and intention prediction, showing that recurrently reasoning about intention can assist with trajectory prediction. We show our method outperforms state-of-the-art trajectory prediction methods by upto 27% and also provide a baseline for frame-wise intention estimation. The dataset is available at https://usa.honda-ri.com/loki",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1612131148",
                        "name": "Harshayu Girase"
                    },
                    {
                        "authorId": "81021298",
                        "name": "Haiming Gang"
                    },
                    {
                        "authorId": "51128743",
                        "name": "Srikanth Malla"
                    },
                    {
                        "authorId": "2125031571",
                        "name": "Jiachen Li"
                    },
                    {
                        "authorId": "67300253",
                        "name": "Akira Kanehara"
                    },
                    {
                        "authorId": "11379939",
                        "name": "K. Mangalam"
                    },
                    {
                        "authorId": "37435569",
                        "name": "Chiho Choi"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "For the models targeting multi-class trajectory prediction either discard the other class data as in [10], [16] or treats all trajectories as a single class as in [10], [17]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dbdd71ab08279592a49270728acd66a4e48e293c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-04740",
                    "MAG": "3187244581",
                    "ArXiv": "2108.04740",
                    "DOI": "10.1109/SMC52423.2021.9658781",
                    "CorpusId": 236965593
                },
                "corpusId": 236965593,
                "publicationVenue": {
                    "id": "e84bb5a1-8f79-42cc-8eb1-3a52f7c73d63",
                    "name": "IEEE International Conference on Systems, Man and Cybernetics",
                    "type": "conference",
                    "alternate_names": [
                        "Smoky Mountains Computational Sciences and Engineering Conference",
                        "Smoky Mt Comput Sci Eng Conf",
                        "IEEE Int Conf Syst Man Cybern",
                        "SMC",
                        "Syst Man Cybern",
                        "Systems, Man and Cybernetics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dbdd71ab08279592a49270728acd66a4e48e293c",
                "title": "Semantics-STGCNN: A Semantics-guided Spatial-Temporal Graph Convolutional Network for Multi-class Trajectory Prediction",
                "abstract": "Predicting the movement trajectories of multiple classes of road users in real-world scenarios is a challenging task due to the diverse trajectory patterns. While recent works of pedestrian trajectory prediction successfully modelled the influence of surrounding neighbours based on the relative distances, they are ineffective on multi-class trajectory prediction. This is because they ignore the impact of the implicit correlations between different types of road users on the trajectory to be predicted\u2014for example, a nearby pedestrian has a different level of influence from a nearby car. In this paper, we propose to introduce class information into a graph convolutional neural network to better predict the trajectory of an individual. We embed the class labels of the surrounding objects into the label adjacency matrix (LAM), which is combined with the velocity-based adjacency matrix (VAM) comprised of the objects\u2019 velocity, thereby generating a semantics-guided graph adjacency (SAM). SAM effectively models semantic information with trainable parameters to automatically learn the embedded label features that will contribute to the fixed velocity-based trajectory. Such information of spatial and temporal dependencies is passed to a graph convolutional and temporal convolutional network to estimate the predicted trajectory distributions. We further propose new metrics, known as Average2 Displacement Error (aADE) and Average Final Displacement Error (aFDE), that assess network accuracy more accurately. We call our framework Semantics-STGCNN. It consistently shows superior performance to the state-of-the-arts in existing and the newly proposed metrics.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1484781704",
                        "name": "Benjamin Rainbow"
                    },
                    {
                        "authorId": "40953181",
                        "name": "Qianhui Men"
                    },
                    {
                        "authorId": "2840036",
                        "name": "Hubert P. H. Shum"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "[19] propose the endpoint conditioned trajectory prediction method, and they try to address agents\u2019 random endpoint choices by gathering scene segmentation maps and agents\u2019 historical trajectories in [39].",
                "Although some models have tried to improve and use specific sampling methods, like the Truncation Trick [19] and the Test-Time Sampling Trick [39], using a \u201csingle\u201d",
                "Although some models have tried to improve and use specific sampling methods, like the Truncation Trick [19] and the Test-Time Sampling Trick [39], using a \u201csingle\u201d\ndistribution to describe the diverse and differentiated behavioral characteristics of agents may compress their personalized styles.",
                "Several researchers [19], [39]\u2013[43] have started to bring them to the trajectory prediction task to explore agents\u2019 multiple future choices."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0dfdd17764a47b9b1af2c3924e8e52d16c6c8753",
                "externalIds": {
                    "DBLP": "journals/tits/WongXPYY23",
                    "ArXiv": "2107.00932",
                    "DOI": "10.1109/TITS.2023.3274777",
                    "CorpusId": 235727436
                },
                "corpusId": 235727436,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0dfdd17764a47b9b1af2c3924e8e52d16c6c8753",
                "title": "MSN: Multi-Style Network for Trajectory Prediction",
                "abstract": "Trajectory prediction aims to forecast agents\u2019 possible future locations considering their observations along with the video context. It is strongly needed by many autonomous platforms like tracking, detection, robot navigation, and self-driving cars. Whether it is agents\u2019 internal personality factors, interactive behaviors with the neighborhood, or the influence of surroundings, they all impact agents\u2019 future planning. However, many previous methods model and predict agents\u2019 behaviors with the same strategy or feature distribution, making them challenging to make predictions with sufficient style differences. This paper proposes the Multi-Style Network (MSN), which utilizes style proposal and stylized prediction using two sub-networks, to provide multi-style predictions in a novel categorical way adaptively. The proposed network contains a series of style channels, and each channel is bound to a unique and specific behavior style. We use agents\u2019 end-point plannings and their interaction context as the basis for the behavior classification, so as to adaptively learn multiple diverse behavior styles through these channels. Then, we assume that the target agents may plan their future behaviors according to each of these categorized styles, thus utilizing different style channels to make predictions with significant style differences in parallel. Experiments show that the proposed MSN outperforms current state-of-the-art methods up to 10% quantitatively on two widely used datasets, and presents better multi-style characteristics qualitatively.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1991582869",
                        "name": "Conghao Wong"
                    },
                    {
                        "authorId": "1561145507",
                        "name": "Beihao Xia"
                    },
                    {
                        "authorId": "2647338",
                        "name": "Qinmu Peng"
                    },
                    {
                        "authorId": "65891191",
                        "name": "Wei Yuan"
                    },
                    {
                        "authorId": "1744228",
                        "name": "Xinge You"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "245d10b95423e1cb4ae755e919d996e65a62eac8",
                "externalIds": {
                    "ArXiv": "2106.13201",
                    "DBLP": "journals/pami/LiCC23",
                    "DOI": "10.1109/TPAMI.2023.3294305",
                    "CorpusId": 252762244,
                    "PubMed": "37432803"
                },
                "corpusId": 252762244,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/245d10b95423e1cb4ae755e919d996e65a62eac8",
                "title": "DROID: Driver-Centric Risk Object Identification",
                "abstract": "Identification of high-risk driving situations is generally approached through collision risk estimation or accident pattern recognition. In this work, we approach the problem from the perspective of subjective risk. We operationalize subjective risk assessment by predicting driver behavior changes and identifying the cause of changes. To this end, we introduce a new task called driver-centric risk object identification (DROID), which uses egocentric video to identify object(s) influencing a driver's behavior, given only the driver's response as the supervision signal. We formulate the task as a cause-effect problem and present a novel two-stage DROID framework, taking inspiration from models of situation awareness and causal inference. A subset of data constructed from the Honda Research Institute Driving Dataset (HDD) is used to evaluate DROID. We demonstrate state-of-the-art DROID performance, even compared with strong baseline models using this dataset. Additionally, we conduct extensive ablative studies to justify our design choices. Moreover, we demonstrate the applicability of DROID for risk assessment.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2145582123",
                        "name": "Chengxi Li"
                    },
                    {
                        "authorId": "1717715",
                        "name": "Stanley H. Chan"
                    },
                    {
                        "authorId": "2109060286",
                        "name": "Yi-Ting Chen"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Grid-based outputs have already been used in pedestrian behavior prediction such as [13, 7, 18, 10, 26]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6562e258e43a0fbc3622dc6353afd7c3251977c8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2105-10968",
                    "ArXiv": "2105.10968",
                    "DOI": "10.1109/itsc48978.2021.9564944",
                    "CorpusId": 235166650
                },
                "corpusId": 235166650,
                "publicationVenue": {
                    "id": "17b6641a-6ee7-414d-8de5-997ba376f619",
                    "name": "International Conference on Intelligent Transportation Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Intell Transp Syst",
                        "ITSC"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6562e258e43a0fbc3622dc6353afd7c3251977c8",
                "title": "HOME: Heatmap Output for future Motion Estimation",
                "abstract": "In this paper, we propose HOME, a framework tackling the motion forecasting problem with an image output representing the probability distribution of the agent's future location. This method allows for a simple architecture with classic convolution networks coupled with attention mechanism for agent interactions, and outputs an unconstrained 2D top-view representation of the agent's possible future. Based on this output, we design two methods to sample a finite set of agent's future locations. These methods allow us to control the optimization trade-off between miss rate and final displacement error for multiple modalities without having to retrain any part of the model. We apply our method to the Argoverse Motion Forecasting Benchmark and achieve 1st place on the online leaderboard.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "15023249",
                        "name": "Thomas Gilles"
                    },
                    {
                        "authorId": "2070460335",
                        "name": "S. Sabatini"
                    },
                    {
                        "authorId": "47102249",
                        "name": "D. Tsishkou"
                    },
                    {
                        "authorId": "2593406",
                        "name": "B. Stanciulescu"
                    },
                    {
                        "authorId": "1748488",
                        "name": "F. Moutarde"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "[24, 25] propose an endpoint conditioned prediction scheme which conditions pedestrian predictions on goal destinations."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bfc52b367265855eac929c9aeb06b5e8a6b27bec",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2104-14679",
                    "ArXiv": "2104.14679",
                    "CorpusId": 233476353
                },
                "corpusId": 233476353,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/bfc52b367265855eac929c9aeb06b5e8a6b27bec",
                "title": "Physically Feasible Vehicle Trajectory Prediction",
                "abstract": "Predicting the future motion of actors in a traffic scene is a crucial part of any autonomous driving system. Recent research in this area has focused on trajectory prediction approaches that optimize standard trajectory error metrics. In this work, we describe three important properties -- physical realism guarantees, system maintainability, and sample efficiency -- which we believe are equally important for developing a self-driving system that can operate safely and practically in the real world. Furthermore, we introduce PTNet (PathTrackingNet), a novel approach for vehicle trajectory prediction that is a hybrid of the classical pure pursuit path tracking algorithm and modern graph-based neural networks. By combining a structured robotics technique with a flexible learning approach, we are able to produce a system that not only achieves the same level of performance as other state-of-the-art methods on traditional trajectory error metrics, but also provides strong guarantees about the physical realism of the predicted trajectories while requiring half the amount of data. We believe focusing on this new class of hybrid approaches is an useful direction for developing and maintaining a safety-critical autonomous driving system.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1612131148",
                        "name": "Harshayu Girase"
                    },
                    {
                        "authorId": "150148498",
                        "name": "Jerrick Hoang"
                    },
                    {
                        "authorId": "70632991",
                        "name": "S. Yalamanchi"
                    },
                    {
                        "authorId": "1405520861",
                        "name": "Micol Marchetti-Bowick"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Subsequent work [18], [19] has reported results on a subset of trajectories primarily consisting of pedestrians.",
                "However, the recently proposed Y-Net [19] achieves lower MinADEK and MinFDEK values.",
                "Several recent works thus incorporate inductive bias into the predicted modes by conditioning on agent goals [17]\u2013[19], lane center-lines [20]\u2013[22] or anchor trajectories [23], [24]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6a4910ceb1a9e1f8b924ec4b45e0d55573c6f6e5",
                "externalIds": {
                    "MAG": "2997264916",
                    "ArXiv": "2001.00735",
                    "DBLP": "journals/corr/abs-2001-00735",
                    "CorpusId": 209832529
                },
                "corpusId": 209832529,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6a4910ceb1a9e1f8b924ec4b45e0d55573c6f6e5",
                "title": "Trajectory Forecasts in Unknown Environments Conditioned on Grid-Based Plans",
                "abstract": "In this paper, we address the problem of forecasting agent trajectories in unknown environments, conditioned on their past motion and scene structure. Trajectory forecasting is a challenging problem due to the large variation in scene structure, and the multi-modal nature of the distribution of future trajectories. Unlike prior approaches that directly learn one-to-many mappings from observed context, to multiple future trajectories, we propose to condition trajectory forecasts on \\textit{plans} sampled from a grid based policy learned using maximum entropy inverse reinforcement learning policy (MaxEnt IRL). We reformulate MaxEnt IRL to allow the policy to jointly infer plausible agent goals and paths to those goals on a coarse 2-D grid defined over an unknown scene. We propose an attention based trajectory generator that generates continuous valued future trajectories conditioned on state sequences sampled from the MaxEnt policy. Quantitative and qualitative evaluation on the publicly available Stanford drone dataset (SDD) shows that our model generates trajectories that are (1) diverse, representing the multi-modal predictive distribution, and (2) precise, conforming to the underlying scene structure over long prediction horizons, achieving state of the art results on the TrajNet benchmark split of SDD.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "9018904",
                        "name": "Nachiket Deo"
                    },
                    {
                        "authorId": "1713989",
                        "name": "M. Trivedi"
                    }
                ]
            }
        },
        {
            "intents": [
                "methodology"
            ],
            "contexts": [
                "Y-Net [107] 2020 Stanford Drone, ETH, UCY Yes U-Net, k-means",
                "The Y-net model [107] uses the U-Net architecture [108] for the semantic segmentation of the input image."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f5d72c862d4aeabd2743682d81b0cd158cec325a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1909-07707",
                    "MAG": "3136121014",
                    "ArXiv": "1909.07707",
                    "DOI": "10.3390/math9060660",
                    "CorpusId": 233685227
                },
                "corpusId": 233685227,
                "publicationVenue": {
                    "id": "6175efe8-6f8e-4cbe-8cee-d154f4e78627",
                    "name": "Mathematics",
                    "issn": "2227-7390",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-283014",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-283014",
                        "https://www.mdpi.com/journal/mathematics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f5d72c862d4aeabd2743682d81b0cd158cec325a",
                "title": "A Review of Tracking, Prediction and Decision Making Methods for Autonomous Driving",
                "abstract": "This paper provides a literature review of some of the most important concepts, techniques, and methodologies used within autonomous car systems. Specifically, we focus on two aspects extensively explored in the related literature: tracking, i.e., identifying pedestrians, cars or obstacles from images, observations or sensor data, and prediction, i.e., anticipating the future trajectories and motion of other vehicles in order to facilitate navigating through various traffic conditions. Approaches based on deep neural networks and others, especially stochastic techniques, are reported.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2060703188",
                        "name": "Florin Leon"
                    },
                    {
                        "authorId": "48236279",
                        "name": "M. Gavrilescu"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e99f4fecd06b0b8af89a8e07de4c97caf53cc53e",
                "externalIds": {
                    "DOI": "10.4324/9780429468018-8",
                    "CorpusId": 241189217
                },
                "corpusId": 241189217,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e99f4fecd06b0b8af89a8e07de4c97caf53cc53e",
                "title": "Game",
                "abstract": ". To accurately predict trajectories in multi-agent settings, e.g. team games, it is important to effectively model the interactions among agents. Whereas a number of methods have been developed for this purpose, existing methods implicitly model these interactions as part of the deep net architecture. However, in the real world, interactions often exist at multiple levels, e.g. individuals may form groups, where interactions among groups and those among the individuals in the same group often follow significantly different patterns. In this paper, we present a novel formulation for multi-agent trajectory prediction, which explicitly introduces the concept of interactive group consensus via an interactive hierarchical latent space. This formulation allows group-level and individual-level interactions to be captured jointly, thus substantially improving the capability of modeling complex dynamics. On two multi-agent settings, i.e. team sports and pedestrians, the proposed framework consistently achieves superior performance compared to existing methods.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "1581347696",
                        "name": "Sloan Kate"
                    }
                ]
            }
        },
        {
            "intents": [],
            "contexts": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "025a44bf059aef8b9ee2e6ca598bebefc59a4a61",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1806-11230",
                    "MAG": "2810685774",
                    "ArXiv": "1806.11230",
                    "DOI": "10.1007/s11263-022-01594-9",
                    "CorpusId": 49551723
                },
                "corpusId": 49551723,
                "publicationVenue": {
                    "id": "939ee07c-6009-43f8-b884-69238b40659e",
                    "name": "International Journal of Computer Vision",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Comput Vis"
                    ],
                    "issn": "0920-5691",
                    "url": "https://www.springer.com/computer/image+processing/journal/11263",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11263",
                        "http://link.springer.com/journal/11263"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61",
                "title": "Human Action Recognition and Prediction: A Survey",
                "abstract": null,
                "year": 2018,
                "authors": [
                    {
                        "authorId": "145873652",
                        "name": "Yu Kong"
                    },
                    {
                        "authorId": "46956675",
                        "name": "Y. Fu"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "Second, we see a similar trend in multi-shot prediction setting as well with our model outperforming PECNet by 33% in ADE and 9% in FDE for pedestrians and a delta of 26% in ADE and 13% in FDE for moving vehicles.",
                "Autonomous agent planning critically depends on anticipating the future of the scene in various forms such as trajectory prediction [30, 77, 78, 31], action forecasting [32, 28, 112] or future scene segmentation [14] and anticipating the future is a activity humans subconsciously do for day-to-day tasks [80].",
                "The study of human behavior as goal-directed entities has a long and rich interdisciplinary history across the subfields of psychology [10], neuroscience [106] and computer vision [77].",
                "There have been numerous subtopics of interest within the trajectory prediction community including compliant trajectory prediction, multi-modal trajectory prediction, and goal-oriented prediction [98, 36, 70, 77, 78, 60, 15, 3, 19, 55, 90, 120].",
                "Recent works have shown that explicitly reasoning about long-term goals [77, 15, 120] and short-term intents [71, 90, 11] can assist with trajectory prediction.",
                "We propose an architecture that considers long-term goals similar to [78, 120, 77, 15] but adds a key component of frame-wise intention estimation which is used to condition the trajectory prediction module.",
                "We benchmark against PECNet [77], a strong scene agnostic trajectory prediction method with state-of-the-art performance on standard intention agnostic prediction datasets.",
                "Because humans are not completely stochastic agents and have a predilection towards certain actions, very recent trajectory forecasting studies have shown the effectiveness of goal-conditioned predictions [92, 19, 78, 77, 116, 90, 119, 15, 120, 18].",
                "Many recent goal-directed works have focused on modeling this through estimating final \u201cendpoint\u201d or \u201cgoal state\u201d distributions as done in [78, 77, 120, 19, 15]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "f8982fa1fa350b12b2fc8ba34b32af6896566652",
                "externalIds": {
                    "CorpusId": 262233591
                },
                "corpusId": 262233591,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f8982fa1fa350b12b2fc8ba34b32af6896566652",
                "title": "Latency-Aware Short-Term Video Action Anticipation and its Application in Trajectory Prediction",
                "abstract": "Latency-Aware Short-Term Video Action Anticipation and its Application in Trajectory Prediction",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1612131148",
                        "name": "Harshayu Girase"
                    },
                    {
                        "authorId": "11379939",
                        "name": "K. Mangalam"
                    },
                    {
                        "authorId": "2244770235",
                        "name": "Jitendra Malik"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "A large number of pedestrian trajectory prediction algorithms are based on the top-down view [22], [23], [24], [25], [26], [27], [28], [29], [30]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8824803b10f363f23663dbaa8116e2bc94433cb9",
                "externalIds": {
                    "DBLP": "journals/tim/LongMM23",
                    "DOI": "10.1109/TIM.2022.3225018",
                    "CorpusId": 255598883
                },
                "corpusId": 255598883,
                "publicationVenue": {
                    "id": "3edbd5e0-8799-420a-9ca8-b35c646c354f",
                    "name": "IEEE Transactions on Instrumentation and Measurement",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Instrum Meas"
                    ],
                    "issn": "0018-9456",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=19",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8824803b10f363f23663dbaa8116e2bc94433cb9",
                "title": "Egocentric Two-Frame Pedestrian Trajectory Prediction Algorithm Based on a Panoramic Camera",
                "abstract": "With the development of service industry, service-oriented mobile robot navigation technology has received more and more attention. In order to improve the obstacle avoidance performance of service-oriented mobile robots, accurate pedestrian trajectory prediction is essential. Therefore, we propose an egocentric two-frame pedestrian trajectory prediction algorithm based on a panoramic camera, the future social prediction (FSP) algorithm, to solve the pedestrian trajectory prediction problem in the human\u2013robot coexistence environment. The input of FSP is the information in the two frames of a panoramic camera. First, the free pedestrian prediction network (FPPN) is used to predict the free movement of pedestrians. Then, the future social pooling module (FSPM) is used to process the prediction results of FPPN. Finally, the social pedestrian prediction network (SPPN) combines the frame information with the output of FSPM to get the final prediction results. A panoramic camera is used as a sensor to reduce blind spots in the field of view. Only two frames are used for prediction to improve the real-time performance of FSP. We record the panoramic video and create a dataset. FSP is tested on our dataset with other two algorithms, and the results show that FSP has a better performance than spatio-temporal encoder\u2013decoder (STED) model and future person localization (FPL).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2199967309",
                        "name": "Juncen Long"
                    },
                    {
                        "authorId": "48414023",
                        "name": "Jie Mei"
                    },
                    {
                        "authorId": "47955233",
                        "name": "Guangfu Ma"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "adversarial networks (GANs) [15], [16], [17], [18] and the Variational AutoEncoder (VAE) [19], [20], [21], [22], which could generate diversity trajectories that are conformed to social rules."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5b42682b9860d4c605af938bbac3bb6f723cb936",
                "externalIds": {
                    "DBLP": "journals/tim/LvY23",
                    "DOI": "10.1109/TIM.2023.3283544",
                    "CorpusId": 259217456
                },
                "corpusId": 259217456,
                "publicationVenue": {
                    "id": "3edbd5e0-8799-420a-9ca8-b35c646c354f",
                    "name": "IEEE Transactions on Instrumentation and Measurement",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Instrum Meas"
                    ],
                    "issn": "0018-9456",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=19",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5b42682b9860d4c605af938bbac3bb6f723cb936",
                "title": "SKGACN: Social Knowledge-Guided Graph Attention Convolutional Network for Human Trajectory Prediction",
                "abstract": "Pedestrian trajectory prediction is crucial in driverless applications. To accurately predict the high-quality trajectory of pedestrians, it is necessary to consider the reasonable social interaction and the spatiotemporal relationships between pedestrians. Previous methods could not accurately capture the social features of pedestrians in realistic congested situations and extract spatiotemporal interaction features with high computation. Therefore, in this article, a novel prediction model is proposed, called the social knowledge-guided graph attention convolutional network (SKGACN), which aims to address the social interactions and the spatiotemporal relationships between pedestrians with low computational requirements. Specifically, the social knowledge-guided graph attention mechanism fully considers multiple information relative to pedestrians to capture their social interaction. For spatiotemporal interactions, an improved temporal convolution network (TCN) model is used as it can parallelize the processing times to get a higher efficiency compared to traditional models. Compared to the state-of-the-art methods, we evaluate our proposed method after applying it on two public datasets (ETH and UCY). The experimental results show that our method performs better in terms of average displacement error (ADE) and final displacement error (FDE) metrics.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2055634356",
                        "name": "Kai Lv"
                    },
                    {
                        "authorId": "2089025639",
                        "name": "Liang Yuan"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "The segmantation maps are byproducts of the GSN from [1].",
                "During testing, instead of picking the position with highest probability, we adopt the test-time sampling trick (TTST) introduced by [1] to sample goals for better performance.",
                "8 seconds which is widely used to evaluate trajectory predictions [2,1,4].",
                "Details of these two U-nets can be found in [1].",
                "Y-net is worse than S-CSR and NSP.",
                "5 to get 20 frames, where the first 8 frames are used as input for Y-net [1] and S-CSR [4].",
                "The remaining 12 frames and the predictions (12 frames) of Y-net and S-CSR are used to calculate the collision rate.",
                "For each interval (8 seconds long), we subsample at FPS = 2.5 to get 20 frames, where the first 8 frames are used as input for Y-net [1] and S-CSR [4].",
                "Figure 2 demonstrates that our method (NSP) has better performance in avoiding collisions than Y-net and S-CSR.",
                "The detailed network architecture of two U-nets, Useg and Ugoal, can be found in [1]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0d1e9e2c446f752862a547b29243b7dd102f28f4",
                "externalIds": {
                    "CorpusId": 253528043
                },
                "corpusId": 253528043,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0d1e9e2c446f752862a547b29243b7dd102f28f4",
                "title": "Human Trajectory Prediction via Neural Social Physics-Supplementary Material",
                "abstract": "We use the collision rate to evaluate prediction plausibility. We first elaborate on the definition of the collision rate and then show more experimental results. Provided there are N agents in a scene, we consider their collision rates during a period of time such as 4.8 seconds which is widely used to evaluate trajectory predictions [2,1,4]. We count one collision if the minimum distance between two agents is smaller than 2r at any time, where r is the radius of a disc representing an agent. The maximum possible number of collisions is N(N \u2212 1)/2. The final collision rate is defined as:",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2178356020",
                        "name": "Jiangbei Yue"
                    },
                    {
                        "authorId": "1699159",
                        "name": "Dinesh Manocha"
                    },
                    {
                        "authorId": "2149698569",
                        "name": "He Wang"
                    }
                ]
            }
        },
        {
            "intents": [
                "background",
                "methodology"
            ],
            "contexts": [
                "When comparing the median ADE from PTPC to the second-best median ADE from Y-net (CWS), we observe \u2248 5% improvement.",
                "Y-net [57] takes the approach of modeling the distribution of specific key points in the path, denoted as waypoints, in the form of spatial probability maps and subsequently using the heatmap representations of the waypoint samples to interpolate the full trajectory.",
                "During inference, [57] propose the use of the Test-Time Sampling Trick (TTST) and ConditionedWaypoint sampling (CWS).",
                "We adapt GoalGAN, PECNet, andY-net to our task setting, which we then use as baselines for benchmarking performance on the task of trajectory prediction on the Talk2CarTrajectory.",
                "Following the U-Net style decoder approach used in Y-net [57], the concatenated features and waypoint heatmaps",
                "Additionally, when we compare with the second-best median FDE from Y-net (TTST + CWS), we observe an improvement of \u2248 14%.",
                "In addition to our own model, we adapt the following baselines for our task setting: A, CNN, LSTM, GoalGAN [53], PECNet [55], Y-net [57], and evaluate their performance on the metrics defined in V-B.",
                "We thus used the\n123820 VOLUME 10, 2022\nText2Conv method in the base version of the PTPC and the Y-net model featured in Table 1.",
                "the command representation into the path prediction pipeline and interpolating the full trajectory from the samples of key locations along the path, inspired by [57], resulting in amodel that achieves state-of-the-art performance on our task setting.",
                "Figure 13 showcases an example where PTPC more readily captures the distributions of waypoints during a U-turn than Y-net.",
                "Y-net [57] features a U-Net style encoder-decoder architecture with skip connections and two decoder subnetworks.",
                "Following the U-Net style decoder approach used in Y-net [57], the concatenated features and waypoint heatmaps\nVOLUME 10, 2022 123815\nfrom the lowest resolution scale are upsampled to the size of the subsequent, higher resolution scale using bilinear interpolation followed by a convolutional layer.",
                "D. TRAJECTORY PREDICTION BASELINES In addition to our own model, we adapt the following baselines for our task setting: A\u2217, CNN, LSTM, GoalGAN [53], PECNet [55], Y-net [57], and evaluate their performance on the metrics defined in V-B.",
                "Unlike in the works of [55] and [57], we do not take the minimum distance among all pairs of predicted and ground truth paths when evaluating the model\u2019s performance on a particular sample.",
                "In the case of PTPC and Y-net, we predict three goals per command and three trajectories per goal, resulting in nine trajectories.",
                "In the case of Y-net, we also evaluate the use of TTST, CWS, and the combination of the two during inference.",
                "It first predicts the waypoints that indicate key locations along the trajectory, as per [57]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2878b7c77f1f303994d9b18f414b0fcf780b0f91",
                "externalIds": {
                    "DBLP": "journals/access/DeruyttereGBM22",
                    "DOI": "10.1109/ACCESS.2022.3224144",
                    "CorpusId": 253935673
                },
                "corpusId": 253935673,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2878b7c77f1f303994d9b18f414b0fcf780b0f91",
                "title": "Talk2Car: Predicting Physical Trajectories for Natural Language Commands",
                "abstract": "In recent years, there has been an increased interest in giving verbal commands to self-driving cars. Even though multiple companies have showcased progress towards fully autonomous vehicles, surveys have indicated that people are wary of relinquishing total control of the vehicle to the AI. Thus, a system allowing passengers to control the vehicle\u2019s actions would be preferable. Natural language, the most widespread form of communication among humans, presents itself as the most natural control interface, and survey results confirm that the ability to give verbal commands to self-driving vehicles would make the passengers more at ease. In this work, we propose a novel system that predicts which object is referred to by the issued command and the path the car should follow through the immediate surroundings to execute the command. We experiment with different approaches and features to predict the object of interest and show that our simple but effective approach achieves state-of-the-art performance. For predicting the trajectory, we propose a model that relies on a mixture density approach for modeling the distributions of key waypoints of the trajectory in the top-down scene layout. Additionally, we investigate the influence of the two tasks on each other and show that improvements in the prediction of the object of interest lead to improvements in the trajectory prediction task. Finally, we provide the research community with an extension to the Talk2Car dataset, with new trajectory annotations for given commands.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1388019217",
                        "name": "Thierry Deruyttere"
                    },
                    {
                        "authorId": "1388019229",
                        "name": "Dusan Grujicic"
                    },
                    {
                        "authorId": "1758219",
                        "name": "Matthew B. Blaschko"
                    },
                    {
                        "authorId": "100781843",
                        "name": "Marie-Francine Moens"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "This section has been referenced from the original paper [9] (Section 3).",
                "The following paper is a reproducibility report for From Goals, Waypoints & Paths To Long Term Human Trajectory 2 Forecasting [9].",
                "Reproducibility report of From goals, waypoints & paths to longterm human trajectory forecasting for ML Reproducibility\nChallenge 2021\nAnonymous Author(s) Affiliation Address email\nScope of Reproducibility1\nThe following paper is a reproducibility report for From Goals, Waypoints & Paths To Long Term Human Trajectory2 Forecasting [9]."
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "cb7fabae1a4f0b4009c73882e5208c1538a40c1a",
                "externalIds": {
                    "CorpusId": 247516704
                },
                "corpusId": 247516704,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/cb7fabae1a4f0b4009c73882e5208c1538a40c1a",
                "title": "Reproducibility report of From goals , waypoints & paths to longterm human trajectory forecasting for ML Reproducibility Challenge 2021",
                "abstract": "The following paper is a reproducibility report for From Goals, Waypoints & Paths To Long Term Human Trajectory 2 Forecasting [9]. The basic code was made available by the author at this https url. We have verified all claims and 3 results from the experiments mentioned in the paper to support the claims. The central claim of YNet is that it sets 4 state-of-the-art short and long-term prediction standards by a multi-modal network employing both segmentation 5 matrices and past trajectory heat-maps together. 6",
                "year": 2022,
                "authors": []
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Several works also leverage top-down images explicitly, whether in an RGB form or with added semantic segmentation [6], [21], [22]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "80ab9c8eec82a1ea771860bf6c0e19b5bef5b280",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-11294",
                    "DOI": "10.48550/arXiv.2209.11294",
                    "CorpusId": 252519276
                },
                "corpusId": 252519276,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/80ab9c8eec82a1ea771860bf6c0e19b5bef5b280",
                "title": "T2FPV: Constructing High-Fidelity First-Person View Datasets From Real-World Pedestrian Trajectories",
                "abstract": "\u2014Predicting pedestrian motion is essential for de- veloping socially-aware robots that interact in a crowded environment. While the natural visual perspective for a social interaction setting is an egocentric view, the majority of existing work in trajectory prediction has been investigated purely in the top-down trajectory space. To support \ufb01rst-person view trajectory prediction research, we present T2FPV, a method for constructing high-\ufb01delity \ufb01rst-person view datasets given a real-world, top-down trajectory dataset; we showcase our approach on the ETH/UCY pedestrian dataset to generate the egocentric visual data of all interacting pedestrians. We report that the bird\u2019s-eye view assumption used in the original ETH/UCY dataset, i.e., an agent can observe everyone in the scene with perfect information, does not hold in the \ufb01rst-person views; only a fraction of agents are fully visible during each 20-timestep scene used commonly in existing work. We evaluate existing trajectory prediction approaches under varying levels of realistic perception\u2014displacement errors suffer a 356% increase compared to the top-down, perfect information setting. To promote research in \ufb01rst-person view trajectory prediction, we release our T2FPV-ETH dataset and software tools \u00a7 .",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2037889761",
                        "name": "Ben Stoler"
                    },
                    {
                        "authorId": "1470729020",
                        "name": "Meghdeep Jana"
                    },
                    {
                        "authorId": "2806202",
                        "name": "Soonmin Hwang"
                    },
                    {
                        "authorId": "143904954",
                        "name": "Jean Oh"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "Most of them only focus on multi-future path prediction [42, 44, 26, 36], and evaluate the model by picking the best out of several predicted paths.",
                "Most works in this context predict multiple future trajectories and choose the best to assess their accuracy and performance [42, 26, 36]."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "77eb136468856e758e838d019ecdf63967f521d3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-08057",
                    "DOI": "10.48550/arXiv.2210.08057",
                    "CorpusId": 252918026
                },
                "corpusId": 252918026,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/77eb136468856e758e838d019ecdf63967f521d3",
                "title": "Pishgu: Universal Path Prediction Architecture through Graph Isomorphism and Attentive Convolution",
                "abstract": "Path prediction is an essential task for several real-world real-time applications, from autonomous driving and video surveillance to environmental monitoring. Most existing approaches are computation-intensive and only target a nar-row domain (e.g., a speci\ufb01c point of view for a particular subject). However, many real-time applications demand a universal path predictor that can work across different subjects (vehicles, pedestrians), perspectives (bird\u2019s-eye, high-angle), and scenes (sidewalk, highway). This article proposes Pishgu, a universal graph isomorphism approach for attentive path prediction that accounts for environmental challenges. Pishgu captures the inter-dependencies within the subjects in each frame by taking advantage of Graph Isomorphism Networks. In addition, an attention module is adopted to represent the intrinsic relations of the subjects of interest with their surroundings. We evaluate the adaptability of our approach to multiple publicly available vehicle (bird\u2019s-eye view) and pedestrian (bird\u2019s-eye and high-angle view) path prediction datasets. Pishgu\u2019s universal solution outperforms existing domain-focused methods by producing state-of-the-art results for vehicle bird\u2019s-eye view by 42% and 61% and pedestrian high-angle views by 23% and 22% in terms of ADE and FDE, respectively. Moreover, we ana-lyze the domain-speci\ufb01c details for various datasets to understand their effect on path prediction and model interpre-tation. Although our model is a single solution for path prediction problems and de\ufb01nes a new standard in multiple domains, it still comparable to state-of-the-art",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2152021044",
                        "name": "Ghazal Alinezhad Noghre"
                    },
                    {
                        "authorId": "79354862",
                        "name": "Vinit Katariya"
                    },
                    {
                        "authorId": "2152020939",
                        "name": "Armin Danesh Pazho"
                    },
                    {
                        "authorId": "2059566339",
                        "name": "Christopher Neff"
                    },
                    {
                        "authorId": "1808141",
                        "name": "H. Tabkhi"
                    }
                ]
            }
        },
        {
            "intents": [
                "background"
            ],
            "contexts": [
                "The intent is defined by a variety of 53 choices, including driving maneuvers [4, 21, 22], goal locations or waypoints [6, 8, 23, 24, 25, 26], 54 and target lanes [7, 27, 28, 29], etc."
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9da549c0c1dfefda010fc866d29cae8b5dd78f68",
                "externalIds": {
                    "CorpusId": 237263341
                },
                "corpusId": 237263341,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/9da549c0c1dfefda010fc866d29cae8b5dd78f68",
                "title": "DeepHybrid: Learned Hybrid Trajectory Prediction via Factored Inference and Adaptive Sampling",
                "abstract": "Abstract: Understanding high-level intent is important for trajectory prediction, 1 a complex multi-modal problem due to uncertainty in human intent. Existing ap2 proaches explore the discrete nature of human intent before predicting continuous 3 trajectories, to improve accuracy and support explainability, yet they often assume 4 a fixed intent over time. In this work, we introduce DeepHybrid, a general and 5 expressive hybrid prediction framework. By modeling traffic agents as a hybrid 6 discrete-continuous system, our approach is capable of predicting discrete intent 7 changes over time. We learn the probabilistic hybrid model as a maximum like8 lihood estimation problem and leverage neural proposal distributions to sequen9 tially sample from the exponentially growing discrete space. The overall approach 10 affords a better trade-off between accuracy and coverage. We train and validate 11 our model on the Argoverse dataset, and demonstrate its effectiveness through 12 comprehensive ablation studies and comparisons with state-of-the-art models. 13",
                "year": 2021,
                "authors": []
            }
        }
    ]
}