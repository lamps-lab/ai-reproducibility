{
    "offset": 0,
    "data": [
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "a3be1524e2295b6b4a90b751b22b04e16ee37a5e",
                "externalIds": {
                    "DBLP": "journals/pr/ShaoXRWCLM23",
                    "DOI": "10.2139/ssrn.4339657",
                    "CorpusId": 256479596
                },
                "corpusId": 256479596,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a3be1524e2295b6b4a90b751b22b04e16ee37a5e",
                "title": "Video anomaly detection with NTCN-ML: A novel TCN for multi-instance learning",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1742219536",
                        "name": "Wenhao Shao"
                    },
                    {
                        "authorId": "9706112",
                        "name": "Ruliang Xiao"
                    },
                    {
                        "authorId": "8979439",
                        "name": "P. Rajapaksha"
                    },
                    {
                        "authorId": "2145364607",
                        "name": "Mengzhu Wang"
                    },
                    {
                        "authorId": "145107973",
                        "name": "N. Crespi"
                    },
                    {
                        "authorId": "2114938960",
                        "name": "Z. Luo"
                    },
                    {
                        "authorId": "1980601",
                        "name": "R. Minerva"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "66359076cf77f52dd2f737849e5d8efcf2b5bce3",
                "externalIds": {
                    "DOI": "10.1016/j.engappai.2023.107057",
                    "CorpusId": 261565867
                },
                "corpusId": 261565867,
                "publicationVenue": {
                    "id": "1a24ea21-4c37-41d8-9e76-ab802d4afb3e",
                    "name": "Engineering applications of artificial intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "Eng appl artif intell",
                        "Eng Appl Artif Intell",
                        "Engineering Applications of Artificial Intelligence"
                    ],
                    "issn": "0952-1976",
                    "url": "http://www.sciencedirect.com/science/journal/09521976"
                },
                "url": "https://www.semanticscholar.org/paper/66359076cf77f52dd2f737849e5d8efcf2b5bce3",
                "title": "Video anomaly detection based on cross-frame prediction mechanism and spatio-temporal memory-enhanced pseudo-3D encoder",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2189031977",
                        "name": "Xiaopeng Wen"
                    },
                    {
                        "authorId": "9674992",
                        "name": "Huicheng Lai"
                    },
                    {
                        "authorId": "1571403632",
                        "name": "Guxue Gao"
                    },
                    {
                        "authorId": "2175451307",
                        "name": "Yang Xiao"
                    },
                    {
                        "authorId": "2216504430",
                        "name": "Tongguan Wang"
                    },
                    {
                        "authorId": "144094780",
                        "name": "Zhen Jia"
                    },
                    {
                        "authorId": "2238123709",
                        "name": "Liejun Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The third group includes one-class classification methods that assume the availability of only normal training data (Liu et al., 2021; Lv et al., 2021; Park et al., 2020).",
                "one-class classification (OOC) (Liu et al., 2021; Lv et al., 2021; Park et al., 2020; Xu et al., 2019): only visual data corresponding to the normal state is used as training data, and an input test video is classified as normal or abnormal based on its deviation from the learnt",
                "Regarding VAD, we compare AnomalyCLIP against stateof-the-art methods with different supervision setups, including one-class (Park et al., 2020; Liu et al., 2021; Lv et al., 2021), unsupervised (Zaheer et al.",
                "However, OOC methods can be particularly in-e ff ective in complex real-world applications where normal activities are diverse.",
                "VAD can be addressed as an out-of-distribution detection problem, i.e . one-class classification (OOC) (Liu et al., 2021; Lv et al., 2021; Park et al., 2020; Xu et al., 2019): only visual data corresponding to the normal state is used as training data, and an input test video is classified as normal or abnormal based on its deviation from the learnt normal state."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "408772a7e41d7ac4cd60d861bcf351c328794250",
                "externalIds": {
                    "ArXiv": "2310.02835",
                    "CorpusId": 263611937
                },
                "corpusId": 263611937,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/408772a7e41d7ac4cd60d861bcf351c328794250",
                "title": "Delving into CLIP latent space for Video Anomaly Recognition",
                "abstract": "We tackle the complex problem of detecting and recognising anomalies in surveillance videos at the frame level, utilising only video-level supervision. We introduce the novel method AnomalyCLIP, the first to combine Large Language and Vision (LLV) models, such as CLIP, with multiple instance learning for joint video anomaly detection and classification. Our approach specifically involves manipulating the latent CLIP feature space to identify the normal event subspace, which in turn allows us to effectively learn text-driven directions for abnormal events. When anomalous frames are projected onto these directions, they exhibit a large feature magnitude if they belong to a particular class. We also introduce a computationally efficient Transformer architecture to model short- and long-term temporal dependencies between frames, ultimately producing the final anomaly score and class prediction probabilities. We compare AnomalyCLIP against state-of-the-art methods considering three major anomaly detection benchmarks, i.e. ShanghaiTech, UCF-Crime, and XD-Violence, and empirically show that it outperforms baselines in recognising video anomalies.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2253491572",
                        "name": "Luca Zanella"
                    },
                    {
                        "authorId": "2253482601",
                        "name": "Benedetta Liberatori"
                    },
                    {
                        "authorId": "1698103472",
                        "name": "Willi Menapace"
                    },
                    {
                        "authorId": "1753989",
                        "name": "F. Poiesi"
                    },
                    {
                        "authorId": "2253817175",
                        "name": "Yiming Wang"
                    },
                    {
                        "authorId": "2176320235",
                        "name": "Elisa Ricci"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Different memory-based auto-encoders [16, 18, 20] have been proposed to reconstruct images with features from memory bank to limit the generalization ability."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "db8845282d9b8daf09be11f2414d81dc9bf66191",
                "externalIds": {
                    "ArXiv": "2310.02576",
                    "CorpusId": 263620419
                },
                "corpusId": 263620419,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/db8845282d9b8daf09be11f2414d81dc9bf66191",
                "title": "A Prototype-Based Neural Network for Image Anomaly Detection and Localization",
                "abstract": "Image anomaly detection and localization perform not only image-level anomaly classification but also locate pixel-level anomaly regions. Recently, it has received much research attention due to its wide application in various fields. This paper proposes ProtoAD, a prototype-based neural network for image anomaly detection and localization. First, the patch features of normal images are extracted by a deep network pre-trained on nature images. Then, the prototypes of the normal patch features are learned by non-parametric clustering. Finally, we construct an image anomaly localization network (ProtoAD) by appending the feature extraction network with $L2$ feature normalization, a $1\\times1$ convolutional layer, a channel max-pooling, and a subtraction operation. We use the prototypes as the kernels of the $1\\times1$ convolutional layer; therefore, our neural network does not need a training phase and can conduct anomaly detection and localization in an end-to-end manner. Extensive experiments on two challenging industrial anomaly detection datasets, MVTec AD and BTAD, demonstrate that ProtoAD achieves competitive performance compared to the state-of-the-art methods with a higher inference speed. The source code is available at: https://github.com/98chao/ProtoAD.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2254192519",
                        "name": "Chao Huang"
                    },
                    {
                        "authorId": "2253508504",
                        "name": "Zhao Kang"
                    },
                    {
                        "authorId": "2253927573",
                        "name": "Hong Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "6237beef8df07d586c428724fa002359450c0d99",
                "externalIds": {
                    "ArXiv": "2310.01904",
                    "CorpusId": 263608923
                },
                "corpusId": 263608923,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/6237beef8df07d586c428724fa002359450c0d99",
                "title": "Beyond the Benchmark: Detecting Diverse Anomalies in Videos",
                "abstract": "Video Anomaly Detection (VAD) plays a crucial role in modern surveillance systems, aiming to identify various anomalies in real-world situations. However, current benchmark datasets predominantly emphasize simple, single-frame anomalies such as novel object detection. This narrow focus restricts the advancement of VAD models. In this research, we advocate for an expansion of VAD investigations to encompass intricate anomalies that extend beyond conventional benchmark boundaries. To facilitate this, we introduce two datasets, HMDB-AD and HMDB-Violence, to challenge models with diverse action-based anomalies. These datasets are derived from the HMDB51 action recognition dataset. We further present Multi-Frame Anomaly Detection (MFAD), a novel method built upon the AI-VAD framework. AI-VAD utilizes single-frame features such as pose estimation and deep image encoding, and two-frame features such as object velocity. They then apply a density estimation algorithm to compute anomaly scores. To address complex multi-frame anomalies, we add a deep video encoding features capturing long-range temporal dependencies, and logistic regression to enhance final score calculation. Experimental results confirm our assumptions, highlighting existing models limitations with new anomaly types. MFAD excels in both simple and complex anomaly detection scenarios.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2253461522",
                        "name": "Yoav Arad"
                    },
                    {
                        "authorId": "2253460101",
                        "name": "Michael Werman"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "3dd5f000dc758732ddc50322d427c9c17a5effeb",
                "externalIds": {
                    "ArXiv": "2309.15662",
                    "CorpusId": 263151992
                },
                "corpusId": 263151992,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3dd5f000dc758732ddc50322d427c9c17a5effeb",
                "title": "Human Kinematics-inspired Skeleton-based Video Anomaly Detection",
                "abstract": "Previous approaches to detecting human anomalies in videos have typically relied on implicit modeling by directly applying the model to video or skeleton data, potentially resulting in inaccurate modeling of motion information. In this paper, we conduct an exploratory study and introduce a new idea called HKVAD (Human Kinematic-inspired Video Anomaly Detection) for video anomaly detection, which involves the explicit use of human kinematic features to detect anomalies. To validate the effectiveness and potential of this perspective, we propose a pilot method that leverages the kinematic features of the skeleton pose, with a specific focus on the walking stride, skeleton displacement at feet level, and neck level. Following this, the method employs a normalizing flow model to estimate density and detect anomalies based on the estimated density. Based on the number of kinematic features used, we have devised three straightforward variant methods and conducted experiments on two highly challenging public datasets, ShanghaiTech and UBnormal. Our method achieves good results with minimal computational resources, validating its effectiveness and potential.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2250044420",
                        "name": "Jian Xiao"
                    },
                    {
                        "authorId": "2249489173",
                        "name": "Tianyuan Liu"
                    },
                    {
                        "authorId": "2248212471",
                        "name": "Genlin Ji"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Memory mechanism [16, 19, 20] are frequently used, memorizing the normal prototypes."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "fa3344f59100315ac95863bffbc4ad11f4c4cfe7",
                "externalIds": {
                    "DBLP": "journals/ijcisys/PeiLZS23",
                    "DOI": "10.1007/s44196-023-00328-0",
                    "CorpusId": 262058001
                },
                "corpusId": 262058001,
                "publicationVenue": {
                    "id": "bc01813d-0622-430d-a5f1-416b7332b85e",
                    "name": "International Journal of Computational Intelligence Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Comput Intell Syst"
                    ],
                    "issn": "1875-6883",
                    "url": "https://www.atlantis-press.com/journals/ijcis",
                    "alternate_urls": [
                        "http://www.tandfonline.com/loi/tcis20#.VqnnWfnhCUl"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fa3344f59100315ac95863bffbc4ad11f4c4cfe7",
                "title": "Self-Supervised Learning for Industrial Image Anomaly Detection by Simulating Anomalous Samples",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2243093096",
                        "name": "Mingjing Pei"
                    },
                    {
                        "authorId": "1870994",
                        "name": "Ningzhong Liu"
                    },
                    {
                        "authorId": "2244148449",
                        "name": "Bing Zhao"
                    },
                    {
                        "authorId": "40186176",
                        "name": "Han Sun"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[28] proposed a memory module where prototypes of normality are stored."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "d2c902e0ccb4add69d38151d79d4d45e68b80133",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-09676",
                    "ArXiv": "2309.09676",
                    "DOI": "10.48550/arXiv.2309.09676",
                    "CorpusId": 262045713
                },
                "corpusId": 262045713,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d2c902e0ccb4add69d38151d79d4d45e68b80133",
                "title": "Conditioning Latent-Space Clusters for Real-World Anomaly Classification",
                "abstract": "Anomalies in the domain of autonomous driving are a major hindrance to the large-scale deployment of autonomous vehicles. In this work, we focus on high-resolution camera data from urban scenes that include anomalies of various types and sizes. Based on a Variational Autoencoder, we condition its latent space to classify samples as either normal data or anomalies. In order to emphasize especially small anomalies, we perform experiments where we provide the VAE with a discrepancy map as an additional input, evaluating its impact on the detection performance. Our method separates normal data and anomalies into isolated clusters while still reconstructing high-quality images, leading to meaningful latent representations.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2243193425",
                        "name": "Daniel Bogdoll"
                    },
                    {
                        "authorId": "2215478156",
                        "name": "Svetlana Pavlitska"
                    },
                    {
                        "authorId": "2243014240",
                        "name": "Simon Klaus"
                    },
                    {
                        "authorId": "32244386",
                        "name": "J. M. Z\u00f6llner"
                    }
                ]
            }
        },
        {
            "contexts": [
                "It should be pointed out that the experimental results of [48], [52], [53], and [54] are the best results obtained on our equipment according to their experimental settings, because we unfortunately did not get their official results for this dataset, since we keep the experimental equipment used unchanged and follow the optimal settings of the method and believe that",
                "[49], [50], [51], [52], [53], [54], [55].",
                "SOTA methods, including AE- and GAN-based methods [9], [11], [48], [50], [51], [52], [53], [54], [55]."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "75792dccf9ee15c115b7cdedb864d18e66969810",
                "externalIds": {
                    "DOI": "10.1109/JSEN.2023.3239219",
                    "CorpusId": 256436358
                },
                "corpusId": 256436358,
                "publicationVenue": {
                    "id": "b210fd3d-11d7-478e-a0aa-7e3d2a4f482d",
                    "name": "IEEE Sensors Journal",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Sens J"
                    ],
                    "issn": "1530-437X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=7361",
                    "alternate_urls": [
                        "http://ieee-sensors.org/sensors-journal/",
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?puNumber=7361",
                        "http://www.ieee-sensors.org/journals",
                        "https://ieee-sensors.org/sensors-journal/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/75792dccf9ee15c115b7cdedb864d18e66969810",
                "title": "Memory Clustering Autoencoder Method for Human Action Anomaly Detection on Surveillance Camera Video",
                "abstract": "Unsupervised deep-learning methods with a deep clustering model are widely used to detect anomaly human actions obtained by surveillance camera due to their powerful image feature learning abilities. These methods aim to optimize a model through a clustering induction target to provide useful cluster assignment and usually use a forward propagation process: an autoencoder (AE) reconstructs an input sequence, a clustering model provides cluster allocation, and a scoring model evaluates distribution and provides scores for each sample. However, these methods have two main problems: one is that an AE is difficult to handle human posture when abnormal and normal actions occur in crowd scenes captured by a surveillance camera. The other is that network updating is interrupted by feature extraction and clustering in one epoch. To solve these problems, we design a deep memory clustering method based on graph convolution AE (MC-GCAE) to implement the real-time updating of pseudo-labels and network parameters. We also design a new loss function to express the similarity between the sample feature and the centroid feature in a memory storage module and to constrain the parameter update of a network. We evaluate the unsupervised method for three important and representative datasets mainly composed of surveillance videos and use the area under ROC curve (AUC) score as an experimental evaluation indicator.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2203456057",
                        "name": "Mingchao Yan"
                    },
                    {
                        "authorId": "2087128758",
                        "name": "Yonghua Xiong"
                    },
                    {
                        "authorId": "2119603718",
                        "name": "Jinhua She"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[10] [11] [19] [12] proposed to combine prediction with reconstruction and built a pool of prototype features for encoding normal dynamics, a few frames were also leveraged to fine-tune hyperparameters to adapt to new scenes.",
                "Existing unsupervised or weakly supervised approaches leverage either the unpredictability of human behaviors [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] or the divergence in deep features [13] [14] [15] [16] [17] [18] [19] [20] between normal and abnormal events.",
                "To generalize to novel circumstances, meta learning-based methods such as [11] [12] introduced adjustable feature representations which can adapt to new domains."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "204f10a229b67cc722f4151551edd7c40364c7c2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-03401",
                    "ArXiv": "2309.03401",
                    "DOI": "10.48550/arXiv.2309.03401",
                    "CorpusId": 261582536
                },
                "corpusId": 261582536,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/204f10a229b67cc722f4151551edd7c40364c7c2",
                "title": "Reasonable Anomaly Detection in Long Sequences",
                "abstract": "Video anomaly detection is a challenging task due to the lack in approaches for representing samples. The visual representations of most existing approaches are limited by short-term sequences of observations which cannot provide enough clues for achieving reasonable detections. In this paper, we propose to completely represent the motion patterns of objects by learning from long-term sequences. Firstly, a Stacked State Machine (SSM) model is proposed to represent the temporal dependencies which are consistent across long-range observations. Then SSM model functions in predicting future states based on past ones, the divergence between the predictions with inherent normal patterns and observed ones determines anomalies which violate normal motion patterns. Extensive experiments are carried out to evaluate the proposed approach on the dataset and existing ones. Improvements over state-of-the-art methods can be observed. Our code is available at https://github.com/AllenYLJiang/Anomaly-Detection-in-Sequences.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2238234286",
                        "name": "Yalong Jiang"
                    },
                    {
                        "authorId": "2216692129",
                        "name": "Changkang Li"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "e15d8656c255a8d3d7dc1aaf0ce3b0be4a3144cf",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-01682",
                    "ArXiv": "2309.01682",
                    "DOI": "10.48550/arXiv.2309.01682",
                    "CorpusId": 261530414
                },
                "corpusId": 261530414,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e15d8656c255a8d3d7dc1aaf0ce3b0be4a3144cf",
                "title": "Prior Knowledge Guided Network for Video Anomaly Detection",
                "abstract": "Video Anomaly Detection (VAD) involves detecting anomalous events in videos, presenting a significant and intricate task within intelligent video surveillance. Existing studies often concentrate solely on features acquired from limited normal data, disregarding the latent prior knowledge present in extensive natural image datasets. To address this constraint, we propose a Prior Knowledge Guided Network(PKG-Net) for the VAD task. First, an auto-encoder network is incorporated into a teacher-student architecture to learn two designated proxy tasks: future frame prediction and teacher network imitation, which can provide better generalization ability on unknown samples. Second, knowledge distillation on proper feature blocks is also proposed to increase the multi-scale detection ability of the model. In addition, prediction error and teacher-student feature inconsistency are combined to evaluate anomaly scores of inference samples more comprehensively. Experimental results on three public benchmarks validate the effectiveness and accuracy of our method, which surpasses recent state-of-the-arts.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2238398960",
                        "name": "Zhewen Deng"
                    },
                    {
                        "authorId": "2237950926",
                        "name": "Dongyue Chen"
                    },
                    {
                        "authorId": "32913412",
                        "name": "Shizhuo Deng"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "28268f2bcc3adda8c4a3b2f006cb40a1a73b95c1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-01377",
                    "ArXiv": "2309.01377",
                    "DOI": "10.48550/arXiv.2309.01377",
                    "CorpusId": 261530132
                },
                "corpusId": 261530132,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/28268f2bcc3adda8c4a3b2f006cb40a1a73b95c1",
                "title": "Memory augment is All You Need for image restoration",
                "abstract": "Image restoration is a low-level vision task, most CNN methods are designed as a black box, lacking transparency and internal aesthetics. Although some methods combining traditional optimization algorithms with DNNs have been proposed, they all have some limitations. In this paper, we propose a three-granularity memory layer and contrast learning named MemoryNet, specifically, dividing the samples into positive, negative, and actual three samples for contrastive learning, where the memory layer is able to preserve the deep features of the image and the contrastive learning converges the learned features to balance. Experiments on Derain/Deshadow/Deblur task demonstrate that these methods are effective in improving restoration performance. In addition, this paper's model obtains significant PSNR, SSIM gain on three datasets with different degradation types, which is a strong proof that the recovered images are perceptually realistic. The source code of MemoryNet can be obtained from https://github.com/zhangbaijin/MemoryNet",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2172376912",
                        "name": "Xiao Feng Zhang"
                    },
                    {
                        "authorId": "2237798600",
                        "name": "Chao Chen Gu"
                    },
                    {
                        "authorId": "2237863669",
                        "name": "Shan Ying Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "fc2fc4323ca64bf29789d512e9fcd407a2c33563",
                "externalIds": {
                    "DOI": "10.1016/j.knosys.2023.110986",
                    "CorpusId": 262029055
                },
                "corpusId": 262029055,
                "publicationVenue": {
                    "id": "12fff95b-d469-49a0-84a5-4fd4696c3f28",
                    "name": "Knowledge-Based Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Knowl Based Syst",
                        "Knowledge Based Systems",
                        "Knowledge-based Syst"
                    ],
                    "issn": "0950-7051",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525448/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/knowledge-based-systems",
                        "http://www.sciencedirect.com/science/journal/09507051"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fc2fc4323ca64bf29789d512e9fcd407a2c33563",
                "title": "Stochastic video normality network for abnormal event detection in surveillance videos",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47909156",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2143920085",
                        "name": "Dingkang Yang"
                    },
                    {
                        "authorId": "2213529330",
                        "name": "Gaoyun Fang"
                    },
                    {
                        "authorId": "2205141992",
                        "name": "Yuzheng Wang"
                    },
                    {
                        "authorId": "2151797908",
                        "name": "Donglai Wei"
                    },
                    {
                        "authorId": "1563747197",
                        "name": "Mengyang Zhao"
                    },
                    {
                        "authorId": "2212633127",
                        "name": "Kai Cheng"
                    },
                    {
                        "authorId": "2153467142",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "2244128106",
                        "name": "Liang Song"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "e8f67c074dc0c80e9d5cf3c958bf3e46c4c3b6a5",
                "externalIds": {
                    "DOI": "10.2139/ssrn.4354294",
                    "CorpusId": 256888415
                },
                "corpusId": 256888415,
                "publicationVenue": {
                    "id": "75d7a8c1-d871-42db-a8e4-7cf5146fdb62",
                    "name": "Social Science Research Network",
                    "type": "journal",
                    "alternate_names": [
                        "SSRN, Social Science Research Network (SSRN) home page",
                        "SSRN Electronic Journal",
                        "Soc Sci Res Netw",
                        "SSRN",
                        "SSRN Home Page",
                        "SSRN Electron J",
                        "Social Science Electronic Publishing presents Social Science Research Network"
                    ],
                    "issn": "1556-5068",
                    "url": "http://www.ssrn.com/",
                    "alternate_urls": [
                        "www.ssrn.com/",
                        "https://fatcat.wiki/container/tol7woxlqjeg5bmzadeg6qrg3e",
                        "https://www.wikidata.org/wiki/Q53949192",
                        "www.ssrn.com/en",
                        "http://www.ssrn.com/en/",
                        "http://umlib.nl/ssrn",
                        "umlib.nl/ssrn"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e8f67c074dc0c80e9d5cf3c958bf3e46c4c3b6a5",
                "title": "A Masked Reverse Knowledge Distillation Method Incorporating Global-Local Information for Image Anomaly Detection",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2200445770",
                        "name": "Yuxin Jiang"
                    },
                    {
                        "authorId": "2165889312",
                        "name": "Yunkang Cao"
                    },
                    {
                        "authorId": "2117228002",
                        "name": "Weiming Shen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "f6b344271c0a74b348ff7d947fe610476f54749a",
                "externalIds": {
                    "DOI": "10.1016/j.neucom.2023.126770",
                    "CorpusId": 262175255
                },
                "corpusId": 262175255,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f6b344271c0a74b348ff7d947fe610476f54749a",
                "title": "Weakly-supervised anomaly detection with a Sub-Max strategy",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2244632149",
                        "name": "Bohua Zhang"
                    },
                    {
                        "authorId": "2244593605",
                        "name": "Jianru Xue"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Memory-based Learning has been widely explored in computer vision [41, 72, 29, 46, 15, 21, 33, 62, 47, 69, 60, 89, 27, 51, 4, 71, 30, 19]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "9afabd4eb3e14836266603a27b667f6c424481fb",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-13236",
                    "ArXiv": "2308.13236",
                    "DOI": "10.48550/arXiv.2308.13236",
                    "CorpusId": 261214533
                },
                "corpusId": 261214533,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/9afabd4eb3e14836266603a27b667f6c424481fb",
                "title": "Black-box Unsupervised Domain Adaptation with Bi-directional Atkinson-Shiffrin Memory",
                "abstract": "Black-box unsupervised domain adaptation (UDA) learns with source predictions of target data without accessing either source data or source models during training, and it has clear superiority in data privacy and flexibility in target network selection. However, the source predictions of target data are often noisy and training with them is prone to learning collapses. We propose BiMem, a bi-directional memorization mechanism that learns to remember useful and representative information to correct noisy pseudo labels on the fly, leading to robust black-box UDA that can generalize across different visual recognition tasks. BiMem constructs three types of memory, including sensory memory, short-term memory, and long-term memory, which interact in a bi-directional manner for comprehensive and robust memorization of learnt features. It includes a forward memorization flow that identifies and stores useful features and a backward calibration flow that rectifies features' pseudo labels progressively. Extensive experiments show that BiMem achieves superior domain adaptation performance consistently across various visual recognition tasks such as image classification, semantic segmentation and object detection.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108122973",
                        "name": "Jingyi Zhang"
                    },
                    {
                        "authorId": "144284509",
                        "name": "Jiaxing Huang"
                    },
                    {
                        "authorId": "2218146258",
                        "name": "Xue-Qiu Jiang"
                    },
                    {
                        "authorId": "2143514677",
                        "name": "Shijian Lu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[33], [34], and inpainting masked regions [15], [35], [36], were adopted to improve the reconstruction result."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "c72cf20b0fadf2c101b14c522af96466f1ed64a5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-12577",
                    "ArXiv": "2308.12577",
                    "DOI": "10.48550/arXiv.2308.12577",
                    "CorpusId": 261100620
                },
                "corpusId": 261100620,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c72cf20b0fadf2c101b14c522af96466f1ed64a5",
                "title": "REB: Reducing Biases in Representation for Industrial Anomaly Detection",
                "abstract": "Existing K-nearest neighbor (KNN) retrieval-based methods usually conduct industrial anomaly detection in two stages: obtain feature representations with a pre-trained CNN model and perform distance measures for defect detection. However, the features are not fully exploited as they ignore domain bias and the difference of local density in feature space, which limits the detection performance. In this paper, we propose Reducing Biases (REB) in representation by considering the domain bias of the pre-trained model and building a self-supervised learning task for better domain adaption with a defect generation strategy (DefectMaker) imitating the natural defects. Additionally, we propose a local density KNN (LDKNN) to reduce the local density bias and obtain effective anomaly detection. We achieve a promising result of 99.5\\% AUROC on the widely used MVTec AD benchmark. We also achieve 88.0\\% AUROC on the challenging MVTec LOCO AD dataset and bring an improvement of 4.7\\% AUROC to the state-of-the-art result. All results are obtained with smaller backbone networks such as Vgg11 and Resnet18, which indicates the effectiveness and efficiency of REB for practical industrial applications.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2233287052",
                        "name": "Shuai Lyu"
                    },
                    {
                        "authorId": "51094580",
                        "name": "Dongmei Mo"
                    },
                    {
                        "authorId": "2087074109",
                        "name": "W. Wong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These generally train a reconstruction model, then either reconstruct the current frame or try to predict the next frame, signaling an anomaly when reconstruction error is high [10, 39, 25, 36, 54, 48]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "6e76cb2c9c43bc910827bacc95aa78139449ae08",
                "externalIds": {
                    "ArXiv": "2308.11072",
                    "DBLP": "journals/corr/abs-2308-11072",
                    "DOI": "10.48550/arXiv.2308.11072",
                    "CorpusId": 261064858
                },
                "corpusId": 261064858,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6e76cb2c9c43bc910827bacc95aa78139449ae08",
                "title": "TeD-SPAD: Temporal Distinctiveness for Self-supervised Privacy-preservation for video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) without human monitoring is a complex computer vision task that can have a positive impact on society if implemented successfully. While recent advances have made significant progress in solving this task, most existing approaches overlook a critical real-world concern: privacy. With the increasing popularity of artificial intelligence technologies, it becomes crucial to implement proper AI ethics into their development. Privacy leakage in VAD allows models to pick up and amplify unnecessary biases related to people's personal information, which may lead to undesirable decision making. In this paper, we propose TeD-SPAD, a privacy-aware video anomaly detection framework that destroys visual private information in a self-supervised manner. In particular, we propose the use of a temporally-distinct triplet loss to promote temporally discriminative features, which complements current weakly-supervised VAD methods. Using TeD-SPAD, we achieve a positive trade-off between privacy protection and utility anomaly detection performance on three popular weakly supervised VAD datasets: UCF-Crime, XD-Violence, and ShanghaiTech. Our proposed anonymization model reduces private attribute prediction by 32.25% while only reducing frame-level ROC AUC on the UCF-Crime anomaly detection dataset by 3.69%. Project Page: https://joefioresi718.github.io/TeD-SPAD_webpage/",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2106407817",
                        "name": "Joe Fioresi"
                    },
                    {
                        "authorId": "2160630204",
                        "name": "I. Dave"
                    },
                    {
                        "authorId": "2111863589",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "One commonly used proxy-task in semi-supervised VAD methods is frame reconstruction [9,10,11,12,13] in which, an unsupervised neural network is trained on normal frames, assuming that the reconstruction error would be comparatively higher for abnormal frames."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "629a0a49b35a065df73e3458bfccd86612cdddf0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-07783",
                    "ArXiv": "2308.07783",
                    "DOI": "10.48550/arXiv.2308.07783",
                    "CorpusId": 260900177
                },
                "corpusId": 260900177,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/629a0a49b35a065df73e3458bfccd86612cdddf0",
                "title": "Future Video Prediction from a Single Frame for Video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) is an important but challenging task in computer vision. The main challenge rises due to the rarity of training samples to model all anomaly cases. Hence, semi-supervised anomaly detection methods have gotten more attention, since they focus on modeling normals and they detect anomalies by measuring the deviations from normal patterns. Despite impressive advances of these methods in modeling normal motion and appearance, long-term motion modeling has not been effectively explored so far. Inspired by the abilities of the future frame prediction proxy-task, we introduce the task of future video prediction from a single frame, as a novel proxy-task for video anomaly detection. This proxy-task alleviates the challenges of previous methods in learning longer motion patterns. Moreover, we replace the initial and future raw frames with their corresponding semantic segmentation map, which not only makes the method aware of object class but also makes the prediction task less complex for the model. Extensive experiments on the benchmark datasets (ShanghaiTech, UCSD-Ped1, and UCSD-Ped2) show the effectiveness of the method and the superiority of its performance compared to SOTA prediction-based VAD methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2093641084",
                        "name": "M. Baradaran"
                    },
                    {
                        "authorId": "2145950",
                        "name": "R. Bergevin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "ity is achieved by exploiting that models learn their training data\u2019s underlying patterns, which implicitly makes them learn a notion of normality corresponding to their training data [5].",
                "The idea is to detect anomalies by their deviation from the learned model of normality [1]\u2013[5].",
                "[5], who propose a memory module, which represents a storage of latent representations of normal image frames.",
                "Since \u201cprediction can be considered as a reconstruction of the future frame using previous ones\u201d [5], the model can be adapted to predict the next frame with minimal effort using the same underlying"
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "f05bae259c29474500201cad207fd6a2f7a1fb21",
                "externalIds": {
                    "ArXiv": "2308.05701",
                    "DBLP": "journals/corr/abs-2308-05701",
                    "DOI": "10.48550/arXiv.2308.05701",
                    "CorpusId": 260775912
                },
                "corpusId": 260775912,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f05bae259c29474500201cad207fd6a2f7a1fb21",
                "title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "abstract": "In recent years there have been remarkable advancements in autonomous driving. While autonomous vehicles demonstrate high performance in closed-set conditions, they encounter difficulties when confronted with unexpected situations. At the same time, world models emerged in the field of model-based reinforcement learning as a way to enable agents to predict the future depending on potential actions. This led to outstanding results in sparse reward and complex control tasks. This work provides an overview of how world models can be leveraged to perform anomaly detection in the domain of autonomous driving. We provide a characterization of world models and relate individual components to previous works in anomaly detection to facilitate further research in the field.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "73381787",
                        "name": "Daniel Bogdoll"
                    },
                    {
                        "authorId": "2229418052",
                        "name": "Lukas Bosch"
                    },
                    {
                        "authorId": "2066556486",
                        "name": "Tim Joseph"
                    },
                    {
                        "authorId": "2203793499",
                        "name": "Helen Gremmelmaier"
                    },
                    {
                        "authorId": "2108604005",
                        "name": "Yitian Yang"
                    },
                    {
                        "authorId": "144727983",
                        "name": "J. Zollner"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To this end, we can employ many methods to generate the reference features, such as sampling key features by coreset subsampling algorithm [35], generating prototype features by memory module [28], or learning codebook features through vector quantization [65] or sparse coding techniques [55].",
                "Many previous works attempt to train AutoEncoders [6, 28, 57, 8, 17, 64], Variational AutoEncoders [23] and GANs [42, 1, 29, 40] to reconstruct the input images.",
                "The core idea of most unsupervised AD methods is to compare with normal samples to distinguish anomalies [46, 35, 60, 11, 28, 58]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "7d71c1d38d7979ecf357959add04d8c824a40628",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-02983",
                    "ArXiv": "2308.02983",
                    "DOI": "10.48550/arXiv.2308.02983",
                    "CorpusId": 260682461
                },
                "corpusId": 260682461,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7d71c1d38d7979ecf357959add04d8c824a40628",
                "title": "Focus the Discrepancy: Intra- and Inter-Correlation Learning for Image Anomaly Detection",
                "abstract": "Humans recognize anomalies through two aspects: larger patch-wise representation discrepancies and weaker patch-to-normal-patch correlations. However, the previous AD methods didn't sufficiently combine the two complementary aspects to design AD models. To this end, we find that Transformer can ideally satisfy the two aspects as its great power in the unified modeling of patch-wise representations and patch-to-patch correlations. In this paper, we propose a novel AD framework: FOcus-the-Discrepancy (FOD), which can simultaneously spot the patch-wise, intra- and inter-discrepancies of anomalies. The major characteristic of our method is that we renovate the self-attention maps in transformers to Intra-Inter-Correlation (I2Correlation). The I2Correlation contains a two-branch structure to first explicitly establish intra- and inter-image correlations, and then fuses the features of two-branch to spotlight the abnormal patterns. To learn the intra- and inter-correlations adaptively, we propose the RBF-kernel-based target-correlations as learning targets for self-supervised learning. Besides, we introduce an entropy constraint strategy to solve the mode collapse issue in optimization and further amplify the normal-abnormal distinguishability. Extensive experiments on three unsupervised real-world AD benchmarks show the superior performance of our approach. Code will be available at https://github.com/xcyao00/FOD.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2213687136",
                        "name": "Xincheng Yao"
                    },
                    {
                        "authorId": "2165552353",
                        "name": "Ruoqing Li"
                    },
                    {
                        "authorId": "2189746705",
                        "name": "Zefeng Qian"
                    },
                    {
                        "authorId": "2112601696",
                        "name": "Yan Luo"
                    },
                    {
                        "authorId": "1750897",
                        "name": "Chongyang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "a0f9cdabab08829f67e6d2c44eea1ec568ec5239",
                "externalIds": {
                    "ArXiv": "2308.01537",
                    "DBLP": "journals/corr/abs-2308-01537",
                    "DOI": "10.48550/arXiv.2308.01537",
                    "CorpusId": 260438467
                },
                "corpusId": 260438467,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a0f9cdabab08829f67e6d2c44eea1ec568ec5239",
                "title": "Learning Causality-inspired Representation Consistency for Video Anomaly Detection",
                "abstract": "Video anomaly detection is an essential yet challenging task in the multimedia community, with promising applications in smart cities and secure communities. Existing methods attempt to learn abstract representations of regular events with statistical dependence to model the endogenous normality, which discriminates anomalies by measuring the deviations to the learned distribution. However, conventional representation learning is only a crude description of video normality and lacks an exploration of its underlying causality. The learned statistical dependence is unreliable for diverse regular events in the real world and may cause high false alarms due to overgeneralization. Inspired by causal representation learning, we think that there exists a causal variable capable of adequately representing the general patterns of regular events in which anomalies will present significant variations. Therefore, we design a causality-inspired representation consistency (CRC) framework to implicitly learn the unobservable causal variables of normality directly from available normal videos and detect abnormal events with the learned representation consistency. Extensive experiments show that the causality-inspired normality is robust to regular events with label-independent shifts, and the proposed CRC framework can quickly and accurately detect various complicated anomalies from real-world surveillance videos.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47909156",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2151464031",
                        "name": "Zhaoyang Xia"
                    },
                    {
                        "authorId": "1563747197",
                        "name": "Mengyang Zhao"
                    },
                    {
                        "authorId": "2151797908",
                        "name": "Donglai Wei"
                    },
                    {
                        "authorId": "2205141992",
                        "name": "Yuzheng Wang"
                    },
                    {
                        "authorId": "2250456982",
                        "name": "Liu Siao"
                    },
                    {
                        "authorId": "152356699",
                        "name": "Bobo Ju"
                    },
                    {
                        "authorId": "2213529330",
                        "name": "Gaoyun Fang"
                    },
                    {
                        "authorId": "2153467142",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "143875337",
                        "name": "Liang Song"
                    }
                ]
            }
        },
        {
            "contexts": [
                "com/zhaojiachen1994/DIP-Anomaly-Detection methods [30], [31], which use the reconstruction errors as anomaly scores.",
                "Therefore, some papers [30], [31], [45] developed semi-supervised deep"
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "133b1ab7e373d18d9a94e389650460c7c7486291",
                "externalIds": {
                    "DBLP": "journals/tbd/ZhaoDZC23",
                    "DOI": "10.1109/TBDATA.2023.3265509",
                    "CorpusId": 258197890
                },
                "corpusId": 258197890,
                "publicationVenue": {
                    "id": "9cc701cf-1f49-4121-8ea9-11bac24d61ad",
                    "name": "IEEE Transactions on Big Data",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Big Data"
                    ],
                    "issn": "2332-7790",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6687317",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6687317",
                        "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6687317"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/133b1ab7e373d18d9a94e389650460c7c7486291",
                "title": "Searching Density-Increasing Path to Local Density Peaks for Unsupervised Anomaly Detection",
                "abstract": "Unsupervised anomaly detection (AD) is a challenging problem in the data mining community. Clustering-based AD methods aim to group normal data points into clusters and then regard a point belonging to none of the clusters as an anomaly. However, they may suffer from the problems of unknown cluster numbers and arbitrary cluster shapes. This paper presents a novel clustering-based AD method named Density-increasing Path (DIP) to tackle these challenges. DIP searches a path for each data point. The path starts at the data point itself, passes through several points with monotonically increasing densities, and ends at a density peak. Further, DIP defines the climbing difficulty of each path by combining the distance and density increment of each step along the path, which can be regarded as the anomaly score of the path starting point. DIP can adaptively decide the number of peaks to address the challenge of unknown cluster numbers. Since DIP requires the path to pass several points rather than directly reaching the peak, it handles arbitrary cluster shapes. We also propose the ensemble DIP to improve prediction accuracy. The experimental results on four synthetic datasets and eleven real-world benchmarks demonstrate that DIP outperforms existing methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46508951",
                        "name": "Jiachen Zhao"
                    },
                    {
                        "authorId": "144688691",
                        "name": "Fang Deng"
                    },
                    {
                        "authorId": "2135347714",
                        "name": "Jia-Lu Zhu"
                    },
                    {
                        "authorId": "48080171",
                        "name": "Jie Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "9f4b6149cc760ccd045fe78babf41ae134b6cb36",
                "externalIds": {
                    "ArXiv": "2308.00429",
                    "DBLP": "journals/corr/abs-2308-00429",
                    "DOI": "10.48550/arXiv.2308.00429",
                    "CorpusId": 260351269
                },
                "corpusId": 260351269,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9f4b6149cc760ccd045fe78babf41ae134b6cb36",
                "title": "Patch-wise Auto-Encoder for Visual Anomaly Detection",
                "abstract": "Anomaly detection without priors of the anomalies is challenging. In the field of unsupervised anomaly detection, traditional auto-encoder (AE) tends to fail based on the assumption that by training only on normal images, the model will not be able to reconstruct abnormal images correctly. On the contrary, we propose a novel patch-wise auto-encoder (Patch AE) framework, which aims at enhancing the reconstruction ability of AE to anomalies instead of weakening it. Each patch of image is reconstructed by corresponding spatially distributed feature vector of the learned feature representation, i.e., patch-wise reconstruction, which ensures anomaly-sensitivity of AE. Our method is simple and efficient. It advances the state-of-the-art performances on Mvtec AD benchmark, which proves the effectiveness of our model. It shows great potential in practical industrial application scenarios.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2115327238",
                        "name": "Yajie Cui"
                    },
                    {
                        "authorId": "2565547",
                        "name": "Zhaoxiang Liu"
                    },
                    {
                        "authorId": "143763659",
                        "name": "Shiguo Lian"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "91e20731b0ed4d6505749d41210427d8a7f46554",
                "externalIds": {
                    "DBLP": "journals/ijis/UllahHU0HRBA23",
                    "DOI": "10.1155/2023/7868415",
                    "CorpusId": 260413957
                },
                "corpusId": 260413957,
                "publicationVenue": {
                    "id": "05528bac-d212-46a6-9c84-314d4bd77368",
                    "name": "International Journal of Intelligent Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Intell Syst"
                    ],
                    "issn": "0884-8173",
                    "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/36062",
                    "alternate_urls": [
                        "https://onlinelibrary.wiley.com/journal/1098111X"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/91e20731b0ed4d6505749d41210427d8a7f46554",
                "title": "AD-Graph: Weakly Supervised Anomaly Detection Graph Neural Network",
                "abstract": "The main challenge faced by video-based real-world anomaly detection systems is the accurate learning of unusual events that are irregular, complicated, diverse, and heterogeneous in nature. Several techniques utilizing deep learning have been created to detect anomalies, yet their effectiveness on real-world data is often limited due to the insufficient incorporation of motion patterns. To address these problems and enhance the traditional functionality of anomaly detection systems for surveillance video data, we propose a weakly supervised graph neural-network-assisted video anomaly detection framework called AD-Graph. To identify temporal information from a series of frames, we extract 3D visual and motion features and represent these in a language-based knowledge graph format. Next, a robust clustering strategy is applied to group together meaningful neighbourhoods of the graph with similar vertices. Furthermore, spectral filters are applied to these graphs, and spectral graph theory is used to generate graph signals and detect anomalous events. Extensive experimental results over two challenging datasets, UCF-Crime and ShanghaiTech, show improvements of 0.35% and 0.78% against a state-of-the-art model.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1885384073",
                        "name": "Waseem Ullah"
                    },
                    {
                        "authorId": "144591441",
                        "name": "Tanveer Hussain"
                    },
                    {
                        "authorId": "2226616342",
                        "name": "Fath U Min Ullah"
                    },
                    {
                        "authorId": "134260245",
                        "name": "K. Muhammad"
                    },
                    {
                        "authorId": "2158637",
                        "name": "M. Hassaballah"
                    },
                    {
                        "authorId": "2068020350",
                        "name": "J. J. Rodrigues"
                    },
                    {
                        "authorId": "1777998",
                        "name": "S. Baik"
                    },
                    {
                        "authorId": "2066172285",
                        "name": "V. H. Albuquerque"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[44] proposed using a memory module with an update scheme, where items in the memory record the normal patterns of the training data.",
                "More recently, some works [7], [13], [44] have applied memory networks to the VAD task in surveillance videos."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "05ad3759aa48d1374340305105f196863574aa5c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-14575",
                    "ArXiv": "2307.14575",
                    "DOI": "10.48550/arXiv.2307.14575",
                    "CorpusId": 260203230
                },
                "corpusId": 260203230,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/05ad3759aa48d1374340305105f196863574aa5c",
                "title": "A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised Traffic Accident Detection in Driving Videos",
                "abstract": "Identifying traffic accidents in driving videos is crucial to ensuring the safety of autonomous driving and driver assistance systems. To address the potential danger caused by the long-tailed distribution of driving events, existing traffic accident detection (TAD) methods mainly rely on unsupervised learning. However, TAD is still challenging due to the rapid movement of cameras and dynamic scenes in driving scenarios. Existing unsupervised TAD methods mainly rely on a single pretext task, i.e., an appearance-based or future object localization task, to detect accidents. However, appearance-based approaches are easily disturbed by the rapid movement of the camera and changes in illumination, which significantly reduce the performance of traffic accident detection. Methods based on future object localization may fail to capture appearance changes in video frames, making it difficult to detect ego-involved accidents (e.g., out of control of the ego-vehicle). In this paper, we propose a novel memory-augmented multi-task collaborative framework (MAMTCF) for unsupervised traffic accident detection in driving videos. Different from previous approaches, our method can more accurately detect both ego-involved and non-ego accidents by simultaneously modeling appearance changes and object motions in video frames through the collaboration of optical flow reconstruction and future object localization tasks. Further, we introduce a memory-augmented motion representation mechanism to fully explore the interrelation between different types of motion representations and exploit the high-level features of normal traffic patterns stored in memory to augment motion representations, thus enlarging the difference from anomalies. Experimental results on recently published large-scale dataset demonstrate that our method achieves better performance compared to previous state-of-the-art approaches.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2030972031",
                        "name": "Rongqin Liang"
                    },
                    {
                        "authorId": "3259148",
                        "name": "Yuanman Li"
                    },
                    {
                        "authorId": "2225233316",
                        "name": "Yingxin Yi"
                    },
                    {
                        "authorId": "2143464770",
                        "name": "Jiantao Zhou"
                    },
                    {
                        "authorId": "2155382374",
                        "name": "Xia Li"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "29d07873a0cd81ff6c534ac7d082dd3e740e8057",
                "externalIds": {
                    "DBLP": "journals/ijis/YasinTFFKA23",
                    "DOI": "10.1155/2023/9822428",
                    "CorpusId": 260190125
                },
                "corpusId": 260190125,
                "publicationVenue": {
                    "id": "05528bac-d212-46a6-9c84-314d4bd77368",
                    "name": "International Journal of Intelligent Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Intell Syst"
                    ],
                    "issn": "0884-8173",
                    "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/36062",
                    "alternate_urls": [
                        "https://onlinelibrary.wiley.com/journal/1098111X"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/29d07873a0cd81ff6c534ac7d082dd3e740e8057",
                "title": "Anomaly Prediction over Human Crowded Scenes via Associate-Based Data Mining and K-Ary Tree Hashing",
                "abstract": "Anomaly detection and behavioral recognition are key research areas widely used to improve human safety. However, in recent times, with the extensive use of surveillance systems and the substantial increase in the volume of recorded scenes, the conventional analysis of categorizing anomalous events has proven to be a difficult task. As a result, machine learning researchers require a smart surveillance system to detect anomalies. This research introduces a robust system for predicting pedestrian anomalies. First, we acquired the crowd data as input from two benchmark datasets (including Avenue and ADOC). Then, different denoising techniques (such as frame conversion, background subtraction, and RGB-to-binary image conversion) for unfiltered data are carried out. Second, texton segmentation is performed to identify human subjects from acquired denoised data. Third, we used Gaussian smoothing and crowd clustering to analyze the multiple subjects from the acquired data for further estimations. The next step is to perform feature extraction to multiple abstract cues from the data. These bag of features include periodic motion, shape autocorrelation, and motion direction flow. Then, the abstracted features are mapped into a single vector in order to apply data optimization and mining techniques. Next, we apply the associate-based mining approach for optimized feature selection. Finally, the resultant vector is served to the k-ary tree hashing classifier to track normal and abnormal activities in pedestrian crowded scenes.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3449455",
                        "name": "Affan Yasin"
                    },
                    {
                        "authorId": "1654176627",
                        "name": "Sheikh Badar ud din Tahir"
                    },
                    {
                        "authorId": "1939357",
                        "name": "J. Frnda"
                    },
                    {
                        "authorId": "39449797",
                        "name": "R. Fatima"
                    },
                    {
                        "authorId": "2125157771",
                        "name": "J. Ali Khan"
                    },
                    {
                        "authorId": "2192077761",
                        "name": "M. S. Anwar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recent researchers mainly adopt deep auto-encoders [2], [4], [24]\u2013[28] for self-supervised learning, e."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "3859171a4d2031b010f9c1eac8d3d57f169da6f7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-12545",
                    "ArXiv": "2307.12545",
                    "DOI": "10.48550/arXiv.2307.12545",
                    "CorpusId": 260125649
                },
                "corpusId": 260125649,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3859171a4d2031b010f9c1eac8d3d57f169da6f7",
                "title": "Towards Video Anomaly Retrieval from Video Anomaly Detection: New Benchmarks and Model",
                "abstract": "Video anomaly detection (VAD) has been paid increasing attention due to its potential applications, its current dominant tasks focus on online detecting anomalies% at the frame level, which can be roughly interpreted as the binary or multiple event classification. However, such a setup that builds relationships between complicated anomalous events and single labels, e.g., ``vandalism'', is superficial, since single labels are deficient to characterize anomalous events. In reality, users tend to search a specific video rather than a series of approximate videos. Therefore, retrieving anomalous events using detailed descriptions is practical and positive but few researches focus on this. In this context, we propose a novel task called Video Anomaly Retrieval (VAR), which aims to pragmatically retrieve relevant anomalous videos by cross-modalities, e.g., language descriptions and synchronous audios. Unlike the current video retrieval where videos are assumed to be temporally well-trimmed with short duration, VAR is devised to retrieve long untrimmed videos which may be partially relevant to the given query. To achieve this, we present two large-scale VAR benchmarks, UCFCrime-AR and XDViolence-AR, constructed on top of prevalent anomaly datasets. Meanwhile, we design a model called Anomaly-Led Alignment Network (ALAN) for VAR. In ALAN, we propose an anomaly-led sampling to focus on key segments in long untrimmed videos. Then, we introduce an efficient pretext task to enhance semantic associations between video-text fine-grained representations. Besides, we leverage two complementary alignments to further match cross-modal contents. Experimental results on two benchmarks reveal the challenges of VAR task and also demonstrate the advantages of our tailored method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2678268",
                        "name": "Peng Wu"
                    },
                    {
                        "authorId": "2163063860",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "153003087",
                        "name": "Xiangteng He"
                    },
                    {
                        "authorId": "143753918",
                        "name": "Yuxin Peng"
                    },
                    {
                        "authorId": "2155302795",
                        "name": "Peng Wang"
                    },
                    {
                        "authorId": "2047640322",
                        "name": "Yanning Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "26f9105452f91de13c06557802a4fa271f84cb85",
                "externalIds": {
                    "DOI": "10.23919/CCC58697.2023.10240970",
                    "CorpusId": 262072672
                },
                "corpusId": 262072672,
                "publicationVenue": {
                    "id": "23f8fe4c-6537-4027-a334-6a5863115984",
                    "name": "Cybersecurity and Cyberforensics Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Chin Control Conf",
                        "Computational Complexity Conference",
                        "CCC",
                        "Comput Complex Conf",
                        "Cybersecur Cyberforensics Conf",
                        "Conference on Computational Complexity",
                        "Computing Colombian Conference",
                        "Conf Comput Complex",
                        "Comput Colomb Conf",
                        "Chinese Control Conference"
                    ],
                    "url": "http://computationalcomplexity.org/"
                },
                "url": "https://www.semanticscholar.org/paper/26f9105452f91de13c06557802a4fa271f84cb85",
                "title": "Dual-Branch Framework with Convolutional Attentive Block for Video Anomaly Detection",
                "abstract": "Video anomaly detection is a challenging task due to the diversity and low frequency of anomalous events. Inspired by two-stream paradigms, we propose a hybrid dual-branch framework for improving the robustness to different anomalous scenarios. We integrate the prediction branch and the reconstruction branch, where the prediction branch learns appearance features from video frames, and the reconstruction branch learns motion features from optical flows, which allows the dual-branch framework to be jointly optimized. Specially, a channel attention block is developed for our dual-branch framework to adaptively enhance feature representations by modeling the interdependence among feature channels. Experimental results on three benchmarks prove the effectiveness of our dual-branch framework for video anomaly detection.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2146088411",
                        "name": "Qun Li"
                    },
                    {
                        "authorId": "2161385774",
                        "name": "Rui Yang"
                    },
                    {
                        "authorId": "2161090947",
                        "name": "Yaying Shen"
                    },
                    {
                        "authorId": "2243954227",
                        "name": "Ziyi Zhang"
                    },
                    {
                        "authorId": "2989422",
                        "name": "Xianzhong Long"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In previous studies, some investigators have developed anomaly detection approaches that learn only normal events [2-4] to detect abnormal events from surveillance camera movies."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "abdda19d64b9543f675650082f3f5b2921c6e427",
                "externalIds": {
                    "DBLP": "conf/mva/KobayashiHN23",
                    "DOI": "10.23919/MVA57639.2023.10215921",
                    "CorpusId": 261106402
                },
                "corpusId": 261106402,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/abdda19d64b9543f675650082f3f5b2921c6e427",
                "title": "Video Anomaly Detection Using Encoder-Decoder Networks with Video Vision Transformer and Channel Attention Blocks",
                "abstract": "A surveillance camera has been introduced in various locations for public safety. However, security personnel who have to keep observing surveillance camera movies with few abnormal events would be boring. The purpose of this study is to develop a computerized anomaly detection method for the surveillance camera movies. Our database consisted of three public datasets for anomaly detection: UCSD Pedestrian 1, 2, and CUHK Avenue datasets. In the proposed network, channel attention blocks were introduced to TransAnomaly which is one of the anomaly detections to focus important channel information. The areas under the receiver operating characteristic curves (AUCs) with the proposed network were 0.827 for UCSD Pedestrian 1, 0.964 for UCSD Pedestrian 2, and 0.854 for CUHK Avenue, respectively. The AUCs for the proposed network were greater than those for a conventional TransAnomaly without channel attention blocks (0.767, 0.934, and 0.839).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2233337452",
                        "name": "Shimpei Kobayashi"
                    },
                    {
                        "authorId": "3357227",
                        "name": "A. Hizukuri"
                    },
                    {
                        "authorId": "3175498",
                        "name": "R. Nakayama"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "6e9a7d79bcdc7b5a49f6a44bcb1f1eb4d36d1209",
                "externalIds": {
                    "DOI": "10.1109/CYBER59472.2023.10256576",
                    "CorpusId": 263230675
                },
                "corpusId": 263230675,
                "publicationVenue": {
                    "id": "05860b0f-ff70-48a0-a93a-71c4be979650",
                    "name": "Cyber ..",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Int Conf Cyber Technol Autom Control Intell Syst",
                        "CYBER",
                        "IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems",
                        "Cyber "
                    ],
                    "issn": "2519-8599",
                    "url": "http://www.thinkmind.org/index.php?event=CYBER&view=event"
                },
                "url": "https://www.semanticscholar.org/paper/6e9a7d79bcdc7b5a49f6a44bcb1f1eb4d36d1209",
                "title": "CDD-YOLOv8: A Small Defect Detection and Classification Algorithm for Cigarette Packages",
                "abstract": "In order to ensure the quality of cigarette products, it is significant to conduct real-time detection and classification for defects on cigarette packages in high-speed assembly line. Most industrial anomaly detection methods can only detect anomalies by modeling normal data distribution, lacking the ability to realize the fine-grained classification of anomalies, which is indispensable for reducing defective products and thus lower production costs. To solve the problem of detecting and classifying small defects in cigarette packaging, we introduced a Cigarette Defect Detection YOLOv8 algorithm (CDD-YOLOv8). By adding a small object detection head and Convolutional Block Attention Module(CBAM), our proposed model achieved better utilization of multi-level features to assist in small defect detection, contributing to better detection performance in our cigarette dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2140022563",
                        "name": "Liming Zhu"
                    },
                    {
                        "authorId": "2187058038",
                        "name": "Jun Zhang"
                    },
                    {
                        "authorId": "2248256835",
                        "name": "Qiang Zhang"
                    },
                    {
                        "authorId": "2248998202",
                        "name": "Hongtao Hu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "fa5aaa7c45e4cd727226a75f5b1b8e5d33460a87",
                "externalIds": {
                    "ArXiv": "2307.03101",
                    "DBLP": "journals/corr/abs-2307-03101",
                    "DOI": "10.48550/arXiv.2307.03101",
                    "CorpusId": 259360785
                },
                "corpusId": 259360785,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/fa5aaa7c45e4cd727226a75f5b1b8e5d33460a87",
                "title": "Contextual Affinity Distillation for Image Anomaly Detection",
                "abstract": "Previous works on unsupervised industrial anomaly detection mainly focus on local structural anomalies such as cracks and color contamination. While achieving significantly high detection performance on this kind of anomaly, they are faced with logical anomalies that violate the long-range dependencies such as a normal object placed in the wrong position. In this paper, based on previous knowledge distillation works, we propose to use two students (local and global) to better mimic the teacher's behavior. The local student, which is used in previous studies mainly focuses on structural anomaly detection while the global student pays attention to logical anomalies. To further encourage the global student's learning to capture long-range dependencies, we design the global context condensing block (GCCB) and propose a contextual affinity loss for the student training and anomaly scoring. Experimental results show the proposed method doesn't need cumbersome training techniques and achieves a new state-of-the-art performance on the MVTec LOCO AD dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "40539618",
                        "name": "J. Zhang"
                    },
                    {
                        "authorId": "9114621",
                        "name": "M. Suganuma"
                    },
                    {
                        "authorId": "1718872",
                        "name": "Takayuki Okatani"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Memory-augmented AEs [8, 27] have been introduced to add a memory module for anomaly detection in image and video data.",
                "Considering that memory can be used to record prototypical patterns of normal data, a number of studies [8,27] proposed to augment AEs with a memory module for image or video anomaly detection.",
                "Due to the ability to store and retrieve important information, memory networks have been proposed and successfully applied to a wide range of domains [8, 10, 16, 27, 36, 38].",
                "AE is also commonly used for anomaly detection in various domains [6,8,27,41,46,47] since anomalies are generally difficult to reconstruct, and thus, they have a higher reconstruction error than normal samples."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3bcc03012f22eb10e7254123b25f3c28c70c3f31",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-00755",
                    "ArXiv": "2307.00755",
                    "DOI": "10.48550/arXiv.2307.00755",
                    "CorpusId": 259316224
                },
                "corpusId": 259316224,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3bcc03012f22eb10e7254123b25f3c28c70c3f31",
                "title": "Graph-level Anomaly Detection via Hierarchical Memory Networks",
                "abstract": "Graph-level anomaly detection aims to identify abnormal graphs that exhibit deviant structures and node attributes compared to the majority in a graph set. One primary challenge is to learn normal patterns manifested in both fine-grained and holistic views of graphs for identifying graphs that are abnormal in part or in whole. To tackle this challenge, we propose a novel approach called Hierarchical Memory Networks (HimNet), which learns hierarchical memory modules -- node and graph memory modules -- via a graph autoencoder network architecture. The node-level memory module is trained to model fine-grained, internal graph interactions among nodes for detecting locally abnormal graphs, while the graph-level memory module is dedicated to the learning of holistic normal patterns for detecting globally abnormal graphs. The two modules are jointly optimized to detect both locally- and globally-anomalous graphs. Extensive empirical results on 16 real-world graph datasets from various domains show that i) HimNet significantly outperforms the state-of-art methods and ii) it is robust to anomaly contamination. Codes are available at: https://github.com/Niuchx/HimNet.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "79690137",
                        "name": "Chaoxi Niu"
                    },
                    {
                        "authorId": "3224619",
                        "name": "Guansong Pang"
                    },
                    {
                        "authorId": "2119323490",
                        "name": "Ling Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", the first category [2], [3], [8], [23]\u2013[25] trains the models on full video frames, the second one [4], [5], [9]\u2013 [11] works with the assistance of object detection, and the last one [6], [12] uses not only object detection but also external datasets to help improve performance.",
                "Due to the lack of abnormal events for supervision, the models learned by existing methods [2], [3], [8] would recklessly fit correlations between non-causal features (e."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "f6249c92c8883a58db82a48ac19880231d6f5021",
                "externalIds": {
                    "DBLP": "conf/icmcs/WanZJ23",
                    "DOI": "10.1109/ICME55011.2023.00464",
                    "CorpusId": 261127866
                },
                "corpusId": 261127866,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f6249c92c8883a58db82a48ac19880231d6f5021",
                "title": "Pose-Motion Video Anomaly Detection via Memory-Augmented Reconstruction and Conditional Variational Prediction",
                "abstract": "Video anomaly detection (VAD) is a challenging computer vision problem. Due to the scarcity of anomalous events in training, the models learned by existing methods would mistakenly fit the ubiquitous non-causal or even spurious correlations, leading to failure in inference. In this paper, we propose a new two-phase Pose-Motion Video Anomaly Detection (PoMo) approach by jointly exploiting the informative features including the poses and optical flows that have rich causal correlations with abnormality. PoMo can effectively prevent the non-causal features from leaking in by either encoding only the essential information, i.e., the poses and optical flows, with our normalized autoencoder (phase one), or separately modeling the knowledge learned in phase one using our causal-conditioned autoencoder (phase two). The difference between normal and abnormal events can be amplified through these two phases. Thus the generalization ability can be reinforced. Extensive experimental results demonstrate the superiority of our approach over the existing methods and the improvements in AUC-ROC can be up to 1.5%.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "12836031",
                        "name": "Weilin Wan"
                    },
                    {
                        "authorId": "47527753",
                        "name": "Weizhong Zhang"
                    },
                    {
                        "authorId": "2211768124",
                        "name": "Cheng Jin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "12d30abe90c1034f514f0be1002bc80001ad16e1",
                "externalIds": {
                    "ArXiv": "2306.14451",
                    "DBLP": "journals/corr/abs-2306-14451",
                    "DOI": "10.48550/arXiv.2306.14451",
                    "CorpusId": 259252177
                },
                "corpusId": 259252177,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/12d30abe90c1034f514f0be1002bc80001ad16e1",
                "title": "Learning Prompt-Enhanced Context Features for Weakly-Supervised Video Anomaly Detection",
                "abstract": "Video anomaly detection under weak supervision is challenging due to the absence of frame-level annotations during the training phase. Previous work has employed graph convolution networks or self-attention mechanisms to model temporal relations, along with multiple instance learning (MIL)-based classification loss to learn discriminative features. However, most of them utilize multi-branches to capture local and global dependencies separately, leading to increased parameters and computational cost. Furthermore, the binarized constraint of the MIL-based loss only ensures coarse-grained interclass separability, ignoring fine-grained discriminability within anomalous classes. In this paper, we propose a weakly supervised anomaly detection framework that emphasizes efficient context modeling and enhanced semantic discriminability. To this end, we first construct a temporal context aggregation (TCA) module that captures complete contextual information by reusing similarity matrix and adaptive fusion. Additionally, we propose a prompt-enhanced learning (PEL) module that incorporates semantic priors into the model by utilizing knowledge-based prompts, aiming at enhancing the discriminative capacity of context features while ensuring separability between anomaly sub-classes. Furthermore, we introduce a score smoothing (SS) module in the testing phase to suppress individual bias and reduce false alarms. Extensive experiments demonstrate the effectiveness of various components of our method, which achieves competitive performance with fewer parameters and computational effort on three challenging benchmarks: the UCF-crime, XD-violence, and ShanghaiTech datasets. The detection accuracy of some anomaly sub-classes is also improved with a great margin.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2155739298",
                        "name": "Yujiang Pu"
                    },
                    {
                        "authorId": "2108070033",
                        "name": "Xiaoyu Wu"
                    },
                    {
                        "authorId": "1678689",
                        "name": "Shengjin Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "1f1b6f5dcd5f802f2782ef15629be57202e3b629",
                "externalIds": {
                    "DBLP": "conf/aaai/SunSJ023",
                    "DOI": "10.1609/aaai.v37i2.25334",
                    "CorpusId": 259581127
                },
                "corpusId": 259581127,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/1f1b6f5dcd5f802f2782ef15629be57202e3b629",
                "title": "Learning Event-Relevant Factors for Video Anomaly Detection",
                "abstract": "Most video anomaly detection methods discriminate events that deviate from normal patterns as anomalies. However, these methods are prone to interferences from event-irrelevant factors, such as background textures and object scale variations, incurring an increased false detection rate. In this paper, we propose to explicitly learn event-relevant factors to eliminate the interferences from event-irrelevant factors on anomaly predictions. To this end, we introduce a causal generative model to separate the event-relevant factors and event-irrelevant ones in videos, and learn the prototypes of event-relevant factors in a memory augmentation module. We design a causal objective function to optimize the causal generative model and develop a counterfactual learning strategy to guide anomaly predictions, which increases the influence of the event-relevant factors. The extensive experiments show the effectiveness of our method for video anomaly detection.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "41172535",
                        "name": "Che Sun"
                    },
                    {
                        "authorId": "2195668886",
                        "name": "Chenrui Shi"
                    },
                    {
                        "authorId": "7415267",
                        "name": "Yunde Jia"
                    },
                    {
                        "authorId": "150352923",
                        "name": "Yuwei Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There are several categories of anomaly detection approaches, including dictionary learning methods [12, 13, 20, 47, 64, 84], probabilistic models [2, 3, 24, 30, 38, 51, 52, 69, 86], change detection frameworks [14, 34, 45, 55], distance-based models [33, 35, 58,59,62,67,68,71,72,75,77] and reconstruction-based approaches [22,27,28,43,44,49,53,57,63,65,76].",
                "To boost the performance of frame-level or cube-level methods, researchers explored the inclusion of various components, such as memory modules [27, 46, 57] or masked convolutional blocks [65].",
                "Thus, to better leverage the reconstruction error of AEs in anomaly detection, researchers explored a few alternatives, from the use of dummy [33] or pseudo-anomalies [5, 26] to the integration of memory modules [27,46,57]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "7ad25dbb5022c119144990cde0d364e2519df728",
                "externalIds": {
                    "ArXiv": "2306.12041",
                    "DBLP": "journals/corr/abs-2306-12041",
                    "DOI": "10.48550/arXiv.2306.12041",
                    "CorpusId": 259212303
                },
                "corpusId": 259212303,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7ad25dbb5022c119144990cde0d364e2519df728",
                "title": "Self-Distilled Masked Auto-Encoders are Efficient Video Anomaly Detectors",
                "abstract": "We propose an efficient abnormal event detection model based on a lightweight masked auto-encoder (AE) applied at the video frame level. The novelty of the proposed model is threefold. First, we introduce an approach to weight tokens based on motion gradients, thus avoiding learning to reconstruct the static background scene. Second, we integrate a teacher decoder and a student decoder into our architecture, leveraging the discrepancy between the outputs given by the two decoders to improve anomaly detection. Third, we generate synthetic abnormal events to augment the training videos, and task the masked AE model to jointly reconstruct the original frames (without anomalies) and the corresponding pixel-level anomaly maps. Our design leads to an efficient and effective model, as demonstrated by the extensive experiments carried out on three benchmarks: Avenue, ShanghaiTech and UCSD Ped2. The empirical results show that our model achieves an excellent trade-off between speed and accuracy, obtaining competitive AUC scores, while processing 1670 FPS. Hence, our model is between 8 and 70 times faster than competing methods. We also conduct an ablation study to justify our design.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "103931166",
                        "name": "Nicolae-Catalin Ristea"
                    },
                    {
                        "authorId": "2154573729",
                        "name": "Florinel-Alin Croitoru"
                    },
                    {
                        "authorId": "1817759",
                        "name": "Radu Tudor Ionescu"
                    },
                    {
                        "authorId": "49006356",
                        "name": "M. Popescu"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "2111863589",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "AutoEncoder (AE) and Variational AE have been the first and most popular models for this purpose [51, 76, 7, 50, 35, 21, 28, 40, 25, 78].",
                "Recently, the memory mechanism is exploited to further constrain model\u2019s capability on reconstructing abnormal samples [21, 40, 25, 78]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "d935b0570f3789c96ea34a8609d78e8699f7bc68",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-11876",
                    "ArXiv": "2306.11876",
                    "DOI": "10.48550/arXiv.2306.11876",
                    "CorpusId": 259212018
                },
                "corpusId": 259212018,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d935b0570f3789c96ea34a8609d78e8699f7bc68",
                "title": "BMAD: Benchmarks for Medical Anomaly Detection",
                "abstract": "Anomaly detection (AD) is a fundamental research problem in machine learning and computer vision, with practical applications in industrial inspection, video surveillance, and medical diagnosis. In medical imaging, AD is especially vital for detecting and diagnosing anomalies that may indicate rare diseases or conditions. However, there is a lack of a universal and fair benchmark for evaluating AD methods on medical images, which hinders the development of more generalized and robust AD methods in this specific domain. To bridge this gap, we introduce a comprehensive evaluation benchmark for assessing anomaly detection methods on medical images. This benchmark encompasses six reorganized datasets from five medical domains (i.e. brain MRI, liver CT, retinal OCT, chest X-ray, and digital histopathology) and three key evaluation metrics, and includes a total of fourteen state-of-the-art AD algorithms. This standardized and well-curated medical benchmark with the well-structured codebase enables comprehensive comparisons among recently proposed anomaly detection methods. It will facilitate the community to conduct a fair comparison and advance the field of AD on medical imaging. More information on BMAD is available in our GitHub repository: https://github.com/DorisBao/BMAD",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2150472403",
                        "name": "Jinan Bao"
                    },
                    {
                        "authorId": "2157488773",
                        "name": "Hanshi Sun"
                    },
                    {
                        "authorId": "2153490019",
                        "name": "Hanqiu Deng"
                    },
                    {
                        "authorId": "2217446675",
                        "name": "Yinsheng He"
                    },
                    {
                        "authorId": "2175272847",
                        "name": "Zhaoxiang Zhang"
                    },
                    {
                        "authorId": "2155444872",
                        "name": "Xingyu Li"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "07f659747525c0df761e28bce5e71a5b92ed7062",
                "externalIds": {
                    "ArXiv": "2306.10720",
                    "CorpusId": 259203095
                },
                "corpusId": 259203095,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/07f659747525c0df761e28bce5e71a5b92ed7062",
                "title": "Exploring the Relationship between Samples and Masks for Robust Defect Localization",
                "abstract": "Defect detection aims to detect and localize regions out of the normal distribution.Previous approaches model normality and compare it with the input to identify defective regions, potentially limiting their generalizability.This paper proposes a one-stage framework that detects defective patterns directly without the modeling process.This ability is adopted through the joint efforts of three parties: a generative adversarial network (GAN), a newly proposed scaled pattern loss, and a dynamic masked cycle-consistent auxiliary network. Explicit information that could indicate the position of defects is intentionally excluded to avoid learning any direct mapping.Experimental results on the texture class of the challenging MVTec AD dataset show that the proposed method is 2.9% higher than the SOTA methods in F1-Score, while substantially outperforming SOTA methods in generalizability.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "79989893",
                        "name": "Jiangke Lin"
                    },
                    {
                        "authorId": "152439250",
                        "name": "Yaping Yan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Unsupervised anomaly detection methods are trained on unlabeled anomaly-free samples, while they are tested on both normal and anomalous samples [18]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5545f3edc6b5eb2847cb9e5fd27ce212c27a76c7",
                "externalIds": {
                    "DBLP": "conf/ijcnn/XiaoDCLCY23",
                    "DOI": "10.1109/IJCNN54540.2023.10191880",
                    "CorpusId": 260387237
                },
                "corpusId": 260387237,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/5545f3edc6b5eb2847cb9e5fd27ce212c27a76c7",
                "title": "Dual-Path Reconstruction Guided Segmentation Network for Unsupervised Anomaly Detection and Localization",
                "abstract": "Visual anomaly detection methods with localization are critically important for industrial manufacturing quality control. Because of the rarity of anomalies and the irregular variation of anomaly patterns, unsupervised methods have been widely explored. For the anomaly detection and localization tasks, the image reconstruction-based approaches have shown competitive performance. However, reconstruction results of those methods are coarse and visually blurred, which leads to a high rate of false detection and false pixel-level localization. To address those issues, we propose a framework called Dual-Path Re-construction Guided Segmentation Network (DRGS-Net), which determines the abnormal regions by segmenting the anomaly image with its reconstructed result as the reference template. DRGS-Net mainly consists of a novel dual-path reconstruction sub-network and a specifically designed anomaly segmentation sub-network. They are jointly trained end-to-end, with the former fusing texture repair and image reconstruction information to obtain fine-grained reconstruction results and the latter learning a decision boundary between normal and anomalous regions based on reconstruction results. On the standard benchmark dataset MVTecAD and an additional dataset DAGM, DRGS-Net shows competitive performance in image-level detection and achieves outstanding improvement in pixel-level localization. Further experiments with the few samples setting demonstrate that DRGS-Net retains strong performance with only few anomaly-free training images.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2165889378",
                        "name": "Junwei Xiao"
                    },
                    {
                        "authorId": "2114190756",
                        "name": "Lei Deng"
                    },
                    {
                        "authorId": "1723853",
                        "name": "Z. Chen"
                    },
                    {
                        "authorId": "2164225707",
                        "name": "Xiu Li"
                    },
                    {
                        "authorId": "2108426292",
                        "name": "Baohua Chen"
                    },
                    {
                        "authorId": "2165879253",
                        "name": "Hanxi Yin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "By assuming that anomaly samples are not available during the training stage, considerable progress has been made in anomaly-free detection studies under the one-classification framework [4, 5, 30, 32], self-supervised framework [2, 8, 9, 19, 38, 42, 45], GAN-based framework [29, 34, 36, 50], and autoencoderbased framework [10, 14, 28, 53, 55]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "2e925205de0150d759518c767811dcbb89fca058",
                "externalIds": {
                    "ArXiv": "2306.08366",
                    "DBLP": "journals/corr/abs-2306-08366",
                    "DOI": "10.48550/arXiv.2306.08366",
                    "CorpusId": 259165220
                },
                "corpusId": 259165220,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2e925205de0150d759518c767811dcbb89fca058",
                "title": "SaliencyCut: Augmenting Plausible Anomalies for Open-set Fine-Grained Anomaly Detection",
                "abstract": "Open-set fine-grained anomaly detection is a challenging task that requires learning discriminative fine-grained features to detect anomalies that were even unseen during training. As a cheap yet effective approach, data augmentation has been widely used to create pseudo anomalies for better training of such models. Recent wisdom of augmentation methods focuses on generating random pseudo instances that may lead to a mixture of augmented instances with seen anomalies, or out of the typical range of anomalies. To address this issue, we propose a novel saliency-guided data augmentation method, SaliencyCut, to produce pseudo but more common anomalies which tend to stay in the plausible range of anomalies. Furthermore, we deploy a two-head learning strategy consisting of normal and anomaly learning heads, to learn the anomaly score of each sample. Theoretical analyses show that this mechanism offers a more tractable and tighter lower bound of the data log-likelihood. We then design a novel patch-wise residual module in the anomaly learning head to extract and assess the fine-grained anomaly features from each sample, facilitating the learning of discriminative representations of anomaly instances. Extensive experiments conducted on six real-world anomaly detection datasets demonstrate the superiority of our method to the baseline and other state-of-the-art methods under various settings.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2153258359",
                        "name": "Jianan Ye"
                    },
                    {
                        "authorId": "1605779900",
                        "name": "Yijie Hu"
                    },
                    {
                        "authorId": "50030828",
                        "name": "Xi Yang"
                    },
                    {
                        "authorId": "2118815749",
                        "name": "Qiufeng Wang"
                    },
                    {
                        "authorId": "35933894",
                        "name": "Chaoqin Huang"
                    },
                    {
                        "authorId": "5380819",
                        "name": "Kaizhu Huang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "d8fb87ee41aa4189e64ff87c3919cc663fea217f",
                "externalIds": {
                    "DBLP": "journals/pr/LiCL23",
                    "DOI": "10.1016/j.patcog.2023.109398",
                    "CorpusId": 256670839
                },
                "corpusId": 256670839,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d8fb87ee41aa4189e64ff87c3919cc663fea217f",
                "title": "Human-related anomalous event detection via memory-augmented Wasserstein generative adversarial network with gradient penalty",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47576810",
                        "name": "Nanjun Li"
                    },
                    {
                        "authorId": "1800264",
                        "name": "F. Chang"
                    },
                    {
                        "authorId": "123266659",
                        "name": "Chunsheng Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "7fd9a5fa8c6c7582ce8b1b3379bc0431c3817b68",
                "externalIds": {
                    "DBLP": "journals/eswa/UllahUKB23",
                    "DOI": "10.1016/j.eswa.2023.120599",
                    "CorpusId": 259044462
                },
                "corpusId": 259044462,
                "publicationVenue": {
                    "id": "987139ae-a65d-49bb-aaf6-fb764dc40b19",
                    "name": "Expert systems with applications",
                    "type": "journal",
                    "alternate_names": [
                        "Expert syst appl",
                        "Expert Systems With Applications",
                        "Expert Syst Appl"
                    ],
                    "issn": "0957-4174",
                    "url": "https://www.journals.elsevier.com/expert-systems-with-applications/",
                    "alternate_urls": [
                        "https://www.sciencedirect.com/journal/expert-systems-with-applications",
                        "http://www.sciencedirect.com/science/journal/09574174"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7fd9a5fa8c6c7582ce8b1b3379bc0431c3817b68",
                "title": "Sequential attention mechanism for weakly supervised video anomaly detection",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1885384073",
                        "name": "Waseem Ullah"
                    },
                    {
                        "authorId": "66624503",
                        "name": "F. Ullah"
                    },
                    {
                        "authorId": "2151239083",
                        "name": "Zulfiqar Ahmad Khan"
                    },
                    {
                        "authorId": "1777998",
                        "name": "S. Baik"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Moreover, the memory module is also leveraged to record prototypical patterns of normal data via update mechanisms [4], [29].",
                "Finally, similar to the previous work [6], [29], [30], we measure the average area under the curve (AUC) by computing the area under the receiver operating characteristic"
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "e6ddd4a317db210c0a91d3b718c60aaeba6717d8",
                "externalIds": {
                    "DBLP": "journals/tcsv/HuangHLHZC23",
                    "DOI": "10.1109/TCSVT.2022.3227716",
                    "CorpusId": 254492218
                },
                "corpusId": 254492218,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e6ddd4a317db210c0a91d3b718c60aaeba6717d8",
                "title": "Boosting Variational Inference With Margin Learning for Few-Shot Scene-Adaptive Anomaly Detection",
                "abstract": "Anomaly detection in surveillance videos aims to identify frames where abnormal events happen. Existing approaches assume that the training and testing videos are from the same scene, exhibiting poor generalization performance when encountering an unseen scene. In this paper, we propose a Variational Anomaly Detection Network (VADNet), which is characterized by its high scene-adaptation - it can identify abnormal events in a new scene only via referring to a few normal samples without fine-tuning. Our model embodies two major innovations. First, a novel Variational Normal Inference (VNI) module is proposed to formulate image reconstruction in a conditional variational auto-encoder (CVAE) framework, which learns a probabilistic decision model instead of a traditional deterministic one. Secondly, a Margin Learning Embedding (MLE) module is leveraged to boost the variational inference and aid in distinguishing normal events. We theoretically demonstrate that minimizing the triplet loss in MLE module facilitates maximizing the evidence lower bound (ELBO) of CVAE, which promotes the convergence of VNI. By incorporating variational inference with margin learning, VADNet becomes much more generative that is able to handle the uncertainty caused by the changed scene and limited reference data. Extensive experiments on several datasets demonstrate that the proposed VADNet can adapt to a new scene effectively without fine-tuning and achieve remarkable performance, which outperforms other methods significantly and establishes new state-of-the-art in the case of few-shot scene-adaptive anomaly detection. We believe our method is closer to real-world application due to its strong generalization ability. All codes are released in https://github.com/huangxx156/VADNet.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2152662778",
                        "name": "Xin Huang"
                    },
                    {
                        "authorId": "46972432",
                        "name": "Yutao Hu"
                    },
                    {
                        "authorId": "2144526712",
                        "name": "Xiaoyan Luo"
                    },
                    {
                        "authorId": "151481622",
                        "name": "Jungong Han"
                    },
                    {
                        "authorId": "1740430",
                        "name": "Baochang Zhang"
                    },
                    {
                        "authorId": "40916581",
                        "name": "Xianbin Cao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[43] presented a new update scheme of the memory module over [42], in which both normal and"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "dbe1eb127c20920eaaa66d642098be26684930d4",
                "externalIds": {
                    "DBLP": "journals/tamd/LiCL23",
                    "DOI": "10.1109/TCDS.2022.3183997",
                    "CorpusId": 249906782
                },
                "corpusId": 249906782,
                "publicationVenue": {
                    "id": "f35f148a-0a3c-45db-b610-3d89e09ddf21",
                    "name": "IEEE Transactions on Cognitive and Developmental Systems",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Cogn Dev Syst"
                    ],
                    "issn": "2379-8920",
                    "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7274989"
                },
                "url": "https://www.semanticscholar.org/paper/dbe1eb127c20920eaaa66d642098be26684930d4",
                "title": "A Self-Trained Spatial Graph Convolutional Network for Unsupervised Human-Related Anomalous Event Detection in Complex Scenes",
                "abstract": "Most of previous works on abnormal event detection take this task as a novelty detection problem, which employ the supervised setting that needs videos containing only normal events for learning normal patterns. However, few works are developed under the unsupervised setting that detects anomaly without labeled normal videos. In this article, we develop a novel unsupervised algorithm using the skeleton feature for detecting human-related anomalous events. Our method applies the idea of self-training regression for iteratively updating the anomaly scores of skeletons for anomaly detection. In detail, each extracted skeleton is first decomposed into global and local feature components. Then, an unsupervised anomaly detector is operated on these two components to generate the initial anomalous and normal skeleton sets. These two sets are utilized to optimize parameters of an anomaly scoring module consisting of a spatial graph convolutional network (SGCN) and fully connected layers. The trained module is then employed to recalculate anomaly scores of all skeletons to update memberships of pseudo anomalous and normal skeletons set for the next training procedure, and this process is performed in an iterative way to get superior anomaly detection performance. Experimental results on two challenging data sets and their subsets that only contain human-related anomalies demonstrate our method outperforms several state-of-the-art supervised methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47576810",
                        "name": "Nanjun Li"
                    },
                    {
                        "authorId": "1800264",
                        "name": "F. Chang"
                    },
                    {
                        "authorId": "123266659",
                        "name": "Chunsheng Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Due to the lack of published results on human-related anomalies on the UCF-Crime dataset, we implement the code of literature [11, 35, 39], where [39] takes [35] as the backbone."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c4be85fdc531a5c34e21d78daac4c660224834af",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiuWZL023",
                    "DOI": "10.1109/CVPR52729.2023.02347",
                    "CorpusId": 260084823
                },
                "corpusId": 260084823,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c4be85fdc531a5c34e21d78daac4c660224834af",
                "title": "Generating Anomalies for Video Anomaly Detection with Prompt-based Feature Mapping",
                "abstract": "Anomaly detection in surveillance videos is a challenging computer vision task where only normal videos are available during training. Recent work released the first virtual anomaly detection dataset to assist real-world detection. However, an anomaly gap exists because the anomalies are bounded in the virtual dataset but unbounded in the real world, so it reduces the generalization ability of the virtual dataset. There also exists a scene gap between virtual and real scenarios, including scene-specific anomalies (events that are abnormal in one scene but normal in another) and scene-specific attributes, such as the viewpoint of the surveillance camera. In this paper, we aim to solve the problem of the anomaly gap and scene gap by proposing a prompt-based feature mapping framework (PFMF). The PFMF contains a mapping network guided by an anomaly prompt to generate unseen anomalies with unbounded types in the real scenario, and a mapping adaptation branch to narrow the scene gap by applying domain classifier and anomaly classifier. The proposed framework outperforms the state-of-the-art on three benchmark datasets. Extensive ablation experiments also show the effectiveness of our framework design.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1720679125",
                        "name": "Zuhao Liu"
                    },
                    {
                        "authorId": "2224384249",
                        "name": "Xiao-Ming Wu"
                    },
                    {
                        "authorId": "2224337700",
                        "name": "Dian Zheng"
                    },
                    {
                        "authorId": "145013251",
                        "name": "Kun-Yu Lin"
                    },
                    {
                        "authorId": "2152975905",
                        "name": "Weihao Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This relies on using generative models to learn the representations of normal samples in video clips by minimising the reconstruction error [18] [28] [31] [32] [35] [42]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a7641ccda07a2fa80259ab5adfe000ed689c8f44",
                "externalIds": {
                    "DBLP": "conf/cvpr/GausBISAB23",
                    "DOI": "10.1109/CVPRW59228.2023.00301",
                    "CorpusId": 260919945
                },
                "corpusId": 260919945,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a7641ccda07a2fa80259ab5adfe000ed689c8f44",
                "title": "Region-based Appearance and Flow Characteristics for Anomaly Detection in Infrared Surveillance Imagery",
                "abstract": "Anomaly detection is a classical problem within automated visual surveillance, namely the determination of the normal from the abnormal when operational data availability is highly biased towards one class (normal) due to both insufficient sample size, and inadequate distribution coverage for the other class (abnormal). In this work, we propose the dual use of both visual appearance and localized motion characteristics, derived from optic flow, applied on a per-region basis to facilitate object-wise anomaly detection within this context. Leveraging established object localization techniques from a region proposal network, optic flow is extracted from each object region and combined with appearance in the far infrared (thermal) band to give a 3-channel spatiotemporal tensor representation for each object (1 \u00d7 thermal - spatial appearance; 2 \u00d7 optic flow magnitude as x and y components - temporal motion). This formulation is used as the basis for training contemporary semi-supervised anomaly detection approaches in a region-based manner such that anomalous objects can be detected as a combination of appearance and/or motion within the scene. Evaluation is performed using the Long-Term infrared (thermal) Imaging (LTD) benchmark dataset against which successful detection of both anomalous object appearance and motion characteristics are demonstrated using a range of semi-supervised anomaly detection approaches.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2747096",
                        "name": "Y. F. A. Gaus"
                    },
                    {
                        "authorId": "40336981",
                        "name": "Neelanjan Bhowmik"
                    },
                    {
                        "authorId": "1483815265",
                        "name": "Brian K. S. Isaac-Medina"
                    },
                    {
                        "authorId": "2840036",
                        "name": "Hubert P. H. Shum"
                    },
                    {
                        "authorId": "1404348990",
                        "name": "Amir Atapour-Abarghouei"
                    },
                    {
                        "authorId": "1803808",
                        "name": "T. Breckon"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "21a3ad7d8b01c0e26e00b52d2a5485ebce8b2292",
                "externalIds": {
                    "DBLP": "conf/cvpr/ChoKHP0L23",
                    "DOI": "10.1109/CVPR52729.2023.01168",
                    "CorpusId": 261008298
                },
                "corpusId": 261008298,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/21a3ad7d8b01c0e26e00b52d2a5485ebce8b2292",
                "title": "Look Around for Anomalies: Weakly-Supervised Anomaly Detection via Context-Motion Relational Learning",
                "abstract": "Weakly-supervised Video Anomaly Detection is the task of detecting frame-level anomalies using video-level labeled training data. It is difficult to explore class representative features using minimal supervision of weak labels with a single backbone branch. Furthermore, in real-world scenarios, the boundary between normal and abnormal is ambiguous and varies depending on the situation. For example, even for the same motion of running person, the abnormality varies depending on whether the surroundings are a playground or a roadway. Therefore, our aim is to extract discriminative features by widening the relative gap between classes' features from a single branch. In the proposed Class-Activate Feature Learning (CLAV), the features are extracted as per the weights that are implicitly activated depending on the class, and the gap is then enlarged through relative distance learning. Furthermore, as the relationship between context and motion is important in order to identify the anomalies in complex and diverse scenes, we propose a Context-Motion Interrelation Module (CoMo), which models the relationship between the appearance of the surroundings and motion, rather than utilizing only temporal dependencies or motion information. The proposed method shows SOTA performance on four benchmarks including large-scale real-world datasets, and we demonstrate the importance of relational information by analyzing the qualitative results and generalization ability.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1387831061",
                        "name": "Myeongah Cho"
                    },
                    {
                        "authorId": "2145950051",
                        "name": "Minjung Kim"
                    },
                    {
                        "authorId": "70397255",
                        "name": "Sangwon Hwang"
                    },
                    {
                        "authorId": "2109124052",
                        "name": "Chaewon Park"
                    },
                    {
                        "authorId": "2187084311",
                        "name": "Kyungjae Lee"
                    },
                    {
                        "authorId": "39847092",
                        "name": "Sangyoun Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Compared with anomaly detection [3, 23, 26], open-set 3D semantic segmentation (O3D) is more challenging, for it also needs to assign labels to seen-class data simultaneously, as shown in Figure 1."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "22f44a52dd9ec98fb610c93018335a8ccf830a58",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiD23",
                    "DOI": "10.1109/CVPR52729.2023.00909",
                    "CorpusId": 260841129
                },
                "corpusId": 260841129,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/22f44a52dd9ec98fb610c93018335a8ccf830a58",
                "title": "Open-set Semantic Segmentation for Point Clouds via Adversarial Prototype Framework",
                "abstract": "Recently, point cloud semantic segmentation has attracted much attention in computer vision. Most of the existing works in literature assume that the training and testing point clouds have the same object classes, but they are generally invalid in many real-world scenarios for identifying the 3D objects whose classes are not seen in the training set. To address this problem, we propose an Adversarial Prototype Framework (APF) for handling the open-set 3D semantic segmentation task, which aims to identify 3D unseen-class points while maintaining the segmentation performance on seen-class points. The proposed APF consists of a feature extraction module for extracting point features, a prototypical constraint module, and a feature adversarial module. The prototypical constraint module is designed to learn prototypes for each seen class from point features. The feature adversarial module utilizes generative adversarial networks to estimate the distribution of unseenclass features implicitly, and the synthetic unseen-class features are utilized to prompt the model to learn more effective point features and prototypes for discriminating unseen-class samples from the seen-class ones. Experimental results on two public datasets demonstrate that the proposed APF outperforms the comparative methods by a large margin in most cases.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2233240458",
                        "name": "Jianan Li"
                    },
                    {
                        "authorId": "40204102",
                        "name": "Qiulei Dong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Park et al. propose augmenting a U-net style encoderdecoder (i.e., a network model for future frame prediction and reconstruction) by using a Memory Module trained to store important features of the normal mode.",
                "The function of the Memory Module[3] is primarily to assist AE in recording normal frame features, weaken the representation ability of CNN, and then achieve the purpose of distinguishing normal frames from abnormal frames.",
                "In order to solve this problem, there is a method of adding a Memory Module in AE.",
                "Subsequent improvements to the Memory Module have significantly reduced the consumption of the Memory Module, resulting in good results."
            ],
            "isInfluential": true,
            "intents": [],
            "citingPaper": {
                "paperId": "4a456f37ebfa595bf3e41cf4b0d83067d0978ce0",
                "externalIds": {
                    "DOI": "10.1117/12.2675188",
                    "CorpusId": 258910373
                },
                "corpusId": 258910373,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/4a456f37ebfa595bf3e41cf4b0d83067d0978ce0",
                "title": "A video anomaly detection method with mask convolution and channel attention",
                "abstract": "Aiming at the problem of Insufficient feature extraction for data sets in video anomaly detection, an enhanced detection method combining masked convolution and channel attention is proposed. The auto-encoder structure is adapted, and a mask convolution module and a channel attention module are embedded in the memory model. The effectiveness of the proposed method is demonstrated by comparing the results of the method and the original method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2218380789",
                        "name": "Dawei Yang"
                    },
                    {
                        "authorId": "2109076489",
                        "name": "Zhiquan Liu"
                    },
                    {
                        "authorId": "2218203467",
                        "name": "Haiyan Hao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "314076656c9e684c3f79e040b92f32c0afaa6d7d",
                "externalIds": {
                    "ArXiv": "2305.13611",
                    "DBLP": "journals/corr/abs-2305-13611",
                    "DOI": "10.1109/CVPR52729.2023.01953",
                    "CorpusId": 258840984
                },
                "corpusId": 258840984,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/314076656c9e684c3f79e040b92f32c0afaa6d7d",
                "title": "A New Comprehensive Benchmark for Semi-supervised Video Anomaly Detection and Anticipation",
                "abstract": "Semi-supervised video anomaly detection (VAD) is a critical task in the intelligent surveillance system. However, an essential type of anomaly in VAD named scene-dependent anomaly has not received the attention of researchers. Moreover, there is no research investigating anomaly anticipation, a more significant task for preventing the occurrence of anomalous events. To this end, we propose a new comprehensive dataset, NWPU Campus, containing 43 scenes, 28 classes of abnormal events, and 16 hours of videos. At present, it is the largest semi-supervised VAD dataset with the largest number of scenes and classes of anomalies, the longest duration, and the only one considering the scene-dependent anomaly. Meanwhile, it is also the first dataset proposed for video anomaly anticipation. We further propose a novel model capable of detecting and anticipating anomalous events simultaneously. Compared with 7 outstanding VAD algorithms in recent years, our method can cope with scene-dependent anomaly detection and anomaly anticipation both well, achieving state-of-the-art performance on ShanghaiTech, CUHK Avenue, IITB Corridor and the newly proposed NWPU Campus datasets consistently. Our dataset and code is available at: https://campusvad.github.io.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3201156",
                        "name": "Congqi Cao"
                    },
                    {
                        "authorId": "2140029231",
                        "name": "Yue Lu"
                    },
                    {
                        "authorId": "2155302795",
                        "name": "Peng Wang"
                    },
                    {
                        "authorId": "2047640322",
                        "name": "Yanning Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, prediction-based frameworks [37, 39, 40] utilize a dedicatedly designed network that directly maps a query frame into a futuristic frame."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "366a171ce994fe0707bb3b665401d1d29aa1b9cb",
                "externalIds": {
                    "DBLP": "journals/mlc/JavedYLAR23",
                    "DOI": "10.1007/s13042-023-01851-4",
                    "CorpusId": 258818203
                },
                "corpusId": 258818203,
                "publicationVenue": {
                    "id": "a0c45882-7c78-4f0c-8886-d3481ba02586",
                    "name": "International Journal of Machine Learning and Cybernetics",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Mach Learn Cybern"
                    ],
                    "issn": "1868-8071",
                    "url": "http://www.springer.com/engineering/mathematical/journal/13042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/13042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/366a171ce994fe0707bb3b665401d1d29aa1b9cb",
                "title": "learning anomalous human actions using frames of interest and decoderless deep embedded clustering",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2065915521",
                        "name": "Muhammad Hafeez Javed"
                    },
                    {
                        "authorId": "50077927",
                        "name": "Zeng Yu"
                    },
                    {
                        "authorId": "2157466662",
                        "name": "Tianrui Li"
                    },
                    {
                        "authorId": "2143882038",
                        "name": "Noreen Anwar"
                    },
                    {
                        "authorId": "2233190238",
                        "name": "Taha M. Rajeh"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Generally, the judgement is based on reconstruction or prediction errors [5].",
                "We compare the proposed method with Conv-AE [11], ConvLSTM-AE [38], AE-Conv3D [15], Unmasking [39], Stacked RNN [21], Frame-Pred [16], MemAE [12], sRNNAE [22] and MNAD [5] on CUHK Avenue dataset in terms of",
                "The frame-level anomaly score scrFR(n + t) for the nth test is calculated by normalizing PSN R( \u00cen+t , In+t ) as follows [5], [16]:",
                "[5] adopt a strategy to update the memory module even during testing.",
                "1) Frame-Level Anomaly Detection: We compare the framelevel AUCs of the proposed method with MPPCA [41], MPPC+SFA [35], MDT [35], Unmasking [39], Conv-AE [11], ConvLSTM-AE [38], Stacked RNN [21], Frame-Pred [16], MemAE [12], LatSp-AG [42], sRNN-AE [22], DeepOC [43], MNAD [5] and ROADMAP [17] on UCSD dataset as listed in Table III.",
                "In Table II, we compare AUCs of the proposed method with Conv-AE [11], TSC [21], Stacked RNN [21], MemAEnonSpar [12], Frame-Pred [16], MemAE [12], MNAD [5] and sRNN-AE [22] in the frame-level evaluation.",
                "trained Frame-Pred [16] without constructing dictionaries or memory, the memory-based MNAD [5], and the proposed method.",
                "We select the memory-based MNAD [5] attaining the top AUC on UCSD Ped2 in the frame-level"
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a5e107a1112c88294f44989f6622433fb402fb31",
                "externalIds": {
                    "DBLP": "journals/tcsv/ZhangFYCL23",
                    "DOI": "10.1109/TCSVT.2022.3221622",
                    "CorpusId": 253470822
                },
                "corpusId": 253470822,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a5e107a1112c88294f44989f6622433fb402fb31",
                "title": "Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes",
                "abstract": "Crowds often appear in surveillance videos in public places, from which anomaly detection is of great importance to public safety. Since the abnormal cases are rare, variable and unpredictable, autoencoders with encoder and decoder structures using only normal samples have become a hot topic among various approaches for anomaly detection. However, since autoencoders have excessive generalization ability, they can sometimes still reconstruct abnormal cases very well. Recently, some researchers construct memory modules under normal conditions and use these normal memory items to reconstruct test samples during inference to increase the reconstruction errors for anomalies. However, in practice, the errors of reconstructing normal samples with the memory items often increase as well, which makes it still difficult to distinguish between normal and abnormal cases. In addition, the memory-based autoencoder is usually available only in the specific scene where the memory module is constructed and almost loses the prospect of cross-scene applications. We mitigate the overgeneralization of autoencoders from a different perspective, namely, by reducing the prediction errors for normal cases rather than increasing the prediction errors for abnormal cases. To this end, we propose an autoencoder based on hybrid attention and motion constraint for anomaly detection. The hybrid attention includes the channel attention used in the encoding process and spatial attention added to the skip connection between the encoder and decoder. The hybrid attention is introduced to reduce the weight of the feature channels and regions representing the background in the feature matrix, which makes the autoencoder features more focused on optimizing the representation of the normal targets during training. Furthermore, we introduce motion constraint to improve the autoencoder\u2019s ability to predict normal activities in crowded scenes. We conduct experiments on real-world surveillance videos, UCSD, CUHK Avenue, and ShanghaiTech datasets. The experimental results indicate that the prediction errors of the proposed method for frequent normal crowd activities are smaller than those of other approaches, which increases the gap between the prediction errors for normal frames and the prediction errors for abnormal frames. In addition, the proposed method does not depend on a specific scene. Therefore, it balances good anomaly detection performance and strong cross-scene capability.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108166116",
                        "name": "Xinfeng Zhang"
                    },
                    {
                        "authorId": "2159079464",
                        "name": "Jinpeng Fang"
                    },
                    {
                        "authorId": "2115355434",
                        "name": "Baoqing Yang"
                    },
                    {
                        "authorId": "2107946888",
                        "name": "Shuhan Chen"
                    },
                    {
                        "authorId": "2156072360",
                        "name": "Bin Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The other hyper-parameters are set following [36]: \u03bbc=0.",
                "[36], [37], [38], [39] is mostly supposed to be an unsupervised learning problem which the model learns to describe normality"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "b95533611d08f00daa03fbf28a4c57456aaf2880",
                "externalIds": {
                    "DBLP": "journals/tcsv/GaoZC23",
                    "DOI": "10.1109/TCSVT.2022.3221723",
                    "CorpusId": 253544520
                },
                "corpusId": 253544520,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b95533611d08f00daa03fbf28a4c57456aaf2880",
                "title": "Robust Tracking via Learning Model Update With Unsupervised Anomaly Detection Philosophy",
                "abstract": "Template tracking is a typical paradigm to adaptively locate arbitrary objects in the tracking literature. Although existing works present diverse template updating approaches, one of the essential problems of template updating has not been solved effectively, i.e., when and how to update a template. In this work, we treat the updating time as an abnormal moment that indicates the previous template cannot depict the target accurately any more. Thus, we introduce an effective State-Edge Awareness (SEA) module that detect such abnormal moments via unsupervised anomaly detection. To be specific, by retaining multi search frames of a video, SEA firstly analysis the correlation features that generated by the template and search images. Then, it estimates the measurement for abnormal degree that is regarded as the sign for template updating. As a result, our method can not only capture the updating time automatically, but also update the templates effectively. Furthermore, the effectiveness of the proposed method has been verified on a representative CNN-based and Transformer-based tracker, respectively. The experimental results on five popular benchmarks show that our tracker can achieve the state-of-the-art performance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2143977478",
                        "name": "Jie Gao"
                    },
                    {
                        "authorId": "40296597",
                        "name": "Bineng Zhong"
                    },
                    {
                        "authorId": "2144284116",
                        "name": "Yan Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "f9c43bf5d8b742f1b4f72e0a6d43c58db66e7b98",
                "externalIds": {
                    "DOI": "10.1016/j.infrared.2023.104718",
                    "CorpusId": 258675946
                },
                "corpusId": 258675946,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f9c43bf5d8b742f1b4f72e0a6d43c58db66e7b98",
                "title": "Memory Linked Knowledge Domain Transfer Few-shot Learning for Thermography Nondestructive Evaluation System",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2067733797",
                        "name": "Jian-ru Xue"
                    },
                    {
                        "authorId": "143701487",
                        "name": "Bin Gao"
                    },
                    {
                        "authorId": "2164717838",
                        "name": "Guohao Liu"
                    },
                    {
                        "authorId": "2108243337",
                        "name": "Yuming Zhang"
                    },
                    {
                        "authorId": "1384252039",
                        "name": "Wai Lok Woo"
                    },
                    {
                        "authorId": "2152916644",
                        "name": "Yang Yang"
                    },
                    {
                        "authorId": "2111509566",
                        "name": "Yongjie Yu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "5a46c0c39ff938c9728fc25115fe7124debe1d1c",
                "externalIds": {
                    "DBLP": "journals/iswa/CaetanoCC23",
                    "DOI": "10.1016/j.iswa.2023.200236",
                    "CorpusId": 258885567
                },
                "corpusId": 258885567,
                "publicationVenue": {
                    "id": "e902b33a-fbe2-45e9-adbe-320952691b1e",
                    "name": "Intelligent Systems with Applications",
                    "type": "journal",
                    "alternate_names": [
                        "Intelligent Systems and Applications",
                        "SAI Intell Syst Conf",
                        "IntelliSys",
                        "SAI Intelligent Systems Conference",
                        "Intell Syst Appl"
                    ],
                    "issn": "2667-3053",
                    "url": "https://www.journals.elsevier.com/intelligent-systems-with-applications"
                },
                "url": "https://www.semanticscholar.org/paper/5a46c0c39ff938c9728fc25115fe7124debe1d1c",
                "title": "Unveiling the performance of video anomaly detection models - A benchmark-based review",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2187268185",
                        "name": "Francisco Caetano"
                    },
                    {
                        "authorId": "153253956",
                        "name": "P. Carvalho"
                    },
                    {
                        "authorId": "2176561281",
                        "name": "Jaime Cardoso"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To prove the efficiency of the method proposed in this paper, we compare our model with the SOTA model, including reconstruction-based methods such as R-VAD [45], ConvVAD [39], MEM-VAD [62], LAD [10], GMFC-VAE [63], MemAE [64], and C-VAD [65]; future frame prediction-based methods such as VEC [66], FPVAD [26], CPNet [9], ConvVRNN [67], Attention-VAD [68], D-VAD [69], and S-VAD [70]; and methods based on multiple information sources such as ASSVAD [71], MPED-RNN [72], ST-CAE [73], AnoPCN [74], and PR-AD [75]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "228273c1beb2f54a56dd19a650e73c10780044c5",
                "externalIds": {
                    "DBLP": "journals/sensors/Huang00CW023",
                    "PubMedCentral": "10221939",
                    "DOI": "10.3390/s23104828",
                    "CorpusId": 258801776,
                    "PubMed": "37430742"
                },
                "corpusId": 258801776,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/228273c1beb2f54a56dd19a650e73c10780044c5",
                "title": "A Novel Unsupervised Video Anomaly Detection Framework Based on Optical Flow Reconstruction and Erased Frame Prediction",
                "abstract": "Reconstruction-based and prediction-based approaches are widely used for video anomaly detection (VAD) in smart city surveillance applications. However, neither of these approaches can effectively utilize the rich contextual information that exists in videos, which makes it difficult to accurately perceive anomalous activities. In this paper, we exploit the idea of a training model based on the \u201cCloze Test\u201d strategy in natural language processing (NLP) and introduce a novel unsupervised learning framework to encode both motion and appearance information at an object level. Specifically, to store the normal modes of video activity reconstructions, we first design an optical stream memory network with skip connections. Secondly, we build a space\u2013time cube (STC) for use as the basic processing unit of the model and erase a patch in the STC to form the frame to be reconstructed. This enables a so-called \u201dincomplete event (IE)\u201d to be completed. On this basis, a conditional autoencoder is utilized to capture the high correspondence between optical flow and STC. The model predicts erased patches in IEs based on the context of the front and back frames. Finally, we employ a generating adversarial network (GAN)-based training method to improve the performance of VAD. By distinguishing the predicted erased optical flow and erased video frame, the anomaly detection results are shown to be more reliable with our proposed method which can help reconstruct the original video in IE. Comparative experiments conducted on the benchmark UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets demonstrate AUROC scores reaching 97.7%, 89.7%, and 75.8%, respectively.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2217679905",
                        "name": "Heqing Huang"
                    },
                    {
                        "authorId": "2112633550",
                        "name": "Bing Zhao"
                    },
                    {
                        "authorId": "2152329578",
                        "name": "F. Gao"
                    },
                    {
                        "authorId": "2158171809",
                        "name": "Penghui Chen"
                    },
                    {
                        "authorId": "66063792",
                        "name": "J. Wang"
                    },
                    {
                        "authorId": "145125161",
                        "name": "A. Hussain"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "393a1d10ff992dd2de7cf972d30a4e290ea88796",
                "externalIds": {
                    "DOI": "10.1117/1.JEI.32.3.033015",
                    "CorpusId": 259036174
                },
                "corpusId": 259036174,
                "publicationVenue": {
                    "id": "c677ab24-0c04-487d-83e2-c252af9479c8",
                    "name": "Journal of Electronic Imaging (JEI)",
                    "type": "journal",
                    "alternate_names": [
                        "J Electron Imaging (JEI",
                        "Journal of Electronic Imaging",
                        "J Electron Imaging"
                    ],
                    "issn": "1017-9909",
                    "url": "https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging",
                    "alternate_urls": [
                        "http://electronicimaging.spiedigitallibrary.org/journal.aspx"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/393a1d10ff992dd2de7cf972d30a4e290ea88796",
                "title": "Deep stacked denoising autoencoder for unsupervised anomaly detection in video surveillance",
                "abstract": "Abstract. Due to the increase of crime and terror, security concerns are rising rapidly every day. The use of surveillance cameras for abnormal behavior detection has become an indispensable part of human beings. But the performance of most of the developed systems is not up to the mark because of the low performance and accuracy in detecting the abnormality in the videos due to mainly the presence of noise. The videos captured by the surveillance camera are generally born with no or more noise due to various reasons. To resolve such issues, we provide a snapshot regarding different categories of noise and handcraft techniques to resolve them. Non-local means, block matching, and 3D filtering filters perform astonishingly well while denoising the images. We also present a robust unsupervised deep learning model called deep stacked denoising autoencoder (DSDAE) for denoising the images and further use it for abnormal activity detection and localization in the videos. Our approach has achieved a noteworthy result in image denoising compared to other handcraft-based techniques. DSDAE uses a separate encoder for the extraction of appearance features using clean and noisy images and motion features through the optical flow images. Early fusion is done in the extracted features and passed to the decoder. Only those pixels whose reconstruction error is greater than the threshold will be considered abnormal pixels. Experiment results are compared quantitatively/qualitatively with the recent competitive state-of-the-art methods in the publicly available benchmark datasets Ped1, Ped2, CUHK Avenue, and ShanghaiTech that demonstrate the superior accuracy and performance of our DSDAE. The obtained area under the curve of DSDAE in Ped1, Ped2, CUHK Avenue, and ShanghaiTech is 98.14%, 97.92%, 95.89%, and 96.7%, respectively, whereas equal error rate for the same datasets is 5.4%, 4.5%, 12.03%, and 7.8%, respectively.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "41076439",
                        "name": "Sanjay Roka"
                    },
                    {
                        "authorId": "2310681",
                        "name": "M. Diwakar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Motivated by a line of research on memory-augmented anomaly detection [8, 24], we put constraints on the learnable parameters to contrast differency of memory items."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "4e93098d60589cc748217fdb21581834fa190e44",
                "externalIds": {
                    "DBLP": "conf/www/Jiang0TY0SCS23",
                    "DOI": "10.1145/3543507.3583991",
                    "CorpusId": 258333658
                },
                "corpusId": 258333658,
                "publicationVenue": {
                    "id": "e07422f9-c065-40c3-a37b-75e98dce79fe",
                    "name": "The Web Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Web Conf",
                        "WWW"
                    ],
                    "url": "http://www.iw3c2.org/"
                },
                "url": "https://www.semanticscholar.org/paper/4e93098d60589cc748217fdb21581834fa190e44",
                "title": "Learning Social Meta-knowledge for Nowcasting Human Mobility in Disaster",
                "abstract": "Human mobility nowcasting is a fundamental research problem for intelligent transportation planning, disaster responses and management, etc. In particular, human mobility under big disasters such as hurricanes and pandemics deviates from its daily routine to a large extent, which makes the task more challenging. Existing works mainly focus on traffic or crowd flow prediction in normal situations. To tackle this problem, in this study, disaster-related Twitter data is incorporated as a covariate to understand the public awareness and attention about the disaster events and thus perceive their impacts on the human mobility. Accordingly, we propose a Meta-knowledge-Memorizable Spatio-Temporal Network (MemeSTN), which leverages memory network and meta-learning to fuse social media and human mobility data. Extensive experiments over three real-world disasters including Japan 2019 typhoon season, Japan 2020 COVID-19 pandemic, and US 2019 hurricane season were conducted to illustrate the effectiveness of our proposed solution. Compared to the state-of-the-art spatio-temporal deep models and multivariate-time-series deep models, our model can achieve superior performance for nowcasting human mobility in disaster situations at both country level and state level.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "31279896",
                        "name": "Renhe Jiang"
                    },
                    {
                        "authorId": "2144719549",
                        "name": "Zhaonan Wang"
                    },
                    {
                        "authorId": "2868174",
                        "name": "Yudong Tao"
                    },
                    {
                        "authorId": "46962297",
                        "name": "Chuang Yang"
                    },
                    {
                        "authorId": "2112276021",
                        "name": "Xuan Song"
                    },
                    {
                        "authorId": "1721111",
                        "name": "R. Shibasaki"
                    },
                    {
                        "authorId": "1705664",
                        "name": "Shu\u2010Ching Chen"
                    },
                    {
                        "authorId": "144987531",
                        "name": "M. Shyu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To enhance the ability to model complex distributions, the variational autoencoder [6] has improved the autoencoder, and the memory structures [4, 12] are introduced to enhance modeling of normal modes.",
                "Existing works mainly learn the difference between abnormal behavior and normal behavior at a local level [2, 4, 7, 10, 12], ignoring the multi-level context of abnormal snippets and failing to identify abnormal behaviors that are similar to normal behavior."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "1ab450c7bac8c69c1a5e84406c0b7da6344e80d1",
                "externalIds": {
                    "DBLP": "journals/mms/LiuLLH23",
                    "DOI": "10.1007/s00530-023-01093-y",
                    "CorpusId": 258341719
                },
                "corpusId": 258341719,
                "publicationVenue": {
                    "id": "d1997ea9-9d41-4458-9280-94feb013bd15",
                    "name": "Multimedia Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Syst"
                    ],
                    "issn": "0942-4962",
                    "url": "http://www.springer.com/computer/information+systems+and+applications/journal/530?changeHeader",
                    "alternate_urls": [
                        "https://link.springer.com/journal/530",
                        "http://www.springer.com/computer/information+systems+and+applications/journal/530?changeHeader="
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1ab450c7bac8c69c1a5e84406c0b7da6344e80d1",
                "title": "Weakly supervised anomaly detection with multi-level contextual modeling",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2049018561",
                        "name": "Mengting Liu"
                    },
                    {
                        "authorId": "2116134669",
                        "name": "Xinrui Li"
                    },
                    {
                        "authorId": "2108136730",
                        "name": "Yong-ge Liu"
                    },
                    {
                        "authorId": "144622313",
                        "name": "Yahong Han"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Ano-pred [35], MNAD [38] and MPN [39] all detect anomaly by the prediction and reconstruction of the whole video frame.",
                "Ano-pred [35], MNAD [38] and MPN [39] all detect anomaly by the prediction and reconstruction of the whole",
                "With the powerful feature representation capability of CNNs, convolutional autoencoders are widely used to reconstruct training data, such as CONV-AE [36], MNAD [38] and MPN [39].",
                "In order to better compare different detection methods, the proposed Stage I (underwater near-vertical human detection) is combined with Ano-pred, MNAD and MPN, and modified these methods into two-stage methods."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "16be25ea091d7f1acdd6398fe8e69abb644ceb77",
                "externalIds": {
                    "DBLP": "journals/nca/HeYLZ23",
                    "DOI": "10.1007/s00521-023-08526-9",
                    "CorpusId": 258224387
                },
                "corpusId": 258224387,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/16be25ea091d7f1acdd6398fe8e69abb644ceb77",
                "title": "A video system based on convolutional autoencoder for drowning detection",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2116554959",
                        "name": "Xinyue He"
                    },
                    {
                        "authorId": "2056632200",
                        "name": "Fei Yuan"
                    },
                    {
                        "authorId": "2185034991",
                        "name": "Tingzhuang Liu"
                    },
                    {
                        "authorId": "2117913655",
                        "name": "Yi Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "It is worth differentiating the definition of unsupervised VAD [13] from one-class VAD since the latter is being referred to as unsupervised in some studies [14, 15, 10, 16, 17, 18]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "0de66912edc5d8b4bdcfb8ddc0f6ebbf795831d2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-05841",
                    "ArXiv": "2304.05841",
                    "DOI": "10.48550/arXiv.2304.05841",
                    "CorpusId": 258079336
                },
                "corpusId": 258079336,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0de66912edc5d8b4bdcfb8ddc0f6ebbf795831d2",
                "title": "Exploring Diffusion Models for Unsupervised Video Anomaly Detection",
                "abstract": "This paper investigates the performance of diffusion models for video anomaly detection (VAD) within the most challenging but also the most operational scenario in which the data annotations are not used. As being sparse, diverse, contextual, and often ambiguous, detecting abnormal events precisely is a very ambitious task. To this end, we rely only on the information-rich spatio-temporal data, and the reconstruction power of the diffusion models such that a high reconstruction error is utilized to decide the abnormality. Experiments performed on two large-scale video anomaly detection datasets demonstrate the consistent improvement of the proposed method over the state-of-the-art generative models while in some cases our method achieves better scores than the more complex models. This is the first study using a diffusion model and examining its parameters' influence to present guidance for VAD in surveillance scenarios.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "152459543",
                        "name": "Anil Osman Tur"
                    },
                    {
                        "authorId": "2139552672",
                        "name": "Nicola Dall\u2019Asen"
                    },
                    {
                        "authorId": "50150787",
                        "name": "C. Beyan"
                    },
                    {
                        "authorId": "40811261",
                        "name": "E. Ricci"
                    }
                ]
            }
        },
        {
            "contexts": [
                "4 shows the results of video frames restored by our method compared with the output of existing reconstruction-based [33] and prediction-based methods [19].",
                "We do not employ other assists such as optical flow [4], adversarial training [19], extraction of the foreground objects [30], or memory enhancement [8, 33]."
            ],
            "isInfluential": false,
            "intents": [
                "result",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "173cc12234e34d65ee4e9a53d3cddedde7b4b544",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-05112",
                    "ArXiv": "2304.05112",
                    "DOI": "10.1109/CVPR52729.2023.01402",
                    "CorpusId": 258060195
                },
                "corpusId": 258060195,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/173cc12234e34d65ee4e9a53d3cddedde7b4b544",
                "title": "Video Event Restoration Based on Keyframes for Video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) is a significant computer vision problem. Existing deep neural network (DNN) based VAD methods mostly follow the route of frame reconstruction or frame prediction. However, the lack of mining and learning of higher-level visual features and temporal context relationships in videos limits the further performance of these two approaches. Inspired by video codec theory, we introduce a brand-new VAD paradigm to break through these limitations: First, we propose a new task of video event restoration based on keyframes. Encouraging DNN to infer missing multiple frames based on video keyframes so as to restore a video event, which can more effectively motivate DNN to mine and learn potential higher-level visual features and comprehensive temporal context relationships in the video. To this end, we propose a novel U-shaped Swin Transformer Network with Dual Skip Connections (USTN-DSC) for video event restoration, where a cross-attention and a temporal upsampling residual skip connection are introduced to further assist in restoring complex static and dynamic motion object features in the video. In addition, we propose a simple and effective adjacent frame difference loss to constrain the motion consistency of the video sequence. Extensive experiments on benchmarks demonstrate that USTN-DSC outperforms most existing methods, validating the effectiveness of our method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2144391581",
                        "name": "Zhiwei Yang"
                    },
                    {
                        "authorId": "2163063860",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "2109666206",
                        "name": "Zhaoyang Wu"
                    },
                    {
                        "authorId": "2678268",
                        "name": "Peng Wu"
                    },
                    {
                        "authorId": "2144485784",
                        "name": "Xiaotao Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We compared our method on itwith some existing methods, including baseline methods: f-AnoGAN [26], AE [18], VAE [27], and MNAD [28]; state-of-the-art methods: S-T [6], SPADE [15], DREAM [24], Pachcore [5], RD4AD [12], and GCAD [18]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a865519bd5373cc5b73f672c1c787064c380aaaf",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-17882",
                    "ArXiv": "2303.17882",
                    "DOI": "10.48550/arXiv.2303.17882",
                    "CorpusId": 257901176
                },
                "corpusId": 257901176,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a865519bd5373cc5b73f672c1c787064c380aaaf",
                "title": "Visual Anomaly Detection via Dual-Attention Transformer and Discriminative Flow",
                "abstract": "In this paper, we introduce the novel state-of-the-art Dual-attention Transformer and Discriminative Flow (DADF) framework for visual anomaly detection. Based on only normal knowledge, visual anomaly detection has wide applications in industrial scenarios and has attracted significant attention. However, most existing methods fail to meet the requirements. In contrast, the proposed DTDF presents a new paradigm: it firstly leverages a pre-trained network to acquire multi-scale prior embeddings, followed by the development of a vision Transformer with dual attention mechanisms, namely self-attention and memorial-attention, to achieve two-level reconstruction for prior embeddings with the sequential and normality association. Additionally, we propose using normalizing flow to establish discriminative likelihood for the joint distribution of prior and reconstructions at each scale. The DADF achieves 98.3/98.4 of image/pixel AUROC on Mvtec AD; 83.7 of image AUROC and 67.4 of pixel sPRO on Mvtec LOCO AD benchmarks, demonstrating the effectiveness of our proposed approach.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2047455663",
                        "name": "Haiming Yao"
                    },
                    {
                        "authorId": "1994508645",
                        "name": "Wei Luo"
                    },
                    {
                        "authorId": "153041366",
                        "name": "Wenyong Yu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recent autoencoder-based methods rely on accurate reconstructions of normal images and inaccurate reconstructions of anomalous images [8, 12, 20, 43].",
                "Generative models such as autoencoders [6, 8, 12, 20, 33, 43, 55] and GANs [2, 21, 45, 58, 59] have been used extensively for anomaly detection.",
                "[43] Hyunjong Park, Jongyoun Noh, and Bumsub Ham."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a5a1486a7874c85fb62c700594db390976a47632",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-14535",
                    "ArXiv": "2303.14535",
                    "DOI": "10.48550/arXiv.2303.14535",
                    "CorpusId": 257766439
                },
                "corpusId": 257766439,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a5a1486a7874c85fb62c700594db390976a47632",
                "title": "EfficientAD: Accurate Visual Anomaly Detection at Millisecond-Level Latencies",
                "abstract": "Detecting anomalies in images is an important task, especially in real-time computer vision applications. In this work, we focus on computational efficiency and propose a lightweight feature extractor that processes an image in less than a millisecond on a modern GPU. We then use a student-teacher approach to detect anomalous features. We train a student network to predict the extracted features of normal, i.e., anomaly-free training images. The detection of anomalies at test time is enabled by the student failing to predict their features. We propose a training loss that hinders the student from imitating the teacher feature extractor beyond the normal images. It allows us to drastically reduce the computational cost of the student-teacher model, while improving the detection of anomalous features. We furthermore address the detection of challenging logical anomalies that involve invalid combinations of normal local features, for example, a wrong ordering of objects. We detect these anomalies by efficiently incorporating an autoencoder that analyzes images globally. We evaluate our method, called EfficientAD, on 32 datasets from three industrial anomaly detection dataset collections. EfficientAD sets new standards for both the detection and the localization of anomalies. At a latency of two milliseconds and a throughput of six hundred images per second, it enables a fast handling of anomalies. Together with its low error rate, this makes it an economical solution for real-world applications and a fruitful basis for future research.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2045281292",
                        "name": "Kilian Batzner"
                    },
                    {
                        "authorId": "2132216065",
                        "name": "Lars Heckler"
                    },
                    {
                        "authorId": "38660507",
                        "name": "Rebecca K\u00f6nig"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "3e90e30b2e8c11c4c459b32fbbe0cd0dbe95d2c3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-13845",
                    "ArXiv": "2303.13845",
                    "DOI": "10.48550/arXiv.2303.13845",
                    "CorpusId": 257757373
                },
                "corpusId": 257757373,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3e90e30b2e8c11c4c459b32fbbe0cd0dbe95d2c3",
                "title": "Anomaly Detection under Distribution Shift",
                "abstract": "Anomaly detection (AD) is a crucial machine learning task that aims to learn patterns from a set of normal training samples to identify abnormal samples in test data. Most existing AD studies assume that the training and test data are drawn from the same data distribution, but the test data can have large distribution shifts arising in many real-world applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering existing AD methods ineffective in such cases. In this paper, we consider the problem of anomaly detection under distribution shift and establish performance benchmarks on four widely-used AD and out-of-distribution (OOD) generalization datasets. We demonstrate that simple adaptation of state-of-the-art OOD generalization methods to AD settings fails to work effectively due to the lack of labeled anomaly data. We further introduce a novel robust AD approach to diverse distribution shifts by minimizing the distribution gap between in-distribution and OOD normal samples in both the training and inference stages in an unsupervised way. Our extensive empirical results on the four datasets show that our approach substantially outperforms state-of-the-art AD methods and OOD generalization methods on data with various distribution shifts, while maintaining the detection accuracy on in-distribution data. Code and data are available at https://github.com/mala-lab/ADShift.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2149281913",
                        "name": "T. Cao"
                    },
                    {
                        "authorId": "2109445463",
                        "name": "Jiawen Zhu"
                    },
                    {
                        "authorId": "3224619",
                        "name": "Guansong Pang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "6af5a5fab6d96e016b932ef8bb07e06e7820ecba",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-13051",
                    "ArXiv": "2303.13051",
                    "DOI": "10.1109/CVPR52729.2023.02188",
                    "CorpusId": 257687336
                },
                "corpusId": 257687336,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6af5a5fab6d96e016b932ef8bb07e06e7820ecba",
                "title": "Hierarchical Semantic Contrast for Scene-aware Video Anomaly Detection",
                "abstract": "Increasing scene-awareness is a key challenge in video anomaly detection (VAD). In this work, we propose a hierarchical semantic contrast (HSC) method to learn a scene-aware VAD model from normal videos. We first incorporate foreground object and background scene features with high-level semantics by taking advantage of pre-trained video parsing models. Then, building upon the autoencoder-based reconstruction framework, we introduce both scene-level and object-level contrastive learning to enforce the encoded latent features to be compact within the same semantic classes while being separable across different classes. This hierarchical semantic contrast strategy helps to deal with the diversity of normal patterns and also increases their discrimination ability. Moreover, for the sake of tackling rare normal activities, we design a skeleton-based motion augmentation to increase samples and refine the model further. Extensive experiments on three public datasets and scene-dependent mixture datasets validate the effectiveness of our proposed method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2164104",
                        "name": "Shengyang Sun"
                    },
                    {
                        "authorId": "144142798",
                        "name": "Xiaojin Gong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To prove the effectiveness of the proposed HN-MUM, we compare it with different methods, which can be specific divided into traditional methods [30, 32, 35, 38, 45], reconstruction based methods [1, 6, 10, 12, 29, 48], and prediction based methods [3, 8, 24, 31, 46], on the publicly available datasets."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "62a4c6f011c80287b8071bfbe5b9108d3de3603d",
                "externalIds": {
                    "DBLP": "journals/mta/LiWCL23",
                    "DOI": "10.1007/s11042-023-15154-x",
                    "CorpusId": 257648818
                },
                "corpusId": 257648818,
                "publicationVenue": {
                    "id": "477368e9-7a8e-475a-8c93-6d623797fd06",
                    "name": "Multimedia tools and applications",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Tools and Applications",
                        "Multimedia Tool Appl",
                        "Multimedia tool appl"
                    ],
                    "issn": "1380-7501",
                    "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/62a4c6f011c80287b8071bfbe5b9108d3de3603d",
                "title": "HN-MUM: heterogeneous video anomaly detection network with multi-united-memory module",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2155567047",
                        "name": "Hongjun Li"
                    },
                    {
                        "authorId": "2143468874",
                        "name": "Yunlong Wang"
                    },
                    {
                        "authorId": "2108633585",
                        "name": "M. Chen"
                    },
                    {
                        "authorId": "2144495577",
                        "name": "Jiaxin Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This improves the quality of obtained video frame features and the accuracyof subsequent detection.ComparedwithMNAD [30], the performance of ourmethod is slightly better, despite the use ofmemory.",
                "The purpose of introducing memory between the encoder and decoder of AE is to resolve the limited representation of the original AE features [30], which means the detection error can be reduced by recording asmany feature prototypes through memory as possible.",
                "ComparedwithMNAD [30], the performance of ourmethod is slightly better, despite the use ofmemory.",
                "The precondition of prediction is that normal behavior is regular and predictable, but the abnormal is unpredictable [30], so the prediction error can be used to determinewhether the predicted video frame is anomalous or not.",
                "According to the experimental settings in the literature [10, 30, 33, 40], the network model was implemented through the deep learning framework Pytorch [49].",
                "[30] followed this innovation and put forward a different strategy, namely, using multiple prototypes to represent various patterns of normal video frames for unsupervised anomaly detection.",
                "Based on the previous work [10, 30], Peak Signal to Noise Ratio (PSNR) was applied to calculate the relationship",
                "We compared with the recent anomaly detection methods on three datasets, including MPPCA [50], AMDN [51], AMC [54], MNAD [30], BiTraP [57], etc.",
                "We compared with the recent anomaly detection methods on three datasets, including MPPCA [50], AMDN [51], AMC [54], MNAD [30], BiTraP [57], etc., as shown in Table 1, and\nthe performance of the other methods was all derived from the corresponding original papers."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "f3afe15c5975b38b3e9b7dd9c9333688fe24d055",
                "externalIds": {
                    "DBLP": "journals/ijmir/ZhouY23",
                    "DOI": "10.1007/s13735-023-00272-x",
                    "CorpusId": 257509781
                },
                "corpusId": 257509781,
                "publicationVenue": {
                    "id": "d9c19003-0fdf-4501-b3cd-cf35b240bc6a",
                    "name": "International Journal of Multimedia Information Retrieval",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Multimedia Inf Retr"
                    ],
                    "issn": "2192-662X",
                    "url": "http://www.springer.com/computer/journal/13735",
                    "alternate_urls": [
                        "https://link.springer.com/journal/13735"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f3afe15c5975b38b3e9b7dd9c9333688fe24d055",
                "title": "Video anomaly detection with memory-guided multilevel embedding",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2211683547",
                        "name": "Liuping Zhou"
                    },
                    {
                        "authorId": "145039750",
                        "name": "J. Yang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "58d59beb750e8c0e1d52b04dbc6c1c8b5ea3178a",
                "externalIds": {
                    "ArXiv": "2303.05768",
                    "DBLP": "journals/corr/abs-2303-05768",
                    "DOI": "10.48550/arXiv.2303.05768",
                    "CorpusId": 257482700
                },
                "corpusId": 257482700,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/58d59beb750e8c0e1d52b04dbc6c1c8b5ea3178a",
                "title": "Learning Global-Local Correspondence with Semantic Bottleneck for Logical Anomaly Detection",
                "abstract": "This paper presents a novel framework, named Global-Local Correspondence Framework (GLCF), for visual anomaly detection with logical constraints. Visual anomaly detection has become an active research area in various real-world applications, such as industrial anomaly detection and medical disease diagnosis. However, most existing methods focus on identifying local structural degeneration anomalies and often fail to detect high-level functional anomalies that involve logical constraints. To address this issue, we propose a two-branch approach that consists of a local branch for detecting structural anomalies and a global branch for detecting logical anomalies. To facilitate local-global feature correspondence, we introduce a novel semantic bottleneck enabled by the visual Transformer. Moreover, we develop feature estimation networks for each branch separately to detect anomalies. Our proposed framework is validated using various benchmarks, including industrial datasets, Mvtec AD, Mvtec Loco AD, and the Retinal-OCT medical dataset. Experimental results show that our method outperforms existing methods, particularly in detecting logical anomalies.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2047455663",
                        "name": "Haiming Yao"
                    },
                    {
                        "authorId": "153041366",
                        "name": "Wenyong Yu"
                    },
                    {
                        "authorId": "1994508645",
                        "name": "Wei Luo"
                    },
                    {
                        "authorId": "2154339795",
                        "name": "Zhenfeng Qiang"
                    },
                    {
                        "authorId": "9393671",
                        "name": "Donghao Luo"
                    },
                    {
                        "authorId": "2211354726",
                        "name": "Xiaotian Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Existing works [2, 6, 14] often use the designed autoencoder (AE) to tackle this problem: an encoder learns to extract features from only normal training video frames, and a decoder generates the predicted target frame by using the extracted features.",
                "At test time, following the existing approaches for VAD [2, 6, 10], we predict framelevel anomaly scores and calculate these scores by using the Peak Signal to Noise Ratio (PSNR).",
                "However, several researchers [5, 6, 8] observe that AEs sometimes reconstruct anomalies well, indicating that the reconstruction difference between normal and abnormal data may not be discriminative enough to detect the anomalies."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "dbd4a383314dcb5d69b9f367fba55e0474c2222d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-05112",
                    "ArXiv": "2303.05112",
                    "DOI": "10.48550/arXiv.2303.05112",
                    "CorpusId": 257427256
                },
                "corpusId": 257427256,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/dbd4a383314dcb5d69b9f367fba55e0474c2222d",
                "title": "Synthetic Pseudo Anomalies for Unsupervised Video Anomaly Detection: A Simple yet Efficient Framework based on Masked Autoencoder",
                "abstract": "Due to the limited availability of anomalous samples for training, video anomaly detection is commonly viewed as a one-class classification problem. Many prevalent methods investigate the reconstruction difference produced by AutoEncoders (AEs) under the assumption that the AEs would reconstruct the normal data well while reconstructing anomalies poorly. However, even with only normal data training, the AEs often reconstruct anomalies well, which depletes their anomaly detection performance. To alleviate this issue, we propose a simple yet efficient framework for video anomaly detection. The pseudo anomaly samples are introduced, which are synthesized from only normal data by embedding random mask tokens without extra data processing. We also propose a normalcy consistency training strategy that encourages the AEs to better learn the regular knowledge from normal and corresponding pseudo anomaly data. This way, the AEs learn more distinct reconstruction boundaries between normal and abnormal data, resulting in superior anomaly discrimination capability. Experimental results demonstrate the effectiveness of the proposed method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2146351387",
                        "name": "Xiangyu Huang"
                    },
                    {
                        "authorId": "8132058",
                        "name": "Caidan Zhao"
                    },
                    {
                        "authorId": "2211134839",
                        "name": "Chenxing Gao"
                    },
                    {
                        "authorId": "2049405794",
                        "name": "Lvdong Chen"
                    },
                    {
                        "authorId": "2146254703",
                        "name": "Zhiqiang Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "2ed0438c7136463c7d742c99b525299268fe854a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-05116",
                    "ArXiv": "2303.05116",
                    "DOI": "10.1109/ICME55011.2023.00462",
                    "CorpusId": 257427501
                },
                "corpusId": 257427501,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2ed0438c7136463c7d742c99b525299268fe854a",
                "title": "Multi-Level Memory-Augmented Appearance-Motion Correspondence Framework for Video Anomaly Detection",
                "abstract": "Frame prediction based on AutoEncoder plays a significant role in unsupervised video anomaly detection. Ideally, the models trained on the normal data could generate larger prediction errors of anomalies. However, the correlation between appearance and motion information is underutilized, which makes the models lack an understanding of normal patterns. Moreover, the models do not work well due to the uncontrollable generalizability of deep AutoEncoder. To tackle these problems, we propose a multi-level memory-augmented appearance-motion correspondence framework. The latent correspondence between appearance and motion is explored via appearance-motion semantics alignment and semantics replacement training. Besides, we also introduce a Memory-Guided Suppression Module, which utilizes the difference from normal prototype features to suppress the reconstruction capacity caused by skip-connection, achieving the tradeoff between the good reconstruction of normal data and the poor reconstruction of abnormal data. Experimental results show that our framework outperforms the state-of-the-art methods, achieving AUCs of 99.6%, 93.8%, and 76.3% on UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2146351387",
                        "name": "Xiangyu Huang"
                    },
                    {
                        "authorId": "8132058",
                        "name": "Caidan Zhao"
                    },
                    {
                        "authorId": "1390869652",
                        "name": "Jinghui Yu"
                    },
                    {
                        "authorId": "2211134839",
                        "name": "Chenxing Gao"
                    },
                    {
                        "authorId": "2146254703",
                        "name": "Zhiqiang Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "d99832baa07b1ffc1812f3cf2ec216c355cd539d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-05047",
                    "ArXiv": "2303.05047",
                    "DOI": "10.1109/CVPR52729.2023.01169",
                    "CorpusId": 257427443
                },
                "corpusId": 257427443,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d99832baa07b1ffc1812f3cf2ec216c355cd539d",
                "title": "Diversity-Measurable Anomaly Detection",
                "abstract": "Reconstruction-based anomaly detection models achieve their purpose by suppressing the generalization ability for anomaly. However, diverse normal patterns are consequently not well reconstructed as well. Although some efforts have been made to alleviate this problem by modeling sample diversity, they suffer from shortcut learning due to undesired transmission of abnormal information. In this paper, to better handle the tradeoff problem, we propose Diversity-Measurable Anomaly Detection (DMAD) framework to enhance reconstruction diversity while avoid the undesired generalization on anomalies. To this end, we design Pyramid Deformation Module (PDM), which models diverse normals and measures the severity of anomaly by estimating multi-scale deformation fields from reconstructed reference to original input. Integrated with an information compression module, PDM essentially decouples deformation from prototypical embedding and makes the final anomaly score more reliable. Experimental results on both surveillance videos and industrial images demonstrate the effectiveness of our method. In addition, DMAD works equally well in front of contaminated data and anomaly-like normal samples.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "120639978",
                        "name": "Wenrui Liu"
                    },
                    {
                        "authorId": "2116284897",
                        "name": "Hong Chang"
                    },
                    {
                        "authorId": "1798982",
                        "name": "Bingpeng Ma"
                    },
                    {
                        "authorId": "145455919",
                        "name": "S. Shan"
                    },
                    {
                        "authorId": "46772547",
                        "name": "Xilin Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[40] introduces memory modules to explicitly model the normal mode.",
                "The global anomaly branch adopts the method in [40], so the result is the same.",
                "This paper follows the experimental protocol in [12, 35, 40], and evaluates the performance of the model by comparing the area under the ROC curve, namely, the AUC (%) value.",
                "[40] do not notice that due to the view difference, the subtle difference between the distant objects are weakened, while those of near objects are magnified, so near objects are more likely to be located as abnormal."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "c5386effca34bdf0a99d97004d72dab8b71dc1b5",
                "externalIds": {
                    "DBLP": "journals/mta/LiCSLC23",
                    "DOI": "10.1007/s11042-023-14956-3",
                    "CorpusId": 257973733
                },
                "corpusId": 257973733,
                "publicationVenue": {
                    "id": "477368e9-7a8e-475a-8c93-6d623797fd06",
                    "name": "Multimedia tools and applications",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Tools and Applications",
                        "Multimedia Tool Appl",
                        "Multimedia tool appl"
                    ],
                    "issn": "1380-7501",
                    "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c5386effca34bdf0a99d97004d72dab8b71dc1b5",
                "title": "Multi-memory video anomaly detection based on scene object distribution",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "119885997",
                        "name": "Hongjun Li"
                    },
                    {
                        "authorId": "2129483802",
                        "name": "Jinyi Chen"
                    },
                    {
                        "authorId": "2157274399",
                        "name": "Xiaohu Sun"
                    },
                    {
                        "authorId": "48161673",
                        "name": "Chaobo Li"
                    },
                    {
                        "authorId": "2108246394",
                        "name": "Junjie Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Among these approaches, memory-based models [8], [9], [10] achieve significant improvement in performance.",
                "techniques [1], [2], [7], [8], [9], [10] are proposed to localize"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "2c8e5a7c4643c92860497f2ff16bc9fe7fe1f046",
                "externalIds": {
                    "DBLP": "journals/tcsv/WuZSWW23",
                    "DOI": "10.1109/TCSVT.2022.3211839",
                    "CorpusId": 252724054
                },
                "corpusId": 252724054,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2c8e5a7c4643c92860497f2ff16bc9fe7fe1f046",
                "title": "Self-Attention Memory-Augmented Wavelet-CNN for Anomaly Detection",
                "abstract": "Anomaly detection plays an important role in manufacturing quality control/assurance. Among approaches adopting computer vision techniques, reconstruction-based methods learn a content-aware mapping function that transfers abnormal regions to normal regions in an unsupervised manner. Such methods usually have difficulty in improving both the reconstruction quality and capacity for abnormal discovery. We observe that high-level semantic contextual features demonstrate a strong ability for abnormal discovery, while variational features help to preserve fine image details. Inspired by the observation, we propose a new abnormal detection model by utilizing features for different purposes depending on their frequency characteristics. The 2D-discrete wavelet transform (DWT) is introduced to obtain the low-frequency and high-frequency components of features and further used to generate the two essential features following different routing paths in our encoder process. To further improve the capacity for abnormal discovery, we propose a novel feature augmentation module that is informed by a customized self-attention mechanism. Extensive experiments are conducted on two popular datasets: MVTec AD and BTAD. The experimental results illustrate that the proposed method outperforms other state-of-the-art approaches in terms of the image-level AUROC score. In particular, our method achieves 100% of the image-level AUROC score on 8 out of 15 classes on the MVTec dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2185216646",
                        "name": "Kun Wu"
                    },
                    {
                        "authorId": "145081300",
                        "name": "Lei Zhu"
                    },
                    {
                        "authorId": "1877189",
                        "name": "Weihang Shi"
                    },
                    {
                        "authorId": "2108936901",
                        "name": "Wenwu Wang"
                    },
                    {
                        "authorId": "2160179345",
                        "name": "Jin Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "2984fb6d404e57af72e5c79c2199a94cc643b9e5",
                "externalIds": {
                    "DBLP": "journals/ijon/AstridZL23",
                    "ArXiv": "2303.10704",
                    "DOI": "10.1016/j.neucom.2023.03.008",
                    "CorpusId": 257472190
                },
                "corpusId": 257472190,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2984fb6d404e57af72e5c79c2199a94cc643b9e5",
                "title": "PseudoBound: Limiting the anomaly reconstruction capability of one-class classifiers using pseudo anomalies",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "145345698",
                        "name": "M. Astrid"
                    },
                    {
                        "authorId": "34148354",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "3193599",
                        "name": "Seung-Ik Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[15], HF2VAD [13], and MNAD [24] in Table 1."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "ea3b80261fd254760b9eeb39bbdc84f1af8cd27d",
                "externalIds": {
                    "ArXiv": "2302.13748",
                    "DBLP": "journals/corr/abs-2302-13748",
                    "DOI": "10.1109/ICASSP49357.2023.10094676",
                    "CorpusId": 257219978
                },
                "corpusId": 257219978,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/ea3b80261fd254760b9eeb39bbdc84f1af8cd27d",
                "title": "Unsupervised Video Anomaly Detection for Stereotypical Behaviours in Autism",
                "abstract": "Monitoring and analyzing stereotypical behaviours is important for early intervention and care taking in Autism Spectrum Disorder (ASD). This paper focuses on automatically detecting stereotypical behaviours with computer vision techniques. Off-the-shelf methods tackle this task by supervised classification and activity recognition techniques. However, the unbounded types of stereotypical behaviours and the difficulty in collecting video recordings of ASD patients largely limit the feasibility of the existing supervised detection methods. As a result, we tackle these challenges from a new perspective, i.e. unsupervised video anomaly detection for stereotypical behaviours detection. The models can be trained among unlabeled videos containing only normal behaviours and unknown types of abnormal behaviours can be detected during inference. Correspondingly, we propose a Dual Stream deep model for Stereotypical Behaviours Detection, DS-SBD, based on the temporal trajectory of human poses and the repetition patterns of human actions. Extensive experiments are conducted to verify the effectiveness of our proposed method and suggest that it serves as a potential benchmark for future research.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2156260068",
                        "name": "Jiaqi Gao"
                    },
                    {
                        "authorId": "2046022",
                        "name": "Xinyang Jiang"
                    },
                    {
                        "authorId": "2125051198",
                        "name": "Yuqing Yang"
                    },
                    {
                        "authorId": "2181524288",
                        "name": "Dongsheng Li"
                    },
                    {
                        "authorId": "2160727304",
                        "name": "Lili Qiu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Namely, we compare to Variational Model (VM) Steger (2001) - a handcrafted similarity measure designed for robustness to different conditions, MNAD Park et al. (2020) - an autoencoder with a memory module, f-AnoGAN Schlegl et al. (2017) - a generative model trained for the reconstruction of anomaly free images, AE / VAE Sakurada & Yairi (2014) - an autoencoder / variational autoencoder, Student Teacher (ST) Bergmann et al. (2020) - a student network aimed to give better reconstruction for the normal data, SPADE Cohen & Hoshen (2020) - a density estimation method using a pyramid of deep ResNet features, PatchCore (PCore) Roth et al. (2022) - a state-of-the-art method for structural anomalies, improving SPADE scoring function, GCAD Bergmann et al. (2022) - a reconstruction based method, based on both local and global deep ResNet features.",
                "Namely, we compare to Variational Model (VM) Steger (2001) - a handcrafted similarity measure designed for robustness to different conditions, MNAD Park et al. (2020) - an autoencoder with a memory module, f-AnoGAN Schlegl et al. (2017) - a generative model trained for the reconstruction of anomaly\u2026"
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "acf2ad442cc67bbfc50b158688b7f2151e28f22f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-12245",
                    "ArXiv": "2302.12245",
                    "DOI": "10.48550/arXiv.2302.12245",
                    "CorpusId": 257102792
                },
                "corpusId": 257102792,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/acf2ad442cc67bbfc50b158688b7f2151e28f22f",
                "title": "Set Features for Fine-grained Anomaly Detection",
                "abstract": "Fine-grained anomaly detection has recently been dominated by segmentation based approaches. These approaches first classify each element of the sample (e.g., image patch) as normal or anomalous and then classify the entire sample as anomalous if it contains anomalous elements. However, such approaches do not extend to scenarios where the anomalies are expressed by an unusual combination of normal elements. In this paper, we overcome this limitation by proposing set features that model each sample by the distribution its elements. We compute the anomaly score of each sample using a simple density estimation method. Our simple-to-implement approach outperforms the state-of-the-art in image-level logical anomaly detection (+3.4%) and sequence-level time-series anomaly detection (+2.4%).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "22021547",
                        "name": "Niv Cohen"
                    },
                    {
                        "authorId": "2210080341",
                        "name": "Issar Tzachor"
                    },
                    {
                        "authorId": "2126490970",
                        "name": "Yedid Hoshen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Hyunjong used feature loss rather than reconstruct loss to simplified the complexity of memory bank and enhanced the effect of memory items [20]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "7d2f87a01cc5d1f5bee7b4d3ab498970ae947403",
                "externalIds": {
                    "DOI": "10.1080/10589759.2023.2169285",
                    "CorpusId": 256933279
                },
                "corpusId": 256933279,
                "publicationVenue": {
                    "id": "1acb5b2e-71f3-4091-98ff-2be2c32aa4bb",
                    "name": "Nondestructive Testing and Evaluation",
                    "type": "journal",
                    "alternate_names": [
                        "Nondestruct Test Evaluation"
                    ],
                    "issn": "1058-9759",
                    "url": "http://www.tandfonline.com/loi/gnte20",
                    "alternate_urls": [
                        "http://www.tandfonline.com/toc/gnte20/current",
                        "http://journalsonline.tandf.co.uk/app/home/journal.asp?backto=searchpublicationsresults,1,1;homemain,1,1;&referrer=parent&wasp=23tyjmuxtj5xnmgunm13"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7d2f87a01cc5d1f5bee7b4d3ab498970ae947403",
                "title": "Semi-supervised pipeline anomaly detection algorithm based on memory items and metric learning",
                "abstract": "ABSTRACT Traditional detection algorithms of pipeline non-destructive testing extract information from a large number of defect samples to ensure the detection performance, but even if an adequate of defect samples are collected, it is difficult to enumerate the possible defect morphology in nature. In this paper, we proposed a new semi-supervised anomaly detection algorithm to solve the existing problems. We consider using the most representative feature vectors generated by feature extractor as memory items to represent background information. In addition, this paper also imports a few defect samples to form a semi-supervised structure in the training stage and introduces a metric learning module to make the memory items have the ability to fully represent the background and enhance robustness. To prove the effectiveness of our algorithm, this paper has verified its performance in micro-size pipeline defects. In the experiment, the high-definition industrial camera was used to scan and record the image sequence from the inner surface of the pipeline sample. The latest anomaly detection algorithms have been used as a platform for objective performance evaluation. The result shows our algorithm is more effective in pipeline defect detection and has strong robustness for anti-interference.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2075430605",
                        "name": "Bingchuan Yan"
                    },
                    {
                        "authorId": "2158167106",
                        "name": "Jianfeng Zheng"
                    },
                    {
                        "authorId": "2150926772",
                        "name": "Rui Li"
                    },
                    {
                        "authorId": "1484212814",
                        "name": "Kuan-Chung Fu"
                    },
                    {
                        "authorId": "30858338",
                        "name": "Pengchao Chen"
                    },
                    {
                        "authorId": "2205175042",
                        "name": "G. Jia"
                    },
                    {
                        "authorId": "2152861927",
                        "name": "Yunhan Shi"
                    },
                    {
                        "authorId": "2208185578",
                        "name": "Junshuang Lv"
                    },
                    {
                        "authorId": "2206889583",
                        "name": "Bin Gao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The methods mainly include Classification-based [9, 16], Density-based [37, 51], Distance-based [45] and Reconstructionbased [11, 29]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "e2d606dc40aee95631f23f9a1cd2fab717f143d1",
                "externalIds": {
                    "ArXiv": "2302.07335",
                    "DBLP": "journals/corr/abs-2302-07335",
                    "DOI": "10.48550/arXiv.2302.07335",
                    "CorpusId": 256868817
                },
                "corpusId": 256868817,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e2d606dc40aee95631f23f9a1cd2fab717f143d1",
                "title": "IDEAL: Toward High-efficiency Device-Cloud Collaborative and Dynamic Recommendation System",
                "abstract": "Recommendation systems have shown great potential to solve the information explosion problem and enhance user experience in various online applications, which recently present two emerging trends: (i) Collaboration: single-sided model trained on-cloud (separate learning) to the device-cloud collaborative recommendation (collaborative learning). (ii) Real-time Dynamic: the network parameters are the same across all the instances (static model) to adaptive network parameters generation conditioned on the real-time instances (dynamic model). The aforementioned two trends enable the device-cloud collaborative and dynamic recommendation, which deeply exploits the recommendation pattern among cloud-device data and efficiently characterizes different instances with different underlying distributions based on the cost of frequent device-cloud communication. Despite promising, we argue that most of the communications are unnecessary to request the new parameters of the recommendation system on the cloud since the on-device data distribution are not always changing. To alleviate this issue, we designed a Intelligent DEvice-Cloud PArameter Request ModeL (IDEAL) that can be deployed on the device to calculate the request revenue with low resource consumption, so as to ensure the adaptive device-cloud communication with high revenue. We envision a new device intelligence learning task to implement IDEAL by detecting the data out-of-domain. Moreover, we map the user's real-time behavior to a normal distribution, the uncertainty is calculated by the multi-sampling outputs to measure the generalization ability of the device model to the current user behavior. Our experimental study demonstrates IDEAL's effectiveness and generalizability on four public benchmarks, which yield a higher efficient device-cloud collaborative and dynamic recommendation paradigm.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1475705618",
                        "name": "Zheqi Lv"
                    },
                    {
                        "authorId": "1505702519",
                        "name": "Zhengyu Chen"
                    },
                    {
                        "authorId": "1739188006",
                        "name": "Shengyu Zhang"
                    },
                    {
                        "authorId": "33870528",
                        "name": "Kun Kuang"
                    },
                    {
                        "authorId": "2108125912",
                        "name": "Wenqiao Zhang"
                    },
                    {
                        "authorId": "31289209",
                        "name": "Meng Li"
                    },
                    {
                        "authorId": "1693070",
                        "name": "B. Ooi"
                    },
                    {
                        "authorId": "93192602",
                        "name": "Fei Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[118] introduced an attention-based memory addressing mechanism and proposed to update the memory pool during the testing phase to ensure that the network can better represent normal events.",
                "Overly powerful deep networks may lead to missing anomalous events as normal due to overgeneralization [42, 118].",
                "With the rise of deep learning in computer vision tasks [136, 184, 191], recent approaches preferred to extracting features representations in an end-to-end framework with deep Auto-Encoders (AE) [21, 46, 87, 90, 118], Generative Adversarial Networks (GAN) [9, 17, 56, 69, 113, 188], and Vision Transformers (ViT) [36, 65, 179].",
                "For example, the dominant prediction-based methods [84, 87, 90, 118] in UVAD route can only give the prediction error of the current input in a single-step execution, while the Informative anomaly score needs are",
                "Mainstream unsupervised datasets [78, 94] and UVAD methods [14, 84, 118] only consider single-scene videos, while the real world always contains multiple scenes, which constitutes another challenge for UVAD methods."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "bb51ca71833d42fa58f9adccb2296bdf665cc158",
                "externalIds": {
                    "ArXiv": "2302.05087",
                    "DBLP": "journals/corr/abs-2302-05087",
                    "DOI": "10.48550/arXiv.2302.05087",
                    "CorpusId": 256808510
                },
                "corpusId": 256808510,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/bb51ca71833d42fa58f9adccb2296bdf665cc158",
                "title": "Generalized Video Anomaly Event Detection: Systematic Taxonomy and Comparison of Deep Models",
                "abstract": "Video Anomaly Event Detection (VAED) is the core technology of intelligent surveillance systems aiming to temporally or spatially locate anomalous events in videos. With the penetration of deep learning, the recent advances in VAED have diverged various routes and achieved significant success. However, most existing reviews focus on traditional and unsupervised VAED methods, lacking attention to emerging weakly-supervised and fully-unsupervised routes. Therefore, this review extends the narrow VAED concept from unsupervised video anomaly detection to Generalized Video Anomaly Event Detection (GVAED), which provides a comprehensive survey that integrates recent works based on different assumptions and learning frameworks into an intuitive taxonomy and coordinates unsupervised, weakly-supervised, fully-unsupervised, and supervised VAED routes. To facilitate future researchers, this review collates and releases research resources such as datasets, available codes, programming tools, and literature. Moreover, this review quantitatively compares the model performance and analyzes the research challenges and possible trends for future work.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47909156",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2143920085",
                        "name": "Dingkang Yang"
                    },
                    {
                        "authorId": "2152542782",
                        "name": "Yan Wang"
                    },
                    {
                        "authorId": "2153467142",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "143875337",
                        "name": "Liang Song"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(Stephen and Menon 2020) follows the MemAE framework and presents a new readable and updatable memory scheme, where memory banks also update at test time."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "965a0ff397ff33dbb9ee9a5b725472af4ffe0892",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-05160",
                    "ArXiv": "2302.05160",
                    "DOI": "10.48550/arXiv.2302.05160",
                    "CorpusId": 256808591
                },
                "corpusId": 256808591,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/965a0ff397ff33dbb9ee9a5b725472af4ffe0892",
                "title": "Dual Memory Units with Uncertainty Regulation for Weakly Supervised Video Anomaly Detection",
                "abstract": "Learning discriminative features for effectively separating abnormal events from normality is crucial for weakly supervised video anomaly detection (WS-VAD) tasks. Existing approaches, both video and segment level label oriented, mainly focus on extracting representations for anomaly data while neglecting the implication of normal data. We observe that such a scheme is sub-optimal, i.e., for better distinguishing anomaly one needs to understand what is a normal state, and may yield a higher false alarm rate. To address this issue, we propose an Uncertainty Regulated Dual Memory Units (UR-DMU) model to learn both the representations of normal data and discriminative features of abnormal data. To be specific, inspired by the traditional global and local structure on graph convolutional networks, we introduce a Global and Local Multi-Head Self Attention (GL-MHSA) module for the Transformer network to obtain more expressive embeddings for capturing associations in videos. Then, we use two memory banks, one additional abnormal memory for tackling hard samples, to store and separate abnormal and normal prototypes and maximize the margins between the two representations. Finally, we propose an uncertainty learning scheme to learn the normal data latent space, that is robust to noise from camera switching, object changing, scene transforming, etc. Extensive experiments on XD-Violence and UCF-Crime datasets demonstrate that our method outperforms the state-of-the-art methods by a sizable margin.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2111825799",
                        "name": "Hang Zhou"
                    },
                    {
                        "authorId": "4210401",
                        "name": "Junqing Yu"
                    },
                    {
                        "authorId": "2150081005",
                        "name": "Wei Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Furthermore, Dictionary learning or sparse coding are also prominent video anomaly detection techniques [17,18].",
                "We have used ShanghaiTech dataset and compared the propsoed model performance with various methods such as predictions of normal frames based on anomaly detection techniques with unsupervised learning [9,17], feature patterns based on unsupervised learning [60,61], and skeleton patterns based on unsupervised learning [62,63]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8c16d24261f7529e788e8632855acc681f4c54d2",
                "externalIds": {
                    "DBLP": "journals/sensors/IslamDAH23",
                    "PubMedCentral": "9966604",
                    "DOI": "10.3390/s23042358",
                    "CorpusId": 257147724,
                    "PubMed": "36850955"
                },
                "corpusId": 257147724,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8c16d24261f7529e788e8632855acc681f4c54d2",
                "title": "An IoT Enable Anomaly Detection System for Smart City Surveillance",
                "abstract": "Since the advent of visual sensors, smart cities have generated massive surveillance video data, which can be intelligently inspected to detect anomalies. Computer vision-based automated anomaly detection techniques replace human intervention to secure video surveillance applications in place from traditional video surveillance systems that rely on human involvement for anomaly detection, which is tedious and inaccurate. Due to the diverse nature of anomalous events and their complexity, it is however, very challenging to detect them automatically in a real-world scenario. By using Artificial Intelligence of Things (AIoT), this research work presents an efficient and robust framework for detecting anomalies in surveillance large video data. A hybrid model integrating 2D-CNN and ESN are proposed in this research study for smart surveillance, which is an important application of AIoT. The CNN is used as feature extractor from input videos which are then inputted to autoencoder for feature refinement followed by ESN for sequence learning and anomalous events detection. The proposed model is lightweight and implemented over edge devices to ensure their capability and applicability over AIoT environments in a smart city. The proposed model significantly enhanced performance using challenging surveillance datasets compared to other methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2110034622",
                        "name": "Muhammad Islam"
                    },
                    {
                        "authorId": "10387969",
                        "name": "Abdulsalam S. Dukyil"
                    },
                    {
                        "authorId": "32794968",
                        "name": "Saleh Alyahya"
                    },
                    {
                        "authorId": "145827751",
                        "name": "Shabana Habib"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "35de38bfa68303566bff360ab7d146609dd4ee68",
                "externalIds": {
                    "ArXiv": "2301.09489",
                    "CorpusId": 258840927
                },
                "corpusId": 258840927,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/35de38bfa68303566bff360ab7d146609dd4ee68",
                "title": "Contracting Skeletal Kinematics for Human-Related Video Anomaly Detection",
                "abstract": "Detecting the anomaly of human behavior is paramount to timely recognizing endangering situations, such as street fights or elderly falls. However, anomaly detection is complex since anomalous events are rare and because it is an open set recognition task, i.e., what is anomalous at inference has not been observed at training. We propose COSKAD, a novel model that encodes skeletal human motion by a graph convolutional network and learns to COntract SKeletal kinematic embeddings onto a latent hypersphere of minimum volume for Video Anomaly Detection. We propose three latent spaces: the commonly-adopted Euclidean and the novel spherical and hyperbolic. All variants outperform the state-of-the-art on the most recent UBnormal dataset, for which we contribute a human-related version with annotated skeletons. COSKAD sets a new state-of-the-art on the human-related versions of ShanghaiTech Campus and CUHK Avenue, with performance comparable to video-based methods. Source code and dataset will be released upon acceptance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2162586026",
                        "name": "Alessandro Flaborea"
                    },
                    {
                        "authorId": "2181502817",
                        "name": "Guido D'Amely"
                    },
                    {
                        "authorId": "1397655869",
                        "name": "S. D'Arrigo"
                    },
                    {
                        "authorId": "2191077580",
                        "name": "Marco Aurelio Sterpa"
                    },
                    {
                        "authorId": "2131867709",
                        "name": "Alessio Sampieri"
                    },
                    {
                        "authorId": "1787725",
                        "name": "Fabio Galasso"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In order to solve this problem, reconstructionbased methods combine memory mechanisms, image masking strategy, and pseudo-anomaly [9], [11], [15]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "205a1c89058ea55fe536c6484a62213d1d0f0160",
                "externalIds": {
                    "DBLP": "conf/icuimc/DucBT23",
                    "DOI": "10.1109/IMCOM56909.2023.10035610",
                    "CorpusId": 256670251
                },
                "corpusId": 256670251,
                "publicationVenue": {
                    "id": "bfdaa902-daba-44e2-9de0-df4e61fe2f80",
                    "name": "International Conference on Ubiquitous Information Management and Communication",
                    "type": "conference",
                    "alternate_names": [
                        "ICUIMC",
                        "IMCOM",
                        "Int Conf Ubiquitous Inf Manag Commun"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1499"
                },
                "url": "https://www.semanticscholar.org/paper/205a1c89058ea55fe536c6484a62213d1d0f0160",
                "title": "An Improved Reverse Distillation Model for Unsupervised Anomaly Detection",
                "abstract": "Using knowledge distillation for unsupervised anomaly detection problems is more efficient. Recently, a reverse distillation (RD) model has been presented a novel teacher-student (T-S) model for the problem [7]. In the model, the student network uses the one-class embedding from the teacher model as input with the goal of restoring the teacher's rep-resentations. The knowledge distillation starts with high-level abstract presentations and moves down to low-level aspects using a model called one-class bottleneck embedding (OCBE). Although its performance is expressive, it still leverages the power of transforming input images before applying this architecture. Instead of only using raw images, in this paper, we transform them using augmentation techniques. The teacher will encode raw and transformed inputs to get raw representation (encoded from raw inputs) and transformed representation (encoded from transformed inputs). The student must restore the transformed representation from the bottleneck to the raw representation. Testing results obtained on benchmarks for AD and one-class novelty detection showed that our proposed model outperforms the SOTA ones, proving the utility and applicability of the suggested strategy.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2075328131",
                        "name": "Van-Duc Nguyen"
                    },
                    {
                        "authorId": "2204877429",
                        "name": "Hoang Huu Bach"
                    },
                    {
                        "authorId": "3056302",
                        "name": "L. Trang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Inspired by normality representation [10, 26] in the OCC methods, we encode normal patterns across all normal video sets into compact prototypes which are the centroids of normal instances.",
                "Our method achieves AUC score of 97.43% with I3D RGB features and 96.02% with C3D RGB features, outperforming existing state-of-the-art one-class classification (OCC) [11, 24, 26, 3, 47] and weakly supervised methods [48, 51, 33, 40, 46, 9, 38, 17, 29].",
                "Consistent with the results on ShanghaiTech, our method outperforms all OCC [11, 34] and weakly supervised approaches [33, 48, 52, 51, 46, 9, 38, 17, 29] by large margins.",
                "02% with C3D RGB features, outperforming existing state-of-the-art one-class classification (OCC) [11, 24, 26, 3, 47] and weakly supervised methods [48, 51, 33, 40, 46, 9, 38, 17, 29].",
                "However, due to a lack of prior knowledge of abnormalities, such OCC methods show relatively low performance compared to wVAD methods [46].",
                "Contrary to the aforementioned OCC methods, we leverage the prototypes to refine the initial noisy prediction of the MIL-based classifier.",
                "Some recent papers [10, 26] solved the problem by introducing normality prototypes.",
                "Our model exceeds OCC methods [31, 11] by a minimum of 47.74% in AP.",
                "It is inspired by the previous memory-based methods [32, 13, 10, 26].",
                "Meanwhile, One-Class Classification (OCC) approaches [11, 24, 50, 19, 10, 26, 21] focus on encoding frequently occurred patterns of normal data as a form of centroids [28] or latent vector [50] to train an one-class classifier.",
                "It allows the model to obtain compact decision boundaries for normal instances [10, 40, 26]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "77564c2f2460fff066cfda9c30fe68dc12dba75c",
                "externalIds": {
                    "DBLP": "conf/wacv/ParkKKKS23",
                    "DOI": "10.1109/WACV56688.2023.00269",
                    "CorpusId": 256653748
                },
                "corpusId": 256653748,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/77564c2f2460fff066cfda9c30fe68dc12dba75c",
                "title": "Normality Guided Multiple Instance Learning for Weakly Supervised Video Anomaly Detection",
                "abstract": "Weakly supervised Video Anomaly Detection (wVAD) aims to distinguish anomalies from normal events based on video-level supervision. Most existing works utilize Multiple Instance Learning (MIL) with ranking loss to tackle this task. These methods, however, rely on noisy predictions from a MIL-based classifier for target instance selection in ranking loss, degrading model performance. To overcome this problem, we propose Normality Guided Multiple Instance Learning (NG-MIL) framework, which encodes diverse normal patterns from noise-free normal videos into prototypes for constructing a similarity-based classifier. By ensembling predictions of two classifiers, our method could refine the anomaly scores, reducing training instability from weak labels. Moreover, we introduce normality clustering and normality guided triplet loss constraining inner bag instances to boost the effect of NG-MIL and increase the discriminability of classifiers. Extensive experiments on three public datasets (ShanghaiTech, UCF-Crime, XD-Violence) demonstrate that our method is comparable to or better than existing weakly supervised methods, achieving state-of-the-art results.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2190474239",
                        "name": "S. Park"
                    },
                    {
                        "authorId": "100840278",
                        "name": "H. Kim"
                    },
                    {
                        "authorId": "2141319949",
                        "name": "Minsu Kim"
                    },
                    {
                        "authorId": "2111303397",
                        "name": "Dahye Kim"
                    },
                    {
                        "authorId": "144442279",
                        "name": "K. Sohn"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In particular MNAD [32] and MPN [26] set up for comparison in the same settings also show this trend.",
                "[32] propose the compact loss and separation loss to reduce the distance of the nearest feature and enhance the diversity of memory patterns, respectively.",
                "Moreover, the memory module remains effective and outperforms the reconstructed results on the predictive model [32].",
                "Instead, abnormal appearance in video frames may be reconstructed partially, or even completely [9, 32].",
                "Despite the specific design, conventional frame prediction-based approaches take a short sequence as input, which may leak anomalous motion patterns existing in those sequences to the synthesized future frame [17, 10, 4, 26, 32, 8], hurting the detection of abnormal motion patterns.",
                "This is different from previous works [9, 32, 26, 4, 19] that either uses a hard threshold to select memory keys, select only the most similar memory key or linearly combine all the keys.",
                "The primary comparison methods are memory-augmented models, which are MemAE [9], MNAD [32], AMMC [4] and MPN [26].",
                "The memory size is same as MNAD [32] and MPN [26] at 10.",
                "[32] and MPN [26] provide results for both.",
                "These approaches take prediction errors as anomaly clues and demonstrate promising performance [4, 32, 10]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "d7de9df4dd7c579651c4b4189cfda6810d2cf032",
                "externalIds": {
                    "DBLP": "conf/wacv/DengZZL23",
                    "DOI": "10.1109/WACV56688.2023.00266",
                    "CorpusId": 256651432
                },
                "corpusId": 256651432,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/d7de9df4dd7c579651c4b4189cfda6810d2cf032",
                "title": "Bi-directional Frame Interpolation for Unsupervised Video Anomaly Detection",
                "abstract": "Anomaly detection in video surveillance aims to detect anomalous frames whose properties significantly differ from normal patterns. Anomalies in videos can occur in both spatial appearance and temporal motion, making unsupervised video anomaly detection challenging. To tackle this problem, we investigate forward and backward motion continuity between adjacent frames and propose a new video anomaly detection paradigm based on bi-directional frame interpolation. The proposed framework consists of an optical flow estimation network and an interpolation network jointly optimized end-to-end to synthesize a middle frame from its nearest two frames. We further introduce a novel dynamic memory mechanism to balance memory sparsity and normality representation diversity, which attenuates abnormal features in frame interpolation without affecting normal prototypes. In inference, interpolation error and dynamic memory error are fused as anomaly scores. The proposed bi-directional interpolation design improves normal frame synthesis, lowering the false alarm rate of anomaly appearance; meanwhile, the implicit \"regular\" motion constraint in our optical flow estimation and the novel dynamic memory mechanism play blocking roles in interpolating abnormal frames, increasing the system\u2019s sensitivity to anomalies. Extensive experiments on public benchmarks demonstrates the superiority of the proposed framework over prior arts.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2153490019",
                        "name": "Hanqiu Deng"
                    },
                    {
                        "authorId": "2156123014",
                        "name": "Zhaoxiang Zhang"
                    },
                    {
                        "authorId": "9399556",
                        "name": "Shihao Zou"
                    },
                    {
                        "authorId": "2158053097",
                        "name": "Xingyu Li"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "fe078a482ecd70a1e61762ccdcd2ccdddcef1896",
                "externalIds": {
                    "DBLP": "journals/pr/WangTZSH23",
                    "DOI": "10.1016/j.patcog.2023.109335",
                    "CorpusId": 255897344
                },
                "corpusId": 255897344,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fe078a482ecd70a1e61762ccdcd2ccdddcef1896",
                "title": "Memory-augmented appearance-motion network for video anomaly detection",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108571702",
                        "name": "Le Wang"
                    },
                    {
                        "authorId": "2201034013",
                        "name": "Junwen Tian"
                    },
                    {
                        "authorId": "3373601",
                        "name": "Sanping Zhou"
                    },
                    {
                        "authorId": "1387721378",
                        "name": "Haoyue Shi"
                    },
                    {
                        "authorId": "144988571",
                        "name": "G. Hua"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "9bd3d258d5c52858aef18134cbfc28704142453b",
                "externalIds": {
                    "DBLP": "journals/ivc/ChenMMWW23",
                    "DOI": "10.1016/j.imavis.2023.104629",
                    "CorpusId": 255904490
                },
                "corpusId": 255904490,
                "publicationVenue": {
                    "id": "6cc36eeb-d056-42c4-a306-7bcb239cc442",
                    "name": "Image and Vision Computing",
                    "type": "journal",
                    "alternate_names": [
                        "Image Vis Comput"
                    ],
                    "issn": "0262-8856",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525443/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/02628856",
                        "https://www.journals.elsevier.com/image-and-vision-computing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9bd3d258d5c52858aef18134cbfc28704142453b",
                "title": "Spatial-temporal graph attention network for video anomaly detection",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2149052803",
                        "name": "Haoyang Chen"
                    },
                    {
                        "authorId": "2067542443",
                        "name": "Xue Mei"
                    },
                    {
                        "authorId": "2116416964",
                        "name": "Zhiyuan Ma"
                    },
                    {
                        "authorId": "2145502514",
                        "name": "Xinhong Wu"
                    },
                    {
                        "authorId": "2201316290",
                        "name": "Yachuan Wei"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recent algorithms can be broadly classified into reconstruction based approaches [13, 15, 26, 29, 30], which try to classify frames based on the reconstruction error, and prediction based approaches [22, 19, 7, 9], which attempt to predict a future frame, primarily by using generative adversarial networks (GANs) [14]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "fcc6ab7340575dfb6db7a13225f9bea19bd02c10",
                "externalIds": {
                    "DBLP": "conf/wacv/DoshiY23",
                    "DOI": "10.1109/WACV56688.2023.00268",
                    "CorpusId": 256652429
                },
                "corpusId": 256652429,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/fcc6ab7340575dfb6db7a13225f9bea19bd02c10",
                "title": "Towards Interpretable Video Anomaly Detection",
                "abstract": "Most video anomaly detection approaches are based on data-intensive end-to-end trained neural networks, which extract spatiotemporal features from videos. The extracted feature representations in such approaches are not interpretable, which prevents the automatic identification of anomaly cause. To this end, we propose a novel framework which can explain the detected anomalous event in a surveillance video. In addition to monitoring objects independently, we also monitor the interactions between them to detect anomalous events and explain their root causes. Specifically, we demonstrate that the scene graphs obtained by monitoring the object interactions provide an interpretation for the context of the anomaly while performing competitively with respect to the recent state-of-the-art approaches. Moreover, the proposed interpretable method enables cross-domain adaptability (i.e., transfer learning in another surveillance scene), which is not feasible for most existing end-to-end methods due to the lack of sufficient labeled training data for every surveillance scene. The quick and reliable detection performance of the proposed method is evaluated both theoretically (through an asymptotic optimality proof) and empirically on the popular benchmark datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "115636521",
                        "name": "Keval Doshi"
                    },
                    {
                        "authorId": "79595155",
                        "name": "Yasin Y\u0131lmaz"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[Park et al. 2020] addressed this drawback by introducing feature compactness loss and feature separateness loss.",
                "To resolve this issue, the memory module [Gong et al. 2019; Park et al. 2020] is incorporated into reconstructionbased methods.",
                "Park\net al. [Park et al. 2020] addressed this drawback by introducing feature compactness loss and feature separateness loss."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "25401efe27c8ba0f1288015ca75bce81f6dbd02a",
                "externalIds": {
                    "DBLP": "conf/vrcai/ChenWWL22",
                    "DOI": "10.1145/3574131.3574463",
                    "CorpusId": 255775637
                },
                "corpusId": 255775637,
                "publicationVenue": {
                    "id": "5666d113-b993-4b48-a56c-12ec44c69ede",
                    "name": "International Conference on Virtual Reality Continuum and its Applications in Industry",
                    "type": "conference",
                    "alternate_names": [
                        "Virtual Real Contin it Appl Ind",
                        "Int Conf Virtual Real Contin it Appl Ind",
                        "Virtual Reality Continuum and its Applications in Industry",
                        "VRCAI"
                    ],
                    "url": "https://web.archive.org/web/*/http://portal.acm.org/toc.cfm?id=SERIES11355"
                },
                "url": "https://www.semanticscholar.org/paper/25401efe27c8ba0f1288015ca75bce81f6dbd02a",
                "title": "Robust Anomaly Detection and Localization via Simulated Anomalies",
                "abstract": "Anomaly detection refers to identifying abnormal images and localizing anomalous regions. Reconstruction-based anomaly detection is a commonly used method; however, traditional reconstruction-based methods perform poorly as deep models generalize successfully enough that even anomalous regions can be well-restored. In this paper, we propose a new method to address the single pseudo-anomaly type and high false positive detection of the existing methods. Specifically, we design a novel pseudo-anomaly simulation module that can generate several types of anomalies on normal images. Furthermore, we propose an effective reconstruction network to improve the robustness of the model against distractors. Finally, we employ a segmentation network to localize anomalous regions. This simple but effective method can detect various anomalies in the real world, even those that are subtle and rare. Extensive experiments on the MVTec anomaly detection dataset demonstrate the effectiveness and superiority of the proposed method, yielding an AUROC score of 98.2% in image-level anomaly detection and 97.8% in pixel-level anomaly localization.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2957397",
                        "name": "Yadang Chen"
                    },
                    {
                        "authorId": "2196204142",
                        "name": "Mei Wang"
                    },
                    {
                        "authorId": "5176032",
                        "name": "Duolin Wang"
                    },
                    {
                        "authorId": "51239371",
                        "name": "Dichao Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "1 in the prediction method, respectively [13].",
                "In Figures 7\u20139, score1 is used to represent the model scores in literature [13], score2 is used to represent themodel scores in this paper, the label is used to represent the label of the testing videos, and the threshold is the division value of abnormal and normal behavior.",
                "In Figures 7\u20139, it is shown that the partial anomaly scores and corresponding division thresholds on the test set given by the prediction model of this paper and the literature [13] in the Ped1, Ped2, and Avenue datasets.",
                "[13] improved the model proposed by Gong et al.",
                "Te loss function has 4 parts, the intensity loss Lossp [7], which constrains pixel similarity, the feature aggregation loss Lossf g and separation loss Lossf s[13], which ensure that the memory module can record typical normal behavior, and the edge loss Lossg, which Skip Connection Memory",
                "So, the model in this paper can more accurately divide the normal and abnormal behavior frames than the model in the literature [13].",
                "In order to evaluate the model performance, we visualize the refactoring error obtained by the prediction model of literature [13] and this paper.",
                "6 in reconstruction and prediction methods [13].",
                "Since the sum of feature similarity and pixel error weights is set to 1 [13], this paper sets \u03bb \ufffd 1 \u2212 \u03b7 \u2212 \u03c6.",
                "Terefore, this paper sets \u03b7 around the value of literature [13] and then adjusts the value of the newly added weight \u03c6."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0d678d6480c8e3d82baa1cea6fc49c9fc499f76f",
                "externalIds": {
                    "DOI": "10.1155/2022/1038225",
                    "CorpusId": 254964558
                },
                "corpusId": 254964558,
                "publicationVenue": {
                    "id": "37555ef6-5b69-4ae8-a9b3-f2052c7552a5",
                    "name": "Advances in Multimedia",
                    "alternate_names": [
                        "Adv Multimedia"
                    ],
                    "issn": "1687-5680",
                    "url": "https://www.hindawi.com/journals/am/"
                },
                "url": "https://www.semanticscholar.org/paper/0d678d6480c8e3d82baa1cea6fc49c9fc499f76f",
                "title": "A New Method of Pedestrian Abnormal Behavior Detection Based on Attention Guidance",
                "abstract": "In public places, some behavior that violates public order and endangers public safety is defined as abnormal behavior. Moreover, it is a necessary auxiliary means to maintain public order and safety by detecting abnormal behavior in a large number of surveillance videos. However, due to the small proportion of abnormal behavior in video data, the extreme imbalance of data seriously restricts the effectiveness of detection. So, weakly supervised learning has become the most suitable and effective detection method. However, existing weakly supervised methods rarely take the locality and slightness of abnormal behavior into account and ignore the details of extracted features. Based on this, an attention-directed abnormal behavior detection model is proposed. In the two common prediction and reconstruction abnormal behavior detection methods based on weak supervision, suitable attention mechanisms are introduced, respectively, and two corresponding attention-directed networks are proposed. In addition, aiming at the problem of inaccurate thresholds for abnormal behavior division, the loss function of the model is improved and a new abnormal behavior evaluation method is proposed. Experiments were carried out on three classical datasets (the USCD Ped1, USCD Ped2, and CUHK Avenue dataset) for abnormal behavior detection. The best results for the area under the curve (AUC) indicator reached 82.7%, 94.5%, and 87.3%, respectively, which are better than many existing literature results.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "70578742",
                        "name": "Jingui Huang"
                    },
                    {
                        "authorId": "2197770868",
                        "name": "Jingyi Li"
                    },
                    {
                        "authorId": "2197770658",
                        "name": "Wenya Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "13edf6a2125465dd88376f3633cf0203de5258b8",
                "externalIds": {
                    "DBLP": "conf/cvpr/SinghJL23",
                    "ArXiv": "2212.07900",
                    "DOI": "10.1109/CVPR52729.2023.01795",
                    "CorpusId": 254496525
                },
                "corpusId": 254496525,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/13edf6a2125465dd88376f3633cf0203de5258b8",
                "title": "EVAL: Explainable Video Anomaly Localization",
                "abstract": "We develop a novel framework for single-scene video anomaly localization that allows for human-understandable reasons for the decisions the system makes. We first learn general representations of objects and their motions (using deep networks) and then use these representations to build a high-level, location-dependent model of any particular scene. This model can be used to detect anomalies in new videos of the same scene. Importantly, our approach is explainable - our high-level appearance and motion features can provide human-understandable reasons for why any part of a video is classified as normal or anomalous. We conduct experiments on standard video anomaly detection datasets (Street Scene, CUHK Avenue, ShanghaiTech and UCSD Ped1, Ped2) and show significant improvements over the previous state-of-the-art. All of our code and extra datasets will be made publicly available.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1824188732",
                        "name": "Vasu Singla"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "65e0ae321f8293066d4aa103ba53d600e213f168",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-07010",
                    "ArXiv": "2212.07010",
                    "DOI": "10.1109/WACV56688.2023.00261",
                    "CorpusId": 254636588
                },
                "corpusId": 254636588,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/65e0ae321f8293066d4aa103ba53d600e213f168",
                "title": "Cross-Domain Video Anomaly Detection without Target Domain Adaptation",
                "abstract": "Most cross-domain unsupervised Video Anomaly Detection (VAD) works assume that at least few task-relevant target domain training data are available for adaptation from the source to the target domain. However, this requires laborious model-tuning by the end-user who may prefer to have a system that works \"out-of-the-box.\" To address such practical scenarios, we identify a novel target domain (inference-time) VAD task where no target domain training data are available. To this end, we propose a new \u2018Zero-shot Cross-domain Video Anomaly Detection (zxVAD)\u2019 framework that includes a future-frame prediction generative model setup. Different from prior future-frame prediction models, our model uses a novel Normalcy Classifier module to learn the features of normal event videos by learning how such features are different \"relatively\" to features in pseudo-abnormal examples. A novel Untrained Convolutional Neural Network based Anomaly Synthesis module crafts these pseudo-abnormal examples by adding foreign objects in normal video frames with no extra training cost. With our novel relative normalcy feature learning strategy, zxVAD generalizes and learns to distinguish between normal and abnormal frames in a new target domain without adaptation during inference. Through evaluations on common datasets, we show that zxVAD outperforms the state-of-the-art (SOTA), regardless of whether task-relevant (i.e., VAD) source training data are available or not. Lastly, zxVAD also beats the SOTA methods in inference-time efficiency metrics including the model size, total parameters, GPU energy consumption, and GMACs.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2274692",
                        "name": "Abhishek Aich"
                    },
                    {
                        "authorId": "2692770",
                        "name": "Kuan-Chuan Peng"
                    },
                    {
                        "authorId": "1404727582",
                        "name": "A. Roy-Chowdhury"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To further enhance its distinguishing power for diverse scenarios on different roads over time, we sparsify the attention-based query mechanism (defined in Equation (7)) with two constraints [53, 54], including a consistency loss L1 and a contrastive loss L2, denoted by:",
                "This technique has been largely employed on computer vision tasks, such as few-shot learning [51, 52] and anomaly detection [53, 54]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "d4aaf667782227915ae44009fc192ed35cd16b27",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-05989",
                    "ArXiv": "2212.05989",
                    "DOI": "10.48550/arXiv.2212.05989",
                    "CorpusId": 254564537
                },
                "corpusId": 254564537,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d4aaf667782227915ae44009fc192ed35cd16b27",
                "title": "MegaCRN: Meta-Graph Convolutional Recurrent Network for Spatio-Temporal Modeling",
                "abstract": "Spatio-temporal modeling as a canonical task of multivariate time series forecasting has been a significant research topic in AI community. To address the underlying heterogeneity and non-stationarity implied in the graph streams, in this study, we propose Spatio-Temporal Meta-Graph Learning as a novel Graph Structure Learning mechanism on spatio-temporal data. Specifically, we implement this idea into Meta-Graph Convolutional Recurrent Network (MegaCRN) by plugging the Meta-Graph Learner powered by a Meta-Node Bank into GCRN encoder-decoder. We conduct a comprehensive evaluation on two benchmark datasets (METR-LA and PEMS-BAY) and a large-scale spatio-temporal dataset that contains a variaty of non-stationary phenomena. Our model outperformed the state-of-the-arts to a large degree on all three datasets (over 27% MAE and 34% RMSE). Besides, through a series of qualitative evaluations, we demonstrate that our model can explicitly disentangle locations and time slots with different patterns and be robustly adaptive to different anomalous situations. Codes and datasets are available at https://github.com/deepkashiwa20/MegaCRN.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "31279896",
                        "name": "Renhe Jiang"
                    },
                    {
                        "authorId": "2144719549",
                        "name": "Zhaonan Wang"
                    },
                    {
                        "authorId": "2064967385",
                        "name": "Jiawei Yong"
                    },
                    {
                        "authorId": "2881420",
                        "name": "P. Jeph"
                    },
                    {
                        "authorId": "40628376",
                        "name": "Quanjun Chen"
                    },
                    {
                        "authorId": "2192604300",
                        "name": "Yasumasa Kobayashi"
                    },
                    {
                        "authorId": "2112276021",
                        "name": "Xuan Song"
                    },
                    {
                        "authorId": "2231831",
                        "name": "T. Suzumura"
                    },
                    {
                        "authorId": "2053705074",
                        "name": "Shintaro Fukushima"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "fecbc97be3dab35ada1a5b91abe3edb9d95c39f6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-05136",
                    "ArXiv": "2212.05136",
                    "DOI": "10.48550/arXiv.2212.05136",
                    "CorpusId": 254563882
                },
                "corpusId": 254563882,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fecbc97be3dab35ada1a5b91abe3edb9d95c39f6",
                "title": "CLIP-TSA: CLIP-Assisted Temporal Self-Attention for Weakly-Supervised Video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) -- commonly formulated as a multiple-instance learning problem in a weakly-supervised manner due to its labor-intensive nature -- is a challenging problem in video surveillance where the frames of anomaly need to be localized in an untrimmed video. In this paper, we first propose to utilize the ViT-encoded visual features from CLIP, in contrast with the conventional C3D or I3D features in the domain, to efficiently extract discriminative representations in the novel technique. We then model temporal dependencies and nominate the snippets of interest by leveraging our proposed Temporal Self-Attention (TSA). The ablation study confirms the effectiveness of TSA and ViT feature. The extensive experiments show that our proposed CLIP-TSA outperforms the existing state-of-the-art (SOTA) methods by a large margin on three commonly-used benchmark datasets in the VAD problem (UCF-Crime, ShanghaiTech Campus, and XD-Violence). Our source code is available at https://github.com/joos2010kj/CLIP-TSA.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2105167644",
                        "name": "Hyekang Joo"
                    },
                    {
                        "authorId": "2065785558",
                        "name": "Khoa T. Vo"
                    },
                    {
                        "authorId": "1556433845",
                        "name": "Kashu Yamazaki"
                    },
                    {
                        "authorId": "144556913",
                        "name": "Ngan T. H. Le"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "41975fa77183ffe7e75d9cb3274d04466924d05a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-04090",
                    "ArXiv": "2212.04090",
                    "DOI": "10.1109/CVPR52729.2023.01561",
                    "CorpusId": 254408833
                },
                "corpusId": 254408833,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/41975fa77183ffe7e75d9cb3274d04466924d05a",
                "title": "Exploiting Completeness and Uncertainty of Pseudo Labels for Weakly Supervised Video Anomaly Detection",
                "abstract": "Weakly supervised video anomaly detection aims to identify abnormal events in videos using only video-level labels. Recently, two-stage self-training methods have achieved significant improvements by self-generating pseudo labels and self-refining anomaly scores with these labels. As the pseudo labels play a crucial role, we propose an enhancement framework by exploiting completeness and uncertainty properties for effective self-training. Specifically, we first design a multi-head classification module (each head serves as a classifier) with a diversity loss to maximize the distribution differences of predicted pseudo labels across heads. This encourages the generated pseudo labels to cover as many abnormal events as possible. We then devise an iterative uncertainty pseudo label refinement strategy, which improves not only the initial pseudo labels but also the updated ones obtained by the desired classifier in the second stage. Extensive experimental results demonstrate the proposed method performs favorably against state-of-the-art approaches on the UCF-Crime, TAD, and XD-Violence benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2200060818",
                        "name": "Chen Zhang"
                    },
                    {
                        "authorId": "2143164613",
                        "name": "Guorong Li"
                    },
                    {
                        "authorId": "35653798",
                        "name": "Yuankai Qi"
                    },
                    {
                        "authorId": "2119545962",
                        "name": "Shuhui Wang"
                    },
                    {
                        "authorId": "2343895",
                        "name": "Laiyun Qing"
                    },
                    {
                        "authorId": "1689702",
                        "name": "Qingming Huang"
                    },
                    {
                        "authorId": "37144787",
                        "name": "Ming-Hsuan Yang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "d31a54553648a1001ebd63b734e5b644c10878f7",
                "externalIds": {
                    "DBLP": "conf/aaai/LuoLYXH023",
                    "ArXiv": "2212.00501",
                    "DOI": "10.48550/arXiv.2212.00501",
                    "CorpusId": 254125157
                },
                "corpusId": 254125157,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/d31a54553648a1001ebd63b734e5b644c10878f7",
                "title": "Crowd-level Abnormal Behavior Detection via Multi-scale Motion Consistency Learning",
                "abstract": "Detecting abnormal crowd motion emerging from complex interactions of individuals is paramount to ensure the safety of crowds. Crowd-level abnormal behaviors (CABs), e.g., counter flow and crowd turbulence, are proven to be the crucial causes of many crowd disasters. In the recent decade, video anomaly detection (VAD) techniques have achieved remarkable success in detecting individual-level abnormal behaviors (e.g., sudden running, fighting and stealing), but research on VAD for CABs is rather limited. Unlike individual-level anomaly, CABs usually do not exhibit salient difference from the normal behaviors when observed locally, and the scale of CABs could vary from one scenario to another. In this paper, we present a systematic study to tackle the important problem of VAD for CABs with a novel crowd motion learning framework, multi-scale motion consistency network (MSMC-Net). MSMC-Net first captures the spatial and temporal crowd motion consistency information in a graph representation. Then, it simultaneously trains multiple feature graphs constructed at different scales to capture rich crowd patterns. An attention network is used to adaptively fuse the multi-scale features for better CAB detection. For the empirical study, we consider three large-scale crowd event datasets, UMN, Hajj and Love Parade. Experimental results show that MSMC-Net could substantially improve the state-of-the-art performance on all the datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "49571827",
                        "name": "Linbo Luo"
                    },
                    {
                        "authorId": "2193104129",
                        "name": "Yuanjing Li"
                    },
                    {
                        "authorId": "50086584",
                        "name": "Haiyan Yin"
                    },
                    {
                        "authorId": "115609021",
                        "name": "Shangwei Xie"
                    },
                    {
                        "authorId": "2067789404",
                        "name": "Ruimin Hu"
                    },
                    {
                        "authorId": "2113720070",
                        "name": "Wen-Feng Cai"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "079d1e6479733ff597ba6afe7eb7128852f4c158",
                "externalIds": {
                    "DBLP": "journals/ijon/HyunNL23",
                    "DOI": "10.1016/j.neucom.2022.12.026",
                    "CorpusId": 254720203
                },
                "corpusId": 254720203,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/079d1e6479733ff597ba6afe7eb7128852f4c158",
                "title": "Dissimilate-and-assimilate strategy for video anomaly detection and localization",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2191246436",
                        "name": "Wooyeol Hyun"
                    },
                    {
                        "authorId": "148354920",
                        "name": "Woo-Jeoung Nam"
                    },
                    {
                        "authorId": "2155886654",
                        "name": "Seong-Whan Lee"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "a03aa9703dcccf927786e5b55768e648527392d7",
                "externalIds": {
                    "DBLP": "journals/jvcir/WangC23",
                    "DOI": "10.1016/j.jvcir.2022.103739",
                    "CorpusId": 255363646
                },
                "corpusId": 255363646,
                "publicationVenue": {
                    "id": "0c711e3b-de49-4786-9dd8-3edd2c943869",
                    "name": "Journal of Visual Communication and Image Representation",
                    "type": "journal",
                    "alternate_names": [
                        "J Vis Commun Image Represent"
                    ],
                    "issn": "1047-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622906/description#description",
                    "alternate_urls": [
                        "http://www.journals.elsevier.com/journal-of-visual-communication-and-image-representation/",
                        "https://www.journals.elsevier.com/journal-of-visual-communication-and-image-representation/",
                        "http://www.idealibrary.com/",
                        "http://www.sciencedirect.com/science/journal/10473203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a03aa9703dcccf927786e5b55768e648527392d7",
                "title": "Anomaly detection with dual-stream memory network",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2158412495",
                        "name": "Zhongyue Wang"
                    },
                    {
                        "authorId": "2118428168",
                        "name": "Ying Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For example, when the memory module is omitted, the AUC score of PA-MAE on Ped2 is 97.66% while the value of MemAE and MNAD is only 91.70% and 94.30%, respectively.",
                "Using only 10 memory items to capture normal patterns, but thanks to two new losses named feature compactness loss and separateness loss, MNAD maintains the diversity and discrimination of memory items.",
                "The table shows that PA-MAE often outperforms MemAE and MNAD.",
                "In video anomaly detection, several memoryaugmented autoencoders are proposed to detect anomalies [9, 22], in which a memory module is built over the latent space between encoder and decoder.",
                "When the memory module is used, the AUC of PA-MAE is also higher than the value of MemAE and MNAD in almost cases except on Avenue where the AUC score of MNAD is slightly higher than that of PA-MAE.",
                "The first set is to compare PA-MAE with two models (MemAE[9] and MNAD[22]) that are based on the memory network.",
                "To address the issue, some recent studies [9, 15, 22] have added memory modules in between the encoder and decoder to weaken the capacity of an autoencoder on abnormal events.",
                "Continuing the idea of applying memory, the authors in [22] proposed a newmemory model named MNAD that is more efficient than MemAE in terms of memory space and performance.",
                "%) score of PA-MAE and two memory augmented networks MemAE[9] and MNAD[22] on the three datasets namely Ped2, Avenue, and ShanghaiTech.",
                "Table 1 presents the AUC(%) score of PA-MAE and two memory augmented networks MemAE[9] and MNAD[22] on the three datasets namely Ped2, Avenue, and ShanghaiTech."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a283e48c27f5b0430536a4e8264aa1055de65cd6",
                "externalIds": {
                    "DBLP": "conf/soict/LeNNPC22",
                    "DOI": "10.1145/3568562.3568642",
                    "CorpusId": 254045294
                },
                "corpusId": 254045294,
                "publicationVenue": {
                    "id": "8f515bf7-e3c7-4242-85e5-14de4c29e76c",
                    "name": "Symposium on Information and Communication Technology",
                    "type": "conference",
                    "alternate_names": [
                        "Symp Inf Commun Technol",
                        "SoICT"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a283e48c27f5b0430536a4e8264aa1055de65cd6",
                "title": "An integration of Pseudo Anomalies and Memory Augmented Autoencoder for Video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) has received a lot of attention from the research community in recent years. The purpose of VAD is to identify the anomalous appearance and behavior of objects in videos. Due to the difficulty in collecting anomalous data, video anomaly detection is often based on a one-class classification (OCC) problem. Among the methods, deep autoencoders have been shown to be effective for anomaly detection in video. Specifically, autoencoders are only trained on normal images during the training time, then it is expected to reconstruct or predicted well for normal frames but poorly for anomalous ones at the test time. Contrary to the expectation, abnormal frames may have a chance of being well constructed by trained autoencoders because of the powerful representation capacity of the deep neural network as well as the diversity of normal patterns. To address the issue, we propose a strategy called and shortened as PA-MAE (Pseudo Anomalies-Memory-augmented Autoencoder) which feeds pseudo anomalies into a memory-augmented autoencoder network during training time. Therefore, the proposed model is able to take advantage of both memory-based autoencoder networks and pseudo-anomaly synthesizers which can store the prototypical features of the normal frames and produce high reconstruction errors on dummy anomaly examples. Experimental results on several benchmark video datasets (i.e. Ped2, Avenue, and ShanghaiTech) demonstrate that our method outperforms some state-of-the-art memory-augmented methods as well as several recent models using pseudo-anomaly synthesizers.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2057527006",
                        "name": "Anh Le"
                    },
                    {
                        "authorId": "40507980",
                        "name": "Quang Uy Nguyen"
                    },
                    {
                        "authorId": "1976308816",
                        "name": "Ngoc Tran Nguyen"
                    },
                    {
                        "authorId": "8092281",
                        "name": "Hai-Hong Phan"
                    },
                    {
                        "authorId": "30264059",
                        "name": "Thi Huong Chu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Prediction-based methods learn to predict frames or flow maps in video clips, including inpainting intermediate frames and predicting future frames [5, 11, 12, 28, 30, 36, 48, 59, 64]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "ecf1b50214ff13d2378e8f637c846c61ff2a0b43",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-00789",
                    "ArXiv": "2212.00789",
                    "DOI": "10.48550/arXiv.2212.00789",
                    "CorpusId": 254125558
                },
                "corpusId": 254125558,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/ecf1b50214ff13d2378e8f637c846c61ff2a0b43",
                "title": "Attribute-based Representations for Accurate and Interpretable Video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) is a challenging computer vision task with many practical applications. As anomalies are inherently ambiguous, it is essential for users to understand the reasoning behind a system's decision in order to determine if the rationale is sound. In this paper, we propose a simple but highly effective method that pushes the boundaries of VAD accuracy and interpretability using attribute-based representations. Our method represents every object by its velocity and pose. The anomaly scores are computed using a density-based approach. Surprisingly, we find that this simple representation is sufficient to achieve state-of-the-art performance in ShanghaiTech, the largest and most complex VAD dataset. Combining our interpretable attribute-based representations with implicit, deep representation yields state-of-the-art performance with a $99.1\\%, 93.3\\%$, and $85.9\\%$ AUROC on Ped2, Avenue, and ShanghaiTech, respectively. Our method is accurate, interpretable, and easy to implement.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1994220582",
                        "name": "Tal Reiss"
                    },
                    {
                        "authorId": "2126490970",
                        "name": "Yedid Hoshen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As a consequence, prediction-based anomaly detection methods have developed rapidly during the last few years [13], [14]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "9e875a417b411bc2923db87cc1b80df4b705bc1c",
                "externalIds": {
                    "DBLP": "journals/tcsv/ZhongCHTR22",
                    "DOI": "10.1109/TCSVT.2022.3190539",
                    "CorpusId": 250537762
                },
                "corpusId": 250537762,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/9e875a417b411bc2923db87cc1b80df4b705bc1c",
                "title": "Bidirectional Spatio-Temporal Feature Learning With Multiscale Evaluation for Video Anomaly Detection",
                "abstract": "Video anomaly detection aims to detect the segments containing abnormal events from video sequence, which is a current research hotspot due to the importance in maintaining social security. Recent detection methods tend to build frame reconstruction or frame prediction model based on deep learning to learn features of events. The reconstruction-based methods reproduce the input frame one-to-one, inevitably losing some temporal features. The prediction-based methods predict frames according to the natural time order, but ignore the reverse time information, causing the deviation in information learning. Besides, anomaly evaluation methods based on patch-level error neglect the diversity of object sizes in complex scenes, and it is difficult to determine the optimal size of the error patch accurately. For these issues, we propose a bidirectional spatio-temporal feature learning framework with multi-scale anomaly evaluation strategy. A video sequence is input to a double-encoder double-decoder network, and bidirectional spatio-temporal features are obtained for bidirectional prediction by fusing forward and backward features extracted from the two encoders. The multi-scale anomaly evaluation method is implemented based on error pyramid and mean pooling, which effectively detects target objects with different sizes. Experiments on several publicly video datasets show that our method outperforms most of existing methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48751559",
                        "name": "Yuanhong Zhong"
                    },
                    {
                        "authorId": "2176480465",
                        "name": "Xia Chen"
                    },
                    {
                        "authorId": "2140880463",
                        "name": "Yongting Hu"
                    },
                    {
                        "authorId": "2047470075",
                        "name": "Panliang Tang"
                    },
                    {
                        "authorId": "93738696",
                        "name": "Fan Ren"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Reconstruction-based methods usually use AutoEncoders (AEs) [8]\u2013[11] or Generative Adversarial Networks (GANs) [12]\u2013[14] to learn the distribution of normal data and then determine whether a test sample is anomalous based on how well it can be recovered."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "61eb26d960eb7b9ea45c26694eec09356773f43a",
                "externalIds": {
                    "DBLP": "conf/hpcc/WangZLLY22",
                    "DOI": "10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00054",
                    "CorpusId": 257808747
                },
                "corpusId": 257808747,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/61eb26d960eb7b9ea45c26694eec09356773f43a",
                "title": "Image Anomaly Detection With Semantic- Enhanced Augmentation and Distributional Kernel",
                "abstract": "In the field of image anomaly detection, self-supervised learning using only normal samples has become a hot research topic since it is difficult to acquire sufficient abnormal data. However, existing self-supervised methods usually consider the impact of the superficial information rather than the semantics of images, resulting in limited generalisation performance. Furthermore, the small amount of training data further limits the performance of anomaly detection. To overcome both issues, we propose a two-stage self-supervised learning framework based on CutPaste with a feature extraction stage followed by an anomaly detection stage. We first add a diminished semantics augmentation to generate harder abnormal samples, so that the feature extraction model pays more attention to semantic information. Furthermore, we increase the density of normal samples with normal sample augmentations and integrate a data-dependent distributional kernel to improve the detection of abnormal images in the second stage, based on the adaptive distributional similarity. Our extensive experiments on the MVTec anomaly detection dataset demonstrate the superior performance of the proposed method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115270285",
                        "name": "Mingxi Wang"
                    },
                    {
                        "authorId": "2124575584",
                        "name": "Ye Zhu"
                    },
                    {
                        "authorId": "2155120733",
                        "name": "Gang Li"
                    },
                    {
                        "authorId": "2146562210",
                        "name": "Gang Liu"
                    },
                    {
                        "authorId": "2119659070",
                        "name": "Bo Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Other works utilize the memory mechanism to memorize normal patterns (Gong et al. 2019; Park, Noh, and Ham 2020; Liu et al. 2021; R. et al. 2021) and use metalearning (Lu et al. 2020) to enhance model\u2019s generalization capability to the unseen normal scenarios."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "9d60265ea72d0344e991e71dfb13b4e1f15d4d4d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-15098",
                    "ArXiv": "2211.15098",
                    "DOI": "10.48550/arXiv.2211.15098",
                    "CorpusId": 254044120
                },
                "corpusId": 254044120,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/9d60265ea72d0344e991e71dfb13b4e1f15d4d4d",
                "title": "MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection",
                "abstract": "Weakly supervised detection of anomalies in surveillance videos is a challenging task. Going beyond existing works that have deficient capabilities to localize anomalies in long videos, we propose a novel glance and focus network to effectively integrate spatial-temporal information for accurate anomaly detection. In addition, we empirically found that existing approaches that use feature magnitudes to represent the degree of anomalies typically ignore the effects of scene variations, and hence result in sub-optimal performance due to the inconsistency of feature magnitudes across scenes. To address this issue, we propose the Feature Amplification Mechanism and a Magnitude Contrastive Loss to enhance the discriminativeness of feature magnitudes for detecting anomalies. Experimental results on two large-scale benchmarks UCF-Crime and XD-Violence manifest that our method outperforms state-of-the-art approaches.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2144541618",
                        "name": "Y. Chen"
                    },
                    {
                        "authorId": "2926099",
                        "name": "Zhengzhe Liu"
                    },
                    {
                        "authorId": "1820336089",
                        "name": "Baoheng Zhang"
                    },
                    {
                        "authorId": "3289203",
                        "name": "W. Fok"
                    },
                    {
                        "authorId": "50844674",
                        "name": "Xiaojuan Qi"
                    },
                    {
                        "authorId": "2107900954",
                        "name": "Yik-Chung Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The anomaly detection approaches are typically categorized into dictionary learning methods [33\u201335, 40, 48], probabilistic models [32, 37, 42, 43, 63\u201367], distance-based approaches [7,8,18,21,44,46,49,68\u2013 71], reconstruction-based methods [6,15,17,20,23,36,39,41, 47, 72, 73] and change detection frameworks [9, 16, 74, 75].",
                "To reduce the generalization capability, researchers employed various techniques, such as adding memory modules [6, 13, 17] or masked convolutional blocks [20]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a2098146f85a41e38d3d33c86ba9060dd2ce26a1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-15597",
                    "ArXiv": "2211.15597",
                    "DOI": "10.48550/arXiv.2211.15597",
                    "CorpusId": 254044329
                },
                "corpusId": 254044329,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a2098146f85a41e38d3d33c86ba9060dd2ce26a1",
                "title": "Lightning Fast Video Anomaly Detection via Adversarial Knowledge Distillation",
                "abstract": "We propose a very fast frame-level model for anomaly detection in video, which learns to detect anomalies by distilling knowledge from multiple highly accurate object-level teacher models. To improve the fidelity of our student, we distill the low-resolution anomaly maps of the teachers by jointly applying standard and adversarial distillation, introducing an adversarial discriminator for each teacher to distinguish between target and generated anomaly maps. We conduct experiments on three benchmarks (Avenue, ShanghaiTech, UCSD Ped2), showing that our method is over 7 times faster than the fastest competing method, and between 28 and 62 times faster than object-centric models, while obtaining comparable results to recent methods. Our evaluation also indicates that our model achieves the best trade-off between speed and accuracy, due to its previously unheard-of speed of 1480 FPS. In addition, we carry out a comprehensive ablation study to justify our architectural design choices.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "103931166",
                        "name": "Nicolae-Catalin Ristea"
                    },
                    {
                        "authorId": "2154573729",
                        "name": "Florinel-Alin Croitoru"
                    },
                    {
                        "authorId": "8675248",
                        "name": "D. Dascalescu"
                    },
                    {
                        "authorId": "1817759",
                        "name": "Radu Tudor Ionescu"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "2111863589",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "12dd3ea6cd7041aef237f63c03a3e90fdc16897b",
                "externalIds": {
                    "DBLP": "conf/aaai/Jiang0YJCK0FS23",
                    "ArXiv": "2211.14701",
                    "DOI": "10.48550/arXiv.2211.14701",
                    "CorpusId": 254043602
                },
                "corpusId": 254043602,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/12dd3ea6cd7041aef237f63c03a3e90fdc16897b",
                "title": "Spatio-Temporal Meta-Graph Learning for Traffic Forecasting",
                "abstract": "Traffic forecasting as a canonical task of multivariate time series forecasting has been a significant research topic in AI community. To address the spatio-temporal heterogeneity and non-stationarity implied in the traffic stream, in this study, we propose Spatio-Temporal Meta-Graph Learning as a novel Graph Structure Learning mechanism on spatio-temporal data. Specifically, we implement this idea into Meta-Graph Convolutional Recurrent Network (MegaCRN) by plugging the Meta-Graph Learner powered by a Meta-Node Bank into GCRN encoder-decoder. We conduct a comprehensive evaluation on two benchmark datasets (i.e., METR-LA and PEMS-BAY) and a new large-scale traffic speed dataset called EXPY-TKY that covers 1843 expressway road links in Tokyo. Our model outperformed the state-of-the-arts on all three datasets. Besides, through a series of qualitative evaluations, we demonstrate that our model can explicitly disentangle the road links and time slots with different patterns and be robustly adaptive to any anomalous traffic situations. Codes and datasets are available at https://github.com/deepkashiwa20/MegaCRN.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "31279896",
                        "name": "Renhe Jiang"
                    },
                    {
                        "authorId": "2144719549",
                        "name": "Zhaonan Wang"
                    },
                    {
                        "authorId": "2064967385",
                        "name": "Jiawei Yong"
                    },
                    {
                        "authorId": "2881420",
                        "name": "P. Jeph"
                    },
                    {
                        "authorId": "40628376",
                        "name": "Quanjun Chen"
                    },
                    {
                        "authorId": "2192604300",
                        "name": "Yasumasa Kobayashi"
                    },
                    {
                        "authorId": "2112276021",
                        "name": "Xuan Song"
                    },
                    {
                        "authorId": "2053705074",
                        "name": "Shintaro Fukushima"
                    },
                    {
                        "authorId": "2231831",
                        "name": "T. Suzumura"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "d7d1358e4ae58f549fa6756bacc591f9d40f486b",
                "externalIds": {
                    "DOI": "10.1109/CAC57257.2022.10055259",
                    "CorpusId": 257514895
                },
                "corpusId": 257514895,
                "publicationVenue": {
                    "id": "bfa6e440-6762-47f0-b1b9-2a43c02d9f62",
                    "name": "ACM Cloud and Autonomic Computing Conference",
                    "type": "conference",
                    "alternate_names": [
                        "ACM Cloud Auton Comput Conf",
                        "Chinese Automation Congress",
                        "Chin Autom Congr",
                        "CAC"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d7d1358e4ae58f549fa6756bacc591f9d40f486b",
                "title": "A Multi-stage Optimization based Model for Component Defect Detection of Trains",
                "abstract": "Long runs of railway trains inevitably lend to fault conditions. Automatic detection of defects in train components is very important for train safety and maintenance. For a long time, our detection of images still required to some extent human visual interpretation. ln recent years, convolutional neural networks have achieved great success in object detection, instance segmentation and image classification. In order to reduce the need of manual inspection, in this paper a multi-level optimized instance detection model (MOIDM) is proposed for instance-level defect detection. In MOIDM, we propose a two-stage instance segmentation method for defect detection. First, the feature pyramid network and the depth residual neural network are used to extract the multi-scale features of the image, and then the region proposal neural network is used to generate the rough defect region with the extracted hierarchical features, and the defect classification is carried out. Finally, the obtained features are used for instance-level prediction of coarse defect areas. In addition, we propose an Improved Pyramid Pooling Module (IPPM) and a multi-level optimisation module CPSPMask to improve the performance. IPPM can effectively establish long-range connections between pixels, further increasing the network\u2019s ability to extract feature and spatial context information. CPSPMask can aggregate the original image and the mask for obtaining a more accurate mask. Experiment on a dataset containing two kinds of defect verifies the effectiveness of the algorithm. Our method can achieve 86.8% accuracy in terms of segmentation. In addition, which proves its promising performance comparison with state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2183041450",
                        "name": "Ke Yang"
                    },
                    {
                        "authorId": "2108936903",
                        "name": "Wenwu Wang"
                    },
                    {
                        "authorId": "145081300",
                        "name": "Lei Zhu"
                    },
                    {
                        "authorId": "2108673638",
                        "name": "Xiaolian Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Both the clustering [12] and memory modules [13], [14] limit the generalization ability of the network from the features themselves, while lacking a more direct way to manipulate the features in anomalous regions."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "e4f805873163a5f2e75bc4dc91b5ad2d0a93821e",
                "externalIds": {
                    "DOI": "10.1109/CAC57257.2022.10055058",
                    "CorpusId": 257525750
                },
                "corpusId": 257525750,
                "publicationVenue": {
                    "id": "bfa6e440-6762-47f0-b1b9-2a43c02d9f62",
                    "name": "ACM Cloud and Autonomic Computing Conference",
                    "type": "conference",
                    "alternate_names": [
                        "ACM Cloud Auton Comput Conf",
                        "Chinese Automation Congress",
                        "Chin Autom Congr",
                        "CAC"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e4f805873163a5f2e75bc4dc91b5ad2d0a93821e",
                "title": "Teacher-student Network As An Attention Module With Memory for Defect Localization",
                "abstract": "The goal of defect detection is to detect and locate defects on product surface. Since the complexity of defect types in actual industrial production and it is difficult to obtain a large number of samples for supervised training. Current defect detection methods are thought to be mainly unsupervised training methods. However, the current unsupervised methods all learn the normal sample feature representation from the whole and lack direct defect location information. In this paper, A teacherstudent network is used as the attention mechanism to provide the network with more direct information on the location of defects. At the same time, to increase the network\u2019s ability to characterize normal samples, a memory module is used to enhance the reconstruction ability of the network. The experimental results show that our approach obtains the best results compared to similar teacher-student networks and attention mechanism networks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1877189",
                        "name": "Weihang Shi"
                    },
                    {
                        "authorId": "2108936901",
                        "name": "Wenwu Wang"
                    },
                    {
                        "authorId": "145081300",
                        "name": "Lei Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Some improvements were made on Memae and proposed MNAD [20], which uses the query features extracted by encoder and the feature vector obtained by prototype weighting to perform a splicing in the channel dimension, and then feeds the spliced features into the decoder."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6a6642bee623cefe732c3db991399c6692cd2353",
                "externalIds": {
                    "DOI": "10.1109/CAC57257.2022.10055281",
                    "CorpusId": 257516544
                },
                "corpusId": 257516544,
                "publicationVenue": {
                    "id": "bfa6e440-6762-47f0-b1b9-2a43c02d9f62",
                    "name": "ACM Cloud and Autonomic Computing Conference",
                    "type": "conference",
                    "alternate_names": [
                        "ACM Cloud Auton Comput Conf",
                        "Chinese Automation Congress",
                        "Chin Autom Congr",
                        "CAC"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6a6642bee623cefe732c3db991399c6692cd2353",
                "title": "An Unsupervised Anomaly Detection Scheme based on Memory Mechanism in Cloud-edge Collaboration Scenario",
                "abstract": "In order to timely reject defective products in high-speed assembly lines, the task of anomaly detection is widely used in industrial production process. Recently, unsupervised anomaly detection has made tremendous developments as more scholars have started to focus on this field. The model detects abnormal samples whose data distribution deviate from the normal data distribution. However, due to the problem of data island in machine learning, it is difficult to achieve global optimization for models trained on local datasets. In this work, a memory network based algorithm for cloud-edge collaborative anomaly detection is proposed to break down data barrier. Our proposed method obtains an anomaly detection model using local datasets trained at each edge side, and the local model updates the parameters in the cloud to obtain the global model, which decoupling the data retrieval and the training of the global model. In addition, due to the inconsistent data distribution, we design the memory module to retain the data features from each edge in order to further improve the detection capability of the global model. The memory module from each edge is iteratively updated in the cloud with the training of the model, so that our final global anomaly detection model retains the information about data distribution features from different domains of different edges.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2140022563",
                        "name": "Liming Zhu"
                    },
                    {
                        "authorId": "2187058038",
                        "name": "Jun Zhang"
                    },
                    {
                        "authorId": "2144444688",
                        "name": "Yuliang Li"
                    },
                    {
                        "authorId": "2211583535",
                        "name": "Xiaozhen Xu"
                    },
                    {
                        "authorId": "2110474695",
                        "name": "Yingxuan Li"
                    },
                    {
                        "authorId": "144316987",
                        "name": "Chunhui Zhao"
                    },
                    {
                        "authorId": "2189860427",
                        "name": "Wenhai Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "1 Encoder and decoder Shared encoder: Previous studies[3-6] usually input sequential frame sequences into the convolutional encoder in a stacked manner to obtain its encoding features.",
                "The neural network structure of the motion decoder is as follows: In this paper, modifications are made to the decoder structure proposed by Park et al.[5], including deletion of skip-connection operation and cancellation of all operations that fuse the intermediate features of the encoder in the decoder.",
                "After calculating the PSNR of each frame in the test video, this paper normalized the PSNR of all frames in the test video into [0,1] following previous work[3-7][9][13], and used the following formula to calculate the normal score of each frame: \u02c6 ( , ) min ( ) 1 max min PSNR t t PSNR S t PSNR PSNR \uf02d \uf03d \uf02d \uf02d (12)",
                "The neural network structure of the appearance decoder is as follows: This paper follows the decoder structure proposed by Park et al.[5] and changes its input channel number to 512.",
                "In recent years, many researchers[3-13] have trained neural network models describing normal events by using convolutional autoencoders to reconstruct or predict future frames without abnormal samples, and then judge whether anomalies occur in the test phase according to the differences between reconstructed frames and ground truth.",
                "The encoded feature 4 ( )af f of the fourth frame image, the appearance decoder ( )aE  , the\nunderlying feature cf input in the skip-connection structure and the reconstructed fourth frame 4\u0302I have the following relationship:\n4 4\u0302 and ( , )a a a cf f I E f f  (3)\nThe neural network structure of the appearance decoder is as follows: This paper follows the decoder structure proposed by Park et al.[5] and changes its input channel number to 512.",
                "The neural network structure of the shared encoder is as follows: In this paper, the encoder structure proposed by Park et al.[5] is modified as follows: (1) The number of input channels of the encoder is changed to 3, so that the encoder encodes a frame image with the number of channels 3 separately each time; (2) BatchNorm layer and ReLU layer are added to the last convolutional layer of the encoder, which can ensure that all feature representations finally obtained have similar distribution and ensure that subsequent incremental calculations are consistent; (3) The output of the intermediate process is retained, but only the output of the intermediate process of the fourth frame is retained, so as to help the appearance decoder rebuild the fourth frame by integrating the underlying features of the encoder with the structure of skip-connection.",
                "4 Normality Score In this paper, the PSNR is used to measure the quality of the predicted image[3-5], and the calculation formula of PSNR is shown as follows:",
                "The relationship between mf , motion\ndecoder ( )mE  , and predicted increment diagram I\u0302 generated by the incremental fusion prediction module is as follows:\n\u02c6 ( )m mI E f  (4)\nThe neural network structure of the motion decoder is as follows: In this paper, modifications are made to the decoder structure proposed by Park et al.[5], including deletion of skip-connection operation and cancellation of all operations that fuse the intermediate features of the encoder in the decoder.",
                "For continuous frame sequences 1I , 2I , 3I and 4I , the shared encoder is  sE  , and the following relation exists:\nProc. of SPIE Vol. 12454 124540D-2\n( ) 1, 2,3,4i s if E I i  (2)\nThe neural network structure of the shared encoder is as follows: In this paper, the encoder structure proposed by Park et al.[5] is modified as follows: (1) The number of input channels of the encoder is changed to 3, so that the encoder encodes a frame image with the number of channels 3 separately each time; (2) BatchNorm layer and ReLU layer are added to the last convolutional layer of the encoder, which can ensure that all feature representations finally obtained have similar distribution and ensure that subsequent incremental calculations are consistent; (3) The output of the intermediate process is retained, but only the output of the intermediate process of the fourth frame is retained, so as to help the appearance decoder rebuild the fourth frame by integrating the underlying features of the encoder with the structure of skip-connection."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "66ca7478d7752a56d296915ec289b70aaf03b847",
                "externalIds": {
                    "DOI": "10.1117/12.2659266",
                    "CorpusId": 253861053
                },
                "corpusId": 253861053,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/66ca7478d7752a56d296915ec289b70aaf03b847",
                "title": "Increment prediction for video anomaly detection",
                "abstract": "The Appearance-based and motion-based dual-stream anomaly detection algorithm uses optical flow to extract motion features in normal video, but optical flow only considers the pixel displacement relationship between two adjacent frames, while ignoring the latent semantic association of continuous changes in multi-frame images. This paper proposes an incremental prediction-based video anomaly detection algorithm (IP-VAD), which first uses an encoder to extract corresponding features of consecutive frames, and then reconstructs feature maps from appearance and motion directions, respectively. In the appearance direction, the last frame is reconstructed by the appearance decoder; in the motion direction, the feature differences of successive frames are stacked and fed into the motion decoder, which then predicts the increment of future and last frames. Finally, future frames are obtained using the reconstructed last frame and the predicted increment. During the test, the peak signal-to-noise ratio is used to measure the reconstruction quality of future frames, and the threshold is used to determine whether it is abnormal. The experimental results on the public datasets UCSD Ped2 and CUHK Avenue show that the AUC indicators of our method are improved by 1.0% and 0.2%, respectively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1810660380",
                        "name": "Xin Guo"
                    },
                    {
                        "authorId": "1735282",
                        "name": "Bai Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "17760fa651e42a5bddb774dae56b821ffe7bdd56",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-10946",
                    "ArXiv": "2211.10946",
                    "DOI": "10.48550/arXiv.2211.10946",
                    "CorpusId": 253734878
                },
                "corpusId": 253734878,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/17760fa651e42a5bddb774dae56b821ffe7bdd56",
                "title": "Normalizing Flows for Human Pose Anomaly Detection",
                "abstract": "Video anomaly detection is an ill-posed problem because it relies on many parameters such as appearance, pose, camera angle, background, and more. We distill the problem to anomaly detection of human pose, thus decreasing the risk of nuisance parameters such as appearance affecting the result. Focusing on pose alone also has the side benefit of reducing bias against distinct minority groups. Our model works directly on human pose graph sequences and is exceptionally lightweight (~1K parameters), capable of running on any machine able to run the pose estimation with negligible additional resources. We leverage the highly compact pose representation in a normalizing flows framework, which we extend to tackle the unique characteristics of spatio-temporal pose data and show its advantages in this use case. The algorithm is quite general and can handle training data of only normal examples as well as a supervised setting that consists of labeled normal and abnormal examples. We report state-of-the-art results on two anomaly detection benchmarks - the unsupervised ShanghaiTech dataset and the recent supervised UBnormal dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2151002676",
                        "name": "Or Hirschorn"
                    },
                    {
                        "authorId": "1815078",
                        "name": "S. Avidan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[17] to introduce a memory enhancement module to learn a limited number of archetypal features that can best represent normal samples, which record various normal behavior patterns and store them in memory."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "a9f42825be86d82184193d4ebcfb75c316d51a09",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-10052",
                    "ArXiv": "2211.10052",
                    "DOI": "10.48550/arXiv.2211.10052",
                    "CorpusId": 253708064
                },
                "corpusId": 253708064,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a9f42825be86d82184193d4ebcfb75c316d51a09",
                "title": "Pedestrian Spatio-Temporal Information Fusion For Video Anomaly Detection",
                "abstract": "Aiming at the problem that the current video anomaly detection cannot fully use the temporal information and ignore the diversity of normal behavior, an anomaly detection method is proposed to integrate the spatiotemporal information of pedestrians. Based on the convolutional autoencoder, the input frame is compressed and restored through the encoder and decoder. Anomaly detection is realized according to the difference between the output frame and the true value. In order to strengthen the characteristic information connection between continuous video frames, the residual temporal shift module and the residual channel attention module are introduced to improve the modeling ability of the network on temporal information and channel information, respectively. Due to the excessive generalization of convolutional neural networks, in the memory enhancement modules, the hopping connections of each codec layer are added to limit autoencoders' ability to represent abnormal frames too vigorously and improve the anomaly detection accuracy of the network. In addition, the objective function is modified by a feature discretization loss, which effectively distinguishes different normal behavior patterns. The experimental results on the CUHK Avenue and ShanghaiTech datasets show that the proposed method is superior to the current mainstream video anomaly detection methods while meeting the real-time requirements.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118130805",
                        "name": "Chao Hu"
                    },
                    {
                        "authorId": "2155728046",
                        "name": "Liqiang Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Indeed, while we learn the memory through contrastive learning, MemAE and others [21, 42] learned it via the pixel-wise reconstruction loss.",
                "Some works used memory in the latent space of an auto-encoder [21, 42] for AD.",
                "Unlike previous memory bank equipped methods [21, 42], our normal memory layers cover the normal class at multiple scales and not only improve anomaly detection but also the quality of the learned representations.",
                "Compared to previous memory bank equipped anomaly detectors [4, 21, 23, 42], our model is the first to memorize the normal class at several scales allowing it to be more robust to anomaly sizes."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "bb0c598b0306bcc862e83a997fd42131d0c292bf",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-09041",
                    "ArXiv": "2211.09041",
                    "DOI": "10.48550/arXiv.2211.09041",
                    "CorpusId": 253553273
                },
                "corpusId": 253553273,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/bb0c598b0306bcc862e83a997fd42131d0c292bf",
                "title": "Anomaly Detection via Multi-Scale Contrasted Memory",
                "abstract": "Deep anomaly detection (AD) aims to provide robust and efficient classifiers for one-class and unbalanced settings. However current AD models still struggle on edge-case normal samples and are often unable to keep high performance over different scales of anomalies. Moreover, there currently does not exist a unified framework efficiently covering both one-class and unbalanced learnings. In the light of these limitations, we introduce a new two-stage anomaly detector which memorizes during training multi-scale normal prototypes to compute an anomaly deviation score. First, we simultaneously learn representations and memory modules on multiple scales using a novel memory-augmented contrastive learning. Then, we train an anomaly distance detector on the spatial deviation maps between prototypes and observations. Our model highly improves the state-of-the-art performance on a wide range of object, style and local anomalies with up to 50% error relative improvement on CIFAR-100. It is also the first model to keep high performance across the one-class and unbalanced settings.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2094190849",
                        "name": "Loic Jezequel"
                    },
                    {
                        "authorId": "145448545",
                        "name": "Ngoc-Son Vu"
                    },
                    {
                        "authorId": "70613101",
                        "name": "Jean Beaudet"
                    },
                    {
                        "authorId": "7206550",
                        "name": "A. Histace"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Unlike MemAE [19] and LMCNet [29], we utilize a memory module with new update and query schemes in prototype branch inspired by MNAD [15] to avoid excessive restrictions on representing normal patterns.",
                "Besides, many prediction-based methods [15], [25] tend to record global normal patterns while ignoring local spatiotemporal representation.",
                "In contrast, some prediction-based methods [15], [25] overfocus on global normality.",
                "Prediction-based methods [15]\u2013[17] typically take frame sequences consisting of several consecutive frames as inputs to generate future frames.",
                "In prediction-based VAD methods [15], [17], [22], [23], [25], [35], [36], the models usually take a number of consecutive video frames as input to generate the next frame.",
                "In recent years, many reconstruction-based VAD methods have been proposed [15], [18], [19], [21], [31], [32].",
                "signed based on autoencoder [15], [18], [19].",
                "However, the powerful prediction ability also allow them to predict some anomalies instances well and cause missed detections [15].",
                "We design the prototype branch to memorize the prototype features with a memory module from whole training videos inspired by MNAD [15] and consider the prototypes as global normality.",
                "[15] devised a new memory module for VAD model to record normal prototype features, which can represent more diverse patterns than the memory module in MemAE [19]."
            ],
            "isInfluential": true,
            "intents": [
                "result",
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "83665e3366c67aade3e771825b2d886fb77e6b02",
                "externalIds": {
                    "ArXiv": "2211.07454",
                    "DBLP": "journals/corr/abs-2211-07454",
                    "DOI": "10.48550/arXiv.2211.07454",
                    "CorpusId": 253510152
                },
                "corpusId": 253510152,
                "publicationVenue": {
                    "id": "75d7a8c1-d871-42db-a8e4-7cf5146fdb62",
                    "name": "Social Science Research Network",
                    "type": "journal",
                    "alternate_names": [
                        "SSRN, Social Science Research Network (SSRN) home page",
                        "SSRN Electronic Journal",
                        "Soc Sci Res Netw",
                        "SSRN",
                        "SSRN Home Page",
                        "SSRN Electron J",
                        "Social Science Electronic Publishing presents Social Science Research Network"
                    ],
                    "issn": "1556-5068",
                    "url": "http://www.ssrn.com/",
                    "alternate_urls": [
                        "www.ssrn.com/",
                        "https://fatcat.wiki/container/tol7woxlqjeg5bmzadeg6qrg3e",
                        "https://www.wikidata.org/wiki/Q53949192",
                        "www.ssrn.com/en",
                        "http://www.ssrn.com/en/",
                        "http://umlib.nl/ssrn",
                        "umlib.nl/ssrn"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/83665e3366c67aade3e771825b2d886fb77e6b02",
                "title": "LGN-Net: Local-Global Normality Network for Video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) has been intensively studied for years because of its potential applications in intelligent video systems. Existing unsupervised VAD methods tend to learn normality from training sets consisting of only normal videos and regard instances deviating from such normality as anomalies. However, they often consider only local or global normality in the temporal dimension. Some of them focus on learning local spatiotemporal representations from consecutive frames to enhance the representation for normal events. But powerful representation allows these methods to represent some anomalies and causes miss detection. In contrast, the other methods are devoted to memorizing prototypical normal patterns of whole training videos to weaken the generalization for anomalies, which also restricts them from representing diverse normal patterns and causes false alarm. To this end, we propose a two-branch model, Local-Global Normality Network (LGN-Net), to simultaneously learn local and global normality. Specifically, one branch learns the evolution regularities of appearance and motion from consecutive frames as local normality utilizing a spatiotemporal prediction network, while the other branch memorizes prototype features of the whole videos as global normality by a memory module. LGN-Net achieves a balance of representing normal and abnormal instances by fusing local and global normality. In addition, the fused normality enables LGN-Net to generalize to various scenes more than exploiting single normality. Experiments demonstrate the effectiveness and superior performance of our method. The code is available online: https://github.com/Myzhao1999/LGN-Net.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1563747197",
                        "name": "Mengyang Zhao"
                    },
                    {
                        "authorId": "47909156",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2153467142",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "2109151723",
                        "name": "Di Li"
                    },
                    {
                        "authorId": "2149581020",
                        "name": "Xinhua Zeng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "tion [54], image colorization [55], anomaly detection [56], [57] and video-based person ReID [53]."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "476c29d6eb08b6c56f0ef89f4839489f3cc4d480",
                "externalIds": {
                    "DBLP": "journals/tip/LiZLTZW22",
                    "DOI": "10.1109/TIP.2022.3220408",
                    "CorpusId": 253457200,
                    "PubMed": "36367912"
                },
                "corpusId": 253457200,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/476c29d6eb08b6c56f0ef89f4839489f3cc4d480",
                "title": "Visible-Infrared Person Re-Identification With Modality-Specific Memory Network",
                "abstract": "Visible-infrared person re-identification (VI-ReID) is challenging due to the large modality discrepancy between visible and infrared images. Existing methods mainly focus on learning modality-shared representations by embedding images from different modalities into a common feature space, in which some discriminative modality information is discarded. Different from these methods, in this paper, we propose a novel Modality-Specific Memory Network (MSMNet) to complete the missing modality information and aggregate visible and infrared modality features into a unified feature space for the VI-ReID task. The proposed model enjoys several merits. First, it can exploit the missing modality information to alleviate the modality discrepancy when only the single-modality input is provided. To the best of our knowledge, this is the first work to exploit the missing modality information completion and alleviate the modality discrepancy with the memory network. Second, to guide the learning process of the memory network, we design three effective learning strategies, including feature consistency, memory representativeness and structural alignment. By incorporating these learning strategies in a unified model, the memory network can be well learned to propagate identity-related information between modalities and boost the VI-ReID performance. Extensive experimental results on two standard benchmarks (SYSU-MM01 and RegDB) demonstrate that the proposed MSMNet performs favorably against state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2111353973",
                        "name": "Yulin Li"
                    },
                    {
                        "authorId": "2146331327",
                        "name": "Tianzhu Zhang"
                    },
                    {
                        "authorId": "2144226573",
                        "name": "Xiang Liu"
                    },
                    {
                        "authorId": "2056267827",
                        "name": "Q. Tian"
                    },
                    {
                        "authorId": "2145050375",
                        "name": "Yongdong Zhang"
                    },
                    {
                        "authorId": "2116505227",
                        "name": "Feng Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "At test-time, reconstruction is expected to be degraded for OOD samples, allowing for their detection [4, 5]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "2fc720a64d4555a06dc7a662e4b4a110ccdd24f5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-05421",
                    "ArXiv": "2211.05421",
                    "DOI": "10.48550/arXiv.2211.05421",
                    "CorpusId": 253447125
                },
                "corpusId": 253447125,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2fc720a64d4555a06dc7a662e4b4a110ccdd24f5",
                "title": "Improving Uncertainty-based Out-of-Distribution Detection for Medical Image Segmentation",
                "abstract": "Deep Learning models are easily disturbed by variations in the input images that were not seen during training, re-sulting in unpredictable behaviours. Such Out-of-Distribution (OOD) images represent a signi\ufb01cant challenge in the context of medical image analysis, where the range of possible abnormalities is extremely wide, including artifacts, unseen pathologies, or different imaging protocols. In this work, we evaluate various uncertainty frameworks to detect OOD inputs in the context of Multiple Sclerosis lesions segmentation. By implementing a comprehensive evaluation scheme including 14 sources of OOD of various nature and strength, we show that methods relying on the predictive uncertainty of binary segmentation models often fails in detecting outlying inputs. On the contrary, learning to segment anatomical labels alongside lesions highly improves the ability to detect OOD inputs.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "153005347",
                        "name": "Benjamin Lambert"
                    },
                    {
                        "authorId": "2074707664",
                        "name": "Florence Forbes"
                    },
                    {
                        "authorId": "28614542",
                        "name": "Senan Doyle"
                    },
                    {
                        "authorId": "2309000",
                        "name": "A. Tucholka"
                    },
                    {
                        "authorId": "1699302",
                        "name": "M. Dojat"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Several VAD approaches [1, 10, 22, 27, 29, 30, 39, 46] employ Autoencoders (AEs), Generative Adversarial Nets (GANs) and their variants under the assumption that the models that are explicitly trained on normal data may not be successful to reconstruct abnormal event as such samples are usually absent in the training set."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "e7935d6944ec6ee2f7e2d5f40833300e4daa78d0",
                "externalIds": {
                    "DBLP": "conf/wacv/ThakareRDCK23",
                    "ArXiv": "2211.00882",
                    "DOI": "10.1109/WACV56688.2023.00550",
                    "CorpusId": 253254897
                },
                "corpusId": 253254897,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/e7935d6944ec6ee2f7e2d5f40833300e4daa78d0",
                "title": "DyAnNet: A Scene Dynamicity Guided Self-Trained Video Anomaly Detection Network",
                "abstract": "Unsupervised approaches for video anomaly detection may not perform as good as supervised approaches. However, learning unknown types of anomalies using an unsupervised approach is more practical than a supervised approach as annotation is an extra burden. In this paper, we use isolation tree-based unsupervised clustering to partition the deep feature space of the video segments. The RGB-stream generates a pseudo anomaly score and the flow stream generates a pseudo dynamicity score of a video segment. These scores are then fused using a majority voting scheme to generate preliminary bags of positive and negative segments. However, these bags may not be accurate as the scores are generated only using the current segment which does not represent the global behavior of a typical anomalous event. We then use a refinement strategy based on a cross-branch feed-forward network designed using a popular I3D network to refine both scores. The bags are then refined through a segment re-mapping strategy. The intuition of adding the dynamicity score of a segment with the anomaly score is to enhance the quality of the evidence. The method has been evaluated on three popular video anomaly datasets, i.e., UCF-Crime, CCTV-Fights, and UBI-Fights. Experimental results reveal that the proposed framework achieves competitive accuracy as compared to the state-of-the-art video anomaly detection methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2148657477",
                        "name": "T. K. Vijay"
                    },
                    {
                        "authorId": "2183490403",
                        "name": "Yash Raghuwanshi"
                    },
                    {
                        "authorId": "3320759",
                        "name": "D. P. Dogra"
                    },
                    {
                        "authorId": "1960214589",
                        "name": "Heeseung Choi"
                    },
                    {
                        "authorId": "2161965217",
                        "name": "Ig-Jae Kim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[9], [10] try to maintain the prototypes of the basic feature in the normal frames and reconstruct frames with them."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c8080f1bc03c52435d58193b64967ac49a07a874",
                "externalIds": {
                    "DBLP": "journals/tcsv/ZhengLLWMQL22",
                    "DOI": "10.1109/TCSVT.2022.3181452",
                    "CorpusId": 253185930
                },
                "corpusId": 253185930,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c8080f1bc03c52435d58193b64967ac49a07a874",
                "title": "Anomaly Detection of Metro Station Tracks Based on Sequential Updatable Anomaly Detection Framework",
                "abstract": "The intrusion of foreign objects in tracks, one of the sources of injuries and fatalities in metro stations, can be solved as an anomaly detection task. However, the existing anomaly detection methods rarely consider the importance of updating the new knowledge from false alarm data, resulting in repeated mistakes. These methods are also impractical for edge devices that cannot afford the high calculation cost. A sequential updatable anomaly detection (SUAD) framework is proposed to tackle these problems. This framework is based on the Robbin-Monro algorithm and a fast version of Mahalanobis distance. A well-trained model of SUAD can continue to learn new knowledge through the sequential knowledge update module based on the Robbin-Monro algorithm without reviewing the old data. SUAD utilizes a new Mahalanobis distance calculation method based on principal component analysis. This new method exhibits a fast inference speed with a lighter model size than before. SUAD is evaluated on a self-built Metro Anomaly Detection (MAD) dataset and three public datasets. SUAD achieves an average area under the receiver operating characteristic curve score of 99.4% at image level and 99.6% at pixel level on MAD. SUAD also reduces at least 78% model size and 60% memory usage. Competitive results are also achieved in public datasets, including MVTec AD, beanTech Anomaly Detection, and CIFAR-10.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2185036386",
                        "name": "Zhongxing Zheng"
                    },
                    {
                        "authorId": "1454014370",
                        "name": "Weiming Liu"
                    },
                    {
                        "authorId": "2152937144",
                        "name": "Ruikang Liu"
                    },
                    {
                        "authorId": "2185059686",
                        "name": "Liang Wang"
                    },
                    {
                        "authorId": "2184926765",
                        "name": "Liang Mao"
                    },
                    {
                        "authorId": "2184948078",
                        "name": "Qisheng Qiu"
                    },
                    {
                        "authorId": "2184838055",
                        "name": "Guangzheng Ling"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "f07f92faa25503749d089764e81aa55964bbab1a",
                "externalIds": {
                    "DBLP": "journals/tits/ZhangLXZSH22",
                    "DOI": "10.1109/TITS.2022.3174088",
                    "CorpusId": 248791263
                },
                "corpusId": 248791263,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f07f92faa25503749d089764e81aa55964bbab1a",
                "title": "Weakly Supervised Anomaly Detection in Videos Considering the Openness of Events",
                "abstract": "Although various weakly supervised anomaly detection methods have been proposed in recent years, generalization of anomaly detection is still not well-explored. Existing weakly supervised methods usually use normal and abnormal events to pose anomaly detection as a regression problem. However, defining concepts that encompass all possible normal and abnormal event patterns is nearly unrealistic, so the anomaly detection model is likely to face both open normal and abnormal events in practical applications. We find some weakly supervised anomaly detection methods suffer from performance degradation when faced with open events due to their poor generalization. To tackle this issue, we propose a two-branch weakly supervised approach, which can improve the anomaly detection performance of open events without affecting the performance of the seen events. Specifically, considering that the pattern of open events is different from that of seen events, we design a Test Data Analyzer (TDA) that determines whether the test video features belong to seen or open data and argue for separate treatment for them. For the seen data, a classifier trained by multiple instance learning is used to predict anomaly scores. For the open data, we design an anomaly detection model via meta-learning named Meta-Learning Anomaly Detection (MLAD), which can directly determine whether open data is abnormal without updating model parameters. In detail, MLAD synthesizes pseudo-seen data and pseudo-open data so that the model can learn to detect anomalies in open data by transferring the knowledge of seen data. Experimental results validate the effectiveness of our proposed method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2200061065",
                        "name": "Chen Zhang"
                    },
                    {
                        "authorId": "2143164613",
                        "name": "Guorong Li"
                    },
                    {
                        "authorId": "34679664",
                        "name": "Qianqian Xu"
                    },
                    {
                        "authorId": "2144483344",
                        "name": "Xinfeng Zhang"
                    },
                    {
                        "authorId": "153142919",
                        "name": "Li Su"
                    },
                    {
                        "authorId": "1689702",
                        "name": "Qingming Huang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "2f0bbb6cb441002909d1dc7c5a6d235d30c55c88",
                "externalIds": {
                    "ArXiv": "2301.12048",
                    "DBLP": "conf/icdm/0006QBXM022",
                    "DOI": "10.1109/ICDM54844.2022.00157",
                    "CorpusId": 256390408
                },
                "corpusId": 256390408,
                "publicationVenue": {
                    "id": "67d15a94-d523-4b5f-be58-03fe2ef9dcfb",
                    "name": "Industrial Conference on Data Mining",
                    "type": "conference",
                    "alternate_names": [
                        "Ind Conf Data Min",
                        "ICDM"
                    ],
                    "url": "http://www.data-mining-forum.de/"
                },
                "url": "https://www.semanticscholar.org/paper/2f0bbb6cb441002909d1dc7c5a6d235d30c55c88",
                "title": "Making Reconstruction-based Method Great Again for Video Anomaly Detection",
                "abstract": "Anomaly detection in videos is a significant yet challenging problem. Previous approaches based on deep neural networks employ either reconstruction-based or prediction-based approaches. Nevertheless, existing reconstruction-based methods 1) rely on old-fashioned convolutional autoencoders and are poor at modeling temporal dependency; 2) are prone to overfit the training samples, leading to indistinguishable reconstruction errors of normal and abnormal frames during the inference phase. To address such issues, firstly, we get inspiration from transformer and propose Spatio-Temporal Auto-Trans-Encoder, dubbed as STATE, as a new autoencoder model for enhanced consecutive frame reconstruction. Our STATE is equipped with a specifically designed learnable convolutional attention module for efficient temporal learning and reasoning. Secondly, we put forward a novel reconstruction-based input perturbation technique during testing to further differentiate anomalous frames. With the same perturbation magnitude, the testing reconstruction error of the normal frames lowers more than that of the abnormal frames, which contributes to mitigating the overfitting problem of reconstruction. Owing to the high relevance of the frame abnormality and the objects in the frame, we conduct object-level reconstruction using both the raw frame and the corresponding optical flow patches. Finally, the anomaly score is designed based on the combination of the raw and motion reconstruction errors using perturbed inputs. Extensive experiments on benchmark video anomaly detection datasets demonstrate that our approach outperforms previous reconstruction-based methods by a notable margin, and achieves state-of-the-art anomaly detection performance consistently. The code is available at https://github.com/wyzjack/MRMGA4VAD.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1717863",
                        "name": "Yizhou Wang"
                    },
                    {
                        "authorId": "12282768",
                        "name": "Can Qin"
                    },
                    {
                        "authorId": "153802755",
                        "name": "Yue Bai"
                    },
                    {
                        "authorId": "2143970051",
                        "name": "Yi Xu"
                    },
                    {
                        "authorId": "1663912566",
                        "name": "Xu Ma"
                    },
                    {
                        "authorId": "2156255943",
                        "name": "Yun Fu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Anomaly detection pretext tasks: Recently, deep learning approaches [8, 7, 11, 15, 14, 9, 21, 27, 23, 24, 3, 34, 32, 20, 12] have shown their effectiveness for detecting abnormal events in videos.",
                "Self-supervised methods [8, 21, 9, 20, 33, 10, 2, 16, 18, 14, 7, 27, 31, 15, 3, 32] use some pretext tasks to learn normal appearance and motion features from training data.",
                "Many previous methods used reconstruction to learn normality [8, 9, 10, 21, 20, 33, 2, 16].",
                "An extension of this approach was proposed by [21] which learns spatio-temporal patch prototypes.",
                "A widely used self-supervised approach for anomaly detection consists in reconstructing normal samples from a low dimensional representations [8, 21, 9, 20, 33, 10, 2, 16, 18]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "08485f86df52e9cf9b02394d6a3aae05aff0a799",
                "externalIds": {
                    "DBLP": "conf/avss/NajiSLGA22",
                    "ArXiv": "2210.15741",
                    "DOI": "10.1109/AVSS56176.2022.9959669",
                    "CorpusId": 253224193
                },
                "corpusId": 253224193,
                "publicationVenue": {
                    "id": "827334c9-c744-4f75-9b28-571cb89ad45f",
                    "name": "Advanced Video and Signal Based Surveillance",
                    "type": "conference",
                    "alternate_names": [
                        "AVSS",
                        "Adv Video Signal Based Surveill"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=266"
                },
                "url": "https://www.semanticscholar.org/paper/08485f86df52e9cf9b02394d6a3aae05aff0a799",
                "title": "Spatio-temporal predictive tasks for abnormal event detection in videos",
                "abstract": "Abnormal event detection in videos is a challenging problem, partly due to the multiplicity of abnormal patterns and the lack of their corresponding annotations. In this paper, we propose new constrained pretext tasks to learn object level normality patterns. Our approach consists in learning a mapping between down-scaled visual queries and their corresponding normal appearance and motion characteristics at the original resolution. The proposed tasks are more challenging than reconstruction and future frame prediction tasks which are widely used in the literature, since our model learns to jointly predict spatial and temporal features rather than reconstructing them. We believe that more constrained pretext tasks induce a better learning of normality patterns. Experiments on several benchmark datasets demonstrate the effectiveness of our approach to localize and track anomalies as it outperforms or reaches the current state-of-the-art on spatio-temporal evaluation metrics.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2158115248",
                        "name": "Yassine Naji"
                    },
                    {
                        "authorId": "2592210",
                        "name": "Aleksandr Setkov"
                    },
                    {
                        "authorId": "37995240",
                        "name": "Ang\u00e9lique Loesch"
                    },
                    {
                        "authorId": "1751461",
                        "name": "M. Gouiff\u00e8s"
                    },
                    {
                        "authorId": "2641858",
                        "name": "Romaric Audigier"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Reconstruction-based or predictionbased methods [4], [11], [25] detect anomalies based on the reconstruction error or prediction error between testing data as ground truth and representations from the normal data.",
                "[25] Proposed a memory module that can update during the detection stage.",
                "proposed the Memory networks [31], memory methods have been developed and enhanced, It has also been extensively used and exhibited effect in video abnormal event detection tasks [11], [20], [25]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3b10ee3b01a496ce87e9781b9a282cf9476f7029",
                "externalIds": {
                    "DOI": "10.1109/ICSP56322.2022.9965355",
                    "CorpusId": 254155439
                },
                "corpusId": 254155439,
                "publicationVenue": {
                    "id": "63410070-a9b9-46ac-bdec-92b016246795",
                    "name": "International Conference on the Software Process",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Signal Process",
                        "ICSP",
                        "Int Conf Softw Process",
                        "International Conference on Signal Processing"
                    ],
                    "url": "http://www.ece.utexas.edu/~perry/prof/ispa/index.html"
                },
                "url": "https://www.semanticscholar.org/paper/3b10ee3b01a496ce87e9781b9a282cf9476f7029",
                "title": "A Video Abnormal Detection Framework based on Appearance-Motion Fuse Memory",
                "abstract": "Abnormal events are usually considered extraneous event deviation from standard events. Context and Movement mode play a pivotal part in determining abnormal events. Due to the forms being unbounded and ambiguous, it is impossible to straight fitting abnormal. Based on this requirement, following a recent series of methods, we used an object detector, followed by abnormal detection at the object level. This paper proposes a brand new video abnormal detection approach. By occupying Appearance-Motion Fuse Memory (AMFM), the new pattern will utilize the appearance message and motion representation. The Spatio-temporal model uses a two-stream encoder. The two streams of input refer to several preceding video frames and their corresponding optical flow data. In the course of training, the two-stream encoder takes the role of extracting the superficial and moving features by the merely normal entities. We discover that a design like this two-stream encoder has the ability to commit the characteristics of normal samples to memory. Experimental results on the commonly used ShanghaiTech dataset and UCSD PED2 dataset verified that our model achieves competitive performance. While we conduct ablation studies to prove the validity of the components constructed in our model.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2193462991",
                        "name": "Yinshuo Sun"
                    },
                    {
                        "authorId": "2053996345",
                        "name": "Tao Cui"
                    },
                    {
                        "authorId": "2896701",
                        "name": "Gaoyun An"
                    },
                    {
                        "authorId": "144695333",
                        "name": "Q. Ruan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, the reconstruction quality of autoencoder is unstable in practice since autoencoder has strong generalization ability and the anomalous regions cannot be eliminated in the reconstructed image [8]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "0e1f9a57a09d85fedcf587615745834e8591bab3",
                "externalIds": {
                    "DBLP": "conf/csae/JingZZ22",
                    "DOI": "10.1145/3565387.3565431",
                    "CorpusId": 254592309
                },
                "corpusId": 254592309,
                "publicationVenue": {
                    "id": "047958df-6384-459e-9864-63f946419551",
                    "name": "International Conference on Computer Science and Application Engineering",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Comput Sci Appl Eng",
                        "IEEE International Conference on Computer Science and Automation Engineering",
                        "IEEE Int Conf Comput Sci Autom Eng",
                        "CSAE"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0e1f9a57a09d85fedcf587615745834e8591bab3",
                "title": "Foreign Object Debris Detection Based on Gaussian Mixture Autoencoder of Pre-trained Features",
                "abstract": "In this study, a novel anomaly localization method called Gaussian Mixture Autoencoder of Pre-trained Features (GMAPF) is proposed to perform foreign object debris (FOD) detection in the field of aviation. GMAPF utilizes the pre-trained deep convolutional neural network to establish multi-hierarchical feature representations, which are then fed into the deep autoencoder for dimensionality reduction and learning of low-dimensional embedding for each pixel of an image. The distribution of the normal pixel embedding is then modeled by Gaussian mixture model (GMM). Besides, instead of Expectation-Maximization (EM), GMAPF leverages a multi-layer perceptron to learn the parameters of GMM. Therefore, GMAPF could simultaneously optimize the parameters of the deep autoencoder and GMM in an end-to-end way. Many experiments are done on a newly collected dataset FOD, and the experimental results demonstrate the validity of GMAPF.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2069093267",
                        "name": "Ying Jing"
                    },
                    {
                        "authorId": "2221771297",
                        "name": "Hong Zheng"
                    },
                    {
                        "authorId": "2152934521",
                        "name": "Wentao Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As such, AE has been widely applied for anomaly detection in various areas [46, 47, 48, 49].",
                "Due to the powerful representation capability of DNN, the AE trained by normal signals with diverse patterns tends to generalize well and may reconstruct abnormal signals with small errors [46, 47].",
                "1(a), the MadeGAN is designed by integrating semi-supervised learning based on memory-augmented deep auto-encoder (MemAE) [46, 47] with adversarial training, which will be detailed in the following subsections.",
                "To mitigate the drawback of traditional AEs, we leverage a memory module to recognize the diversity of normal patterns and reduce the generalizability of AE to abnormal signals as inspired by the work from [46, 47]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0a585461a9682e63f80d0ae0dde64e312c3d8efa",
                "externalIds": {
                    "DBLP": "journals/cbm/WangSY23",
                    "ArXiv": "2210.11408",
                    "DOI": "10.48550/arXiv.2210.11408",
                    "CorpusId": 253018446,
                    "PubMed": "36773553"
                },
                "corpusId": 253018446,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0a585461a9682e63f80d0ae0dde64e312c3d8efa",
                "title": "Hierarchical Deep Learning with Generative Adversarial Network for Automatic Cardiac Diagnosis from ECG Signals",
                "abstract": "Cardiac disease is the leading cause of death in the US. Accurate heart disease detection is critical to timely medical treatment to save patients' lives. Routine use of the electrocardiogram (ECG) is the most common method for physicians to assess the cardiac electrical activities and detect possible abnormal conditions. Fully utilizing the ECG data for reliable heart disease detection depends on developing effective analytical models. In this paper, we propose a two-level hierarchical deep learning framework with Generative Adversarial Network (GAN) for ECG signal analysis. The first-level model is composed of a Memory-Augmented Deep AutoEncoder with GAN (MadeGAN), which aims to differentiate abnormal signals from normal ECGs for anomaly detection. The second-level learning aims at robust multi-class classification for different arrhythmia identification, which is achieved by integrating the transfer learning technique to transfer knowledge from the first-level learning with the multi-branching architecture to handle the data-lacking and imbalanced data issues. We evaluate the performance of the proposed framework using real-world ECG data from the MIT-BIH arrhythmia database. Experimental results show that our proposed model outperforms existing methods that are commonly used in current practice.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1999172002",
                        "name": "Zekai Wang"
                    },
                    {
                        "authorId": "2164609796",
                        "name": "S. Stavrakis"
                    },
                    {
                        "authorId": "47713732",
                        "name": "B. Yao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Examples of such methods include AE-SSIM [27], MemAE [18], MGNAD [19], and DAAD [28], which mainly employ image reconstruction techniques.",
                "To prevent the recovery of abnormal images, some studies [18], [19], [28], [32] introduce memory modules that store normal features."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3198dd7e8cdb182564f2b5fc7a72c76307f3ee1c",
                "externalIds": {
                    "ArXiv": "2210.10495",
                    "CorpusId": 260115116
                },
                "corpusId": 260115116,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3198dd7e8cdb182564f2b5fc7a72c76307f3ee1c",
                "title": "ADPS: Asymmetric Distillation Post-Segmentation for Image Anomaly Detection",
                "abstract": "Knowledge Distillation-based Anomaly Detection (KDAD) methods rely on the teacher-student paradigm to detect and segment anomalous regions by contrasting the unique features extracted by both networks. However, existing KDAD methods suffer from two main limitations: 1) the student network can effortlessly replicate the teacher network's representations, and 2) the features of the teacher network serve solely as a ``reference standard\"and are not fully leveraged. Toward this end, we depart from the established paradigm and instead propose an innovative approach called Asymmetric Distillation Post-Segmentation (ADPS). Our ADPS employs an asymmetric distillation paradigm that takes distinct forms of the same image as the input of the teacher-student networks, driving the student network to learn discriminating representations for anomalous regions. Meanwhile, a customized Weight Mask Block (WMB) is proposed to generate a coarse anomaly localization mask that transfers the distilled knowledge acquired from the asymmetric paradigm to the teacher network. Equipped with WMB, the proposed Post-Segmentation Module (PSM) is able to effectively detect and segment abnormal regions with fine structures and clear boundaries. Experimental results demonstrate that the proposed ADPS outperforms the state-of-the-art methods in detecting and segmenting anomalies. Surprisingly, ADPS significantly improves Average Precision (AP) metric by 9% and 20% on the MVTec AD and KolektorSDD2 datasets, respectively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2186112803",
                        "name": "Peng Xing"
                    },
                    {
                        "authorId": "2112389443",
                        "name": "Hao Tang"
                    },
                    {
                        "authorId": "2152930463",
                        "name": "Jinhui Tang"
                    },
                    {
                        "authorId": "3233021",
                        "name": "Zechao Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "It is more likely to avoid confusion over abnormal samples with plain representations [8]; ii) reconstruct-based: Reconstruct methods can be divided into AE-baesd [2, 10, 11] and GAN-based [9, 12, 13]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "51d6dd873e1894c1befc51a612377b4d88e32697",
                "externalIds": {
                    "DBLP": "conf/icip/ZhuangZXM022",
                    "DOI": "10.1109/ICIP46576.2022.9897566",
                    "CorpusId": 253345904
                },
                "corpusId": 253345904,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/51d6dd873e1894c1befc51a612377b4d88e32697",
                "title": "PGTNet: Prototype Guided Transfer Network for Few-Shot Anomaly Localization",
                "abstract": "Anomaly localization is pixel-level regions detection in the image. The challenge is how to generate accurate representations of the novel anomaly types which are multifarious. Besides, the anomaly sample size is often not enough to support model learning to detection because of the limitations of real conditions. In this work, we present a novel few-shot setting for anomaly detection and reorganize the defective datasets. Based on the few-shot learning, we transfer the idea of metric learning and propose the prototype-guided transfer network (PGTNet). Extensive experiment results suggest that PGT-Net outperforms current SOTA methods and provides a novel perspective for the anomaly localization task.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2149928368",
                        "name": "Zisong Zhuang"
                    },
                    {
                        "authorId": "2144181836",
                        "name": "Junhang Zhang"
                    },
                    {
                        "authorId": "2110506578",
                        "name": "Luwei Xiao"
                    },
                    {
                        "authorId": "1805932704",
                        "name": "Tianlong Ma"
                    },
                    {
                        "authorId": "2112480606",
                        "name": "Liang He"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "21dc7af5d2a3416e49bb44d6714e2fea8feef1c0",
                "externalIds": {
                    "DBLP": "conf/icip/TianLYLYD22",
                    "DOI": "10.1109/ICIP46576.2022.9897321",
                    "CorpusId": 253323398
                },
                "corpusId": 253323398,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/21dc7af5d2a3416e49bb44d6714e2fea8feef1c0",
                "title": "PPT: Anomaly Detection Dataset of Printed Products with Templates",
                "abstract": "Visual anomaly detection has been an active topic in industrial applications. In particular, it aims to classify anomalies and precisely locate defective areas in the printed products. To the best of our knowledge, there is no anomaly detection dataset for industrial printings. In this paper, we are the first to introduce a Printed Products with Templates (PPT) dataset, which contains large templates and sliced images collected from industry scene images. PPT is a challenging dataset with more variable surface defects and more disturbing background than existing related benchmarks. Furthermore, we propose a template matching method for anomaly detection of printed products, which consists of a fast template matching block with a convolutional operation using the test sliced image as its kernel, and a prediction network for generating an anomaly map of the test sliced image. Experimental results show that our method achieves state-of-the-art performance compared to the related anomaly detection approaches.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2069987631",
                        "name": "Huang Tian"
                    },
                    {
                        "authorId": "2144439048",
                        "name": "Xiang Li"
                    },
                    {
                        "authorId": "2146416206",
                        "name": "Lingfeng Yang"
                    },
                    {
                        "authorId": "46276037",
                        "name": "Jun Yu Li"
                    },
                    {
                        "authorId": "2146236917",
                        "name": "Jian Yang"
                    },
                    {
                        "authorId": "2189754097",
                        "name": "Weidong Du"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "2c4194837fa408b63d52599b2b98f19b76ce6a67",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-07697",
                    "ArXiv": "2210.07697",
                    "DOI": "10.1109/CVPRW59228.2023.00290",
                    "CorpusId": 252907614
                },
                "corpusId": 252907614,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2c4194837fa408b63d52599b2b98f19b76ce6a67",
                "title": "Multi-Task Learning based Video Anomaly Detection with Attention",
                "abstract": "Multi-task learning based video anomaly detection methods combine multiple proxy tasks in different branches to detect video anomalies in different situations. Most existing methods suffer from one of these shortcomings: I) Combination of proxy tasks in their methods is not in a complementary and explainable way. II) Class of the object is not effectively considered. III) All motion anomaly cases are not covered. IV) Context information is not engaged in anomaly detection. To address these shortcomings, we propose a novel multi-task learning based method that combines complementary proxy tasks to better consider the motion and appearance features. In one branch, motivated by the abilities of the semantic segmentation and future frame prediction tasks, we combine them into a novel task of future semantic segmentation prediction to learn normal object classes and consistent motion patterns, and to detect respective anomalies simultaneously. In the second branch, we leverage optical flow magnitude estimation for motion anomaly detection and we propose an attention mechanism to engage context information in normal motion modeling and to detect motion anomalies with attention to object parts, the direction of motion, and the distance of the objects from the camera. Our qualitative results show that the proposed method considers the object class effectively and learns motion with attention to the aforementioned determinant factors which results in precise motion modeling and better motion anomaly detection. Additionally, quantitative results show the superiority of our method compared with state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2093641084",
                        "name": "M. Baradaran"
                    },
                    {
                        "authorId": "2145950",
                        "name": "R. Bergevin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For comparison, we apply MNAD-P w/o Mem [30] as our baseline to learn the semantic pool for video anomaly prediction and obtain the results of 71.3% on UCSD Ped2 [18] and 67.5% on CUHK Avenue [24].",
                "For comparison, we apply MNAD-P w/o Mem [30] as our baseline to learn the semantic pool for video anomaly prediction and obtain the results of 71.",
                "Although our simple anomaly detection model is outperformed by MNAD-P on CUHK Avenue [24] and some other methods on UCSD Ped2 [18] in video anomaly detection, such methods use a few additional modules, such as 3D CNNs, memory guiders, optical flow estimators, or some other constraints, which lead to more training time and computational cost, while ours just consists of our CSE and a simple decoder.",
                "Table 1: Quantitative comparison with the state of the art for anomaly detection and MNAD-P w/o Mem [30] for anomaly prediction.",
                "Compared to theMNAD-P w/o Mem [30], our method achieves better performance by replacing the encoder with the proposed CSE.",
                "\u2022 We also combine the proposed CSE and a simple decoder as an AE, similar to MNAD-P w/o Mem [30], to detect anomalies, which exhibits strong competitiveness with low complexity and small computational cost.",
                "Taking advantage of the unpredictable characteristics of abnormal frames, prediction-based methods [3, 17, 21, 25, 30] are proposed, which first use the previous frames to predict the current frame, and then calculate the prediction error to quantify the extent of abnormalities of the current frame.",
                "[30] employed a different update strategy and presented a more compact memory considering the diversity of normal patterns.",
                "In addition, we also give the results of the video anomaly detection task through the channel-selected shift encoder (CSE) and decoder, similar toMNAD-Pw/oMem [30].",
                "Note that EPAP-Netv0 is our baseline, MNAD-P w/o Mem [30].",
                "Figure 8: What is video anomaly prediction? Existing methods like MNAD-P [30] can only detect anomalies in the frame 174 or 561, but our EPAP-Net can make a judgment on the future frame 175 or 562, which has not happened yet."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "49b6d465be011c71ae9074ba51afe33313636a63",
                "externalIds": {
                    "DBLP": "conf/mm/LengT0LX22",
                    "DOI": "10.1145/3503161.3548000",
                    "CorpusId": 252782267
                },
                "corpusId": 252782267,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/49b6d465be011c71ae9074ba51afe33313636a63",
                "title": "Anomaly Warning: Learning and Memorizing Future Semantic Patterns for Unsupervised Ex-ante Potential Anomaly Prediction",
                "abstract": "Existing video anomaly detection methods typically utilize reconstruction or prediction error to detect anomalies in the current frame. However, these methods cannot predict ex-ante potential anomalies in future frames, which is imperative in real scenes. Inspired by the ex-ante prediction ability of humans, we propose an unsupervised Ex-ante Potential Anomaly Prediction Network (EPAP-Net), which learns to build a semantic pool to memorize the normal semantic patterns of future frames for indirect anomaly prediction. At the training time, the memorized patterns are encouraged to be discriminated through our Semantic Pool Building Module (SPBM) with the novel padding and updating strategies. Moreover, we present a novel Semantic Similarity Loss (SSLoss) at the feature level to maximize the semantic consistency of memorized items and corresponding future frames. Specially, to enhance the value of our work, we design a Multiple Frames Prediction module (MFP) to achieve anomaly prediction in future multiple frames. At the test time, we utilize the trained semantic pool instead of ground truth to evaluate the anomalies of future frames. Besides, to obtain better feature representations for our task, we introduce a novel Channel-selected Shift Encoder (CSE), which shifts channels along the temporal dimension between the input frames to capture motion information without generating redundant features. Experimental results demonstrate that the proposed EPAP-Net can effectively predict the potential anomalies in future frames and exhibit superior or competitive performance on video anomaly detection.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40939264",
                        "name": "Jiaxu Leng"
                    },
                    {
                        "authorId": "2187309458",
                        "name": "Mingpi Tan"
                    },
                    {
                        "authorId": "2164214077",
                        "name": "Xinbo Gao"
                    },
                    {
                        "authorId": "145440137",
                        "name": "Wen Lu"
                    },
                    {
                        "authorId": "1997053",
                        "name": "Zongyi Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[36] imitated and improved the memory module, which can be updated in both training and testing phases, and introduced a compactness loss and a separateness loss to make the stored memory items more sparse and robust.",
                "Compared to previous methods [1, 12, 36] which memorize the features of the whole video frame, RCM-MemAE makes the stored prototypes more compact and also improves the separability between prototypes.",
                "Among them, MPPCA [21], MDT [34] are handcrafted feature-basedmethods; Conv-AE [16], ConvLSTM-AE [30], MemAE [12], Cluster-AE [4] and MNAD-R [36] are reconstruction-based methods; Frame-Pred [27], Attention-Prediction [53], MNAD-P [36], AMMC-Net [1] and VEC [45] are prediction-based methods; Table 1: Frame-level video anomaly detection comparison",
                "Memory augmented networks are now widely used in many video analysis tasks, such as video summarization [23], video prediction [22] and video anomaly detection [12, 36].",
                "Among them, MPPCA [21], MDT [34] are handcrafted feature-basedmethods; Conv-AE [16], ConvLSTM-AE [30], MemAE [12], Cluster-AE [4] and MNAD-R [36] are reconstruction-based methods; Frame-Pred [27], Attention-Prediction [53], MNAD-P [36], AMMC-Net [1] and VEC [45] are prediction-based methods;\nST-CAE [50], Reconstruction&Prediction[40] and AnoPCN [44] are hybrid methods.",
                "There are other works [18, 36, 45] that have verified that prediction-based methods yield to better anomaly detection performance than reconstruction methods when analyzing moving objects.",
                "HSNBM also shows superior results compared to other methods that incorporate memory modules [1, 12, 36], because HSNBM considers more local characteristics of the scene when storing memory prototypes, while adding more dimensional information to the scene normality pattern through region segmentation.",
                "To overcome this problem, memory-enhanced autoencoder (MemAE) carrying memory bank has been proposed [1, 12, 36] to improve the model\u2019s ability to discriminate abnormal frames during inference by storing the patterns extracted from normal frames.",
                "Following the popular evaluation settings in the video anomaly detection community [8, 11, 17, 27, 32, 36], we report the area under the receiver operating characteristics curve (AUC) to evaluate the performance of the proposed framework.",
                "At present, many methods [28, 36] will insert one or more memory modules into the bottleneck of the autoencoder to form a memory autoencoder (MemAE) to reduce the representation ability of the network."
            ],
            "isInfluential": true,
            "intents": [
                "result",
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0c9add302abbc4efc853fd6766fdf0bb40c91e2b",
                "externalIds": {
                    "DBLP": "conf/mm/BaoLLJL022",
                    "DOI": "10.1145/3503161.3548199",
                    "CorpusId": 252782329
                },
                "corpusId": 252782329,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0c9add302abbc4efc853fd6766fdf0bb40c91e2b",
                "title": "Hierarchical Scene Normality-Binding Modeling for Anomaly Detection in Surveillance Videos",
                "abstract": "Anomaly detection in surveillance videos is an important topic in the multimedia community, which requires efficient scene context extraction and the capture of temporal information as a basis for decision. From the perspective of hierarchical modeling, we parse the surveillance scene from global to local and propose a Hierarchical Scene Normality-Binding Modeling framework (HSNBM) to handle anomaly detection. For the static background hierarchy, we design a Region Clustering-driven Multi-task Memory Autoencoder (RCM-MemAE), which can simultaneously perform region segmentation and scene reconstruction. The normal prototypes of each local region are stored, and the frame reconstruction error is subsequently amplified by global memory augmentation. For the dynamic foreground object hierarchy, we employ a Scene-Object Binding Frame Prediction module (SOB-FP) to bind all foreground objects in the frame with the prototypes stored in the background hierarchy according their positions, thus fully exploit the normality relationship between foreground and background. The bound features are then fed into the decoder to predict the future movement of the objects. With the binding mechanism between foreground and background, HSNBM effectively integrates the \"reconstruction\" and \"prediction\" tasks and builds a semantic bridge between the two hierarchies. Finally, HSNBM fuses the anomaly scores of the two hierarchies to make a comprehensive decision. Extensive empirical studies on three standard video anomaly detection datasets demonstrate the effectiveness of the proposed HSNBM framework.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2134728243",
                        "name": "Qianyue Bao"
                    },
                    {
                        "authorId": "70448703",
                        "name": "F. Liu"
                    },
                    {
                        "authorId": "2152797300",
                        "name": "Yang Liu"
                    },
                    {
                        "authorId": "2143819911",
                        "name": "Licheng Jiao"
                    },
                    {
                        "authorId": "2110952179",
                        "name": "Xu Liu"
                    },
                    {
                        "authorId": "47681424",
                        "name": "Lingling Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The majority of existing methods [7, 23, 26, 29, 32, 34, 35, 38] rely on pixel-based features that are learned from complete frames, image patches, or regions of interest.",
                "To address thia issue, several works [8, 23, 26] introduced a memory module into deep AE.",
                "Compared with the pixel-based models Frame Pred [16], CT-D2GAN [7], AnoPCN [34], CAC [32], MNAD [26], F2PN [21] andAMMC-Net [2], our STGformer obtains significant performance improvements, since our model can reduce the negative influences of background noises.",
                "Among them, Frame Pred [16], CT-D2GAN [7], AnoPCN [34], CAC [32], MNAD [26], F2PN [21] and AMMC-Net [2] are pixelbased methods; while MPED-RNN [25], ST-GCAE [24], MTS [28], PoseCVAE [12], Normal Graph [20], HSTGCNN [39] andMoPRL [37] are pose-based models."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0cbe5e313b344e7391cc3ef2f20ade3e3e4c881a",
                "externalIds": {
                    "DBLP": "conf/mm/0001L0000W22",
                    "DOI": "10.1145/3503161.3548369",
                    "CorpusId": 252782894
                },
                "corpusId": 252782894,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0cbe5e313b344e7391cc3ef2f20ade3e3e4c881a",
                "title": "Hierarchical Graph Embedded Pose Regularity Learning via Spatio-Temporal Transformer for Abnormal Behavior Detection",
                "abstract": "Abnormal behavior detection in surveillance video is a fundamental task in modern public security. Different from typical pixel-based solutions, pose-based approaches leverage low-dimensional and strongly-structured skeleton feature, which enables the anomaly detector to be immune to complex background noise and obtain higher efficiency. However, existing pose-based methods only utilize the pose of each individual independently while ignore the important interactions between individuals. In this paper, we present a hierarchical graph embedded pose regularity learning framework via spatio-temporal transformer, which leverages the strength of graph representation in encoding strongly-structured skeleton feature. Specifically, skeleton feature is encoded as the hierarchical graph representation, which jointly models the interactions among multiple individuals and the correlations among body joints within the same individual. Furthermore, a novel task-specific spatial-temporal graph transformer is designed to encode the hierarchical spatio-temporal graph embeddings of human skeletons and learn the regular patterns within normal training videos. Experimental results indicate that our method obtains superior performance over state-of-the-art methods on several challenging datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2110928189",
                        "name": "Chao Huang"
                    },
                    {
                        "authorId": "2187561557",
                        "name": "Yabo Liu"
                    },
                    {
                        "authorId": "38448016",
                        "name": "Zheng Zhang"
                    },
                    {
                        "authorId": "2155880965",
                        "name": "Chengliang Liu"
                    },
                    {
                        "authorId": "144888860",
                        "name": "Jie Wen"
                    },
                    {
                        "authorId": "2146648728",
                        "name": "Yong Xu"
                    },
                    {
                        "authorId": "2187446521",
                        "name": "Yaowei Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Consequently, they often capture insufficient high-level semantic features, which hinders them from discriminating abnormal events [22, 51, 68].",
                "To improve the quality and discriminative power of low-level learning, various networks or techniques have been explored such as convolutional auto-encoder [24], U-Net [37], adversarial learning [21, 57, 74], memory module [22, 39, 51], foreground localization [73, 80] and transformer [18]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "22349e53dc9b7a0f6c1563db06577e8d1fee41d9",
                "externalIds": {
                    "DBLP": "conf/mm/YuWCLW22",
                    "DOI": "10.1145/3503161.3547944",
                    "CorpusId": 252782916
                },
                "corpusId": 252782916,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/22349e53dc9b7a0f6c1563db06577e8d1fee41d9",
                "title": "Effective Video Abnormal Event Detection by Learning A Consistency-Aware High-Level Feature Extractor",
                "abstract": "With pure normal training videos, video abnormal event detection (VAD) aims to build a normality model, and then detect abnormal events that deviate from this model. Despite of some progress, existing VAD methods typically train the normality model by a low-level learning objective (e.g. pixel-wise reconstruction/prediction), which often overlooks the high-level semantics in videos. To better exploit high-level semantics for VAD, we propose a novel paradigm that performs VAD by learning a Consistency-Aware high-level Feature Extractor (CAFE). Specifically, with a pre-trained deep neural network (DNN) as teacher network, we first feed raw video events into the teacher network and extract the outputs of multiple hidden layers as their high-level features, which contain rich high-level semantics. Guided by high-level features extracted from normal training videos, we train a student network to be the high-level feature extractor of normal events, so as to explicitly consider high-level semantics in training. For inference, a video event can be viewed as normal if the student extractor produces similar high-level features to the teacher network. Second, based on the fact that consecutive video frames usually enjoy minor differences, we propose a consistency-aware scheme that requires high-level features extracted from neighboring frames to be consistent. Our consistency-aware scheme not only encourages the student extractor to ignore low-level differences and capture more high-level semantics, but also enables better anomaly scoring. Last, we also design a generic framework that can bridge high-level and low-level learning in VAD to further ameliorate VAD performance. By flexibly embedding one or more low-level learning objectives into CAFE, the framework makes it possible to combine the strengths of both high-level and low-level learning. The proposed method attains state-of-the-art results on commonly-used benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2116615990",
                        "name": "Guang Yu"
                    },
                    {
                        "authorId": "2143244326",
                        "name": "Siqi Wang"
                    },
                    {
                        "authorId": "143942560",
                        "name": "Zhiping Cai"
                    },
                    {
                        "authorId": "2130021053",
                        "name": "Xinwang Liu"
                    },
                    {
                        "authorId": "2151103182",
                        "name": "Cheng-Feng Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "7eac922309a7f562a3012595e86b28529859ca33",
                "externalIds": {
                    "DBLP": "conf/mm/SunJW22",
                    "DOI": "10.1145/3503161.3548091",
                    "CorpusId": 252782205
                },
                "corpusId": 252782205,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7eac922309a7f562a3012595e86b28529859ca33",
                "title": "Evidential Reasoning for Video Anomaly Detection",
                "abstract": "Video anomaly detection aims to discriminate events that deviate from normal patterns in a video. Modeling the decision boundaries of anomalies is challenging, due to the uncertainty in the probability of deviating from normal patterns. In this paper, we propose a deep evidential reasoning method that explicitly learns the uncertainty to model the boundaries. Our method encodes various visual cues as evidences representing potential deviations, assigns beliefs to the predicted probability of deviating from normal patterns based on the evidences, and estimates the uncertainty from the remained beliefs to model the boundaries. To do this, we build a deep evidential reasoning network to encode evidence vectors and estimate uncertainty by learning evidence distributions and deriving beliefs from the distributions. We introduce an unsupervised strategy to train our network by minimizing an energy function of the deep Gaussian mixed model (GMM). Experimental results show that our uncertainty score is beneficial for modeling the boundaries of video anomalies on three benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "41172535",
                        "name": "Che Sun"
                    },
                    {
                        "authorId": "7415267",
                        "name": "Yunde Jia"
                    },
                    {
                        "authorId": "150352923",
                        "name": "Yuwei Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These approaches hold the hypothesis that anomalous regions are hard to be reconstructed since the model trained on normal samples only [3, 12, 27, 39, 40, 50]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "44c37b0892c3c16824bddcde10072e7c89f8e84c",
                "externalIds": {
                    "DBLP": "conf/mm/LiZWXGLWZ22",
                    "DOI": "10.1145/3503161.3548232",
                    "CorpusId": 252782604
                },
                "corpusId": 252782604,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/44c37b0892c3c16824bddcde10072e7c89f8e84c",
                "title": "Towards Continual Adaptation in Industrial Anomaly Detection",
                "abstract": "Anomaly detection (AD) has gained widespread attention due to its ability to identify defects in industrial scenarios using only normal samples. Although traditional AD methods achieved acceptable performance, they mainly focus on the current set of examples solely, leading to catastrophic forgetting of previously learned tasks when trained on a new one. Due to the limitation of flexibility and the requirements of realistic industrial scenarios, it is urgent to enhance the ability of continual adaptation of AD models. Therefore, this paper proposes a unified framework by incorporating continual learning (CL) to achieve our newly designed task of continual anomaly detection (CAD). Note that, we observe that data augmentation strategy can make AD methods well adapted to supervised CL (SCL) via constructing anomaly samples. Based on this, we hence propose a novel method named Distribution of Normal Embeddings (DNE), which utilizes the feature distribution of normal training samples from past tasks. It not only effectively alleviates catastrophic forgetting in CAD but also can be integrated with SCL methods to further improve their performance. Extensive experiments and visualization results on the popular benchmark dataset MVTec AD, have demonstrated advanced performance and the excellent continual adaption ability of our proposed method compared to other AD methods. To the best of our knowledge, we are the first to introduce and tackle the task of CAD. We believe that the proposed task and benchmark will be beneficial to the field of AD. Our code is available in thesupplementary material.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2155415351",
                        "name": "Wu-Jun Li"
                    },
                    {
                        "authorId": "14895949",
                        "name": "Jiawei Zhan"
                    },
                    {
                        "authorId": "49606486",
                        "name": "Jinbao Wang"
                    },
                    {
                        "authorId": "2313422",
                        "name": "Bizhong Xia"
                    },
                    {
                        "authorId": "2226422",
                        "name": "Bin-Bin Gao"
                    },
                    {
                        "authorId": "9756930",
                        "name": "Jun Liu"
                    },
                    {
                        "authorId": "1978245",
                        "name": "Chengjie Wang"
                    },
                    {
                        "authorId": "2057491839",
                        "name": "Feng Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following [26, 29, 40], a prototype diversity loss is defined to ensure the diversity of learned prototypes",
                "Similar to [26, 29], we adopt two memory learning losses, i."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "4c98fa39eb8a50db4afcef15f68f150194e3c6e6",
                "externalIds": {
                    "DBLP": "conf/mm/00080ZW0J022",
                    "DOI": "10.1145/3503161.3548082",
                    "CorpusId": 252782867
                },
                "corpusId": 252782867,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4c98fa39eb8a50db4afcef15f68f150194e3c6e6",
                "title": "Pixel-Level Anomaly Detection via Uncertainty-aware Prototypical Transformer",
                "abstract": "Pixel-level visual anomaly detection, which aims to recognize the abnormal areas from images, plays an important role in industrial fault detection and medical diagnosis. However, it is a challenging task due to the following reasons: i) the large variation of anomalies; and ii) the ambiguous boundary between anomalies and their normal surroundings. In this work, we present an uncertainty-aware prototypical transformer (UPformer), which takes into account both the diversity and uncertainty of anomaly to achieve accurate pixel-level visual anomaly detection. To this end, we first design a memory-guided prototype learning transformer encoder to learn and memorize the prototypical representations of anomalies for enabling the model to capture the diversity of anomalies. Additionally, an anomaly detection uncertainty quantizer is designed to learn the distributions of anomaly detection for measuring the anomaly detection uncertainty. Furthermore, an uncertainty-aware transformer decoder is proposed to leverage the detection uncertainties to guide the model to focus on the uncertain areas and generate the final detection results. As a result, our method achieves more accurate anomaly detection by combining the benefits of prototype learning and uncertainty estimation. Experimental results on five datasets indicate that our method achieves state-of-the-art anomaly detection performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2110928189",
                        "name": "Chao Huang"
                    },
                    {
                        "authorId": "2155880965",
                        "name": "Chengliang Liu"
                    },
                    {
                        "authorId": "38448016",
                        "name": "Zheng Zhang"
                    },
                    {
                        "authorId": "2146252912",
                        "name": "Zhihao Wu"
                    },
                    {
                        "authorId": "144888860",
                        "name": "Jie Wen"
                    },
                    {
                        "authorId": "3318404",
                        "name": "Qiuping Jiang"
                    },
                    {
                        "authorId": "2146648728",
                        "name": "Yong Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The backbone of our framework is a U-Net model [25], from which we remove the ReLU activation functions of the encoder and decoder since they restrict the partial feature representation [14].",
                "The reconstruction method assumes that the reconstruction errors in anomalous regions are significant, so some researchers suggest using memory to limit the reconstruction effect of abnormal areas [13] [14] [16].",
                "This issue can be addressed by recently introduced memory reconstruction strategies, including Learning Memory-guided Normality for Anomaly Detection (MNAD) [14] and Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection (MemAE) [16].",
                "Inspired by the MNAD reconstruction method [14], Our approach adds an encoder II to the network structure, retaining skip connections and batch normalization of per-layer convolution, while employing a novel memory update policy.",
                "This paper defines a joint loss function comprising three losses [14]: reconstruction, feature compactness and feature separation loss, denoted as Lrec, Lcomp, and Lsepa, respectively, where \u03b1 and \u03b2 adjust the balance of the loss function, as follows:"
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a2f1da91e928ec3e0d0b515eb5336430b9a15296",
                "externalIds": {
                    "DBLP": "conf/smc/WuRST22",
                    "DOI": "10.1109/SMC53654.2022.9945141",
                    "CorpusId": 253630722
                },
                "corpusId": 253630722,
                "publicationVenue": {
                    "id": "e84bb5a1-8f79-42cc-8eb1-3a52f7c73d63",
                    "name": "IEEE International Conference on Systems, Man and Cybernetics",
                    "type": "conference",
                    "alternate_names": [
                        "Smoky Mountains Computational Sciences and Engineering Conference",
                        "Smoky Mt Comput Sci Eng Conf",
                        "IEEE Int Conf Syst Man Cybern",
                        "SMC",
                        "Syst Man Cybern",
                        "Systems, Man and Cybernetics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a2f1da91e928ec3e0d0b515eb5336430b9a15296",
                "title": "Memory Reconstruction Based Dual Encoders for Anomaly Detection",
                "abstract": "Anomaly detection technology relying on memory reconstruction leverages the difference in reconstruction errors between the normal and abnormal frames to achieve superior detection performance. However, there are still some challenges with this technology. First, the memory has insufficient representation capacity for features. Second, there is a contradiction between feature fusion and reconstruction. As feature fusion copies the abnormal patterns into the reconstructed frames, the abnormal frames are effectively reconstructed, reducing the detection performance. In response to these challenges, we use a memory update threshold to improve the representational power of memory. We also propose a dual-encoder anomaly detection model to restrict anomaly feature propagation. Experiment results demonstrate the effectiveness and robustness of our approach.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115853393",
                        "name": "Yirong Wu"
                    },
                    {
                        "authorId": "2191244397",
                        "name": "Qi Ren"
                    },
                    {
                        "authorId": "144408598",
                        "name": "Shuifa Sun"
                    },
                    {
                        "authorId": "47127366",
                        "name": "Tinglong Tang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[15], AMMC-Net [16], and FastAno [26] leverage the frame prediction approach as we adopted.",
                "Frame prediction methods [15], [16], [22] share the same principle as the reconstruction methods, except that they are designed to reconstruct a future frame from a series of past frames."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "1a17b3dc975a81f0a0d0b68b77baf682fc9bb2e3",
                "externalIds": {
                    "DBLP": "conf/smc/HyunNLL22",
                    "DOI": "10.1109/SMC53654.2022.9945233",
                    "CorpusId": 253630624
                },
                "corpusId": 253630624,
                "publicationVenue": {
                    "id": "e84bb5a1-8f79-42cc-8eb1-3a52f7c73d63",
                    "name": "IEEE International Conference on Systems, Man and Cybernetics",
                    "type": "conference",
                    "alternate_names": [
                        "Smoky Mountains Computational Sciences and Engineering Conference",
                        "Smoky Mt Comput Sci Eng Conf",
                        "IEEE Int Conf Syst Man Cybern",
                        "SMC",
                        "Syst Man Cybern",
                        "Systems, Man and Cybernetics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1a17b3dc975a81f0a0d0b68b77baf682fc9bb2e3",
                "title": "Learning Temporal Context of Normality for Unsupervised Anomaly Detection in Videos",
                "abstract": "Incomplete reconstruction of abnormal samples using convolutional autoencoders trained only on normal samples has been the key principle of anomaly detection. Such detection mechanisms utilize reconstruction error differences between normal and abnormal frames. This is not consistent, however, causing the normal and abnormal samples undistin-guishable. To handle this problem, we propose a shuffle-and-sort strategy for learning the temporal context of normality. The purpose of the strategy is to reconstruct shuffled input frames into an output with the correct order using a self-attention mechanism. Consequently, the proposed method can model the temporal context of normal events, which prevents the successful completion of reconstructing anomalies by the convolutional layers. We demonstrated the detection efficiency of the proposed method using public benchmark datasets: UCSD Pedestrian 2, CUHK Avenue, and ShanghaiTech Campus Datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2191246436",
                        "name": "Wooyeol Hyun"
                    },
                    {
                        "authorId": "148354920",
                        "name": "Woo-Jeoung Nam"
                    },
                    {
                        "authorId": "2108648957",
                        "name": "Jooyeon Lee"
                    },
                    {
                        "authorId": "2164853907",
                        "name": "Seong-Whan Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "MNAD [36] A, P, S Added a memory module to record prototypical patterns of normal data in memory items, training it with compactness and separateness losses.",
                "[36] proposed a memory module that updates items in the memory while assuring that these represent prototypical patterns of normal data."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "16117969f1fd354e90ed9906d8b3f7d9c1fd39d7",
                "externalIds": {
                    "DOI": "10.3390/app121910011",
                    "CorpusId": 252774714
                },
                "corpusId": 252774714,
                "publicationVenue": {
                    "id": "136edf8d-0f88-4c2c-830f-461c6a9b842e",
                    "name": "Applied Sciences",
                    "type": "journal",
                    "alternate_names": [
                        "Appl Sci"
                    ],
                    "issn": "2076-3417",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-217814",
                    "alternate_urls": [
                        "http://www.mathem.pub.ro/apps/",
                        "https://www.mdpi.com/journal/applsci",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-217814"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/16117969f1fd354e90ed9906d8b3f7d9c1fd39d7",
                "title": "Deep Anomaly Detection for In-Vehicle Monitoring\u2014An Application-Oriented Review",
                "abstract": "Anomaly detection has been an active research area for decades, with high application potential. Recent work has explored deep learning approaches to the detection of abnormal behaviour and abandoned objects in outdoor video surveillance scenarios. The extension of this recent work to in-vehicle monitoring using solely visual data represents a relevant research opportunity that has been overlooked in the accessible literature. With the increasing importance of public and shared transportation for urban mobility, it becomes imperative to provide autonomous intelligent systems capable of detecting abnormal behaviour that threatens passenger safety. To investigate the applicability of current works to this scenario, a recapitulation of relevant state-of-the-art techniques and resources is presented, including available datasets for their training and benchmarking. The lack of public datasets dedicated to in-vehicle monitoring is addressed alongside other issues not considered in previous works, such as moving backgrounds and frequent illumination changes. Despite its relevance, similar surveys and reviews have disregarded this scenario and its specificities. This work initiates an important discussion on application-oriented issues, proposing solutions to be followed in future works, particularly synthetic data augmentation to achieve representative instances with the low amount of available sequences.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2187268185",
                        "name": "Francisco Caetano"
                    },
                    {
                        "authorId": "153253956",
                        "name": "P. Carvalho"
                    },
                    {
                        "authorId": "2176561281",
                        "name": "Jaime Cardoso"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To reinforce above assumption, Gong et al. (MemAE) [9] and Park et al. (LMN) [10] introduced a memory mechanism for recording normal patterns among training data.",
                "(LMN) [10] introduced a memory mechanism for recording normal patterns among training data."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "65259c0f4ba59025cdb6a440548dd2288c765d5c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-13116",
                    "ArXiv": "2209.13116",
                    "DOI": "10.48550/arXiv.2209.13116",
                    "CorpusId": 252545321
                },
                "corpusId": 252545321,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/65259c0f4ba59025cdb6a440548dd2288c765d5c",
                "title": "Spatio-Temporal Relation Learning for Video Anomaly Detection",
                "abstract": "Anomaly identification is highly dependent on the relationship between the object and the scene, as different/same object actions in same/different scenes may lead to various degrees of normality and anomaly. Therefore, object-scene relation actually plays a crucial role in anomaly detection but is inadequately explored in previous works. In this paper, we propose a Spatial-Temporal Relation Learning (STRL) framework to tackle the video anomaly detection task. First, considering dynamic characteristics of the objects as well as scene areas, we construct a Spatio-Temporal Auto-Encoder (STAE) to jointly exploit spatial and temporal evolution patterns for representation learning. For better pattern extraction, two decoding branches are designed in the STAE module, i.e. an appearance branch capturing spatial cues by directly predicting the next frame, and a motion branch focusing on modeling the dynamics via optical flow prediction. Then, to well concretize the object-scene relation, a Relation Learning (RL) module is devised to analyze and summarize the normal relations by introducing the Knowledge Graph Embedding methodology. Specifically in this process, the plausibility of object-scene relation is measured by jointly modeling object/scene features and optimizable object-scene relation maps. Extensive experiments are conducted on three public datasets, and the superior performance over the state-of-the-art methods demonstrates the effectiveness of our method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2064712029",
                        "name": "Hui Lv"
                    },
                    {
                        "authorId": "144801562",
                        "name": "Zhen Cui"
                    },
                    {
                        "authorId": "2136056033",
                        "name": "Biao Wang"
                    },
                    {
                        "authorId": null,
                        "name": "Jian Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "larger than the ones of normal samples, some methods [15], [16], [27], [29] combine AE and the traditional memory",
                "3) Evaluation: Following [27], [41], the area under the curve (AUC) of the receiver operating characteristic (ROC) of the image level and pixel level are used to measure the performance of model.",
                "Recently, Some existing works introduce memory bank to computer vision tasks [50], [51], such as fake video detection [52] and anomaly detection [27], [29].",
                "[27] proposes a combination network of AE and memory module for video anomaly detection.",
                "However, the powerful reconstruction ability of AE is not beneficial for visual anomaly detection [15], [27].",
                "Moreover, Existing methods [15], [27] adopt a scheme, which concatenates the outputs of last encoder and the reads of the memory module as the input of the decoder.",
                "As shown in Figure 1 (1) and Figure 1 (2), the query generated by the traditional method is a logical reorganization of features at the same location but from different channels of the original feature map [16], [27].",
                "3) Evaluation: Following [27], [41], the area under the curve (AUC) of the receiver operating characteristic (ROC)"
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6841ea2b9aead78b6335d6636f7e4ae7e33cbe4b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-12441",
                    "ArXiv": "2209.12441",
                    "DOI": "10.1109/TCSVT.2023.3237562",
                    "CorpusId": 252531926
                },
                "corpusId": 252531926,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/6841ea2b9aead78b6335d6636f7e4ae7e33cbe4b",
                "title": "Visual Anomaly Detection via Partition Memory Bank Module and Error Estimation",
                "abstract": "Reconstruction method based on the memory module for visual anomaly detection attempts to narrow the reconstruction error for normal samples while enlarging it for anomalous samples. Unfortunately, the existing memory module is not fully applicable to the anomaly detection task, and the reconstruction error of the anomaly samples remains small. Towards this end, this work proposes a new unsupervised visual anomaly detection method to jointly learn effective normal features and eliminate unfavorable reconstruction errors. Specifically, a novel Partition Memory Bank (PMB) module is proposed to effectively learn and store detailed features with semantic integrity of normal samples. It develops a new partition mechanism and a unique query generation method to preserve the context information and then improves the learning ability of the memory module. The proposed PMB and the skip connection are alternatively explored to make the reconstruction of abnormal samples worse. To obtain more precise anomaly localization results and solve the problem of cumulative reconstruction error, a novel Histogram Error Estimation module is proposed to adaptively eliminate the unfavorable errors by the histogram of the difference image. It improves the anomaly localization performance without increasing the cost. To evaluate the effectiveness of the proposed method for anomaly detection and localization, extensive experiments are conducted on three widely-used anomaly detection datasets. The encouraging performance of the proposed method compared to the recent approaches based on the memory module demonstrates its superiority.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47189056",
                        "name": "Peng-Fei Xing"
                    },
                    {
                        "authorId": "3233021",
                        "name": "Zechao Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The work [12] further improves the original memory module and introduces a new loss function to improve the learning of the memory module.",
                "However, anomalous events are incidental and diverse resulting in the impracticality of collecting the sufficient anomalous samples [11], [12].",
                "Some methods are proposed [11], [12], [17], [29] to reduce the reconstruction ability of AE by introducing memory networks."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "2b32b46f346d9b13268f0e74e5242a10a712a352",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-12440",
                    "ArXiv": "2209.12440",
                    "DOI": "10.48550/arXiv.2209.12440",
                    "CorpusId": 252531159
                },
                "corpusId": 252531159,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2b32b46f346d9b13268f0e74e5242a10a712a352",
                "title": "Self-Supervised Guided Segmentation Framework for Unsupervised Anomaly Detection",
                "abstract": "\u2014Unsupervised anomaly detection is a challenging task in industrial applications since it is impracticable to col-lect suf\ufb01cient anomalous samples. In this paper, a novel Self- Supervised Guided Segmentation Framework (SGSF) is proposed by jointly exploring effective generation method of forged anoma- lous samples and the normal sample features as the guidance information of segmentation for anomaly detection. Speci\ufb01cally, to ensure that the generated forged anomaly samples are conducive to model training, the Saliency Augmentation Module (SAM) is proposed. SAM introduces a saliency map to generate saliency Perlin noise map, and develops an adaptive segmentation strategy to generate irregular masks in the saliency region. Then, the masks are utilized to generate forged anomalous samples as negative samples for training. Unfortunately, the distribution gap between forged and real anomaly samples makes it dif\ufb01cult for models trained based on forged samples to effectively locate real anomalies. Towards this end, the Self-supervised Guidance Network (SGN) is proposed. It leverages the self-supervised module to extract features that are noise-free and contain normal semantic information as the prior knowledge of the segmentation module. The segmentation module with the knowledge of normal patterns segments out the abnormal regions that are different from the guidance features. To evaluate the effectiveness of SGSF for anomaly detection, extensive experiments are conducted on three anomaly detection datasets. The experimental results show that SGSF achieves state-of-the-art anomaly detection results.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2186112803",
                        "name": "Peng Xing"
                    },
                    {
                        "authorId": "2145377104",
                        "name": "Yanpeng Sun"
                    },
                    {
                        "authorId": "3233021",
                        "name": "Zechao Li"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "7f12319e9b0cdbef09f720bd34dacb8422504df6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-12148",
                    "ArXiv": "2209.12148",
                    "DOI": "10.1109/TPAMI.2023.3322604",
                    "CorpusId": 252531780,
                    "PubMed": "37801379"
                },
                "corpusId": 252531780,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7f12319e9b0cdbef09f720bd34dacb8422504df6",
                "title": "Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection",
                "abstract": "Anomaly detection has recently gained increasing attention in the field of computer vision, likely due to its broad set of applications ranging from product fault detection on industrial production lines and impending event detection in video surveillance to finding lesions in medical scans. Regardless of the domain, anomaly detection is typically framed as a one-class classification task, where the learning is conducted on normal examples only. An entire family of successful anomaly detection methods is based on learning to reconstruct masked normal inputs (eg\u00a0patches, future frames, etc.) and exerting the magnitude of the reconstruction error as an indicator for the abnormality level. Unlike other reconstruction-based methods, we present a novel self-supervised masked convolutional transformer block (SSMCTB) that comprises the reconstruction-based functionality at a core architectural level. The proposed self-supervised block is extremely flexible, enabling information masking at any layer of a neural network and being compatible with a wide range of neural architectures. In this work, we extend our previous self-supervised predictive convolutional attentive block (SSPCAB) with a 3D masked convolutional layer, a transformer for channel-wise attention, as well as a novel self-supervised objective based on Huber loss. Furthermore, we show that our block is applicable to a wider variety of tasks, adding anomaly detection in medical images and thermal videos to the previously considered tasks based on RGB images and surveillance videos. We exhibit the generality and flexibility of SSMCTB by integrating it into multiple state-of-the-art neural models for anomaly detection, bringing forth empirical results that confirm considerable performance improvements on five benchmarks: MVTec AD, BRATS, Avenue, ShanghaiTech, and Thermal Rare Event. We release our code and data as open source at: https://github.com/ristea/ssmctb.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "144074579",
                        "name": "Neelu Madan"
                    },
                    {
                        "authorId": "103931166",
                        "name": "Nicolae-Catalin Ristea"
                    },
                    {
                        "authorId": "1817759",
                        "name": "Radu Tudor Ionescu"
                    },
                    {
                        "authorId": "2143163793",
                        "name": "Kamal Nasrollahi"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "1700569",
                        "name": "T. Moeslund"
                    },
                    {
                        "authorId": "2111863589",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Our method demonstrates the capability of detecting different anomalous events and even presents better performance than memory-based methods, such as MemAE and MNAD, that are specially designed to deal with various anomalies.",
                "7) Memory-Guided Normality for Anomaly Detection (MNAD) [74]: MNAD uses a memory module to record multiple prototypes that represent diverse representations of normalities for unsupervised anomaly detection.",
                "In this article, we equip it on the MNAD [74] model, which is still denoted SSPCAB.",
                "Specifically, in the highway scene, our method presents a better performance of detecting different anomalies than memory-based methods, i.e., MemAE and MNAD, which are specially designed to deal with various anomalies.",
                "7) Memory-Guided Normality for Anomaly Detection (MNAD) [74]: MNAD uses a memory module to record",
                "For anomaly detection in aerial videos, comparing with the commonly used reconstruction-based framework [31], [66], [67], [68], [69], [70], [71], [72], [73], [74] where target values are equal to the inputs, it is more natural to predict the",
                "our prediction-based framework with a commonly used reconstruction-based methodology [31], [66], [67], [68], [69], [70], [71], [72], [73], [74].",
                "Memory-based and GAN-based\nmethods, namely, Skip-GAN, MemAE, and MNAD, show superior performance in this scene."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "1337f8d4c9cc3164f2e337a0496601005f4375ff",
                "externalIds": {
                    "DBLP": "journals/tgrs/JinMXZ22",
                    "ArXiv": "2209.13363",
                    "DOI": "10.1109/TGRS.2022.3198130",
                    "CorpusId": 251532009
                },
                "corpusId": 251532009,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1337f8d4c9cc3164f2e337a0496601005f4375ff",
                "title": "Anomaly Detection in Aerial Videos With Transformers",
                "abstract": "Unmanned aerial vehicles (UAVs) are widely applied for purposes of inspection, search, and rescue operations by the virtue of low-cost, large-coverage, real-time, and high-resolution data acquisition capacities. Massive volumes of aerial videos are produced in these processes, in which normal events often account for an overwhelming proportion. It is extremely difficult to localize and extract abnormal events containing potentially valuable information from long video streams manually. Therefore, we are dedicated to developing anomaly detection methods to solve this issue. In this article, we create a new dataset, named Drone-Anomaly, for anomaly detection in aerial videos. This dataset provides 37 training video sequences and 22 testing video sequences from seven different realistic scenes with various anomalous events. There are 87488 color video frames (51635 for training and 35853 for testing) with the size of 640 $\\times640$ at 30 frames/s. Based on this dataset, we evaluate existing methods and offer a benchmark for this task. Furthermore, we present a new baseline model, anomaly detection with Transformers (ANDTs), which treats consecutive video frames as a sequence of tubelets, utilizes a Transformer encoder to learn feature representations from the sequence, and leverages a decoder to predict the next frame. Our network models normality in the training phase and identifies an event with unpredictable temporal dynamics as an anomaly in the test phase. Moreover, to comprehensively evaluate the performance of our proposed method, we use not only our Drone-Anomaly dataset but also another dataset. We will make our dataset and code publicly available. A demo video is available at https://youtu.be/ancczYryOBY. We make our dataset and code publicly available (https://gitlab.lrz.de/ai4eo/reasoning/drone-anomaly https://github.com/Jin-Pu/Drone-Anomaly).",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "36352940",
                        "name": "P. Jin"
                    },
                    {
                        "authorId": "35041003",
                        "name": "Lichao Mou"
                    },
                    {
                        "authorId": "2065082655",
                        "name": "Guisong Xia"
                    },
                    {
                        "authorId": "2125159330",
                        "name": "Xiao Xiang Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "1d9678297c0d05f801ee6b174ab9d023db242e4d",
                "externalIds": {
                    "DOI": "10.1002/stc.3096",
                    "CorpusId": 252548797
                },
                "corpusId": 252548797,
                "publicationVenue": {
                    "id": "fd4fe610-eb5f-49f5-9e1b-06837a1343d8",
                    "name": "Structural Control & Health Monitoring",
                    "type": "journal",
                    "alternate_names": [
                        "Struct Control  Health Monit"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1d9678297c0d05f801ee6b174ab9d023db242e4d",
                "title": "Anomaly detection in rolling bearings based on the Mel\u2010frequency cepstrum coefficient and masked autoencoder for distribution estimation",
                "abstract": "It is difficult to establish a classification and recognition model of machinery and equipment based on labeled samples in the actual industrial environment because of the imperfect fault modes and data missing. To solve this problem, a semisupervised anomaly detection method based on masked autoencoders of distribution estimation (MADE) is designed. First, the Mel\u2010frequency cepstrum coefficient (MFCC) is employed to extract fault features from vibration signals of rolling bearings. Then, a group of mask matrices are set on each hidden layer to overcome the perfect reconstruction problem of the autoencoders' input, and the full\u2010connection probability of reconstruction is used to replace the reconstruction error and adopted as the anomaly score. Finally, the diagnostic threshold is determined according to the Youden index. Experimental results show that the MADE method can extract fault\u2010sensitive features from a noisy industrial environment and introduce mask matrices renders to make the network autoregressive, thus solving the problem of perfect reconstruction of autoencoders. It is verified based on three rolling bearing datasets that the accuracy, precision, recall, and F1\u2010score of the proposed method are confirmed to be all 100%. Moreover, the accuracy of the proposed method is 17.19% higher than that of the memory\u2010inhibition method on the rolling bearing dataset provided by the Center for Intelligent Maintenance Systems (IMS) in University of Cincinnati (USA). The accuracy of the proposed method is also improved compared with other state\u2010of\u2010the\u2010art anomaly detection methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "95934454",
                        "name": "Suchao Xie"
                    },
                    {
                        "authorId": "3049742",
                        "name": "Runda Liu"
                    },
                    {
                        "authorId": "2048600694",
                        "name": "Leilei Du"
                    },
                    {
                        "authorId": "2048917522",
                        "name": "Hongchuang Tan"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "8d1d7a023dfe090fa09bb2624b9feb8735190c76",
                "externalIds": {
                    "ArXiv": "2209.10865",
                    "DBLP": "conf/ssci/LaakomRIG22",
                    "DOI": "10.1109/SSCI51031.2022.10022157",
                    "CorpusId": 252438808
                },
                "corpusId": 252438808,
                "publicationVenue": {
                    "id": "8a9e9f3b-a025-473d-801e-72cdb0653d22",
                    "name": "IEEE Symposium Series on Computational Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Symp Ser Comput Intell",
                        "SSCI"
                    ],
                    "url": "http://www.ieee-ssci.org/"
                },
                "url": "https://www.semanticscholar.org/paper/8d1d7a023dfe090fa09bb2624b9feb8735190c76",
                "title": "Efficient CNN with uncorrelated Bag of Features pooling",
                "abstract": "Despite the superior performance of CNN, deploying them on low computational power devices is still limited as they are typically computationally expensive. One key cause of the high complexity is the connection between the convolution layers and the fully connected layers, which typically requires a high number of parameters. To alleviate this issue, Bag of Features (BoF) pooling has been recently proposed. BoF learns a dictionary, that is used to compile a histogram representation of the input. In this paper, we propose an approach that builds on top of BoF pooling to boost its efficiency by ensuring that the items of the learned dictionary are non-redundant. We propose an additional loss term, based on the pair-wise correlation of the items of the dictionary, which complements the standard loss to explicitly regularize the model to learn a more diverse and rich dictionary. The proposed strategy yields an efficient variant of BoF and further boosts its performance, without any additional parameters.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "133961681",
                        "name": "Firas Laakom"
                    },
                    {
                        "authorId": "2139894277",
                        "name": "Jenni Raitoharju"
                    },
                    {
                        "authorId": "3074923",
                        "name": "Alexandros Iosifidis"
                    },
                    {
                        "authorId": "9219875",
                        "name": "M. Gabbouj"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In recent years, many methods for video anomaly detection [23, 34, 43] have been proposed with great success."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "a214eb8ba010c204e8328c7771f33ec0b2e5cbeb",
                "externalIds": {
                    "DBLP": "journals/mta/LiSLSCCX23",
                    "DOI": "10.1007/s11042-022-13834-8",
                    "CorpusId": 252472536
                },
                "corpusId": 252472536,
                "publicationVenue": {
                    "id": "477368e9-7a8e-475a-8c93-6d623797fd06",
                    "name": "Multimedia tools and applications",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Tools and Applications",
                        "Multimedia Tool Appl",
                        "Multimedia tool appl"
                    ],
                    "issn": "1380-7501",
                    "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a214eb8ba010c204e8328c7771f33ec0b2e5cbeb",
                "title": "MPAT: multi-path attention temporal method for video anomaly detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2155567047",
                        "name": "Hongjun Li"
                    },
                    {
                        "authorId": "2157274399",
                        "name": "Xiaohu Sun"
                    },
                    {
                        "authorId": "48161673",
                        "name": "Chaobo Li"
                    },
                    {
                        "authorId": "2034199702",
                        "name": "Xulin Shen"
                    },
                    {
                        "authorId": "2129483802",
                        "name": "Jinyi Chen"
                    },
                    {
                        "authorId": "2144139728",
                        "name": "Junjie Chen"
                    },
                    {
                        "authorId": "1906009",
                        "name": "Zhengguang Xie"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Anomaly detection in literature can be categorized into 3 groups; which are memory-based methods [12], one-class classification methods [16] and current"
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "58db123b63cbb3dc59a4d95174e3a75aa5237e5c",
                "externalIds": {
                    "DBLP": "conf/eccv/TufekciKAU22",
                    "ArXiv": "2209.05269",
                    "DOI": "10.48550/arXiv.2209.05269",
                    "CorpusId": 252199837
                },
                "corpusId": 252199837,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/58db123b63cbb3dc59a4d95174e3a75aa5237e5c",
                "title": "Detecting Driver Drowsiness as an Anomaly Using LSTM Autoencoders",
                "abstract": "In this paper, an LSTM autoencoder-based architecture is utilized for drowsiness detection with ResNet-34 as feature extractor. The problem is considered as anomaly detection for a single subject; therefore, only the normal driving representations are learned and it is expected that drowsiness representations, yielding higher reconstruction losses, are to be distinguished according to the knowledge of the network. In our study, the confidence levels of normal and anomaly clips are investigated through the methodology of label assignment such that training performance of LSTM autoencoder and interpretation of anomalies encountered during testing are analyzed under varying confidence rates. Our method is experimented on NTHU-DDD and benchmarked with a state-of-the-art anomaly detection method for driver drowsiness. Results show that the proposed model achieves detection rate of 0.8740 area under curve (AUC) and is able to provide significant improvements on certain scenarios.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2186188762",
                        "name": "G\u00fclin T\u00fcfekci"
                    },
                    {
                        "authorId": "2100459581",
                        "name": "Alper Kayabasi"
                    },
                    {
                        "authorId": "30446204",
                        "name": "Erdem Akag\u00fcnd\u00fcz"
                    },
                    {
                        "authorId": "152986771",
                        "name": "I. Ulusoy"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "274fe6d15b7d13d9514976fad2cfc8f744bb8c4b",
                "externalIds": {
                    "ArXiv": "2209.02899",
                    "DBLP": "journals/corr/abs-2209-02899",
                    "DOI": "10.48550/arXiv.2209.02899",
                    "CorpusId": 252110998
                },
                "corpusId": 252110998,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/274fe6d15b7d13d9514976fad2cfc8f744bb8c4b",
                "title": "Context Recovery and Knowledge Retrieval: A Novel Two-Stream Framework for Video Anomaly Detection",
                "abstract": "\u2014Video anomaly detection aims to \ufb01nd the events in a video that do not conform to the expected behavior. The prevalent methods mainly detect anomalies by snippet reconstruction or future frame prediction error. However, the error is highly dependent on the local context of the current snippet and lacks the understanding of normality. To address this issue, we propose to detect anomalous events not only by the local context, but also according to the consistency between the testing event and the knowledge about normality from the training data. Concretely, we propose a novel two-stream framework based on context recovery and knowledge retrieval, where the two streams can complement each other. For the context recovery stream, we propose a spatiotemporal U-Net which can fully utilize the motion information to predict the future frame. Furthermore, we propose a maximum local error mechanism to alleviate the problem of large recovery errors caused by complex foreground objects. For the knowledge retrieval stream, we propose an improved learnable locality-sensitive hashing, which optimizes hash functions via a Siamese network and a mutual difference loss. The knowledge about normality is encoded and stored in hash tables, and the distance between the testing event and the knowledge representation is used to reveal the probability of anomaly. Finally, we fuse the anomaly scores from the two streams to detect anomalies. Extensive experiments demonstrate the effectiveness and complementarity of the two streams, whereby the proposed two-stream framework achieves state-of-the-art performance on four datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3201156",
                        "name": "Congqi Cao"
                    },
                    {
                        "authorId": "2140029231",
                        "name": "Yue Lu"
                    },
                    {
                        "authorId": "2047640322",
                        "name": "Yanning Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "AE [6,13,16,25] and GAN [26,29,39] are intuitive choices of reconstruction models.",
                "[25] introduce a memory module to select the most similar embedding in embedding storage of normal samples to restrict the generalization on anomalies."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "5533bf9f2385ebece563fea35b19e998db64e597",
                "externalIds": {
                    "ArXiv": "2209.01816",
                    "DBLP": "journals/corr/abs-2209-01816",
                    "DOI": "10.48550/arXiv.2209.01816",
                    "CorpusId": 252090291
                },
                "corpusId": 252090291,
                "publicationVenue": {
                    "id": "bc5a5118-8f5c-49c7-806e-fb8d44c10ae7",
                    "name": "International Conference on Neural Information Processing",
                    "type": "conference",
                    "alternate_names": [
                        "ICONIP",
                        "Int Conf Neural Inf Process"
                    ],
                    "url": "https://link.springer.com/conference/iconip"
                },
                "url": "https://www.semanticscholar.org/paper/5533bf9f2385ebece563fea35b19e998db64e597",
                "title": "ADTR: Anomaly Detection Transformer with Feature Reconstruction",
                "abstract": "Anomaly detection with only prior knowledge from normal samples attracts more attention because of the lack of anomaly samples. Existing CNN-based pixel reconstruction approaches suffer from two concerns. First, the reconstruction source and target are raw pixel values that contain indistinguishable semantic information. Second, CNN tends to reconstruct both normal samples and anomalies well, making them still hard to distinguish. In this paper, we propose Anomaly Detection TRansformer (ADTR) to apply a transformer to reconstruct pre-trained features. The pre-trained features contain distinguishable semantic information. Also, the adoption of transformer limits to reconstruct anomalies well such that anomalies could be detected easily once the reconstruction fails. Moreover, we propose novel loss functions to make our approach compatible with the normal-sample-only case and the anomaly-available case with both image-level and pixel-level labeled anomalies. The performance could be further improved by adding simple synthetic or external irrelevant anomalies. Extensive experiments are conducted on anomaly detection datasets including MVTec-AD and CIFAR-10. Our method achieves superior performance compared with all baselines.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2062515754",
                        "name": "Zhiyuan You"
                    },
                    {
                        "authorId": "2188992002",
                        "name": "Kai Yang"
                    },
                    {
                        "authorId": "145909988",
                        "name": "Wenhan Luo"
                    },
                    {
                        "authorId": "2106412819",
                        "name": "Lei Cui"
                    },
                    {
                        "authorId": "2052967041",
                        "name": "Xinyi Le"
                    },
                    {
                        "authorId": "2149515750",
                        "name": "Yu Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "12fd0f83daee6004943651d6637b0b67574039fb",
                "externalIds": {
                    "DOI": "10.3390/aerospace9090480",
                    "CorpusId": 251962009
                },
                "corpusId": 251962009,
                "publicationVenue": {
                    "id": "eec60769-4238-493f-94a7-aef2343f1137",
                    "name": "Aerospace",
                    "alternate_names": [
                        "Aerospace"
                    ],
                    "issn": "0001-9321"
                },
                "url": "https://www.semanticscholar.org/paper/12fd0f83daee6004943651d6637b0b67574039fb",
                "title": "A Pixel-Wise Foreign Object Debris Detection Method Based on Multi-Scale Feature Inpainting",
                "abstract": "In the aviation industry, foreign object debris (FOD) on airport runways is a serious threat to aircraft during takeoff and landing. Therefore, FOD detection is important for improving the safety of aircraft flight. In this paper, an unsupervised anomaly detection method called Multi-Scale Feature Inpainting (MSFI) is proposed to perform FOD detection in images, in which FOD is defined as an anomaly. This method adopts a pre-trained deep convolutional neural network (CNN) to generate multi-scale features for the input images. Based on the multi-scale features, a deep feature inpainting module is designed and trained to learn how to reconstruct the missing region masked by the multi-scale grid masks. During the inference stage, an anomaly map for the test image is obtained by computing the difference between the original feature and its reconstruction. Based on the anomaly map, the abnormal regions are identified and located. The performance of the proposed method is demonstrated on a newly collected FOD dataset and the public benchmark dataset MVTec AD. The results show that the proposed method is superior to other methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2069093267",
                        "name": "Ying Jing"
                    },
                    {
                        "authorId": "2115720160",
                        "name": "Hong Zheng"
                    },
                    {
                        "authorId": "2152934521",
                        "name": "Wentao Zheng"
                    },
                    {
                        "authorId": "1996148484",
                        "name": "Kaihan Dong"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "6192fff1c7e296ae0a98985c55246e150d02214b",
                "externalIds": {
                    "DBLP": "journals/air/ChandrakalaDR23",
                    "DOI": "10.1007/s10462-022-10258-6",
                    "CorpusId": 251892970
                },
                "corpusId": 251892970,
                "publicationVenue": {
                    "id": "ea8553fe-2467-4367-afee-c4deb3754820",
                    "name": "Artificial Intelligence Review",
                    "type": "journal",
                    "alternate_names": [
                        "Artif Intell Rev"
                    ],
                    "issn": "0269-2821",
                    "url": "https://link.springer.com/journal/10462"
                },
                "url": "https://www.semanticscholar.org/paper/6192fff1c7e296ae0a98985c55246e150d02214b",
                "title": "Anomaly detection in surveillance videos: a thematic taxonomy of deep models, review and performance analysis",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1727475",
                        "name": "S. Chandrakala"
                    },
                    {
                        "authorId": "153145089",
                        "name": "K. Deepak"
                    },
                    {
                        "authorId": "47453115",
                        "name": "G. Revathy"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Among them are (1) reconstruction-based approaches such as Conv-AE [29], TSC [15], StackRNN [15], MemAE [12], MNAD [9], etc.; (2) prediction-based methods: Frame-Pred [8], PGDLE [10], IPR [37].",
                "Among them are (1) reconstruction-based approaches such as Conv-AE [29], TSC [15], StackRNN [15], MemAE [12], MNAD [9], etc.",
                "[9] employed the same network structure as Gong et al.",
                "As revealed by the existing works [8, 9, 42], Peak Signal to Noise Ratio (PSNR) is a more accurate method to determine the picture\u2019s grade, shown as following:",
                "In compared to the method MNAD [9] with a memory module, its performance illustrated by the experimental outcomes on 3 datasets has been elevated, whether it is a reconstruction task or a prediction task.",
                "[9], developed a hybrid framework integrating optical flow reconstruction and frame prediction to carry out video anomaly detection.",
                "[56] 32 MemAE [12] 38 PGDLE [10] 42 MNAD [9] 67 Ours 46\n1 3",
                "[9] adopted multiple prototypes to represent different models of normal video frames.",
                "Future frame prediction is another prevalent video anomaly detection (VAD) methodology, which commonly achieves a better anomaly detection accuracy than reconstruction-based methods [9, 34, 35].",
                "Notably, prediction may be regarded of as a reconstruction of the future frame based on prior frames [9]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "01bc4aa30aa0ad201bf6cbb6948bb155198f9c60",
                "externalIds": {
                    "DBLP": "journals/mms/WangHW23",
                    "DOI": "10.1007/s00530-022-00991-x",
                    "CorpusId": 251822448
                },
                "corpusId": 251822448,
                "publicationVenue": {
                    "id": "d1997ea9-9d41-4458-9280-94feb013bd15",
                    "name": "Multimedia Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Syst"
                    ],
                    "issn": "0942-4962",
                    "url": "http://www.springer.com/computer/information+systems+and+applications/journal/530?changeHeader",
                    "alternate_urls": [
                        "https://link.springer.com/journal/530",
                        "http://www.springer.com/computer/information+systems+and+applications/journal/530?changeHeader="
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/01bc4aa30aa0ad201bf6cbb6948bb155198f9c60",
                "title": "Dual-branch network with memory for video anomaly detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "153168200",
                        "name": "Dicong Wang"
                    },
                    {
                        "authorId": "117110855",
                        "name": "Qinghua Hu"
                    },
                    {
                        "authorId": "49334463",
                        "name": "Kaijun Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following previous work [3], [19], The PSNR of each test frame is normalized to the range [0, 1] and the following formula calculates the regular score of each frame:",
                "The prediction-based VAD methods [3], [18], [19] consider the instances with lower prediction errors as normal while considering unpredictable events as abnormal.",
                "However, we evaluate the quality of predicted frames utilizing the Peak Signal to Noise Ratio (PSNR), which has proven to be a more effective measure [19]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0548c96de57f8fad3053be706e094320e14c10ec",
                "externalIds": {
                    "ArXiv": "2211.00829",
                    "DBLP": "journals/corr/abs-2211-00829",
                    "DOI": "10.1109/ICPR56361.2022.9956287",
                    "CorpusId": 253254922
                },
                "corpusId": 253254922,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0548c96de57f8fad3053be706e094320e14c10ec",
                "title": "Exploiting Spatial-temporal Correlations for Video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) remains a challenging task in the pattern recognition community due to the ambiguity and diversity of abnormal events. Existing deep learning-based VAD methods usually leverage proxy tasks to learn the normal patterns and discriminate the instances that deviate from such patterns as abnormal. However, most of them do not take full advantage of spatial-temporal correlations among video frames, which is critical for understanding normal patterns. In this paper, we address unsupervised VAD by learning the evolution regularity of appearance and motion in the long and short-term and exploit the spatial-temporal correlations among consecutive frames in normal videos more adequately. Specifically, we proposed to utilize the spatiotemporal long short-term memory (ST-LSTM) to extract and memorize spatial appearances and temporal variations in a unified memory cell. In addition, inspired by the generative adversarial network, we introduce a discriminator to perform adversarial learning with the ST-LSTM to enhance the learning capability. Experimental results on standard benchmarks demonstrate the effectiveness of spatial-temporal correlations for unsupervised VAD. Our method achieves competitive performance compared to the state-of-the-art methods with AUCs of 96.7%, 87.8%, and 73.1% on the UCSD Ped2, CUHK Avenue, and ShanghaiTech, respectively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1563747197",
                        "name": "Mengyang Zhao"
                    },
                    {
                        "authorId": "2152799399",
                        "name": "Yang Liu"
                    },
                    {
                        "authorId": "2152908615",
                        "name": "Jing Li"
                    },
                    {
                        "authorId": "2149581020",
                        "name": "Xinhua Zeng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Similarly, LMN [11] proposes to manually update the memory module, along with a triplet loss to better reflect normal behavior patterns.",
                "[11] introduced memory into autoencoders in video anomaly detection."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "180c61e996019b2f39ef81a0b92782e7108e1007",
                "externalIds": {
                    "DBLP": "conf/icpr/LiSXF22",
                    "DOI": "10.1109/ICPR56361.2022.9956318",
                    "CorpusId": 254099073
                },
                "corpusId": 254099073,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/180c61e996019b2f39ef81a0b92782e7108e1007",
                "title": "Memory-Token Transformer for Unsupervised Video Anomaly Detection",
                "abstract": "Video anomaly detection is crucial for behavior analysis, which has witnessed continuous progress in recent years with the auto-encoder based reconstruction framework. However, in some cases, abnormal frames may also be reconstructed well due to the strong representation ability of deep networks, increasing missed detection. To mitigate this issue, the existing methods usually the memory bank method. This method records normal patterns and assigns high errors for the reconstruction of abnormal frames into normal frames. In this paper, to better use the semantic information of normal videos recorded in the memory module, we introduce the Memory-Token Transformer (MTT) to boost the reconstruction performance on normal frames. We assume that the anomalies in a video mainly concentrate on the regions containing people and relevant objects. Therefore, during the decoding stage, we first extract the semantic concepts of a feature map and generate the corresponding semantic tokens. Then the tokens are combined with the proposed memory module. Last, we introduce a transformer to fuse the complex relationship among different tokens, and use 3D convolution with the pooling operator in our encoder to enhance spatio-temporal feature extraction as compared with 2D models. The experimental results obtained on various benchmarks demonstrate the effectiveness of the proposed method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2110860772",
                        "name": "Youyu Li"
                    },
                    {
                        "authorId": "2152114039",
                        "name": "Xiaoning Song"
                    },
                    {
                        "authorId": null,
                        "name": "Tianyang Xu"
                    },
                    {
                        "authorId": "2976854",
                        "name": "Zhenhua Feng"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "8494eb2ca3713a29825eac71da495e62423ec7c3",
                "externalIds": {
                    "DBLP": "conf/case/WanCGSL22",
                    "DOI": "10.1109/CASE49997.2022.9926547",
                    "CorpusId": 253186315
                },
                "corpusId": 253186315,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/8494eb2ca3713a29825eac71da495e62423ec7c3",
                "title": "Position Encoding Enhanced Feature Mapping for Image Anomaly Detection",
                "abstract": "Image anomaly detection is an important stage for automatic visual inspection in intelligent manufacturing systems. The wide-ranging anomalies in images, such as various sizes, shapes, and colors, make automatic visual inspection challenging. Previous work on image anomaly detection has achieved significant advancements. However, there are still limitations in terms of detection performance and efficiency. In this paper, a novel Position Encoding enhanced Feature Mapping (PEFM) method is proposed to address the problem of image anomaly detection, detecting the anomalies by mapping a pair of pre-trained features embedded with position encodes. Experiment results show that the proposed PEFM achieves better performance and efficiency than the state-of-the-art methods on the MVTec AD dataset, an AUCROC of 98.30% and an AUCPRO of 95.52%, and achieves the AUCPRO of 94.0% on the MVTec 3D AD dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2111721746",
                        "name": "Qian Wan"
                    },
                    {
                        "authorId": "2165889312",
                        "name": "Yunkang Cao"
                    },
                    {
                        "authorId": "2148990145",
                        "name": "Liang Gao"
                    },
                    {
                        "authorId": "2117664427",
                        "name": "Weiming Shen"
                    },
                    {
                        "authorId": "1574064065",
                        "name": "Xinyu Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "It is worth pointing out that training only on normal data is often claimed as unsupervision like [11], [13], [30] recently."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "e6e2c93ee6ef830bd8e3bf6ef8ff2f7cf834746e",
                "externalIds": {
                    "DOI": "10.1109/PRAI55851.2022.9904101",
                    "CorpusId": 252720600
                },
                "corpusId": 252720600,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e6e2c93ee6ef830bd8e3bf6ef8ff2f7cf834746e",
                "title": "Video Anomaly Detection via Successive Image Frame Prediction Leveraging Optical Flows",
                "abstract": "Video anomaly detection is challenging due to the diversity of abnormal events, which turns unsupervised learning the promising solution in recent endeavors. In a framework as such, the existing works hold with such an assumption that anomalies cannot be reconstructed or predicated from historical data as accurately as normal ones, so the reconstruction or prediction error can act as an indicator of anomalies. In this study, we propose to discriminate anomalies from normal ones by fusing both appearance and motion in a frame prediction framework, where the uniqueness lies in that we embed optical flows into the frame prediction framework as the clue to direct the transformation from the input to the predicted frame, making appearance-motion fusion quite natural without any extra effort to align them. Then, the error of predicting the next frame based on the concatenation of the appearance and the associated motion of the present frame can indicate the anomaly score. Notably, we employ one frame-based optical flow computation instead of the traditional ones over two continuous frames. The goal is to make the optical flows subject to the whole training data such that anomalies deviating remarkably from the training data will result in highly distorted optical flows and relatively high prediction error correspondingly, which is not promised by the traditional optical flows rooting in the differential of two continuous frames. In summary, we extend the appearance-motion correspondence learning to motion-guided prediction tying the appearances of two consecutive frames. We also introduce a margin loss to enhance the learning of frame prediction. Experiments on widely accepted benchmarks demonstrate the state-of-the-art performance of our approach.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109799958",
                        "name": "Hongyong Wang"
                    },
                    {
                        "authorId": "2107989630",
                        "name": "Xinjian Zhang"
                    },
                    {
                        "authorId": "145803491",
                        "name": "Su Yang"
                    },
                    {
                        "authorId": "2145505597",
                        "name": "Weishan Zhang"
                    },
                    {
                        "authorId": "2155872133",
                        "name": "Jie Li"
                    },
                    {
                        "authorId": "2116381792",
                        "name": "Haiyun Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "5f9d13713a1af5adb372d9b40d33fcff7b7f1e38",
                "externalIds": {
                    "DBLP": "journals/chinaf/ZhongCJR22",
                    "DOI": "10.1007/s11432-021-3444-9",
                    "CorpusId": 251713922
                },
                "corpusId": 251713922,
                "publicationVenue": {
                    "id": "0534c8a0-1226-4f5b-bcf6-a13a8dd1825e",
                    "name": "Science China Information Sciences",
                    "alternate_names": [
                        "Sci China Inf Sci"
                    ],
                    "issn": "1869-1919",
                    "url": "http://info.scichina.com/"
                },
                "url": "https://www.semanticscholar.org/paper/5f9d13713a1af5adb372d9b40d33fcff7b7f1e38",
                "title": "Reverse erasure guided spatio-temporal autoencoder with compact feature representation for video anomaly detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48751559",
                        "name": "Yuanhong Zhong"
                    },
                    {
                        "authorId": "2176480465",
                        "name": "Xia Chen"
                    },
                    {
                        "authorId": null,
                        "name": "Jinyang Jiang"
                    },
                    {
                        "authorId": "2182250084",
                        "name": "Fan Ren"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[17] integrated a memory network with an encoder-decoder scheme, where components in the memory network record prototypical",
                "As we can see, ST-AE and MNAD score lower in AUC than the proposed method, although they achieve a high value on public datasets such as UCSD [40] and ShanghaiTech [41].",
                "One is a baseline spatial-temporal AE network (ST-AE) [12] and the other is the state-of-the-art video anomaly detection based on memory-guided normality for anomaly detection (MNAD) [17]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "94fc2da6c40940f24950953dee5d2ea3c105ba3a",
                "externalIds": {
                    "DBLP": "journals/nca/JiangSQW22",
                    "DOI": "10.1007/s00521-022-07660-0",
                    "CorpusId": 251553030
                },
                "corpusId": 251553030,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/94fc2da6c40940f24950953dee5d2ea3c105ba3a",
                "title": "A deep learning framework for detecting and localizing abnormal pedestrian behaviors at grade crossings",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "9432041",
                        "name": "Zhuocheng Jiang"
                    },
                    {
                        "authorId": "2072634447",
                        "name": "Ge Song"
                    },
                    {
                        "authorId": "2114897270",
                        "name": "Yu Qian"
                    },
                    {
                        "authorId": "2154458044",
                        "name": "Yi Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "If there are multiple attentions, the output of multihead cross\u2010attention is shown in Equation (12).",
                "\u22ef ( ) M MCA = CA + CA + + CA / , i i i i 1 2 (12)"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "18abe29e2c50fa0b5c113a2e9458b89fb1197a8d",
                "externalIds": {
                    "DBLP": "journals/ijis/XieHNWLY22",
                    "DOI": "10.1002/int.22974",
                    "CorpusId": 251451556
                },
                "corpusId": 251451556,
                "publicationVenue": {
                    "id": "05528bac-d212-46a6-9c84-314d4bd77368",
                    "name": "International Journal of Intelligent Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Intell Syst"
                    ],
                    "issn": "0884-8173",
                    "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/36062",
                    "alternate_urls": [
                        "https://onlinelibrary.wiley.com/journal/1098111X"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/18abe29e2c50fa0b5c113a2e9458b89fb1197a8d",
                "title": "RDAD: A reconstructive and discriminative anomaly detection model based on transformer",
                "abstract": "Given the shortcomings of low detection accuracy and poor generalization performance of most current surface defect detection methods for industrial products, this paper proposes a reconstructive and discriminative anomaly detection model. The proposed method uses squeeze\u2010and\u2010excitation block to assign the attention of feature channels to enhance the sensitivity of related features and improve the ability of the model to learn normal and anomaly boundaries. In addition, channel transformer is introduced in the encoder\u2013decoder, so that the decoder better fuses the features in the encoder and reduces the semantic gap, and enhances the segmentation ability of anomalous regions of the model. The model is only trained with normal samples, and completes the localization of anomalous regions while detecting anomalies. Experiments are conducted on the challenging MVTec anomaly detection and Magnetic Tile Defect data sets. Compared with the current state\u2010of\u2010the\u2010art unsupervised anomaly detection methods, the model not only improves the accuracy of anomaly detection, but also has better generality.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1988027266",
                        "name": "Xin Xie"
                    },
                    {
                        "authorId": "2108723330",
                        "name": "Yuhui Huang"
                    },
                    {
                        "authorId": "2123422204",
                        "name": "Weiye Ning"
                    },
                    {
                        "authorId": "2180854366",
                        "name": "Dengquan Wu"
                    },
                    {
                        "authorId": "2118274700",
                        "name": "Zixi Li"
                    },
                    {
                        "authorId": "2115538250",
                        "name": "Hao Yang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "be29ba635bf85faee837056e918414e8f4cf3472",
                "externalIds": {
                    "DOI": "10.3390/jrfm15080342",
                    "CorpusId": 251355622
                },
                "corpusId": 251355622,
                "publicationVenue": {
                    "id": "5bccd387-3836-42f2-9b60-9c190333ae01",
                    "name": "Journal of Risk and Financial Management",
                    "type": "journal",
                    "alternate_names": [
                        "J Risk Financial Manag"
                    ],
                    "issn": "1911-8066",
                    "url": "https://www.mdpi.com/journal/jrfm",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-318032"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/be29ba635bf85faee837056e918414e8f4cf3472",
                "title": "HF-SCA: Hands-Free Strong Customer Authentication Based on a Memory-Guided Attention Mechanisms",
                "abstract": "Strong customer authentication (SCA) is a requirement of the European Union Revised Directive on Payment Services (PSD2) which ensures that electronic payments are performed with multifactor authentication. While increasing the security of electronic payments, the SCA impacted seriously on the shopping carts abandonment: an Italian bank computed that 22% of online purchases in the first semester of 2021 did not complete because of problems with the SCA. Luckily, the PSD2 allows the use of transaction risk analysis tool to exempt the SCA process. In this paper, we propose an unsupervised novel combination of existing machine learning techniques able to determine if a purchase is typical or not for a specific customer, so that in the case of a typical purchase the SCA could be exempted. We modified a well-known architecture (U-net) by replacing convolutional blocks with squeeze-and-excitation blocks. After that, a memory network was added in a latent space and an attention mechanism was introduced in the decoding side of the network. The proposed solution was able to detect nontypical purchases by creating temporal correlations between transactions. The network achieved 97.7% of AUC score over a well-known dataset retrieved online. By using this approach, we found that 98% of purchases could be executed by securely exempting the SCA, while shortening the customer\u2019s journey and providing an elevated user experience. As an additional validation, we developed an Alexa skill for Amazon smart glasses which allows a user to shop and pay online by merely using vocal interaction, leaving the hands free to perform other activities, for example driving a car.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1741861",
                        "name": "C. Distante"
                    },
                    {
                        "authorId": "2180581280",
                        "name": "Laura Fineo"
                    },
                    {
                        "authorId": "2969145",
                        "name": "L. Mainetti"
                    },
                    {
                        "authorId": "35701990",
                        "name": "Luigi Manco"
                    },
                    {
                        "authorId": "151484529",
                        "name": "Benito Taccardi"
                    },
                    {
                        "authorId": "1883772",
                        "name": "R. Vergallo"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "74f81238922f1ae1e22d6cbd50da2a06959b8bba",
                "externalIds": {
                    "DOI": "10.2139/ssrn.4147725",
                    "CorpusId": 250435705
                },
                "corpusId": 250435705,
                "publicationVenue": {
                    "id": "75d7a8c1-d871-42db-a8e4-7cf5146fdb62",
                    "name": "Social Science Research Network",
                    "type": "journal",
                    "alternate_names": [
                        "SSRN, Social Science Research Network (SSRN) home page",
                        "SSRN Electronic Journal",
                        "Soc Sci Res Netw",
                        "SSRN",
                        "SSRN Home Page",
                        "SSRN Electron J",
                        "Social Science Electronic Publishing presents Social Science Research Network"
                    ],
                    "issn": "1556-5068",
                    "url": "http://www.ssrn.com/",
                    "alternate_urls": [
                        "www.ssrn.com/",
                        "https://fatcat.wiki/container/tol7woxlqjeg5bmzadeg6qrg3e",
                        "https://www.wikidata.org/wiki/Q53949192",
                        "www.ssrn.com/en",
                        "http://www.ssrn.com/en/",
                        "http://umlib.nl/ssrn",
                        "umlib.nl/ssrn"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/74f81238922f1ae1e22d6cbd50da2a06959b8bba",
                "title": "A Novel Method for Trajectory Recognition and Working Condition Diagnosis of Sucker Rod Pumping Systems Based on High-Resolution Representation Learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2224668481",
                        "name": "Qiang Wang"
                    },
                    {
                        "authorId": "97653327",
                        "name": "Kai Zhang"
                    },
                    {
                        "authorId": "3022691",
                        "name": "Huaqing Zhang"
                    },
                    {
                        "authorId": "47059797",
                        "name": "Liming Zhang"
                    },
                    {
                        "authorId": "2166041056",
                        "name": "Xia Yan"
                    },
                    {
                        "authorId": "31869802",
                        "name": "Piyang Liu"
                    },
                    {
                        "authorId": "2147259893",
                        "name": "Ling Fan"
                    },
                    {
                        "authorId": "49307630",
                        "name": "Yongfei Yang"
                    },
                    {
                        "authorId": "30915444",
                        "name": "Jun-wu Yao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "6739f9c45837eb3ee7c0dd7063425146ec43fa8e",
                "externalIds": {
                    "DBLP": "journals/ijon/ZhangTGWFBJ22",
                    "DOI": "10.1016/j.neucom.2022.08.039",
                    "CorpusId": 251455247
                },
                "corpusId": 251455247,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6739f9c45837eb3ee7c0dd7063425146ec43fa8e",
                "title": "Dynamic prototypical feature representation learning framework for semi-supervised skin lesion segmentation",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109506952",
                        "name": "Zhenxi Zhang"
                    },
                    {
                        "authorId": "2094026",
                        "name": "Chunna Tian"
                    },
                    {
                        "authorId": "10699750",
                        "name": "Xinbo Gao"
                    },
                    {
                        "authorId": "2181058141",
                        "name": "Cui Wang"
                    },
                    {
                        "authorId": "2109389230",
                        "name": "Xue Feng"
                    },
                    {
                        "authorId": "2067571077",
                        "name": "H. Bai"
                    },
                    {
                        "authorId": "3406199",
                        "name": "Z. Jiao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(2) A dictionary is trained where patterns of normal events are recorded based on their high-level semantic features, and the score of abnormality is calculated with the help of the dictionary [23, 29, 33].",
                "Compared with real-time models, TSSTGM is still a little lower than P w/Mem model [23].",
                "The comparison approaches include FSCN [29], Conv-AE [7], STAE [3], P w/Mem [23], ConvLSTM-AE [18], STAE-grayscale [34], STAE-optflow [34], Optical flow-GAN [25], ST-CaAE [14], STAN [13] and the methods proposed by Gao et al.",
                "[23] propose a model, called P w/Mem, using a memory module with an update scheme where items in the memory record prototypical patterns of normal data."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6d7e7d102559743cbae81ea0b4ec1f040f17a68f",
                "externalIds": {
                    "DBLP": "journals/mms/LiuCZLZ23",
                    "DOI": "10.1007/s00530-022-00979-7",
                    "CorpusId": 251207387
                },
                "corpusId": 251207387,
                "publicationVenue": {
                    "id": "d1997ea9-9d41-4458-9280-94feb013bd15",
                    "name": "Multimedia Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Syst"
                    ],
                    "issn": "0942-4962",
                    "url": "http://www.springer.com/computer/information+systems+and+applications/journal/530?changeHeader",
                    "alternate_urls": [
                        "https://link.springer.com/journal/530",
                        "http://www.springer.com/computer/information+systems+and+applications/journal/530?changeHeader="
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6d7e7d102559743cbae81ea0b4ec1f040f17a68f",
                "title": "Real-time anomaly detection on surveillance video with two-stream spatio-temporal generative model",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109235161",
                        "name": "Weijia Liu"
                    },
                    {
                        "authorId": "1705153",
                        "name": "Jiuxin Cao"
                    },
                    {
                        "authorId": "2117870221",
                        "name": "Yilin Zhu"
                    },
                    {
                        "authorId": "40107085",
                        "name": "Bo Liu"
                    },
                    {
                        "authorId": "2116570482",
                        "name": "Xueling Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Either separately training the feature extraction and clustering steps [48,13,14,41,32], or jointly training both steps end-to-end [1,11,34,3,27,2]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "66c04f66231c147f15dc9101cd1a250d9567e351",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-13798",
                    "ArXiv": "2207.13798",
                    "DOI": "10.48550/arXiv.2207.13798",
                    "CorpusId": 251134981
                },
                "corpusId": 251134981,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/66c04f66231c147f15dc9101cd1a250d9567e351",
                "title": "Look at Adjacent Frames: Video Anomaly Detection without Offline Training",
                "abstract": "We propose a solution to detect anomalous events in videos without the need to train a model offline. Specifically, our solution is based on a randomly-initialized multilayer perceptron that is optimized online to reconstruct video frames, pixel-by-pixel, from their frequency information. Based on the information shifts between adjacent frames, an incremental learner is used to update parameters of the multilayer perceptron after observing each frame, thus allowing to detect anomalous events along the video stream. Traditional solutions that require no offline training are limited to operating on videos with only a few abnormal frames. Our solution breaks this limit and achieves strong performance on benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2030975823",
                        "name": "Yuqi Ouyang"
                    },
                    {
                        "authorId": "2052469776",
                        "name": "Guodong Shen"
                    },
                    {
                        "authorId": "2125466533",
                        "name": "Victor Sanchez"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[31] both proposed to record prototypes of normal data by inserting a memory bank into AE, which can enhance the ability of AE to model normal behavior patterns.",
                "In addition, in order to make prototypes have the characteristics of compactness and diversity, we follow the work [31] using feature compaction loss and feature separation loss to constrain prototypes.",
                "[31] followed this trend and presented an anomaly detection method that uses multiple prototypes to consider various patterns of normal data, which can obtain more compact and sparse memory bank.",
                "In addition, MemAE [11], MNAD [31], and MPN [27], are most-related methods to our approach.",
                "[31] have enhanced the ability of AE to model normal frames by establishing a memory bank.",
                "Compared with previous memory bank based methods [11,31], DLAN can automatically learn prototypes online without additional memory consumptions."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "4be5be316bad2a8ec2aed3ca4460012e383ba3c1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-10948",
                    "ArXiv": "2207.10948",
                    "DOI": "10.48550/arXiv.2207.10948",
                    "CorpusId": 251018647
                },
                "corpusId": 251018647,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/4be5be316bad2a8ec2aed3ca4460012e383ba3c1",
                "title": "Dynamic Local Aggregation Network with Adaptive Clusterer for Anomaly Detection",
                "abstract": "Existing methods for anomaly detection based on memory-augmented autoencoder (AE) have the following drawbacks: (1) Establishing a memory bank requires additional memory space. (2) The fixed number of prototypes from subjective assumptions ignores the data feature differences and diversity. To overcome these drawbacks, we introduce DLAN-AC, a Dynamic Local Aggregation Network with Adaptive Clusterer, for anomaly detection. First, The proposed DLAN can automatically learn and aggregate high-level features from the AE to obtain more representative prototypes, while freeing up extra memory space. Second, The proposed AC can adaptively cluster video data to derive initial prototypes with prior information. In addition, we also propose a dynamic redundant clustering strategy (DRCS) to enable DLAN for automatically eliminating feature clusters that do not contribute to the construction of prototypes. Extensive experiments on benchmarks demonstrate that DLAN-AC outperforms most existing methods, validating the effectiveness of our method. Our code is publicly available at https://github.com/Beyond-Zw/DLAN-AC.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2144391581",
                        "name": "Zhiwei Yang"
                    },
                    {
                        "authorId": "2678268",
                        "name": "Peng Wu"
                    },
                    {
                        "authorId": "2163063860",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "2144485784",
                        "name": "Xiaotao Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The use of memory mechanisms [16, 43] or multi-modal data (e.",
                "To address this, some follow-up studies attempt to boost the accuracy through incorporating memory modules [16, 43], modeling optical flows [29], redesigning specific architectures [58], etc."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "6f154c62bde8492837114c41f541e88f920fc96d",
                "externalIds": {
                    "DBLP": "conf/eccv/WangWQZB022",
                    "ArXiv": "2207.10172",
                    "DOI": "10.48550/arXiv.2207.10172",
                    "CorpusId": 250918173
                },
                "corpusId": 250918173,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/6f154c62bde8492837114c41f541e88f920fc96d",
                "title": "Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw Puzzles",
                "abstract": "Video Anomaly Detection (VAD) is an important topic in computer vision. Motivated by the recent advances in self-supervised learning, this paper addresses VAD by solving an intuitive yet challenging pretext task, i.e., spatio-temporal jigsaw puzzles, which is cast as a multi-label fine-grained classification problem. Our method exhibits several advantages over existing works: 1) the spatio-temporal jigsaw puzzles are decoupled in terms of spatial and temporal dimensions, responsible for capturing highly discriminative appearance and motion features, respectively; 2) full permutations are used to provide abundant jigsaw puzzles covering various difficulty levels, allowing the network to distinguish subtle spatio-temporal differences between normal and abnormal events; and 3) the pretext task is tackled in an end-to-end manner without relying on any pre-trained models. Our method outperforms state-of-the-art counterparts on three public benchmarks. Especially on ShanghaiTech Campus, the result is superior to reconstruction and prediction-based methods by a large margin.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2110431303",
                        "name": "Guodong Wang"
                    },
                    {
                        "authorId": "2108702972",
                        "name": "Yunhong Wang"
                    },
                    {
                        "authorId": "144411970",
                        "name": "Jie Qin"
                    },
                    {
                        "authorId": "49357199",
                        "name": "Dongming Zhang"
                    },
                    {
                        "authorId": "39844997",
                        "name": "Xiuguo Bao"
                    },
                    {
                        "authorId": "2110181103",
                        "name": "Di Huang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In previous work, researchers define video content patterns that are different from usual patterns are anomalies [1-5].",
                "There mainly are two methods: 1) unsupervised learning methods [1-5] train the detection model with only normal samples and the different patterns in test part are considered as anomalies.",
                "Gong et al. (MemAE) [4] and Park et al. (LMN) [5] introduce a memory bank into the AE for anomaly detection.",
                "2) Weakly supervised learning methods [5-10] distinguish abnormal and normal events with video-level annotations.",
                "(LMN) [5] introduce a memory bank into the AE for anomaly detection.",
                "VAD is an important yet challenge task, which has been researched for decades [1-10]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "e727e8d69037145875e36e2e6c89117167588419",
                "externalIds": {
                    "DBLP": "conf/icmcs/Yu0XW22",
                    "DOI": "10.1109/ICME52920.2022.9859607",
                    "CorpusId": 251846717
                },
                "corpusId": 251846717,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e727e8d69037145875e36e2e6c89117167588419",
                "title": "TCA-VAD: Temporal Context Alignment Network for Weakly Supervised Video Anomly Detection",
                "abstract": "Video Anomaly detection (VAD) with weakly supervised is usually formulated as a multiple instance learning (MIL) problem. Although the current MIL-based methods have achieved promising detection performance, the temporal dependencies in videos are not well exploited. There may multiple abnormal clips in a given anomaly video, while the previous work only focused on the most abnormal one. To address above issues, a temporal context alignment (TCA) network for video anomaly detection is proposed in this work. Its merits are three-fold, 1) a sparse continuous sampling strategy is proposed to adapt the varying length of untrimmed videos; 2) a multi-scale attention module is used to establish the video temporal dependencies; 3) a top-k loss strategy is used to enlarge the distance between the top-k normal and abnormal clips. Extensive experiments demonstrate the noticeable anomaly discriminability of the proposed network on two public datasets (ShanghaiTech and UCF-Crime).",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2148457287",
                        "name": "Shenghao Yu"
                    },
                    {
                        "authorId": "2146309168",
                        "name": "Chong Wang"
                    },
                    {
                        "authorId": "2182891374",
                        "name": "Lehong Xiang"
                    },
                    {
                        "authorId": "2109211638",
                        "name": "Jiafei Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The reconstruction error defines the novelty score [40,15,59]: GAN and flow-based invertible models have been exploited for this purpose [71,80,51]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "952e5ebd290d04bf67a6d601ae890b9d285054df",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-08699",
                    "ArXiv": "2207.08699",
                    "DOI": "10.48550/arXiv.2207.08699",
                    "CorpusId": 250626496
                },
                "corpusId": 250626496,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/952e5ebd290d04bf67a6d601ae890b9d285054df",
                "title": "Semantic Novelty Detection via Relational Reasoning",
                "abstract": "Semantic novelty detection aims at discovering unknown categories in the test data. This task is particularly relevant in safety-critical applications, such as autonomous driving or healthcare, where it is crucial to recognize unknown objects at deployment time and issue a warning to the user accordingly. Despite the impressive advancements of deep learning research, existing models still need a finetuning stage on the known categories in order to recognize the unknown ones. This could be prohibitive when privacy rules limit data access, or in case of strict memory and computational constraints (e.g. edge computing). We claim that a tailored representation learning strategy may be the right solution for effective and efficient semantic novelty detection. Besides extensively testing state-of-the-art approaches for this task, we propose a novel representation learning paradigm based on relational reasoning. It focuses on learning how to measure semantic similarity rather than recognizing known categories. Our experiments show that this knowledge is directly transferable to a wide range of scenarios, and it can be exploited as a plug-and-play module to convert closed-set recognition models into reliable open-set ones.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1716197648",
                        "name": "Francesco Cappio Borlino"
                    },
                    {
                        "authorId": "32081825",
                        "name": "S. Bucci"
                    },
                    {
                        "authorId": "2087226",
                        "name": "T. Tommasi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Different from previous work [10], considering the diversity of normal events, only part of the query vectors are written into the memory pool instead of all, which helps the pool to record general patterns of normal events.",
                "However, most existing methods [3, 4, 10] do not consider the difference of spatial and temporal features in isolation.",
                "Follow previous works [3, 10], e is defined as the peak signal-to-noise ratio between the predicted frames \u00cet and the ground truth It, as follows:"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "7b9ae9a6d627e44e197ca1e246d1344576824a05",
                "externalIds": {
                    "DBLP": "conf/icmcs/LiuLZYZS22",
                    "ArXiv": "2207.13361",
                    "DOI": "10.1109/ICME52920.2022.9859727",
                    "CorpusId": 251104767
                },
                "corpusId": 251104767,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7b9ae9a6d627e44e197ca1e246d1344576824a05",
                "title": "Learning Appearance-Motion Normality for Video Anomaly Detection",
                "abstract": "Video anomaly detection is a challenging task in the Computer vision community. Most single task-based methods do not consider the independence of unique spatial and temporal patterns, while two-stream structures lack the exploration of the correlations. In this paper, we propose spatial-temporal memories augmented two-stream auto-encoder framework, which learns the appearance normality and motion normal-ity independently and explores the correlations via adversar-ial learning. Specifically, we first design two proxy tasks to train the two-stream structure to extract appearance and motion features in isolation. Then, the prototypical features are recorded in the corresponding spatial and temporal memory pools. Finally, the encoding-decoding network performs ad-versariallearning with the discriminator to explore the corre-lations between spatial and temporal patterns. Experimental results show that our framework outperforms the state-of-the-art methods, achieving AUCs of 98.1% and 89.8% on UCSD Ped2 and CUHK Avenue datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47909156",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2153467142",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "1563747197",
                        "name": "Mengyang Zhao"
                    },
                    {
                        "authorId": "2143920085",
                        "name": "Dingkang Yang"
                    },
                    {
                        "authorId": "2116150834",
                        "name": "Xiaoguang Zhu"
                    },
                    {
                        "authorId": "143875337",
                        "name": "Liang Song"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Since most surveillance videos are normal, some previous works [2][3][4][5] treat anomaly detection as an unsupervised learning task."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "ce32b80dddffc2bf1da0817e787b63d243ead52e",
                "externalIds": {
                    "DBLP": "conf/icmcs/GongWDYXW22",
                    "DOI": "10.1109/ICME52920.2022.9860012",
                    "CorpusId": 251847412
                },
                "corpusId": 251847412,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ce32b80dddffc2bf1da0817e787b63d243ead52e",
                "title": "Multi-Scale Continuity-Aware Refinement Network for Weakly Supervised Video Anomaly Detection",
                "abstract": "In many previous work, weakly supervised video anomaly detection is formulated as a multiple instance learning (MIL) problem, which represents the video as a bag of multiple instances. However, most MIL-based frameworks only focused on identifying anomalous events from the given instances, without considering the event continuity. Motivated by the fact that abnormal events tend to be more continuous in real-world videos, a Multi-scale Continuity-aware Refinement Network (MCR) is proposed in this paper. It utilizes the property of multi-scale continuity to refine anomaly scores by introducing differential contextual information of instances. At the same time, multi-scale attention is designed to produce a video-level weights in order to select the proper scale and fuse all scores at different scales. Experimental results of MCR show noticeable improvement on two public datasets, specifically obtaining a frame-level AUC 94.92% on ShanghaiTech dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2183042413",
                        "name": "Yiling Gong"
                    },
                    {
                        "authorId": "2146309168",
                        "name": "Chong Wang"
                    },
                    {
                        "authorId": "2158176877",
                        "name": "Xinmiao Dai"
                    },
                    {
                        "authorId": "2148457287",
                        "name": "Shenghao Yu"
                    },
                    {
                        "authorId": "2182891374",
                        "name": "Lehong Xiang"
                    },
                    {
                        "authorId": "2109211638",
                        "name": "Jiafei Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "d1000a75f3a6bf7c71b2d30f0a9d74c541977d4d",
                "externalIds": {
                    "DBLP": "conf/icmcs/HuY0ZCZ22",
                    "DOI": "10.1109/ICME52920.2022.9859873",
                    "CorpusId": 251848323
                },
                "corpusId": 251848323,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d1000a75f3a6bf7c71b2d30f0a9d74c541977d4d",
                "title": "Detecting Anomalous Events from Unlabeled Videos via Temporal Masked Auto-Encoding",
                "abstract": "Unsupervised video anomaly detection (UVAD) intends to discern anomalous events from fully unlabeled videos. However, existing UVAD methods suffer from poor performance. Inspired by recent masked autoencoder (MAE) [1], we propose Temporal Masked Auto-Encoding (TMAE) as an effective end-to-end UVAD method. Specifically, we first denote video events by spatial-temporal cubes (STCs), which are built by temporally consecutive foreground patches from unlabeled videos. Then, half of patches in an STC are masked along the temporal dimension, while a vision transformer (ViT) is trained to exploit unmasked patches to predict masked patches. The rare and unusual nature of anomaly will result in a poorer prediction for anomalous events, which enables us to discriminate anomalies from unlabeled videos and compute the anomaly scores. Furthermore, to utilize motion clues in videos, we also propose to apply TMAE on optical flow, which can further boost performance. Experiments show that TMAE significantly outperforms existing UVAD methods by a notable margin (3.9%\u20136.6% AUC).",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "123925173",
                        "name": "Jingtao Hu"
                    },
                    {
                        "authorId": "2116615990",
                        "name": "Guang Yu"
                    },
                    {
                        "authorId": "1421268306",
                        "name": "Siqi Wang"
                    },
                    {
                        "authorId": "143753739",
                        "name": "En Zhu"
                    },
                    {
                        "authorId": "143942560",
                        "name": "Zhiping Cai"
                    },
                    {
                        "authorId": "35103216",
                        "name": "Xinzhong Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To detect whether a frame is anomalous or not, we use PSNR to calculate the abnormal score [2] [3] [5] [7] [13].",
                "According to the previous work [1] [5] [13], we calculate the Area Under Curve(AUC) of the Receiver Operation Characteristic(ROC), and compare it with hand-crafted based method [15] [20], prediction-based method [5], convolution LSTM based method [16] [17] [21], memory-based method [2] [13], and two-stream based method [1] [3] [4] [7]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "1f74d0419bee627c2812289c2b6902addb15c731",
                "externalIds": {
                    "DBLP": "conf/icmcs/ZouWJZ022",
                    "DOI": "10.1109/ICMEW56448.2022.9859414",
                    "CorpusId": 251773019
                },
                "corpusId": 251773019,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1f74d0419bee627c2812289c2b6902addb15c731",
                "title": "Surveillance Video Anomaly Detection with Feature Enhancement and Consistency Frame Prediction",
                "abstract": "Surveillance video anomaly detection is a challenging problem because of the diversity of abnormal events. The current prediction-based methods outperform reconstruction-based methods. But the former has the following issues: 1) Using optical flow to represent motion will affect real-time detection. 2) Distinguishing abnormal events only by local relationships will lead to ambiguity. 3) Semantic information and spatiotemporal constraint are not fully utilized. To address these problems, we propose FECP-Net: a network with feature enhancement and consistency frame prediction for surveillance video anomaly detection. We use the RGB difference between consecutive frames rather than optical flow to realize real-time detection. Meanwhile, we design a feature enhancement module to enrich semantics and global context information in features. In addition, we add spatiotemporal consistency constraint and consistency loss to strengthen consistency predictions. Extensive experiments on standard benchmarks demonstrate the effectiveness of our method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2064360810",
                        "name": "Beiji Zou"
                    },
                    {
                        "authorId": "2145299467",
                        "name": "Min Wang"
                    },
                    {
                        "authorId": "150188539",
                        "name": "Lingzi Jiang"
                    },
                    {
                        "authorId": "39939186",
                        "name": "Yue Zhang"
                    },
                    {
                        "authorId": "2135212664",
                        "name": "Shu Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We compare our method with well-designed state-of-the-art methods including Stacked RNN [36], ConvAE [14], AE [37], MemAE [37], and MMNP [38]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "74863ff04ca4654d5c2861f5d8d85dc488eb65cc",
                "externalIds": {
                    "DBLP": "conf/ijcnn/YangLSZ22",
                    "DOI": "10.1109/IJCNN55064.2022.9892924",
                    "CorpusId": 252626254
                },
                "corpusId": 252626254,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/74863ff04ca4654d5c2861f5d8d85dc488eb65cc",
                "title": "Anomaly Detection in Surveillance Videos via Memory-augmented Frame Prediction",
                "abstract": "Anomaly detection in surveillance videos is a challenging task in computer vision, and can be defined as the detection of actions or events that do not conform to the expected behaviors. Most of the existing methods solve the task by minimizing the reconstruction errors between the ground-truth video frames and their reconstructed frames. However, these methods sometimes reconstruct anomalies well that results in high false detections and a decrease of the performance. Therefore, we propose a frame prediction method which is based on a memory-augmented scheme for anomaly detection. Our method regards anomaly detection as a frame prediction task, and uses a generative network to achieve the frame prediction. For generating high quality video frames, we embed a memory module into the generative network, which effectively improves the feature representation of normal events and reduces the representation of abnormal events. In addition, we adapt an attention mechanism to model the interdependence between feature channels. In order to evaluate our method, we introduce a new anomaly detection dataset that consists of real and multi-scene surveillance videos. Extensive experiments on our dataset and publicly available datasets validate the effectiveness and robustness of our proposed method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2161385774",
                        "name": "Rui Yang"
                    },
                    {
                        "authorId": "2146088411",
                        "name": "Qun Li"
                    },
                    {
                        "authorId": "2161090947",
                        "name": "Yaying Shen"
                    },
                    {
                        "authorId": "2116461437",
                        "name": "Ziyi Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The former uses only normal videos to train a deep model to understand the archetypal space-time patterns of normal occurrences through the solution of a proxy problem like reconstructing [13] or predicting video frames [14].",
                "[14] proposed an encoder-decoder with a learned memory module to predict future frames."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "1b91f350bd5a9eb35ab06f3b442729b8945dc175",
                "externalIds": {
                    "DBLP": "conf/ijcnn/LiuLNS22",
                    "DOI": "10.1109/IJCNN55064.2022.9892231",
                    "CorpusId": 252626161
                },
                "corpusId": 252626161,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/1b91f350bd5a9eb35ab06f3b442729b8945dc175",
                "title": "Abnormal Event Detection with Self-guiding Multi-instance Ranking Framework",
                "abstract": "The detection of abnormal events in surveillance videos with weak supervision is a challenging task, which tries to temporally find abnormal frames using readily accessible video-level labels. In this paper, we propose a self-guiding multi-instance ranking (SMR) framework, which has explored task-specific deep representations and considered the temporal correlations between video clips. Specifically, we apply a clustering algorithm to fine-tune the features extracted by the pre-trained 3D-convolutional-based models. Besides, the clustering module can generate clip-level labels for abnormal videos, and the pseudo-labels are in part used to supervise the training of the multi-instance regression. While implementing the regression module, we compare the effectiveness of various recurrent neural networks, and the results demonstrate the necessity of temporal correlations for weakly supervised video anomaly detection tasks. Experimental results on two standard benchmarks reveal that the SMR framework is comparable to the state-of-the-art approaches, with frame-level AUCs of 81.7% and 92.4% on the UCF-crime and UCSD Ped2 datasets respectively. Additionally, ablation studies and visualization results prove the effectiveness of the component, and our framework can accurately locate abnormal events.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47909156",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2153467142",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "2139789207",
                        "name": "Wei Ni"
                    },
                    {
                        "authorId": "2163009545",
                        "name": "Liang Song"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026gains with respect to SSMTL (Georgescu et al., 2021), while also attaining superior results compared to other recent state-of-the-art methods (Astrid et al., 2021a,b; Bertasius et al., 2021; Chang et al., 2022; Dong et al., 2020; Doshi and Yilmaz, 2020a,b; Georgescu et al., 2022; Gong et\u2026",
                "\u2026Cheng et al., 2015; Feng et al., 2017; Hinami et al., 2017; Kim and Grauman, 2009; Mehran et al., 2009; Wu et al., 2010), reconstruction-based (Astrid et al., 2021a; Gong et al., 2019; Hasan et al., 2016; Huang et al., 2022a,b,c; Luo et al., 2017, 2022; Nguyen and Meunier, 2019; Park et al.,\u2026",
                "In addition, we note that our approach is different from the method proposed by Astrid et al. (2021a), since this related method aims to reconstruct unmodified frames from pseudo-abnormal frames without changing the learning procedure, i.e. without reversing the gradients, as we do."
            ],
            "isInfluential": false,
            "intents": [
                "result",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "507d3bf6e6ee737e49171ad2fce47d4f0dbba724",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-08003",
                    "ArXiv": "2207.08003",
                    "DOI": "10.48550/arXiv.2207.08003",
                    "CorpusId": 250627358
                },
                "corpusId": 250627358,
                "publicationVenue": {
                    "id": "5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                    "name": "Computer Vision and Image Understanding",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Vis Image Underst"
                    ],
                    "issn": "1077-3142",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/10773142",
                        "http://www.idealibrary.com/links/toc/cviu",
                        "https://www.journals.elsevier.com/computer-vision-and-image-understanding"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/507d3bf6e6ee737e49171ad2fce47d4f0dbba724",
                "title": "SSMTL++: Revisiting Self-Supervised Multi-Task Learning for Video Anomaly Detection",
                "abstract": "A self-supervised multi-task learning (SSMTL) framework for video anomaly detection was recently introduced in literature. Due to its highly accurate results, the method attracted the attention of many researchers. In this work, we revisit the self-supervised multi-task learning framework, proposing several updates to the original method. First, we study various detection methods, e.g. based on detecting high-motion regions using optical flow or background subtraction, since we believe the currently used pre-trained YOLOv3 is suboptimal, e.g. objects in motion or objects from unknown classes are never detected. Second, we modernize the 3D convolutional backbone by introducing multi-head self-attention modules, inspired by the recent success of vision transformers. As such, we alternatively introduce both 2D and 3D convolutional vision transformer (CvT) blocks. Third, in our attempt to further improve the model, we study additional self-supervised learning tasks, such as predicting segmentation maps through knowledge distillation, solving jigsaw puzzles, estimating body pose through knowledge distillation, predicting masked regions (inpainting), and adversarial learning with pseudo-anomalies. We conduct experiments to assess the performance impact of the introduced changes. Upon finding more promising configurations of the framework, dubbed SSMTL++v1 and SSMTL++v2, we extend our preliminary experiments to more data sets, demonstrating that our performance gains are consistent across all data sets. In most cases, our results on Avenue, ShanghaiTech and UBnormal raise the state-of-the-art performance bar to a new level.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1739398670",
                        "name": "Antonio B\u0103rb\u0103l\u0103u"
                    },
                    {
                        "authorId": "1817759",
                        "name": "Radu Tudor Ionescu"
                    },
                    {
                        "authorId": "41021255",
                        "name": "Mariana-Iuliana Georgescu"
                    },
                    {
                        "authorId": "9714545",
                        "name": "J. Dueholm"
                    },
                    {
                        "authorId": "1415112439",
                        "name": "B. Ramachandra"
                    },
                    {
                        "authorId": "2143163793",
                        "name": "Kamal Nasrollahi"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "1700569",
                        "name": "T. Moeslund"
                    },
                    {
                        "authorId": "2111863589",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "1* Corresponding author Various methods related to the unsupervised anomaly detection [2, 3, 4, 5] have been explored."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "eb15a45a83bbc2d8cecd599767aa6fd2f0735b61",
                "externalIds": {
                    "DOI": "10.1109/ITC-CSCC55581.2022.9894934",
                    "CorpusId": 252699878
                },
                "corpusId": 252699878,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/eb15a45a83bbc2d8cecd599767aa6fd2f0735b61",
                "title": "Weakly supervised video anomaly detection with temporal attention module",
                "abstract": "Weakly supervised anomaly detection has become more attractive in terms of various application, such as surveillance video, and monitoring unacceptable video contents. A lot of existing weakly supervised learning methods depend on a Multiple Instance Learning (MIL) framework since MIL allows that a neural network yields temporal predictions when video-level annotations are only given. Although those methods have shown outstanding performance, it has still problems in terms of the fact that they do not consider temporal dependencies among instances. To tackle this issue, we propose Weakly supervised video anomaly detection with temporal attention module, which facilitate the model to learn the relations of consecutive snippets of videos. In addition, we select top-k features in both abnormal segments and normal segments to maximize the separability of abnormal and normal instances. With the help of the proposed method, we improve performance on anomaly detection in UCF Crime dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "153539300",
                        "name": "W. Song"
                    },
                    {
                        "authorId": "2117145348",
                        "name": "Jong-Han Kim"
                    },
                    {
                        "authorId": "1722566",
                        "name": "Joongkyu Kim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Also, in [18], they introduced a memory module with items that capture prototypical models of the inlier class with a new update system."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "821cc82f268a721665f37a5767618ec684452cb0",
                "externalIds": {
                    "ArXiv": "2207.01112",
                    "DBLP": "journals/corr/abs-2207-01112",
                    "DOI": "10.48550/arXiv.2207.01112",
                    "CorpusId": 250264325
                },
                "corpusId": 250264325,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/821cc82f268a721665f37a5767618ec684452cb0",
                "title": "Augment to Detect Anomalies with Continuous Labelling",
                "abstract": "Anomaly detection is to recognize samples that differ in some respect from the training observations. These samples which do not conform to the distribution of normal data are called outliers or anomalies. In real-world anomaly detection problems, the outliers are absent, not well defined, or have a very limited number of instances. Recent state-of-the-art deep learning-based anomaly detection methods suffer from high computational cost, complexity, unstable training procedures, and non-trivial implementation, making them difficult to deploy in real-world applications. To combat this problem, we leverage a simple learning procedure that trains a lightweight convolutional neural network, reaching state-of-the-art performance in anomaly detection. In this paper, we propose to solve anomaly detection as a supervised regression problem. We label normal and anomalous data using two separable distributions of continuous values. To compensate for the unavailability of anomalous samples during training time, we utilize straightforward image augmentation techniques to create a distinct set of samples as anomalies. The distribution of the augmented set is similar but slightly deviated from the normal data, whereas real anomalies are expected to have an even further distribution. Therefore, training a regressor on these augmented samples will result in more separable distributions of labels for normal and real anomalous data points. Anomaly detection experiments on image and video datasets show the superiority of the proposed method over the state-of-the-art approaches.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1752873904",
                        "name": "Vahid Reza Khazaie"
                    },
                    {
                        "authorId": "122738612",
                        "name": "A. Wong"
                    },
                    {
                        "authorId": "49318589",
                        "name": "Y. Mohsenzadeh"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "ecc08a8f034d538f11e3d7153a8761ebaa4c4e25",
                "externalIds": {
                    "DBLP": "journals/ipm/MuSWC22",
                    "DOI": "10.1016/j.ipm.2022.102983",
                    "CorpusId": 249117422
                },
                "corpusId": 249117422,
                "publicationVenue": {
                    "id": "37f5b9b7-f828-4ae1-a174-45b538cbd4e4",
                    "name": "Information Processing & Management",
                    "type": "journal",
                    "alternate_names": [
                        "Inf Process Manag",
                        "Inf Process  Manag",
                        "Information Processing and Management"
                    ],
                    "issn": "0306-4573",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/244/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/information-processing-and-management/",
                        "http://www.sciencedirect.com/science/journal/03064573",
                        "http://www.journals.elsevier.com/information-processing-and-management/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ecc08a8f034d538f11e3d7153a8761ebaa4c4e25",
                "title": "Spatio-temporal graph-based CNNs for anomaly detection in weakly-labeled videos",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40959390",
                        "name": "Huiyu Mu"
                    },
                    {
                        "authorId": "2124674",
                        "name": "Ruizhi Sun"
                    },
                    {
                        "authorId": "2111003410",
                        "name": "Miaomiao Wang"
                    },
                    {
                        "authorId": "35328507",
                        "name": "Zeqiu Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "b6367100e0a013284cd55fb0fd60e30b634a46ab",
                "externalIds": {
                    "DBLP": "journals/pr/ZhuDZC22",
                    "DOI": "10.1016/j.patcog.2022.108897",
                    "CorpusId": 250469757
                },
                "corpusId": 250469757,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b6367100e0a013284cd55fb0fd60e30b634a46ab",
                "title": "Adaptive aggregation-distillation autoencoder for unsupervised anomaly detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2135347714",
                        "name": "Jia-Lu Zhu"
                    },
                    {
                        "authorId": "144688691",
                        "name": "Fang Deng"
                    },
                    {
                        "authorId": "46508951",
                        "name": "Jiachen Zhao"
                    },
                    {
                        "authorId": "48080171",
                        "name": "Jie Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "e97a764c2ac3d0dc588dc363ea77721b300c0790",
                "externalIds": {
                    "DBLP": "conf/aaai/ChenXLYJZQQRM22",
                    "DOI": "10.1609/aaai.v36i1.19898",
                    "CorpusId": 250301157
                },
                "corpusId": 250301157,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/e97a764c2ac3d0dc588dc363ea77721b300c0790",
                "title": "Comprehensive Regularization in a Bi-directional Predictive Network for Video Anomaly Detection",
                "abstract": "Video anomaly detection aims to automatically identify unusual objects or behaviours by learning from normal videos. Previous methods tend to use simplistic reconstruction or prediction constraints, which leads to the insufficiency of learned representations for normal data. As such, we propose a novel bi-directional architecture with three consistency constraints to comprehensively regularize the prediction task from pixel-wise, cross-modal, and temporal-sequence levels. First, predictive consistency is proposed to consider the symmetry property of motion and appearance in forwards and backwards time, which ensures the highly realistic appearance and motion predictions at the pixel-wise level. Second, association consistency considers the relevance between different modalities and uses one modality to regularize the prediction of another one. Finally, temporal consistency utilizes the relationship of the video sequence and ensures that the predictive network generates temporally consistent frames. During inference, the pattern of abnormal frames is unpredictable and will therefore cause higher prediction errors. Experiments show that our method outperforms advanced anomaly detectors and achieves state-of-the-art results on UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "120896528",
                        "name": "Chengwei Chen"
                    },
                    {
                        "authorId": "2154871672",
                        "name": "Yuan Xie"
                    },
                    {
                        "authorId": "3431378",
                        "name": "Shaohui Lin"
                    },
                    {
                        "authorId": "144031869",
                        "name": "Angela Yao"
                    },
                    {
                        "authorId": "2084534028",
                        "name": "Guannan Jiang"
                    },
                    {
                        "authorId": "32794831",
                        "name": "W. Zhang"
                    },
                    {
                        "authorId": "1696146",
                        "name": "Yanyun Qu"
                    },
                    {
                        "authorId": "2835750",
                        "name": "Ruizhi Qiao"
                    },
                    {
                        "authorId": "1999889514",
                        "name": "Bohan Ren"
                    },
                    {
                        "authorId": "2149343311",
                        "name": "Lizhuang Ma"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "2caeea7cb81973ba56bba6daf46137a6b7b279d8",
                "externalIds": {
                    "DBLP": "conf/aaai/LinCLY22",
                    "DOI": "10.1609/aaai.v36i2.20053",
                    "CorpusId": 250288971
                },
                "corpusId": 250288971,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/2caeea7cb81973ba56bba6daf46137a6b7b279d8",
                "title": "A Causal Inference Look at Unsupervised Video Anomaly Detection",
                "abstract": "Unsupervised video anomaly detection, a task that requires no labeled normal/abnormal training data in any form, is challenging yet of great importance to both industrial applications and academic research. Existing methods typically follow an iterative pseudo label generation process. However, they lack a principled analysis of the impact of such pseudo label generation on training. Furthermore, the long-range temporal dependencies also has been overlooked, which is unreasonable since the definition of an abnormal event depends on the long-range temporal context. To this end, first, we propose a causal graph to analyze the confounding effect of the pseudo label generation process. Then, we introduce a simple yet effective causal inference based framework to disentangle the noisy pseudo label's impact. Finally, we perform counterfactual based model ensemble that blends long-range temporal context with local image context in inference to make final anomaly detection. Extensive experiments on six standard benchmark datasets show that our proposed method significantly outperforms previous state-of-the-art methods, demonstrating our framework's effectiveness.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "71443792",
                        "name": "Xiangru Lin"
                    },
                    {
                        "authorId": "2109290666",
                        "name": "Yuyang Chen"
                    },
                    {
                        "authorId": "144958813",
                        "name": "Guanbin Li"
                    },
                    {
                        "authorId": "1841911",
                        "name": "Yizhou Yu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "edee93ddcfcfeb0674464080800623bf0ac0e71b",
                "externalIds": {
                    "DBLP": "journals/sivp/YangCLX23",
                    "DOI": "10.1007/s11760-022-02274-4",
                    "CorpusId": 249857188
                },
                "corpusId": 249857188,
                "publicationVenue": {
                    "id": "11437c2b-f0a0-4db5-ac17-56dd7a223080",
                    "name": "Signal, Image and Video Processing",
                    "type": "journal",
                    "alternate_names": [
                        "Signal Image Video Process"
                    ],
                    "issn": "1863-1703",
                    "url": "https://link.springer.com/journal/11760"
                },
                "url": "https://www.semanticscholar.org/paper/edee93ddcfcfeb0674464080800623bf0ac0e71b",
                "title": "Multi-scale Siamese prediction network for video anomaly detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2121285399",
                        "name": "Jingxiang Yang"
                    },
                    {
                        "authorId": "2216476",
                        "name": "Yiheng Cai"
                    },
                    {
                        "authorId": "2146031940",
                        "name": "Dan Liu"
                    },
                    {
                        "authorId": "2153623948",
                        "name": "Jin Xie"
                    }
                ]
            }
        },
        {
            "contexts": [
                "methods include Conv-AE[4], 3D-Conv[35], MemAE[1], and MNAD-R[6], while MNAD-P[6], AMMC-Net[8], FramePred[5], VEC[7], C2-D2GAN[3], and Transanomaly[14], are TABLE IV AUROC PERFORMANCE (%) COMPARISON WITH PREVIOUS WORKS ON UCSD PED2, CUHK AVENUE AND SHTECH DATASETS",
                "First, reconstruction-based methods include Conv-AE[4], 3D-Conv[35], MemAE[1], and MNAD-R[6], while MNAD-P[6], AMMC-Net[8], FramePred[5], VEC[7], C2-D2GAN[3], and Transanomaly[14], are\nprediction-based methods and HF2-VAD[2] is the hybrid method.",
                "with a memory module[1], [6], [8] have been extensively studied.",
                "To alleviate this generalizing issue, an AE with a memory module[1], [6], [8], has been proposed in recent years."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "1c1c590ffd5d5f4e9ce455bbdbc15d0e781ac540",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-08568",
                    "ArXiv": "2206.08568",
                    "DOI": "10.1109/ICPR56361.2022.9956507",
                    "CorpusId": 249848137
                },
                "corpusId": 249848137,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1c1c590ffd5d5f4e9ce455bbdbc15d0e781ac540",
                "title": "Multi-Contextual Predictions with Vision Transformer for Video Anomaly Detection",
                "abstract": "Video Anomaly Detection(VAD) has been traditionally tackled in two main methodologies: the reconstruction-based approach and the prediction-based one. As the reconstruction-based methods learn to generalize the input image, the model merely learns an identity function and strongly causes the problem called generalizing issue. On the other hand, since the prediction-based ones learn to predict a future frame given several previous frames, they are less sensitive to the generalizing issue. However, it is still uncertain if the model can learn the spatio-temporal context of a video. Our intuition is that the understanding of the spatio-temporal context of a video plays a vital role in VAD as it provides precise information on how the appearance of an event in a video clip changes. Hence, to fully exploit the context information for anomaly detection in video circumstances, we designed the transformer model with three different contextual prediction streams: masked, whole and partial. By learning to predict the missing frames of consecutive normal frames, our model can effectively learn various normality patterns in the video, which leads to a high reconstruction error at the abnormal cases that are unsuitable to the learned context. To verify the effectiveness of our approach, we assess our model on the public benchmark datasets: USCD Pedestrian 2, CUHK Avenue and ShanghaiTech and evaluate the performance with the anomaly score metric of reconstruction error. The results demonstrate that our proposed approach achieves a competitive performance compared to the existing video anomaly detection methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Joo-Yeon Lee"
                    },
                    {
                        "authorId": "148354920",
                        "name": "Woo-Jeoung Nam"
                    },
                    {
                        "authorId": "2155886654",
                        "name": "Seong-Whan Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Dataset Future Frame Prediction [79] MLEP [78] MNAD [114]\nStreet Scene [123] 3130 48000* 37 Subway Entrance [1] 1000 1000* 43 UCF-Crime [150] 2105 10000* 2\n*: In MLEP, the training process gets randomly video snippets as input, so we can only get the number of iterations needed to obtain the result.",
                "From the results is presented in Table 10, it is clear that almost all of the state-of-the-art approaches primarily focused on unsupervised or weakly-supervised deep learning are becoming increasingly pervasive on video tasks, specifically anomaly analysis tasks because of the overall performance of these methods outperforming all traditional methods on two different public benchmark datasets by a large margin such as Future Frame Prediction [79], MLEP [78], Memoryguided Normality [114].",
                "Street Scene [123] Subway Entrance [1] UCF-Crime [150] Method\nAUC EER AUC EER AUC EER\nFuture Frame Prediction [79] 56.53 46.14 71.72 32.22 66.53 38.67 MLEP [78] 53.46 30.49 77.30 46.63 55.08 47.05 MNAD [114] 57.25 44.36 69.37 35.69 65.53 39.69\nnumber of epochs and iterations with the best result of each method showed in Table 12.",
                "Notable unsupervised learning methods for anomaly analysis in videos [79, 100, 114, 182].",
                "In this section, the goal of our experiments is to evaluate three benchmark methods including Future Frame Prediction [79], MLEP [78] and MNAD [114] on three most commonly used datasets namely Street Scene [123], Subway Entrance [1], and UCF-Crime [150] in terms of EER and ROC-AUC metrics at frame-level to evaluate these results of these methods performed on diferent anomalous video datasets.",
                "In this section, the goal of our experiments is to evaluate three benchmark methods including Future Frame Prediction [79], MLEP [78], and MNAD [114] on three most commonly used datasets, namely, Street Scene [123], Subway Entrance [1], and UCF-Crime [150] in terms of EER and ROC-AUC metrics at frame-level to evaluate these results of these methods performed on different anomalous video datasets.",
                "Table 11 shows percentages of three prominent methods namely Future Frame Prediction [79], MLEP [78] and MNAD [114] on three abnormal video datasets in terms of AUC and EER metrics at frame-level.",
                "Dataset Future Frame Prediction [79] MLEP [78] MNAD [114]",
                "Table 11 shows percentages of three prominent methods, namely, Future Frame Prediction [79], MLEP [78], and MNAD [114] on three abnormal video datasets in terms of AUC and EER metrics at frame-level.",
                "With regard to the AUC metric, the number of MNAD method is the highest igure of the three well-known methods on the Street Scene dataset at 57.25%, however, the igure of this method on the Subway Entrance dataset is the lowest at 69.37%.",
                "Furthermore, the MNAD method is also slightly lower than that of the Future frame prediction method on the UCF-Crime dataset at 65.53% compared to at 66.53%."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6a0082b379359ca0f79a164538eec9ef0a184244",
                "externalIds": {
                    "DBLP": "journals/csur/TranVVNN23",
                    "DOI": "10.1145/3544014",
                    "CorpusId": 249679804
                },
                "corpusId": 249679804,
                "publicationVenue": {
                    "id": "7b2adce0-d53f-49d6-8784-b0645604fe62",
                    "name": "ACM Computing Surveys",
                    "type": "journal",
                    "alternate_names": [
                        "ACM Comput Surv"
                    ],
                    "issn": "0360-0300",
                    "url": "http://www.acm.org/pubs/surveys/",
                    "alternate_urls": [
                        "http://portal.acm.org/csur",
                        "https://csur.acm.org/",
                        "http://csur.acm.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6a0082b379359ca0f79a164538eec9ef0a184244",
                "title": "Anomaly Analysis in Images and Videos: A Comprehensive Review",
                "abstract": "Anomaly analysis is an important component of any surveillance system. In recent years, it has drawn the attention of the computer vision and machine learning communities. In this article, our overarching goal is thus to provide a coherent and systematic review of state-of-the-art techniques and a comprehensive review of the research works in anomaly analysis. We will provide a broad vision of computational models, datasets, metrics, extensive experiments, and what anomaly analysis can do in images and videos. Intensively covering nearly 200 publications, we review (i) anomaly related surveys, (ii) taxonomy for anomaly problems, (iii) the computational models, (iv) the benchmark datasets for studying abnormalities in images and videos, and (v) the performance of state-of-the-art methods in this research problem. In addition, we provide insightful discussions and pave the way for future work.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2154432442",
                        "name": "T. Tran"
                    },
                    {
                        "authorId": "2153857205",
                        "name": "Tu N. Vu"
                    },
                    {
                        "authorId": "2198372",
                        "name": "Nguyen D. Vo"
                    },
                    {
                        "authorId": "34646933",
                        "name": "Tam V. Nguyen"
                    },
                    {
                        "authorId": "1399684830",
                        "name": "Khang Nguyen"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", structural [53] or semantic [39, 46]), memory mechanism [19, 20, 29], iteration mechanism [12], image masking strategy [47], and pseudo-anomaly [9, 32]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "0e8446c00ed21c19f62d71ab208a7b3601671766",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-03687",
                    "ArXiv": "2206.03687",
                    "DOI": "10.48550/arXiv.2206.03687",
                    "CorpusId": 249462039
                },
                "corpusId": 249462039,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0e8446c00ed21c19f62d71ab208a7b3601671766",
                "title": "A Unified Model for Multi-class Anomaly Detection",
                "abstract": "Despite the rapid advance of unsupervised anomaly detection, existing methods require to train separate models for different objects. In this work, we present UniAD that accomplishes anomaly detection for multiple classes with a unified framework. Under such a challenging setting, popular reconstruction networks may fall into an\"identical shortcut\", where both normal and anomalous samples can be well recovered, and hence fail to spot outliers. To tackle this obstacle, we make three improvements. First, we revisit the formulations of fully-connected layer, convolutional layer, as well as attention layer, and confirm the important role of query embedding (i.e., within attention layer) in preventing the network from learning the shortcut. We therefore come up with a layer-wise query decoder to help model the multi-class distribution. Second, we employ a neighbor masked attention module to further avoid the information leak from the input feature to the reconstructed output feature. Third, we propose a feature jittering strategy that urges the model to recover the correct message even with noisy inputs. We evaluate our algorithm on MVTec-AD and CIFAR-10 datasets, where we surpass the state-of-the-art alternatives by a sufficiently large margin. For example, when learning a unified model for 15 categories in MVTec-AD, we surpass the second competitor on the tasks of both anomaly detection (from 88.1% to 96.5%) and anomaly localization (from 89.5% to 96.8%). Code is available at https://github.com/zhiyuanyou/UniAD.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2062515754",
                        "name": "Zhiyuan You"
                    },
                    {
                        "authorId": "2106412819",
                        "name": "Lei Cui"
                    },
                    {
                        "authorId": "2117687899",
                        "name": "Yujun Shen"
                    },
                    {
                        "authorId": "2188992002",
                        "name": "Kai Yang"
                    },
                    {
                        "authorId": "145574672",
                        "name": "Xin Lu"
                    },
                    {
                        "authorId": "2149515750",
                        "name": "Yu Zheng"
                    },
                    {
                        "authorId": "2052967041",
                        "name": "Xinyi Le"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Anomaly Detection aims to detect unusual samples in data.",
                "Deep Anomaly Detection [62, 63, 56, 36, 48, 3, 76, 51, 5, 16, 53, 54, 55, 20] takes the advantage of DNNs to have better scalability and performance on high dimensional data."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "56f67b02d4a48c68e81e43f65b7e3f2c3d701305",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-00489",
                    "ArXiv": "2206.00489",
                    "DOI": "10.48550/arXiv.2206.00489",
                    "CorpusId": 249240188
                },
                "corpusId": 249240188,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/56f67b02d4a48c68e81e43f65b7e3f2c3d701305",
                "title": "Attack-Agnostic Adversarial Detection",
                "abstract": "The growing number of adversarial attacks in recent years gives attackers an advantage over defenders, as defenders must train detectors after knowing the types of attacks, and many models need to be maintained to ensure good performance in detecting any upcoming attacks. We propose a way to end the tug-of-war between attackers and defenders by treating adversarial attack detection as an anomaly detection problem so that the detector is agnostic to the attack. We quantify the statistical deviation caused by adversarial perturbations in two aspects. The Least Significant Component Feature (LSCF) quantifies the deviation of adversarial examples from the statistics of benign samples and Hessian Feature (HF) reflects how adversarial examples distort the landscape of the model's optima by measuring the local loss curvature. Empirical results show that our method can achieve an overall ROC AUC of 94.9%, 89.7%, and 94.6% on CIFAR10, CIFAR100, and SVHN, respectively, and has comparable performance to adversarial detectors trained with adversarial examples on most of the attacks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "33896010",
                        "name": "Jiaxin Cheng"
                    },
                    {
                        "authorId": "2052375209",
                        "name": "Mohamed Hussein"
                    },
                    {
                        "authorId": "2710228",
                        "name": "J. Billa"
                    },
                    {
                        "authorId": "17806729",
                        "name": "Wael AbdAlmageed"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "eb31173dfe39ec3a9d487ba776c9933c168eded4",
                "externalIds": {
                    "DBLP": "journals/pr/ZhouLWRM22",
                    "DOI": "10.1016/j.patcog.2022.108860",
                    "CorpusId": 249840206
                },
                "corpusId": 249840206,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/eb31173dfe39ec3a9d487ba776c9933c168eded4",
                "title": "Discovering unknowns: Context-enhanced anomaly detection for curiosity-driven autonomous underwater exploration",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2145499530",
                        "name": "Yang Zhou"
                    },
                    {
                        "authorId": "2158837",
                        "name": "Baihua Li"
                    },
                    {
                        "authorId": "2118443928",
                        "name": "Jiangtao Wang"
                    },
                    {
                        "authorId": "2038524938",
                        "name": "Emanuele Rocco"
                    },
                    {
                        "authorId": "2112722704",
                        "name": "Qinggang Meng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "They were adopted in several tasks such as object tracking [14, 43], anomaly detection [16,36], predictive learning [19,28,29], and few-shot learning [8, 23, 45]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "14f6b71c2d7c75851295044a5ce602cec120eccb",
                "externalIds": {
                    "DBLP": "conf/cvpr/0001KR22",
                    "DOI": "10.1109/CVPR52688.2022.01028",
                    "CorpusId": 249980209
                },
                "corpusId": 249980209,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/14f6b71c2d7c75851295044a5ce602cec120eccb",
                "title": "Weakly Paired Associative Learning for Sound and Image Representations via Bimodal Associative Memory",
                "abstract": "Data representation learning without labels has attracted increasing attention due to its nature that does not require human annotation. Recently, representation learning has been extended to bimodal data, especially sound and image which are closely related to basic human senses. Existing sound and image representation learning methods necessarily require a large number of sound and image with corresponding pairs. Therefore, it is difficult to ensure the effectiveness of the methods in the weakly paired condition, which lacks paired bimodal data. In fact, according to human cognitive studies, the cognitive functions in the human brain for a certain modality can be enhanced by receiving other modalities, even not directly paired ones. Based on the observation, we propose a new problem to deal with the weakly paired condition: How to boost a certain modal representation even by using other unpaired modal data. To address the issue, we introduce a novel bimodal associative memory (BMA-Memory) with key-value switching. It enables to build sound-image association with small paired bimodal data and to boost the built association with the eas-ily obtainable large amount of unpaired data. Through the proposed associative learning, it is possible to reinforce the representation of a certain modality (e.g., sound) even by using other unpaired modal data (e.g., images).",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2909533",
                        "name": "Sangmin Lee"
                    },
                    {
                        "authorId": "2109581766",
                        "name": "Hyungil Kim"
                    },
                    {
                        "authorId": "2075377906",
                        "name": "Y. Ro"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Hence, video anomaly detection has been attracting an increasing amount of research interest, with most of the recent approaches heavily dependent on end-to-end trained complex deep learning based approaches [11, 32, 43].",
                "Recent algorithms can be broadly classified into reconstruction based approaches [15, 17, 36, 41, 43], which try to classify frames based on the reconstruction error, and prediction based approaches [8, 11, 29, 32], which attempt to predict a future frame, primarily by using generative adversarial networks (GANs) [16].",
                "A common technique used by several recent works [22, 32, 40, 43] is to normalize the computed statistic for each test video independently, including the ShanghaiTech dataset."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "92b11986706a6e45533ced0240a49fb44bdc5b4d",
                "externalIds": {
                    "DBLP": "conf/cvpr/DoshiY22a",
                    "DOI": "10.1109/CVPRW56347.2022.00434",
                    "CorpusId": 250085421
                },
                "corpusId": 250085421,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/92b11986706a6e45533ced0240a49fb44bdc5b4d",
                "title": "Multi-Task Learning for Video Surveillance with Limited Data",
                "abstract": "Learning from limited data in video surveillance is important for sustainable performance while adapting to new information in a scene over time or adapting to a different scene. In a real-world scene, for an anomaly detection algorithm, all possible nominal patterns and behaviors are not typically available immediately for a single training session. In contrast, labeled nominal data patterns may become available irregularly over a long time horizon, and the anomaly detection algorithm needs to quickly learn such new patterns from limited samples for acceptable performance. Otherwise, it would suffer from frequent false alarms. Additionally, the anomaly detection algorithm needs to continually learn new nominal patterns in multiple training sessions without forgetting the previous knowledge and losing performance. Cross-domain adaptability (i.e., transfer learning to another surveillance scene) is another task where the anomaly detection algorithm has to quickly learn from limited nominal training data to achieve acceptable performance. To overcome these challenges, we design a modular framework and use it to extract semantic embeddings, which we then train on by using deep metric learning. Particularly, we study these three problems (few-shot learning, continual learning, cross-domain adaptability) in a multi-task learning setting. We also compare our proposed framework to existing state-of-the-art approaches using various evaluation metrics. The empirical results indicate that the proposed approach is able to outperform the existing approaches on all three tasks for three benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "115636521",
                        "name": "Keval Doshi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The results show that the DPU is more memory-efficient than the memory module in previous work [17], [18].",
                "UCSDPed1 is relatively poor, whilst for CUHK Avenue, the AUC is better than most methods, except FlowNet-Unet-GAN [14], MemAE [17], LMN [18], MPD [19].",
                "Performance on UCSDPed1 is relatively poor, whilst for CUHK Avenue, the AUC is better than most methods, except FlowNet-Unet-GAN [14], MemAE [17], LMN [18], MPD [19].",
                "We achieve 75 fps for anomaly detection with a GeForce GTX TITAN X, faster than other state of the art methods with the same setting [18].",
                "As in previous work [18], the DPU inputs the encoding feature maps, which are outputs of the encoder part of U-net, to generate a pool of dynamic prototypes.",
                "However, MemAE [17], LMN [18] and MPD [19] have more parameters than our models which is shown in table III.",
                "A memory module is proposed into the AE to address these problems [17], [18].",
                "Since normal patterns in training and testing sets may be different, the memory items are updated during training and testing time, with the use of a predefined threshold to prevent updating on anomaly patterns [18]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "result",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "ee80aa6eeac855df0fe923533d26b2298efa09e8",
                "externalIds": {
                    "ArXiv": "2205.08812",
                    "DBLP": "journals/corr/abs-2205-08812",
                    "DOI": "10.48550/arXiv.2205.08812",
                    "CorpusId": 248863175
                },
                "corpusId": 248863175,
                "publicationVenue": {
                    "id": "4593201d-306b-49d0-84bd-14d259ab15ea",
                    "name": "Journal of Science and Technology Issue on Information and Communications Technology",
                    "type": "journal",
                    "alternate_names": [
                        "J Sci Technol Issue Inf Commun Technol"
                    ],
                    "issn": "1859-1531"
                },
                "url": "https://www.semanticscholar.org/paper/ee80aa6eeac855df0fe923533d26b2298efa09e8",
                "title": "Anomaly detection using prediction error with Spatio-Temporal Convolutional LSTM",
                "abstract": "In this paper, we propose a novel method for video anomaly detection motivated by an existing architecture for sequence-to-sequence prediction and reconstruction using a spatio-temporal convolutional Long Short-Term Memory (convLSTM). As in previous work on anomaly detection, anomalies arise as spatially localised failures in reconstruction or prediction. In experiments with five benchmark datasets, we show that using prediction gives superior performance to using reconstruction. We also compare performance with different length input/output sequences. Overall, our results using prediction are comparable with the state of the art on the benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "143601301",
                        "name": "Hanh T. M. Tran"
                    },
                    {
                        "authorId": "1967104",
                        "name": "David C. Hogg"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[4], [5], [9], [10], [11] or a prediction task [2], [12], [13], [14]."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "be089bf77c9df64e2ef258a50f29924949f08aa2",
                "externalIds": {
                    "DBLP": "conf/crv/BaradaranB22",
                    "ArXiv": "2205.01706",
                    "DOI": "10.1109/CRV55824.2022.00020",
                    "CorpusId": 248512899
                },
                "corpusId": 248512899,
                "publicationVenue": {
                    "id": "3eaf5a5d-62f7-41b6-817e-92d78060c075",
                    "name": "Canadian Conference on Computer and Robot Vision",
                    "type": "conference",
                    "alternate_names": [
                        "CRV",
                        "Can Conf Comput Robot Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=583"
                },
                "url": "https://www.semanticscholar.org/paper/be089bf77c9df64e2ef258a50f29924949f08aa2",
                "title": "Object Class Aware Video Anomaly Detection through Image Translation",
                "abstract": "Semi-supervised video anomaly detection (VAD) methods formulate the task of anomaly detection as detection of deviations from the learned normal patterns. Previous works in the field (reconstruction or prediction-based methods) suffer from two drawbacks: 1) They focus on low-level features, and they (especially holistic approaches) do not effectively consider the object classes. 2) Object-centric approaches neglect some of the context information (such as location). To tackle these challenges, this paper proposes a novel two-stream object-aware VAD method that learns the normal appearance and motion patterns through image translation tasks. The appearance branch translates the input image to the target semantic segmentation map produced by Mask-RCNN, and the motion branch associates each frame with its expected optical flow magnitude. Any deviation from the expected appearance or motion in the inference stage shows the degree of potential abnormality. We evaluated our proposed method on the ShanghaiTech, UCSD-Pedl, and UCSD-Ped2 datasets and the results show competitive performance compared with state-of-the-art works. Most importantly, the results show that, as significant improvements to previous methods, detections by our method are completely explainable and anomalies are localized accurately in the frames.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2093641084",
                        "name": "M. Baradaran"
                    },
                    {
                        "authorId": "2145950",
                        "name": "R. Bergevin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "By weakening the strong generalization ability with a new memory module and maximizing the margin between abnormal and normal samples via few-shot learning, it makes the model more sensitive to abnormal behaviors and improves the model\u2019s discrimination ability, compared with both prediction-based models(4,28) and memory-based models.(3,9) By observing the above tables, we can further draw the following conclusions."
            ],
            "isInfluential": false,
            "intents": [
                "result"
            ],
            "citingPaper": {
                "paperId": "63bad217597ce33ddf915f1ab7bb951bab2c4663",
                "externalIds": {
                    "DOI": "10.1117/1.JEI.31.3.033003",
                    "CorpusId": 248640374
                },
                "corpusId": 248640374,
                "publicationVenue": {
                    "id": "c677ab24-0c04-487d-83e2-c252af9479c8",
                    "name": "Journal of Electronic Imaging (JEI)",
                    "type": "journal",
                    "alternate_names": [
                        "J Electron Imaging (JEI",
                        "Journal of Electronic Imaging",
                        "J Electron Imaging"
                    ],
                    "issn": "1017-9909",
                    "url": "https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging",
                    "alternate_urls": [
                        "http://electronicimaging.spiedigitallibrary.org/journal.aspx"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/63bad217597ce33ddf915f1ab7bb951bab2c4663",
                "title": "Anomaly detection model based on few-shot learning and memory modules",
                "abstract": "Abstract. Anomaly detection is a key issue in public security. Its accuracy is essential to identify abnormalities and take corresponding actions to ensure the safety of relevant objects, which have a broad application space. The traditional anomaly detection method based on deep learning has too strong generalization ability. At the same time, it lacks recognition ability because it only uses normal data for training. To this end, we propose an anomaly detection model based on few-shot learning, guided by memory modules and trained by a large number of normal samples combined with a small number of observed abnormalities. We introduce memory modules to record normal features, which has the function of updating and reading. When training modules, feature compactness, and separateness loss are utilized, it successfully weakens the strong generalization of CNN and improves the memory module to identify normal samples. Then, based on the few-shot learning approach, we learn a more compact normal data distribution and expand the margin between normal and anomalous events to improve the discriminant ability. Many experimental results demonstrate that our method is practical and feasible, and its performance is better than the existing detection methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2145275527",
                        "name": "Zihao Li"
                    },
                    {
                        "authorId": "2112452837",
                        "name": "Sisi Wu"
                    },
                    {
                        "authorId": "2108118174",
                        "name": "Yingmiao Zhang"
                    },
                    {
                        "authorId": "1778986",
                        "name": "Wanru Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In [36], they added a new update system to the memory module for"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "2c487159d7d712c195449f9a5fa77419c9d700e6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-01106",
                    "ArXiv": "2207.01106",
                    "DOI": "10.1109/CRV55824.2022.00031",
                    "CorpusId": 250264172
                },
                "corpusId": 250264172,
                "publicationVenue": {
                    "id": "3eaf5a5d-62f7-41b6-817e-92d78060c075",
                    "name": "Canadian Conference on Computer and Robot Vision",
                    "type": "conference",
                    "alternate_names": [
                        "CRV",
                        "Can Conf Comput Robot Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=583"
                },
                "url": "https://www.semanticscholar.org/paper/2c487159d7d712c195449f9a5fa77419c9d700e6",
                "title": "Anomaly Detection with Adversarially Learned Perturbations of Latent Space",
                "abstract": "Anomaly detection is to identify samples that do not conform to the distribution of the normal data. Due to the unavailability of anomalous data, training a supervised deep neural network is a cumbersome task. As such, unsupervised methods are preferred as a common approach to solve this task. Deep autoencoders have been broadly adopted as a base of many unsupervised anomaly detection methods. However, a notable shortcoming of deep autoencoders is that they provide insufficient representations for anomaly detection by generalizing to reconstruct outliers. In this work, we have designed an adversarial framework consisting of two competing components, an Adversarial Distorter, and an Autoencoder. The Adversarial Distorter is a convolutional encoder that learns to produce effective perturbations and the autoencoder is a deep convolutional neural network that aims to reconstruct the images from the perturbed latent feature space. The networks are trained with opposing goals in which the Adversarial Distorter produces perturbations that are applied to the en-coder's latent feature space to maximize the reconstruction error and the autoencoder tries to neutralize the effect of these perturbations to minimize it. When applied to anomaly detection, the proposed method learns semantically richer representations due to applying perturbations to the feature space. The proposed method outperforms the existing state-of-the-art methods in anomaly detection on image and video datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1752873904",
                        "name": "Vahid Reza Khazaie"
                    },
                    {
                        "authorId": "122738612",
                        "name": "A. Wong"
                    },
                    {
                        "authorId": "2060864798",
                        "name": "John Taylor Jewell"
                    },
                    {
                        "authorId": "49318589",
                        "name": "Y. Mohsenzadeh"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[44] further improved performance by introducing extra loss functions such as intra-class distance and inter-class distance, but its application scope was limited to the computer vision field."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "7e2769b93f15f95b4450fb16f97e232414bc6ef7",
                "externalIds": {
                    "DOI": "10.1155/2022/6418420",
                    "CorpusId": 248411997
                },
                "corpusId": 248411997,
                "publicationVenue": {
                    "id": "02a4454a-84c8-471c-9b40-cc045d4f3223",
                    "name": "Security and Communication Networks",
                    "type": "journal",
                    "alternate_names": [
                        "Secur Commun Netw"
                    ],
                    "issn": "1939-0122",
                    "url": "https://www.hindawi.com/journals/scn/",
                    "alternate_urls": [
                        "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1939-0122",
                        "http://www.interscience.wiley.com/journal/security"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7e2769b93f15f95b4450fb16f97e232414bc6ef7",
                "title": "Memory-Augmented Insider Threat Detection with Temporal-Spatial Fusion",
                "abstract": "Insider threat detection is important for the smooth operation and security protection of an organizational system. Most existing detection models establish historical baseline by reconstructing single-day and individual user behaviors, and then treat any outlier of the baseline as a threat. However, such methods ignore the temporal and spatial correlations between different activities, which result in an unsatisfying performance. To address such an issue, we propose a novel insider threat detection method, namely, Memory-Augmented Insider Threat Detection (MAITD), in this paper. Such an idea is motivated by the observation that the combination of individual model that focuses on historical baseline and group model that represents peer baseline can effectively identify the low-signal yet long-lasting insider threats, and reduce the possibility of false positives. To illustrate, our MAITD captures the temporal and spatial correlation of user behaviors by constructing compound behavioral matrix and common group model, and combines specific application scenarios to integrate the detection results. Moreover, it introduces the memory-augmented network into autoencoder to enlarge the reconstruction error of abnormal samples, thereby reducing the false negative rate. The experimental results on CERT dataset show that the instance-based and user-based AUCs of MAITD reach up to 87.54% and 94.56%, respectively, which significantly outperform previous works.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2129502772",
                        "name": "Dongyang Li"
                    },
                    {
                        "authorId": "13223344",
                        "name": "Linfu Yang"
                    },
                    {
                        "authorId": "2143622843",
                        "name": "Hongguang Zhang"
                    },
                    {
                        "authorId": "2145746470",
                        "name": "Xiaolei Wang"
                    },
                    {
                        "authorId": "1936569",
                        "name": "Linru Ma"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We also compare our method with the state-of-the-art video prediction methods, including FFP, latent space autoregression (LSA) [47], memory-guided normality method (MNN) [48], ADL [20], deep multi-branch mask network (DMMNet) [49], future frame prediction network (F2PN) [50] and non-local U-Net (NU-Net) [51].",
                "The performance of MNN is also influenced by the size of memory."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "32c82fa3e438521d010e7c7b95a7c01d61f2ceff",
                "externalIds": {
                    "DBLP": "journals/apin/LiLZ23",
                    "DOI": "10.1007/s10489-022-03488-2",
                    "CorpusId": 248315854
                },
                "corpusId": 248315854,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/32c82fa3e438521d010e7c7b95a7c01d61f2ceff",
                "title": "Future frame prediction based on generative assistant discriminative network for anomaly detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48161673",
                        "name": "Chaobo Li"
                    },
                    {
                        "authorId": "119885997",
                        "name": "Hongjun Li"
                    },
                    {
                        "authorId": "2116096948",
                        "name": "Guoan Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "And we observe that the methods which use memory networks to keep the representations, such as MemAE [7], MNAD-R [21], MNAD-P [21], and AMMC-Net [3], have a limited performance for anomaly detection on Avenue and ShanghaiTech.",
                "Within our best knowledge, we compare our AMSRC with stateof-the-art methods, including: (1) classic video anomaly detection methods: MPPCA [10], MPPC+SFA [19], and MDT [19]; (2) reconstruction-based methods: ConvAE [8], ConvLSTM-AE [17], MemAE [7], andMNAD-R [21]; (3) prediction-basedmethods: FramePred [13], MNAD-P [21], and VEC [31]; (4) hybrid and other methods: Stacked RNN [18], AMC [20], AnoPCN [29], AMMC-Net [3], and HF2-VAD [14].",
                "Reconstruction-based methods [7, 8, 17, 21] usually train an autoencoder on normal data and expect abnormal data to incur larger reconstruction errors at test time, making abnormal data detectable from normal ones."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "57007e8282be15329090fc34e759fe71b3782aed",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-04151",
                    "ArXiv": "2204.04151",
                    "DOI": "10.48550/arXiv.2204.04151",
                    "CorpusId": 248069156
                },
                "corpusId": 248069156,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/57007e8282be15329090fc34e759fe71b3782aed",
                "title": "A Video Anomaly Detection Framework based on Appearance-Motion Semantics Representation Consistency",
                "abstract": "Video anomaly detection refers to the identification of events that deviate from the expected behavior. Due to the lack of anomalous samples in training, video anomaly detection becomes a very challenging task. Existing methods almost follow a reconstruction or future frame prediction mode. However, these methods ignore the consistency between appearance and motion information of samples, which limits their anomaly detection performance. Anomalies only occur in the moving foreground of surveillance videos, so the semantics expressed by video frame sequences and optical flow without background information in anomaly detection should be highly consistent and significant for anomaly detection. Based on this idea, we propose Appearance-Motion Semantics Representation Consistency (AMSRC), a framework that uses normal data's appearance and motion semantic representation consistency to handle anomaly detection. Firstly, we design a two-stream encoder to encode the appearance and motion information representations of normal samples and introduce constraints to further enhance the consistency of the feature semantics between appearance and motion information of normal samples so that abnormal samples with low consistency appearance and motion feature representation can be identified. Moreover, the lower consistency of appearance and motion features of anomalous samples can be used to generate predicted frames with larger reconstruction error, which makes anomalies easier to spot. Experimental results demonstrate the effectiveness of the proposed method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2146351387",
                        "name": "Xiangyu Huang"
                    },
                    {
                        "authorId": "8132058",
                        "name": "Caidan Zhao"
                    },
                    {
                        "authorId": "2136929844",
                        "name": "Yilin Wang"
                    },
                    {
                        "authorId": "2146254703",
                        "name": "Zhiqiang Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The trained models for MNAD and MOVAD on ShanghaiTech dataset are not publicly available.",
                "Performance (AUC) drop in FFPN [18], MNAD [23], and MOVAD [7] due to the Slow-Fast-Freeze effect.",
                "For detecting anomalies, both MNAD and FFPN compute the Peak Signal to Noise Ratio (PSNR) between the actual frame and predicted frame.",
                "Performance drops of FFPN [18] with adversarial ShanghaiTech dataset (top), MNAD [23] with adversarial Avenue dataset (middle), MOVAD [7] with adversarial Avenue dataset (bottom).",
                "(iii) Finally, we used our new datasets simulating the Wi-Fi deauthentication attack to evaluate performance of several state-of-the-art DNNbased anomaly detection methods: Future Frame Prediction [18], Memory-guided Normality for Anomaly Detection (MNAD) [23], Modular Online Video Anomaly Detector (MOVAD) [7].",
                "The recent DNN-based methods can be categorized into two main groups, prediction-based [4, 6, 16, 18] and reconstructionbased [9, 11, 20, 22, 23].",
                "We notice that the AUC drops from 0.855 to 0.795 for the FFPN approach and from 0.885 to 0.819 for the MNAD model.",
                "In this section, we evaluate the performance of existing state-of-the-art approaches, namely the Future Frame Prediction (FFPN) [18], Memory-guided Normality for Anomaly Detection (MNAD) [23], and Modular Online Video Anomaly Detector (MOVAD) [7] on the generated adversarial datasets."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3a5cba9420e8097218acf4e6772b63e469afdaa0",
                "externalIds": {
                    "ArXiv": "2204.03141",
                    "DBLP": "journals/corr/abs-2204-03141",
                    "DOI": "10.1109/CVPRW56347.2022.00034",
                    "CorpusId": 248006351
                },
                "corpusId": 248006351,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3a5cba9420e8097218acf4e6772b63e469afdaa0",
                "title": "Adversarial Machine Learning Attacks Against Video Anomaly Detection Systems",
                "abstract": "Anomaly detection in videos is an important computer vision problem with various applications including auto-mated video surveillance. Although adversarial attacks on image understanding models have been heavily investigated, there is not much work on adversarial machine learning targeting video understanding models and no previous work which focuses on video anomaly detection. To this end, we investigate an adversarial machine learning attack against video anomaly detection systems, that can be implemented via an easy-to-perform cyber-attack. Since surveillance cameras are usually connected to the server running the anomaly detection model through a wireless network, they are prone to cyber-attacks targeting the wireless connection. We demonstrate how Wi-Fi deauthentication attack, a notoriously easy-to-perform and effective denial-of-service (DoS) attack, can be utilized to generate adversarial data for video anomaly detection systems. Specifically, we apply several effects caused by the Wi-Fi deauthentication attack on video quality (e.g., slow down, freeze, fast forward, low resolution) to the popular bench-mark datasets for video anomaly detection. Our experiments with several state-of-the-art anomaly detection models show that the attackers can significantly undermine the reliability of video anomaly detection systems by causing frequent false alarms and hiding physical anomalies from the surveillance system.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2161662354",
                        "name": "Furkan Mumcu"
                    },
                    {
                        "authorId": "115636521",
                        "name": "Keval Doshi"
                    },
                    {
                        "authorId": "79595155",
                        "name": "Yasin Y\u0131lmaz"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Memory guided normality for anomaly detection is proposed in (Park et al., 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "6fed66c59da242dd5fcc8ee233cf6ea142fcd48d",
                "externalIds": {
                    "DOI": "10.3389/fenrg.2022.856635",
                    "CorpusId": 247980718
                },
                "corpusId": 247980718,
                "publicationVenue": {
                    "id": "757ec547-4fbf-4010-b6ae-c6b833ccd3a4",
                    "name": "Frontiers in Energy Research",
                    "type": "journal",
                    "alternate_names": [
                        "Front Energy Res"
                    ],
                    "issn": "2296-598X",
                    "url": "http://www.frontiersin.org/Energy_Research",
                    "alternate_urls": [
                        "https://www.frontiersin.org/journals/energy-research",
                        "http://www.frontiersin.org/Energy_Research/archive"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6fed66c59da242dd5fcc8ee233cf6ea142fcd48d",
                "title": "Anomaly Detection of Hydropower Units Based on Recurrent Neural Network",
                "abstract": "Anomaly detection for hydraulic turbine unit has an important role in hydropower system. In hydropower systems, different components will produce n-dimensional heterogeneous time series with different characteristics at all times. Due to the characteristic evolution and time dependence, vibration-based anomaly detection for hydraulic turbine unit is extremely challenging. In this paper, we propose a conditional quantile regression based recurrent neural network (QRNN), which models the time dependence and probability distribution between random variables. The proposed method aims to extract the actual representation patterns from the fitted models and it can effectively detect anomalies in the non-uniform time series of feature evolution. The experimental results show that the proposed method has better accuracy in anomaly detection (error reduction by 34%) than the traditional method, and saves at least 25.6% of execution time.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2068239052",
                        "name": "Lei Xiong"
                    },
                    {
                        "authorId": "49721729",
                        "name": "Jiajun Liu"
                    },
                    {
                        "authorId": "2108022674",
                        "name": "Feng Yang"
                    },
                    {
                        "authorId": "2138290361",
                        "name": "Gang Zhang"
                    },
                    {
                        "authorId": "144562617",
                        "name": "Jian Dang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "045e1882054de185d8205d974810e0918346764c",
                "externalIds": {
                    "DBLP": "journals/jksucis/KimYLK22",
                    "DOI": "10.1016/j.jksuci.2022.04.011",
                    "CorpusId": 248488896
                },
                "corpusId": 248488896,
                "publicationVenue": {
                    "id": "5d2ac1a1-1fcd-4505-8b9d-5484ad5ffa66",
                    "name": "Journal of King Saud University: Computer and Information Sciences",
                    "type": "journal",
                    "alternate_names": [
                        "Journal of King Saud University - Computer and Information Sciences",
                        "J King Saud Univ Comput Inf Sci",
                        "J King Saud Univ  Comput Inf Sci"
                    ],
                    "issn": "1319-1578",
                    "url": "https://www.journals.elsevier.com/journal-of-king-saud-university-computer-and-information-sciences/",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/13191578"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/045e1882054de185d8205d974810e0918346764c",
                "title": "Video anomaly detection using Cross U-Net and cascade sliding window",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2124917681",
                        "name": "Yujun Kim"
                    },
                    {
                        "authorId": "2151482780",
                        "name": "Jin-Yong Yu"
                    },
                    {
                        "authorId": "1880611",
                        "name": "Euijong Lee"
                    },
                    {
                        "authorId": "9433532",
                        "name": "Young-Gab Kim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Most existing anomaly detection methods, such as autoencoder-base methods [13, 18, 38, 71, 73], GAN-base methods [39, 45, 48, 68], selfsupervised methods [2, 11, 12, 25, 50, 56, 60], and one-class classification methods [7,8,40,43], assume that only normal data can be accessed during training."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6a4f7514cf25a36b746b09eab4a2576a12961cb0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-14506",
                    "ArXiv": "2203.14506",
                    "DOI": "10.1109/CVPR52688.2022.00724",
                    "CorpusId": 247763083
                },
                "corpusId": 247763083,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6a4f7514cf25a36b746b09eab4a2576a12961cb0",
                "title": "Catching Both Gray and Black Swans: Open-set Supervised Anomaly Detection*",
                "abstract": "Despite most existing anomaly detection studies assume the availability of normal training samples only, a few labeled anomaly examples are often available in many real-world applications, such as defect samples identified during random quality inspection, lesion images confirmed by radiologists in daily medical screening, etc. These anomaly examples provide valuable knowledge about the application-specific abnormality, enabling significantly improved detection of similar anomalies in some recent models. However, those anomalies seen during training often do not illustrate every possible class of anomaly, rendering these models ineffective in generalizing to unseen anomaly classes. This paper tackles open-set supervised anomaly detection, in which we learn detection models using the anomaly examples with the objective to detect both seen anomalies (\u2018gray swans\u2019) and unseen anomalies (\u2018black swans\u2019). We propose a novel approach that learns disentangled representations of abnormalities illustrated by seen anomalies, pseudo anomalies, and latent residual anomalies (i.e., samples that have unusual residuals compared to the normal data in a latent space), with the last two abnormalities designed to detect unseen anomalies. Extensive experiments on nine real-world anomaly detection datasets show superior performance of our model in detecting seen and unseen anomalies under diverse settings. Code and data are available at: https://github.com/choubo/DRA",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2153255258",
                        "name": "Choubo Ding"
                    },
                    {
                        "authorId": "3224619",
                        "name": "Guansong Pang"
                    },
                    {
                        "authorId": "12459603",
                        "name": "Chunhua Shen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Methods in [4, 5] apply the memory module to restrict the space of prototypical normal patterns, which prevents abnormal patterns from being decoded.",
                "Moreover, in addition to the reconstruction loss (L2 loss), the feature compactness loss and feature separateness loss [5] are applied in order to enhance the memory space\u2019s representativeness and discriminability, which are expressed as follows."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "3b838d0f2fe17fbbda0fd50a18e717cd5b15adeb",
                "externalIds": {
                    "DBLP": "conf/isbi/LiuDAW22",
                    "DOI": "10.1109/ISBI52829.2022.9761586",
                    "CorpusId": 248407966
                },
                "corpusId": 248407966,
                "publicationVenue": {
                    "id": "a38e0d3d-6929-4868-b4e4-af8bbacf711e",
                    "name": "IEEE International Symposium on Biomedical Imaging",
                    "type": "conference",
                    "alternate_names": [
                        "ISBI",
                        "International Symposium on Biomedical Imaging",
                        "Int Symp Biomed Imaging",
                        "IEEE Int Symp Biomed Imaging"
                    ],
                    "issn": "1945-7928",
                    "alternate_issns": [
                        "1945-8452"
                    ],
                    "url": "http://www.biomedicalimaging.org/",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3b838d0f2fe17fbbda0fd50a18e717cd5b15adeb",
                "title": "Unsupervised Retinal Lesion Detection by Learning to Restore Corrupted Fundus Images",
                "abstract": "Anomaly detection is an important topic in medical image analysis, and some unsupervised deep learning methods have been proposed for lesions detection in medical images. However, these unsupervised methods show poor performance on pixel-level lesion detection in fundus images, since retinal images contain many small lesions and retinal lesions usually show diversity in shapes, sizes, textures, and positions. This paper proposes a new unsupervised framework to solve this problem, in which a high-accuracy anomaly-free image will be reconstructed for a given retinal image, and thus diverse lesions are well separated by comparing these two images. In our framework, an autoencoder augmented by a memory module is forced to reconstruct high-accuracy anomaly-free retinal images from corrupted retinal images with synthetic lesions generated from Perlin noise during training, by which real lesions in anomalous images can be removed on the inference stage. Meanwhile, a false positive suppression algorithm (FPSA) is also proposed to reduce false positives caused by regions with low reconstruction quality. Comparative experiments show that our proposed framework achieves advanced performance and outperforms the state-of-the-art methods on the task of retinal lesion detection from fundus images.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "46935802",
                        "name": "Hao Liu"
                    },
                    {
                        "authorId": "2108268528",
                        "name": "Yuchen Du"
                    },
                    {
                        "authorId": "82327783",
                        "name": "Chengyang An"
                    },
                    {
                        "authorId": "40367852",
                        "name": "Lisheng Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "095084fb7eb10788503ca214b4303e9cef05f499",
                "externalIds": {
                    "ArXiv": "2203.13716",
                    "DBLP": "journals/corr/abs-2203-13716",
                    "DOI": "10.1109/TIP.2022.3204217",
                    "CorpusId": 247748673,
                    "PubMed": "36094978"
                },
                "corpusId": 247748673,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/095084fb7eb10788503ca214b4303e9cef05f499",
                "title": "Stabilizing Adversarially Learned One-Class Novelty Detection Using Pseudo Anomalies",
                "abstract": "Recently, anomaly scores have been formulated using reconstruction loss of the adversarially learned generators and/or classification loss of discriminators. Unavailability of anomaly examples in the training data makes optimization of such networks challenging. Attributed to the adversarial training, performance of such models fluctuates drastically with each training step, making it difficult to halt the training at an optimal point. In the current study, we propose a robust anomaly detection framework that overcomes such instability by transforming the fundamental role of the discriminator from identifying real vs. fake data to distinguishing good vs. bad quality reconstructions. For this purpose, we propose a method that utilizes the current state as well as an old state of the same generator to create good and bad quality reconstruction examples. The discriminator is trained on these examples to detect the subtle distortions that are often present in the reconstructions of anomalous data. In addition, we propose an efficient generic criterion to stop the training of our model, ensuring elevated performance. Extensive experiments performed on six datasets across multiple domains including image and video based anomaly detection, medical diagnosis, and network security, have demonstrated excellent performance of our approach.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "34148354",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "2108602720",
                        "name": "Jin-ha Lee"
                    },
                    {
                        "authorId": "81223085",
                        "name": "Arif Mahmood"
                    },
                    {
                        "authorId": "145345698",
                        "name": "M. Astrid"
                    },
                    {
                        "authorId": "3193599",
                        "name": "Seung-Ik Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Video anomaly detection (VAD) aims to identify anomalous events on both the object level [7, 22, 68] and frame level [35, 39, 51] by techniques such as skeleton trajectory modeling [43], weakly supervised learning [69], attention [47], temporal pose graph [38], self-supervised learning [10] and autoencoders [3]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "2355a9d63a0b874836fa87ca38f144343725b507",
                "externalIds": {
                    "ArXiv": "2203.03800",
                    "DBLP": "journals/corr/abs-2203-03800",
                    "DOI": "10.1109/CVPR52688.2022.01331",
                    "CorpusId": 247315245
                },
                "corpusId": 247315245,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2355a9d63a0b874836fa87ca38f144343725b507",
                "title": "Unknown-Aware Object Detection: Learning What You Don't Know from Videos in the Wild",
                "abstract": "Building reliable object detectors that can detect out-of-distribution (OOD) objects is critical yet underexplored. One of the key challenges is that models lack supervision signals from unknown data, producing over-confident predictions on OOD objects. We propose a new unknown-aware object detection framework through Spatial-Temporal Unknown Distillation (STUD), which dis-tills unknown objects from videos in the wild and meaningfully regularizes the model's decision boundary. STUD first identifies the unknown candidate object proposals in the spatial dimension, and then aggregates the candidates across multiple video frames to form a diverse set of unknown objects near the decision boundary. Along-side, we employ an energy-based uncertainty regularization loss, which contrastively shapes the uncertainty space between the in-distribution and distilled unknown objects. STUD establishes the state-of-the-art performance on OOD detection tasks for object detection, reducing the FPR95 score by over 10% compared to the previous best method. Code is available at https://github.com/deep/earning-wisc/stud.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "151480429",
                        "name": "Xuefeng Du"
                    },
                    {
                        "authorId": "153316152",
                        "name": "Xin Wang"
                    },
                    {
                        "authorId": "2158115954",
                        "name": "Gabriel Gozum"
                    },
                    {
                        "authorId": "1527103472",
                        "name": "Yixuan Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "More specifically, we neither use the normal class annotations as in one class classification (OCC) approaches [12, 37, 54], nor binary annotations used by the weakly supervised anomaly detection systems [50,67,69,74].",
                "Note that, the term \u2018unsupervised\u2019 in literature often refers to OCC approaches which assume all normal training data [11, 37, 64, 66]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "568a93409f91e959b075ffee9435204b4f15569c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-03962",
                    "ArXiv": "2203.03962",
                    "DOI": "10.1109/CVPR52688.2022.01433",
                    "CorpusId": 247315313
                },
                "corpusId": 247315313,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/568a93409f91e959b075ffee9435204b4f15569c",
                "title": "Generative Cooperative Learning for Unsupervised Video Anomaly Detection",
                "abstract": "Video anomaly detection is well investigated in weakly-supervised and one-class classification (OCC) settings. However, unsupervised video anomaly detection methods are quite sparse, likely because anomalies are less frequent in occurrence and usually not well-defined, which when coupled with the absence of ground truth supervision, could adversely affect the performance of the learning algorithms. This problem is challenging yet rewarding as it can completely eradicate the costs of obtaining laborious annotations and enable such systems to be deployed without human intervention. To this end, we propose a novel unsupervised Generative Cooperative Learning (GCL) approach for video anomaly detection that exploits the low frequency of anomalies towards building a cross-supervision between a generator and a discriminator. In essence, both networks get trained in a cooperative fashion, thereby allowing unsupervised learning. We conduct extensive experiments on two large-scale video anomaly detection datasets, UCF crime and ShanghaiTech. Consistent improvement over the existing state-of-the-art unsupervised and OCC methods corroborate the effectiveness of our approach.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "34148354",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "81223085",
                        "name": "Arif Mahmood"
                    },
                    {
                        "authorId": "40256699",
                        "name": "M. H. Khan"
                    },
                    {
                        "authorId": "151136071",
                        "name": "Mattia Segu"
                    },
                    {
                        "authorId": "1807197",
                        "name": "F. Yu"
                    },
                    {
                        "authorId": "3193599",
                        "name": "Seung-Ik Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Similarly to [12], discriminative normality action features prototypes are learnt based on nearest neighbor distances within the memory space via a loss that favors compactness of data samples around prototypes:",
                "Similarly to [11, 12], we incorporate a memory block in our framework in order to model diverse normality patterns.",
                "In addition, training 3 is much faster than in [12]: only 70 min on ShanghaiTech, 9 min on Avenue and 4 min on UCSD ped2 with a single NVIDIA TITAN X (PASCAL) GPU.",
                "\u2217Equal contributions reconstruction-based methods [10, 11, 12, 4, 13].",
                "Instead, we propose to tackle these challenges by extending the mainstream reconstruction assumption on which most state-of-the-art methods [3, 11, 12, 13] are implicitly based: Given a normality model, normal observations are easier to reconstruct from a low-dimensional representation than abnormal observations.",
                "Contrarily to [12], we incorporate a third term LOLE that adds orthogonality constraints within the memory space.",
                "We also use the same triplet loss Ltr introduced in [12].",
                "Similar to [12] the most similar memory item mk to the query h is defined as the soft nearest neighbor:"
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "ad4355016b60c83ac585bff29b124ee1a9767d14",
                "externalIds": {
                    "DBLP": "conf/icip/BergaouiNSLGA22",
                    "ArXiv": "2203.03677",
                    "DOI": "10.1109/ICIP46576.2022.9897259",
                    "CorpusId": 247315184
                },
                "corpusId": 247315184,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ad4355016b60c83ac585bff29b124ee1a9767d14",
                "title": "Object-Centric and Memory-Guided Normality Reconstruction for Video Anomaly Detection",
                "abstract": "This paper addresses video anomaly detection problem for videosurveillance. Due to the inherent rarity and heterogeneity of abnormal events, the problem is viewed as a normality modeling strategy, in which our model learns object-centric normal patterns without seeing anomalous samples during training. The main contributions consist in coupling pre-trained object-level action features prototypes with a cosine distance-based anomaly estimation function, therefore extending previous methods by introducing additional constraints to the mainstream reconstruction-based strategy. Our framework leverages both appearance and motion information to learn object-level behavior and captures prototypical patterns within a memory module. Experiments on several well-known datasets demonstrate the effectiveness of our method as it outperforms current state-of-the-art on most relevant spatio-temporal evaluation metrics.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2158115243",
                        "name": "K. Bergaoui"
                    },
                    {
                        "authorId": "2158115248",
                        "name": "Yassine Naji"
                    },
                    {
                        "authorId": "2592210",
                        "name": "Aleksandr Setkov"
                    },
                    {
                        "authorId": "37995240",
                        "name": "Ang\u00e9lique Loesch"
                    },
                    {
                        "authorId": "1751461",
                        "name": "M. Gouiff\u00e8s"
                    },
                    {
                        "authorId": "2641858",
                        "name": "Romaric Audigier"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To ensure the comparability between different methods, we calculate AUC for the frame-level prediction [4,5,7].",
                "[5] propose to use a memory module with a new update scheme where items in the memory record prototypical patterns of normal data, and it represents the SOTA solution of unsupervised anomaly detection."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "b27060be59c1171410bffe1c9a0e11f110d3adc9",
                "externalIds": {
                    "DBLP": "journals/sivp/XuLXW22",
                    "DOI": "10.1007/s11760-022-02174-7",
                    "CorpusId": 247279744
                },
                "corpusId": 247279744,
                "publicationVenue": {
                    "id": "11437c2b-f0a0-4db5-ac17-56dd7a223080",
                    "name": "Signal, Image and Video Processing",
                    "type": "journal",
                    "alternate_names": [
                        "Signal Image Video Process"
                    ],
                    "issn": "1863-1703",
                    "url": "https://link.springer.com/journal/11760"
                },
                "url": "https://www.semanticscholar.org/paper/b27060be59c1171410bffe1c9a0e11f110d3adc9",
                "title": "Motion-aware future frame prediction for video anomaly detection based on saliency perception",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118533944",
                        "name": "Haitao Xu"
                    },
                    {
                        "authorId": "1943870",
                        "name": "Weibin Liu"
                    },
                    {
                        "authorId": "145767614",
                        "name": "Weiwei Xing"
                    },
                    {
                        "authorId": "50652909",
                        "name": "Xiang Wei"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "b162cd9e3578269873548224c119e525d86c52c7",
                "externalIds": {
                    "DBLP": "journals/di/KhaireK22",
                    "DOI": "10.1016/j.fsidi.2022.301346",
                    "CorpusId": 246507418
                },
                "corpusId": 246507418,
                "publicationVenue": {
                    "id": "edd9eb69-fde5-4f95-9170-ef55eaa93377",
                    "name": "Digital Investigation. The International Journal of Digital Forensics and Incident Response",
                    "type": "journal",
                    "alternate_names": [
                        "Digital Investigation",
                        "Digit Investig",
                        "Digit Investig Int J Digit Forensics Incid Response"
                    ],
                    "issn": "1742-2876",
                    "alternate_issns": [
                        "1873-202X"
                    ],
                    "url": "http://www.sciencedirect.com/science/journal/17422876"
                },
                "url": "https://www.semanticscholar.org/paper/b162cd9e3578269873548224c119e525d86c52c7",
                "title": "A semi-supervised deep learning based video anomaly detection framework using RGB-D for surveillance of real-world critical environments",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "46234730",
                        "name": "Pushpajit A. Khaire"
                    },
                    {
                        "authorId": "2118921250",
                        "name": "Praveen Kumar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To discourage this behavior, Park et al. (2020) introduce MNAD, an autoencoder with an integrated memory module."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "e26851c89afcfb1a0fe00292590c9f6e830c4ec0",
                "externalIds": {
                    "DBLP": "journals/ijcv/BergmannBFSS22",
                    "DOI": "10.1007/s11263-022-01578-9",
                    "CorpusId": 247063535
                },
                "corpusId": 247063535,
                "publicationVenue": {
                    "id": "939ee07c-6009-43f8-b884-69238b40659e",
                    "name": "International Journal of Computer Vision",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Comput Vis"
                    ],
                    "issn": "0920-5691",
                    "url": "https://www.springer.com/computer/image+processing/journal/11263",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11263",
                        "http://link.springer.com/journal/11263"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e26851c89afcfb1a0fe00292590c9f6e830c4ec0",
                "title": "Beyond Dents and Scratches: Logical Constraints in Unsupervised Anomaly Detection and Localization",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "33609329",
                        "name": "Paul Bergmann"
                    },
                    {
                        "authorId": "2045281292",
                        "name": "Kilian Batzner"
                    },
                    {
                        "authorId": "34194478",
                        "name": "Michael Fauser"
                    },
                    {
                        "authorId": "23633923",
                        "name": "David Sattlegger"
                    },
                    {
                        "authorId": "36494513",
                        "name": "C. Steger"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following [2, 11, 4, 7, 5, 10, 9, 8], we normalize PSNR(Pt,Pt) of each video clip to the range [0, 1] to obtain the final normality score St.",
                "Since the first five frames of each clip cannot be predicted, they are ignored in the evaluation, following other prediction-based methods [4, 6, 5, 9].",
                "Following this circumstance, most of the deep-learning based VAD models [4, 5, 6, 7, 8, 9, 10] are trained to recognize the normal patterns during training, and detect the frames with the outlying patterns during testing.",
                "Dataset Model STAN [10] Abn GAN [25] HyAE [7] Mem AE [11] AD [26] IntAE [6] MNAD -Recon [5] Fast Ano [9] Base Base+R Base+R+M (Ours) Avenue [1] 81."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "b3d2ec82e9c26569b68db083426b804b59a9562c",
                "externalIds": {
                    "ArXiv": "2202.06256",
                    "DBLP": "journals/corr/abs-2202-06256",
                    "CorpusId": 246822525
                },
                "corpusId": 246822525,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b3d2ec82e9c26569b68db083426b804b59a9562c",
                "title": "RandomSEMO: Normality Learning Of Moving Objects For Video Anomaly Detection",
                "abstract": "Recent anomaly detection algorithms have shown powerful performance by adopting frame predicting autoencoders. However, these methods face two challenging circumstances. First, they are likely to be trained to be excessively powerful, generating even abnormal frames well, which leads to failure in detecting anomalies. Second, they are distracted by the large number of objects captured in both foreground and background. To solve these problems, we propose a novel superpixel-based video data transformation technique named Random Superpixel Erasing on Moving Objects (RandomSEMO) and Moving Object Loss (MOLoss), built on top of a simple lightweight autoencoder. RandomSEMO is applied to the moving object regions by randomly erasing their superpixels. It enforces the network to pay attention to the foreground objects and learn the normal features more effectively, rather than simply predicting the future frame. Moreover, MOLoss urges the model to focus on learning normal objects captured within RandomSEMO by amplifying the loss on the pixels near the moving objects. The experimental results show that our model outperforms state-of-the-arts on three benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109124052",
                        "name": "Chaewon Park"
                    },
                    {
                        "authorId": "2109503396",
                        "name": "Minhyeok Lee"
                    },
                    {
                        "authorId": "1387831061",
                        "name": "Myeongah Cho"
                    },
                    {
                        "authorId": "39847092",
                        "name": "Sangyoun Lee"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "2e6088d5f1081f2b46295d8783a5c2642ec35041",
                "externalIds": {
                    "DBLP": "journals/pr/ChangTXLZSY22",
                    "MAG": "3190318906",
                    "DOI": "10.1016/J.PATCOG.2021.108213",
                    "CorpusId": 238691174
                },
                "corpusId": 238691174,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2e6088d5f1081f2b46295d8783a5c2642ec35041",
                "title": "Video anomaly detection with spatio-temporal dissociation",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2219835649",
                        "name": "Y. Chang"
                    },
                    {
                        "authorId": "143611428",
                        "name": "Zhigang Tu"
                    },
                    {
                        "authorId": "2113723004",
                        "name": "Wei Xie"
                    },
                    {
                        "authorId": "2151264226",
                        "name": "B. Luo"
                    },
                    {
                        "authorId": "2145401982",
                        "name": "Shifu Zhang"
                    },
                    {
                        "authorId": "2451742",
                        "name": "H. Sui"
                    },
                    {
                        "authorId": "48837492",
                        "name": "Junsong Yuan"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "7fd052d40660d65c8497599794467812b78e1d0b",
                "externalIds": {
                    "DBLP": "journals/pr/ZhongCJR22",
                    "MAG": "3199265481",
                    "DOI": "10.1016/j.patcog.2021.108336",
                    "CorpusId": 240573591
                },
                "corpusId": 240573591,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7fd052d40660d65c8497599794467812b78e1d0b",
                "title": "A cascade reconstruction model with generalization ability evaluation for anomaly detection in videos",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48751559",
                        "name": "Yuanhong Zhong"
                    },
                    {
                        "authorId": "2109481146",
                        "name": "Xia Chen"
                    },
                    {
                        "authorId": null,
                        "name": "Jinyang Jiang"
                    },
                    {
                        "authorId": "93738696",
                        "name": "Fan Ren"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In the context of one-class distillation for unsupervised AD, the student model is expected to generate highly different representations from the teacher when the queries are anomalous samples [11, 26].",
                "To address this issue, memory mechanism [11, 16, 26] , image masking strategy [42, 46] and pseudo-anomaly [28, 45] are incorporated in reconstruction-based methods.",
                "These tasks include, but not limited to, sample reconstruction [2,5,11,16,26,34,38,48], pseudo-outlier augmenFigure 1.",
                "Notably, traditional AE-based methods [5, 11, 16, 26] detect anomalies utilising pixel differences, whereas we perform discrimination with dense descriptive features."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3b3aefbbdb64e5812f133f220b3f129a36a30065",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-10703",
                    "ArXiv": "2201.10703",
                    "DOI": "10.1109/CVPR52688.2022.00951",
                    "CorpusId": 246285427
                },
                "corpusId": 246285427,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3b3aefbbdb64e5812f133f220b3f129a36a30065",
                "title": "Anomaly Detection via Reverse Distillation from One-Class Embedding",
                "abstract": "Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective \u201creverse distillation\u201d paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multi-scale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but aban-dons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2153490019",
                        "name": "Hanqiu Deng"
                    },
                    {
                        "authorId": "2155444872",
                        "name": "Xingyu Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Therefore detecting abnormal behavior in video automatically has attracted increasing attentions in recent years [22, 43, 55, 56, 73, 86]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "9835b0730e616b9377c87ab09fd67ac39a39761e",
                "externalIds": {
                    "DBLP": "journals/apin/JiangWGPZW22",
                    "DOI": "10.1007/s10489-021-02881-7",
                    "CorpusId": 250095229
                },
                "corpusId": 250095229,
                "publicationVenue": {
                    "id": "2c01e8b4-1888-4cf0-91e6-6b1213cdca16",
                    "name": "Applied intelligence (Boston)",
                    "type": "journal",
                    "alternate_names": [
                        "Applied Intelligence",
                        "Appl Intell",
                        "Appl intell t"
                    ],
                    "issn": "0924-669X",
                    "url": "https://link.springer.com/journal/10489"
                },
                "url": "https://www.semanticscholar.org/paper/9835b0730e616b9377c87ab09fd67ac39a39761e",
                "title": "Abnormal behavior detection using streak flow acceleration",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47911425",
                        "name": "Jun Jiang"
                    },
                    {
                        "authorId": "2115554681",
                        "name": "Xinyue Wang"
                    },
                    {
                        "authorId": "39810756",
                        "name": "Mingliang Gao"
                    },
                    {
                        "authorId": "49106674",
                        "name": "Jinfeng Pan"
                    },
                    {
                        "authorId": "2115459969",
                        "name": "Chengyuan Zhao"
                    },
                    {
                        "authorId": "2174161012",
                        "name": "Jia Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, this framework usually misidentifies the small probability events in a scene as the abnormal events, because it is infeasible to collect all possible normal events [41, 52].",
                "However, it remains as an challenging task due to the unbounded and rare property of abnormal events [18, 37, 41, 52]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "87721cf4dccc60e640205d13a0f329416984d596",
                "externalIds": {
                    "DBLP": "journals/tjs/MaZ22",
                    "DOI": "10.1007/s11227-021-04190-9",
                    "CorpusId": 248120109
                },
                "corpusId": 248120109,
                "publicationVenue": {
                    "id": "26ed29a9-64ce-4d6c-9024-8b022fd2fe22",
                    "name": "Journal of Supercomputing",
                    "type": "journal",
                    "alternate_names": [
                        "The Journal of Supercomputing",
                        "J Supercomput"
                    ],
                    "issn": "0920-8542",
                    "url": "http://www.springer.com/computer/programming/journal/11227",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11227",
                        "https://www.springer.com/computer/swe/journal/11227?changeHeader"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/87721cf4dccc60e640205d13a0f329416984d596",
                "title": "Attention-based framework for weakly supervised video anomaly detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "153176779",
                        "name": "Hualin Ma"
                    },
                    {
                        "authorId": "2144195455",
                        "name": "Liyan Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Four models apply different methods to generate diversified trajectories, i.e., Social-STGCNN and SGCN model the pedestrian trajectories as a bi-variate Gaussian distribution, while STAR and STGAT add the random Gaussian noise to their predictions.",
                "We use SGCN\u2019s Shi et al. (2021a) TP model architecture, and follow the loss function and anomaly scoring function designed by 4 stat-of-the-arts AD methods: MNAD Park et al. (2020), P-NET Zhou et al. (2020), RSRAE Lai et al. (2020), and GEPC Markovitz et al. (2020), and thus construct some trajectory ADmodels.",
                "C. Wang, C. Liang, X. Chen, H. Wang: Preprint submitted to Elsevier Page 8 of 14\nIn addition, we analyze 4 state-of-the-arts stochastic TP models, including Social-STGCNN Mohamed et al. (2020), STAR Yu et al. (2020), STGAT Huang et al. (2019) and SGCN Shi et al. (2021a).",
                "Solutions of the each stage are extracted from two parts: (1) 5 state-of-the-arts AD models analyzed in Table 1; (2) 5 state-of-the-art TP models, including SGCN Shi et al. (2021a) (\ue2391), LB-EBM Pang et al."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8b38afe9d895239adb02fcd00b612fefddc0dc04",
                "externalIds": {
                    "DBLP": "journals/pr/WangLCW23",
                    "ArXiv": "2201.02941",
                    "DOI": "10.1016/j.patcog.2023.109559",
                    "CorpusId": 245837363
                },
                "corpusId": 245837363,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8b38afe9d895239adb02fcd00b612fefddc0dc04",
                "title": "Identifying effective trajectory predictions under the guidance of trajectory anomaly detection model",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "35504064",
                        "name": "Chunnan Wang"
                    },
                    {
                        "authorId": "2154311465",
                        "name": "Cheng Liang"
                    },
                    {
                        "authorId": "2143735745",
                        "name": "Xiang Chen"
                    },
                    {
                        "authorId": "2145338519",
                        "name": "Hongzhi Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Events that cannot be described by the normal model during the test are considered anomalies [4], which are usually judged based on reconstruction or prediction errors.",
                "The proposed method is an attention-based encoder-decoder, and achieves comparable\nperformance to the Frame-Pred method with an AUC of 71.0%, which is better than 70.5% of MNAD.",
                "MNAD uses several memory items to record prototypical patterns of normal activities, but the ShanghaiTech dataset contains a variety of scenarios.",
                "[4] propose an update method of memory module, which uses the coding features of sample to retrieve memory items and update them during training and testing.",
                "In order to evaluate the proposed method, we compare the AUC of the proposed method with Conv-AE [8], Stacked RNN [7], MemAE-nonSpar [2], Frame-Pred [5], MemAE [2] and MNAD [4] on the ShanghaiTech dataset.",
                "In order to evaluate the proposed method, we compare the AUC of the proposed method with MPPCA [14], MPPC+SFA [11], MDT [11], Unmasking [15], Conv-AE [8], ConvLSTMAE [17], Stacked RNN [7], Frame-Pred [5], MemAE [2] and MNAD [4] on the UCSD Ped1 dataset.",
                "Some heatmaps of normalized prediction errors of the proposed method and MNAD for anomaly detection on the UCSD Ped1 test set are shown in Fig."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "472fe70d6869a678735c6d6227f08a42a5206a90",
                "externalIds": {
                    "DOI": "10.1109/ICCRD54409.2022.9730481",
                    "CorpusId": 247477653
                },
                "corpusId": 247477653,
                "publicationVenue": {
                    "id": "37c759ea-5c9d-4517-bbfa-e6285a7e8e7a",
                    "name": "International Conference on Computer Research and Development",
                    "type": "conference",
                    "alternate_names": [
                        "CRD",
                        "Int Conf Comput Res Dev"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/472fe70d6869a678735c6d6227f08a42a5206a90",
                "title": "An Attention-based U-Net Network for Anomaly Detection in Crowded Scenes",
                "abstract": "Anomaly detection in surveillance video is of great significance for public safety. Deep autoencoder has been widely used in anomaly detection. Because of its good generalization ability, sometimes abnormal samples can still be reconstructed very well. Some scholars use memory module constructed by using the normal samples to reconstruct the test samples. The memory items need to be retrieved and updated during the training and testing process, hence more memory space is required to store memory module, which greatly increases the training and test costs. We tackle the problem of the excessive generalization ability of autoencoder from a new perspective. We introduce an attention mechanism to propose an attention-based U-Net network to detect anomalies. The network adds an attention module before the skip connection of U -Net network, so that the model pays more attention to the foreground targets. During the training process, the normal foreground targets are learned more fully. Therefore, in the test, the proposed method can achieve more accurate prediction of normal targets that appear frequently, so that the rare abnormal targets can be highlighted because of the large prediction errors. We conduct experiments on real surveillance videos of UCSD Ped l and ShanghaiTech datasets, and the experimental results demonstrate that the proposed method is an efficient model.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2159079464",
                        "name": "Jinpeng Fang"
                    },
                    {
                        "authorId": "2108166116",
                        "name": "Xinfeng Zhang"
                    },
                    {
                        "authorId": "2115355434",
                        "name": "Baoqing Yang"
                    },
                    {
                        "authorId": "2107946888",
                        "name": "Shuhan Chen"
                    },
                    {
                        "authorId": "2156072360",
                        "name": "Bin Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Owing to its flexibility, it has been widely adopted for solving various vision problems including movie understanding [52], video object segmentation [53]\u2013[55], image generation [56], VQA [57], and anomaly detection [58], [59]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0607079be58dd3cf442e81c39978bcbe2f20971d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-01883",
                    "ArXiv": "2201.01883",
                    "DOI": "10.1109/TIP.2022.3180561",
                    "CorpusId": 245769593,
                    "PubMed": "35687627"
                },
                "corpusId": 245769593,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0607079be58dd3cf442e81c39978bcbe2f20971d",
                "title": "Memory-Guided Image De-Raining Using Time-Lapse Data",
                "abstract": "This paper addresses the problem of single image de-raining, that is, the task of recovering clean and rain-free background scenes from a single image obscured by a rainy artifact. Although recent advances adopt real-world time-lapse data to overcome the need for paired rain-clean images, they are limited to fully exploit the time-lapse data. The main cause is that, in terms of network architectures, they could not capture long-term rain streak information in the time-lapse data during training owing to the lack of memory components. To address this problem, we propose a novel network architecture combining the time-lapse data and, the memory network that explicitly helps to capture long-term rain streak information. Our network comprises the encoder-decoder networks and a memory network. The features extracted from the encoder are read and updated in the memory network that contains several memory items to store rain streak-aware feature representations. With the read/update operation, the memory network retrieves relevant memory items in terms of the queries, enabling the memory items to represent the various rain streaks included in the time-lapse data. To boost the discriminative power of memory features, we also present a novel background selective whitening (BSW) loss for capturing only rain streak information in the memory network by erasing the background information. Experimental results on standard benchmarks demonstrate the effectiveness and superiority of our approach.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "84209943",
                        "name": "Jaehoon Cho"
                    },
                    {
                        "authorId": "2099537",
                        "name": "Seungryong Kim"
                    },
                    {
                        "authorId": "144442279",
                        "name": "K. Sohn"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Besides, we use a variable r as the initial weight of adaptive fusion network with FC(2R)\n4. https://pyod.readthedocs.io/en/stable/, https://github.com/ 7fantasysz/MSCRED,https://github.com/cvlab-yonsei/MNAD,https: //github.com/Vniex/BeatGAN, https://github.com/d-ailin/GDN\n\u2192 BN \u2192 Sigmoid \u2192 Multiply.",
                "We present case studies of MNAD, UODA and our method AMSL as shown in Fig.",
                "0\n0.2\n0.4\n0.6\n0.8\n1\nF 1\nOCSVM ConvLSTM-COMP MNAD-R AMSL\nFig.",
                "We compare the performance of four methods: OCSVM, ConvLSTM-COMPOSITE, MNAD-R and AMSL.",
                "MNAD and ConvLSTM are proposed for video data, which may not be suitable for multivariate time series.",
                "Each column is the instance whether is correctly detected by our method AMSL, MNAD and UODA.",
                "[39], neural machine translation [40], anomaly detection [41], [42], [43].",
                "It has two variants: one with the prediction task (MNAD-P), another with the reconstruction task (MNAD-R).",
                "In\n10\nNormal AbnormalNormal AbnormalNormal Abnormal\nUODA:\nOurs:\nMNAD:\nUODA:\nOurs:\nMNAD:\nUODA:\nOurs:\nMNAD:\nUODA:\nOurs:\nMNAD:\nUODA:\nOurs:\nMNAD:\nUODA:\nOurs:\nMNAD:\nAc ce le ra tio\nn\nTime\nAc ce le ra tio\nn\nTime\nAc ce le ra tio\nn\nTime\nAc ce le ra tio\nn\nTime\nAc ce le ra tio\nn\nTime\nAc ce le ra tio\nn\nTime\nFig.",
                "\u2022 MNAD [43], which is an encoder-decoder model based on a memory module for video anomaly detection."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6bbec2104e48df02f5319af6cfd5320411f9dec1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-00464",
                    "ArXiv": "2201.00464",
                    "DOI": "10.1109/tkde.2021.3139916",
                    "CorpusId": 245650506
                },
                "corpusId": 245650506,
                "publicationVenue": {
                    "id": "c6840156-ee10-4d78-8832-7f8909811576",
                    "name": "IEEE Transactions on Knowledge and Data Engineering",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Knowl Data Eng"
                    ],
                    "issn": "1041-4347",
                    "url": "https://www.computer.org/web/tkde",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=69"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6bbec2104e48df02f5319af6cfd5320411f9dec1",
                "title": "Adaptive Memory Networks with Self-supervised Learning for Unsupervised Anomaly Detection",
                "abstract": "Unsupervised anomaly detection aims to build models to effectively detect unseen anomalies by only training on the normal data. Although previous reconstruction-based methods have made fruitful progress, their generalization ability is limited due to two critical challenges. First, the training dataset only contains normal patterns, which limits the model generalization ability. Second, the feature representations learned by existing models often lack representativeness which hampers the ability to preserve the diversity of normal patterns. In this paper, we propose a novel approach called Adaptive Memory Network with Self-supervised Learning (AMSL) to address these challenges and enhance the generalization ability in unsupervised anomaly detection. Based on the convolutional autoencoder structure, AMSL incorporates a self-supervised learning module to learn general normal patterns and an adaptive memory fusion module to learn rich feature representations. Experiments on four public multivariate time series datasets demonstrate that AMSL significantly improves the performance compared to other state-of-the-art methods. Specifically, on the largest CAP sleep stage detection dataset with 900 million samples, AMSL outperforms the second-best baseline by \\textbf{4}\\%+ in both accuracy and F1 score. Apart from the enhanced generalization ability, AMSL is also more robust against input noise.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108078103",
                        "name": "Yu-xin Zhang"
                    },
                    {
                        "authorId": "1519290245",
                        "name": "Jindong Wang"
                    },
                    {
                        "authorId": "2109360525",
                        "name": "Yiqiang Chen"
                    },
                    {
                        "authorId": "3273556",
                        "name": "Hanchao Yu"
                    },
                    {
                        "authorId": "2066169077",
                        "name": "Tao Qin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6",
                "externalIds": {
                    "DBLP": "journals/ijon/XiaPLHMZD22",
                    "DOI": "10.1016/j.neucom.2021.12.093",
                    "CorpusId": 245682770
                },
                "corpusId": 245682770,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6",
                "title": "GAN-based anomaly detection: A review",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1557264594",
                        "name": "X. Xia"
                    },
                    {
                        "authorId": "41052354",
                        "name": "Xizhou Pan"
                    },
                    {
                        "authorId": "2155791602",
                        "name": "Nan Li"
                    },
                    {
                        "authorId": "2154166161",
                        "name": "Xing He"
                    },
                    {
                        "authorId": "2152343688",
                        "name": "Lin Ma"
                    },
                    {
                        "authorId": "2135851366",
                        "name": "Xiaoguang Zhang"
                    },
                    {
                        "authorId": "2066767656",
                        "name": "N. Ding"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "a23aeca0d66268cdb7fc25f76c0346ad64b9bb2c",
                "externalIds": {
                    "DBLP": "journals/ijon/YinZZ22",
                    "DOI": "10.1016/j.neucom.2021.12.080",
                    "CorpusId": 245694901
                },
                "corpusId": 245694901,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a23aeca0d66268cdb7fc25f76c0346ad64b9bb2c",
                "title": "Defending against adversarial attacks using spherical sampling-based variational auto-encoder",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2151229768",
                        "name": "Sheng-lin Yin"
                    },
                    {
                        "authorId": "49470277",
                        "name": "Xing-lan Zhang"
                    },
                    {
                        "authorId": "2054756302",
                        "name": "Li Zuo"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "d5495b3a429deb3c69f3b4e5aed881e03acee6c3",
                "externalIds": {
                    "DBLP": "journals/ivc/GuoGZWG22",
                    "DOI": "10.1016/j.imavis.2022.104391",
                    "CorpusId": 246455596
                },
                "corpusId": 246455596,
                "publicationVenue": {
                    "id": "6cc36eeb-d056-42c4-a306-7bcb239cc442",
                    "name": "Image and Vision Computing",
                    "type": "journal",
                    "alternate_names": [
                        "Image Vis Comput"
                    ],
                    "issn": "0262-8856",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525443/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/02628856",
                        "https://www.journals.elsevier.com/image-and-vision-computing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d5495b3a429deb3c69f3b4e5aed881e03acee6c3",
                "title": "Self-trained prediction model and novel anomaly score mechanism for video anomaly detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2046826270",
                        "name": "AiBin Guo"
                    },
                    {
                        "authorId": "49868741",
                        "name": "Lijun Guo"
                    },
                    {
                        "authorId": "13451126",
                        "name": "Rong-Rrong Zhang"
                    },
                    {
                        "authorId": "2107919803",
                        "name": "Yirui Wang"
                    },
                    {
                        "authorId": "1791190",
                        "name": "Shangce Gao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "7f6b95c8edb5876b0db0ad76f21741bf1aaee5ff",
                "externalIds": {
                    "DBLP": "journals/ivc/YiFW22",
                    "DOI": "10.1016/j.imavis.2022.104397",
                    "CorpusId": 246468064
                },
                "corpusId": 246468064,
                "publicationVenue": {
                    "id": "6cc36eeb-d056-42c4-a306-7bcb239cc442",
                    "name": "Image and Vision Computing",
                    "type": "journal",
                    "alternate_names": [
                        "Image Vis Comput"
                    ],
                    "issn": "0262-8856",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525443/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/02628856",
                        "https://www.journals.elsevier.com/image-and-vision-computing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7f6b95c8edb5876b0db0ad76f21741bf1aaee5ff",
                "title": "Batch feature standardization network with triplet loss for weakly-supervised video anomaly detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2152087809",
                        "name": "Shuhan Yi"
                    },
                    {
                        "authorId": "2113847323",
                        "name": "Zheyi Fan"
                    },
                    {
                        "authorId": null,
                        "name": "Di Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[17] improved this drawback by introducing feature compactness loss and feature separateness loss.",
                "Previous deep learning methods for anomaly detection and segmentation are usually based on reconstructionbased neural network architectures, such as autoencoders (AE) [3], [5], [11], [15], [17], variational autoencoders (VAE) [14], [23], and generative adversarial networks (GAN) [1], [20]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "45535b86c60661dd4c4e4f375abae80937563499",
                "externalIds": {
                    "DBLP": "conf/wacv/TsaiWL22",
                    "DOI": "10.1109/WACV51458.2022.00312",
                    "CorpusId": 246609804
                },
                "corpusId": 246609804,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/45535b86c60661dd4c4e4f375abae80937563499",
                "title": "Multi-Scale Patch-Based Representation Learning for Image Anomaly Detection and Segmentation",
                "abstract": "Unsupervised representation learning has been proven to be effective for the challenging anomaly detection and segmentation tasks. In this paper, we propose a multi-scale patch-based representation learning method to extract critical and representative information from normal images. By taking the relative feature similarity between patches of different local distances into account, we can achieve better representation learning. Moreover, we propose a refined way to improve the self-supervised learning strategy, thus allowing our model to learn better geometric relationship between neighboring patches. Through sliding patches of different scales all over an image, our model extracts representative features from each patch and compares them with those in the training set of normal images to detect the anomalous regions. Our experimental results on MVTec AD dataset and BTAD dataset demonstrate the proposed method achieves the state-of-the-art accuracy for both anomaly detection and segmentation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2153663903",
                        "name": "Chin-Chia Tsai"
                    },
                    {
                        "authorId": "2149372111",
                        "name": "Tsung-Hsuan Wu"
                    },
                    {
                        "authorId": "1696527",
                        "name": "S. Lai"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "a59c31e0c1c2ccbfafe86bc2342906b9fcd062a6",
                "externalIds": {
                    "DBLP": "journals/ijon/0001ZSG22",
                    "DOI": "10.1016/j.neucom.2022.01.026",
                    "CorpusId": 247321887
                },
                "corpusId": 247321887,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a59c31e0c1c2ccbfafe86bc2342906b9fcd062a6",
                "title": "Weakly-supervised anomaly detection in video surveillance via graph convolutional label noise cleaning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2149457243",
                        "name": "Nannan Li"
                    },
                    {
                        "authorId": "28891563",
                        "name": "Jia-Xing Zhong"
                    },
                    {
                        "authorId": "9183117",
                        "name": "Xiujun Shu"
                    },
                    {
                        "authorId": "2750523",
                        "name": "Huiwen Guo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Most of the above works use pixel-wise metrics between input and output to detect anomalies [5, 13, 4, 16].",
                "We compare our methods with the existing state-of-the-art approaches: FFP-MC [11], DAML [9], MemAE [4], and MNAD [16].",
                "Automated anomaly detection has attracted significant attention because of its importance for surveillance systems and public security [12, 11, 19, 1, 4, 16]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "084a63d0eb0b0f5a57555a00813d386768ae6ff4",
                "externalIds": {
                    "DBLP": "conf/wacv/LerouxLS22",
                    "DOI": "10.1109/WACV51458.2022.00308",
                    "CorpusId": 246868159
                },
                "corpusId": 246868159,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/084a63d0eb0b0f5a57555a00813d386768ae6ff4",
                "title": "Multi-branch Neural Networks for Video Anomaly Detection in Adverse Lighting and Weather Conditions",
                "abstract": "Automated anomaly detection in surveillance videos has attracted much interest as it provides a scalable alternative to manual monitoring. Most existing approaches achieve good performance on clean benchmark datasets recorded in well-controlled environments. However, detecting anomalies is much more challenging in the real world. Adverse weather conditions like rain or changing brightness levels cause a significant shift in the input data distribution, which in turn can lead to the detector model incorrectly reporting high anomaly scores. Additionally, surveillance cameras are usually deployed in evolving environments such as a city street of which the appearance changes over time because of seasonal changes or roadworks. The anomaly detection model will need to be updated periodically to deal with these issues. In this paper, we introduce a multi-branch model that is equipped with a trainable preprocessing step and multiple identical branches for detecting anomalies during day and night as well as in sunny and rainy conditions. We experimentally validate our approach on a distorted version of the Avenue dataset and provide qualitative results on real-world surveillance camera data. Experimental results show that our method outperforms the existing methods in terms of detection accuracy while being faster and more robust on scenes with varying visibility.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3162144",
                        "name": "Sam Leroux"
                    },
                    {
                        "authorId": "71788673",
                        "name": "Bo Li"
                    },
                    {
                        "authorId": "34209448",
                        "name": "P. Simoens"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", anatomical structures) across persons, we incorporate a memory bank [21] M \u2208 R to store the common patterns.",
                "Apart from the single-view internal learning and cross-view mutual distillation loss functions, the compactness (L) and separateness (L) constraints as in [21], are used to regularize the memory bank,",
                "Given two adjacent slices, a U-shape network constituted by convolution layers, residual groups [3] and a memory bank [21], synthesizes r \u2212 1 intermediate slices."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "48c6589c86881f7cf3e9e3d7a487e56edaa4a815",
                "externalIds": {
                    "DBLP": "conf/cvpr/FangWZXYH22",
                    "ArXiv": "2112.10325",
                    "DOI": "10.1109/CVPR52688.2022.02002",
                    "CorpusId": 245334862
                },
                "corpusId": 245334862,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/48c6589c86881f7cf3e9e3d7a487e56edaa4a815",
                "title": "Incremental Cross-view Mutual Distillation for Self-supervised Medical CT Synthesis",
                "abstract": "Due to the constraints of the imaging device and high cost in operation time, computer tomography (CT) scans are usually acquired with low within-slice resolution. Improving the inter-slice resolution is beneficial to the disease diagnosis for both human experts and computer-aided systems. To this end, this paper builds a novel medical slice synthesis to increase the inter-slice resolution. Considering that the groundtruth intermediate medical slices are always absent in clinical practice, we introduce the incremental cross-view mutual distillation strategy to accomplish this task in the self-supervised learning manner. Specifically, we model this problem from three different views: slice-wise interpolation from axial view and pixel-wise interpolation from coronal and sagittal views. Under this circumstance, the models learned from different views can distill valuable knowledge to guide the learning processes of each other. We can repeat this process to make the models synthesize intermediate slice data with increasing between-slice resolution. To demonstrate the effectiveness of the proposed approach, we conduct comprehensive experiments on a large-scale $CT$ dataset. Quantitative and qualitative comparison results show that our method outperforms state-of-the-art algorithms by clear margins.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2082794",
                        "name": "Chaowei Fang"
                    },
                    {
                        "authorId": "2144695316",
                        "name": "Liang Wang"
                    },
                    {
                        "authorId": "39901030",
                        "name": "Dingwen Zhang"
                    },
                    {
                        "authorId": "145971173",
                        "name": "Jun Xu"
                    },
                    {
                        "authorId": "3080513",
                        "name": "Yixuan Yuan"
                    },
                    {
                        "authorId": "2156545589",
                        "name": "Junwei Han"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Similarly, methods based on autoencoders (Bergmann et al., 2019b; Park et al., 2020) first encode input images with a low dimensional latent sample, and then decode that sample to minimize a pixelwise reconstruction error."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5da4eb1135d5827ce30e099bda377a19f3a52730",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-09045",
                    "ArXiv": "2112.09045",
                    "DOI": "10.5220/0010865000003124",
                    "CorpusId": 245218819
                },
                "corpusId": 245218819,
                "publicationVenue": {
                    "id": "3e53351c-7355-4159-a3f2-f3b03a3aa989",
                    "name": "VISIGRAPP",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Comput Vis Imaging Comput Graph Theory Appl",
                        "International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications"
                    ],
                    "issn": "2184-4321",
                    "alternate_issns": [
                        "2184-5921"
                    ],
                    "url": "http://www.visigrapp.org/"
                },
                "url": "https://www.semanticscholar.org/paper/5da4eb1135d5827ce30e099bda377a19f3a52730",
                "title": "The MVTec 3D-AD Dataset for Unsupervised 3D Anomaly Detection and Localization",
                "abstract": "We introduce the first comprehensive 3D dataset for the task of unsupervised anomaly detection and localization. It is inspired by real-world visual inspection scenarios in which a model has to detect various types of defects on manufactured products, even if it is trained only on anomaly-free data. There are defects that manifest themselves as anomalies in the geometric structure of an object. These cause significant deviations in a 3D representation of the data. We employed a high-resolution industrial 3D sensor to acquire depth scans of 10 different object categories. For all object categories, we present a training and validation set, each of which solely consists of scans of anomaly-free samples. The corresponding test sets contain samples showing various defects such as scratches, dents, holes, contaminations, or deformations. Precise ground-truth annotations are provided for every anomalous test sample. An initial benchmark of 3D anomaly detection methods on our dataset indicates a considerable room for improvement.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "33609329",
                        "name": "Paul Bergmann"
                    },
                    {
                        "authorId": "1485402830",
                        "name": "Xin Jin"
                    },
                    {
                        "authorId": "23633923",
                        "name": "David Sattlegger"
                    },
                    {
                        "authorId": "36494513",
                        "name": "C. Steger"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To compare our methods to the rapidly developing field of algorithms for AD in surveillance videos, we choose to run the Memoryguided Normality for Anomaly Detection (MNAD [7]) method on our dataset.",
                "In recent years, many new techniques have been suggested, pushing forward performance on such benchmarks [6, 7].",
                "More recent methods have been able to outperform using pretraining and self-supervised learning [12, 6, 7]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8d6d799d6723a751b8808ab783d223671f89e552",
                "externalIds": {
                    "DBLP": "conf/icassp/KartC22",
                    "ArXiv": "2112.07661",
                    "DOI": "10.1109/ICASSP43922.2022.9747367",
                    "CorpusId": 245131228
                },
                "corpusId": 245131228,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/8d6d799d6723a751b8808ab783d223671f89e552",
                "title": "Approaches Toward Physical and General Video Anomaly Detection",
                "abstract": "In recent years, many works have addressed the problem of finding never-seen-before anomalies in videos. Yet, most work has been focused on detecting anomalous frames in surveillance videos taken from security cameras. Meanwhile, the task of anomaly detection (AD) in videos exhibiting anomalous mechanical behavior, has been mostly overlooked. Anomaly detection in such videos is both of academic and practical interest, as they may enable automatic detection of malfunctions in many manufacturing, maintenance, and real-life settings. To assess the potential of the different approaches to detect such anomalies, we evaluate two simple baseline approaches: (i) Temporal-pooled image AD techniques. (ii) Density estimation of videos represented with features pretrained for video-classification.Development of such methods calls for new benchmarks to al-low evaluation of different possible approaches. We introduce the Physical Anomalous Trajectory or Motion (PHANTOM) dataset 1, which contains six different video classes. Each class consists of normal and anomalous videos. The classes differ in the presented phenomena, the normal class variability, and the kind of anomalies in the videos. We also suggest an even harder benchmark where anomalous activities should be spotted on highly variable scenes.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2145259654",
                        "name": "Laura Kart"
                    },
                    {
                        "authorId": "22021547",
                        "name": "Niv Cohen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "use reconstruction loss, feature compactness loss, and feature separateness loss in [24].",
                "For the anomaly detection task, we evaluate our methods on a memory-guided autoencoder network from [24].",
                "Since [24] deals with image and video data, we change the network structure for the network anomaly detection."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "985cc7f7f7b5efc794af9ff617672b24d792a9af",
                "externalIds": {
                    "DBLP": "conf/apsipa/LeeRSKC21",
                    "CorpusId": 246532473
                },
                "corpusId": 246532473,
                "publicationVenue": {
                    "id": "5b924e1a-30f3-4275-bdb8-5a15517c0fde",
                    "name": "Asia-Pacific Signal and Information Processing Association Annual Summit and Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Asia-pacific Signal Inf Process Assoc Annu Summit Conf",
                        "APSIPA"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/985cc7f7f7b5efc794af9ff617672b24d792a9af",
                "title": "Network Intrusion Detection with Improved Feature Representation",
                "abstract": "This paper presents new feature representation methods for the network intrusion detection. Like conventional work, our method is based on neural networks. However, rather than focusing on the network architecture search, we improve the performance by developing effective feature representation methods. First, we apply the embedding method to categorical features in the network data. Although embedding has been commonly used in natural language processing and recommen-dation systems, categorical features in network problems were often ignored or simply used in a one-hot-encoding vector form. By applying the embedding method to categorical features, we can effectively exploit them. Second, we apply a robust scaler to numerical features. Numerical features are concentrated in a few clusters with a small portion of outliers, and we can effectively remove outliers with a robust scaler. Finally, we augment feature vectors with categorical representations of numerical values. These categorical representations (e.g., high, medium, and low) help to discover simple logical rules and facilitate the intrusion detection. We have applied our method to two scenarios: a normal/attack classification and an unsupervised learning of anomaly detection. Experimental results have shown that the proposed method outperforms conventional methods on public benchmark datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152841248",
                        "name": "Geonsu Lee"
                    },
                    {
                        "authorId": "1557389407",
                        "name": "Hochang Rhee"
                    },
                    {
                        "authorId": "2152647727",
                        "name": "Jae Hoon Shim"
                    },
                    {
                        "authorId": "2463454",
                        "name": "H. Koo"
                    },
                    {
                        "authorId": "1707645",
                        "name": "N. Cho"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Finally, separatedness loss [18] is used to help learn a diverse feature representation and improve the discriminative power of the codebook.",
                "The second group of approaches to anomaly detection with deep learning is to reconstruct or predict future \u2018normal\u2019 video frames from sparse feature representations [3, 15, 27], sometimes augmented with memory modules [18], and/or optical-flow images [13, 19, 20].",
                "The total loss function consists of the prediction loss Lpred, embedding loss Lembed, the so-called commitment loss [26] Lcommit and feature separatedness loss [18] Lsep.",
                "Our method is most similar to the memory-augmented autoencoder [18], where the features at the bottleneck are appended to the closest entries from a learnt codebook containing a small number of codes.",
                "Following [18] we remove the last batch normalization layer and the last ReLU activation layer, because ReLU cuts off negative values, possibly restricting the diverse feature representation.",
                "[18] that (1) the size of the bottleneck of the method is twice as big as the input, hence the model could potentially copy the input when reconstructing and (2) the codebook could simply be ignored by the decoder as it has access to raw bottleneck features.",
                "The network architecture is based on U-Net [23], which has been successfully applied to the task of reconstruction and future frame prediction [18, 13]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "d85b756b8e4d584a53483c6562eb968efdb1fc0c",
                "externalIds": {
                    "ArXiv": "2112.05585",
                    "DBLP": "journals/corr/abs-2112-05585",
                    "DOI": "10.1109/WACV51458.2022.00157",
                    "CorpusId": 245117337
                },
                "corpusId": 245117337,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/d85b756b8e4d584a53483c6562eb968efdb1fc0c",
                "title": "Discrete neural representations for explainable anomaly detection",
                "abstract": "The aim of this work is to detect and automatically generate high-level explanations of anomalous events in video. Understanding the cause of an anomalous event is crucial as the required response is dependant on its nature and severity. Recent works typically use object or action classifier to detect and provide labels for anomalous events. However, this constrains detection systems to a finite set of known classes and prevents generalisation to unknown objects or behaviours. Here we show how to robustly detect anomalies without the use of object or action classifiers yet still recover the high level reason behind the event. We make the following contributions: (1) a method using saliency maps to decouple the explanation of anomalous events from object and action classifiers, (2) show how to improve the quality of saliency maps using a novel neural architecture for learning discrete representations of video by predicting future frames and (3) beat the state-of-the-art anomaly explanation methods by 60% on a subset of the public benchmark X-MAN dataset [25].",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2112694047",
                        "name": "Stanislaw Szymanowicz"
                    },
                    {
                        "authorId": "2055745260",
                        "name": "James Charles"
                    },
                    {
                        "authorId": "1745672",
                        "name": "R. Cipolla"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As more research efforts been invested into anomaly detection, recent studies combined the feature extraction step with the model training step and proposed deep learning methods in an end-to-end manner, such as VAE [50], Generative Adversarial Network (GAN) [51], Recurrent Neural Network (RNN) [7] and Long Short-Term Memory (LSTM) [52], etc.",
                "The w/ Mem [67] predicts anomalies based on reconstruction error.",
                "The ten methods are Frame-Pred [1], MPED-RNN [2], w/Mem [67], ST-GCAE [68], Multi-",
                "Qualitative results for future frame prediction of (top to bottom): w/ Mem [67] model, MPED-RNN [2] model and our HSTGCNN model.",
                "The ten methods are Frame-Pred [1], MPED-RNN [2], w/Mem [67], ST-GCAE [68], Multitimescale [9], PoseCVAE [60], LSA [69], Ano-Graph [70],\nAnomalyNet [71], and Normal Graph [5], some of them integrate a model focusing on appearance and motion with others dealing with the trajectories of human skeletons."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8f66cd3c89239ae596656eb13d8290035c7e550a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-04294",
                    "ArXiv": "2112.04294",
                    "DOI": "10.1109/TCSVT.2021.3134410",
                    "CorpusId": 244954553
                },
                "corpusId": 244954553,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/8f66cd3c89239ae596656eb13d8290035c7e550a",
                "title": "A Hierarchical Spatio-Temporal Graph Convolutional Neural Network for Anomaly Detection in Videos",
                "abstract": "Deep learning models have been widely used for anomaly detection in surveillance videos. Typical models are equipped with the capability to reconstruct normal videos and evaluate the reconstruction errors on anomalous videos to indicate the extent of abnormalities. However, existing approaches suffer from two disadvantages. Firstly, they can only encode the movements of each identity independently, without considering the interactions among identities which may also indicate anomalies. Secondly, they leverage inflexible models whose structures are fixed under different scenes, this configuration disables the understanding of scenes. In this paper, we propose a Hierarchical Spatio-Temporal Graph Convolutional Neural Network (HSTGCNN) to address these problems, the HSTGCNN is composed of multiple branches that correspond to different levels of graph representations. High-level graph representations encode the trajectories of people and the interactions among multiple identities while low-level graph representations encode the local body postures of each person. Furthermore, we propose to weightedly combine multiple branches that are better at different scenes. An improvement over single-level graph representations is achieved in this way. An understanding of scenes is achieved and serves anomaly detection. High-level graph representations are assigned higher weights to encode moving speed and directions of people in low-resolution videos while low-level graph representations are assigned higher weights to encode human skeletons in high-resolution videos. Experimental results show that the proposed HSTGCNN significantly outperforms current state-of-the-art models on four benchmark datasets (UCSD Pedestrian, ShanghaiTech, CUHK Avenue and IITB-Corridor) by using much less learnable parameters.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2111552372",
                        "name": "Xianling Zeng"
                    },
                    {
                        "authorId": "9325297",
                        "name": "Yalong Jiang"
                    },
                    {
                        "authorId": "2911928",
                        "name": "Wenrui Ding"
                    },
                    {
                        "authorId": "2109042832",
                        "name": "Hongguang Li"
                    },
                    {
                        "authorId": "2117835076",
                        "name": "Yafeng Hao"
                    },
                    {
                        "authorId": "2053913061",
                        "name": "Zifeng Qiu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Among them, MPPCA (hybrid of probabilistic principal component analyzer) + SF (social power) [17] and MDT (hybrid of dynamic texture) [18] are methods based on manual features; Conv-AE [8], 3D Conv [19], Stacked RNN [20] and ConvLSTM-AE [21], MemNormality [10], and ClusterAE [22] are all methods based on autoencoders; AbnormalGAN [7] and Pred +Recon [23] are based on generating the adversarial networks\u2019 method."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "f06496d365ed8b5e9d5d91920c1b4d215e342803",
                "externalIds": {
                    "DBLP": "journals/cin/BianT21",
                    "PubMedCentral": "8674060",
                    "DOI": "10.1155/2021/9861533",
                    "CorpusId": 245105409,
                    "PubMed": "34925499"
                },
                "corpusId": 245105409,
                "publicationVenue": {
                    "id": "f32b7322-b69c-4e63-801d-8f50784ef778",
                    "name": "Computational Intelligence and Neuroscience",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Intell Neurosci"
                    ],
                    "issn": "1687-5265",
                    "url": "https://www.hindawi.com/journals/cin/"
                },
                "url": "https://www.semanticscholar.org/paper/f06496d365ed8b5e9d5d91920c1b4d215e342803",
                "title": "Abnormal Detection in Big Data Video with an Improved Autoencoder",
                "abstract": "With the rapid growth of video surveillance data, there is an increasing demand for big data automatic anomaly detection of large-scale video data. The detection methods using reconstruction errors based on deep autoencoders have been widely discussed. However, sometimes the autoencoder could reconstruct the anomaly well and lead to missing detections. In order to solve this problem, this paper uses a memory module to enhance the autoencoder, which is called the memory-augmented autoencoder (Memory AE) method. Given the input, Memory AE first obtains the code from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. In the training phase, the memory content is updated and encouraged to represent prototype elements of normal data. In the test phase, the learned memory elements are fixed, and reconstruction is obtained from several selected memory records of normal data. So, the reconstruction will tend to be close to normal samples. Therefore, the reconstruction of abnormal errors will be strengthened for abnormal detection. The experimental results on two public video anomaly detection datasets, i.e., Avenue dataset and ShanghaiTech dataset, prove the effectiveness of the proposed method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2135549528",
                        "name": "Yihan Bian"
                    },
                    {
                        "authorId": "2149346967",
                        "name": "Xinchen Tang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "network (GAN) [14], U-Net with memory module [15], and convolutional neural network (CNN)-based data augmentation [16] have been developed to reconstruct normal data."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "91339b5f3f9db068675e7d6f0e1ba94287195a18",
                "externalIds": {
                    "ArXiv": "2207.02279",
                    "DBLP": "conf/ssci/Kanu-AsiegbuVD21",
                    "DOI": "10.1109/SSCI50451.2021.9660004",
                    "CorpusId": 246290788
                },
                "corpusId": 246290788,
                "publicationVenue": {
                    "id": "8a9e9f3b-a025-473d-801e-72cdb0653d22",
                    "name": "IEEE Symposium Series on Computational Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "IEEE Symp Ser Comput Intell",
                        "SSCI"
                    ],
                    "url": "http://www.ieee-ssci.org/"
                },
                "url": "https://www.semanticscholar.org/paper/91339b5f3f9db068675e7d6f0e1ba94287195a18",
                "title": "Leveraging Trajectory Prediction for Pedestrian Video Anomaly Detection",
                "abstract": "Video anomaly detection is a core problem in vision. Correctly detecting and identifying anomalous behaviors in pedestrians from video data will enable safety-critical applications such as surveillance, activity monitoring, and human-robot interaction. In this paper, we propose to leverage trajectory localization and prediction for unsupervised pedestrian anomaly event detection. Different than previous reconstruction-based approaches, our proposed framework rely on the prediction errors of normal and abnormal pedestrian trajectories to detect anomalies spatially and temporally. We present experimental results on real-world benchmark datasets on varying timescales and show that our proposed trajectory-predictor-based anomaly detection pipeline is effective and efficient at identifying anomalous activities of pedestrians in videos. Code will be made available at https://github.com/akanuasiegbu/Leveraging-Trajectory-Prediction-for-Pedestrian-Video-Anomaly-Detection.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1410534719",
                        "name": "A. Kanu-Asiegbu"
                    },
                    {
                        "authorId": "145386932",
                        "name": "Ram Vasudevan"
                    },
                    {
                        "authorId": "1410629683",
                        "name": "Xiaoxiao Du"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "120d6d2b8869604ff59a1d6d12634db24b0715d8",
                "externalIds": {
                    "DBLP": "journals/ijon/LiCL22",
                    "DOI": "10.1016/j.neucom.2021.12.023",
                    "CorpusId": 245456764
                },
                "corpusId": 245456764,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/120d6d2b8869604ff59a1d6d12634db24b0715d8",
                "title": "Human-related anomalous event detection via spatial-temporal graph convolutional autoencoder with embedded long short-term memory network",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "47576810",
                        "name": "Nanjun Li"
                    },
                    {
                        "authorId": "1800264",
                        "name": "F. Chang"
                    },
                    {
                        "authorId": "123266659",
                        "name": "Chunsheng Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "36eaff88cbf65fbc62bebcf3cf81db1e721544ad",
                "externalIds": {
                    "DBLP": "journals/tcyb/HuangYWXJYW22",
                    "DOI": "10.1109/TCYB.2021.3127716",
                    "CorpusId": 244807296,
                    "PubMed": "34851847"
                },
                "corpusId": 244807296,
                "publicationVenue": {
                    "id": "404813e7-95da-4137-be14-2ba73d2df4fd",
                    "name": "IEEE Transactions on Cybernetics",
                    "alternate_names": [
                        "IEEE Trans Cybern"
                    ],
                    "issn": "2168-2267",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6221036",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221036"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/36eaff88cbf65fbc62bebcf3cf81db1e721544ad",
                "title": "Self-Supervision-Augmented Deep Autoencoder for Unsupervised Visual Anomaly Detection",
                "abstract": "Deep autoencoder (AE) has demonstrated promising performances in visual anomaly detection (VAD). Learning normal patterns on normal data, deep AE is expected to yield larger reconstruction errors for anomalous samples, which is utilized as the criterion for detecting anomalies. However, this hypothesis cannot be always tenable since the deep AE usually captures the low-level shared features between normal and abnormal data, which leads to similar reconstruction errors for them. To tackle this problem, we propose a self-supervised representation-augmented deep AE for unsupervised VAD, which can enlarge the gap of anomaly scores between normal and abnormal samples by introducing autoencoding transformation (AT). Essentially, AT is introduced to facilitate AE to learn the high-level visual semantic features of normal images by introducing a self-supervision task (transformation reconstruction). In particular, our model inputs the original and transformed images into the encoder for obtaining latent representations; afterward, they are fed to the decoder for reconstructing both the original image and applied transformation. In this way, our model can utilize both image and transformation reconstruction errors to detect anomaly. Extensive experiments indicate that the proposed method outperforms other state-of-the-art methods, which demonstrates the validity and advancement of our model.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "35933894",
                        "name": "Chaoqin Huang"
                    },
                    {
                        "authorId": "2142755095",
                        "name": "Zehua Yang"
                    },
                    {
                        "authorId": "144888860",
                        "name": "Jie Wen"
                    },
                    {
                        "authorId": "2146648728",
                        "name": "Yong Xu"
                    },
                    {
                        "authorId": "3318404",
                        "name": "Qiuping Jiang"
                    },
                    {
                        "authorId": "51460259",
                        "name": "Jian Yang"
                    },
                    {
                        "authorId": "5765799",
                        "name": "Yaowei Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "e2977c67f55b8a2a58ff1c232c96bed25002f8a2",
                "externalIds": {
                    "ArXiv": "2111.13495",
                    "DBLP": "conf/cvpr/XiangZLYZ0Z23",
                    "DOI": "10.1109/CVPR52729.2023.02288",
                    "CorpusId": 257766829
                },
                "corpusId": 257766829,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e2977c67f55b8a2a58ff1c232c96bed25002f8a2",
                "title": "SQUID: Deep Feature In-Painting for Unsupervised Anomaly Detection",
                "abstract": "Radiography imaging protocols focus on particular body regions, therefore producing images of great similarity and yielding recurrent anatomical structures across patients. To exploit this structured information, we propose the use of Space-aware Memory Queues for In-painting and Detecting anomalies from radiography images (abbreviated as SQUID). We show that SQUID can taxonomize the ingrained anatomical structures into recurrent patterns; and in the inference, it can identify anomalies (unseen/modified patterns) in the image. SQUID surpasses 13 state-of-the-art methods in unsupervised anomaly detection by at least 5 points on two chest X-ray benchmark datasets measured by the Area Under the Curve (AUC). Additionally, we have created a new dataset (DigitAnatomy), which synthesizes the spatial correlation and consistent shape in chest anatomy. We hope DigitAnatomy can prompt the development, evaluation, and interpretability of anomaly detection methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "151389946",
                        "name": "Tiange Xiang"
                    },
                    {
                        "authorId": "2108247693",
                        "name": "Yixiao Zhang"
                    },
                    {
                        "authorId": "2946371",
                        "name": "Yongyi Lu"
                    },
                    {
                        "authorId": "145081362",
                        "name": "A. Yuille"
                    },
                    {
                        "authorId": "90477010",
                        "name": "Chaoyi Zhang"
                    },
                    {
                        "authorId": "122905659",
                        "name": "Weidong (Tom) Cai"
                    },
                    {
                        "authorId": "2198519",
                        "name": "Zongwei Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "495035ca18ceb82d13e5b42beece8eb633f6095c",
                "externalIds": {
                    "DBLP": "conf/cvpr/AcsintoaeFGMSIK22",
                    "ArXiv": "2111.08644",
                    "DOI": "10.1109/CVPR52688.2022.01951",
                    "CorpusId": 244130284
                },
                "corpusId": 244130284,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/495035ca18ceb82d13e5b42beece8eb633f6095c",
                "title": "UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection",
                "abstract": "Detecting abnormal events in video is commonly framed as a one-class classification task, where training videos contain only normal events, while test videos encompass both normal and abnormal events. In this scenario, anomaly detection is an open-set problem. However, some studies assimilate anomaly detection to action recognition. This is a closed-set scenario that fails to test the capability of systems at detecting new anomaly types. To this end, we propose UBnormal, a new supervised open-set benchmark composed of multiple virtual scenes for video anomaly detection. Unlike existing data sets, we introduce abnormal events annotated at the pixel level at training time, for the first time enabling the use of fully-supervised learning methods for abnormal event detection. To preserve the typical open-set formulation, we make sure to include dis-joint sets of anomaly types in our training and test collections of videos. To our knowledge, UBnormal is the first video anomaly detection benchmark to allow a fair head-to-head comparison between one-class open-set models and supervised closed-set models, as shown in our experiments. Moreover, we provide empirical evidence showing that UB-normal can enhance the performance of a state-of-the-art anomaly detection framework on two prominent data sets, Avenue and ShanghaiTech. Our benchmark is freely available at https://github.com/lilygeorgescu/UBnormal.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2140580585",
                        "name": "Andra Acsintoae"
                    },
                    {
                        "authorId": "2140580622",
                        "name": "Andrei Florescu"
                    },
                    {
                        "authorId": "41021255",
                        "name": "Mariana-Iuliana Georgescu"
                    },
                    {
                        "authorId": "2125716049",
                        "name": "Tudor Mare"
                    },
                    {
                        "authorId": "2140582724",
                        "name": "Paul Sumedrea"
                    },
                    {
                        "authorId": "1817759",
                        "name": "Radu Tudor Ionescu"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "145103012",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "and cannot be combined with the deep learning technique, leading to inferior performance compared with recent DNNbased approaches [20], [27], [29].",
                "based or prediction-based methods with distance-based methods, such as [16], [24], [27], [29], and [30].",
                "The main drawback of these methods is that they do not consider the diversity of normal patterns explicitly [27].",
                "reaches the best performance among the frame-level methods, and outperforms recent memory-augmented prediction-based methods [16], [24], [27], [29] by 4%\u223c7%.",
                "To comprehensively compare the state-of-the-art methods on the Corridor dataset, we re-implement two outstanding approaches MNAD [27] and MPN [29] (marked with \u2020) on Corridor along with other datasets using their official codes and settings.",
                "Quantitatively, under the circumstance (c), the average AUC of LLSH is 87.5%, surpassing MNAD (82.3",
                "Some methods [5], [27], [38], [39] directly use the simple nearest neighbor search to calculate the distances between the testing instance and its normal neighbors as the anomaly score.",
                "Quantitatively, the average decreased AUC of LLSH is only 1.3%, while it is 2.4% and 1.8% for MNAD\nand MPN.",
                "[27] design a memory module to record the features of normal data.",
                "MNAD [27] and MPN [29] (marked with \u2020) on Corridor",
                "From the results in (a) and (b) we can see that LLSH outperforms MNAD and MPN in 8 scenes consistently.",
                "Several subsequent prediction-based methods [16], [24], [27], [29], [30] have shown encouraging performance.",
                "Reconstruction-based methods [3], [14], [15], [16], [17], [18], [19] and prediction-based methods [4], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33] train deep neural networks (DNNs), such as convolutional auto-encoders and variational auto-encoders, on normal data to reconstruct the current frame or to predict the next frame.",
                "We compare two frame-level competitive methods MNAD [27] and MPN [29] with our LLSH under three circumstances: (a) training and testing models in each single scene, (b) computing average result of the first N scenes obtained in (a), and (c) training and testing models in the first N scenes.",
                "To be specific, the average absolute AUC of LLSH is 86.1%, outperforming MNAD and MPN by 2.5% and 4.8%, respectively.",
                "Therefore, we compare the scalability of MNAD [27], MPN [29] and the proposed LLSH for newly added scenes."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "result",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "1601a7da2da79447dae5f03545c4fbcd040180a7",
                "externalIds": {
                    "DBLP": "journals/tcsv/LuCZZ23",
                    "ArXiv": "2111.07839",
                    "DOI": "10.1109/TCSVT.2022.3205348",
                    "CorpusId": 244116838
                },
                "corpusId": 244116838,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1601a7da2da79447dae5f03545c4fbcd040180a7",
                "title": "Learnable Locality-Sensitive Hashing for Video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) mainly refers to identifying anomalous events that have not occurred in the training set where only normal samples are available. Existing works usually formulate VAD as a reconstruction or prediction problem. However, the adaptability and scalability of these methods are limited. In this paper, we propose a novel distance-based VAD method to take advantage of all the available normal data efficiently and flexibly. In our method, the smaller the distance between a testing sample and normal samples, the higher the probability that the testing sample is normal. Specifically, we propose to use locality-sensitive hashing (LSH) to map the samples whose similarity exceeds a certain threshold into the same bucket in advance. To utilize multiple hashes and further alleviate the computation and memory usage, we propose to use the hash codes rather than the features as the representations of the samples. In this manner, the complexity of near neighbor search is cut down significantly. To make the samples that are semantically similar get closer and those not similar get further apart, we propose a novel learnable version of LSH that embeds LSH into a neural network and optimizes the hash functions with contrastive learning strategy. The proposed method is robust to data imbalance and can handle the large intra-class variations in normal data flexibly. Besides, it has a good ability of scalability. Extensive experiments demonstrate the superiority of our method, which achieves new state-of-the-art results on VAD benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2140029231",
                        "name": "Yue Lu"
                    },
                    {
                        "authorId": "3201156",
                        "name": "Congqi Cao"
                    },
                    {
                        "authorId": "40382978",
                        "name": "Yifan Zhang"
                    },
                    {
                        "authorId": "2047640322",
                        "name": "Yanning Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "318abe78ac4df567e812ba43e49bb10bf0da17c9",
                "externalIds": {
                    "ArXiv": "2111.01604",
                    "DBLP": "journals/corr/abs-2111-01604",
                    "DOI": "10.1007/s11042-023-16445-z",
                    "CorpusId": 240419726
                },
                "corpusId": 240419726,
                "publicationVenue": {
                    "id": "477368e9-7a8e-475a-8c93-6d623797fd06",
                    "name": "Multimedia tools and applications",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Tools and Applications",
                        "Multimedia Tool Appl",
                        "Multimedia tool appl"
                    ],
                    "issn": "1380-7501",
                    "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/318abe78ac4df567e812ba43e49bb10bf0da17c9",
                "title": "A Critical Study on the Recent Deep Learning Based Semi-Supervised Video Anomaly Detection Methods",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2093641084",
                        "name": "M. Baradaran"
                    },
                    {
                        "authorId": "2145950",
                        "name": "R. Bergevin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "1cc7763152fecfd4cbd9d94cbb13fb664baa66f3",
                "externalIds": {
                    "MAG": "3203396666",
                    "DOI": "10.35940/ijeat.a3161.1011121",
                    "CorpusId": 244181495
                },
                "corpusId": 244181495,
                "publicationVenue": {
                    "id": "47ee480e-9ef9-480e-86e1-bd7187dc7ad4",
                    "name": "International Journal of Engineering and Advanced Technology",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Eng Adv Technol"
                    ],
                    "issn": "2249-8958",
                    "url": "https://www.ijeat.org/"
                },
                "url": "https://www.semanticscholar.org/paper/1cc7763152fecfd4cbd9d94cbb13fb664baa66f3",
                "title": "A Spatial-Temporal based Next Frame Prediction and Unsupervised Classification of Video Anomalies in Real Time Estimation",
                "abstract": "Anomaly detection is an area of video analysis has a great importance in automated surveillance. Although it has been extensively studied, there has been little work started using CNN networks. Hence, in this thesis we presented a novel approach for learning motion features and modeling normal Spatio-temporal dynamics for anomaly detection. In our technique, we capture variations in scale of the patterns of motion in an image object by using optical flow dense estimation technique and train our auto encoder model using convolution long short term memories (ConvLSTM2D) as we are processing video frames and we predict the anomaly in real time using Euclidean distance between the generated and the ground truth frame and we achieved a real time accuracy of nearly 98% for the youtube videos which are not used for either testing or training. Error between the network\u2019s output and the target output is used to classify a video volume as normal or abnormal. In addition to the use of reconstruction error, we also use prediction error for anomaly detection. The prediction models show comparable performance with state of the art methods. In comparison with the proposed method, performance is improved in one dataset. Moreover, running time is significantly faster.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2054366985",
                        "name": "S. Sahu"
                    },
                    {
                        "authorId": "69569725",
                        "name": "M. Rao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The external memory can be used to address various vision problems, including video object segmentation [31, 32], image generation [62], object tracking [59], and anomaly detection [10, 34]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c71a601b807aea5493ec6a0ac8b4c382062ab53e",
                "externalIds": {
                    "DBLP": "conf/bmvc/ChoLOSS21",
                    "ArXiv": "2110.11586",
                    "CorpusId": 239616194
                },
                "corpusId": 239616194,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/c71a601b807aea5493ec6a0ac8b4c382062ab53e",
                "title": "Wide and Narrow: Video Prediction from Context and Motion",
                "abstract": "Video prediction, forecasting the future frames from a sequence of input frames, is a challenging task since the view changes are influenced by various factors, such as the global context surrounding the scene and local motion dynamics. In this paper, we propose a new framework to integrate these complementary attributes to predict complex pixel dynamics through deep networks. We present global context propagation networks that iteratively aggregate the non-local neighboring representations to preserve the contextual information over the past frames. To capture the local motion pattern of objects, we also devise local filter memory networks that generate adaptive filter kernels by storing the prototypical motion of moving objects in the memory. The proposed framework, utilizing the outputs from both networks, can address blurry predictions and color distortion. We conduct experiments on Caltech pedestrian and UCF101 datasets, and demonstrate state-of-the-art results. Especially for multi-step prediction, we obtain an outstanding performance in quantitative and qualitative evaluation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "84209943",
                        "name": "Jaehoon Cho"
                    },
                    {
                        "authorId": "2141768156",
                        "name": "Jiyoung Lee"
                    },
                    {
                        "authorId": "2431463",
                        "name": "Changjae Oh"
                    },
                    {
                        "authorId": "66401313",
                        "name": "Wonil Song"
                    },
                    {
                        "authorId": "144442279",
                        "name": "K. Sohn"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[16] presented a new memory update scheme and used feature compactness and separateness losses to enable the sparse access of the memory."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "2e480dc29e21541a6c96217f80528802f106b8ba",
                "externalIds": {
                    "DOI": "10.1109/CAC53003.2021.9728080",
                    "CorpusId": 247459134
                },
                "corpusId": 247459134,
                "publicationVenue": {
                    "id": "bfa6e440-6762-47f0-b1b9-2a43c02d9f62",
                    "name": "ACM Cloud and Autonomic Computing Conference",
                    "type": "conference",
                    "alternate_names": [
                        "ACM Cloud Auton Comput Conf",
                        "Chinese Automation Congress",
                        "Chin Autom Congr",
                        "CAC"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2e480dc29e21541a6c96217f80528802f106b8ba",
                "title": "Image Self-Generation Based Defect Detection Method for Train Brake Pad",
                "abstract": "The brake pads of trains will inevitably wear out with use. The most common defect is the wear, missing or damage of the brake pad\u2019s friction block. This will directly affect the braking performance of the train and lead to potential risks to the safety of train operation. In order to detect defects on train brake pads with insufficient defect samples, an algorithm based on an image self-generation mechanism is proposed. This algorithm first identifies the brake pads at different locations in multi-view complete images of the bottom of the train. Then, utilizing multiple encoder-decoder combinations obtained by learning on normal samples, the algorithm can automatically generate defective samples and add them to the discriminator training for defect diagnosis. Experiments on real train brake pad data show that the proposed algorithm has higher performance and more usability than other advanced methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2144615838",
                        "name": "Hao Zhang"
                    },
                    {
                        "authorId": "145766219",
                        "name": "Xue Yuan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "AE/VAE-based Models Apart from the standard combination of reconstruction-error and AE/VAE models [111], [112], other methods use more sophisticated strategies such as reconstructing by memorized normality [115], [116], adapting model architectures [117], and partial/conditional reconstruction [89], [118], [119].",
                "2: Reconstruction-Error [89], [111], [111], [112], [112], [113], [113], [114], [115], [116], [117], [118], [119], [120], [121], [122], [123], [124]"
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "7b2180d7fa0d65e8756401cb077bf3dea3f9b575",
                "externalIds": {
                    "ArXiv": "2110.11334",
                    "DBLP": "journals/corr/abs-2110-11334",
                    "CorpusId": 239049401
                },
                "corpusId": 239049401,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7b2180d7fa0d65e8756401cb077bf3dea3f9b575",
                "title": "Generalized Out-of-Distribution Detection: A Survey",
                "abstract": "Out-of-distribution (OOD) detection is critical to ensuring the reliability and safety of machine learning systems. For instance, in autonomous driving, we would like the driving system to issue an alert and hand over the control to humans when it detects unusual scenes or objects that it has never seen during training time and cannot make a safe decision. The term, OOD detection, first emerged in 2017 and since then has received increasing attention from the research community, leading to a plethora of methods developed, ranging from classification-based to density-based to distance-based ones. Meanwhile, several other problems, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD), are closely related to OOD detection in terms of motivation and methodology. Despite common goals, these topics develop in isolation, and their subtle differences in definition and problem setting often confuse readers and practitioners. In this survey, we first present a unified framework called generalized OOD detection, which encompasses the five aforementioned problems, i.e., AD, ND, OSR, OOD detection, and OD. Under our framework, these five problems can be seen as special cases or sub-tasks, and are easier to distinguish. We then review each of these five areas by summarizing their recent technical developments, with a special focus on OOD detection methodologies. We conclude this survey with open challenges and potential research directions.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2295601",
                        "name": "Jingkang Yang"
                    },
                    {
                        "authorId": "9368124",
                        "name": "Kaiyang Zhou"
                    },
                    {
                        "authorId": "1527103472",
                        "name": "Yixuan Li"
                    },
                    {
                        "authorId": "2117940996",
                        "name": "Ziwei Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Our approach is different as we do not utilize any additional component and solely rely on the reconstruction based AEs.",
                "Reconstruction Based Methods: A common way to tackle the one-class classification (OCC) problem is by utilizing autoencoders (AEs) which learn normal data representations by reconstructing the inputs [9, 10, 29, 30, 35, 58].",
                "This clearly demonstrates the superiority of our proposed approach, i.e., training AEs by encouraging only normal data reconstructions assisted by pseudo anomalies.",
                "By encouraging to reconstruct only normal data for any kind of input (i.e., normal or pseudo anomalous), AEs are specifically trained to limit their reconstruction boundaries around the normal data hence not affecting the normal reconstructions while distorting anomalies, as illustrated in Fig.",
                "In contrast, our approach encourages AEs to produce unconstrained reconstructions for normal inputs while limiting the reconstructions for anomalous inputs, thus producing more discriminative anomaly scores.",
                ": LEARNING NOT TO RECONSTRUCT ANOMALIES 3 2 Related Works Reconstruction Based Methods: A common way to tackle the one-class classification (OCC) problem is by utilizing autoencoders (AEs) which learn normal data representations by reconstructing the inputs [9, 10, 29, 30, 35, 58].",
                "Typically, to tackle OCC problem, AEs are utilized to learn the normal representations by minimizing the reconstruction loss between the normal input XN and its reconstruction X\u0302N as follows:\nLN = 1 T \u00d7C\u00d7H\u00d7W \u2225\u2225X\u0302N\u2212XN\u2225\u22252F , (2)\nwhere \u2016.",
                "Concurrent with other recent anomaly detection methods [5, 24, 35], we utilize Peak Signal to Noise Ratio (PSNR) Pt between an input frame and its reconstruction to compute the anomaly score as follows:",
                "In order to capture rich information from video data, AEs are often designed to take multiple frames as input [9, 10, 35, 58].",
                "Non-Reconstruction Methods: Several researchers adopt different schemes for OCC based anomaly detection: focusing only on objects by utilizing object detectors in the frameworks [6, 7, 8, 11, 12, 43, 52]; predicting future frames from the past few consecutive frames with the intuition that it is difficult to predict unseen anomalous data [5, 24, 27, 28, 35]; or incorporating adversarial components [14, 19, 20, 24, 39, 45].",
                "Finally, following [5, 24, 35], the anomaly score St is obtained using min-max normalization of Pt as: St = 1\u2212 Pt \u2212mint(Pt) maxt(Pt)\u2212mint(Pt) , (10)",
                "However, since AEs can also wellreconstruct anomalous data [9, 33, 54, 60], several researchers proposed memory based networks to limit reconstruction capability of AEs [9, 35].",
                "One way to tackle the OCC problem is by using a deep autoencoder (AE) trained to reconstruct normal data [9, 10, 29, 30, 35, 58].",
                "Methods Ped2 [22] Ave [26] Sh [30] M is ce lla ne ou s AbnormalGAN [39] 93.5% - - Smeureanu et al. [41] - 84.6% - AMDN [49, 50] 90.8% - - STAN [19] 96.5% 87.2% - MC2ST [25] 87.5% 84.4% - Ionescu et al. [13] - 88.9% - BMAN [20] 96.6% 90.0% 76.2% AMC [34] 96.2% 86.9% - Vu et al. [45] 99.21% 71.54% - DeepOC [47] - 86.6% - TAM-Net [14] 98.1% 78.3% - LSA [1] 95.4% - 72.5% Ramachandra et al. [38] 94.0% 87.2% - Tang et al. [44] 96.3% 85.1% 73.0% Wang et al. [46] - 87.0% 79.3% OGNet [54] 98.1% - - Conv-VRNN [27] 96.06% 85.78% - Chang et al. [3] 96.5% 86.0% 73.3%\nO bj\nec t-\nce nt\nri c MT-FRCN [11] 92.2% - -\nIonescu et al. [12] 1 94.3% 87.4% 78.7% Doshi and Yilmaz [6, 7] 97.8% 86.4% 71.62% Sun et al. [43] - 89.6% 74.7% VEC [52] 97.3% 89.6% 74.8% Georgescu et al. [8] 98.7% 92.3% 82.7%\nMethods Ped2 [22] Ave [26] Sh [30]\nN on\nde ep\nle ar\nni ng MPPCA [15] 69.3% - - MPPC+SFA [15] 61.3% - - Mehran et al. [32] 55.6% - - MDT [31] 82.9% - - Lu et al. [26] - 80.9% - AMDN [50] 90.8% - - Del Giorno et al. [4] - 78.3% - LSHF [57] 91.0% - - Xu et al. [48] 88.2% - - Ramachandra and Jones [37] 88.3% 72.0% -\nPr ed\nic tio n Frame-Pred [24] 95.4% 85.1% 72.8% Dong et al. [5] 95.6% 84.9% 73.7% Lu et al. [28] 96.2% 85.8% 77.9% MNAD-Pred [35] 97.0% 88.5% 70.5%\nR ec\non st\nru ct\nio n AE-Conv2D [10] 90.0% 70.2% 60.85% AE-Conv3D [58] 91.2% 71.1% - AE-ConvLSTM [29] 88.10% 77.00% - TSC [30] 91.03% 80.56% 67.94% StackRNN [30] 92.21% 81.71% 68.00% MemAE [9] 94.1% 83.3% 71.2% MNAD-Recon [35] 90.2% 82.8% 69.8% Baseline 92.49% 81.47% 71.28% Ours: Patch based 94.77% 84.91% 72.46% Ours: Skip frame based 96.50% 84.67% 75.97%\n1Micro AUC reported in [8]\nTable 1: AUC performance comparison of our approach with several existing SOTA methods on Ped2, Avenue (Ave), and ShanghaiTech (Sh).",
                "To alleviate this problem, several researchers [9, 35] proposed employing a memory mechanism over the latent space between the encoder and the decoder of an AE to limit the reconstruction capability in the case of anomalous input.",
                "The contributions of this work are threefold: 1) We propose a pseudo anomaly based novel method of encouraging only normal data reconstructions to train AEs in the OCC setting.",
                "Interestingly, both of our models trained with different kinds of pseudo anomalies achieve better performance than the memory based networks, such as MNAD-Recon [35] and MemAE [9], considering that we use a very similar network architecture with these approaches and a common goal of limiting the AE capability of reconstructing anomalies."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "68661cad6ee64aa0b0eea029a50b65286525a58a",
                "externalIds": {
                    "DBLP": "conf/bmvc/AstridZLL21",
                    "ArXiv": "2110.09742",
                    "CorpusId": 239024474
                },
                "corpusId": 239024474,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/68661cad6ee64aa0b0eea029a50b65286525a58a",
                "title": "Learning Not to Reconstruct Anomalies",
                "abstract": "Video anomaly detection is often seen as one-class classification (OCC) problem due to the limited availability of anomaly examples. Typically, to tackle this problem, an autoencoder (AE) is trained to reconstruct the input with training set consisting only of normal data. At test time, the AE is then expected to well reconstruct the normal data while poorly reconstructing the anomalous data. However, several studies have shown that, even with only normal data training, AEs can often start reconstructing anomalies as well which depletes the anomaly detection performance. To mitigate this problem, we propose a novel methodology to train AEs with the objective of reconstructing only normal data, regardless of the input (i.e., normal or abnormal). Since no real anomalies are available in the OCC settings, the training is assisted by pseudo anomalies that are generated by manipulating normal data to simulate the out-of-normal-data distribution. We additionally propose two ways to generate pseudo anomalies: patch and skip frame based. Extensive experiments on three challenging video anomaly datasets demonstrate the effectiveness of our method in improving conventional AEs, achieving state-of-the-art performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145345698",
                        "name": "M. Astrid"
                    },
                    {
                        "authorId": "34148354",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "2108383541",
                        "name": "Jae-Yeong Lee"
                    },
                    {
                        "authorId": "3193599",
                        "name": "Seung-Ik Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following [1], [3], [10], [13], [16], [17], we scale the anomaly score to fall within the range of [0, 1]:"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "00469158ef8a1f5f53c9c685ce293b122e0980bb",
                "externalIds": {
                    "DBLP": "conf/smc/TangL21",
                    "DOI": "10.1109/SMC52423.2021.9658826",
                    "CorpusId": 245802506
                },
                "corpusId": 245802506,
                "publicationVenue": {
                    "id": "e84bb5a1-8f79-42cc-8eb1-3a52f7c73d63",
                    "name": "IEEE International Conference on Systems, Man and Cybernetics",
                    "type": "conference",
                    "alternate_names": [
                        "Smoky Mountains Computational Sciences and Engineering Conference",
                        "Smoky Mt Comput Sci Eng Conf",
                        "IEEE Int Conf Syst Man Cybern",
                        "SMC",
                        "Syst Man Cybern",
                        "Systems, Man and Cybernetics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/00469158ef8a1f5f53c9c685ce293b122e0980bb",
                "title": "A Latent Feature Autoencoder via Adversarial Training for Unsupervised Anomaly Detection",
                "abstract": "Anomaly detection is an active area of computer vision and widely applied in diverse fields. As known, it is a considerable challenge to collect abnormalities in practice. To tackle it, researchers propose many unsupervised or semi-supervised algorithms based on autoencoders or their variants. They focus on reconstruction loss between input and reconstructed samples but ignore the latent features extracted by an autoencoder. Namely, the existing algorithms tend to learn the local features of samples and have the approximate capabilities to reconstruct normal and abnormal samples. To capture the latent spatial features of anomaly detection, we present an unsupervised latent feature autoencoder via adversarial training. Particularly, we propose a weighted feature consistency loss to exploit the correlation between the corresponding layers of an encoder and decoder in the autoencoder. A feature discrimination loss is also designed to improve its ability to identify real and reconstructed samples by utilizing the latent spatial features of a discriminator. Next, we develop a discriminator that consists of two networks, i.e., a feature extraction network and a classification one. The pre-trained model can extract the input features accurately and stably, while the classification network can avoid excessive information losses and strengthen the ability to acquire deep semantics. Extensive experiments conducted on six public datasets show that the proposed method is competitive with the existing mainstream methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2021307128",
                        "name": "Wei Tang"
                    },
                    {
                        "authorId": "2152748618",
                        "name": "Jun Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As for anomaly detection, previous works (Gong et al. 2019; Park, Noh, and Ham 2020) have utilized memory to prevent unexpected generalization on anomalous inputs."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "1b5f98f3a27bc7d50620d45696d34405cd8fa1f7",
                "externalIds": {
                    "ArXiv": "2110.08306",
                    "DBLP": "journals/corr/abs-2110-08306",
                    "CorpusId": 239016694
                },
                "corpusId": 239016694,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1b5f98f3a27bc7d50620d45696d34405cd8fa1f7",
                "title": "Memory-augmented Adversarial Autoencoders for Multivariate Time-series Anomaly Detection with Deep Reconstruction and Prediction",
                "abstract": "Detecting anomalies for multivariate time-series without manual supervision continues a challenging problem due to the increased scale of dimensions and complexity of today's IT monitoring systems. Recent progress of unsupervised time-series anomaly detection mainly use deep autoencoders to solve this problem, i.e. training on normal samples and producing significant reconstruction error on abnormal inputs. However, in practice, autoencoders can reconstruct anomalies so well, due to powerful capabilites of neural networks. Besides, these approaches can be ineffective for identifying non-point anomalies, e.g. contextual anomalies and collective anomalies, since they solely utilze a point-wise reconstruction objective. To tackle the above issues, we propose MemAAE (\\textit{Memory-augmented Adversarial Autoencoders with Deep Reconstruction and Prediction}), a novel unsupervised anomaly detection method for time-series. By jointly training two complementary proxy tasks, reconstruction and prediction, with a shared network architecture, we show that detecting anomalies via multiple tasks obtains superior performance rather than single-task training. Additionally, a compressive memory module is introduced to preserve normal patterns, avoiding unexpected generalization on abnormal inputs. Through extensive experiments, MemAAE achieves an overall F1 score of 0.90 on four public datasets, significantly outperforming the best baseline by 0.02.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2113517543",
                        "name": "Qinfeng Xiao"
                    },
                    {
                        "authorId": "2137348770",
                        "name": "Shikuan Shao"
                    },
                    {
                        "authorId": "2152438043",
                        "name": "Jing Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[30] in both forms of 1) reconstruction-based: CUHK Avenue [21] by 4.",
                "[30], which produce spatial anomaly detection scores.",
                "[30] incorporates additional memory modules for both prediction-based and reconstruction-based anomaly detection.",
                "The baseline architectures of [30, 19] are trained for 15 epochs each on Nvidia RTX 2080 Ti GPU on ShanghaiTech [19] dataset, which took \u223c12hrs to complete.",
                "We performed micro-level evaluation, as done in [9, 30], where we concatenate all the sequence and learned the parameters for",
                "The memory-augmented autoencoders [30, 10] contain an extra memory module along with a prediction/reconstruction-based network.",
                "[30] uses convolutional autoencoders for both reconstruction and prediction networks.",
                "[30] contains an additional memory module which records prototypical pattern of normal data.",
                "come this drawback, memory-augmented auto-encoders [30, 10] are proposed.",
                "A common approach to aid in the learning is to use pre-trained systems to impose what is already known and learned, either in the form of optical flow [9], object detectors [32, 15, 36], skeletons [27], or memory augmentation [10, 30]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "ad701e78ec1c897542c7c0ecbf7590d6f3889422",
                "externalIds": {
                    "DBLP": "conf/iccvw/MadanFNEM21",
                    "DOI": "10.1109/ICCVW54120.2021.00244",
                    "CorpusId": 244350589
                },
                "corpusId": 244350589,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ad701e78ec1c897542c7c0ecbf7590d6f3889422",
                "title": "Temporal Cues from Socially Unacceptable Trajectories for Anomaly Detection",
                "abstract": "State-of-the-Art (SoTA) deep learning-based approaches to detect anomalies in surveillance videos utilize limited temporal information, including basic information from motion, e.g., optical flow computed between consecutive frames. In this paper, we compliment the SoTA methods by including long-range dependencies from trajectories for anomaly detection. To achieve that, we first created trajectories by running a tracker on two SoTA datasets, namely Avenue and Shanghai-Tech. We propose a prediction-based anomaly detection method using trajectories based on Social GANs, also called in this paper as temporal-based anomaly detection. Then, we hypothesize that late fusion of the result of this temporal-based anomaly detection system with spatial-based anomaly detection systems produces SoTA results. We verify this hypothesis on two spatial-based anomaly detection systems. We show that both cases produce results better than baseline spatial-based systems, indicating the usefulness of the temporal information coming from the trajectories for anomaly detection. We observe that the proposed approach depicts the maximum improvement in micro-level Area-Under-the-Curve (AUC) by 4.1% on CUHK Avenue and 3.4% on Shanghai-Tech over one of the baseline method. We also show a high performance on cross-data evaluation, where we learn the weights to combine spatial and temporal information on Shanghai-Tech and perform evaluation on CUHK Avenue and vice-versa.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "144074579",
                        "name": "Neelu Madan"
                    },
                    {
                        "authorId": "2141230919",
                        "name": "Arya Farkhondeh"
                    },
                    {
                        "authorId": "1803459",
                        "name": "Kamal Nasrollahi"
                    },
                    {
                        "authorId": "7855312",
                        "name": "Sergio Escalera"
                    },
                    {
                        "authorId": "1700569",
                        "name": "T. Moeslund"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently, it has also been utilized in anomaly detection [29, 18] where PSNR between an input frame and its reconstruction is used to calculate the anomaly score.",
                "2) Extensive experiments demonstrate the superiority of our method compared to a wide range of existing state-of-the-art (SOTA) works [12, 25, 22, 19, 44, 33, 8, 45, 20, 21, 34, 39, 1, 4, 18, 7, 29, 10] on three benchmark datasets.",
                "An AE is trained only on normal data for reconstruction [7, 29, 8, 45, 35, 39] or prediction [29, 18] tasks.",
                "With the recent popularity of deep learning, several researchers [8, 45, 39, 4, 28, 21, 29, 20, 35, 7] utilize autoencoder (AE) based networks to learn normal data representations.",
                "In order to capture robust representations, autoencoders (AE) are often designed to take multi-frame inputs [7, 29, 8, 45].",
                "Memory-based networks [7, 29] employ a memory mechanism over the latent space between the encoder and the decoder of an AE.",
                "Similar to the common practices in training a conventional AE [8, 29],",
                "One common way to tackle the OCC problem is by using a deep autoencoder (AE) [8, 45, 39, 4, 21, 29, 20, 35, 7].",
                "At test time, concurrent to the existing approaches [7, 29, 18, 8, 45, 39, 41], we predict anomaly scores at frame level."
            ],
            "isInfluential": true,
            "intents": [
                "result",
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8c81ec9f95b30e72a1140fabd689f75b1ba3cbcb",
                "externalIds": {
                    "DBLP": "conf/iccvw/AstridZL21",
                    "ArXiv": "2110.09768",
                    "DOI": "10.1109/ICCVW54120.2021.00028",
                    "CorpusId": 239024750
                },
                "corpusId": 239024750,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/8c81ec9f95b30e72a1140fabd689f75b1ba3cbcb",
                "title": "Synthetic Temporal Anomaly Guided End-to-End Video Anomaly Detection",
                "abstract": "Due to the limited availability of anomaly examples, video anomaly detection is often seen as one-class classification (OCC) problem. A popular way to tackle this problem is by utilizing an autoencoder (AE) trained only on normal data. At test time, the AE is then expected to reconstruct the normal input well while reconstructing the anomalies poorly. However, several studies show that, even with normal data only training, AEs can often start reconstructing anomalies as well which depletes their anomaly detection performance. To mitigate this, we propose a temporal pseudo anomaly synthesizer that generates fake-anomalies using only normal data. An AE is then trained to maximize the reconstruction loss on pseudo anomalies while minimizing this loss on normal data. This way, the AE is encouraged to produce distinguishable reconstructions for normal and anomalous frames. Extensive experiments and analysis on three challenging video anomaly datasets demonstrate the effectiveness of our approach to improve the basic AEs in achieving superiority against several existing state-of-the-art models.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145345698",
                        "name": "M. Astrid"
                    },
                    {
                        "authorId": "34148354",
                        "name": "M. Zaheer"
                    },
                    {
                        "authorId": "3193599",
                        "name": "Seung-Ik Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The read policy of memory bank is different from those used in memory networks [7, 8, 21, 25, 31, 32].",
                "Memory network usually reads and writes its item according to the similarity score [21, 25, 32].",
                "But for the memory network using the similarity scores as weights [21, 25, 32], gi is set to constant."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "c11fb05633b86549d1802f153dbede9e8ae99f49",
                "externalIds": {
                    "DBLP": "conf/iccv/LeeKS21",
                    "DOI": "10.1109/ICCV48922.2021.00731",
                    "CorpusId": 244873316
                },
                "corpusId": 244873316,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/c11fb05633b86549d1802f153dbede9e8ae99f49",
                "title": "Weakly Supervised Segmentation of Small Buildings with Point Labels",
                "abstract": "Most supervised image segmentation methods require delicate and time-consuming pixel-level labeling of building or objects, especially for small objects. In this paper, we present a weakly supervised segmentation network for aerial/satellite images, separately considering small and large objects. First, we propose a simple point labeling method for small objects, while large objects are fully labeled. Then, we present a segmentation network trained with a small object mask to separate small and large objects in the loss function. During training, we employ a memory bank to cope with the limited number of point labels. Experiments results with three public datasets demonstrate the feasibility of our approach.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2108806101",
                        "name": "Jae-Hun Lee"
                    },
                    {
                        "authorId": "2125798191",
                        "name": "ChanYoung Kim"
                    },
                    {
                        "authorId": "3153528",
                        "name": "S. Sull"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently, memory augmented neural networks have been introduced in various computer vision fields [6, 10, 15, 18, 30, 31, 37, 43, 50, 52, 61]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "141cb4b4af2a9b7e449c1eda554d937ebead0ad6",
                "externalIds": {
                    "DBLP": "conf/iccv/KimPR21",
                    "DOI": "10.1109/ICCV48922.2021.00304",
                    "CorpusId": 244895790
                },
                "corpusId": 244895790,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/141cb4b4af2a9b7e449c1eda554d937ebead0ad6",
                "title": "Robust Small-scale Pedestrian Detection with Cued Recall via Memory Learning",
                "abstract": "Although the visual appearances of small-scale objects are not well observed, humans can recognize them by associating the visual cues of small objects from their memorized appearance. It is called cued recall. In this paper, motivated by the memory process of humans, we introduce a novel pedestrian detection framework that imitates cued recall in detecting small-scale pedestrians. We propose a large-scale embedding learning with the large-scale pedestrian recalling memory (LPR Memory). The purpose of the proposed large-scale embedding learning is to memorize and recall the large-scale pedestrian appearance via the LPR Memory. To this end, we employ the large-scale pedestrian exemplar set, so that, the LPR Memory can recall the information of the large-scale pedestrians from the small-scale pedestrians. Comprehensive quantitative and qualitative experimental results validate the effectiveness of the proposed framework with the LPR Memory.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2110838691",
                        "name": "Jung Uk Kim"
                    },
                    {
                        "authorId": "70213349",
                        "name": "Sungjune Park"
                    },
                    {
                        "authorId": "7251290",
                        "name": "Yong Man Ro"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "19fd7a304b1496260adcc4e85de7a26e51646543",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2109-14020",
                    "ArXiv": "2109.14020",
                    "CorpusId": 238215561
                },
                "corpusId": 238215561,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/19fd7a304b1496260adcc4e85de7a26e51646543",
                "title": "Y-GAN: Learning Dual Data Representations for Efficient Anomaly Detection",
                "abstract": "We propose a novel reconstruction-based model for anomaly detection, called Y-GAN. The model consists of a Y-shaped auto-encoder and represents images in two separate latent spaces. The first captures meaningful image semantics, key for representing (normal) training data, whereas the second encodes low-level residual image characteristics. To ensure the dual representations encode mutually exclusive information, a disentanglement procedure is designed around a latent (proxy) classifier. Additionally, a novel consistency loss is proposed to prevent information leakage between the latent spaces. The model is trained in a one-class learning setting using normal training data only. Due to the separation of semantically-relevant and residual information, Y-GAN is able to derive informative data representations that allow for efficient anomaly detection across a diverse set of anomaly detection tasks. The model is evaluated in comprehensive experiments with several recent anomaly detection models using four popular datasets, i.e., MNIST, FMNIST and CIFAR10, and PlantVillage.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2088933365",
                        "name": "Marija Ivanovska"
                    },
                    {
                        "authorId": "2011218",
                        "name": "V. \u0160truc"
                    }
                ]
            }
        },
        {
            "contexts": [
                "deep lear ing [60, 136]) have been provided.",
                "They also use deep architectures to learn a compressed representation for the training data, by reducing the number of hidden units [60].",
                "ey also se ee arc itect res to lear a co resse re rese tatio for t e trai i g ata, by re ci g t e ber of i e its [60].",
                "d ep learning [60, 136]) have b en provided.",
                "deep learning [60, 136]) have been provided."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "35aded5d84ca7f6c74a66116927401d9d204c2bc",
                "externalIds": {
                    "DBLP": "journals/itc/MuSYW21",
                    "DOI": "10.5755/j01.itc.50.3.27864",
                    "CorpusId": 238862971
                },
                "corpusId": 238862971,
                "publicationVenue": {
                    "id": "a4309073-67f4-4a9c-91e4-a8a7b73ff0cf",
                    "name": "Information Technology and Control",
                    "type": "journal",
                    "alternate_names": [
                        "Information Technologies and Control",
                        "Inf Technol Control"
                    ],
                    "issn": "1392-124X",
                    "alternate_issns": [
                        "1312-2622"
                    ],
                    "url": "http://itc.ktu.lt/",
                    "alternate_urls": [
                        "http://www.acad.bg/rismim/itc/index.html",
                        "http://www.itc.ktu.lt/index.php/ITC",
                        "http://ei.libis.lt/pradinis.php?antras=mokslas/zurnalai/zurnalai.html&pirmas=mokslas/mokslas_menu.html&url=http://www.ktu.lt/lt/scriptas1.asp?meniu%3Dvirsus2_3.html",
                        "http://eia.libis.lt/isteklius.php?url=http://itc.ktu.lt/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/35aded5d84ca7f6c74a66116927401d9d204c2bc",
                "title": "Abnormal Human Behavior Detection in Videos: A Review",
                "abstract": "Modeling human behavior patterns for detecting the abnormal event has become an important domain in recentyears. A lot of efforts have been made for building smart video surveillance systems with the purpose ofscene analysis and making correct semantic inference from the video moving target. Current approaches havetransferred from rule-based to statistical-based methods with the need of efficient recognition of high-levelactivities. This paper presented not only an update expanding previous related researches, but also a study coveredthe behavior representation and the event modeling. Especially, we provided a new perspective for eventmodeling which divided the methods into the following subcategories: modeling normal event, predictionmodel, query model and deep hybrid model. Finally, we exhibited the available datasets and popular evaluationschemes used for abnormal behavior detection in intelligent video surveillance. More researches will promotethe development of abnormal human behavior detection, e.g. deep generative network, weakly-supervised. It isobviously encouraged and dictated by applications of supervising and monitoring in private and public space.The main purpose of this paper is to widely recognize recent available methods and represent the literature ina way of that brings key challenges into notice.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "40959390",
                        "name": "Huiyu Mu"
                    },
                    {
                        "authorId": "2124674",
                        "name": "Ruizhi Sun"
                    },
                    {
                        "authorId": "122634575",
                        "name": "Gang Yuan"
                    },
                    {
                        "authorId": "2118375819",
                        "name": "Yun Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In early stages, the unsupervised video anomaly detection methods are dominating and they can be categorized into two categories, the reconstruction methods [1, 2, 3, 4, 5, 6, 7] and prediction methods [8, 9]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "1288eb9c5d83e08c9ebff35d9f9b76437dd25bce",
                "externalIds": {
                    "MAG": "3193710481",
                    "DBLP": "conf/icip/ZhenGWB021",
                    "DOI": "10.1109/ICIP42928.2021.9506580",
                    "CorpusId": 238704887
                },
                "corpusId": 238704887,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1288eb9c5d83e08c9ebff35d9f9b76437dd25bce",
                "title": "Multi-Scale Background Suppression Anomaly Detection In Surveillance Videos",
                "abstract": "Video anomaly detection has been widely applied in various surveillance systems for public security. However, the existing weakly supervised video anomaly detection methods tend to ignore the interference of the background frames and possess limited ability to extract effective temporal information among the video snippets. In this paper, a multi-scale background suppression based anomaly detection (MSBSAD) method is proposed to suppress the interference of the background frames. We propose a multi-scale temporal convolution module to effectively extract more temporal information among the video snippets for the anomaly events with different durations. A modified hinge loss is constructed in the suppression branch to help our model to better differentiate the abnormal samples from the confusing samples. Experiments on UCF Crime demonstrate the superiority of our MS-BSAD method in the video anomaly detection task.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2104017964",
                        "name": "Yang Zhen"
                    },
                    {
                        "authorId": "152699317",
                        "name": "Yuanfan Guo"
                    },
                    {
                        "authorId": "2111524869",
                        "name": "Jinjie Wei"
                    },
                    {
                        "authorId": "39844997",
                        "name": "Xiuguo Bao"
                    },
                    {
                        "authorId": "2148909376",
                        "name": "Di Huang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Many deep learningbased methods have been proposed [1], with a wide range of input data, including sound [2], big data [3], signal data [4], natural language [5], image [6], and video [7]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "ca6294ce6f38f3f6ff694ba67d02eaad7fc92f4e",
                "externalIds": {
                    "ArXiv": "2304.03420",
                    "DBLP": "conf/icip/MasudaHFSS21",
                    "MAG": "3194885736",
                    "DOI": "10.1109/ICIP42928.2021.9506795",
                    "CorpusId": 238690177
                },
                "corpusId": 238690177,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ca6294ce6f38f3f6ff694ba67d02eaad7fc92f4e",
                "title": "Toward Unsupervised 3d Point Cloud Anomaly Detection Using Variational Autoencoder",
                "abstract": "In this paper, we present an end-to-end unsupervised anomaly detection framework for 3D point clouds. To the best of our knowledge, this is the first work to tackle the anomaly detection task on a general object represented by a 3D point cloud. We propose a deep variational autoencoder based unsupervised anomaly detection network adapted to the 3D point cloud and an anomaly score specifically for 3D point clouds. To verify the effectiveness of the model, we conducted extensive experiments on ShapeNet dataset. Through quantitative and qualitative evaluation, we demonstrate that the proposed method outperforms the baseline method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2037409608",
                        "name": "Mana Masuda"
                    },
                    {
                        "authorId": "10681518",
                        "name": "Ryo Hachiuma"
                    },
                    {
                        "authorId": "151184222",
                        "name": "Ryoske Fujii"
                    },
                    {
                        "authorId": "145791378",
                        "name": "H. Saito"
                    },
                    {
                        "authorId": "144560591",
                        "name": "Yusuke Sekikawa"
                    }
                ]
            }
        },
        {
            "contexts": [
                "With the advent of deep learning, AE-based approaches are dominating this area and achieve state-of-the-art performance [1], [5], [7], [8], [23], [31], [32], [33], [34].",
                "This can be achieved by constraining the latent space to make the features closer to a prior distribution [7], [23]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4093d9e59f0be07b709d1157aab7fa2d0e41689b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-11168",
                    "ArXiv": "2108.11168",
                    "DOI": "10.1109/TPAMI.2022.3189638",
                    "CorpusId": 237291787,
                    "PubMed": "35816537"
                },
                "corpusId": 237291787,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4093d9e59f0be07b709d1157aab7fa2d0e41689b",
                "title": "Adversarially Robust One-Class Novelty Detection",
                "abstract": "One-class novelty detectors are trained with examples of a particular class and are tasked with identifying whether a query example belongs to the same known class. Most recent advances adopt a deep auto-encoder style architecture to compute novelty scores for detecting novel class data. Deep networks have shown to be vulnerable to adversarial attacks, yet little focus is devoted to studying the adversarial robustness of deep novelty detectors. In this article, we first show that existing novelty detectors are susceptible to adversarial examples. We further demonstrate that commonly-used defense approaches for classification tasks have limited effectiveness in one-class novelty detection. Hence, we need a defense specifically designed for novelty detection. To this end, we propose a defense strategy that manipulates the latent space of novelty detectors to improve the robustness against adversarial examples. The proposed method, referred to as Principal Latent Space (PrincipaLS), learns the incrementally-trained cascade principal components in the latent space to robustify novelty detectors. PrincipaLS can purify latent space against adversarial examples and constrain latent space to exclusively model the known class distribution. We conduct extensive experiments on eight attacks, five datasets and seven novelty detectors, showing that PrincipaLS consistently enhances the adversarial robustness of novelty detection models.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "80977068",
                        "name": "Shao-Yuan Lo"
                    },
                    {
                        "authorId": "144477698",
                        "name": "Poojan Oza"
                    },
                    {
                        "authorId": "1741177",
                        "name": "Vishal M. Patel"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The first one is widely adopted in existing literature [37, 10, 22, 19, 23, 27], where only normal videos are available during training.",
                "MemAE [10] and LMN [37] are most-related methods to our approach.",
                "Previous approaches [37, 10] proposed to explicitly model the shared normal patterns across normal training videos with a memory bank, for",
                "To this end, [37] defines a rule for updating items in the memory bank based on a threshold to record normal patterns and ignore abnormal ones.",
                "[37] further expand the update rules of the memory bank by using a threshold to distinguish abnormal frames and record normal patterns.",
                "(LMN) [37] introduce a memory bank into the AE for anomaly detecE Encoder DDecoder EnsembleOperation AggregationOperation",
                "Gong et al. (MemAE) [10] and Park et al. (LMN) [37] introduce a memory bank into the AE for anomaly detec-\ntion.",
                "We adopt the same network architecture in [22, 37] as the backbone of AE to facilitate a fair comparison.",
                "The learning procedure is fully differentiable and the prototypes are dynamically learned with the benefits of adapting to the current scene spatially and temporally, compared with querying and updating the memory bank with pre-defined rules for recording rough patterns cross the training data in [10, 37].",
                "These models are prone to face the \u2018overgeneralizing\u2019 dilemma, where all video frames can be predicted well, no matter they are normal or abnormal, owing to the powerful representation capacity of convolutional neural networks (CNNs) [37, 10].",
                "Moreover, the prototypes are automatically derived based on the real-time video data during inference, without referencing to the memory items collected from the training phase [10, 37]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "7188bfc6b763da275c53ed3f76c5c4be5439ef7f",
                "externalIds": {
                    "ArXiv": "2108.11055",
                    "DBLP": "journals/corr/abs-2108-11055",
                    "CorpusId": 237290073
                },
                "corpusId": 237290073,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7188bfc6b763da275c53ed3f76c5c4be5439ef7f",
                "title": "Normal Learning in Videos with Attention Prototype Network",
                "abstract": "Frame reconstruction (current or future frame) based on Auto-Encoder (AE) is a popular method for video anomaly detection. With models trained on the normal data, the reconstruction errors of anomalous scenes are usually much larger than those of normal ones. Previous methods introduced the memory bank into AE, for encoding diverse normal patterns across the training videos. However, they are memory consuming and cannot cope with unseen new scenarios in the testing data. In this work, we propose a self-attention prototype unit (APU) to encode the normal latent space as prototypes in real time, free from extra memory cost. In addition, we introduce circulative attention mechanism to our backbone to form a novel feature extracting learner, namely Circulative Attention Unit (CAU). It enables the fast adaption capability on new scenes by only consuming a few iterations of update. Extensive experiments are conducted on various benchmarks. The superior performance over the state-of-the-art demonstrates the effectiveness of our method. Our code isavail-able at https://github.com/huchao-AI/APN/.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118130805",
                        "name": "Chao Hu"
                    },
                    {
                        "authorId": "2116490292",
                        "name": "Fan Wu"
                    },
                    {
                        "authorId": "1515514053",
                        "name": "Weijie Wu"
                    },
                    {
                        "authorId": "2057146186",
                        "name": "Weibin Qiu"
                    },
                    {
                        "authorId": "2146349348",
                        "name": "Shengxin Lai"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", one-shot learning [1], video object segmentation [26], domain adaptation [48], image colorization [42], and anomaly detection [6, 27]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "760fed70cbb6a6739722148c111b5ac123ad20fa",
                "externalIds": {
                    "DBLP": "conf/iccv/EomLLH21",
                    "ArXiv": "2108.09039",
                    "DOI": "10.1109/ICCV48922.2021.01182",
                    "CorpusId": 237259923
                },
                "corpusId": 237259923,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/760fed70cbb6a6739722148c111b5ac123ad20fa",
                "title": "Video-based Person Re-identification with Spatial and Temporal Memory Networks",
                "abstract": "Video-based person re-identification (reID) aims to retrieve person videos with the same identity as a query person across multiple cameras. Spatial and temporal distractors in person videos, such as background clutter and partial occlusions over frames, respectively, make this task much more challenging than image-based person reID. We observe that spatial distractors appear consistently in a particular location, and temporal distractors show several patterns, e.g., partial occlusions occur in the first few frames, where such patterns provide informative cues for predicting which frames to focus on (i.e., temporal attentions). Based on this, we introduce a novel Spatial and Temporal Memory Networks (STMN). The spatial memory stores features for spatial distractors that frequently emerge across video frames, while the temporal memory saves attentions which are optimized for typical temporal patterns in person videos. We leverage the spatial and temporal memories to refine frame-level person representations and to aggregate the refined frame-level features into a sequence-level person representation, respectively, effectively handling spatial and temporal distractors in person videos. We also introduce a memory spread loss preventing our model from addressing particular items only in the memories. Experimental results on standard benchmarks, including MARS, DukeMTMC-VideoReID, and LSVID, demonstrate the effectiveness of our method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "9366027",
                        "name": "Chanho Eom"
                    },
                    {
                        "authorId": "2140802823",
                        "name": "Geon Lee"
                    },
                    {
                        "authorId": "26973831",
                        "name": "Junghyup Lee"
                    },
                    {
                        "authorId": "38723538",
                        "name": "Bumsub Ham"
                    }
                ]
            }
        },
        {
            "contexts": [
                "From top to bottom, we show the sampled video frames, ground-truth abnormal sections (green regions are abnormal), result of MNAD-R [38], result of MNAD-P [38], result of VEC-VAD [47] and result of HF(2)-VAD.",
                "We compare our proposed HF2-VAD with state-of-the-art methods, including (1) reconstruction-based methods: Conv-AE [11], ConvLSTMAE [31], GMFC-VAE [7], MemAE [8] and MNADR [38]; (2) prediction-based methods: Frame-Pred.",
                "[38] follow this trend and present a more compact memory that can be updated during testing.",
                "[25], MNAD-P [38], VEC [47] and Conv-VRNN [30]; and (3) hybrid methods including ST-AE [50], AMC [36] and AnoPCN [46].",
                "Rather than traditional handcrafted feature based methods [1, 20, 2, 34], a lot of modern deep neural network based methods [11, 45, 50, 31, 25, 30, 8, 36, 38, 47, 43, 24] have been proposed for VAD.",
                "For saving space, we do not show predicted frames by VEC and MNAD-P, but instead show the difference maps\nbetween the ground-truth and the predicted frames by HF2VAD, VEC and MNAD-P in the last three columns respectively.",
                "Reconstruction-based methods [11, 31, 8, 36, 7, 38] typically train autoencoders on normal data.",
                "Placing a memory module at the bottleneck of AE is a recent development in VAD community [8, 38].",
                "As can be seen, VEC and HF2-VAD perform much better than MNAD-R and MNAD-P in normal sections, producing lower and more stable anomaly scores.",
                "We compare our proposed HF(2)-VAD with state-of-the-art methods, including (1) reconstruction-based methods: Conv-AE [11], ConvLSTMAE [31], GMFC-VAE [7], MemAE [8] and MNADR [38]; (2) prediction-based methods: Frame-Pred.",
                "Examples in Figure 5 show anomaly curves of two testing videos compared among MNAD-R [38], MNAD-P [38], VEC [47] and HF2-VAD.",
                "Future frame prediction is another prevalent VAD paradigm, often obtaining better anomaly detection accuracy than reconstruction-based methods [47, 38].",
                "Inspired by [8, 38], we design a Multi-Level Memoryaugmented Autoencoder with Skip Connections (MLMemAE-SC) for optical flow reconstruction."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5cccc8bab11927e5527dd5b917ed4c306a2ccf49",
                "externalIds": {
                    "ArXiv": "2108.06852",
                    "DBLP": "journals/corr/abs-2108-06852",
                    "DOI": "10.1109/ICCV48922.2021.01333",
                    "CorpusId": 237091198
                },
                "corpusId": 237091198,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/5cccc8bab11927e5527dd5b917ed4c306a2ccf49",
                "title": "A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction",
                "abstract": "In this paper, we propose HF2-VAD, a Hybrid framework that integrates Flow reconstruction and Frame prediction seamlessly to handle Video Anomaly Detection. Firstly, we design the network of ML-MemAE-SC (Multi-Level Memory modules in an Autoencoder with Skip Connections) to memorize normal patterns for optical flow reconstruction so that abnormal events can be sensitively identified with larger flow reconstruction errors. More importantly, conditioned on the reconstructed flows, we then employ a Conditional Variational Autoencoder (CVAE), which captures the high correlation between video frame and optical flow, to predict the next frame given several previous frames. By CVAE, the quality of flow reconstruction essentially influences that of frame prediction. Therefore, poorly reconstructed optical flows of abnormal events further deteriorate the quality of the final predicted future frame, making the anomalies more detectable. Experimental results demonstrate the effectiveness of the proposed method. Code is available at https://github.com/LiUzHiAn/hf2vad.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2124012978",
                        "name": "Zhian Liu"
                    },
                    {
                        "authorId": "37221211",
                        "name": "Yongwei Nie"
                    },
                    {
                        "authorId": "48015811",
                        "name": "Chengjiang Long"
                    },
                    {
                        "authorId": "2108056030",
                        "name": "Qing Zhang"
                    },
                    {
                        "authorId": "2108694687",
                        "name": "Guiqing Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "flexibility, it is adapted to a variety of tasks, such as fewshot learning [41], [42], video summarization [43], image captioning [44], anomaly detection [45], etc."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "134a6cdab5a7477ba3ddae68bef994f4f20ec733",
                "externalIds": {
                    "DBLP": "conf/iros/JinHK21",
                    "ArXiv": "2108.05635",
                    "DOI": "10.1109/IROS51168.2021.9636620",
                    "CorpusId": 236986912
                },
                "corpusId": 236986912,
                "publicationVenue": {
                    "id": "37275deb-3fcf-4d16-ae77-95db9899b1f3",
                    "name": "IEEE/RJS International Conference on Intelligent RObots and Systems",
                    "type": "conference",
                    "alternate_names": [
                        "IROS",
                        "Intelligent Robots and Systems",
                        "Intell Robot Syst",
                        "IEEE/RJS Int Conf Intell Robot Syst"
                    ],
                    "url": "http://www.iros.org/"
                },
                "url": "https://www.semanticscholar.org/paper/134a6cdab5a7477ba3ddae68bef994f4f20ec733",
                "title": "Memory-based Semantic Segmentation for Off-road Unstructured Natural Environments",
                "abstract": "With the availability of many datasets tailored for autonomous driving in real-world urban scenes, semantic segmentation for urban driving scenes achieves significant progress. However, semantic segmentation for off-road, unstructured environments is not widely studied. Directly applying existing segmentation networks often results in performance degradation as they cannot overcome intrinsic problems in such environments, such as illumination changes. In this paper, a built-in memory module for semantic segmentation is proposed to overcome these problems. The memory module stores significant representations of training images as memory items. In addition to the encoder embedding like items together, the proposed memory module is specifically designed to cluster together instances of the same class even when there are significant variances in embedded features. Therefore, it makes segmentation networks better deal with unexpected illumination changes. A triplet loss is used in training to minimize redundancy in storing discriminative representations of the memory module. The proposed memory module is general so that it can be adopted in a variety of networks. We conduct experiments on the Robot Unstructured Ground Driving (RUGD) dataset and RELLIS dataset, which are collected from off-road, unstructured natural environments. Experimental results show that the proposed memory module improves the performance of existing segmentation networks and contributes to capturing unclear objects over various off-road, unstructured natural scenes with equivalent computational cost and network parameters. As the proposed method can be integrated into compact networks, it presents a viable approach for resource-limited small autonomous platforms.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "66957238",
                        "name": "Youngsaeng Jin"
                    },
                    {
                        "authorId": "2757702",
                        "name": "D. Han"
                    },
                    {
                        "authorId": "144878703",
                        "name": "Hanseok Ko"
                    }
                ]
            }
        },
        {
            "contexts": [
                "mance on image-to-image tasks such as segmentation and super-resolution, has been widely used in previous anomaly detection methods [14, 22, 24, 29].",
                "Some methods [8, 24] exploited memory networks to read and write normal patterns and made reconstructions biased to normal events.",
                "Although these methods achieved improved performance, most of them require heavy computations as they employ conventional U-Net for reconstruction or prediction [14, 22, 24, 29]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "9a0dc6bdd589c1c6fae74e3acd46232381754232",
                "externalIds": {
                    "DBLP": "conf/avss/JinHHK21",
                    "ArXiv": "2108.04454",
                    "DOI": "10.1109/AVSS52988.2021.9663798",
                    "CorpusId": 236965487
                },
                "corpusId": 236965487,
                "publicationVenue": {
                    "id": "827334c9-c744-4f75-9b28-571cb89ad45f",
                    "name": "Advanced Video and Signal Based Surveillance",
                    "type": "conference",
                    "alternate_names": [
                        "AVSS",
                        "Adv Video Signal Based Surveill"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=266"
                },
                "url": "https://www.semanticscholar.org/paper/9a0dc6bdd589c1c6fae74e3acd46232381754232",
                "title": "CPNet: Cross-Parallel Network for Efficient Anomaly Detection",
                "abstract": "Anomaly detection in video streams is a challenging problem because of the scarcity of abnormal events and the difficulty of accurately annotating them. To alleviate these issues, unsupervised learning-based prediction methods have been previously applied. These approaches train the model with only normal events and predict a future frame from a sequence of preceding frames by use of encoder-decoder architectures so that they result in small prediction errors on normal events but large errors on abnormal events. The architecture, however, comes with the computational burden as some anomaly detection tasks require low computational cost without sacrificing performance. In this paper, Cross-Parallel Network (CPNet) for efficient anomaly detection is proposed here to minimize computations without performance drops. It consists of N smaller parallel U-Net, each of which is designed to handle a single input frame, to make the calculations significantly more efficient. Additionally, an inter-network shift module is incorporated to capture temporal relationships among sequential frames to enable more accurate future predictions. The quantitative results show that our model requires less computational cost than the baseline U-Net while delivering equivalent performance in anomaly detection.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "66957238",
                        "name": "Youngsaeng Jin"
                    },
                    {
                        "authorId": "2149084558",
                        "name": "Jonghwan Hong"
                    },
                    {
                        "authorId": "2757702",
                        "name": "D. Han"
                    },
                    {
                        "authorId": "144878703",
                        "name": "Hanseok Ko"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Similarly, Park et al. [60] advocated a memory module with new update scheme to learn the feature representation of normal behaviors.",
                "00 - - - - - - - - Park et al.[60]-2020 88.",
                "[60] advocated a memory module with new update scheme to learn the feature representation of normal behaviors.",
                "00 - - - Park et al.[60]-2020 - - - - - 97."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "a024ac49a2b3272ee174ef2a991d3515359fe148",
                "externalIds": {
                    "DBLP": "journals/ijon/WuLCH21",
                    "MAG": "3189010710",
                    "DOI": "10.1016/J.NEUCOM.2021.05.112",
                    "CorpusId": 238812255
                },
                "corpusId": 238812255,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a024ac49a2b3272ee174ef2a991d3515359fe148",
                "title": "Improving video anomaly detection performance by mining useful data from unseen video frames",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "12533022",
                        "name": "Renzhi Wu"
                    },
                    {
                        "authorId": "1750922204",
                        "name": "Shuai Li"
                    },
                    {
                        "authorId": "3289090",
                        "name": "Chenglizhao Chen"
                    },
                    {
                        "authorId": "144795824",
                        "name": "A. Hao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[44] propose a new memory module to record normal prototypical patterns, which is deployed in the reconstruction and prediction networks respectively."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "712e926751b3d2c5e5b01f7c3be5eab6e7cb149b",
                "externalIds": {
                    "ArXiv": "2108.02356",
                    "DBLP": "journals/corr/abs-2108-02356",
                    "CorpusId": 236924553
                },
                "corpusId": 236924553,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/712e926751b3d2c5e5b01f7c3be5eab6e7cb149b",
                "title": "Video Abnormal Event Detection by Learning to Complete Visual Cloze Tests",
                "abstract": "Although deep neural networks (DNNs) enable great progress in video abnormal event detection (VAD), existing solutions typically suffer from two issues: (1) The localization of video events cannot be both precious and comprehensive. (2) The semantics and temporal context are under-explored. To tackle those issues, we are motivated by the prevalent cloze test in education and propose a novel approach named Visual Cloze Completion (VCC), which conducts VAD by learning to complete\"visual cloze tests\"(VCTs). Specifically, VCC first localizes each video event and encloses it into a spatio-temporal cube (STC). To achieve both precise and comprehensive localization, appearance and motion are used as complementary cues to mark the object region associated with each event. For each marked region, a normalized patch sequence is extracted from current and adjacent frames and stacked into a STC. With each patch and the patch sequence of a STC compared to a visual\"word\"and\"sentence\"respectively, we deliberately erase a certain\"word\"(patch) to yield a VCT. Then, the VCT is completed by training DNNs to infer the erased patch and its optical flow via video semantics. Meanwhile, VCC fully exploits temporal context by alternatively erasing each patch in temporal context and creating multiple VCTs. Furthermore, we propose localization-level, event-level, model-level and decision-level solutions to enhance VCC, which can further exploit VCC's potential and produce significant performance improvement gain. Extensive experiments demonstrate that VCC achieves state-of-the-art VAD performance. Our codes and results are open at https://github.com/yuguangnudt/VEC_VAD/tree/VCC.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1421268306",
                        "name": "Siqi Wang"
                    },
                    {
                        "authorId": "2116615990",
                        "name": "Guang Yu"
                    },
                    {
                        "authorId": "143942560",
                        "name": "Zhiping Cai"
                    },
                    {
                        "authorId": "2108754292",
                        "name": "Xinwang Liu"
                    },
                    {
                        "authorId": "143753739",
                        "name": "En Zhu"
                    },
                    {
                        "authorId": "145311707",
                        "name": "Jianping Yin"
                    },
                    {
                        "authorId": "2143543790",
                        "name": "Qing Liao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "f71663aa71f1dd4e3540df2e968f85d802a47846",
                "externalIds": {
                    "ArXiv": "2108.01975",
                    "DBLP": "conf/cvpr/YuWCLXW22",
                    "DOI": "10.1109/CVPR52688.2022.01360",
                    "CorpusId": 249917174
                },
                "corpusId": 249917174,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f71663aa71f1dd4e3540df2e968f85d802a47846",
                "title": "Deep Anomaly Discovery from Unlabeled Videos via Normality Advantage and Self-Paced Refinement",
                "abstract": "While classic video anomaly detection (VAD) requires labeled normal videos for training, emerging unsupervised VAD (UVAD) aims to discover anomalies directly from fully unlabeled videos. However, existing UVAD methods still rely on shallow models to perform detection or initialization, and they are evidently inferior to classic VAD methods. This paper proposes a full deep neural network (DNN) based solution that can realize highly effective UVAD. First, we, for the first time, point out that deep reconstruction can be surprisingly effective for UVAD, which inspires us to unveil a property named \u201cnormality advantage\u201d, i.e., normal events will enjoy lower reconstruction loss when DNN learns to reconstruct unlabeled videos. With this property, we propose Localization based Reconstruction (LBR) as a strong UVAD baseline and a solid foundation of our solution. Second, we propose a novel self-paced refinement (SPR) scheme, which is synthesized into LBR to conduct UVAD. Unlike ordinary self-paced learning that injects more samples in an easy-to-hard manner, the proposed SPR scheme gradually drops samples so that suspicious anomalies can be removed from the learning process. In this way, SPR consolidates normality advantage and enables better UVAD in a more proactive way. Finally, we further design a variant solution that explicitly takes the motion cues into account. The solution evidently enhances the UVAD performance, and it sometimes even surpasses the best classic VAD methods. Experiments show that our solution not only significantly outperforms existing UVAD methods by a wide margin (5% to 9% AUROC), but also enables UVAD to catch up with the mainstream performance of classic VAD.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2116615990",
                        "name": "Guang Yu"
                    },
                    {
                        "authorId": "2143244326",
                        "name": "Siqi Wang"
                    },
                    {
                        "authorId": "143942560",
                        "name": "Zhiping Cai"
                    },
                    {
                        "authorId": "2130021053",
                        "name": "Xinwang Liu"
                    },
                    {
                        "authorId": "7521170",
                        "name": "Chuanfu Xu"
                    },
                    {
                        "authorId": "2151103182",
                        "name": "Cheng-Feng Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
                "externalIds": {
                    "ArXiv": "2108.00462",
                    "DBLP": "journals/corr/abs-2108-00462",
                    "CorpusId": 236772195
                },
                "corpusId": 236772195,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
                "title": "Explainable Deep Few-shot Anomaly Detection with Deviation Networks",
                "abstract": "Existing anomaly detection paradigms overwhelmingly focus on training detection models using exclusively normal data or unlabeled data (mostly normal samples). One notorious issue with these approaches is that they are weak in discriminating anomalies from normal samples due to the lack of the knowledge about the anomalies. Here, we study the problem of few-shot anomaly detection, in which we aim at using a few labeled anomaly examples to train sample-efficient discriminative detection models. To address this problem, we introduce a novel weakly-supervised anomaly detection framework to train detection models without assuming the examples illustrating all possible classes of anomaly. Specifically, the proposed approach learns discriminative normality (regularity) by leveraging the labeled anomalies and a prior probability to enforce expressive representations of normality and unbounded deviated representations of abnormality. This is achieved by an end-to-end optimization of anomaly scores with a neural deviation learning, in which the anomaly scores of normal samples are imposed to approximate scalar scores drawn from the prior while that of anomaly examples is enforced to have statistically significant deviations from these sampled scores in the upper tail. Furthermore, our model is optimized to learn fine-grained normality and abnormality by top-K multiple-instance-learning-based feature subspace deviation learning, allowing more generalized representations. Comprehensive experiments on nine real-world image anomaly detection benchmarks show that our model is substantially more sample-efficient and robust, and performs significantly better than state-of-the-art competing methods in both closed-set and open-set settings. Our model can also offer explanation capability as a result of its prior-driven anomaly score learning. Code and datasets are available at: https://git.io/DevNet.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3224619",
                        "name": "Guansong Pang"
                    },
                    {
                        "authorId": "2153255258",
                        "name": "Choubo Ding"
                    },
                    {
                        "authorId": "1780381",
                        "name": "Chunhua Shen"
                    },
                    {
                        "authorId": "5546141",
                        "name": "A. Hengel"
                    }
                ]
            }
        },
        {
            "contexts": [
                "4.1.2 CUHK Avenue.",
                "CUHK Avenue includes pedestrians and objects both moving parallel to or toward/away from the camera.",
                "Despite a substantial amount of research effort has been devoted to this problem [3, 8, 13, 14, 16, 19, 22, 31, 34], video anomaly detection, which aims to identify the activities that do not conform to regular patterns in a video sequence, is still a challenging task.",
                "proposed CT-D2GAN framework achieves the best performance on UCSD Ped2 and SH-Tech, and close to the best performance in CUHK [22].",
                "Recent memory or clustering enhanced methods [3, 6, 22] show good performance and is orthogonal to our proposed framework and can integrate with our proposed framework in future work to further improve performance.",
                "Thoroughly empirical studies on three public video anomaly detection datasets, i.e., UCSD Ped2, CUHK Avenue, and Shanghai Tech Campus, demonstrate the effectiveness of the proposed framework and techniques.",
                "Among those, MPPCA (mixture of probabilistic principal component analyzers) + SF (social force) [19], MDT (mixture of dynamic textures) [13, 19] are handcrafted feature based methods; Conv-AE [8], 3D Conv [40], Stacked RNN [18], and ConvLSTM-AE [17] are encoder-decoder based approaches; MemAE [6], MemNormality [22] and ClusterAE [3] are recent encoder-decoder based methods enhanced with memory module or clustering; AbnormalGAN [25], Frame prediction [14], and Pred+Recon [31] are methods based on adversarial training.",
                "We evaluate our framework on threewidely used public video anomaly detection datasets, i.e., UCSD Ped2 dataset [13] 1, CUHK Avenue dataset [16] 2, and ShanghaiTech Campus (SH-Tech) dataset [18] 3.",
                "Finally, our\nproposed CT-D2GAN framework achieves the best performance on UCSD Ped2 and SH-Tech, and close to the best performance in CUHK [22]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "014ad6b5c003ecf7566570266d43154ac8683758",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2107-13720",
                    "ArXiv": "2107.13720",
                    "DOI": "10.1145/3474085.3475693",
                    "CorpusId": 236493410
                },
                "corpusId": 236493410,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/014ad6b5c003ecf7566570266d43154ac8683758",
                "title": "Convolutional Transformer based Dual Discriminator Generative Adversarial Networks for Video Anomaly Detection",
                "abstract": "Detecting abnormal activities in real-world surveillance videos is an important yet challenging task as the prior knowledge about video anomalies is usually limited or unavailable. Despite that many approaches have been developed to resolve this problem, few of them can capture the normal spatio-temporal patterns effectively and efficiently. Moreover, existing works seldom explicitly consider the local consistency at frame level and global coherence of temporal dynamics in video sequences. To this end, we propose Convolutional Transformer based Dual Discriminator Generative Adversarial Networks (CT-D2GAN) to perform unsupervised video anomaly detection. Specifically, we first present a convolutional transformer to perform future frame prediction. It contains three key components, i.e., a convolutional encoder to capture the spatial information of the input video clips, a temporal self-attention module to encode the temporal dynamics, and a convolutional decoder to integrate spatio-temporal features and predict the future frame. Next, a dual discriminator based adversarial training procedure, which jointly considers an image discriminator that can maintain the local consistency at frame-level and a video discriminator that can enforce the global coherence of temporal dynamics, is employed to enhance the future frame prediction. Finally, the prediction error is used to identify abnormal video frames. Thoroughly empirical studies on three public video anomaly detection datasets, i.e., UCSD Ped2, CUHK Avenue, and Shanghai Tech Campus, demonstrate the effectiveness of the proposed adversarial spatio-temporal modeling framework.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "4738891",
                        "name": "Xinyang Feng"
                    },
                    {
                        "authorId": "2451800",
                        "name": "Dongjin Song"
                    },
                    {
                        "authorId": "2786131",
                        "name": "Yuncong Chen"
                    },
                    {
                        "authorId": "1766853",
                        "name": "Zhengzhang Chen"
                    },
                    {
                        "authorId": "2090567",
                        "name": "Jingchao Ni"
                    },
                    {
                        "authorId": "2145225543",
                        "name": "Haifeng Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "93040f8a5d10e8fde279e18d353aa3dca2873900",
                "externalIds": {
                    "ArXiv": "2107.13118",
                    "DBLP": "journals/corr/abs-2107-13118",
                    "DOI": "10.1109/ICCV48922.2021.00867",
                    "CorpusId": 236469071
                },
                "corpusId": 236469071,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/93040f8a5d10e8fde279e18d353aa3dca2873900",
                "title": "Divide-and-Assemble: Learning Block-wise Memory for Unsupervised Anomaly Detection",
                "abstract": "Reconstruction-based methods play an important role in unsupervised anomaly detection in images. Ideally, we expect a perfect reconstruction for normal samples and poor reconstruction for abnormal samples. Since the generalizability of deep neural networks is difficult to control, existing models such as autoencoder do not work well. In this work, we interpret the reconstruction of an image as a divide-and-assemble procedure. Surprisingly, by varying the granularity of division on feature maps, we are able to modulate the reconstruction capability of the model for both normal and abnormal samples. That is, finer granularity leads to better reconstruction, while coarser granularity leads to poorer reconstruction. With proper granularity, the gap between the reconstruction error of normal and abnormal samples can be maximized. The divide-and-assemble framework is implemented by embedding a novel multi-scale block-wise memory module into an autoencoder network. Besides, we introduce adversarial learning and explore the semantic latent representation of the discriminator, which improves the detection of subtle anomaly. We achieve state-of-the-art performance on the challenging MVTec AD dataset. Remarkably, we improve the vanilla autoencoder model by 10.1% in terms of the AUROC score.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1992870390",
                        "name": "Jinlei Hou"
                    },
                    {
                        "authorId": null,
                        "name": "Yingying Zhang"
                    },
                    {
                        "authorId": "1842317",
                        "name": "Qiaoyong Zhong"
                    },
                    {
                        "authorId": "50322310",
                        "name": "Di Xie"
                    },
                    {
                        "authorId": "3290437",
                        "name": "Shiliang Pu"
                    },
                    {
                        "authorId": "2157473721",
                        "name": "Hong Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "It has also been applied for anomaly detection problems [18], [19].",
                "To test the effectiveness of our proposed cluster-based memory module, Table III lists the results of MemAE and AE+memory.",
                "It should be noted that AE+Memory still achieves better results than MemAE on CIFAR10 when the training dataset is mixed with 10% outliers.",
                "One can observe that when the training dataset only has inliers, AE+Memory has comparable performance compared with MemAE on MNIST and significantly outperforms MemAE on CIFAR10.",
                "Besides, we compare our methods with another memory augmented AE MemAE [19]."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3bb8a74d9dda7ffdff72ed41191a9f6b5b1d1d39",
                "externalIds": {
                    "DBLP": "journals/tip/HuyanQZLCJ22",
                    "ArXiv": "2107.12642",
                    "DOI": "10.1109/TIP.2022.3211476",
                    "CorpusId": 236447683,
                    "PubMed": "36215361"
                },
                "corpusId": 236447683,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3bb8a74d9dda7ffdff72ed41191a9f6b5b1d1d39",
                "title": "Unsupervised Outlier Detection Using Memory and Contrastive Learning",
                "abstract": "Outlier detection is to separate anomalous data from inliers in the dataset. Recently, the most deep learning methods of outlier detection leverage an auxiliary reconstruction task by assuming that outliers are more difficult to recover than normal samples (inliers). However, it is not always true in deep auto-encoder (AE) based models. The auto-encoder based detectors may recover certain outliers even if outliers are not in the training data, because they do not constrain the feature learning. Instead, we think outlier detection can be done in the feature space by measuring the distance between outliers\u2019 features and the consistency feature of inliers. To achieve this, we propose an unsupervised outlier detection method using a memory module and a contrastive learning module (MCOD). The memory module constrains the consistency of features, which merely represent the normal data. The contrastive learning module learns more discriminative features, which boosts the distinction between outliers and inliers. Extensive experiments on four benchmark datasets show that our proposed MCOD performs well and outperforms eleven state-of-the-art methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "31067096",
                        "name": "Ning Huyan"
                    },
                    {
                        "authorId": "38965976",
                        "name": "Dou Quan"
                    },
                    {
                        "authorId": "26887655",
                        "name": "Xiangrong Zhang"
                    },
                    {
                        "authorId": "2735528",
                        "name": "Xuefeng Liang"
                    },
                    {
                        "authorId": "1744943",
                        "name": "J. Chanussot"
                    },
                    {
                        "authorId": "144125122",
                        "name": "L. Jiao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Some of techniques of contrast learning are just beginning to be used in anomaly detection [38, 14, 31]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "da8932d53a73b8a2b6c2b39d70c789cda4acee0b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2107-12753",
                    "ArXiv": "2107.12753",
                    "CorpusId": 236447378
                },
                "corpusId": 236447378,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/da8932d53a73b8a2b6c2b39d70c789cda4acee0b",
                "title": "Discriminative-Generative Representation Learning for One-Class Anomaly Detection",
                "abstract": "As a kind of generative self-supervised learning methods, generative adversarial nets have been widely studied in the field of anomaly detection. However, the representation learning ability of the generator is limited since it pays too much attention to pixel-level details, and generator is difficult to learn abstract semantic representations from label prediction pretext tasks as effective as discriminator. In order to improve the representation learning ability of generator, we propose a self-supervised learning framework combining generative methods and discriminative methods. The generator no longer learns representation by reconstruction error, but the guidance of discriminator, and could benefit from pretext tasks designed for discriminative methods. Our discriminative-generative representation learning method has performance close to discriminative methods and has a great advantage in speed. Our method used in one-class anomaly detection task significantly outperforms several state-of-the-arts on multiple benchmark data sets, increases the performance of the top-performing GAN-based baseline by 6% on CIFAR-10 and 2% on MVTAD.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1557264594",
                        "name": "X. Xia"
                    },
                    {
                        "authorId": "41052354",
                        "name": "Xizhou Pan"
                    },
                    {
                        "authorId": "2154166161",
                        "name": "Xing He"
                    },
                    {
                        "authorId": "2145379955",
                        "name": "Jingfei Zhang"
                    },
                    {
                        "authorId": "2066768061",
                        "name": "N. Ding"
                    },
                    {
                        "authorId": "2152343688",
                        "name": "Lin Ma"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[12] used a memory module to record a prototypical pattern of normal data, while lessening the representation capacity of CNNs."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3e82d64cf64f1678e597ec43aea2ff8a0e87dd83",
                "externalIds": {
                    "MAG": "3184731081",
                    "DBLP": "journals/access/YangLW21",
                    "DOI": "10.1109/ACCESS.2021.3100678",
                    "CorpusId": 236940010
                },
                "corpusId": 236940010,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3e82d64cf64f1678e597ec43aea2ff8a0e87dd83",
                "title": "Bidirectional Retrospective Generation Adversarial Network for Anomaly Detection in Videos",
                "abstract": "Anomaly detection in videos is the task of identifying frames from a video sequence that depict events that do not conform to expected behavior, which is an extremely challenging task due to the ambiguous and unbounded properties of anomalies. With the development of deep learning, video anomaly detection methods based on deep neural networks have made great progress. The existing methods mainly follow two routes, namely, frame reconstruction and frame prediction. Due to the powerful generalization ability of neural networks, the application of reconstruction-based methods is limited. Recently, anomaly detection methods based on prediction have achieved advanced performance. However, their performance suffers when they cannot guarantee lower prediction errors for normal events. In this paper, we propose a novel future frame prediction model based on a bidirectional retrospective generation adversarial network (BR-GAN) for anomaly detection. To predict a future frame with higher quality for normal events, first, we propose a bidirectional prediction combined with a retrospective prediction method to fully mine the bidirectional temporal information between the predicted frame and the input frame sequence. Then, the intensity and gradient loss between the predicted frame and the actual frame together with an adversarial loss are used for appearance (spatial) constraints. In addition, we propose a sequence discriminator composed of a 3-dimensional (3D) convolutional neural network to capture the long-term temporal relationships between frame sequences composed of predicted frames and input frames; this network plays a crucial role in maintaining the motion (temporal) consistency of the predicted frames for normal events. Such appearance and motion constraints further facilitate future frame prediction for normal events, and thus, the prediction network can be highly capable of distinguishing normal and abnormal patterns. Extensive experiments on benchmark datasets demonstrate that our method outperforms most existing state-of-the-art methods, validating the effectiveness of our method for anomaly detection.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "40615725",
                        "name": "Zhiwei Yang"
                    },
                    {
                        "authorId": "2163063860",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "2678268",
                        "name": "Peng Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "introduced loss functions that, unlike memoryguided AE, guarantee intra-class compactness and inter-class separateness of \u201cnormal\u201d instance patterns based on a 2D convolutional AE to increase the efficiency of the memory module [17]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "7b7087b7452adc2fe8a874678049f591c1342c0f",
                "externalIds": {
                    "MAG": "3183348949",
                    "DOI": "10.3390/APP11146545",
                    "CorpusId": 237680466
                },
                "corpusId": 237680466,
                "publicationVenue": {
                    "id": "136edf8d-0f88-4c2c-830f-461c6a9b842e",
                    "name": "Applied Sciences",
                    "type": "journal",
                    "alternate_names": [
                        "Appl Sci"
                    ],
                    "issn": "2076-3417",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-217814",
                    "alternate_urls": [
                        "http://www.mathem.pub.ro/apps/",
                        "https://www.mdpi.com/journal/applsci",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-217814"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7b7087b7452adc2fe8a874678049f591c1342c0f",
                "title": "Deep Morphological Anomaly Detection Based on Angular Margin Loss",
                "abstract": "Deep anomaly detection aims to identify \u201cabnormal\u201d data by utilizing a deep neural network trained on a normal training dataset. In general, industrial visual anomaly detection systems distinguish between normal and \u201cabnormal\u201d data through small morphological differences such as cracks and stains. Nevertheless, most existing algorithms emphasize capturing the semantic features of normal data rather than the morphological features. Therefore, they yield poor performance on real-world visual inspection, although they show their superiority in simulations with representative image classification datasets. To address this limitation, we propose a novel deep anomaly detection algorithm based on the salient morphological features of normal data. The main idea behind the proposed algorithm is to train a multiclass model to classify hundreds of morphological transformation cases applied to all the given data. To this end, the proposed algorithm utilizes a self-supervised learning strategy, making unsupervised learning straightforward. Additionally, to enhance the performance of the proposed algorithm, we replaced the cross-entropy-based loss function with the angular margin loss function. It is experimentally demonstrated that the proposed algorithm outperforms several recent anomaly detection methodologies in various datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152984395",
                        "name": "Taehyeon Kim"
                    },
                    {
                        "authorId": "66295992",
                        "name": "E. Hong"
                    },
                    {
                        "authorId": "1809767",
                        "name": "Yoonsik Choe"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "427694c173453e816d5d37545bec79b2589e9d1e",
                "externalIds": {
                    "DBLP": "journals/ieeejas/WangXSY21",
                    "DOI": "10.1109/JAS.2021.1004045",
                    "CorpusId": 235307728
                },
                "corpusId": 235307728,
                "publicationVenue": {
                    "id": "ef1356d5-69c7-484e-a110-3efae1e93ecc",
                    "name": "IEEE/CAA Journal of Automatica Sinica",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE/CAA J Autom Sin"
                    ],
                    "issn": "2329-9266",
                    "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=6570654",
                    "alternate_urls": [
                        "http://www.ieee-jas.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/427694c173453e816d5d37545bec79b2589e9d1e",
                "title": "A Cognitive Memory-Augmented Network for Visual Anomaly Detection",
                "abstract": "With the rapid development of automated visual analysis, visual analysis systems have become a popular research topic in the field of computer vision and automated analysis. Visual analysis systems can assist humans to detect anomalous events (e.g., fighting, walking alone on the grass, etc). In general, the existing methods for visual anomaly detection are usually based on an autoencoder architecture, i.e., reconstructing the current frame or predicting the future frame. Then, the reconstruction error is adopted as the evaluation metric to identify whether an input is abnormal or not. The flaws of the existing methods are that abnormal samples can also be reconstructed well. In this paper, inspired by the human memory ability, we propose a novel deep neural network (DNN) based model termed cognitive memory-augmented network (CMAN) for the visual anomaly detection problem. The proposed CMAN model assumes that the visual analysis system imitates humans to remember normal samples and then distinguishes abnormal events from the collected videos. Specifically, in the proposed CMAN model, we introduce a memory module that is able to simulate the memory capacity of humans and a density estimation network that can learn the data distribution. The reconstruction errors and the novelty scores are used to distinguish abnormal events from videos. In addition, we develop a two-step scheme to train the proposed model so that the proposed memory module and the density estimation network can cooperate to improve performance. Comprehensive experiments evaluated on various popular benchmarks show the superiority and effectiveness of the proposed CMAN model for visual anomaly detection comparing with the state-of-the-arts methods. The implementation code of our CMAN method can be accessed at https://github.com/CMAN-code/CMAN_pytorch.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118915615",
                        "name": "Tian Wang"
                    },
                    {
                        "authorId": "47158869",
                        "name": "Xing Xu"
                    },
                    {
                        "authorId": "144618699",
                        "name": "Fumin Shen"
                    },
                    {
                        "authorId": "2152283122",
                        "name": "Yang Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The autoencoders have many variations, such as residual learning model [19], self-attention model [20] and feature memory model [21], super-resolution model [22], temporally coherent sparse coding RNN [23], stacked RNN auto-encoder [24].",
                "The above methods learn normal feature pattern [23, 24], normal frame prediction [21, 26], and normal skeleton pattern [13, 14]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "241f77911f359c190e5ab2ef4811a9bd1f171218",
                "externalIds": {
                    "DBLP": "journals/iet-ipr/YangWWXH21",
                    "MAG": "3173811016",
                    "DOI": "10.1049/ipr2.12299",
                    "CorpusId": 237931054
                },
                "corpusId": 237931054,
                "publicationVenue": {
                    "id": "409a4f56-7785-415a-8fa6-32fde080b401",
                    "name": "IET Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "Iet Image Processing",
                        "IET Image Process",
                        "Iet Image Process"
                    ],
                    "issn": "1751-9659",
                    "url": "http://www.iee.org/Publish/Journals/Profjourn/Proc/vis/",
                    "alternate_urls": [
                        "http://www.ietdl.org/IET-IPR"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/241f77911f359c190e5ab2ef4811a9bd1f171218",
                "title": "Deep social force network for anomaly event detection",
                "abstract": "Anomaly event detection is vital in surveillance video analysis. However, how to learn the discriminative motion in the crowd scene is still not tackled. Here, a deep social force network by exploiting both social force extracting and deep motion coding is proposed. Given a grid of particles with velocity provided by the optical \ufb02ow, the interaction force in the crowd scene is investigated and a social force module is embedded in a deep network. A deep motion convolution was further designed with a 3D (DMC-3D) module. The DMC-3D not only eliminates the noise motion in the crowd scene with a spatial encoder\u2013decoder but also learns the 3D feature with a spatio-temporal encoder. The deep social force coding is modelled with multiple features, in which each feature can describe speci\ufb01c anomaly motion. The experiments on UCF-Crime and ShanghaiTech datasets demonstrate that our method can predict the temporal localization of anomaly events and outperform the state-of-the-art methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2150439680",
                        "name": "Xingming Yang"
                    },
                    {
                        "authorId": "2108397571",
                        "name": "Zhiming Wang"
                    },
                    {
                        "authorId": "2054077",
                        "name": "Kewei Wu"
                    },
                    {
                        "authorId": "144918654",
                        "name": "Zhao Xie"
                    },
                    {
                        "authorId": "39969056",
                        "name": "Jinkui Hou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "recently, explicit characterization of the diversity of the normal data is explored in [73], self-supervised learning is proposed in [74], and normalizing flows for the task in [75]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "efecefb050d0c61561707414f288e93039024d43",
                "externalIds": {
                    "ArXiv": "2106.13272",
                    "DBLP": "journals/corr/abs-2106-13272",
                    "DOI": "10.1109/TPAMI.2021.3092999",
                    "CorpusId": 235652398,
                    "PubMed": "34181535"
                },
                "corpusId": 235652398,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/efecefb050d0c61561707414f288e93039024d43",
                "title": "Generalized One-Class Learning Using Pairs of Complementary Classifiers",
                "abstract": "One-class learning is the classic problem of fitting a model to the data for which annotations are available only for a single class. In this paper, we explore novel objectives for one-class learning, which we collectively refer to as Generalized One-class Discriminative Subspaces (GODS). Our key idea is to learn a pair of complementary classifiers to flexibly bound the one-class data distribution, where the data belongs to the positive half-space of one of the classifiers in the complementary pair and to the negative half-space of the other. To avoid redundancy while allowing non-linearity in the classifier decision surfaces, we propose to design each classifier as an orthonormal frame and seek to learn these frames via jointly optimizing for two conflicting objectives, namely: i) to minimize the distance between the two frames, and ii) to maximize the margin between the frames and the data. The learned orthonormal frames will thus characterize a piecewise linear decision surface that allows for efficient inference, while our objectives seek to bound the data within a minimal volume that maximizes the decision margin, thereby robustly capturing the data distribution. We explore several variants of our formulation under different constraints on the constituent classifiers, including kernelized feature maps. We demonstrate the empirical benefits of our approach via experiments on data from several applications in computer vision, such as anomaly detection in video sequences, human poses, and human activities. We also explore the generality and effectiveness of GODS for non-vision tasks via experiments on several UCI datasets, demonstrating state-of-the-art results.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2691929",
                        "name": "A. Cherian"
                    },
                    {
                        "authorId": "2144536737",
                        "name": "Jue Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "12f9e3261cbf353c56077883f6345e656b6df21b",
                "externalIds": {
                    "DBLP": "conf/iccv/WangZQSZGS21",
                    "ArXiv": "2106.11149",
                    "DOI": "10.1109/ICCV48922.2021.00747",
                    "CorpusId": 235490392
                },
                "corpusId": 235490392,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/12f9e3261cbf353c56077883f6345e656b6df21b",
                "title": "OadTR: Online Action Detection with Transformers",
                "abstract": "Most recent approaches for online action detection tend to apply Recurrent Neural Network (RNN) to capture long-range temporal structure. However, RNN suffers from non-parallelism and gradient vanishing, hence it is hard to be optimized. In this paper, we propose a new encoder-decoder framework based on Transformers, named OadTR, to tackle these problems. The encoder attached with a task token aims to capture the relationships and global inter-actions between historical observations. The decoder extracts auxiliary information by aggregating anticipated future clip representations. Therefore, OadTR can recognize current actions by encoding historical information and predicting future context simultaneously. We extensively evaluate the proposed OadTR on three challenging datasets: HDD, TVSeries, and THUMOS14. The experimental results show that OadTR achieves higher training and inference speeds than current RNN based approaches, and significantly outperforms the state-of-the-art methods in terms of both mAP and mcAP. Code is available at https://github.com/wangxiang1230/OadTR.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2144796430",
                        "name": "Xiang Wang"
                    },
                    {
                        "authorId": "50202110",
                        "name": "Shiwei Zhang"
                    },
                    {
                        "authorId": "1750375688",
                        "name": "Zhiwu Qing"
                    },
                    {
                        "authorId": "2195861",
                        "name": "Yuanjie Shao"
                    },
                    {
                        "authorId": "2452739",
                        "name": "Zhe Zuo"
                    },
                    {
                        "authorId": "40115662",
                        "name": "Changxin Gao"
                    },
                    {
                        "authorId": "1707161",
                        "name": "N. Sang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Since the first five frames of each clip cannot be predicted, they are ignored in the evaluation, following [22, 34, 43].",
                "Frame predicting AEs [22, 43] and frame reconstructing AEs [33, 13] have been proposed assuming that anomalies that are unseen in the training phase cannot be predicted or reconstructed when the model is trained only on normal frames.",
                "Additionally, many effective reconstructing AEs [33, 51, 34, 5] have been proposed.",
                "Our patch anomaly generation phase is computationally cheaper than the other methods that embed spatio-temporal feature extraction in networks, such as storing and updating memory items [12, 34], and estimating optical flow with pre-trained networks [22, 39, 49, 2].",
                "To the best of our knowledge, unlike [22, 12, 34, 39, 15, 38], our framework performs the fastest because there are no additional modules or pre-trained networks.",
                "[34] suggested networks that employ memory modules to read and update memory items.",
                "We compare the frame-level AUC of our model with those of nonprediction-based methods [13, 28, 39, 42, 40, 33, 12, 15, 34, 49, 51, 10, 11] and prediction-based methods [22, 43, 32, 34].",
                "Focusing on the fact that abnormal events occur in small regions, patch-based AEs [51, 47, 33, 8], have been proposed.",
                "However, it has been observed that AEs tend to generalize well to generate abnormal events strongly, mainly due to the capacity of CNNs, which leads to missing out on anomalies during detection.",
                "Frame predicting and reconstructing AEs have been proposed under the assumption that models trained only on normal data are not capable of predicting or reconstructing abnormal frames, because these are unseen during training.",
                "Some studies [22, 43, 34, 26] trained AEs that predict a single future frame from several successive input frames.",
                "[34] proposed memory-based methods to use only the most essential features of normal frames for the generation.",
                "This metric is used in most studies [4, 10, 11, 27, 28, 33, 34, 49, 51] on video anomaly detection.",
                "Following the method of many related studies [6, 12, 13, 21, 22, 28, 34, 40], we define the final normality score St by normalizing PSNR(Pt,Pt) of each video clip to the range [0, 1]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0de3d8697dd2ff82e78e49fab86ac03b912c0e66",
                "externalIds": {
                    "ArXiv": "2106.08613",
                    "DBLP": "conf/wacv/ParkCLL22",
                    "DOI": "10.1109/WACV51458.2022.00197",
                    "CorpusId": 235446435
                },
                "corpusId": 235446435,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/0de3d8697dd2ff82e78e49fab86ac03b912c0e66",
                "title": "FastAno: Fast Anomaly Detection via Spatio-temporal Patch Transformation",
                "abstract": "Video anomaly detection has gained significant attention due to the increasing requirements of automatic monitoring for surveillance videos. Especially, the prediction based approach is one of the most studied methods to detect anomalies by predicting frames that include abnormal events in the test set after learning with the normal frames of the training set. However, a lot of prediction networks are computationally expensive owing to the use of pre-trained optical flow networks, or fail to detect abnormal situations because of their strong generative ability to predict even the anomalies. To address these shortcomings, we propose spatial rotation transformation (SRT) and temporal mixing transformation (TMT) to generate irregular patch cuboids within normal frame cuboids in order to enhance the learning of normal features. Additionally, the proposed patch transformation is used only during the training phase, allowing our model to detect abnormal frames at fast speed during inference. Our model is evaluated on three anomaly detection benchmarks, achieving competitive accuracy and surpassing all the previous works in terms of speed.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109124052",
                        "name": "Chaewon Park"
                    },
                    {
                        "authorId": "1387831061",
                        "name": "Myeongah Cho"
                    },
                    {
                        "authorId": "2109503396",
                        "name": "Minhyeok Lee"
                    },
                    {
                        "authorId": "39847092",
                        "name": "Sangyoun Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "A common approach to anomaly detection with deep learning is to predict future \u2018normal\u2019 video frames from sparse feature representations [3, 15, 26], sometimes augmented with memory modules [19], and/or optical-flow images [13, 20, 21]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "296a22664daf1a4a39a22697a6e379720646c283",
                "externalIds": {
                    "DBLP": "conf/cvpr/SzymanowiczCC21",
                    "ArXiv": "2106.08856",
                    "DOI": "10.1109/CVPRW53098.2021.00360",
                    "CorpusId": 235446522
                },
                "corpusId": 235446522,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/296a22664daf1a4a39a22697a6e379720646c283",
                "title": "X-MAN: Explaining multiple sources of anomalies in video",
                "abstract": "Our objective is to detect anomalies in video while also automatically explaining the reason behind the detector\u2019s response. In a practical sense, explainability is crucial for this task as the required response to an anomaly depends on its nature and severity. However, most leading methods (based on deep neural networks) are not interpretable and hide the decision making process in uninterpretable feature representations. In an effort to tackle this problem we make the following contributions: (1) we show how to build interpretable feature representations suitable for detecting anomalies with state of the art performance, (2) we propose an interpretable probabilistic anomaly detector which can describe the reason behind it\u2019s response using high level concepts, (3) we are the first to directly consider object interactions for anomaly detection and (4) we propose a new task of explaining anomalies and release a large dataset for evaluating methods on this task. Our method competes well with the state of the art on public datasets while also providing anomaly explanation based on objects and their interactions.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2112694047",
                        "name": "Stanislaw Szymanowicz"
                    },
                    {
                        "authorId": "2055745260",
                        "name": "James Charles"
                    },
                    {
                        "authorId": "1745672",
                        "name": "R. Cipolla"
                    }
                ]
            }
        },
        {
            "contexts": [
                "al [39] propose to further enhance the performance by adopting a memory module to record representative normal patterns."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "dbc023b52618972847e2dcbd641949daeaabfc9d",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiuCLK21",
                    "DOI": "10.1109/CVPR46437.2021.00076",
                    "CorpusId": 235702971
                },
                "corpusId": 235702971,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dbc023b52618972847e2dcbd641949daeaabfc9d",
                "title": "Deep Learning in Latent Space for Video Prediction and Compression",
                "abstract": "Learning-based video compression has achieved substantial progress during recent years. The most influential approaches adopt deep neural networks (DNNs) to remove spatial and temporal redundancies by finding the appropriate lower-dimensional representations of frames in the video. We propose a novel DNN based framework that predicts and compresses video sequences in the latent vector space. The proposed method first learns the efficient lower-dimensional latent space representation of each video frame and then performs inter-frame prediction in that latent domain. The proposed latent domain compression of individual frames is obtained by a deep autoencoder trained with a generative adversarial network (GAN). To exploit the temporal correlation within the video frame sequence, we employ a convolutional long short-term memory (ConvLSTM) network to predict the latent vector representation of the future frame. We demonstrate our method with two applications; video compression and abnormal event detection that share the identical latent frame prediction network. The proposed method exhibits superior or competitive performance compared to the state-of-the-art algorithms specifically designed for either video compression or anomaly detection.1",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1878722108",
                        "name": "Bowen Liu"
                    },
                    {
                        "authorId": "2144837651",
                        "name": "Yu Chen"
                    },
                    {
                        "authorId": "1879298369",
                        "name": "Shiyu Liu"
                    },
                    {
                        "authorId": "120799396",
                        "name": "Hun-Seok Kim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[36] believe that limiting the generalization ability is vital in finding novel images, and hence propose a memory-based autoencoder to reconstruct images from features.",
                "They commonly utilize AutoEncoders [40, 11, 20, 50, 17, 14, 36, 32] or GANs [49, 46, 37, 39, 5] to learn the distribution underlying normal data and then make the decision based on whether a test sample can be well recovered or not.",
                "Anomaly detection has received broad attention in recent years due to its wide applications in industrial inspection [6, 7, 48, 11, 10, 32], medical diagnosis [51, 5, 46, 42], and surveillance [27, 30, 36]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4758baad6b22c61682e7f7182bb93723046f36f5",
                "externalIds": {
                    "DBLP": "conf/cvpr/WangWCS21",
                    "DOI": "10.1109/CVPR46437.2021.00032",
                    "CorpusId": 235692290
                },
                "corpusId": 235692290,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4758baad6b22c61682e7f7182bb93723046f36f5",
                "title": "Glancing at the Patch: Anomaly Localization with Global and Local Feature Comparison",
                "abstract": "Anomaly localization, with the purpose to segment the anomalous regions within images, is challenging due to the large variety of anomaly types. Existing methods typically train deep models by treating the entire image as a whole yet put little effort into learning the local distribution, which is vital for this pixel-precise task. In this work, we propose an unsupervised patch-based approach that gives due consideration to both the global and local information. More concretely, we employ a Local-Net and Global-Net to extract features from any individual patch and its surrounding respectively. Global-Net is trained with the purpose to mimic the local feature such that we can easily detect an abnormal patch when its feature mismatches that from the context. We further introduce an Inconsistency Anomaly Detection (IAD) head and a Distortion Anomaly Detection (DAD) head to sufficiently spot the discrepancy between global and local features. A scoring function derived from the multi-head design facilitates high-precision anomaly localization. Extensive experiments on a couple of real-world datasets suggest that our approach outperforms state-of-the-art competitors by a sufficiently large margin.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2151226174",
                        "name": "S. Wang"
                    },
                    {
                        "authorId": "49279300",
                        "name": "Liwei Wu"
                    },
                    {
                        "authorId": "2106412819",
                        "name": "Lei Cui"
                    },
                    {
                        "authorId": "2117687899",
                        "name": "Yujun Shen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In the literature of anomaly detection [1\u201312], a common evaluation metric is frame-level AUC, which gradually uses the abnormal score as the threshold and does not rely on subjective thresholds.",
                "Based on autoencoders, the prior methods [10\u201312] detect abnormal events by reconstructing or predicting video frames.",
                "(15) D\u0302(Qt,Mp) = D(Qt,Mp)\u2212mint(D(Qt,Mp)) maxt(D(Qt,Mp))\u2212mint(D(Qt,Mp)) (16) In the RGB color space, according to [11, 12], we calculate the peak signal-to-noise ratio (PSNR) between the predicted frame \u00cet and its ground truth It, and normalize PSNR:",
                "To remedy these issues, some approaches [6, 8, 10\u201312] to anomaly detection are based",
                "Following [11, 12], we input a video clip with consecutive t \u2212 1 frames to the encoder, and the decoder can predict the t-th frame.",
                "This is a significant and practical field on many occasions, especially video surveillance [1\u201312].",
                "712 MNAD [11] 0.",
                "[11] claim to learn memory-guided normality for anomaly detection (MNAD), which can reconstruct and predict video frames.",
                "Similar to [11, 12], we use 2 norm to calculate the mean square error between the predicted frame \u00cet and its ground truth It."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "263de653929d8aaaf44917ee7db2fed188f978db",
                "externalIds": {
                    "MAG": "3184253077",
                    "DOI": "10.1109/YAC53711.2021.9486538",
                    "CorpusId": 236479356
                },
                "corpusId": 236479356,
                "publicationVenue": {
                    "id": "7e280d98-c90c-428c-baba-a46e4abde912",
                    "name": "Youth Academic Annual Conference of Chinese Association of Automation",
                    "type": "conference",
                    "alternate_names": [
                        "YAC",
                        "Youth Acad Annu Conf Chin Assoc Autom"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/263de653929d8aaaf44917ee7db2fed188f978db",
                "title": "An Autoencoder with a Memory Module for Video Anomaly Detection",
                "abstract": "With the rise of deep convolutional neural networks (CNNs), considerable attention has been paid to video anomaly detection (VAD). Autoencoders are a popular type of framework for VAD, and many existing VAD methods are based on it. However, these methods take an assumption of closed-world VAD, i.e., do not comprehensively consider the diversity of normal patterns. Besides, a competent CNN allows the autoencoder to reconstruct or predict abnormal video frames proficiently, resulting in missing anomalies. To mitigate these drawbacks, we propose an Autoencoder with a Memory Module (AMM) to realize video anomaly detection by predicting video frames. AMM consists of three modules: an encoder, a decoder, and a memory module. First, the consecutive frames are fed into the encoder to yield latent spatial features. Then, the features are utilized to retrieve corresponding memory items in the memory module to generate memory mapping features. Finally, the memory mapping features are adopted in the decoder for predicting the next frame. To match the queries against memory items accurately, we propose a memory triplet loss, which takes into account both size and angle discrepancies between the queries and memory items. At the training stage, AMM utilizes the memory triplet loss, a prediction loss, and multi-scale structure similarity measure. Moreover, the modes of retrieving and updating memory items are ameliorated by a scaled dot product model, which can alleviate vanishing gradient problems to a certain extent. Extensive experiments are conducted on three benchmark public datasets, and the results demonstrate the superior performance of AMM.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2021307128",
                        "name": "Wei Tang"
                    },
                    {
                        "authorId": "1570777908",
                        "name": "Yunjian Feng"
                    },
                    {
                        "authorId": "2152748618",
                        "name": "Jun Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "MNAD and OGNet are latest unsupervised anomaly detection methods.",
                "The unsupervised anomaly detection methods contain GMM [12], Sparse [11], ConvAE [4], Stack RNN [13], U-Net [5], MNAD [7] and OGNet [8]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "d3d5836cfd6de0441f3b84cc8b5afc3407739c76",
                "externalIds": {
                    "ArXiv": "2106.08570",
                    "DBLP": "journals/corr/abs-2106-08570",
                    "MAG": "3164956984",
                    "DOI": "10.1049/IPR2.12258",
                    "CorpusId": 235446672
                },
                "corpusId": 235446672,
                "publicationVenue": {
                    "id": "409a4f56-7785-415a-8fa6-32fde080b401",
                    "name": "IET Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "Iet Image Processing",
                        "IET Image Process",
                        "Iet Image Process"
                    ],
                    "issn": "1751-9659",
                    "url": "http://www.iee.org/Publish/Journals/Profjourn/Proc/vis/",
                    "alternate_urls": [
                        "http://www.ietdl.org/IET-IPR"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d3d5836cfd6de0441f3b84cc8b5afc3407739c76",
                "title": "Anomaly Detection in Video Sequences: A Benchmark and Computational Model",
                "abstract": "Anomaly detection has attracted considerable search attention. However, existing anomaly detection databases encounter two major problems. Firstly, they are limited in scale. Secondly, training sets contain only video-level labels indicating the existence of an abnormal event during the full video while lacking annotations of precise time durations. To tackle these problems, we contribute a new Large-scale Anomaly Detection (LAD) database as the benchmark for anomaly detection in video sequences, which is featured in two aspects. 1) It contains 2000 video sequences including normal and abnormal video clips with 14 anomaly categories including crash, fire, violence, etc. with large scene varieties, making it the largest anomaly analysis database to date. 2) It provides the annotation data, including video-level labels (abnormal/normal video, anomaly type) and frame-level labels (abnormal/normal video frame) to facilitate anomaly detection. Leveraging the above benefits from the LAD database, we further formulate anomaly detection as a fully-supervised learning problem and propose a multi-task deep neural network to solve it. We first obtain the local spatiotemporal contextual feature by using an Inflated 3D convolutional (I3D) network. Then we construct a recurrent convolutional neural network fed the local spatiotemporal contextual feature to extract the spatiotemporal contextual feature. With the global spatiotemporal contextual feature, the anomaly type and score can be computed simultaneously by a multi-task neural network. Experimental results show that the proposed method outperforms the state-of-the-art anomaly detection methods on our database and other public databases of anomaly detection. Codes are available at https://github.com/wanboyang/anomaly_detection_LAD2000.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "152393567",
                        "name": "Boyang Wan"
                    },
                    {
                        "authorId": "2116486153",
                        "name": "Wenhui Jiang"
                    },
                    {
                        "authorId": "4639656",
                        "name": "Yuming Fang"
                    },
                    {
                        "authorId": "35585444",
                        "name": "Zhiyuan Luo"
                    },
                    {
                        "authorId": "50164924",
                        "name": "Guanqun Ding"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The DNNbased anomaly detection technology has been applied to many fields (Liu et al. 2013; Zhao et al. 2017; Abati et al. 2019; Markovitz et al. 2020; Pang et al. 2020; Park, Noh, and Ham 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "883c5791a627d5bf679da1b5f871ff0d51792c6d",
                "externalIds": {
                    "DBLP": "conf/aaai/JiangXLJL21",
                    "DOI": "10.1609/aaai.v35i5.16536",
                    "CorpusId": 235306515
                },
                "corpusId": 235306515,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/883c5791a627d5bf679da1b5f871ff0d51792c6d",
                "title": "LREN: Low-Rank Embedded Network for Sample-Free Hyperspectral Anomaly Detection",
                "abstract": "Hyperspectral anomaly detection (HAD) is a challenging task because it explores the intrinsic structure of complex high-dimensional signals without any samples at training time. Deep neural networks (DNNs) can dig out the underlying distribution of hyperspectral data but are limited by the labeling of large-scale hyperspectral datasets, especially the low spatial resolution of hyperspectral data, which makes labeling more difficult. To tackle this problem while ensuring the detection performance, we present an unsupervised low-rank embedded network (LREN) in this paper. LREN is a joint learning network in which the latent representation is specifically designed for HAD, rather than merely as a feature input for the detector. And it searches the lowest rank representation based on a representative and discriminative dictionary in the deep latent space to estimate the residual efficiently. Considering the physically mixing properties in hyperspectral imaging, we develop a trainable density estimation module based on Gaussian mixture model (GMM) in the deep latent space to construct a dictionary that can better characterize the complex hyperspectral images (HSIs). The closed-form solution of the proposed low-rank learner surpasses existing approaches on four real hyperspectral datasets with different anomalies. We argue that this unified framework paves a novel way to combine feature extraction and anomaly estimation-based methods for HAD, which intends to learn the underlying representation tailored for HAD without the prerequisite of manually labeled data. Code available at https://github.com/xdjiangkai/LREN.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "9215892",
                        "name": "K. Jiang"
                    },
                    {
                        "authorId": "2664460",
                        "name": "Weiying Xie"
                    },
                    {
                        "authorId": "2118171262",
                        "name": "Jie Lei"
                    },
                    {
                        "authorId": "143872550",
                        "name": "Tao Jiang"
                    },
                    {
                        "authorId": "2721212",
                        "name": "Yunsong Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To show the effectiveness of our AMMC-Net, we compare our method with different prediction-based method (Liu et al. 2018), memory-based method (Gong et al. 2019; Park, Noh, and Ham 2020) and two-stream-based method (Prawiro et al. 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "08c4fa2132dda85c5f02a88fddfb7f17973f3978",
                "externalIds": {
                    "DBLP": "conf/aaai/CaiZ0GH21",
                    "DOI": "10.1609/aaai.v35i2.16177",
                    "CorpusId": 235306583
                },
                "corpusId": 235306583,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/08c4fa2132dda85c5f02a88fddfb7f17973f3978",
                "title": "Appearance-Motion Memory Consistency Network for Video Anomaly Detection",
                "abstract": "Abnormal event detection in the surveillance video is an essential\nbut challenging task, and many methods have been\nproposed to deal with this problem. The previous methods\neither only consider the appearance information or directly\nintegrate the results of appearance and motion information\nwithout considering their endogenous consistency\nsemantics explicitly. Inspired by the rule humans identify\nthe abnormal frames from multi-modality signals, we propose\nan Appearance-Motion Memory Consistency Network\n(AMMC-Net). Our method first makes full use of the prior\nknowledge of appearance and motion signals to explicitly\ncapture the correspondence between them in the high-level\nfeature space. Then, it combines the multi-view features to\nobtain a more essential and robust feature representation of\nregular events, which can significantly increase the gap between\nan abnormal and a regular event. In the anomaly detection\nphase, we further introduce a commit error in the latent\nspace joint with the prediction error in pixel space to enhance\nthe detection accuracy. Solid experimental results on various\nstandard datasets validate the effectiveness of our approach.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "39913331",
                        "name": "Ruichu Cai"
                    },
                    {
                        "authorId": "2144613446",
                        "name": "Hao Zhang"
                    },
                    {
                        "authorId": "2117934369",
                        "name": "Wen Liu"
                    },
                    {
                        "authorId": "1702868",
                        "name": "Shenghua Gao"
                    },
                    {
                        "authorId": "145586380",
                        "name": "Z. Hao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Many approaches have been proposed such as AE based methods[1, 13, 38], OSVM based methods[6, 42], and density based methods[49, 52]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "bd64c3ed6e6dca90bdd628ef1d4d94a5279c5106",
                "externalIds": {
                    "ArXiv": "2105.06649",
                    "DBLP": "journals/corr/abs-2105-06649",
                    "CorpusId": 234681937
                },
                "corpusId": 234681937,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/bd64c3ed6e6dca90bdd628ef1d4d94a5279c5106",
                "title": "Importance Weighted Adversarial Discriminative Transfer for Anomaly Detection",
                "abstract": "Previous transfer methods for anomaly detection generally assume the availability of labeled data in source or target domains. However, such an assumption is not valid in most real applications where large-scale labeled data are too expensive. Therefore, this paper proposes an importance weighted adversarial autoencoder-based method to transfer anomaly detection knowledge in an unsupervised manner, particularly for a rarely studied scenario where a target domain has no labeled normal/abnormal data while only normal data from a related source domain exist. Specifically, the method learns to align the distributions of normal data in both source and target domains, but leave the distribution of abnormal data in the target domain unchanged. In this way, an obvious gap can be produced between the distributions of normal and abnormal data in the target domain, therefore enabling the anomaly detection in the domain. Extensive experiments on multiple synthetic datasets and the UCSD benchmark demonstrate the effectiveness of our approach.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1657460771",
                        "name": "Cangning Fan"
                    },
                    {
                        "authorId": "2153306163",
                        "name": "Fangyi Zhang"
                    },
                    {
                        "authorId": "145779142",
                        "name": "Peng Liu"
                    },
                    {
                        "authorId": "2109166067",
                        "name": "Xiuyu Sun"
                    },
                    {
                        "authorId": "1706574",
                        "name": "Hao Li"
                    },
                    {
                        "authorId": "2061135550",
                        "name": "Ting Xiao"
                    },
                    {
                        "authorId": "144122124",
                        "name": "Wei Zhao"
                    },
                    {
                        "authorId": "1767901",
                        "name": "Xianglong Tang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[34] proposed a model that can be applied for reconstruction or prediction.",
                "It is worth pointing out that training only on normal data is often claimed as unsupervision like [12, 13, 34] recently."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4e3aaa868a8dce4067c4053cfef960f3f6b5f9cd",
                "externalIds": {
                    "ArXiv": "2105.04302",
                    "DBLP": "journals/corr/abs-2105-04302",
                    "CorpusId": 234342006
                },
                "corpusId": 234342006,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4e3aaa868a8dce4067c4053cfef960f3f6b5f9cd",
                "title": "Video Anomaly Detection By The Duality Of Normality-Granted Optical Flow",
                "abstract": "Video anomaly detection is a challenging task because of diverse abnormal events. To this task, methods based on reconstruction and prediction are wildly used in recent works, which are built on the assumption that learning on normal data, anomalies cannot be reconstructed or predicated as good as normal patterns, namely the anomaly result with more errors. In this paper, we propose to discriminate anomalies from normal ones by the duality of normality-granted optical flow, which is conducive to predict normal frames but adverse to abnormal frames. The normality-granted optical flow is predicted from a single frame, to keep the motion knowledge focused on normal patterns. Meanwhile, We extend the appearance-motion correspondence scheme from frame reconstruction to prediction, which not only helps to learn the knowledge about object appearances and correlated motion, but also meets the fact that motion is the transformation between appearances. We also introduce a margin loss to enhance the learning of frame prediction. Experiments on standard benchmark datasets demonstrate the impressive performance of our approach.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109799958",
                        "name": "Hongyong Wang"
                    },
                    {
                        "authorId": "2107989630",
                        "name": "Xinjian Zhang"
                    },
                    {
                        "authorId": "145803491",
                        "name": "Su Yang"
                    },
                    {
                        "authorId": "2108238266",
                        "name": "Weishan Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "After that, we send the converted 2D feature map to the Memory [10] Module.",
                "Among them, Memory [10] is used to aggregate similar features, while separating different features, and all classes are weighted for feature integration.",
                "[10, 15] proposed to use 2D convolutions to construct an autoencoder, which performs well in small anomaly detection datasets while being faster.",
                "After completing the Memory [10] operation, we send the feature map to the 2D Decoder Module, The 2D decoder up-samples the obtained features, and combines the features directly output from the encoder through skip connections, and fmally generates the predicted value lt through three up\u00ad sampling.",
                "represents the weight, Lpre , Lcompact, Lseparate represents the prediction loss, feature compactness loss and feature separateness loss [10], It represents the ground truth value, lt represents the predicted value, and T represents the total length of a video sequence.",
                "On the other hand, inspired by [10], We build a 2D convolutional decoder to predict the image while achieving faster speed.",
                "At present, methods based on 2D convolutional autoencoders [10] have good real-time performance.",
                "This architecture takes continuous video frames as input, the left side is the 3D encoder structure, and the three modules in the middle are the Skip Connections Module, Dimensional Alignment Module, and the Memory [10] Module.",
                "The comprehensive loss includes the prediction loss (as shown in formula (4)), the feature compactness loss and feature separateness loss proposed in [10].",
                "For the Memory [10], our hyperparameters are consistent with the settings in [10]."
            ],
            "isInfluential": true,
            "intents": [
                "result",
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "da2ca8ed4289c7df0ee1871002bcfc33fe9dbd95",
                "externalIds": {
                    "DBLP": "conf/cscwd/LvYLHZZW21",
                    "DOI": "10.1109/CSCWD49262.2021.9437868",
                    "CorpusId": 235235378
                },
                "corpusId": 235235378,
                "publicationVenue": {
                    "id": "a966c5e8-76dc-45c0-942a-3c7e41ac9b1a",
                    "name": "International Conference on Computer Supported Cooperative Work in Design",
                    "type": "conference",
                    "alternate_names": [
                        "Computer Supported Cooperative Work in Design",
                        "Int Conf Comput Support Cooperative Work Des",
                        "CSCWD",
                        "Comput Support Cooperative Work Des"
                    ],
                    "url": "http://www.cscwd.org/"
                },
                "url": "https://www.semanticscholar.org/paper/da2ca8ed4289c7df0ee1871002bcfc33fe9dbd95",
                "title": "Asymmetric Anomaly Detection for Human-Robot Interaction",
                "abstract": "Security in human-robot interaction is the focus of research in this field. Rapid detection of abnormal events that may cause danger in the interaction process can effectively reduce the probability of occurrence of danger. In general anomaly detection methods, 2D or 3D convolutional autoencoders are widely used for anomaly detection. Among them, 2D convolutional autoencoders are with good real-time performance and lower detection accuracy, while 3D convolutional autoencoders are with higher detection accuracy and insufficient real-time performance. In order to ensure realtime performance and obtain higher accuracy, an end-to-end asymmetric convolutional autoencoder network (ACANet) using both 2D and 3D convolutions is designed. Specifically, 3D convolution is used to build the encoder to learn comprehensive information in continuous input frames, and 2D convolution is used to build the decoder to model the information fast, a dimensional alignment module is constructed to connect the encoder and the decoder while avoiding a large number of calculations in the latent space of the 3D features output by the encoder, and the skip connections module is used to obtain accurate predictions. Anomaly detection can then be completed by evaluating the differences between results predicted by the ACANet and real frames. The experimental results show that our method achieves competitive accuracy on mainstream datasets and at the same time obtains the fastest speed. Compared with mainstream methods, this method is more suitable for anomaly detection tasks in human-robot interaction.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2166164912",
                        "name": "Hao Lv"
                    },
                    {
                        "authorId": "144108977",
                        "name": "Pengfei Yi"
                    },
                    {
                        "authorId": "144207288",
                        "name": "R. Liu"
                    },
                    {
                        "authorId": "1828559",
                        "name": "Yingkun Hou"
                    },
                    {
                        "authorId": "144158951",
                        "name": "D. Zhou"
                    },
                    {
                        "authorId": "33822530",
                        "name": "Qiang Zhang"
                    },
                    {
                        "authorId": "1706625",
                        "name": "Xiaopeng Wei"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "0e168983a36d0c1246210ebca2d54ebd7190b4e6",
                "externalIds": {
                    "ArXiv": "2104.14945",
                    "DBLP": "conf/icdm/LaiHW21",
                    "DOI": "10.1109/ICDM51629.2021.00040",
                    "CorpusId": 233476674
                },
                "corpusId": 233476674,
                "publicationVenue": {
                    "id": "67d15a94-d523-4b5f-be58-03fe2ef9dcfb",
                    "name": "Industrial Conference on Data Mining",
                    "type": "conference",
                    "alternate_names": [
                        "Ind Conf Data Min",
                        "ICDM"
                    ],
                    "url": "http://www.data-mining-forum.de/"
                },
                "url": "https://www.semanticscholar.org/paper/0e168983a36d0c1246210ebca2d54ebd7190b4e6",
                "title": "Anomaly Detection with Prototype-Guided Discriminative Latent Embeddings",
                "abstract": "Recent efforts towards video anomaly detection (VAD) try to learn a deep autoencoder to describe normal event patterns with small reconstruction errors. The video inputs with large reconstruction errors are regarded as anomalies at the test time. However, these methods sometimes reconstruct abnormal inputs well because of the powerful generalization ability of deep autoencoder. To address this problem, we present a novel approach for anomaly detection, which utilizes discriminative prototypes of normal data to reconstruct video frames. In this way, the model will favor the reconstruction of normal events and distort the reconstruction of abnormal events. Specifically, we use a prototype-guided memory module to perform discriminative latent embedding. We introduce a new discriminative criterion for the memory module, as well as a loss function correspondingly, which can encourage memory items to record the representative embeddings of normal data, i.e. prototypes. Besides, we design a novel two-branch autoencoder, which is composed of a future frame prediction network and an RGB difference generation network that share the same encoder. The stacked RGB difference contains motion information just like optical flow, so our model can learn temporal regularity. We evaluate the effectiveness of our method on three benchmark datasets and experimental results demonstrate the proposed method outperforms the state-of-the-art.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1877227048",
                        "name": "Yuandu Lai"
                    },
                    {
                        "authorId": "144622313",
                        "name": "Yahong Han"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following the standard evaluation metric in the latest works [7], [6], [8], [9], we use the average frame-level area under curve (AUC) as the metric with varying threshold values for abnormality scores.",
                "Following [7], [6], [8], we use Peak Signal to Noise Ratio (PSNR) between the predicted frame and its ground truth to quantify the reconstruction.",
                "Prediction based anomaly detection [3], [7], [8], on the other hand, uses the consecutive t frames to predict the next frame and assumes anomaly will cause a large prediction error.",
                "Following the standard memory network [8], we use the compactness loss and separateness loss to conduct a sparse effect for both feature space as well.",
                "(denoted by *) of Frame-Pred [6] and Mem-Guided [8] on new testing set.",
                "For one image of size 256x256, ours achieves 52 fps, while Mem-Guided [8] is 56 fps, MLEP [9] is 65 fps, Frame-pred [6] is 24 fps.",
                "2 is a memory-based [6], [8] frame prediction network.",
                "The most related work to ours is Mem-Guided [8].",
                "A basic idea in memory-based network [6], [8] is to represent each kind of normal features using their nearest memory.",
                "Mem-Guided [8] benefits from a specially designed memory structure for only normal data."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "702bf4e263f35d3ca9e04d1d4fd6df8acef34b20",
                "externalIds": {
                    "ArXiv": "2104.14430",
                    "DBLP": "journals/corr/abs-2104-14430",
                    "CorpusId": 233444025
                },
                "corpusId": 233444025,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/702bf4e263f35d3ca9e04d1d4fd6df8acef34b20",
                "title": "Discriminative-Generative Dual Memory Video Anomaly Detection",
                "abstract": "Recently, people tried to use a few anomalies for video anomaly detection (VAD) instead of only normal data during the training process. A side effect of data imbalance occurs when a few abnormal data face a vast number of normal data. The latest VAD works use triplet loss or data re-sampling strategy to lessen this problem. However, there is still no elaborately designed structure for discriminative VAD with a few anomalies. In this paper, we propose a DiscRiminative-gEnerative duAl Memory (DREAM) anomaly detection model to take advantage of a few anomalies and solve data imbalance. We use two shallow discriminators to tighten the normal feature distribution boundary along with a generator for the next frame prediction. Further, we propose a dual memory module to obtain a sparse feature representation in both normality and abnormality space. As a result, DREAM not only solves the data imbalance problem but also learn a reasonable feature space. Further theoretical analysis shows that our DREAM also works for the unknown anomalies. Comparing with the previous methods on UCSD Ped1, UCSD Ped2, CUHK Avenue, and ShanghaiTech, our model outperforms all the baselines with no extra parameters. The ablation study demonstrates the effectiveness of our dual memory module and discriminative-generative network.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2116513722",
                        "name": "Xin Guo"
                    },
                    {
                        "authorId": "2427514",
                        "name": "Zhongming Jin"
                    },
                    {
                        "authorId": "2135176888",
                        "name": "Chong Chen"
                    },
                    {
                        "authorId": "2086828357",
                        "name": "Helei Nie"
                    },
                    {
                        "authorId": "50535545",
                        "name": "Jianqiang Huang"
                    },
                    {
                        "authorId": "2143899452",
                        "name": "Deng Cai"
                    },
                    {
                        "authorId": "3945955",
                        "name": "Xiaofei He"
                    },
                    {
                        "authorId": "2053903039",
                        "name": "Xiansheng Hua"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In [50], the authors propose a memory network to memorize normal patterns for detecting anomalies in an video.",
                "Moreover, the memory network is further applied in video analysis [49, 50, 51] and image captioning [52].",
                "Driven by this observation, we propose a novel network, termed as prototype-based memory network (PM-Net), which is inspired by recent successes of memory networks in natural language processing (NLP) tasks [47, 48] and video analysis [49, 50, 51]."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "a09497a49e10e24a67c69e4302bb8b1c61cfd9c7",
                "externalIds": {
                    "ArXiv": "2104.11200",
                    "DBLP": "journals/corr/abs-2104-11200",
                    "PubMedCentral": "8218792",
                    "DOI": "10.1016/j.isprsjprs.2021.04.006",
                    "CorpusId": 233347033,
                    "PubMed": "34219969"
                },
                "corpusId": 233347033,
                "publicationVenue": {
                    "id": "227fb221-5e57-477c-b756-e39dd8ffd538",
                    "name": "Isprs Journal of Photogrammetry and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Isprs J Photogramm Remote Sens"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a09497a49e10e24a67c69e4302bb8b1c61cfd9c7",
                "title": "Aerial scene understanding in the wild: Multi-scene recognition via prototype-based memory networks",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51151222",
                        "name": "Yuansheng Hua"
                    },
                    {
                        "authorId": "35041003",
                        "name": "Lichao Mou"
                    },
                    {
                        "authorId": "2671789",
                        "name": "Jianzhe Lin"
                    },
                    {
                        "authorId": "1411506064",
                        "name": "Konrad Heidler"
                    },
                    {
                        "authorId": "46875441",
                        "name": "Xiaoxiang Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "46ecff6db6e08b7e610e392d7a07a0582d69e5bf",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2104-09758",
                    "ArXiv": "2104.09758",
                    "DOI": "10.1109/CVPRW53098.2021.00479",
                    "CorpusId": 233307109
                },
                "corpusId": 233307109,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/46ecff6db6e08b7e610e392d7a07a0582d69e5bf",
                "title": "An Efficient Approach for Anomaly Detection in Traffic Videos",
                "abstract": "Due to its relevance in intelligent transportation systems, anomaly detection in traffic videos has recently received much interest. It remains a difficult problem due to a variety of factors influencing the video quality of a real-time traffic feed, such as temperature, perspective, lighting conditions, and so on. Even though state-of-the-art methods perform well on the available benchmark datasets, they need a large amount of external training data as well as substantial computational resources. In this paper, we propose an efficient approach for a video anomaly detection system which is capable of running at the edge devices, e.g., on a roadside camera. The proposed approach comprises a preprocessing module that detects changes in the scene and removes the corrupted frames, a two-stage background modelling module and a two-stage object detector. Finally, a backtracking anomaly detection algorithm computes a similarity statistic and decides on the onset time of the anomaly. We also propose a sequential change detection algorithm that can quickly adapt to a new scene and detect changes in the similarity statistic. Experimental results on the Track 4 test set of the 2021 AI City Challenge show the efficacy of the proposed framework as we achieve an F1-score of 0. 9157 along with 8.4027 root mean square error (RMSE) and are ranked fourth in the competition.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "115636521",
                        "name": "Keval Doshi"
                    },
                    {
                        "authorId": "79595155",
                        "name": "Yasin Y\u0131lmaz"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As in previous methods [22, 10, 37], frame prediction error is also leveraged as an anomaly descriptor: Sfra = Lfra(\u0177t, yt).",
                "The first one is widely adopted in existing literature [37, 10, 22, 19, 23, 27], where only normal videos are available during training.",
                "MemAE [10] and LMN [37] are most-related methods to our approach.",
                "Previous approaches [37, 10] proposed to explicitly model the shared normal patterns across normal training videos with a memory bank, for",
                "To this end, [37] defines a rule for updating items in the memory bank based on a threshold to record normal patterns and ignore abnormal ones.",
                "[37] further expand the update rules of the memory bank by using a threshold to distinguish abnormal frames and record normal patterns.",
                "We adopt the same network architecture in [22, 37] as the backbone of AE to facilitate a fair comparison.",
                "Gong et al. (MemAE) [10] and Park et al. (LMN) [37] introduce a memory bank into the AE for anomaly detection.",
                "The learning procedure is fully differentiable and the prototypes are dynamically learned with the benefits of adapting to the current scene spatially and temporally, compared with querying and updating the memory bank with pre-defined rules for recording rough patterns cross the training data in [10, 37].",
                "These models are prone to face the \u2018overgeneralizing\u2019 dilemma, where all video frames can be predicted well, no matter they are normal or abnormal, owing to the powerful representation capacity of convolutional neural networks (CNNs) [37, 10].",
                "(LMN) [37] introduce a memory bank into the AE for anomaly detection.",
                "Moreover, the prototypes are automatically derived based on the real-time video data during inference, without referencing to the memory items collected from the training phase [10, 37]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "65b166c644478c83c745ce8befc084411048d424",
                "externalIds": {
                    "DBLP": "conf/cvpr/LvCCXL021",
                    "MAG": "3176309086",
                    "ArXiv": "2104.06689",
                    "DOI": "10.1109/CVPR46437.2021.01517",
                    "CorpusId": 233231431
                },
                "corpusId": 233231431,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/65b166c644478c83c745ce8befc084411048d424",
                "title": "Learning Normal Dynamics in Videos with Meta Prototype Network",
                "abstract": "Frame reconstruction (current or future frame) based on Auto-Encoder (AE) is a popular method for video anomaly detection. With models trained on the normal data, the reconstruction errors of anomalous scenes are usually much larger than those of normal ones. Previous methods introduced the memory bank into AE, for encoding diverse normal patterns across the training videos. However, they are memory-consuming and cannot cope with unseen new scenarios in the testing data. In this work, we propose a dynamic prototype unit (DPU) to encode the normal dynamics as prototypes in real time, free from extra memory cost. In addition, we introduce meta-learning to our DPU to form a novel few-shot normalcy learner, namely Meta-Prototype Unit (MPU). It enables the fast adaption capability on new scenes by only consuming a few iterations of update. Extensive experiments are conducted on various benchmarks. The superior performance over the state-of-the-art demonstrates the effectiveness of our method. Our code is available at https://github.com/ktr-hubrt/MPN/.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2064712029",
                        "name": "Hui Lv"
                    },
                    {
                        "authorId": "2127379958",
                        "name": "Chen Chen"
                    },
                    {
                        "authorId": "144801562",
                        "name": "Zhen Cui"
                    },
                    {
                        "authorId": "48258938",
                        "name": "Chunyan Xu"
                    },
                    {
                        "authorId": "2154404294",
                        "name": "Yong Li"
                    },
                    {
                        "authorId": "51460259",
                        "name": "Jian Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This is conceptually similar to feature separateness loss in [33], which encourages the queries to be close to the nearest item and separates individual items in the memory."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "84149211ed84edb70170845494230c5e97b60c60",
                "externalIds": {
                    "ArXiv": "2104.05170",
                    "DBLP": "journals/corr/abs-2104-05170",
                    "DOI": "10.1109/CVPR46437.2021.00649",
                    "CorpusId": 233210032
                },
                "corpusId": 233210032,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/84149211ed84edb70170845494230c5e97b60c60",
                "title": "Memory-guided Unsupervised Image-to-image Translation",
                "abstract": "We present a novel unsupervised framework for instance-level image-to-image translation. Although recent advances have been made by incorporating additional object annotations, existing methods often fail to handle images with multiple disparate objects. The main cause is that, during inference, they apply a global style to the whole image and do not consider the large style discrepancy between instance and background, or within instances. To address this problem, we propose a class-aware memory network that explicitly reasons about local style variations. A key-values memory structure, with a set of read/update operations, is introduced to record class-wise style variations and access them without requiring an object detector at the test time. The key stores a domain-agnostic content representation for allocating memory items, while the values encode domain-specific style representations. We also present a feature contrastive loss to boost the discriminative power of memory items. We show that by incorporating our memory, we can transfer class-aware and accurate style representations across domains. Experimental results demonstrate that our model outperforms recent instance-level methods and achieves state-of-the-art performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "35609663",
                        "name": "Somi Jeong"
                    },
                    {
                        "authorId": "2639155",
                        "name": "Youngjung Kim"
                    },
                    {
                        "authorId": "2115591671",
                        "name": "Eungbean Lee"
                    },
                    {
                        "authorId": "144442279",
                        "name": "K. Sohn"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Such computer vision tasks include anomaly detection [9, 23], few-shot learning [3, 14, 46], image generation [47], and video summarization [20]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "df37e254a5e2d966680d9c4ef70b44d43a073eb9",
                "externalIds": {
                    "DBLP": "conf/cvpr/LeeKCKR21",
                    "ArXiv": "2104.00924",
                    "DOI": "10.1109/CVPR46437.2021.00307",
                    "CorpusId": 233004334
                },
                "corpusId": 233004334,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/df37e254a5e2d966680d9c4ef70b44d43a073eb9",
                "title": "Video Prediction Recalling Long-term Motion Context via Memory Alignment Learning",
                "abstract": "Our work addresses long-term motion context issues for predicting future frames. To predict the future precisely, it is required to capture which long-term motion context (e.g., walking or running) the input motion (e.g., leg movement) belongs to. The bottlenecks arising when dealing with the long-term motion context are: (i) how to predict the long-term motion context naturally matching input sequences with limited dynamics, (ii) how to predict the long-term motion context with high-dimensionality (e.g., complex motion). To address the issues, we propose novel motion context-aware video prediction. To solve the bottle-neck (i), we introduce a long-term motion context memory (LMC-Memory) with memory alignment learning. The pro-posed memory alignment learning enables to store long-term motion contexts into the memory and to match them with sequences including limited dynamics. As a result, the long-term context can be recalled from the limited in-put sequence. In addition, to resolve the bottleneck (ii), we propose memory query decomposition to store local motion context (i.e., low-dimensional dynamics) and recall the suitable local context for each local part of the input individually. It enables to boost the alignment effects of the memory. Experimental results show that the proposed method outperforms other sophisticated RNN-based methods, especially in long-term condition. Further, we validate the effectiveness of the proposed network designs by conducting ablation studies and memory feature analysis. The source code of this work is available\u2020.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2909533",
                        "name": "Sangmin Lee"
                    },
                    {
                        "authorId": "3009805",
                        "name": "Hak Gu Kim"
                    },
                    {
                        "authorId": "2000522574",
                        "name": "Dae Hwi Choi"
                    },
                    {
                        "authorId": "2109581766",
                        "name": "Hyungil Kim"
                    },
                    {
                        "authorId": "7251290",
                        "name": "Yong Man Ro"
                    }
                ]
            }
        },
        {
            "contexts": [
                "A number of approaches have adopted the memory-augmented networks to solve various computer vision tasks including visual question answering [9, 17, 25], one-shot learning [2, 14, 32], anomaly detection [11, 27], and person recognition [41, 48]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "61502aa4665add575eced99ccd159758ad5a8c4b",
                "externalIds": {
                    "DBLP": "conf/cvpr/NohLH21",
                    "ArXiv": "2104.00902",
                    "DOI": "10.1109/CVPR46437.2021.01437",
                    "CorpusId": 233004521
                },
                "corpusId": 233004521,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/61502aa4665add575eced99ccd159758ad5a8c4b",
                "title": "HVPR: Hybrid Voxel-Point Representation for Single-stage 3D Object Detection",
                "abstract": "We address the problem of 3D object detection, that is, estimating 3D object bounding boxes from point clouds. 3D object detection methods exploit either voxel-based or point-based features to represent 3D objects in a scene. Voxel-based features are efficient to extract, while they fail to preserve fine-grained 3D structures of objects. Point-based features, on the other hand, represent the 3D structures more accurately, but extracting these features is computationally expensive. We introduce in this paper a novel single-stage 3D detection method having the merit of both voxel-based and point-based features. To this end, we propose a new convolutional neural network (CNN) architecture, dubbed HVPR, that integrates both features into a single 3D representation effectively and efficiently. Specifically, we augment the point-based features with a memory module to reduce the computational cost. We then aggregate the features in the memory, semantically similar to each voxel-based one, to obtain a hybrid 3D representation in a form of a pseudo image, allowing to localize 3D objects in a single stage efficiently. We also propose an Attentive Multi-scale Feature Module (AMFM) that extracts scale-aware features considering the sparse and irregular patterns of point clouds. Experimental results on the KITTI dataset demonstrate the effectiveness and efficiency of our approach, achieving a better compromise in terms of speed and accuracy.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1598361735",
                        "name": "Jongyoun Noh"
                    },
                    {
                        "authorId": "2144572533",
                        "name": "Sanghoon Lee"
                    },
                    {
                        "authorId": "38723538",
                        "name": "Bumsub Ham"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "91336c65cddd8546745f67a1b860c2595904ac15",
                "externalIds": {
                    "DBLP": "journals/pr/ChenYCXJ21",
                    "MAG": "3145726664",
                    "DOI": "10.1016/J.PATCOG.2021.107969",
                    "CorpusId": 233533911
                },
                "corpusId": 233533911,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/91336c65cddd8546745f67a1b860c2595904ac15",
                "title": "NM-GAN: Noise-modulated generative adversarial network for video anomaly detection",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3228938",
                        "name": "Dongyue Chen"
                    },
                    {
                        "authorId": "2087488270",
                        "name": "Lingyi Yue"
                    },
                    {
                        "authorId": "1642134508",
                        "name": "Xingya Chang"
                    },
                    {
                        "authorId": "2153557751",
                        "name": "Ming Xu"
                    },
                    {
                        "authorId": "36098263",
                        "name": "Tong Jia"
                    }
                ]
            }
        },
        {
            "contexts": [
                "A common technique used by several recent works [22, 14, 31, 33] is to normalize the computed statistic for each test video independently, including the ShanghaiTech dataset.",
                "For example, even recent algorithms such as [48, 22, 33] cannot detect (or be modified to detect) anomalies pertaining to changes in human poses."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "d47ac61d72a8287b3d28441c4329c81e9ef5ccdd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-11299",
                    "ArXiv": "2103.11299",
                    "DOI": "10.1109/WACV51458.2022.00306",
                    "CorpusId": 232307021
                },
                "corpusId": 232307021,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/d47ac61d72a8287b3d28441c4329c81e9ef5ccdd",
                "title": "A Modular and Unified Framework for Detecting and Localizing Video Anomalies",
                "abstract": "Anomaly detection in videos has been attracting an increasing amount of attention. Despite the competitive performance of recent methods on benchmark datasets, they typically lack desirable features such as modularity, cross-domain adaptivity, interpretability, and real-time anomalous event detection. Furthermore, current state-of-the-art approaches are evaluated using the standard instance-based detection metric by considering video frames as independent instances, which is not ideal for video anomaly detection. Motivated by these research gaps, we propose a modular and unified approach to the online video anomaly detection and localization problem, called MOVAD, which consists of a novel transfer learning based plug-and-play architecture, a sequential anomaly detector, a mathematical framework for selecting the detection threshold, and a suitable performance metric for real-time anomalous event detection in videos. Extensive performance evaluations on benchmark datasets show that the proposed framework significantly outperforms the current state-of-the-art approaches.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "115636521",
                        "name": "Keval Doshi"
                    },
                    {
                        "authorId": "79595155",
                        "name": "Yasin Y\u0131lmaz"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Owing to the mentioned challenges and growing related critical applications such as detecting criminal events [70], road-traffic accidents [36] and, vehicle collisions for selfdriving cars [84], VAD has recently gained significant attention [13, 14, 15, 19, 25, 26, 34, 42, 48, 50, 51, 88, 80, 17].",
                "Therefore, recently, AE-based approaches [1, 64, 9, 51, 19, 61, 21, 91] have been used dominantly aiming to encode and decode every consecutive fixed T frames of normal training samples, supposedly failing to reconstruct anomalous ones.",
                "[19, 51] try to use memory-based AEs to learn different normal patterns for the normal representation space.",
                "Similar to previous methods [39, 64, 26, 25, 51, 19, 1] the frame-level area under the curve (AUC) is exploited for evaluation the performance of our method on Avenue, ShanghaiTech, UCSD-Ped2, ADOC, and Street Scene datasets."
            ],
            "isInfluential": true,
            "intents": [],
            "citingPaper": {
                "paperId": "12ebe64bf81b85b2331875895bd3a2b5978dabd8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-10502",
                    "MAG": "3139105571",
                    "ArXiv": "2103.10502",
                    "CorpusId": 232290776
                },
                "corpusId": 232290776,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/12ebe64bf81b85b2331875895bd3a2b5978dabd8",
                "title": "Ano-Graph: Learning Normal Scene Contextual Graphs to Detect Video Anomalies",
                "abstract": "Video anomaly detection has proved to be a challenging task owing to its unsupervised training procedure and high spatio-temporal complexity existing in real-world scenarios. In the absence of anomalous training samples, state-of-the-art methods try to extract features that fully grasp normal behaviors in both space and time domains using different approaches such as autoencoders, or generative adversarial networks. However, these approaches completely ignore or, by using the ability of deep networks in the hierarchical modeling, poorly model the spatio-temporal interactions that exist between objects. To address this issue, we propose a novel yet efficient method named Ano-Graph for learning and modeling the interaction of normal objects. Towards this end, a Spatio-Temporal Graph (STG) is made by considering each node as an object's feature extracted from a real-time off-the-shelf object detector, and edges are made based on their interactions. After that, a self-supervised learning method is employed on the STG in such a way that encapsulates interactions in a semantic space. Our method is data-efficient, significantly more robust against common real-world variations such as illumination, and passes SOTA by a large margin on the challenging datasets ADOC and Street Scene while stays competitive on Avenue, ShanghaiTech, and UCSD.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2599182",
                        "name": "M. PourReza"
                    },
                    {
                        "authorId": "13082059",
                        "name": "Mohammadreza Salehi"
                    },
                    {
                        "authorId": "2884918",
                        "name": "M. Sabokrou"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "5937d7c2c10da2418f7979cd55ad12fa1b93a58e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-04224",
                    "ArXiv": "2103.04224",
                    "DOI": "10.1109/CVPR46437.2021.00449",
                    "CorpusId": 232147762
                },
                "corpusId": 232147762,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5937d7c2c10da2418f7979cd55ad12fa1b93a58e",
                "title": "MeGA-CDA: Memory Guided Attention for Category-Aware Unsupervised Domain Adaptive Object Detection",
                "abstract": "Existing approaches for unsupervised domain adaptive object detection perform feature alignment via adversarial training. While these methods achieve reasonable improvements in performance, they typically perform category-agnostic domain alignment, thereby resulting in negative transfer of features. To overcome this issue, in this work, we attempt to incorporate category information into the domain adaptation process by proposing Memory Guided Attention for Category-Aware Domain Adaptation (MeGA-CDA). The proposed method consists of employing category-wise discriminators to ensure category-aware feature alignment for learning domain-invariant discriminative features. However, since the category information is not available for the target samples, we propose to generate memory-guided category-specific attention maps which are then used to route the features appropriately to the corresponding category discriminator. The proposed method is evaluated on several benchmark datasets and is shown to outperform existing approaches.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51005492",
                        "name": "VS Vibashan"
                    },
                    {
                        "authorId": "1838218557",
                        "name": "Vikram Gupta"
                    },
                    {
                        "authorId": "144477698",
                        "name": "Poojan Oza"
                    },
                    {
                        "authorId": "2577847",
                        "name": "Vishwanath A. Sindagi"
                    },
                    {
                        "authorId": "1741177",
                        "name": "Vishal M. Patel"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "15042bc65fce78075f58c8a7a40f05034deed0b2",
                "externalIds": {
                    "DBLP": "conf/mmasia/TangZY0Y20",
                    "DOI": "10.1145/3444685.3446316",
                    "CorpusId": 233486417
                },
                "corpusId": 233486417,
                "publicationVenue": {
                    "id": "94b02de5-862a-4b6b-b584-500c2d265667",
                    "name": "ACM Multimedia Asia",
                    "type": "conference",
                    "alternate_names": [
                        "MMAsia",
                        "ACM Multimedia Asia"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/15042bc65fce78075f58c8a7a40f05034deed0b2",
                "title": "Graph-based motion prediction for abnormal action detection",
                "abstract": "Abnormal action detection is the most noteworthy part of anomaly detection, which tries to identify unusual human behaviors in videos. Previous methods typically utilize future frame prediction to detect frames deviating from the normal scenario. While this strategy enjoys success in the accuracy of anomaly detection, critical information such as the cause and location of the abnormality is unable to be acquired. This paper proposes human motion prediction for abnormal action detection. We employ sequence of human poses to represent human motion, and detect irregular behavior by comparing the predicted pose with the actual pose detected in the frame. Hence the proposed method is able to explain why the action is regarded as irregularity and locate where the anomaly happens. Moreover, pose sequence is robust to noise, complex background and small targets in videos. Since posture information is non-Euclidean data, graph convolutional network is adopted for future pose prediction, which not only leads to greater expressive power but also stronger generalization capability. Experiments are conducted both on the widely used anomaly detection dataset ShanghaiTech and our newly proposed dataset NJUST-Anomaly, which mainly contains irregular behaviors happened in the campus. Our dataset expands the existing datasets by giving more abnormal actions attracting public attention in social security, which happen in more complex scenes and dynamic backgrounds. Experimental results on both datasets demonstrate the superiority of our method over the-state-of-the-art methods. The source code and NJUST-Anomaly dataset will be made public at https://github.com/datangzhengqing/MP-GCN.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2111285884",
                        "name": "Yao Tang"
                    },
                    {
                        "authorId": "2111641357",
                        "name": "Lin Zhao"
                    },
                    {
                        "authorId": "1815314450",
                        "name": "Zhaoliang Yao"
                    },
                    {
                        "authorId": "1443742776",
                        "name": "Chen Gong"
                    },
                    {
                        "authorId": "51460259",
                        "name": "Jian Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These methods [1]\u2013[3], [5], [48]\u2013[52], [63], [64] generally construct a normal pattern to encode normal samples."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "36db3efac28debf164ed83363a9b7a5ecc9fd17b",
                "externalIds": {
                    "DBLP": "journals/tip/WuL21",
                    "DOI": "10.1109/TIP.2021.3062192",
                    "CorpusId": 232114573,
                    "PubMed": "33656993"
                },
                "corpusId": 232114573,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/36db3efac28debf164ed83363a9b7a5ecc9fd17b",
                "title": "Learning Causal Temporal Relation and Feature Discrimination for Anomaly Detection",
                "abstract": "Weakly supervised anomaly detection is a challenging task since frame-level labels are not given in the training phase. Previous studies generally employ neural networks to learn features and produce frame-level predictions and then use multiple instance learning (MIL)-based classification loss to ensure the interclass separability of the learned features; all operations simply take into account the current time information as input and ignore the historical observations. According to investigations, these solutions are universal but ignore two essential factors, i.e., the temporal cue and feature discrimination. The former introduces temporal context to enhance the current time feature, and the latter enforces the samples of different categories to be more separable in the feature space. In this article, we propose a method that consists of four modules to leverage the effect of these two ignored factors. The causal temporal relation (CTR) module captures local-range temporal dependencies among features to enhance features. The classifier (CL) projects enhanced features to the category space using the causal convolution and further expands the temporal modeling range. Two additional modules, namely, compactness (CP) and dispersion (DP) modules, are designed to learn the discriminative power of features, where the compactness module ensures the intraclass compactness of normal features, and the dispersion module enhances the interclass dispersion. Extensive experiments on three public benchmarks demonstrate the significance of causal temporal relations and feature discrimination for anomaly detection and the superiority of our proposed method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2678268",
                        "name": "Peng Wu"
                    },
                    {
                        "authorId": "2163063860",
                        "name": "Jing Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[Park et al., 2020; Gong et al., 2019] had a tendency to store several prototypes for normal samples by considering a memory module where individual items in it correspond to prototypical features of normal patterns."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "49ae00b9a8539ba1a2a7d77408daad850fd33095",
                "externalIds": {
                    "ArXiv": "2103.01739",
                    "DBLP": "journals/corr/abs-2103-01739",
                    "CorpusId": 232092251
                },
                "corpusId": 232092251,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/49ae00b9a8539ba1a2a7d77408daad850fd33095",
                "title": "Image/Video Deep Anomaly Detection: A Survey",
                "abstract": "The considerable significance of Anomaly Detection (AD) problem has recently drawn the attention of many researchers. Consequently, the number of proposed methods in this research field has been increased steadily. AD strongly correlates with the important computer vision and image processing tasks such as image/video anomaly, irregularity and sudden event detection. More recently, Deep Neural Networks (DNNs) offer a high performance set of solutions, but at the expense of a heavy computational cost. However, there is a noticeable gap between the previously proposed methods and an applicable real-word approach. Regarding the raised concerns about AD as an ongoing challenging problem, notably in images and videos, the time has come to argue over the pitfalls and prospects of methods have attempted to deal with visual AD tasks. Hereupon, in this survey we intend to conduct an in-depth investigation into the images/videos deep learning based AD methods. We also discuss current challenges and future research directions thoroughly.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "81976406",
                        "name": "Bahram Mohammadi"
                    },
                    {
                        "authorId": "144664641",
                        "name": "M. Fathy"
                    },
                    {
                        "authorId": "2884918",
                        "name": "M. Sabokrou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Anomaly detection has been performed pixel-wise in video [29]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "0e9268131f720bb5d64521e8e29839f3185ed178",
                "externalIds": {
                    "DBLP": "conf/icra/WilliamsGMN21",
                    "ArXiv": "2103.00869",
                    "DOI": "10.1109/ICRA48506.2021.9561165",
                    "CorpusId": 232076482
                },
                "corpusId": 232076482,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0e9268131f720bb5d64521e8e29839f3185ed178",
                "title": "Fool Me Once: Robust Selective Segmentation via Out-of-Distribution Detection with Contrastive Learning",
                "abstract": "In this work, a neural network is trained to simultaneously perform segmentation and pixel-wise Out-of-Distribution (OoD) detection, such that the segmentation of unknown regions of scenes can be rejected. This is made possible by leveraging an OoD dataset with a novel contrastive objective and data augmentation scheme. By including unknown classes in the training data, a more robust feature representation is learned with known classes represented distinctly from those unknown. In comparison, when presented with unknown classes or conditions, many current approaches for segmentation frequently exhibit high confidence in their inaccurate segmentations and cannot be trusted in many operational environments. We validate our system on a real-world dataset of unusual driving scenes, and show that by selectively segmenting scenes based on what is predicted as OoD, we can increase the segmentation accuracy by an IoU of 0.2 with respect to alternative techniques.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152728183",
                        "name": "David Williams"
                    },
                    {
                        "authorId": "2346231",
                        "name": "Matthew Gadd"
                    },
                    {
                        "authorId": "7764753",
                        "name": "D. Martini"
                    },
                    {
                        "authorId": "144214578",
                        "name": "P. Newman"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "77ec17343a691e629baf41ad1e30364ef1ba8b53",
                "externalIds": {
                    "ArXiv": "2101.12382",
                    "MAG": "3153418084",
                    "DBLP": "journals/corr/abs-2101-12382",
                    "CorpusId": 231728408
                },
                "corpusId": 231728408,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/77ec17343a691e629baf41ad1e30364ef1ba8b53",
                "title": "Re Learning Memory Guided Normality for Anomaly Detection",
                "abstract": "The authors have introduced a novel method for unsupervised anomaly detection that utilises a newly introduced Memory Module in their paper. We validate the authors claim that this helps improve performance by helping the network learn prototypical patterns, and uses the learnt memory to reduce the representation capacity of Convolutional Neural Networks. Further, we validate the efficacy of two losses introduced by the authors, Separateness Loss and Compactness Loss presented to increase the discriminative power of the memory items and the deeply learned features. We test the efficacy with the help of t-SNE plots of the memory items.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2069206629",
                        "name": "Kevin Stephen"
                    },
                    {
                        "authorId": "2142511521",
                        "name": "Varun G. Menon"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Our method RTFM achieves superior performance when compared with previous SOTA unsupervised learning methods [15, 27, 30, 41, 70] and weaklysupervised approaches [62, 74, 78]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6ec00ff233c19b47ef44dd57cdb22a7385586c0c",
                "externalIds": {
                    "DBLP": "conf/iccv/TianPCSVC21",
                    "ArXiv": "2101.10030",
                    "DOI": "10.1109/ICCV48922.2021.00493",
                    "CorpusId": 236950792
                },
                "corpusId": 236950792,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/6ec00ff233c19b47ef44dd57cdb22a7385586c0c",
                "title": "Weakly-supervised Video Anomaly Detection with Robust Temporal Feature Magnitude Learning",
                "abstract": "Anomaly detection with weakly supervised video-level labels is typically formulated as a multiple instance learning (MIL) problem, in which we aim to identify snippets containing abnormal events, with each video represented as a bag of video snippets. Although current methods show effective detection performance, their recognition of the positive instances, i.e., rare abnormal snippets in the abnormal videos, is largely biased by the dominant negative instances, especially when the abnormal events are subtle anomalies that exhibit only small differences compared with normal events. This issue is exacerbated in many methods that ignore important video temporal dependencies. To address this issue, we introduce a novel and theoretically sound method, named Robust Temporal Feature Magnitude learning (RTFM), which trains a feature magnitude learning function to effectively recognise the positive instances, substantially improving the robustness of the MIL approach to the negative instances from abnormal videos. RTFM also adapts dilated convolutions and self-attention mechanisms to capture long- and short-range temporal dependencies to learn the feature magnitude more faithfully. Extensive experiments show that the RTFM-enabled MIL model (i) outperforms several state-of-the-art methods by a large margin on four benchmark data sets (ShanghaiTech, UCF-Crime, XD-Violence and UCSD-Peds) and (ii) achieves significantly improved subtle anomaly discriminability and sample efficiency.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152947915",
                        "name": "Yu Tian"
                    },
                    {
                        "authorId": "3224619",
                        "name": "Guansong Pang"
                    },
                    {
                        "authorId": "2144036204",
                        "name": "Yuanhong Chen"
                    },
                    {
                        "authorId": "2115743780",
                        "name": "Rajvinder Singh"
                    },
                    {
                        "authorId": "3582291",
                        "name": "J. Verjans"
                    },
                    {
                        "authorId": "145575177",
                        "name": "G. Carneiro"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Therefore, we don\u2019t compare our method with other anomaly detection algorithms which are based on original data of Shanghai Tech [30], such as [20], [21], [30], [31]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "ceffcaa632aa0ef753e72fbface8b812a3ac49ea",
                "externalIds": {
                    "DBLP": "conf/icpr/Lin020",
                    "DOI": "10.1109/ICPR48806.2021.9412673",
                    "CorpusId": 233876912
                },
                "corpusId": 233876912,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ceffcaa632aa0ef753e72fbface8b812a3ac49ea",
                "title": "Dual-Mode iterative denoiser: Tackling the weak label for anomaly detection",
                "abstract": "Crowd anomaly detection suffers from limited training data under weak supervision. In this paper, we propose a dual-mode iterative denoiser to tackle the weak label challenge for anomaly detection. First, we use a convolution autoencoder (CAE) in image space to act as a cluster for grouping similar video clips, where the spatial-temporal similarity helps the cluster metric to represent the reconstruction error. Then we use the graph convolution neural network (GCN) to explore the temporal correlation and the feature similarity between video clips within different rough labels, where the classifier can be constantly updated in the label denoising process. Without specific image-level labels, our model can predict the clip-level anomaly probabilities for videos. Extensive experiment results on two public datasets show that our approach performs favorably against the state-of-the-art methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1430765963",
                        "name": "Shuheng Lin"
                    },
                    {
                        "authorId": "46402216",
                        "name": "Huan Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "It has attracted increasing interest for solving problems like question-answering systems [14, 15], summarization [16],image generation[17], and anomaly detection[18]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "4c4a6a0e8c57e282dc96a100d1db8d9410c3bd67",
                "externalIds": {
                    "ArXiv": "2012.11113",
                    "DBLP": "journals/corr/abs-2012-11113",
                    "CorpusId": 229340070
                },
                "corpusId": 229340070,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4c4a6a0e8c57e282dc96a100d1db8d9410c3bd67",
                "title": "Improving unsupervised anomaly localization by applying multi-scale memories to autoencoders",
                "abstract": "Autoencoder and its variants have been widely applicated in anomaly detection.The previous work memory-augmented deep autoencoder proposed memorizing normality to detect anomaly, however it neglects the feature discrepancy between different resolution scales, therefore we introduce multi-scale memories to record scale-specific features and multi-scale attention fuser between the encoding and decoding module of the autoencoder for anomaly detection, namely MMAE.MMAE updates slots at corresponding resolution scale as prototype features during unsupervised learning. For anomaly detection, we accomplish anomaly removal by replacing the original encoded image features at each scale with most relevant prototype features,and fuse these features before feeding to the decoding module to reconstruct image. Experimental results on various datasets testify that our MMAE successfully removes anomalies at different scales and performs favorably on several datasets compared to similar reconstruction-based methods.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Yifei Yang"
                    },
                    {
                        "authorId": "2056271669",
                        "name": "Shibing Xiang"
                    },
                    {
                        "authorId": "1410336598",
                        "name": "Ruixiang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "he image- and video-based AUC AE-Conv2D [6]y 0.609 TSC [64]y 0.679 Stack RNN [64]y 0.680 AE-Conv3D [65]y 0.697 MemAE [20]y 0.712 LSA [39] 0.725 ITAE [41] 0.725 FFP+MC [66] 0.728 Mem-Guided (w/o Mem.) [67] 0.668 Mem-Guided (w/ Mem.) [67] 0.705 MemAE-nonSpar [20] 0.688 MemAE [20] 0.712 Clustering-Driven [68] 0.733 MOCCA (s) 0.730 MOCCA (h) 0.725 yValues reported in [41] TABLE VI AUC VALUES FOR THE SHANG"
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "ab96c776f96e10f10d88ac5abbe9335afe935c81",
                "externalIds": {
                    "MAG": "3117272077",
                    "ArXiv": "2012.12111",
                    "DBLP": "journals/tnn/MassoliFKAEA22",
                    "DOI": "10.1109/TNNLS.2021.3130074",
                    "CorpusId": 229349123,
                    "PubMed": "34874873"
                },
                "corpusId": 229349123,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ab96c776f96e10f10d88ac5abbe9335afe935c81",
                "title": "MOCCA: Multilayer One-Class Classification for Anomaly Detection",
                "abstract": "Anomalies are ubiquitous in all scientific fields and can express an unexpected event due to incomplete knowledge about the data distribution or an unknown process that suddenly comes into play and distorts the observations. Usually, due to such events\u2019 rarity, to train deep learning (DL) models on the anomaly detection (AD) task, scientists only rely on \u201cnormal\u201d data, i.e., nonanomalous samples. Thus, letting the neural network infer the distribution beneath the input data. In such a context, we propose a novel framework, named multilayer one-class classification (MOCCA), to train and test DL models on the AD task. Specifically, we applied our approach to autoencoders. A key novelty in our work stems from the explicit optimization of the intermediate representations for the task at hand. Indeed, differently from commonly used approaches that consider a neural network as a single computational block, i.e., using the output of the last layer only, MOCCA explicitly leverages the multilayer structure of deep architectures. Each layer\u2019s feature space is optimized for AD during training, while in the test phase, the deep representations extracted from the trained layers are combined to detect anomalies. With MOCCA, we split the training process into two steps. First, the autoencoder is trained on the reconstruction task only. Then, we only retain the encoder tasked with minimizing the $L_{2}$ distance between the output representation and a reference point, the anomaly-free training data centroid, at each considered layer. Subsequently, we combine the deep features extracted at the various trained layers of the encoder model to detect anomalies at inference time. To assess the performance of the models trained with MOCCA, we conduct extensive experiments on publicly available datasets, namely CIFAR10, MVTec AD, and ShanghaiTech. We show that our proposed method reaches comparable or superior performance to state-of-the-art approaches available in the literature. Finally, we provide a model analysis to give insights regarding the benefits of our training procedure.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "5744388",
                        "name": "F. V. Massoli"
                    },
                    {
                        "authorId": "1846129",
                        "name": "F. Falchi"
                    },
                    {
                        "authorId": "1410151432",
                        "name": "Alperen Kantarci"
                    },
                    {
                        "authorId": "2040278882",
                        "name": "cSeymanur Akti"
                    },
                    {
                        "authorId": "3025777",
                        "name": "H. K. Ekenel"
                    },
                    {
                        "authorId": "144514869",
                        "name": "G. Amato"
                    }
                ]
            }
        },
        {
            "contexts": [
                "4 MemAE2020 [30] 97."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "beed3d46938a4cf406dfaf2d08124ee618822b80",
                "externalIds": {
                    "MAG": "3109883993",
                    "DBLP": "conf/icpr/OuyangS20",
                    "ArXiv": "2012.01468",
                    "DOI": "10.1109/ICPR48806.2021.9412694",
                    "CorpusId": 227254334
                },
                "corpusId": 227254334,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/beed3d46938a4cf406dfaf2d08124ee618822b80",
                "title": "Video Anomaly Detection by Estimating Likelihood of Representations",
                "abstract": "Video anomaly detection is a challenging task not only because it involves solving many sub-tasks such as motion representation, object localization and action recognition, but also because it is commonly considered as an unsupervised learning problem that involves detecting outliers. Traditionally, solutions to this task have focused on the mapping between video frames and their low-dimensional features, while ignoring the spatial connections of those features. Recent solutions focus on analyzing these spatial connections by using hard clustering techniques, such as K-Means, or applying neural networks to map latent features to a general understanding, such as action attributes. In order to solve video anomaly in the latent feature space, we propose a deep probabilistic model to transfer this task into a density estimation problem where latent manifolds are generated by a deep denoising autoencoder and clustered by expectation maximization. Evaluations on several benchmarks datasets show the strengths of our model, achieving outstanding performance on challenging datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2030975823",
                        "name": "Yuqi Ouyang"
                    },
                    {
                        "authorId": "153618912",
                        "name": "Victor Sanchez"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Frame-level AUC scores (in %) of the state-of-the-art methods [7, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 47, 48, 49, 51, 53, 55, 57, 59, 60, 61, 62, 64] versus our deep+wide architecture trained on four proxy tasks at the object level, at the frame level or based on late fusion.",
                "Our approach outperforms the state-of-the-art methods [7, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 47, 48, 49, 51, 53, 55, 57, 59, 60, 61, 62, 64] on all three data sets, achieving frame-level AUC scores of 92.",
                "In recent years, a growing interest has been dedicated to the task of detecting anomalous events in video [8, 9, 10, 13, 17, 19, 20, 24, 30, 34, 35, 36, 37, 38, 39, 49, 51, 55, 57, 61, 62, 63].",
                "Employing generative networks for video anomaly detection [8, 36, 41] is another significant line of research that relies on the same principle, that is, synthesizing future frames will prove to be significantly more challenging when an anomalous event occurs than in a normal situation.",
                "Aside from the direction relying on reconstruction errors [14, 27, 29, 31, 34, 36, 41, 51, 53], other recent works, such as [9, 38], tackle the problem from completely different angles.",
                "Without being able to employ standard supervision, researchers have proposed alternative approaches ranging from distance-based [17, 19, 37, 38, 40, 44, 45, 46, 47, 50, 52, 59] and reconstruction-based strategies [5, 13, 14, 27, 29, 31, 34, 36, 41, 51, 53] to probabilistic [1, 2, 4, 12, 16, 21, 32, 33, 58] and change detection methods [7, 18, 28, 35]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "57b2198f9a8df773425aa6cc88c9870cb07779e2",
                "externalIds": {
                    "MAG": "3104870221",
                    "DBLP": "conf/cvpr/GeorgescuBIKPS21",
                    "ArXiv": "2011.07491",
                    "DOI": "10.1109/CVPR46437.2021.01255",
                    "CorpusId": 226964553
                },
                "corpusId": 226964553,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/57b2198f9a8df773425aa6cc88c9870cb07779e2",
                "title": "Anomaly Detection in Video via Self-Supervised and Multi-Task Learning",
                "abstract": "Anomaly detection in video is a challenging computer vision problem. Due to the lack of anomalous events at training time, anomaly detection requires the design of learning methods without full supervision. In this paper, we approach anomalous event detection in video through self-supervised and multi-task learning at the object level. We first utilize a pre-trained detector to detect objects. Then, we train a 3D convolutional neural network to produce discriminative anomaly-specific information by jointly learning multiple proxy tasks: three self-supervised and one based on knowledge distillation. The self-supervised tasks are: (i) discrimination of forward/backward moving objects (arrow of time), (ii) discrimination of objects in consecutive/intermittent frames (motion irregularity) and (iii) reconstruction of object-specific appearance information. The knowledge distillation task takes into account both classification and detection information, generating large prediction discrepancies between teacher and student models when anomalies occur. To the best of our knowledge, we are the first to approach anomalous event detection in video as a multi-task learning problem, integrating multiple self-supervised and knowledge distillation proxy tasks in a single architecture. Our lightweight architecture outperforms the state-of-the-art methods on three benchmarks: Avenue, ShanghaiTech and UCSD Ped2. Additionally, we perform an ablation study demonstrating the importance of integrating self-supervised learning and normality-specific distillation in a multi-task learning setting.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "41021255",
                        "name": "Mariana-Iuliana Georgescu"
                    },
                    {
                        "authorId": "1739398670",
                        "name": "Antonio B\u0103rb\u0103l\u0103u"
                    },
                    {
                        "authorId": "1817759",
                        "name": "Radu Tudor Ionescu"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "49006356",
                        "name": "M. Popescu"
                    },
                    {
                        "authorId": "145103012",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "dae4243c7e45f0d73c56cb58898ece8c9693469b",
                "externalIds": {
                    "ArXiv": "2011.05054",
                    "MAG": "3099247170",
                    "DBLP": "journals/cviu/LiLS21",
                    "DOI": "10.1016/J.CVIU.2021.103249",
                    "CorpusId": 226290014
                },
                "corpusId": 226290014,
                "publicationVenue": {
                    "id": "5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                    "name": "Computer Vision and Image Understanding",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Vis Image Underst"
                    ],
                    "issn": "1077-3142",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/10773142",
                        "http://www.idealibrary.com/links/toc/cviu",
                        "https://www.journals.elsevier.com/computer-vision-and-image-understanding"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dae4243c7e45f0d73c56cb58898ece8c9693469b",
                "title": "Decoupled Appearance and Motion Learning for Efficient Anomaly Detection in Surveillance Video",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2155883623",
                        "name": "Bo Li"
                    },
                    {
                        "authorId": "3162144",
                        "name": "Sam Leroux"
                    },
                    {
                        "authorId": "34209448",
                        "name": "P. Simoens"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Without an external model, the memory-based approach [15, 42] that stores and updates normal query feaStatic Histogram Dynamic Histogram",
                "13 where norm(\u00b7) denotes normalization within a video clip as in some previous studies [29, 1, 42].",
                "Other algorithms have been proposed by learning reconstruction with other objectives [39], usingmemory modules [15, 42], reconstructing optical flows from frames [48], or encoding normal patterns with sparse dictionary learning [57, 35].",
                "As in a previous study [42], the error maps are visualized by marking the pixel that is larger than the average error value within the frame."
            ],
            "isInfluential": true,
            "intents": [
                "result",
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "e4b4349d19124be609622b75585d158055c1a0b3",
                "externalIds": {
                    "DBLP": "journals/pr/ChoKKCL22",
                    "ArXiv": "2010.07524",
                    "DOI": "10.1016/j.patcog.2022.108703",
                    "CorpusId": 248117132
                },
                "corpusId": 248117132,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e4b4349d19124be609622b75585d158055c1a0b3",
                "title": "Unsupervised video anomaly detection via normalizing flows with implicit latent features",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1387831061",
                        "name": "Myeongah Cho"
                    },
                    {
                        "authorId": "48271129",
                        "name": "Taeoh Kim"
                    },
                    {
                        "authorId": "1491411369",
                        "name": "Woojin Kim"
                    },
                    {
                        "authorId": "9613506",
                        "name": "Suhwan Cho"
                    },
                    {
                        "authorId": "39847092",
                        "name": "Sangyoun Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following (Park, Noh, and Ham 2020), the error maps are visualized by marking the pixel that is larger than the average error value within the frame.",
                "Other algorithms have been proposed via learning reconstruction with other objectives (Nguyen and Meunier 2019b), memory modules (Gong et al. 2019; Park, Noh, and Ham 2020), or reconstructing optical flows from frames (Ra-\nvanbakhsh et al. 2017; Ganokratanaa, Aramvith, and Sebe 2020).",
                "In non-reconstruction method, good performance is achieved by the Mem-guided (Park, Noh, and Ham 2020), which is a prediction-based method that stores and updates normal query features by memory module."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "616e4fa9ac89ef99f073aabfcdb4cc05e4407520",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2010-07524",
                    "MAG": "3092921121",
                    "CorpusId": 222377887
                },
                "corpusId": 222377887,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/616e4fa9ac89ef99f073aabfcdb4cc05e4407520",
                "title": "Unsupervised Video Anomaly Detection via Flow-based Generative Modeling on Appearance and Motion Latent Features",
                "abstract": "Surveillance video anomaly detection searches for anomalous events such as crimes or accidents among normal scenes. Since anomalous events occur rarely, there is a class imbalance problem between normal and abnormal data and it is impossible to collect all potential anomalous events, which makes the task challenging. Therefore, performing anomaly detection requires learning the patterns of normal scenes to detect unseen and undefined anomalies. Since abnormal scenes are distinguished from normal scenes by appearance or motion, lots of previous approaches have used an explicit pre-trained model such as optical flow for motion information, which makes the network complex and dependent on the pre-training. We propose an implicit two-path AutoEncoder (ITAE) that exploits the structure of a SlowFast network and focuses on spatial and temporal information through appearance (slow) and motion (fast) encoders, respectively. The two encoders and a single decoder learn normal appearance and behavior by reconstructing normal videos of the training set. Furthermore, with features from the two encoders, we suggest density estimation through flow-based generative models to learn the tractable likelihoods of appearance and motion features. Finally, we show the effectiveness of appearance and motion encoders and their distribution modeling through experiments in three benchmarks which result outperforms the state-of-the-art methods.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1387831061",
                        "name": "Myeongah Cho"
                    },
                    {
                        "authorId": "48271129",
                        "name": "Taeoh Kim"
                    },
                    {
                        "authorId": "39847092",
                        "name": "Sangyoun Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "TABLE 1 Micro-averaged AUC, macro-averaged AUC, RBDC and TBDC scores (in %) of our approach compared to the state-of-the-art methods [4], [5], [6], [7], [9], [11], [12], [13], [16], [18], [19], [24], [25], [31], [33], [34], [35], [38], [39], [40], [41], [45], [46], [47] on the Avenue data set.",
                "We first compare our approach with several state-of-theart methods [4], [5], [6], [7], [9], [11], [12], [13], [16], [18], [19], [24], [25], [31], [33], [34], [35], [38], [39], [40], [41], [45], [46], [47] reporting results on the Avenue data set.",
                "Most of the recent works treat abnormal event detection as an outlier detection task [2], [3], [4], [5], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [24], [25], [26], [27], [28], [30], [32], [51], learning a model using only normal data.",
                "Considering the prior work on video anomaly detection [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], we can devise a non-exhaustive taxonomy of abnormal events that includes: appearance anomalies (for example, a car or a truck in a pedestrian area), short-term motion anomalies (for example, a person running or a person throwing an object), long-term motion anomalies (for instance, loitering) and group anomalies (for example, several people running inside a public building).",
                "We further compare our method with the state-of-the-art approaches [4], [5], [6], [9], [11], [13], [16], [18], [37], [38], [39], TABLE 2 Micro-averaged AUC, macro-averaged AUC, RBDC and TBDC scores (in %) of our approach compared to the state-of-the-art methods [4], [5], [6], [9], [11], [13], [16], [18], [37], [38], [39], [45], [46], [47] on the ShanghaiTech data set.",
                "We conduct experiments on four challenging benchmarks, namely Avenue [12], ShanghaiTech [13], Subway [23] and UCSD Ped2 [14], reporting favorable performance levels compared to the state-of-the-art methods [4], [5], [6], [7], [8], [9], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [24], [25], [26], [30], [31], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48].",
                "In general, existing abnormal event detection methods build the normality model using local features [7], [8], [12], [13], [14], [19], [22], [27], [28], [29], [30], global (frame-level) features [4], [9], [11], [15], [16], [17], [18], [24], [25], [26], [31], or both [3], [5], [32].",
                "There are at least two works [6], [16] that report the macroaveraged AUC.",
                "Existing abnormal event detection methods can be categorized into distance-based approaches [6], [7], [17], [24], [25], [27], [29], [31], [52], [53], [54], reconstructionbased models [5], [11], [12], [13], [16], [18], [26], [32], [41], [42], probabilistic models [2], [3], [8], [14], [15], [23], [55], [56], [57] and change detection methods [33], [34], [35], [36].",
                "Therefore, the majority of anomaly detection methods proposed so far are based on outlier detection [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [24], [25], [26], [27], learning normality models from training videos containing only normal events."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "51548f7f7493b8ae758925a924df0394051b8ba8",
                "externalIds": {
                    "ArXiv": "2008.12328",
                    "DBLP": "journals/pami/GeorgescuIKPS22",
                    "DOI": "10.1109/TPAMI.2021.3074805",
                    "CorpusId": 233293201,
                    "PubMed": "33881990"
                },
                "corpusId": 233293201,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/51548f7f7493b8ae758925a924df0394051b8ba8",
                "title": "A Background-Agnostic Framework With Adversarial Training for Abnormal Event Detection in Video",
                "abstract": "Abnormal event detection in video is a complex computer vision problem that has attracted significant attention in recent years. The complexity of the task arises from the commonly-adopted definition of an abnormal event, that is, a rarely occurring event that typically depends on the surrounding context. Following the standard formulation of abnormal event detection as outlier detection, we propose a background-agnostic framework that learns from training videos containing only normal events. Our framework is composed of an object detector, a set of appearance and motion auto-encoders, and a set of classifiers. Since our framework only looks at object detections, it can be applied to different scenes, provided that normal events are defined identically across scenes and that the single main factor of variation is the background. This makes our method background agnostic, as we rely strictly on objects that can cause anomalies, and not on the background. To overcome the lack of abnormal data during training, we propose an adversarial learning strategy for the auto-encoders. We create a scene-agnostic set of out-of-domain pseudo-abnormal examples, which are correctly reconstructed by the auto-encoders before applying gradient ascent on the pseudo-abnormal examples. We further utilize the pseudo-abnormal examples to serve as abnormal examples when training appearance-based and motion-based binary classifiers to discriminate between normal and abnormal latent features and reconstructions. Furthermore, to ensure that the auto-encoders focus only on the main object inside each bounding box image, we introduce a branch that learns to segment the main object. We compare our framework with the state-of-the-art methods on four benchmark data sets, using various evaluation metrics. Compared to existing methods, the empirical results indicate that our approach achieves favorable performance on all data sets. In addition, we provide region-based and track-based annotations for two large-scale abnormal event detection data sets from the literature, namely ShanghaiTech and Subway.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "41021255",
                        "name": "Mariana-Iuliana Georgescu"
                    },
                    {
                        "authorId": "1817759",
                        "name": "Radu Tudor Ionescu"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "49006356",
                        "name": "M. Popescu"
                    },
                    {
                        "authorId": "145103012",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Most of the recent works treat abnormal event detection as an outlier detection task [1], [2], [3], [4], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [28], [30], [43], [44], learning a model using only normal data.",
                "[28], global (frame-level) features [3], [8], [10], [14], [15], [16], [17], [18], [19], [21], [29], or both [2], [4], [30].",
                "TABLE 1 Micro-averaged AUC, macro-averaged AUC, RBDC and TBDC scores (in %) of our approach compared to the state-of-the-art methods [3], [4], [5], [6], [8], [10], [11], [12], [15], [16], [17], [21], [22], [29], [31], [32], [33], [37], [41], [42] on the Avenue data set.",
                "There are at least two works [5], [15] that report the macro-averaged AUC.",
                "Several methods trained on the ShanghaiTech training videos [4], [5], [8], [10], [12], [15], [21], [35], [37] are included as reference.",
                "Therefore, the majority of anomaly detection methods proposed so far are based on outlier detection [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], learning normality models from training videos containing only normal events.",
                "We further compare our method with the state-of-the art approaches [3], [4], [5], [8], [10], [12], [15], [21], [35], [37] on the ShanghaiTech data set, presenting the corresponding results in Table 2.",
                "We first compare our approach with several state-of-the-art methods [3], [4], [5], [6], [8], [10], [11], [12], [15], [16], [17], [21], [22], [29], [31], [32], [33], [37], [41], [42] reporting results on the Avenue data set.",
                "TABLE 2 Micro-averaged AUC, macro-averaged AUC, RBDC and TBDC scores (in %) of our approach compared to the state-of-the-art methods [3], [4], [5], [8], [10], [12], [15], [21], [35], [37] on the ShanghaiTech data set.",
                "We conduct experiments on three challenging benchmark data sets, namely Avenue [11], ShanghaiTech [12] and Subway [40], reporting favorable performance levels compared to the state-of-the-art methods [3], [4], [5], [6], [8], [10], [11], [12], [15], [16], [17], [21], [22], [29], [31], [32], [33], [34], [35], [37], [38], [41], [42]."
            ],
            "isInfluential": true,
            "intents": [
                "result",
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "769eda3e381760b22451a4567a9945a8701a079b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2008-12328",
                    "MAG": "3082213779",
                    "CorpusId": 221370573
                },
                "corpusId": 221370573,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/769eda3e381760b22451a4567a9945a8701a079b",
                "title": "A Scene-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video",
                "abstract": "Abnormal event detection in video is a complex computer vision problem that has attracted significant attention in recent years. The complexity of the task arises from the commonly-agreed definition of an abnormal event, that is, a rarely occurring event that typically depends on the surrounding context. Following the standard formulation of abnormal event detection as outlier detection, we propose a scene-agnostic framework that learns from training videos containing only normal events. Our framework is composed of an object detector, a set of appearance and motion auto-encoders, and a discriminator. Since our framework only looks at object detections, it can be applied to different scenes, provided that abnormal events are defined identically across scenes. This makes our method scene agnostic, as we rely strictly on objects that can cause anomalies, and not on the background. To overcome the lack of abnormal data during training, we propose an adversarial learning strategy for the auto-encoders. We create a scene-agnostic set of out-of-domain adversarial examples, which are correctly reconstructed by the auto-encoders before applying gradient ascent on the adversarial examples. We further utilize the adversarial examples to serve as abnormal examples when training a binary classifier to discriminate between normal and abnormal latent features and reconstructions. Furthermore, to ensure that the auto-encoders focus only on the main object inside each bounding box image, we introduce a branch that learns to segment the main object. We compare our framework with the state-of-the-art methods on three benchmark data sets, using various evaluation metrics. Compared to existing methods, the empirical results indicate that our approach achieves favorable performance on all data sets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "41021255",
                        "name": "Mariana-Iuliana Georgescu"
                    },
                    {
                        "authorId": "1817759",
                        "name": "Radu Tudor Ionescu"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "49006356",
                        "name": "M. Popescu"
                    },
                    {
                        "authorId": "145103012",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Video anomaly detectors are originally designed in an unsupervised manner [9], [17], [18], [19], [20] that only normal samples are available in the training phase without any labels."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "c6af93925826c0c918f6aed7261c62f6ba5ed6df",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2008-08944",
                    "MAG": "3058842179",
                    "ArXiv": "2008.08944",
                    "DOI": "10.1109/TIP.2021.3072863",
                    "CorpusId": 221186800,
                    "PubMed": "33872149"
                },
                "corpusId": 221186800,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c6af93925826c0c918f6aed7261c62f6ba5ed6df",
                "title": "Localizing Anomalies From Weakly-Labeled Videos",
                "abstract": "Video anomaly detection under video-level labels is currently a challenging task. Previous works have made progresses on discriminating whether a video sequence contains anomalies. However, most of them fail to accurately localize the anomalous events within videos in the temporal domain. In this paper, we propose a Weakly Supervised Anomaly Localization (WSAL) method focusing on temporally localizing anomalous segments within anomalous videos. Inspired by the appearance difference in anomalous videos, the evolution of adjacent temporal segments is evaluated for the localization of anomalous segments. To this end, a high-order context encoding model is proposed to not only extract semantic representations but also measure the dynamic variations so that the temporal context could be effectively utilized. In addition, in order to fully utilize the spatial context information, the immediate semantics are directly derived from the segment representations. The dynamic variations as well as the immediate semantics, are efficiently aggregated to obtain the final anomaly scores. An enhancement strategy is further proposed to deal with noise interference and the absence of localization guidance in anomaly detection. Moreover, to facilitate the diversity requirement for anomaly detection benchmarks, we also collect a new traffic anomaly (TAD) dataset which specifies in the traffic conditions, differing greatly from the current popular anomaly detection evaluation benchmarks. Thedataset and the benchmark test codes, as well as experimental results, are made public on http://vgg-ai.cn/pages/Resource/ and https://github.com/ktr-hubrt/WSAL. Extensive experiments are conducted to verify the effectiveness of different components, and our proposed method achieves new state-of-the-art performance on the UCF-Crime and TAD datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2064712029",
                        "name": "Hui Lv"
                    },
                    {
                        "authorId": "2110714728",
                        "name": "Chuanwei Zhou"
                    },
                    {
                        "authorId": "144801562",
                        "name": "Zhen Cui"
                    },
                    {
                        "authorId": "48258938",
                        "name": "Chunyan Xu"
                    },
                    {
                        "authorId": "2154404294",
                        "name": "Yong Li"
                    },
                    {
                        "authorId": "51460259",
                        "name": "Jian Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[57] Recon.",
                "8% Memory-guided normality [57] -/97.",
                "In [57], the authors contend that CNN-based reconstruction approaches suffer from reconstructing anomalous events well because of CNNs\u2019 high representational capacity.",
                "Another problematic practice that has emerged is that of per-video normalization, such as that in [9], [10], [18], [46], [54], [56], [57]."
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "02d0ef096d3b39bb83a344393522360aaf69d694",
                "externalIds": {
                    "MAG": "3015495912",
                    "ArXiv": "2004.05993",
                    "DBLP": "journals/corr/abs-2004-05993",
                    "DOI": "10.1109/tpami.2020.3040591",
                    "CorpusId": 215745350,
                    "PubMed": "33237854"
                },
                "corpusId": 215745350,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/02d0ef096d3b39bb83a344393522360aaf69d694",
                "title": "A Survey of Single-Scene Video Anomaly Detection",
                "abstract": "This article summarizes research trends on the topic of anomaly detection in video feeds of a single scene. We discuss the various problem formulations, publicly available datasets and evaluation criteria. We categorize and situate past research into an intuitive taxonomy and provide a comprehensive comparison of the accuracy of many algorithms on standard test sets. Finally, we also provide best practices and suggest some possible directions for future research.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1415112439",
                        "name": "B. Ramachandra"
                    },
                    {
                        "authorId": "2111328837",
                        "name": "Michael J. Jones"
                    },
                    {
                        "authorId": "3001600",
                        "name": "Ranga Raju Vatsavai"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "30aa23a6a32312666f2609339582744203024993",
                "externalIds": {
                    "DBLP": "conf/kdd/PangS0H23",
                    "ArXiv": "1910.13601",
                    "DOI": "10.1145/3580305.3599302",
                    "CorpusId": 210718609
                },
                "corpusId": 210718609,
                "publicationVenue": {
                    "id": "a0edb93b-1e95-4128-a295-6b1659149cef",
                    "name": "Knowledge Discovery and Data Mining",
                    "type": "conference",
                    "alternate_names": [
                        "KDD",
                        "Knowl Discov Data Min"
                    ],
                    "url": "http://www.acm.org/sigkdd/"
                },
                "url": "https://www.semanticscholar.org/paper/30aa23a6a32312666f2609339582744203024993",
                "title": "Deep Weakly-supervised Anomaly Detection",
                "abstract": "Recent semi-supervised anomaly detection methods that are trained using small labeled anomaly examples and large unlabeled data (mostly normal data) have shown largely improved performance over unsupervised methods. However, these methods often focus on fitting abnormalities illustrated by the given anomaly examples only (i.e., seen anomalies), and consequently they fail to generalize to those that are not, i.e., new types/classes of anomaly unseen during training. To detect both seen and unseen anomalies, we introduce a novel deep weakly-supervised approach, namely Pairwise Relation prediction Network (PReNet), that learns pairwise relation features and anomaly scores by predicting the relation of any two randomly sampled training instances, in which the pairwise relation can be anomaly-anomaly, anomaly-unlabeled, or unlabeled-unlabeled. Since unlabeled instances are mostly normal, the relation prediction enforces a joint learning of anomaly-anomaly, anomaly-normal, and normal-normal pairwise discriminative patterns, respectively. PReNet can then detect any seen/unseen abnormalities that fit the learned pairwise abnormal patterns, or deviate from the normal patterns. Further, this pairwise approach also seamlessly and significantly augments the training anomaly data. Empirical results on 12 real-world datasets show that PReNet significantly outperforms nine competing methods in detecting seen and unseen anomalies. We also theoretically and empirically justify the robustness of our model w.r.t. anomaly contamination in the unlabeled data. The code is available at https://github.com/mala-lab/PReNet.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "3224619",
                        "name": "Guansong Pang"
                    },
                    {
                        "authorId": "12459603",
                        "name": "Chunhua Shen"
                    },
                    {
                        "authorId": "34941321",
                        "name": "Huidong Jin"
                    },
                    {
                        "authorId": "133678193",
                        "name": "A. van den Hengel"
                    }
                ]
            }
        },
        {
            "contexts": [
                "5%, compared with the algorithms MemAE [14] and P w/ MemAE [20] using memory modules, our results are also greatly improved, because there are more targets per frame in this data set, and the abnormal events are a small number of bicycles and cars, skateboards, and the normal mode can be well learned through spatial context information fusion to check out the abnormal target.",
                "Video anomaly detection uses unsupervised training, Only using the normal samples as training, and spatial context information of each frame represents a normal mode, so the normal mode from the training set is the key to our anomaly generalization ability, so that part of the exception context information can also be better used for reconstruction, we added a memory module [14] after the context encoding, aiming to learn a limited number of prototype features that can best characterize all normal context information, and save them in memory items, the structure is as shown in Figure 2, the memory block is a matrix of size N\u00d7C, M \u2208 RN\u00d7C, storing N memory items, each memory item is mj, the dimension is C, update and read the memory item during training, Only memory entries are read during testing.",
                "[14] in the AE method added the Memory module, which reduces the generalization ability of the model and makes abnormal samples have larger reconstruction errors.",
                "Obviously, our method has achieved the best results on UCSD-ped2 dataset, compared with the same object detection algorithm FPN-AE-SVM [15], our results are improved by 1.5%, compared with the algorithms MemAE [14] and P w/ MemAE [20] using memory modules, our results are also greatly improved, because there are more targets per frame in this data set, and the abnormal events are a small number of bicycles and cars, skateboards, and the normal mode can be well learned through spatial context information fusion to check out the abnormal target."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "2ef9f7f6c9ff66bf8427203b092ba0d99dc3b0fa",
                "externalIds": {
                    "ArXiv": "1409.8398",
                    "MAG": "2283539075",
                    "DBLP": "journals/corr/abs-2210-09572",
                    "DOI": "10.1109/PRMVIA58252.2023.00037",
                    "CorpusId": 982609
                },
                "corpusId": 982609,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2ef9f7f6c9ff66bf8427203b092ba0d99dc3b0fa",
                "title": "Spatio-Temporal-based Context Fusion for Video Anomaly Detection",
                "abstract": "Video anomaly detection (VAD) detects target objects such as people and vehicles to discover abnormal events in videos. There are abundant spatio-temporal context information in different objects of videos. Most existing methods pay more attention to temporal context than spatial context in VAD. The spatial context information represents the relationship between the detection target and surrounding targets. Anomaly detection makes a lot of sense. To this end, a video anomaly detection algorithm based on target spatio-temporal context fusion is proposed. Firstly, the target in the video frame is extracted through the target detection network to reduce background interference. Then the optical flow map of two adjacent frames is calculated. Motion features are used multiple targets in the video frame to construct spatial context simultaneously, re-encoding the target appearance and motion features, and finally reconstructing the above features through the spatiotemporal dual-stream network, and using the reconstruction error to represent the abnormal score. The algorithm achieves frame-level AUCs of 98.5% on UCSDped2 and 86.3% on Avenue datasets. On UCSDped2 dataset, the spatio-temporal dual-stream network improves frames by 5.1% and 0.3%, respectively, compared to the temporal and spatial stream networks. After using spatial context encoding, the frame-level AUC is enhanced by 1%, which verifies the method\u2019s effectiveness.",
                "year": 2001,
                "authors": [
                    {
                        "authorId": "2118130805",
                        "name": "Chao Hu"
                    },
                    {
                        "authorId": "2057146186",
                        "name": "Weibin Qiu"
                    },
                    {
                        "authorId": "2110542814",
                        "name": "Weijie Wu"
                    },
                    {
                        "authorId": "2155728046",
                        "name": "Liqiang Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To evaluate the results of ABD, during inference, we use average area under curve (AUC) [10].",
                "Detailed description can be found in [10].",
                "As a result, the AUC is boosted by 4.4%.",
                "During training, the final loss function is calculated as the linear combination of prediction, feature compactness, and feature separateness losses [10].",
                "Experimental results show that our method achieves AUC=76.0% on Northking2022.",
                "Following [10], the min-max normalization of L2 distance and PSNR (peak signal-to-noise ratio) is adopted for anomaly score\u2019s calculation, where the L2 distance measures the gap between the actual observed frame features and the pattern features memorized by the model, and the PSNR measures the pixel-level gap between the actual observed frame and the predicted one from the model.",
                "Similar to [10], the input of OLAD is t=4 adjacent frames in the video, and the output is the prediction result for the 5th frame.",
                "One of them employ traditional framelevel unsupervised ABD methods (such as MNAD algorithm [10]), and the other introduces videobased object-level image segmentation methods (for example Mask2Former algorithm [13,14])."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "c6c4c70be42a609e7d4f27fabc4b198776eec526",
                "externalIds": {
                    "DOI": "10.1088/1742-6596/2504/1/012029",
                    "CorpusId": 258998159
                },
                "corpusId": 258998159,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c6c4c70be42a609e7d4f27fabc4b198776eec526",
                "title": "Video Surveillance for Indoor Office Environment Based on Object-Level Anomaly Detection",
                "abstract": "Traditional methods of Abnormal Behavior Detection (ABD) process the surveillance video on frame-level, which ignores object-level abnormal behavior patterns. To address the problem, this paper presents Object-Level Anomaly Detection model (OLAD), which aims to model various normal behavior patterns of different objects and the normal interaction patterns between them. Specifically, OLAD introduces an encoding-embedding network to transform object-level information into the feature space. By integrating such information, OLAD processes both frame-level and object-level cues in the video for ABD. In addition, we construct our own dataset Northking2022 especially for office scenes because of the lack of public datasets for indoor office environments. Experimental results show that OLAD gains better performance on both the public benchmark and Northking2022.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2218704037",
                        "name": "Haotian Chen"
                    },
                    {
                        "authorId": "2218927441",
                        "name": "Chao Zhang"
                    },
                    {
                        "authorId": "33383055",
                        "name": "Zhouchen Lin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "An autoencoder may generalize and fit PAs well, especially when the PAs have structures that are similar to those of bona fide samples [14], [15].",
                "An autoencoder is inclined to reconstruct anomalies so well that it cannot distinguish them if the anomalies share common compositional patterns with normal training data, or the autoencoder learns general OCT image features rather than the particular features of a bona fide sample [14], [15], [18].",
                "ting [14], [15], [18], which enables them to fit presentation attack (PA) samples well, especially those that closely resemble bona fide samples; (2) OCT images contain severe noise, making image-based reconstruction methods vulnerable to noise interference [13]; and (3) existing unsupervised models have difficulty identifying more compact decision boundaries for differentiating between bona fide and PA samples.",
                "Since our approach is derived from an memory-based autoencoder inspired by anomaly detection, we also investigate other unsupervised models for anomaly detection, such as an autoencoder(AE) [49], a variational autoencoder(VAE) [50], a memory-augmented autoencoder(MemAE) [18] and two memory-based models (MAEP [43] and LMN [14]).",
                "In these experiments, the AE, VAE, MemAE, MAEP, and LMN use reconstructed images for discrimination.",
                "proposed a new update strategy to compute queries and distinctions separately and proposed a separateness loss training model [14].",
                "a variational autoencoder(VAE) [50], a memory-augmented autoencoder(MemAE) [18] and two memory-based models (MAEP [43] and LMN [14]).",
                "The proposed model achieves outstanding performance compared to that of the state-of-the-art PAD methods (FFDM [13] and LMD [14]), as shown in Table IV."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "b66965589aa9218c77da8e4d6ce4327993a130d9",
                "externalIds": {
                    "DBLP": "journals/tifs/LiuZLSL23",
                    "DOI": "10.1109/TIFS.2023.3282386",
                    "CorpusId": 259059202
                },
                "corpusId": 259059202,
                "publicationVenue": {
                    "id": "d406a3f4-dc05-43be-b1f6-812f29de9c0e",
                    "name": "IEEE Transactions on Information Forensics and Security",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Inf Forensics Secur"
                    ],
                    "issn": "1556-6013",
                    "url": "http://www.ieee.org/organizations/society/sp/tifs.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=10206",
                        "http://www.signalprocessingsociety.org/publications/periodicals/forensics/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b66965589aa9218c77da8e4d6ce4327993a130d9",
                "title": "Prototype-Guided Autoencoder for OCT-Based Fingerprint Presentation Attack Detection",
                "abstract": "Anti-spoofing ability is vital for fingerprint identification systems. Conventional fingerprint scanning devices can only obtain information from the fingertip surfaces, and their performance is susceptible to skin conditions and presentation attacks (PAs). However, optical coherence tomography (OCT) can scan subcutaneous tissue and obtain 3D fingerprint structures, naturally enhancing its PA detection (PAD) ability from the perspective of hardware. Existing unsupervised PAD methods are based on image reconstruction. However, the reconstruction error is easily affected by OCT noise and the rich details of OCT images. Therefore we propose feature-based reconstruction to alleviate this problem, called the prototype-guided autoencoder. The model consists of a memory module and a denoising autoencoder without the requirement of PA fingerprints. As only bona fide fingerprints are available during the training phase, the memory module contains the prototype features of the bona fide fingerprints. During the inference phase, as the prototype memory module is frozen, the reconstructed representation of the bona fide input is close to the bona fide fingerprint features. Calculating the distance between the original features and the prototype reconstructed representation of the sample can achieve PAD. To obtain a better decision making boundary, we propose a representation consistency constraint, which reduces the bona fide representation reconstruction distance closer, so that it is easier to differentiate between fingerprints and PAs.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108064641",
                        "name": "Yipeng Liu"
                    },
                    {
                        "authorId": "2133777179",
                        "name": "Wangyang Zuo"
                    },
                    {
                        "authorId": "2070440739",
                        "name": "Ronghua Liang"
                    },
                    {
                        "authorId": "2118181028",
                        "name": "Haohao Sun"
                    },
                    {
                        "authorId": "2145303823",
                        "name": "Zhanqing Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "1) Read: Different from [5], [9], which use cosine similarity to retrieve the appropriate memory items, we distribute the input data to each memory item.",
                "3310882 training, and treats those that do not conform to the model as anomalies during testing [5].",
                "[5] proposed to integrate a memory module that includes an updating mechanism at the bottleneck of the network to record diverse prototypical normal patterns, thereby enhancing the model\u2019s prediction ability for normal video frames while simultaneously suppressing it for abnormal events.",
                "To mitigate this drawback, some recent work [5], [9], [10] have proposed utilizing memory networks to preserve prototypical normal patterns, which can help reduce the representation capability of DNNs."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3af29d2d4bd9262f3c54e6a787c90821a056209a",
                "externalIds": {
                    "DBLP": "journals/spl/ZhongHTW23",
                    "DOI": "10.1109/LSP.2023.3310882",
                    "CorpusId": 261451928
                },
                "corpusId": 261451928,
                "publicationVenue": {
                    "id": "d5da7004-7b61-450a-9c7d-a39500de7acf",
                    "name": "IEEE Signal Processing Letters",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Signal Process Lett"
                    ],
                    "issn": "1070-9908",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=97"
                },
                "url": "https://www.semanticscholar.org/paper/3af29d2d4bd9262f3c54e6a787c90821a056209a",
                "title": "Associative Memory With Spatio-Temporal Enhancement for Video Anomaly Detection",
                "abstract": "Memory network has been extensively used to record prototypical normal patterns to prevent overgeneralization of the network to reconstruct anomalies for video anomaly detection. However, existing memory-based methods only record the lossy representation of normal item prototypes, without recording the rich relationships between them. In this work, we propose an Associative Memory with Spatio-Temporal Enhancement (AMSTE) which introduces the global context information constraint of motion to enhance the appearance features and learn the normal item prototypes and their relationship. Specifically, we utilize two encoders to extract spatio-temporal features with the Spatio-Temporal Enhancement Module (STEM) to enhance appearance features with global motion constraints. Then, the prototypical patterns of normal data and their relationships are recorded in the item memory and relational memory, respectively. Finally, we retrieve features from the memory pools and reconstruct the video frame through the decoder. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our approach.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2237100340",
                        "name": "Yuanhong Zhong"
                    },
                    {
                        "authorId": "2237107020",
                        "name": "Yongting Hu"
                    },
                    {
                        "authorId": "2047470075",
                        "name": "Panliang Tang"
                    },
                    {
                        "authorId": "2237090870",
                        "name": "Heng Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                ",n and use them as queries to read the scene features in M, as the reading operation [16].",
                "Therefore, existing methods [13], [14], [15], [16] typically formulate VAD as an unsupervised learning task, where only easily collected normal videos are used to train the model to learn prototypical features of normal events and discriminate",
                "The methods involved in the comparison include (a) traditional handicraft feature-based methods [32], [39], [40], [41], (b) single-stream networks [14], [15], [16], [42], (c) two-stream networks [20], [21], [22], [43], and (d) object-level methods [23], [24], [25].",
                "object-scene interactions, while limiting the model\u2019s ability to generalize to abnormal events to prevent missed detections [16], [17], [18]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "e4e6f0afca17f79dc7a1ab671ab5ad448e97ae7d",
                "externalIds": {
                    "DBLP": "journals/spl/LiuGLLS23",
                    "DOI": "10.1109/LSP.2023.3263792",
                    "CorpusId": 257890729
                },
                "corpusId": 257890729,
                "publicationVenue": {
                    "id": "d5da7004-7b61-450a-9c7d-a39500de7acf",
                    "name": "IEEE Signal Processing Letters",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Signal Process Lett"
                    ],
                    "issn": "1070-9908",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=97"
                },
                "url": "https://www.semanticscholar.org/paper/e4e6f0afca17f79dc7a1ab671ab5ad448e97ae7d",
                "title": "OSIN: Object-Centric Scene Inference Network for Unsupervised Video Anomaly Detection",
                "abstract": "Video Anomaly Detection (VAD) is an essential yet challenging task in the signal processing community, which aims to understand the spatial and temporal contextual interactions between objects and surrounding scenes to detect unexpected events in surveillance videos. However, existing unsupervised methods either use a single network to learn global prototype patterns without making a unique distinction between foreground objects and background scenes or try to strip objects from frames, ignoring that the essence of anomalies lies in unusual object-scene interactions. To this end, this letter proposes an Object-centric Scene Inference Network (OSIN) that uses a well-designed three-stream structure to learn both global scene normality and local object-specific normal patterns as well as explore the object-scene interactions using scene memory networks. Experimental results on three benchmark datasets demonstrate the effectiveness of the proposed OSIN model, which achieves frame-level AUCs of 91.7%, 79.6%, and 98.3% on the CUHK Avenue, ShanghaiTech, and UCSD Ped2 datasets, respectively.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47909156",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2214002144",
                        "name": "Zhengliang Guo"
                    },
                    {
                        "authorId": "2153467142",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "2167599109",
                        "name": "Chengfang Li"
                    },
                    {
                        "authorId": "143875337",
                        "name": "Liang Song"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", models can reconstruct unseen anomalies very well [2], [10], [11], [12].",
                "ory [21], some methods intentionally constrain the representation ability of AE by inserting memory modules between the encoder and decoder [2], [10], [11].",
                "However, it has been widely observed that the AE trained on normal samples can also reconstruct unseen anomalies quite well [2], [10], [11], leading to missed detections of anomalies (as shown in Fig.",
                "On the one hand, some methods have been proposed that attempt to intentionally regulate AEs\u2019 reconstruction ability by inserting memory modules into feature spaces [2], [10], [11].",
                "However, this assumption has been generally observed to be difficult to hold by many works\u2014the trained model can also reconstruct unseen anomalies well [2], [10], [11], [12], [13], [14].",
                "However, it has been widely observed that the unsupervised trained models can also reconstruct unseen anomalies well, leading to missed detection [2], [11], [12], [14]."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "a4b4b63968260f142b0b5a10d8868f18d6930f4c",
                "externalIds": {
                    "DBLP": "journals/tim/ZhangWT23",
                    "DOI": "10.1109/TIM.2023.3276529",
                    "CorpusId": 258732158
                },
                "corpusId": 258732158,
                "publicationVenue": {
                    "id": "3edbd5e0-8799-420a-9ca8-b35c646c354f",
                    "name": "IEEE Transactions on Instrumentation and Measurement",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Instrum Meas"
                    ],
                    "issn": "0018-9456",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=19",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a4b4b63968260f142b0b5a10d8868f18d6930f4c",
                "title": "MTHM: Self-Supervised Multitask Anomaly Detection With Hard Example Mining",
                "abstract": "It is still challenging to detect and locate anomalies by models trained only with normal samples. Methods using image reconstruction as a pretext task can provide precise localization but suffer from harnessing the reconstruction capability on unseen anomalies. This article proposes a new framework of multitasking and hard example mining (MTHM) for anomaly detection and localization. The self-supervised multitask setting creatively takes advantage of the competition among different tasks to learn more compact and efficient representations for detection tasks. Moreover, introducing other semantic tasks allows the shared encoder to learn beyond the pixel-to-pixel mapping of only a single image reconstruction task. Subsequent analysis experiments demonstrate that the proposed method can achieve a more suppressive reconstruction capability for anomalies. During the test process, the outputs of the other tasks can also provide valuable information for anomaly detection and localization. Furthermore, in combination with a novel hard example mining strategy, the byproducts of the image reconstruction task are inexpensively exploited as hard-to-detect samples for enhancing models\u2019 detection ability. And as the model capability increases during training, the detection difficulty of these samples is able to increase adaptively. Our experiments show that hard samples generated in the later training stages can better approximate the real data distribution. With the help of the multitask framework and hard example mining strategy, our method surpasses many state-of-the-art methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2120359876",
                        "name": "Chenkai Zhang"
                    },
                    {
                        "authorId": "2180458547",
                        "name": "Yueming Wang"
                    },
                    {
                        "authorId": "51151126",
                        "name": "Wenming Tan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Most of the previous VAD methods were devoted to unsupervised learning paradigms [4], [5], [6], [7], which train a model to memorize normal patterns by solely using normal samples."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "cfe5f5fad6a1cf11ed5dfdcff9f307506fbd644f",
                "externalIds": {
                    "DBLP": "journals/tifs/LiuZLK23",
                    "DOI": "10.1109/TIFS.2022.3216479",
                    "CorpusId": 253341632
                },
                "corpusId": 253341632,
                "publicationVenue": {
                    "id": "d406a3f4-dc05-43be-b1f6-812f29de9c0e",
                    "name": "IEEE Transactions on Information Forensics and Security",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Inf Forensics Secur"
                    ],
                    "issn": "1556-6013",
                    "url": "http://www.ieee.org/organizations/society/sp/tifs.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=10206",
                        "http://www.signalprocessingsociety.org/publications/periodicals/forensics/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/cfe5f5fad6a1cf11ed5dfdcff9f307506fbd644f",
                "title": "Decouple and Resolve: Transformer-Based Models for Online Anomaly Detection From Weakly Labeled Videos",
                "abstract": "As one of the vital topics in intelligent surveillance, weakly supervised online video anomaly detection (WS-OVAD) aims to identify the ongoing anomalous events moment-to-moment in streaming videos, trained with only video-level annotations. Previous studies tended to utilize a unified single-stage framework, which struggled to simultaneously address the issues of online constraints and weakly supervised settings. To solve this dilemma, in this paper, we propose a two-stage-based framework, namely \u201cdecouple and resolve\u201d (DAR), which consists of two modules, i.e., temporal proposal producer (TPP) and online anomaly localizer (OAL). With the supervision of video-level binary labels, the TPP module targets fully exploiting hierarchical temporal relations among snippets for generating precise snippet-level pseudo-labels. Then, given fine-grained supervisory signals produced by TPP, the Transformer-based OAL module is trained to aggregate both the useful cues retrieved from historical observations and anticipated future semantics, for making predictions at the current time step. Both the TPP and OAL modules are jointly trained to share the beneficial knowledge in a multi-task learning paradigm. Extensive experimental results on three public data sets validate the superior performance of the proposed DAR framework over the competing methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "66506230",
                        "name": "Tianshan Liu"
                    },
                    {
                        "authorId": "2143528650",
                        "name": "Cong Zhang"
                    },
                    {
                        "authorId": "145412853",
                        "name": "K. Lam"
                    },
                    {
                        "authorId": "2072806649",
                        "name": "J. Kong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "advantage of the memory module [22], [23], [24] as the second part of the multi-scale-memorizer, which was previously used in the frame-reconstruction-based method to alleviate the over-generalization issue of autoencoders [22]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "6b1c013e1de3346c4cfe1da631be1a5f61f044c1",
                "externalIds": {
                    "DBLP": "journals/access/TaghinezhadY23",
                    "DOI": "10.1109/ACCESS.2023.3237028",
                    "CorpusId": 256130686
                },
                "corpusId": 256130686,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6b1c013e1de3346c4cfe1da631be1a5f61f044c1",
                "title": "A New Unsupervised Video Anomaly Detection Using Multi-Scale Feature Memorization and Multipath Temporal Information Prediction",
                "abstract": "Anomaly detection in video is an advanced computer vision challenge that recognizes video segments containing out-of-the-ordinary motions or objects. Most recent techniques in video anomaly detection have focused on reconstruction and prediction methods; however, in practice, frame reconstruction methods deliver suboptimal results due to the outstanding generalization abilities of convolutional neural networks when reconstructing abnormal frames. Meanwhile, frame prediction methods have drawn much attention and are a powerful way of simulating the dynamics of natural scenes. This paper provides a new unsupervised frame prediction-based algorithm for anomaly detection that improves overall performance. Our suggested strategy follows a U-Net-like architecture that employs a Time-distributed 2D CNN-based encoder and 2D CNN-based decoder. A memory module is used in the design to retrieve and store the most relevant prototypical pattern of the normal scenario in the memory slots during training giving our model the capacity to produce poor predictions in the case of unusual input. For the memory module to fully retain normal semantic patterns on multiple scales, we propose an upstream multi-branch structure composed of dilated convolutions to extract contextual information. We also provide a multi-path structure that, as a great substitute for the optical flow loss function, directly includes temporal information into the network design. Experiments on the UCSD Ped1, UCSD Ped2, and CUHK Avenue benchmark datasets revealed that our design outperforms most competing models.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2203616169",
                        "name": "Neda Taghinezhad"
                    },
                    {
                        "authorId": "145105283",
                        "name": "M. Yazdi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In [37], the authors augmented the output of an encoder in a variation of an auto-encoder CNN with a memory module that adaptively records prototypical patterns of normal data formore accurate detection of violent cases in a given database.",
                "There were also approaches that augmented memory modules [37]",
                "Authors in [37], [38], and [39] also incorporated auto-encoders to learn normal behaviors, but without"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "9e45f928e499ba2b97d2b396cc402aa842ef159b",
                "externalIds": {
                    "DBLP": "journals/access/HuszarANK23",
                    "DOI": "10.1109/ACCESS.2023.3245521",
                    "CorpusId": 256891190
                },
                "corpusId": 256891190,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9e45f928e499ba2b97d2b396cc402aa842ef159b",
                "title": "Toward Fast and Accurate Violence Detection for Automated Video Surveillance Applications",
                "abstract": "Surveillance cameras are increasingly being used worldwide due to the proliferation of digital video capturing, storage, and processing technologies. However, the large volume of video data generated makes it difficult for humans to perform real-time analysis, and even manual approaches can result in delayed detection of events. Automatic violence detection in surveillance footage has therefore gained significant attention in the scientific community as a way to address this challenge. With the advancement of machine learning algorithms, automatic video recognition tasks such as violence detection have become increasingly feasible. In this study, we investigate the use of smart networks that model the dynamic relationships between actors and/or objects using 3D convolutions to capture both the spatial and temporal structure of the data. We also leverage the knowledge learned by a pre-trained action recognition model for efficient and accurate violence detection in surveillance footage. We extend and evaluate several public datasets featuring diverse and challenging video content to assess the effectiveness of our proposed methods. Our results show that our approach outperforms state-of-the-art methods, achieving approximately a 2% improvement in accuracy with fewer model parameters. Additionally, our experiments demonstrate the robustness of our approach under common compression artifacts encountered in remote server processing applications.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2139628274",
                        "name": "Viktor D\u00e9nes Husz\u00e1r"
                    },
                    {
                        "authorId": "3309933",
                        "name": "V. K. Adhikarla"
                    },
                    {
                        "authorId": "2088936516",
                        "name": "Imre Negyesi"
                    },
                    {
                        "authorId": "71345010",
                        "name": "Csaba Krasznay"
                    }
                ]
            }
        },
        {
            "contexts": [
                "ingly, memory mechanism [29], [30] and iteration mecha-"
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "361493f638981e3aec1f55966a066f0138f01bc8",
                "externalIds": {
                    "DBLP": "journals/access/ZhuDDL23",
                    "DOI": "10.1109/ACCESS.2023.3265715",
                    "CorpusId": 258068348
                },
                "corpusId": 258068348,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/361493f638981e3aec1f55966a066f0138f01bc8",
                "title": "Factorized Industrial Anomaly Detection and Localization",
                "abstract": "Convolutional neural networks trained on large datasets can generalize various down-streaming tasks, including industrial anomaly detection and localization, which is critical in modern large-scale industrial manufacturing. Whereas previous methods have demonstrated that the feature fusion strategy across multiple layers is effective for better performance on industrial anomaly detection and localization, they lack flexibility in intervening and manipulating the local and global information composition process. Through experiments, we demonstrate that the brute-force feature fusion strategy used in previous methods leads to sub-optimal performance in most industrial anomaly detection scenarios. To this end, we propose a novel feature factorization and reversion framework based on invertible neural networks, enabling the selective emphasis or suppression of distinct information in a continuous space by request to fit various preferences for detecting different abnormalities. The preferred local and global info-combination for detecting different defects on 15 objects is studied by experiments exhaustively on the popular benchmark MVTec-AD. Based on feature factorization and reversion, our method is able to outperform previous state-of-the-art methods by a noticeable margin, achieving an image-level anomaly detection AUROC score of up to 99.67% (previously 99.4%), pixel-level anomaly localization AUROC score of 98.61% (previously 98.5%), and AUPRO of 95.15% (previously 94.6%), which validates the effectiveness of the proposed method for industrial anomaly detection and localization.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2203265362",
                        "name": "Yuhao Zhu"
                    },
                    {
                        "authorId": "2214238311",
                        "name": "Linlin Dai"
                    },
                    {
                        "authorId": "2169922214",
                        "name": "Xingzhi Dong"
                    },
                    {
                        "authorId": "2420746",
                        "name": "P. Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "vised learning [2], [3], [4] or weakly supervised methods [5],"
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "e627302263f9f227e961e0d5862d254eca0659d3",
                "externalIds": {
                    "DBLP": "journals/access/GanCTNLC23",
                    "DOI": "10.1109/ACCESS.2023.3266345",
                    "CorpusId": 258098988
                },
                "corpusId": 258098988,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e627302263f9f227e961e0d5862d254eca0659d3",
                "title": "Contrastive-Regularized U-Net for Video Anomaly Detection",
                "abstract": "Video anomaly detection aims to identify anomalous segments in a video. It is typically trained with weakly supervised video-level labels. This paper focuses on two crucial factors affecting the performance of video anomaly detection models. First, we explore how to capture the local and global temporal dependencies more effectively. Previous architectures are effective at capturing either local and global information, but not both. We propose to employ a U-Net like structure to model both types of dependencies in a unified structure where the encoder learns global dependencies hierarchically on top of local ones; then the decoder propagates this global information back to the segment level for classification. Second, overfitting is a non-trivial issue for video anomaly detection due to limited training data. We propose weakly supervised contrastive regularization which adopts a feature-based approach to regularize the network. Contrastive regularization learns more generalizable features by enforcing inter-class separability and intra-class compactness. Extensive experiments on the UCF-Crime dataset shows that our approach outperforms several state-of-the-art methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2214074007",
                        "name": "Kian Yu Gan"
                    },
                    {
                        "authorId": "5524736",
                        "name": "Y. Cheng"
                    },
                    {
                        "authorId": "2087109348",
                        "name": "H. Tan"
                    },
                    {
                        "authorId": "39259570",
                        "name": "Hui-Fuang Ng"
                    },
                    {
                        "authorId": "1890438",
                        "name": "M. Leung"
                    },
                    {
                        "authorId": "38900275",
                        "name": "Joon Huang Chuah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Thus, some methods [21], [22], [23] introduce the memory consisting of only normal sample features into anomaly detection to explicitly suppress the generalization ability of the reconstruction network."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "e50f35840c6f9bbfeb468bede9201df2619769e3",
                "externalIds": {
                    "DBLP": "journals/tim/YangZLH0023",
                    "DOI": "10.1109/TIM.2023.3273681",
                    "CorpusId": 258581116
                },
                "corpusId": 258581116,
                "publicationVenue": {
                    "id": "3edbd5e0-8799-420a-9ca8-b35c646c354f",
                    "name": "IEEE Transactions on Instrumentation and Measurement",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Instrum Meas"
                    ],
                    "issn": "0018-9456",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=19",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e50f35840c6f9bbfeb468bede9201df2619769e3",
                "title": "Self-Supervised Surface Defect Localization via Joint De-Anomaly Reconstruction and Saliency-Guided Segmentation",
                "abstract": "Anomaly localization plays one of the significant role in practical industrial applications but still faces some unique challenges due to the rarity and diversity of anomalies. To address this issue, we propose a self-supervised surface defect localization method via joint de-anomaly reconstruction and saliency-guided segmentation, also named JDRSS. Considering the severe lack of anomalous images, an approach for synthesizing anomalous samples is proposed to simulate different types of anomalies, which results in a variety of realistic and diverse anomalous images. To promote the reconstruction quality to the normal reference, we develop a novel autoencoder-based reconstruction network by applying the bundled de-anomaly constraint to refrain both the embedding space and the reconstruction space from the interference of abnormality. Furthermore, in order to accurately localize the surface defect, an anomalous saliency map-guided segmentation network is proposed, in which the residuals from the reconstructed image and input are dexterously injected into each segmentation layer as spatial attention, thus enhancing the sensitivity to anomalies. We have conducted extensive experiments on the MVTec anomaly detection (MVTec AD) dataset and the proposed model achieves considerable performance for different classes of anomaly localization.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2213548347",
                        "name": "Hanyue Yang"
                    },
                    {
                        "authorId": "2157606419",
                        "name": "Zhenfeng Zhu"
                    },
                    {
                        "authorId": "2146250651",
                        "name": "Chen Lin"
                    },
                    {
                        "authorId": "2149917858",
                        "name": "Wenjun Hui"
                    },
                    {
                        "authorId": "2151485619",
                        "name": "Shenghui Wang"
                    },
                    {
                        "authorId": "2143397421",
                        "name": "Yao Zhao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This module utilizes the Dynamic Memoryguided Normality for Anomaly Detection (DMNAD) method [17], [18] to differentiate between pedestrians and personal mobility users.",
                "Memory-based anomaly detection network used for mobility user recognition [17], [18].",
                "detection-based mobility user recognition [17], [18]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8e135f494c0fee38b852fa9f56eaef16bba2b60a",
                "externalIds": {
                    "DBLP": "journals/access/RohL23",
                    "DOI": "10.1109/ACCESS.2023.3286872",
                    "CorpusId": 259235637
                },
                "corpusId": 259235637,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8e135f494c0fee38b852fa9f56eaef16bba2b60a",
                "title": "Augmented Reality-Based Navigation Using Deep Learning-Based Pedestrian and Personal Mobility User Recognition\u2014A Comparative Evaluation for Driving Assistance",
                "abstract": "Recently, research on augmented reality-based head-up displays (AR-HUDs) for driving assistance has been widely conducted in the automotive industry. The disadvantage of having to look away from the road while driving can be compensated by using AR-HUD-based visualization instead of an auxiliary display on the central dashboard. As the number of personal mobility users on the road increases, and their moving speed is considerably faster than pedestrians, personal mobility makes it more difficult for the driver to cope with dangerous situations. However, there is little research work for considering personal mobility users for driving assistance. This study aims to enhance the driver\u2019s situational awareness to respond to unexpected situation by providing driver assistance information on the AR-HUD by combining deep learning and AR. In particular, the deep learning-based anomaly detection method can recognize personal mobility users effectively. This study also investigates the driver\u2019s understanding of the relationship between the amount of prioritized information provided to AR-HUD and situational cognitive ability. This understanding can be used to adjust the amount of information displayed on the AR-HUD to maintain drivers\u2019 situational awareness. The proposed approach was evaluated through an online study. The results showed that the proposed deep learning-based AR-HUD system improved the driver\u2019s situational awareness and showed advantages in driving assistance compared to the typical system.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2133671658",
                        "name": "D. Roh"
                    },
                    {
                        "authorId": "2155780969",
                        "name": "Jae Yeol Lee"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "67715cca7777da9e7b1237c5ad7b03a8d0443487",
                "externalIds": {
                    "CorpusId": 259325773
                },
                "corpusId": 259325773,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/67715cca7777da9e7b1237c5ad7b03a8d0443487",
                "title": "Deep Anomaly Detection for In-Vehicle Monitoring",
                "abstract": "Deep learning approaches to the detection of visual data instances that markedly digress from regular sequences have been mostly focusing on outdoor video-surveillance scenarios, mainly regarding abnormal behaviour and suspicious or abandoned object detection. However, with the increasing importance of public and shared transportation for urban mobility, it becomes imperative to provide autonomous intelligent systems capable of detecting abnormal behaviour that threatens passenger safety. In-vehicle monitoring becomes particularly relevant for Shared Autonomous Vehicles, which do not have a driver responsible for assuring the well-being and safety of passengers; such vehicles must be accompanied by reliable autonomous in-vehicle surveillance systems.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2187268185",
                        "name": "Francisco Caetano"
                    },
                    {
                        "authorId": "153253956",
                        "name": "P. Carvalho"
                    },
                    {
                        "authorId": "2176561281",
                        "name": "Jaime Cardoso"
                    }
                ]
            }
        },
        {
            "contexts": [
                "into a hybrid paradigm [9], [63], [64], [65], [66]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "073049dbe5bd7a8959bc42d71399011d0074aaed",
                "externalIds": {
                    "DBLP": "journals/tifs/YuWCLZY23",
                    "DOI": "10.1109/TIFS.2023.3300094",
                    "CorpusId": 260409500
                },
                "corpusId": 260409500,
                "publicationVenue": {
                    "id": "d406a3f4-dc05-43be-b1f6-812f29de9c0e",
                    "name": "IEEE Transactions on Information Forensics and Security",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Inf Forensics Secur"
                    ],
                    "issn": "1556-6013",
                    "url": "http://www.ieee.org/organizations/society/sp/tifs.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=10206",
                        "http://www.signalprocessingsociety.org/publications/periodicals/forensics/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/073049dbe5bd7a8959bc42d71399011d0074aaed",
                "title": "Video Anomaly Detection via Visual Cloze Tests",
                "abstract": "Although great progress has been sparked in video anomaly detection (VAD) by deep neural networks (DNNs), existing solutions still fall short in two aspects: 1) The extraction of video events cannot be both precise and comprehensive. 2) The semantics and temporal context are under-explored. To tackle above issues, we are inspired by cloze tests in language education and propose a novel approach named Visual Cloze Completion (VCC), which conducts VAD by completing visual cloze tests (VCTs). Specifically, VCC first localizes each video event and encloses it into a spatio-temporal cube (STC). To realize both precise and comprehensive event extraction, appearance and motion are used as complementary cues to mark the object region associated with each event. For each marked region, a normalized patch sequence is extracted from several neighboring frames and stacked into a STC. With each patch and the patch sequence of a STC regarded as a visual \u201cword\u201d and \u201csentence\u201d respectively, we deliberately erase a certain \u201cword\u201d (patch) to yield a VCT. Then, the VCT is completed by training DNNs to infer the erased patch and its optical flow via video semantics. Meanwhile, VCC fully exploits temporal context by alternatively erasing each patch in temporal context and creating multiple VCTs. Furthermore, we propose localization-level, event-level, model-level and decision-level solutions to enhance VCC, which can further exploit VCC\u2019s potential and produce significant VAD performance improvement. Extensive experiments demonstrate that VCC achieves highly competitive VAD performance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2116615990",
                        "name": "Guang Yu"
                    },
                    {
                        "authorId": "2143244326",
                        "name": "Siqi Wang"
                    },
                    {
                        "authorId": "2182067720",
                        "name": "Zhiping Cai"
                    },
                    {
                        "authorId": "2130021053",
                        "name": "Xinwang Liu"
                    },
                    {
                        "authorId": "143753739",
                        "name": "En Zhu"
                    },
                    {
                        "authorId": "145311707",
                        "name": "Jianping Yin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To mitigate this problem, some approaches [6], [8] propose to replace the features of the input with a combination of normal features, however, the combination sometimes is not still normal [6].",
                "To solve the anomaly escape problem, some approaches [6], [8] propose to replace the feature of the input with a combination of the normal features saved during training."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "b86e5a571c756ea536da38bbe0426a4b80020b7e",
                "externalIds": {
                    "DBLP": "journals/tim/WangLZW23",
                    "DOI": "10.1109/TIM.2023.3300458",
                    "CorpusId": 260415064
                },
                "corpusId": 260415064,
                "publicationVenue": {
                    "id": "3edbd5e0-8799-420a-9ca8-b35c646c354f",
                    "name": "IEEE Transactions on Instrumentation and Measurement",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Instrum Meas"
                    ],
                    "issn": "0018-9456",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=19",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b86e5a571c756ea536da38bbe0426a4b80020b7e",
                "title": "Dual-Branch Learning With Prior Information for Surface Anomaly Detection",
                "abstract": "Visual surface anomaly detection focuses on the classification (CLS) and location (LOC) of regions that deviate from the normal appearance, and generally, only normal samples are provided for training. The reconstruction-based method is widely used, which locates the anomalies by analyzing the reconstruction error. However, there are two problems unsettled in the reconstruction-based method. First, the reconstruction error in the normal regions is sometimes large. This might mislead the model to take the normal regions as anomalies, which is named an overkill problem. Second, it has been observed that the anomalous regions sometimes cannot be repaired to normal, which results in a small reconstruction error in the anomalous regions. This misleads the model to take the anomalies as normal, which is called an anomaly escape problem. Aiming at the above two problems, we propose a model named dual-branch autoencoder with prior information (DBPI) which is mainly composed of a dual-branch AE structure and a GA unit. To alleviate the overkill problem, a natural idea is to reduce the reconstruction error in the normal regions, and therefore a dual-branch AE is proposed. The dual-branch AE reconstructs two images with consistent normal regions and different anomalous regions. By analyzing the reconstruction error between the above two reconstructed images, the anomalies can be detected without causing overkill. For the anomaly escape problem, an effective solution is to add prior information of normal appearance to the reconstructive network, which assists in repairing the anomalous regions and increasing the reconstruction error in the anomalous regions. Since the mathematical expectation map of the training data contains crucial features of the normal appearance, we utilize it as the prior information of the normal appearance. And the prior information is selectively introduced by the proposed gated attention (GA) unit, which effectively assists in reconstructing a normal image and further mitigates the anomaly escape problem. On the average precision (AP) metric for the anomaly detection benchmark dataset MVTec, the proposed unsupervised method outperforms the current state-of-the-art reconstruction-based method self-supervised predictive convolutional attentive block (SSPCAB) by 7.4%. Meanwhile, our unsupervised method also exhibits comparable performance to the best supervised methods on the surface defect detection DAGM dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2203024076",
                        "name": "Shuyuan Wang"
                    },
                    {
                        "authorId": "1484134119",
                        "name": "Chengkan Lv"
                    },
                    {
                        "authorId": "2242886",
                        "name": "Zhengtao Zhang"
                    },
                    {
                        "authorId": "2226694936",
                        "name": "Xueyan Wei"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "2a9e8fcab2b0c1e5c34764b00e20061858bb3e92",
                "externalIds": {
                    "DBLP": "conf/uai/LiCX23",
                    "CorpusId": 260957142
                },
                "corpusId": 260957142,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/2a9e8fcab2b0c1e5c34764b00e20061858bb3e92",
                "title": "Memory Mechanism for Unsupervised Anomaly Detection",
                "abstract": "Unsupervised anomaly detection is a binary classi-\ufb01cation that detects anomalies in unseen samples given only unlabeled normal data. Reconstruction-based approaches are widely used, which perform reconstruction error minimization on training data to learn normal patterns and quantify the degree of anomalies by reconstruction errors on testing data. However, this approach tends to miss anomalies when the normal data has multi-pattern. Because the model generalizes unrestrictedly beyond normal patterns even to include anomaly patterns. In this paper, we proposed a memory mechanism that memorizes typical normal patterns through a capacity-controlled external differentiable matrix so that the generalization of the model to anomalies is limited by the retrieval of the matrix. We achieved state-of-the-art performance on several public benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108959608",
                        "name": "Jiahao Li"
                    },
                    {
                        "authorId": "2145270369",
                        "name": "Yiqiang Chen"
                    },
                    {
                        "authorId": "1430778430",
                        "name": "Yunbing Xing"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The second is a memory-guided AE \u2014 MNAD (Park et al., 2020) that uses a concatenated latent space (of the naive latent space from the encoder output and\nthe typical features stored in a memory module constructed from training) to reconstruct the input.",
                "\u2026inputs (Song et al., 2019), using both the memorized features of the training set and the input\u2019s features to do reconstruction (Gong et al., 2019; Park et al., 2020), and so on, these methods are only studies on benchmark datasets \u2014 Avenue (Lu et al., 2013), ShanghaiTech (Luo et al., 2017),\u2026",
                ", 2019), using both the memorized features of the training set and the input\u2019s features to do reconstruction (Gong et al., 2019; Park et al., 2020), and so on, these methods are only studies on benchmark datasets \u2014 Avenue (Lu et al.",
                "The second is a memory-guided AE \u2014 MNAD (Park et al., 2020) that uses a concatenated latent space (of the naive latent space from the encoder output and the typical features stored in a memory module constructed from training) to reconstruct the input."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5c672e6aeeaf964f218f6ea85d1b0df9c9ce2592",
                "externalIds": {
                    "DBLP": "conf/visapp/LiuNPM22",
                    "DOI": "10.5220/0010907000003124",
                    "CorpusId": 246851323
                },
                "corpusId": 246851323,
                "publicationVenue": {
                    "id": "3e53351c-7355-4159-a3f2-f3b03a3aa989",
                    "name": "VISIGRAPP",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Comput Vis Imaging Comput Graph Theory Appl",
                        "International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications"
                    ],
                    "issn": "2184-4321",
                    "alternate_issns": [
                        "2184-5921"
                    ],
                    "url": "http://www.visigrapp.org/"
                },
                "url": "https://www.semanticscholar.org/paper/5c672e6aeeaf964f218f6ea85d1b0df9c9ce2592",
                "title": "Detecting Anomalies Reliably in Long-term Surveillance Systems",
                "abstract": "In surveillance systems, detecting anomalous events like emergencies or potentially dangerous incidents by manual labor is an expensive task. To improve this, anomaly detection automatically by computer vision relying on the reconstruction error of an autoencoder (AE) is extensively studied. However, these detection methods are often studied in benchmark datasets with relatively short time duration \u2014 a few minutes or hours. This is different from long-term applications where time-induced environmental changes impose an additional influence on the reconstruction error. To reduce this effect, we propose a weighted reconstruction error for anomaly detection in long-term conditions, which separates the foreground from the background and gives them different weights in calculating the error, so that extra attention is paid on human-related regions. Compared with the conventional reconstruction error where each pixel contributes the same, the proposed method increases the anomaly detection rate by more than twice with three kinds of AEs (a variational AE, a memory-guided AE, and a classical AE) running on long-term (three months) thermal datasets, proving the effectiveness of the method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108374960",
                        "name": "Jinsong Liu"
                    },
                    {
                        "authorId": "50577939",
                        "name": "I. Nikolov"
                    },
                    {
                        "authorId": "40601459",
                        "name": "M. P. Philipsen"
                    },
                    {
                        "authorId": "1700569",
                        "name": "T. Moeslund"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(1)\nMeanwhile, inspired by (Park et al., 2020), to increase the diversity of embeddings for learning various patterns of normal samples, a separateness loss Lseparate is adopted to keep the distance of between ze(x) and its nearest embedding e1 smaller than the distance between ze(x) and its second closest embedding e2 with a margin m (set to 1), as shown in Eq.",
                "(1)\nMeanwhile, inspired by (Park et al., 2020), to increase the diversity of embeddings for learning various patterns of normal samples, a separateness loss Lseparate is adopted to keep the distance of between ze(x) and its nearest embedding e1 smaller than the distance between ze(x) and its second\u2026",
                "To solve this, Gong et al. (Gong et al., 2019) and Park et al. (Park et al., 2020) proposed memory-augmented autoencoder methods, which employ a memory book to learn only the key common features of the training dataset to ensure that the reconstructed image is generated from the latent\u2026",
                "(Park et al., 2020) proposed memory-augmented autoencoder methods, which employ a memory book to learn only the key common features of the training dataset to ensure that the reconstructed image is generated from the latent representations of in-distribution data.",
                "Meanwhile, inspired by (Park et al., 2020), to increase the diversity of embeddings for learning various patterns of normal samples, a separateness loss Lseparate is adopted to keep the distance of between ze(x) and its nearest embedding e1 smaller than the distance between ze(x) and its second closest embedding e2 with a margin m (set to 1), as shown in Eq.",
                "To solve this, Gong et al. (Gong et al., 2019) and Park et al. (Park et al., 2020) proposed memory-augmented autoencoder methods, which employ a memory book to learn only the key common features of the training dataset to ensure that the reconstructed image is generated from the latent representations of in-distribution data."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5f7134900435671d8292b0a65fe9983fc1bbd12a",
                "externalIds": {
                    "CorpusId": 247408440
                },
                "corpusId": 247408440,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/5f7134900435671d8292b0a65fe9983fc1bbd12a",
                "title": "Detecting Out-of-Distribution via an Unsupervised Uncertainty Estimation for Prostate Cancer Diagnosis ProstateAI Clinical Collaborators",
                "abstract": "Artificial intelligence-based prostate cancer (PCa) detection models have been widely ex-plored to assist clinical diagnosis. However, these trained models may generate erroneous results specifically on datasets that are not within training distribution. In this paper, we propose an approach to tackle this so-called out-of-distribution (OOD) data problem. Specifically, we devise an end-to-end unsupervised framework to estimate uncertainty values for cases analyzed by a previously trained PCa detection model. Our PCa detection model takes the inputs of bpMRI scans and through our proposed approach we identify OOD cases that are likely to generate degraded performance due to the data distribution shifts. The proposed OOD framework consists of two parts. First, an autoencoder-based reconstruction network is proposed, which learns discrete latent representations of in-distribution data. Second, the uncertainty is computed using perceptual loss that measures the distance between original and reconstructed images in the feature space of a pre-trained PCa detection network. The effectiveness of the proposed framework is evaluated on seven independent data collections with a total of 1,432 cases. The performance of pre-trained PCa detection model is significantly improved by excluding cases with high uncertainty. the convolutional feature maps of a pre-trained (and fixed) PCa detection network between the original and reconstructed images.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "34754023",
                        "name": "H. Huisman"
                    },
                    {
                        "authorId": "39339525",
                        "name": "A. Tong"
                    },
                    {
                        "authorId": "2125693",
                        "name": "T. Penzkofer"
                    },
                    {
                        "authorId": "13975529",
                        "name": "I. Shabunin"
                    },
                    {
                        "authorId": "4024410",
                        "name": "M. Choi"
                    },
                    {
                        "authorId": "2061622061",
                        "name": "Pengyi Xing"
                    },
                    {
                        "authorId": "1392273226",
                        "name": "D. Szolar"
                    },
                    {
                        "authorId": "2052151601",
                        "name": "Steven Shea"
                    },
                    {
                        "authorId": "3111787",
                        "name": "F. Coakley"
                    },
                    {
                        "authorId": "2300588",
                        "name": "M. Harisinghani"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(1)\nMeanwhile, inspired by (Park et al., 2020), to increase the diversity of embeddings for learning various patterns of normal samples, a separateness loss Lseparate is adopted to keep the distance of between ze(x) and its nearest embedding e1 smaller than the distance between ze(x) and its second closest embedding e2 with a margin m (set to 1), as shown in Eq.",
                "(1)\nMeanwhile, inspired by (Park et al., 2020), to increase the diversity of embeddings for learning various patterns of normal samples, a separateness loss Lseparate is adopted to keep the distance of between ze(x) and its nearest embedding e1 smaller than the distance between ze(x) and its second\u2026",
                "To solve this, Gong et al. (Gong et al., 2019) and Park et al. (Park et al., 2020) proposed memory-augmented autoencoder methods, which employ a memory book to learn only the key common features of the training dataset to ensure that the reconstructed image is generated from the latent\u2026",
                "(Park et al., 2020) proposed memory-augmented autoencoder methods, which employ a memory book to learn only the key common features of the training dataset to ensure that the reconstructed image is generated from the latent representations of in-distribution data.",
                "Meanwhile, inspired by (Park et al., 2020), to increase the diversity of embeddings for learning various patterns of normal samples, a separateness loss Lseparate is adopted to keep the distance of between ze(x) and its nearest embedding e1 smaller than the distance between ze(x) and its second closest embedding e2 with a margin m (set to 1), as shown in Eq.",
                "To solve this, Gong et al. (Gong et al., 2019) and Park et al. (Park et al., 2020) proposed memory-augmented autoencoder methods, which employ a memory book to learn only the key common features of the training dataset to ensure that the reconstructed image is generated from the latent representations of in-distribution data."
            ],
            "isInfluential": true,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "5bd2ab16483818363639f0ea91de7e34ec9ae60b",
                "externalIds": {
                    "DBLP": "conf/midl/LiuLDMB0TCK22",
                    "CorpusId": 256942866
                },
                "corpusId": 256942866,
                "publicationVenue": {
                    "id": "2c1c3a62-7d6e-44b9-b225-a9ddb7ebdb8d",
                    "name": "International Conference on Medical Imaging with Deep Learning",
                    "type": "conference",
                    "alternate_names": [
                        "MIDL",
                        "Int Conf Med Imaging Deep Learn"
                    ],
                    "url": "https://www.midl.io/"
                },
                "url": "https://www.semanticscholar.org/paper/5bd2ab16483818363639f0ea91de7e34ec9ae60b",
                "title": "Detecting Out-of-Distribution via an Unsupervised Uncertainty Estimation for Prostate Cancer Diagnosis",
                "abstract": "Artificial intelligence-based prostate cancer (PCa) detection models have been widely explored to assist clinical diagnosis. However, these trained models may generate erroneous results specifically on datasets that are not within training distribution. In this paper, we propose an approach to tackle this so-called out-of-distribution (OOD) data problem. Specifically, we devise an end-to-end unsupervised framework to estimate uncertainty values for cases analyzed by a previously trained PCa detection model. Our PCa detection model takes the inputs of bpMRI scans and through our proposed approach we identify OOD cases that are likely to generate degraded performance due to the data distribution shifts. The proposed OOD framework consists of two parts. First, an autoencoder-based reconstruction network is proposed, which learns discrete latent representations of in-distribution data. Second, the uncertainty is computed using perceptual loss that measures the distance between original and reconstructed images in the feature space of a pre-trained PCa detection network. The effectiveness of the proposed framework is evaluated on seven independent data collections with a total of 1,432 cases. The performance of pre-trained PCa detection model is significantly improved by excluding cases with high uncertainty.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "120809691",
                        "name": "Jingya Liu"
                    },
                    {
                        "authorId": "1403691201",
                        "name": "B. Lou"
                    },
                    {
                        "authorId": "144446750",
                        "name": "M. Diallo"
                    },
                    {
                        "authorId": "46942360",
                        "name": "T. Meng"
                    },
                    {
                        "authorId": "66643452",
                        "name": "H. V. Busch"
                    },
                    {
                        "authorId": "7511921",
                        "name": "R. Grimm"
                    },
                    {
                        "authorId": "35484757",
                        "name": "Yingli Tian"
                    },
                    {
                        "authorId": "1685020",
                        "name": "D. Comaniciu"
                    },
                    {
                        "authorId": "1680557",
                        "name": "A. Kamen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Moreover, (Park et al., 2020) uses a memory module with a different update design to record the prototypical patterns of normal data."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "744fa06d197aa4a1882cd244fd144c7d82a16564",
                "externalIds": {
                    "DBLP": "conf/visapp/El-TahanT22",
                    "DOI": "10.5220/0010909600003124",
                    "CorpusId": 246857878
                },
                "corpusId": 246857878,
                "publicationVenue": {
                    "id": "3e53351c-7355-4159-a3f2-f3b03a3aa989",
                    "name": "VISIGRAPP",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Comput Vis Imaging Comput Graph Theory Appl",
                        "International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications"
                    ],
                    "issn": "2184-4321",
                    "alternate_issns": [
                        "2184-5921"
                    ],
                    "url": "http://www.visigrapp.org/"
                },
                "url": "https://www.semanticscholar.org/paper/744fa06d197aa4a1882cd244fd144c7d82a16564",
                "title": "Semi-supervised Anomaly Detection for Weakly-annotated Videos",
                "abstract": "One of the significant challenges in surveillance anomaly detection research is the scarcity of surveillance datasets satisfying specific ethical and logistical requirements during the collection process. Weakly supervised models aim to solve those challenges by only weakly annotating surveillance videos and creating sophisticated learning techniques to optimize these models, such as Multiple Instance Learning (MIL), which maximizes the boundary between the most anomalous video clip and the least normal (false alarm) video clip using ranking loss. However, maximizing the boundary does not necessarily assign each clip its correct class. We propose a semi-supervision technique that creates pseudo labels for each correct class. Also, we investigate different video recognition models for better features representation. We evaluate our work on the UCF-Crime (Weakly Supervised) dataset and show that it almost outperforms all other approaches by only using the same simple baseline (multilayer perceptron neural network). Moreover, we incorporate different evaluation metrics to show that not only did our solution increase the AUC, but it also increased the top-1 accuracy drastically.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2154539449",
                        "name": "Khaled El-Tahan"
                    },
                    {
                        "authorId": "41133590",
                        "name": "Marwan Torki"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Typical data sources in AD include images [34, 36, 43], video [30, 42], audio [29] and text [36]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "f4ef329dd9e84fa2a4fa7634c6f255eb4035f6d6",
                "externalIds": {
                    "DBLP": "conf/atal/MullerIPHL22",
                    "DOI": "10.5555/3535850.3536113",
                    "CorpusId": 248700170
                },
                "corpusId": 248700170,
                "publicationVenue": {
                    "id": "6c3a9833-5fac-49d3-b7e7-64910bd40b4e",
                    "name": "Adaptive Agents and Multi-Agent Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Adapt Agent Multi-agent Syst",
                        "International Joint Conference on Autonomous Agents & Multiagent Systems",
                        "Adapt Agent Multi-agents Syst",
                        "AAMAS",
                        "Adaptive Agents and Multi-Agents Systems",
                        "Int Jt Conf Auton Agent  Multiagent Syst"
                    ],
                    "url": "http://www.ifaamas.org/"
                },
                "url": "https://www.semanticscholar.org/paper/f4ef329dd9e84fa2a4fa7634c6f255eb4035f6d6",
                "title": "Towards Anomaly Detection in Reinforcement Learning",
                "abstract": "Identifying datapoints that substantially differ from normality is the task of anomaly detection (AD). While AD has gained wide-spread attention in rich data domains such as images, videos, audio and text, it has has been studied less frequently in the context of reinforcement learning (RL). This is due to the additional layer of complexity that RL introduces through sequential decision making. Developing suitable anomaly detectors for RL is of particular importance in safety-critical scenarios where acting on anomalous data could result in hazardous situations. In this work, we address the question of what AD means in the context of RL. We found that current research trains and evaluates on overly simplistic and unrealistic scenarios which reduce to classic pattern recognition tasks. We link AD in RL to various fields in RL such as lifelong RL and generalization. We discuss their similarities, differences, and how the fields can benefit from each other. Moreover, we identify non-stationarity to be one of the key drivers for future research on AD in RL and make a first step towards a more formal treatment of the problem by framing it in terms of the recently introduced block contextual Markov decision process. Finally, we define a list of practical desiderata for future problems.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2114053260",
                        "name": "Robert M\u00fcller"
                    },
                    {
                        "authorId": "51893497",
                        "name": "Steffen Illium"
                    },
                    {
                        "authorId": "41021158",
                        "name": "Thomy Phan"
                    },
                    {
                        "authorId": "2122948810",
                        "name": "Tom Haider"
                    },
                    {
                        "authorId": "1402371578",
                        "name": "C. Linnhoff-Popien"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Also, in [34], they introduced a memory module with items that capture prototypical models of inlier class with a new update system."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "98d1178c5190c73e70770c5c87b9bbcc1a0e9eae",
                "externalIds": {
                    "CorpusId": 250121967
                },
                "corpusId": 250121967,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/98d1178c5190c73e70770c5c87b9bbcc1a0e9eae",
                "title": "Solving Challenges in Deep Unsupervised Methods for Anomaly Detection",
                "abstract": "Anomaly Detection (AD) is to identify samples that differ from training observations in some way. Those samples that do not follow the distribution of normal data are called outliers or anomalies. In this thesis, we examined two different challenges related to deep learning-based anomaly detection methods. The first challenge is the generalizability to outliers. A wide range of unsupervised anomaly detection methods use deep autoencoders as a foundation. However, a notable limitation of deep autoencoders is that they generalize to outliers and reconstruct them with low error. In order to overcome this issue, we propose an adversarial framework consisting of two competing components, an adversarial distorter, and an autoencoder. During training, the adversarial distorter produces perturbations that are applied to the encoder\u2019s latent space to maximize the reconstruction error. The autoencoder attempts to neutralize the effects of these perturbations to minimize the reconstruction error. Another challenge is the high computational cost, complexity, and unstable training procedures of deep anomaly detection methods. Despite being successful at anomaly detection, deep neural networks are difficult to deploy in realworld applications because of this challenge. We overcome this problem by using a simple learning procedure that trains a lightweight convolutional neural network. We propose to solve anomaly detection as a supervised regression problem. We label normal and anomalous data using two separable distributions of continuous values. As a way to compensate for the lack of anomalous samples during training, we use straightforward image augmentation techniques to create a distinct set of anomalous samples. An augmented set has a distribution that is similar to normal data, but deviates slightly from it, while real anomalies should have a further distribution. Consequently, training a regressor on normal and these augmented samples will result in more distinct distributions of labels for normal and real anomalous data points. In several image and video anomaly detection benchmarks, our methods outperform cutting-edge approaches.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1752873904",
                        "name": "Vahid Reza Khazaie"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Inspired by [33, 35], we design the following composite operation (equation (11)).",
                "On this basis, reference [35] used U-Net and memory module; reference [36] used AE and DPU module.",
                "Some work built memory modules that learn only normal patterns from normal data and determine the presence of anomalies by computing reconstruction errors [33, 35]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "13d31719fc5de6f40a288400824cff0960bd4a77",
                "externalIds": {
                    "CorpusId": 250616303
                },
                "corpusId": 250616303,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/13d31719fc5de6f40a288400824cff0960bd4a77",
                "title": "A Three-Stage Anomaly Detection Framework for Traffic Videos",
                "abstract": "As reported by the United Nations in 2021, road accidents cause 1.3 million deaths and 50 million injuries worldwide each year. Detecting traffic anomalies timely and taking immediate emergency response and rescue measures are essential to reduce casualties, economic losses, and traffic congestion. 'is paper proposed a three-stage method for video-based traffic anomaly detection. In the first stage, the ViVit network is employed as a feature extractor to capture the spatiotemporal features from the input video. In the second stage, the class and patch tokens are fed separately to the segment-level and video-level traffic anomaly detectors. In the third stage, we finished the construction of the entire composite traffic anomaly detection framework by fusing outputs of two traffic anomaly detectors above with different granularity. Experimental evaluation demonstrates that the proposed method outperforms the SOTA method with 2.07% AUC on the TAD testing overall set and 1.43% AUC on the TAD testing anomaly subset. 'is work provides a new reference for traffic anomaly detection research.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2723374",
                        "name": "Junzhou Chen"
                    },
                    {
                        "authorId": "2116328603",
                        "name": "Jiancheng Wang"
                    },
                    {
                        "authorId": "2176714927",
                        "name": "Jiajun Pu"
                    },
                    {
                        "authorId": "2152042536",
                        "name": "Ronghui Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Therefore, some researches introduced more complex self-supervised tasks enabling the model to learn semantic reconstruction [15,32] or memory modules storing normal sample features while only reading normal features [16,19,27,43].",
                "The AE-based anomaly detection model depends on that the train AE to reconstruct only normal images [5,15,16,23, 27,32]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "methodology"
            ],
            "citingPaper": {
                "paperId": "61840de4d9610558d510cfcf32986e93511a4cef",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-10495",
                    "DOI": "10.48550/arXiv.2210.10495",
                    "CorpusId": 252992969
                },
                "corpusId": 252992969,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/61840de4d9610558d510cfcf32986e93511a4cef",
                "title": "Asymmetric Distillation Post-Segmentation Method for Image Anomaly Detection",
                "abstract": "Knowledge distillation-based anomaly detection methods generate same outputs for unknown classes due to the symmetric form of the input and ignore the powerful semantic information of the output of the teacher network since it is only used as a \u201creference standard\u201d. Towards this end, this work proposes a novel Asymmetric Distillation Post-Segmentation (ADPS) method to effectively explore the asymmetric structure of the input and the discriminative features of the teacher network. Speci\ufb01cally, a simple yet effective asymmetric input approach is proposed to make different data \ufb02ows through the teacher and student networks. The student network enables to have different inductive and expressive abilities, which can generate different outputs in anomalous regions. Besides, to further explore the semantic information of the teacher network and obtain effective discriminative boundaries, the Weight Mask Block (WMB) and the post-segmentation module are proposede. WMB leverages a weighted strategy by exploring teacher-student feature maps to highlight anomalous features. The post-segmentation module further learns the anomalous features and obtains valid discriminative boundaries. Experimental results on three benchmark datasets demonstrate that the proposed ADPS achieves state-of-the-art anomaly segmentation results.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47189056",
                        "name": "Peng-Fei Xing"
                    },
                    {
                        "authorId": "3233021",
                        "name": "Zechao Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The methods based on different modalities can be categorized into three classes: Unimodal Methods [3], [8], [9], Multimodal Mutual Loss Methods [10], [11] and Multimodal Fusion Methods [12], [13], [14], [15], as shown in Fig.",
                "Evaluation metrics: Following previous works [8], [9], [10], [11], [12], we use the area under the curve (AUC) of the framelevel receiver operating characteristics (ROC) as a primary metric."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "586c45a634b6edcf3ec4d565463d461f1b20e90c",
                "externalIds": {
                    "DBLP": "journals/spl/WeiLZLZ22",
                    "DOI": "10.1109/LSP.2022.3216500",
                    "CorpusId": 253250853
                },
                "corpusId": 253250853,
                "publicationVenue": {
                    "id": "d5da7004-7b61-450a-9c7d-a39500de7acf",
                    "name": "IEEE Signal Processing Letters",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Signal Process Lett"
                    ],
                    "issn": "1070-9908",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=97"
                },
                "url": "https://www.semanticscholar.org/paper/586c45a634b6edcf3ec4d565463d461f1b20e90c",
                "title": "MSAF: Multimodal Supervise-Attention Enhanced Fusion for Video Anomaly Detection",
                "abstract": "The complementarity of multimodal signal is essential for video anomaly detection. However, existing methods either lack exploration to multimodal data or ignore the implicit alignment of multimodal features. In our work, we address this problem using a novel fusion method and propose a Multimodal Supervise-Attention enhanced Fusion (MSAF) framework under weak supervision. Our framework can be divided into two parts: 1) the multimodal labels refinement part refines video-level ground truth into pseudo clip-level labels for subsequent training, 2) the multimodal supervise-attention fusion network enhances features via implicitly aligning different information, then fusing them effectively to predict anomaly scores with the help of refined labels. We validate our framework on four challenging datasets: ShanghaiTech, UCF-Crime, LAD, and XD-Violence. Extensive experiments on the benchmarks demonstrate the effectiveness of our framework, which achieves comparable results on several benchmarks and outperforms current state-of-the-art methods on the XD-Violence audiovisual multimodal dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2151797908",
                        "name": "Donglai Wei"
                    },
                    {
                        "authorId": "47909156",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2116150834",
                        "name": "Xiaoguang Zhu"
                    },
                    {
                        "authorId": "2153467142",
                        "name": "Jing Liu"
                    },
                    {
                        "authorId": "2149581020",
                        "name": "Xinhua Zeng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Relevant studies on VAD can be broadly classified into two categories: unsupervised learning methods [6, 17, 42, 45, 12, 16, 35, 36, 1, 38, 5, 14, 18, 23, 31, 15, 52, 27, 20, 25, 46] and weakly supervised learning methods [29, 51, 32, 4, 48, 53, 40, 21, 47, 39, 34, 41]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "0e8acbcafb1001208dfc14a3fbd3b9a8105dc237",
                "externalIds": {
                    "DBLP": "conf/eccv/LiCZZ22",
                    "DOI": "10.1007/978-3-031-19772-7_20",
                    "CorpusId": 253448802
                },
                "corpusId": 253448802,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/0e8acbcafb1001208dfc14a3fbd3b9a8105dc237",
                "title": "Scale-Aware Spatio-Temporal Relation Learning for Video Anomaly Detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2190443394",
                        "name": "Guoqiu Li"
                    },
                    {
                        "authorId": "7818158",
                        "name": "Guanxiong Cai"
                    },
                    {
                        "authorId": "2550719",
                        "name": "Xingyu Zeng"
                    },
                    {
                        "authorId": "2114012493",
                        "name": "Rui Zhao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Inspired by the memory network [45, 41, 28, 35], we adopt a similar memory update strategy for prototypes."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "9c2be7373d63bba4130bfc33b647276011114b85",
                "externalIds": {
                    "DBLP": "conf/eccv/LiZZSL22",
                    "DOI": "10.1007/978-3-031-20080-9_37",
                    "CorpusId": 253304364
                },
                "corpusId": 253304364,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/9c2be7373d63bba4130bfc33b647276011114b85",
                "title": "Out-of-Distribution Identification: Let Detector Tell Which I Am Not Sure",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2112079860",
                        "name": "Ruoqi Li"
                    },
                    {
                        "authorId": "1750897",
                        "name": "Chongyang Zhang"
                    },
                    {
                        "authorId": "49780826",
                        "name": "Hao Zhou"
                    },
                    {
                        "authorId": "2175688965",
                        "name": "Chao Shi"
                    },
                    {
                        "authorId": "2112601696",
                        "name": "Yan Luo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Previous methods [4,7,12,13,20,21,22,23,27,30,31,33,35,40,43,44,48] deal with VAD in the one-class setup."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "8289f11a7317ecbad3d178ff97a48d2cf2f2601e",
                "externalIds": {
                    "DBLP": "conf/eccv/WuHCFL22",
                    "DOI": "10.1007/978-3-031-19778-9_42",
                    "CorpusId": 253448678
                },
                "corpusId": 253448678,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/8289f11a7317ecbad3d178ff97a48d2cf2f2601e",
                "title": "Self-supervised Sparse Representation for Video Anomaly Detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1557358488",
                        "name": "Jhih-Ciang Wu"
                    },
                    {
                        "authorId": "29850862",
                        "name": "He-Yen Hsieh"
                    },
                    {
                        "authorId": "2785372",
                        "name": "Ding-Jie Chen"
                    },
                    {
                        "authorId": "1703041",
                        "name": "C. Fuh"
                    },
                    {
                        "authorId": "1805102",
                        "name": "Tyng-Luh Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There were several tasks to exploit the memory such as anomaly detection [18,44], few-shot learning [2,23,62], object tracking/detection [15, 25, 58], future prediction [29, 37], and representation learning [19, 26, 30]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "72120226e1c6fb97bd0472cab7f85b2672df9cdb",
                "externalIds": {
                    "DBLP": "conf/eccv/LeePR22",
                    "DOI": "10.1007/978-3-031-19781-9_29",
                    "CorpusId": 253120650
                },
                "corpusId": 253120650,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/72120226e1c6fb97bd0472cab7f85b2672df9cdb",
                "title": "Audio-Visual Mismatch-Aware Video Retrieval via Association and Adjustment",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2909533",
                        "name": "Sangmin Lee"
                    },
                    {
                        "authorId": "70213349",
                        "name": "Sungjune Park"
                    },
                    {
                        "authorId": "2075377906",
                        "name": "Y. Ro"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently, memory networks have been introduced in many computer vision tasks, such as anomaly detection [14, 47], few-shot learning [5, 20, 68], video captioning [48], video prediction [29], etc."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "11739bdb8c9596bfc63fa0044b3e0abd82f790f5",
                "externalIds": {
                    "DBLP": "conf/eccv/SunZCCL22",
                    "DOI": "10.1007/978-3-031-20053-3_13",
                    "CorpusId": 253527663
                },
                "corpusId": 253527663,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/11739bdb8c9596bfc63fa0044b3e0abd82f790f5",
                "title": "MENet: A Memory-Based Network with Dual-Branch for Efficient Event Stream Processing",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2110887906",
                        "name": "Linhui Sun"
                    },
                    {
                        "authorId": "40382978",
                        "name": "Yifan Zhang"
                    },
                    {
                        "authorId": "1998966851",
                        "name": "Ke Cheng"
                    },
                    {
                        "authorId": "2163382256",
                        "name": "Jian Cheng"
                    },
                    {
                        "authorId": "1694235",
                        "name": "Hanqing Lu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We look at the typical reconstruction based comparison (MNAD_recon), as well as the prediction approach (MNAD_pred), using the preceding four consecutive frames to predict the future frame.",
                "The backbone consists of the U-Net structure, without skip-connections for the MNAD_recon variant.",
                "Two versions of the anomaly detector method MNAD [57] are also tested.",
                "The MNAD_pred is the only model keeping a consistent performance through the months without any noticeable drift.",
                "We can see that the MSE for the CAE, VQVAE2 and MNAD_recon increases the farther away the test data goes from the training data.",
                "209 Two versions of the anomaly detector method MNAD [57] are also tested."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3ddf7ac02ae693f7ec85f11f3ceaaa3411353fa1",
                "externalIds": {
                    "DBLP": "conf/nips/NikolovPLDJNM21",
                    "CorpusId": 244907702
                },
                "corpusId": 244907702,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3ddf7ac02ae693f7ec85f11f3ceaaa3411353fa1",
                "title": "Seasons in Drift: A Long Term Thermal Imaging Dataset for Studying Concept Drift",
                "abstract": "The time dimension of datasets and long-term performance of machine learning models have received little attention. With extended deployments in the wild, models are bound to encounter novel scenarios and concept drift that cannot be accounted for during development and training. In order for long-term patterns and cycles to appear in datasets, the datasets must cover long periods of time. Since this is rarely the case, it is difficult to explore how computer vision algorithms cope with changes in data distribution occurring across long-term cycles such as seasons. Video surveillance is an application area clearly affected by concept drift. For this reason we publish the Long-term Thermal Drift (LTD) dataset. LTD consists of thermal surveillance imaging from a single location across 8 months. Along with thermal images we provide relevant metadata such as weather, the day/night cycle and scene activity. In this paper we use the metadata for in-depth analysis of the causal and correlational relationships between environmental variables and the performance of selected computer vision algorithms used for anomaly and object detection. Long-term performance is shown to be most correlated with temperature, humidity, the day/night cycle and scene activity level. This suggests that the coverage of these variables should be prioritised when building datasets for similar applications. As a baseline, we propose to mitigate the impact of concept drift by first detecting points in time where drift occurs. At this point we collect additional data that is used to retraining the models. This improves later performance by an average of 25% across all tested algorithms.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "50577939",
                        "name": "I. Nikolov"
                    },
                    {
                        "authorId": "40601459",
                        "name": "M. P. Philipsen"
                    },
                    {
                        "authorId": "2108374960",
                        "name": "Jinsong Liu"
                    },
                    {
                        "authorId": "9714545",
                        "name": "J. Dueholm"
                    },
                    {
                        "authorId": "2075449066",
                        "name": "A. S. Johansen"
                    },
                    {
                        "authorId": "2143163793",
                        "name": "Kamal Nasrollahi"
                    },
                    {
                        "authorId": "1700569",
                        "name": "T. Moeslund"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Alternatively, this was also solved with generative models, such as the generative adversarial network (GAN) [53] and auto-encoders (AE) [12, 21, 30, 30, 39, 46, 48, 48, 48, 50, 58, 61, 62, 73, 82, 88].",
                "Initially, OCCs were explored with hand-crafted features [4, 45, 75, 83], but more recently, end-to-end deep learning models that learn both the feature extractor and classifier have been proposed [1, 6, 8, 13, 16, 20, 44, 46, 50, 50, 53, 60, 62, 69, 73, 74, 87]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "cdfff974b7f35f0f54c00f1b8412b5b4703a52b7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-10043",
                    "CorpusId": 231699267
                },
                "corpusId": 231699267,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/cdfff974b7f35f0f54c00f1b8412b5b4703a52b7",
                "title": "Unsupervised Anomaly Detection and Localisation with Multi-scale Interpolated Gaussian Descriptors",
                "abstract": "Current unsupervised anomaly detection and localisation systems are commonly formulated as one-class classifiers that depend on an effective estimation of the distribution of normal images and robust criteria to identify anomalies. However, the distribution of normal images estimated by current systems tends to be unstable for classes of normal images that are under-represented in the training set, and the anomaly identification criteria commonly explored in the field does not work well for multi-scale structural and non-structural anomalies. In this paper, we introduce an unsupervised anomaly detection and localisation method designed to address these two issues. More specifically, we introduce a normal image distribution estimation method that is robust to under-represented classes of normal images \u2013 this method is based on adversarially interpolated descriptors from training images and a Gaussian classifier. We also propose a new anomaly identification criterion that can accurately detect and localise multi-scale structural and non-structural anomalies. In extensive experiments on MNIST, Fashion MNIST, CIFAR10 and MVTec AD data sets, our approach shows better results than the current state of the arts in the standard experimental setup for unsupervised anomaly detection and localisation. Code is available at https://github.com/tianyu0207/IGD.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "50581035",
                        "name": "Yuanhong Chen"
                    },
                    {
                        "authorId": "2004357371",
                        "name": "Yu Tian"
                    },
                    {
                        "authorId": "3224619",
                        "name": "Guansong Pang"
                    },
                    {
                        "authorId": "145575177",
                        "name": "G. Carneiro"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Our method MTN-KMIL achieves superior performance when compared with previous SOTA unsupervised learning methods [14, 25, 27, 37, 65] and weaklysupervised approaches [54, 66, 70].",
                "Alternatively, some approaches depend on data reconstruction using generative models to learn the representations of normal samples by (adversarially) minimising the reconstruction error [6,13,18,18,25,31,32,32,33,37,43,46,47,53,60,73]."
            ],
            "isInfluential": false,
            "intents": [
                "background",
                "result"
            ],
            "citingPaper": {
                "paperId": "5ea7869451f38b9f590b53cf5a19c4675d039f13",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-10030",
                    "CorpusId": 231698908
                },
                "corpusId": 231698908,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5ea7869451f38b9f590b53cf5a19c4675d039f13",
                "title": "Weakly-supervised Video Anomaly Detection with Contrastive Learning of Long and Short-range Temporal Features",
                "abstract": "In this paper, we address the problem of weaklysupervised video anomaly detection, in which given videolevel labels for training, we aim to identify in test videos, the snippets containing abnormal events. Although current methods based on multiple instance learning (MIL) show effective detection performance, they ignore important video temporal dependencies. Also, the number of abnormal snippets can vary per anomaly video, which complicates the training process of MIL-based methods because they tend to focus on the most abnormal snippet \u2013 this can cause it to mistakenly select a normal snippet instead of an abnormal snippet, and also to fail to select all abnormal snippets available. We propose a novel method, named Multiscale Temporal Network trained with top-K Contrastive Multiple Instance Learning (MTN-KMIL), to address the issues above. The main contributions of MTN-KMIL are: 1) a novel synthesis of a pyramid of dilated convolutions and a self-attention mechanism, with the former capturing the multi-scale short-range temporal dependencies between snippets and the latter capturing long-range temporal dependencies; and 2) a novel contrastive MIL learning method that enforces large margins between the top-K normal and abnormal video snippets at the feature representation level and anomaly score level, resulting in accurate anomaly discrimination. Extensive experiments show that our method outperforms several state-of-the-art methods by a large margin on three benchmark data sets (ShanghaiTech, UCF-Crime and XD-Violence). Code is available at https://github.com/tianyu0207/MTNKMIL.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2004357371",
                        "name": "Yu Tian"
                    },
                    {
                        "authorId": "3224619",
                        "name": "Guansong Pang"
                    },
                    {
                        "authorId": "50581035",
                        "name": "Yuanhong Chen"
                    },
                    {
                        "authorId": "2115743780",
                        "name": "Rajvinder Singh"
                    },
                    {
                        "authorId": "3582291",
                        "name": "J. Verjans"
                    },
                    {
                        "authorId": "145575177",
                        "name": "G. Carneiro"
                    }
                ]
            }
        },
        {
            "contexts": [
                "introduce the memory module with a new update scheme into the convolutional neural network for anomaly detection, and train the memory according to new feature compactness and separateness losses [15]."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "be3c6ec44c6bc31b7f81b1ba6307dda139f1b036",
                "externalIds": {
                    "DBLP": "journals/access/SongWGDDC21",
                    "DOI": "10.1109/ACCESS.2021.3087705",
                    "CorpusId": 235617806
                },
                "corpusId": 235617806,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/be3c6ec44c6bc31b7f81b1ba6307dda139f1b036",
                "title": "Modeling and Optimization of Semantic Segmentation for Track Bed Foreign Object Based on Attention Mechanism",
                "abstract": "The problem of foreign object intrusion onto the track bed often occurs in the actual operation process of high-speed railways. To solve the problem, we propose an anomaly detection method for the ballastless track bed, which is based on semantic segmentation. Firstly, we put forward the RFODLab semantic segmentation network according to the randomness of foreign objects distribution, and a small proportion of target pixels in the track image. The segmentation results of track image obtained through this model can be used to obtain the accurate pixel information of foreign objects. To further improve the recall and precision, the channel attention mechanism is introduced for the backbone network of the model to aggregate the context information of images, which achieves the weighted constraints of the model on the area to be recognized. Furthermore, to improve the model performance affected by unbalanced sample category distribution during the anomaly detection, we modify the loss function by balancing distribution of each category. The experimental results show that our proposed method can effectively segment various types of anomalies on the ballastless track bed including broken elastic strips, animal carcasses, and fallen pieces. The precision of anomaly detection on the test set can reach 90% while the recall can be maintained at more than 95%. The anomaly detection results on actual lines also verify the effectiveness of the method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "10032491",
                        "name": "Haoran Song"
                    },
                    {
                        "authorId": "3290389",
                        "name": "Shengchun Wang"
                    },
                    {
                        "authorId": "2650085",
                        "name": "Zichen Gu"
                    },
                    {
                        "authorId": "2065773830",
                        "name": "Peng Dai"
                    },
                    {
                        "authorId": "4331849",
                        "name": "Xinyu Du"
                    },
                    {
                        "authorId": "2153512943",
                        "name": "Yu Cheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "trajectory Piciarelli et al. (2008), dynamic texture Mahadevan et al."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "70f1940ce489f82802c7619bd00979a5d7ad6c99",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-01975",
                    "CorpusId": 236912825
                },
                "corpusId": 236912825,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/70f1940ce489f82802c7619bd00979a5d7ad6c99",
                "title": "Sensing Anomalies like Humans: A Hominine Framework to Detect Abnormal Events from Unlabeled Videos",
                "abstract": "Video anomaly detection (VAD) has constantly been a vital topic in video analysis. As anomalies are often rare, it is typically addressed under a semi-supervised setup, which requires a training set with pure normal videos. To avoid exhausted manual labeling, we are inspired by how humans sense anomalies and propose a hominine framework that enables both unsupervised and end-to-end VAD. The framework is based on two key observations: 1) Human perception is usually local, i.e. focusing on local foreground and its context when sensing anomalies. Thus, we propose to impose locality-awareness by localizing foreground with generic knowledge, and a region localization strategy is designed to exploit local context. 2) Frequentlyoccurred events will mould humans\u2019 definition of normality, which motivates us to devise a surrogate training paradigm. It trains a deep neural network (DNN) to learn a surrogate task with unlabeled videos, and frequently-occurred events will play a dominant role in \u201cmoulding\u201d the DNN. In this way, a training loss gap will automatically manifest rarely-seen novel events as anomalies. For implementation, we explore various surrogate tasks as well as both classic and emerging DNN models. Extensive evaluations on commonly-used VAD benchmarks justify the framework\u2019s applicability to different surrogate tasks or DNN models, and demonstrate its astonishing effectiveness: It not only outperforms existing unsupervised solutions by a wide margin (8% to 10% AUROC gain), but also achieves comparable or even superior performance to state-of-the-art semi-supervised counterparts.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1421268306",
                        "name": "Siqi Wang"
                    },
                    {
                        "authorId": "2116615990",
                        "name": "Guang Yu"
                    },
                    {
                        "authorId": "143942560",
                        "name": "Zhiping Cai"
                    },
                    {
                        "authorId": "143753739",
                        "name": "En Zhu"
                    },
                    {
                        "authorId": "2108754292",
                        "name": "Xinwang Liu"
                    },
                    {
                        "authorId": "145311707",
                        "name": "Jianping Yin"
                    },
                    {
                        "authorId": "3038898",
                        "name": "Chengzhang Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026results to classic and state-of-the-art methods on both USCD datasets (Ped1 and Ped2) as in Table 7, we notice that both C3D and AE3D methods for learning representations achieved remarkable results on Ped2, specially regarding AUC comparisons even when compared to recent work (Park et al., 2020).",
                "When comparing C3D and AE3D results to classic and state-of-the-art methods on both USCD datasets (Ped1 and Ped2) as in Table 7, we notice that both C3D and AE3D methods for learning representations achieved remarkable results on Ped2, specially regarding AUC comparisons even when compared to recent work (Park et al., 2020)."
            ],
            "isInfluential": false,
            "intents": [
                "result"
            ],
            "citingPaper": {
                "paperId": "a8ccb4a2d1d63a4106d9ab2dc6d394ff62ef2e94",
                "externalIds": {
                    "DBLP": "conf/visapp/NazareMP21",
                    "DOI": "10.5220/0010347907530762",
                    "CorpusId": 232094020
                },
                "corpusId": 232094020,
                "publicationVenue": {
                    "id": "3e53351c-7355-4159-a3f2-f3b03a3aa989",
                    "name": "VISIGRAPP",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Comput Vis Imaging Comput Graph Theory Appl",
                        "International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications"
                    ],
                    "issn": "2184-4321",
                    "alternate_issns": [
                        "2184-5921"
                    ],
                    "url": "http://www.visigrapp.org/"
                },
                "url": "https://www.semanticscholar.org/paper/a8ccb4a2d1d63a4106d9ab2dc6d394ff62ef2e94",
                "title": "Investigating 3D Convolutional Layers as Feature Extractors for Anomaly Detection Systems Applied to Surveillance Videos",
                "abstract": "Over the last few years, several strategies have been leveraged to detect unusual behavior in surveillance videos. Nonetheless, there are still few studies that compare strategies based on 3D Convolutional Neural Networks to tackle such problem. This research gap has motivated the this work in which we aim at investigating the features from a pre-trained C3D model and the training of fully 3D-convolutional auto-encoders for automated video anomaly detection systems, comparing them with respect to the anomaly detection performance and the processing power demands. Additionally, we present an auto-encoder model to detect anomalous behavior based on the pixel reconstruction error. While C3D features coming from the first layers were shown to be both better descriptors and faster to be computed, the auto-encoder achieved results comparable to the C3D, while requiring less computational effort. When compared to other studies using two benchmark datasets, the proposed methods are comparable to the state-of-the-art for the Ped2 dataset, while inferior when detecting anomalies on the Ped1 dataset. Additionally, our experimental results support the development of future 3DCNN-based anomaly detection methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145150241",
                        "name": "T. S. Nazar\u00e9"
                    },
                    {
                        "authorId": "145921064",
                        "name": "R. Mello"
                    },
                    {
                        "authorId": "145202695",
                        "name": "M. Ponti"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[49] introduced a nonlearnable memory module that can be updated with inputs.",
                "[49] Hyunjong Park, Jongyoun Noh, and Bumsub Ham."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "0a0adec915e0a0165e9d048df46dc11404d8f9ca",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-13495",
                    "CorpusId": 244709610
                },
                "corpusId": 244709610,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0a0adec915e0a0165e9d048df46dc11404d8f9ca",
                "title": "In-painting Radiography Images for Unsupervised Anomaly Detection",
                "abstract": "We propose s pace-aware memory qu eues for i n-painting and d etecting anomalies from radiography images (abbre-viated as SQUID). Radiography imaging protocols focus on particular body regions, therefore producing images of great similarity and yielding recurrent anatomical structures across patients. To exploit this structured information, our SQUID consists of a new Memory Queue and a novel in-painting block in the feature space. We show that SQUID can taxonomize the ingrained anatomical structures into recurrent patterns; and in the inference, SQUID can identify anomalies (unseen/modi\ufb01ed patterns) in the image. SQUID surpasses the state of the art in unsupervised anomaly detection by over 5 points on two chest X-ray benchmark datasets. Additionally, we have created a new dataset (Dig-itAnatomy), which synthesizes the spatial correlation and consistent shape in chest anatomy. We hope DigitAnatomy can prompt the development, evaluation, and interpretability of anomaly detection methods, particularly for radiography imaging. Code and dataset will be made available.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "151389946",
                        "name": "Tiange Xiang"
                    },
                    {
                        "authorId": "2946371",
                        "name": "Yongyi Lu"
                    },
                    {
                        "authorId": "145081362",
                        "name": "A. Yuille"
                    },
                    {
                        "authorId": "90477010",
                        "name": "Chaoyi Zhang"
                    },
                    {
                        "authorId": "122905659",
                        "name": "Weidong (Tom) Cai"
                    },
                    {
                        "authorId": "1389392654",
                        "name": "Zongwei Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "AE [1-6] (Auto-Encoder), VAE [7, 8] (Variational Auto-Encoder), f-AnoGAN [9] and their variants attempt to model the distribution of normality with abnormal samples, by reducing reconstruction error between origin image and reconstructed image."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "19ac86e7ac8d42f02e6936b7ee820ef6cc1ff752",
                "externalIds": {
                    "CorpusId": 246063046
                },
                "corpusId": 246063046,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/19ac86e7ac8d42f02e6936b7ee820ef6cc1ff752",
                "title": "Improved Anomaly Detection Based on Image Reconstruction and Global Template Features for Industrial Products",
                "abstract": "Anomaly detection in industry applications is a challenging problem when negative (defective) samples are unavailable, especially in the case where there are missing parts or foreign objects occupied a relatively large region. Conventional reconstruction-based approaches cannot guarantee the restored image being a normal one, leading to poor segmentation results. In this work, we propose an unsupervised anomaly detection approach to tackle the problem of large-area anomaly detection by incorporating global template features into an Auto-Encoder like reconstruction model. In particular, our model infers the value of each pixel based on both the surrounding local-neighborhood information and the global information encoded at the same pixel position. During the reconstruction phase, any abnormal features are then replaced with normal ones, avoiding over-reconstruction of large-area abnormalities. The experimental results in comparison with other methods demonstrate its effectiveness for industrial anomaly detection.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2107555518",
                        "name": "H. Tang"
                    },
                    {
                        "authorId": "102328811",
                        "name": "Guanghuan Hu"
                    },
                    {
                        "authorId": "3112184",
                        "name": "Wenli He"
                    },
                    {
                        "authorId": "2150566673",
                        "name": "Qianxi Tu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The deep methods of abnormal event detection can be roughly divided into classificationbased methods [13], [24], [25] and reconstruction-based methods [12], [26], [27]."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "7e3a6497bf2d6be62738ed05d0e6adfe606a6a3d",
                "externalIds": {
                    "MAG": "3085932345",
                    "DBLP": "journals/tmm/SunJSW21",
                    "DOI": "10.1109/TMM.2020.3023303",
                    "CorpusId": 226721276
                },
                "corpusId": 226721276,
                "publicationVenue": {
                    "id": "10e76a35-58d6-443c-9683-fc16f2dd0a92",
                    "name": "IEEE transactions on multimedia",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Transactions on Multimedia",
                        "IEEE Trans Multimedia",
                        "IEEE trans multimedia"
                    ],
                    "issn": "1520-9210",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6046"
                },
                "url": "https://www.semanticscholar.org/paper/7e3a6497bf2d6be62738ed05d0e6adfe606a6a3d",
                "title": "Adversarial 3D Convolutional Auto-Encoder for Abnormal Event Detection in Videos",
                "abstract": "Abnormal event detection aims to identify the events that deviate from expected normal patterns. Existing methods usually extract normal spatio-temporal patterns of appearance and motion in a separate manner, which ignores low-level correlations between appearance and motion patterns and may fall short of capturing fine-grained spatio-temporal patterns. In this paper, we propose to simultaneously learn appearance and motion to obtain fine-grained spatio-temporal patterns. To this end, we present an adversarial 3D convolutional auto-encoder to learn the normal spatio-temporal patterns and then identify abnormal events by diverging them from the learned normal patterns in videos. The encoder captures the low-level correlations between spatial and temporal dimensions of videos, and generates distinctive features representing visual spatio-temporal information. The decoder reconstrucccts the original video from the encoded features representing by 3D de-convolutions and learns the normal spatio-temporal patterns in an unsupervised manner. We introduce the denoising reconstruction error and adversarial learning strategy to train the 3D convolutional auto-encoder to implicitly learn accurate data distributions that are considered normal patterns, which benefits enhancing the reconstruction ability of the auto-encoder to discriminate abnormal events. Both the theoretical analysis and the extensive experiments on four publicly available datasets demonstrate the effectiveness of our method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "41172535",
                        "name": "Che Sun"
                    },
                    {
                        "authorId": "7415267",
                        "name": "Yunde Jia"
                    },
                    {
                        "authorId": "40506635",
                        "name": "Hao Song"
                    },
                    {
                        "authorId": "150352923",
                        "name": "Yuwei Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We compare our method with multiple existing methods [1], [18], [42], [43], [45]\u2013[47], [49]\u2013[55]."
            ],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "64f61bed2b9d8c7bf28601d2b7425f958f466c4f",
                "externalIds": {
                    "DBLP": "journals/access/ZhangWHWW21",
                    "DOI": "10.1109/ACCESS.2021.3110798",
                    "CorpusId": 237520562
                },
                "corpusId": 237520562,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/64f61bed2b9d8c7bf28601d2b7425f958f466c4f",
                "title": "Generative Adversarial Networks for Abnormal Event Detection in Videos Based on Self-Attention Mechanism",
                "abstract": "Unsupervised anomaly detection defines an abnormal event as an event that does not conform to expected behavior. In the field of unsupervised anomaly detection, it is a pioneering work that leverages the difference between a future frame predicted by a generative adversarial network and its ground truth to detect an abnormal event. Based on the work, we improve the ability of video prediction framework to detect abnormal events by enhancing the difference between prediction results for normal and abnormal events. We incorporate super-resolution and self-attention mechanism to design a generative adversarial network. We propose an auto-encoder as a generator, which incorporates dense residual networks and self-attention. Moreover, we propose a new discriminator, which introduces self-attention on the basis of a relativistic discriminator. To predict a future frame with higher quality for normal events, we impose a constraint on the motion in video prediction by fusing optical flow and gradient difference between frames. We also introduce a perception constraint in video prediction to enrich the texture details of a frame. The AUC of our method on CUHK Avenue and Shanghai Tech datasets reaches 89.2% and 75.7% respectively, which is better than most existing methods. In addition, we propose a processing flow that can realize real-time anomaly detection in videos. The average running time of our video prediction framework is 37 frames per second. Among all real-time methods for abnormal event detection in videos, our method is competitive with the state-of-the-art methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2108043743",
                        "name": "Weichao Zhang"
                    },
                    {
                        "authorId": "48738181",
                        "name": "Guanjun Wang"
                    },
                    {
                        "authorId": "2108508955",
                        "name": "Mengxing Huang"
                    },
                    {
                        "authorId": "2109799094",
                        "name": "Hongyu Wang"
                    },
                    {
                        "authorId": "2131810955",
                        "name": "Shaoping Wen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "31662bfb4f1fc457713f22769c113786cca0bc8d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-14953",
                    "CorpusId": 263612025
                },
                "corpusId": 263612025,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/31662bfb4f1fc457713f22769c113786cca0bc8d",
                "title": "OLED: One-Class Learned Encoder-Decoder Network with Adversarial Context Masking for Novelty Detection",
                "abstract": "Novelty detection is the task of recognizing samples that do not belong to the distribution of the target class. During training, the novelty class is absent, preventing the use of traditional classification approaches. Deep autoencoders have been widely used as a base of many unsupervised novelty detection methods. In particular, context autoencoders have been successful in the novelty detection task because of the more effective representations they learn by reconstructing original images from randomly masked images. However, a significant drawback of context autoencoders is that random masking fails to consistently cover important structures of the input image, leading to suboptimal representations especially for the novelty detection task. In this paper, to optimize input masking, we have designed a framework consisting of two competing networks, a Mask Module and a Reconstructor. The Mask Module is a convolutional autoencoder that learns to generate optimal masks that cover the most important parts of images. Alternatively, the Reconstructor is a convolutional encoderdecoder that aims to reconstruct unperturbed images from masked images. The networks are trained in an adversarial manner in which the Mask Module generates masks that are applied to images given to the Reconstructor. In this way, the Mask Module seeks to maximize the reconstruction error that the Reconstructor is minimizing. When applied to novelty detection, the proposed approach learns semantically richer representations compared to context autoencoders and enhances novelty detection at test time through more optimal masking. Novelty detection experiments on the MNIST and CIFAR-10 image datasets demonstrate the proposed approach\u2019s superiority over cutting-edge methods. In a further experiment on the UCSD video dataset for novelty detection, the proposed approach achieves a framelevel Area Under the Curve (AUC) of 99.02% and an Equal Error Rate (EER) of 5.4%, exceeding recent state-of-the-art models.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2060864798",
                        "name": "John Taylor Jewell"
                    },
                    {
                        "authorId": "1752873904",
                        "name": "Vahid Reza Khazaie"
                    },
                    {
                        "authorId": "49318589",
                        "name": "Y. Mohsenzadeh"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Datasets for Anomaly Detection: Today vision algorithms are heavily data driven.",
                "\u2013 Future Frame Prediction for Anomaly Detection \u2013",
                "Anomaly Detection in Surveillance Cameras: Surveillance cameras are deployed in a variety of scenarios and are expected to function through varying global conditions like natural illumination changes such as day, night, dawn, etc. and weather changes such as rain, snow, and fog.",
                "\u2013 Learning Memory-guided Normality for Anomaly Detection [29] (Mnad) (CVPR 2020): This method is similar to the MemAE [28]."
            ],
            "isInfluential": true,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "3487a04ce0a9c48387641c9fd957cc390bf267f9",
                "externalIds": {
                    "MAG": "3109624656",
                    "CorpusId": 229676946
                },
                "corpusId": 229676946,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3487a04ce0a9c48387641c9fd957cc390bf267f9",
                "title": "A Day on Campus - An Anomaly Detection Dataset for Events in a Single Camera",
                "abstract": "Detecting anomalies in videos is a complex problem with a myriad of applications in video surveillance. However, large and complex datasets that are representative of real-world deployment of surveillance cameras are unavailable. Anomalies in surveillance videos are not well defined and the standard and existing metrics for evaluation do not quantify the performance of algorithms accurately. We provide a large scale dataset, A Day on Campus (ADOC), with 25 event types, spanning over 721 instances and occurring over a period of 24 hours. This is the largest dataset with localized bounding box annotations that is available to perform anomaly detection. We design a novel metric to evaluate the performance of methods and we perform an evaluation of the state-ofthe-art methods to ascertain their readiness to transition into real-world surveillance scenarios.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "97362708",
                        "name": "M. Pranav"
                    },
                    {
                        "authorId": "2145367101",
                        "name": "Zhenggang Li"
                    },
                    {
                        "authorId": "2099110164",
                        "name": "S. Shishir"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently, some deep learningbased methods have been proposed in various products, such as the detecting defects on fabric, metallic surfaces [19], [34], images and videos [4], [12], [23], [24], [30], [31], [37]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "0978c043b11c9c2737449a4abdd253b7748ab5f0",
                "externalIds": {
                    "DBLP": "journals/access/KimJCSLL20",
                    "MAG": "3107325278",
                    "DOI": "10.1109/ACCESS.2020.3041790",
                    "CorpusId": 228092949
                },
                "corpusId": 228092949,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0978c043b11c9c2737449a4abdd253b7748ab5f0",
                "title": "Spatially Variant Convolutional Autoencoder Based on Patch Division for Pill Defect Detection",
                "abstract": "Detecting pill defection remains challenging, despite recent extensive studies, because of the lack of defective data. In this paper, we propose a pipeline composed of a pill detection module and an autoencoder-based defect detection module to detect defective pills in pill packages. Furthermore, we created a new dataset to test our model. The pill detection module segments pills in an aluminum-plastic package into individual pills. To segment pills, we used a shallow segmentation network that is then divided into individual pills using the watershed algorithm. The defect detection module identifies defects in individual pills. It is trained only on the normal data. Thus, it is expected that the module will be unable to reconstruct defective data correctly. However, in reality, the conventional autoencoder reconstructs defective data better than expected, even if the network is trained only on normal data. Hence, we introduce a patch division method to prevent this problem. The patch division involves dividing the output of the convolutional encoder network into patch-wise features, and then applying patch-wise encoder layer. In this process, each latent patch has its independent weight and bias. This can be interpreted as reconstructing the input image using multiple local autoencoders. The patch division makes the network concentrate only on reconstructing local regions, thereby reducing the overall capacity. This prohibits the proposed network reconstructing unseen data well. Experiments show that the proposed patch division technique indeed improves the defect detection performance and outperforms existing deep learning based anomaly detection methods. The ablation study shows the efficacy of patch division and compression following the concatenation of patch-wise features.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2109593073",
                        "name": "Sora Kim"
                    },
                    {
                        "authorId": "3419929",
                        "name": "Young-Hoo Jo"
                    },
                    {
                        "authorId": "2803030",
                        "name": "Jungchan Cho"
                    },
                    {
                        "authorId": "2047081270",
                        "name": "Jiwoo Song"
                    },
                    {
                        "authorId": "2109236645",
                        "name": "Younyoung Lee"
                    },
                    {
                        "authorId": "2646766",
                        "name": "Minsik Lee"
                    }
                ]
            }
        }
    ]
}