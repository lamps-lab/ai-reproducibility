{
    "offset": 0,
    "data": [
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "5f686b80f912d24051c847f4e7e651be07ea0729",
                "externalIds": {
                    "ArXiv": "2303.14646",
                    "DBLP": "journals/corr/abs-2303-14646",
                    "DOI": "10.48550/arXiv.2303.14646",
                    "CorpusId": 257766517
                },
                "corpusId": 257766517,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5f686b80f912d24051c847f4e7e651be07ea0729",
                "title": "A Survey of Machine Learning-Based Ride-Hailing Planning",
                "abstract": "Ride-hailing is a sustainable transportation paradigm where riders access door-to-door traveling services through a mobile phone application, which has attracted a colossal amount of usage. There are two major planning tasks in a ride-hailing system: (1) matching, i.e., assigning available vehicles to pick up the riders, and (2) repositioning, i.e., proactively relocating vehicles to certain locations to balance the supply and demand of ride-hailing services. Recently, many studies of ride-hailing planning that leverage machine learning techniques have emerged. In this article, we present a comprehensive overview on latest developments of machine learning-based ride-hailing planning. To offer a clear and structured review, we introduce a taxonomy into which we carefully fit the different categories of related works according to the types of their planning tasks and solution schemes, which include collective matching, distributed matching, collective repositioning, distributed repositioning, and joint matching and repositioning. We further shed light on many real-world datasets and simulators that are indispensable for empirical studies on machine learning-based ride-hailing planning strategies. At last, we propose several promising research directions for this rapidly growing research and practical field.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "7020081",
                        "name": "Dacheng Wen"
                    },
                    {
                        "authorId": "2110458079",
                        "name": "Yupeng Li"
                    },
                    {
                        "authorId": "1697834",
                        "name": "F. Lau"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "f4ddc5c64e9c9ff2355937a059bab9511c3df999",
                "externalIds": {
                    "DBLP": "conf/aips/KumarV023",
                    "ArXiv": "2303.14332",
                    "DOI": "10.48550/arXiv.2303.14332",
                    "CorpusId": 257766700
                },
                "corpusId": 257766700,
                "publicationVenue": {
                    "id": "267934f4-c986-4571-bef8-d0eebc5e0e54",
                    "name": "International Conference on Automated Planning and Scheduling",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Autom Plan Sched",
                        "ICAPS"
                    ],
                    "url": "http://www.icaps-conference.org/"
                },
                "url": "https://www.semanticscholar.org/paper/f4ddc5c64e9c9ff2355937a059bab9511c3df999",
                "title": "Using Simple Incentives to Improve Two-Sided Fairness in Ridesharing Systems",
                "abstract": "State-of-the-art order dispatching algorithms for ridesharing batch passenger requests and allocate them to a fleet of vehicles in a centralized manner, optimizing over the estimated values of each vehicle-passenger matching using integer linear programming. Using good estimates of future value, such ILP-based approaches are able to significantly increase the service rates (percentage of requests served) for a fixed fleet of vehicles.\nHowever, such approaches that focus solely on maximizing efficiency can lead to disparities for both drivers (e.g., income inequality) and passengers (e.g., inequality of service for different groups). Existing approaches that consider fairness only do it for naive assignment policies, require extensive training or look at only single-sided fairness.\nWe propose a simple incentive-based fairness scheme (SI) that can be implemented online as a part of this ILP formulation that allows us to improve fairness over a variety of fairness metrics. Deriving from a lens of variance minimization, we describe how these fairness incentives can be formulated for two distinct use cases for passenger groups (SIP) and driver (SID) fairness. We show that under mild conditions, our approach can guarantee an improvement in the chosen metric for the worst-off individual. \nWe also show empirically that our Simple Incentives approach significantly outperforms prior art, despite requiring no retraining; indeed, it often leads to a large improvement over the state-of-the-art fairness-aware approach in both overall service rate and fairness.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2118070729",
                        "name": "Ashwin Kumar"
                    },
                    {
                        "authorId": "1699600",
                        "name": "Yevgeniy Vorobeychik"
                    },
                    {
                        "authorId": "1805457",
                        "name": "W. Yeoh"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "ffae901292c459ac22c299279381db6ffafd1d90",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-01725",
                    "ArXiv": "2212.01725",
                    "DOI": "10.48550/arXiv.2212.01725",
                    "CorpusId": 254247312
                },
                "corpusId": 254247312,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/ffae901292c459ac22c299279381db6ffafd1d90",
                "title": "Fairness in Contextual Resource Allocation Systems: Metrics and Incompatibility Results",
                "abstract": "We study critical systems that allocate scarce resources to satisfy basic needs, such as homeless services that provide housing. These systems often support communities disproportionately affected by systemic racial, gender, or other injustices, so it is crucial to design these systems with fairness considerations in mind. To address this problem, we propose a framework for evaluating fairness in contextual resource allocation systems that is inspired by fairness metrics in machine learning. This framework can be applied to evaluate the fairness properties of a historical policy, as well as to impose constraints in the design of new (counterfactual) allocation policies. Our work culminates with a set of incompatibility results that investigate the interplay between the different fairness metrics we propose. Notably, we demonstrate that: 1) fairness in allocation and fairness in outcomes are usually incompatible; 2) policies that prioritize based on a vulnerability score will usually result in unequal outcomes across groups, even if the score is perfectly calibrated; 3) policies using contextual information beyond what is needed to characterize baseline risk and treatment effects can be fairer in their outcomes than those using just baseline risk and treatment effects; and 4) policies using group status in addition to baseline risk and treatment effects are as fair as possible given all available information. Our framework can help guide the discussion among stakeholders in deciding which fairness metrics to impose when allocating scarce resources.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2125455978",
                        "name": "Nathanael Jo"
                    },
                    {
                        "authorId": "100609934",
                        "name": "Bill Tang"
                    },
                    {
                        "authorId": "2151088102",
                        "name": "Kathryn Dullerud"
                    },
                    {
                        "authorId": "15015367",
                        "name": "S. Aghaei"
                    },
                    {
                        "authorId": "2150010373",
                        "name": "Eric Rice"
                    },
                    {
                        "authorId": "1716369",
                        "name": "P. Vayanos"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "isInfluential": false,
            "intents": [],
            "citingPaper": {
                "paperId": "2661c3ba34e6e82b38387a610767b57fe42d9757",
                "externalIds": {
                    "DBLP": "conf/kdd/SunJYSW22",
                    "DOI": "10.1145/3534678.3539060",
                    "CorpusId": 251518265
                },
                "corpusId": 251518265,
                "publicationVenue": {
                    "id": "a0edb93b-1e95-4128-a295-6b1659149cef",
                    "name": "Knowledge Discovery and Data Mining",
                    "type": "conference",
                    "alternate_names": [
                        "KDD",
                        "Knowl Discov Data Min"
                    ],
                    "url": "http://www.acm.org/sigkdd/"
                },
                "url": "https://www.semanticscholar.org/paper/2661c3ba34e6e82b38387a610767b57fe42d9757",
                "title": "Optimizing Long-Term Efficiency and Fairness in Ride-Hailing via Joint Order Dispatching and Driver Repositioning",
                "abstract": "The ride-hailing service offered by mobility-on-demand platforms, such as Uber and Didi Chuxing, has greatly facilitated people's traveling and commuting, and become increasingly popular in recent years. Efficiency (e.g., gross merchandise volume) has always been an important metric for such platforms. However, only focusing on the efficiency inevitably ignores the fairness of driver incomes, which could impair the sustainability of the overall ride-hailing system in the long run. To optimize the aforementioned two essential metrics, order dispatching and driver repositioning play an important role, as they impact not only the immediate, but also the future order-serving outcomes of drivers. Thus, in this paper, we aim to exploit joint order dispatching and driver repositioning to optimize both the long-term efficiency and fairness for ride-hailing platforms. To address this problem, we propose a novel multi-agent reinforcement learning framework, referred to as JDRL, to help drivers make distributed order selection and repositioning decisions. Specifically, to cope with the variable action space, JDRL segments the action space into a fixed number of action groups, and fixes the policy output dimension for order selection as the number of action groups. In terms of the fairness criterion, JDRL adopts the max-min fairness, and augments the vanilla policy gradient to an iterative training algorithm that alternates between a minimization step and a policy improvement step to maximize both the worst and the overall performance of agents. In addition, we provide the theoretical convergence guarantee of our JDRL training algorithm even under non-convex policy networks and stochastic gradient updating. Extensive experiments are conducted with three public real-world ride-hailing order datasets, including over 2 million orders in Haikou, China, over 5 million orders in Chengdu, China, and over 6 million orders in New York City, USA. Experimental results show that JDRL demonstrates a consistent advantage compared to state-of-the-art baselines in terms of both efficiency and fairness. To the best of our knowledge, this is the first work that exploits joint order dispatching and driver repositioning to optimize both the long-term efficiency and fairness in a ride-hailing system.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2145750884",
                        "name": "Jiahui Sun"
                    },
                    {
                        "authorId": "144834709",
                        "name": "Haiming Jin"
                    },
                    {
                        "authorId": "2155030384",
                        "name": "Zhaoxing Yang"
                    },
                    {
                        "authorId": "2152221975",
                        "name": "Lu Su"
                    },
                    {
                        "authorId": "1860265446",
                        "name": "Xinbing Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", commission fee [105], surge pricing rate [106], incentive threshold [107], working speed [108]) and run the allocation engine to simulate What If the parameters were different (5a), or request recommendations of fairer settings (5b)."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "d72289a1b7ce1e25afb4f1673978e7cb1004d357",
                "externalIds": {
                    "ArXiv": "2202.07349",
                    "DBLP": "journals/corr/abs-2202-07349",
                    "DOI": "10.1109/tvcg.2023.3239909",
                    "CorpusId": 246863881,
                    "PubMed": "37022033"
                },
                "corpusId": 246863881,
                "publicationVenue": {
                    "id": "5e1f6444-5d03-48c7-b202-7f47d492aeae",
                    "name": "IEEE Transactions on Visualization and Computer Graphics",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Vis Comput Graph"
                    ],
                    "issn": "1077-2626",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=2945"
                },
                "url": "https://www.semanticscholar.org/paper/d72289a1b7ce1e25afb4f1673978e7cb1004d357",
                "title": "IF-City: Intelligible Fair City Planning to Measure, Explain and Mitigate Inequality",
                "abstract": "With the increasing pervasiveness of Artificial Intelligence (AI), many visual analytics tools have been proposed to examine fairness, but they mostly focus on data scientist users. Instead, tackling fairness must be inclusive and involve domain experts with specialized tools and workflows. Thus, domain-specific visualizations are needed for algorithmic fairness. Furthermore, while much work on AI fairness has focused on predictive decisions, less has been done for fair allocation and planning, which require human expertise and iterative design to integrate myriad constraints. We propose the Intelligible Fair Allocation (IF-Alloc) Framework that leverages explanations of causal attribution (Why), contrastive (Why Not) and counterfactual reasoning (What If, How To) to aid domain experts to assess and alleviate unfairness in allocation problems. We apply the framework to fair urban planning for designing cities that provide equal access to amenities and benefits for diverse resident types. Specifically, we propose an interactive visual tool, Intelligible Fair City Planner (IF-City), to help urban planners to perceive inequality across groups, identify and attribute sources of inequality, and mitigate inequality with automatic allocation simulations and constraint-satisfying recommendations (IF-Plan). We demonstrate and evaluate the usage and usefulness of IF-City on a real neighborhood in New York City, US, with practicing urban planners from multiple countries, and discuss generalizing our findings, application, and framework to other use cases and applications of fair allocation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48036771",
                        "name": "Yan Lyu"
                    },
                    {
                        "authorId": "2115607491",
                        "name": "Hangxin Lu"
                    },
                    {
                        "authorId": "2109515767",
                        "name": "Min Kyung Lee"
                    },
                    {
                        "authorId": "91894315",
                        "name": "G. Schmitt"
                    },
                    {
                        "authorId": "2053567081",
                        "name": "Brian Y. Lim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In the context of mobility on demand, [6] proposes a deep-learning approach to operate a system that considers its equity impacts, while [7] points to similar profit for every driver and also similar rejection rates at every zone (as we do), but using a method that deals only with hundreds of users and tens of zones."
            ],
            "isInfluential": false,
            "intents": [
                "methodology"
            ],
            "citingPaper": {
                "paperId": "bda5c01a3e13719b786d1bb83cfcabb31cc6a05a",
                "externalIds": {
                    "DBLP": "conf/itsc/SchullerFA21",
                    "DOI": "10.1109/itsc48978.2021.9564910",
                    "CorpusId": 239958740
                },
                "corpusId": 239958740,
                "publicationVenue": {
                    "id": "17b6641a-6ee7-414d-8de5-997ba376f619",
                    "name": "International Conference on Intelligent Transportation Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Intell Transp Syst",
                        "ITSC"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/bda5c01a3e13719b786d1bb83cfcabb31cc6a05a",
                "title": "Towards a geographically even level of service in on-demand ridepooling",
                "abstract": "On-demand ridepooling systems usually need to decide which requests to serve, when the number of vehicles is not enough to transport them all with waiting times that are acceptable by the users. When doing so, they tend to provide uneven service rates, concentrating rejections in some zones within the operation area. In this paper, we propose two techniques that modify the objective function governing the assignment of users to vehicles, to prioritize requests originated at zones that present a relatively large rejection rate. The goal is to diminish the Gini Index of the rejections' rate, which is a well established way to measure inequality in economics. We test these techniques over an artificial small network and a real-life case in Manhattan, and we show that they are able to reduce the Gini Index of the rejection rates. Moreover, the overall rejection rate can be simultaneously reduced, thanks to utilizing the vehicles more efficiently.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2135119689",
                        "name": "Pieter Schuller"
                    },
                    {
                        "authorId": "51468468",
                        "name": "Andr\u00e9s Fielbaum"
                    },
                    {
                        "authorId": "1400049336",
                        "name": "Javier Alonso-Mora"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[51]\u2019s approaches to eliminate inequity while increasing utility might help ridehailing providers design a more equitable price discrimination algorithm.",
                "[51] studied the impact of rider-driver matching policy and redistributing income to reduce forms of inequality",
                "We examine two different categories of related work in the space of algorithmic bias: research examining bias specifically in ridehailing and taxi service pickup rates [12, 31, 32], and research detailing how to ensure the fairness of supervised learning models [24, 28, 29, 51, 69]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "839d091b48625d4d258e323eab2bcd61891cef90",
                "externalIds": {
                    "DBLP": "conf/aies/PandeyC21",
                    "MAG": "3149403622",
                    "DOI": "10.1145/3461702.3462561",
                    "CorpusId": 233182090
                },
                "corpusId": 233182090,
                "publicationVenue": {
                    "id": "ace94611-0469-4818-ae70-43bdb8082d73",
                    "name": "AAAI/ACM Conference on AI, Ethics, and Society",
                    "type": "conference",
                    "alternate_names": [
                        "AAAI/ACM conference Artificial Intelligence, Ethics, and Society",
                        "AIES",
                        "AAAI/ACM Conf AI Ethics Soc",
                        "AAAI/ACM conf Artif Intell Ethics Soc",
                        "AIES "
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/839d091b48625d4d258e323eab2bcd61891cef90",
                "title": "Disparate Impact of Artificial Intelligence Bias in Ridehailing Economy's Price Discrimination Algorithms",
                "abstract": "Ridehailing applications that collect mobility data from individuals to inform smart city planning predict each trip's fare pricing with automated algorithms that rely on artificial intelligence (AI). This type of AI algorithm, namely a price discrimination algorithm, is widely used in the industry's black box systems for dynamic individualized pricing. Lacking transparency, studying such AI systems for fairness and disparate impact has not been possible without access to data used in generating the outcomes of price discrimination algorithms. Recently, in an effort to enhance transparency in city planning, the city of Chicago regulation mandated that transportation providers publish anonymized data on ridehailing. As a result, we present the first large-scale measurement of the disparate impact of price discrimination algorithms used by ridehailing applications. The application of random effects models from the meta-analysis literature combines the city-level effects of AI bias on fare pricing from census tract attributes, aggregated from the American Community Survey. An analysis of 100 million ridehailing samples from the city of Chicago indicates a significant disparate impact in fare pricing of neighborhoods due to AI bias learned from ridehailing utilization patterns associated with demographic attributes. Neighborhoods with larger non-white populations, higher poverty levels, younger residents, and high education levels are significantly associated with higher fare prices, with combined effect sizes, measured in Cohen's d, of -0.32, -0.28, 0.69, and 0.24 for each demographic, respectively. Further, our methods hold promise for identifying and addressing the sources of disparate impact in AI algorithms learning from datasets that contain U.S. geolocations.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2070539062",
                        "name": "Akshat Pandey"
                    },
                    {
                        "authorId": "144537437",
                        "name": "Aylin Caliskan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "ur work does not rely on a user study, and unlike both Ge et al. [32] and Brown [12], our work is the first to provide an analysis on ridehailing trip fare pricing rather than frequency. Raman et al. [51] studied the impact of rider-driver matching policy and redistributing income to reduce forms of inequality in ridehailing. The analysis revealed that policies minimizing the variance of income also m",
                "ace of algorithmic bias: research examining bias specifically in ridehailing and taxi service pickup rates [12, 31, 32], and research detailing how to ensure the fairness of supervised learning models[24,28,29,51,69].WealsoexaminetwopapersontheuseofACS demographic data rather than individual demographic attributes to make inferences about an individual [33, 55]. Dillahunt et al. [27] recruited 13 low-income indiv",
                "ocation on supply, transit geography, and economic geography of the cities in which they operate when designing fare pricing algorithms. Moreover, measuring bias, simulating fairness, or Raman et al. [51]\u2019s approaches to eliminate inequity while increasing utility might help ridehailing providers design a more equitable price discrimination algorithm. To extend this analysis, obtaining the supply allo"
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "034f3497b8c840af97b23becefccee2cd38219b6",
                "externalIds": {
                    "ArXiv": "2006.04599",
                    "DBLP": "journals/corr/abs-2006-04599",
                    "MAG": "3033631579",
                    "CorpusId": 219531101
                },
                "corpusId": 219531101,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/034f3497b8c840af97b23becefccee2cd38219b6",
                "title": "Iterative Effect-Size Bias in Ridehailing: Measuring Social Bias in Dynamic Pricing of 100 Million Rides",
                "abstract": "Algorithmic bias is the systematic preferential or discriminatory treatment of a group of people by an artificial intelligence system. In this work we develop a random-effects based metric for the analysis of social bias in supervised machine learning prediction models where model outputs depend on U.S. locations. We define a methodology for using U.S. Census data to measure social bias on user attributes legally protected against discrimination, such as ethnicity, sex, and religion, also known as protected attributes. We evaluate our method on the Strategic Subject List (SSL) gun-violence prediction dataset, where we have access to both U.S. Census data as well as ground truth protected attributes for 224,235 individuals in Chicago being assessed for participation in future gun-violence incidents. Our results indicate that quantifying social bias using U.S. Census data provides a valid approach to auditing a supervised algorithmic decision-making system. Using our methodology, we then quantify the potential social biases of 100 million ridehailing samples in the city of Chicago. \nThis work is the first large-scale fairness analysis of the dynamic pricing algorithms used by ridehailing applications. An analysis of Chicago ridehailing samples in conjunction with American Community Survey data indicates possible disparate impact due to social bias based on age, house pricing, education, and ethnicity in the dynamic fare pricing models used by ridehailing applications, with effect-sizes of 0.74, 0.70, 0.34, and -0.31 (using Cohen's d) for each demographic respectively. Further, our methodology provides a principled approach to quantifying algorithmic bias on datasets where protected attributes are unavailable, given that U.S. geolocations and algorithmic decisions are provided.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2070539062",
                        "name": "Akshat Pandey"
                    },
                    {
                        "authorId": "144537437",
                        "name": "Aylin Caliskan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This leads directly to the next thrust of research: Is there a way to select actions that improve long-term fairness? Existing work [6] tries to add variance as a cost to the optimization objective in the ridesharing context."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "fbdf8bf4427f257c086110288991ee0dbca63389",
                "externalIds": {
                    "DBLP": "conf/atal/Kumar23a",
                    "DOI": "10.5555/3545946.3599131",
                    "CorpusId": 258845573
                },
                "corpusId": 258845573,
                "publicationVenue": {
                    "id": "6c3a9833-5fac-49d3-b7e7-64910bd40b4e",
                    "name": "Adaptive Agents and Multi-Agent Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Adapt Agent Multi-agent Syst",
                        "International Joint Conference on Autonomous Agents & Multiagent Systems",
                        "Adapt Agent Multi-agents Syst",
                        "AAMAS",
                        "Adaptive Agents and Multi-Agents Systems",
                        "Int Jt Conf Auton Agent  Multiagent Syst"
                    ],
                    "url": "http://www.ifaamas.org/"
                },
                "url": "https://www.semanticscholar.org/paper/fbdf8bf4427f257c086110288991ee0dbca63389",
                "title": "Algorithmic Fairness in Temporal Resource Allocation",
                "abstract": "There has been a significant body of research on improving social welfare in resource allocation, but much of it has focused on single-shot allocation scenarios, where a given pool of resources must be divided equitably. In contrast, my research aims to address the unique challenges posed by temporal resource allocation problems that involve many repeated allocations, with both resources and beneficiaries able to re-enter the market at different points in time. Automated algorithms are often employed to guide resource allocation in these scenarios by estimating and comparing utilities of different allocations, making algorithmic fairness a concern as well. In this work, I aim to improve long-term social welfare in addition to maximizing the utility of such systems through the lens of pre-, in-, and post-processing fairness. I propose a simple incentive-based approach for post-processing fairness with black-box value func-tions, outperforming existing baselines in a ridesharing application. I discuss two other research thrusts using fairness-aware dataset balancing for pre-processing fairness and learning non-myopic fairness policies for in-processing fairness. Combining all of these approaches, my goal is to present a holistic view of improving social welfare in temporal resource allocation through the lens of algorithmic fairness",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2118070511",
                        "name": "Ashwin Kumar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "systems, formulating the TNDP as a Deep Reinforcement Learning (Deep RL) problem can inspire new solutions that enable nonmyopic long-term decisions, as noted in recent work [5, 17]."
            ],
            "isInfluential": false,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "29a7138a483e7c3906de5689c90fdf6c8aa4f147",
                "externalIds": {
                    "DBLP": "conf/atal/MichailidisGS23",
                    "DOI": "10.5555/3545946.3598992",
                    "CorpusId": 258845836
                },
                "corpusId": 258845836,
                "publicationVenue": {
                    "id": "6c3a9833-5fac-49d3-b7e7-64910bd40b4e",
                    "name": "Adaptive Agents and Multi-Agent Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Adapt Agent Multi-agent Syst",
                        "International Joint Conference on Autonomous Agents & Multiagent Systems",
                        "Adapt Agent Multi-agents Syst",
                        "AAMAS",
                        "Adaptive Agents and Multi-Agents Systems",
                        "Int Jt Conf Auton Agent  Multiagent Syst"
                    ],
                    "url": "http://www.ifaamas.org/"
                },
                "url": "https://www.semanticscholar.org/paper/29a7138a483e7c3906de5689c90fdf6c8aa4f147",
                "title": "Balancing Fairness and Efficiency in Transport Network Design through Reinforcement Learning",
                "abstract": "Abstract",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2070207887",
                        "name": "Dimitrios Michailidis"
                    },
                    {
                        "authorId": "1682828",
                        "name": "S. Ghebreab"
                    },
                    {
                        "authorId": "144438218",
                        "name": "F. Santos"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[19], which looks at disparate treatment of passengers and income disparity amongst drivers.",
                "[19] as a baseline for fairness, using their passenger-side fairness implementation, which we call FairNN.",
                "Recent work [19] aims to maximize the minimum service rate by including variance in service rates across different zones in the"
            ],
            "isInfluential": true,
            "intents": [
                "background"
            ],
            "citingPaper": {
                "paperId": "bc627bcef23336e32af91bb00a7a1429900a2749",
                "externalIds": {
                    "DBLP": "conf/ijcai/KumarV022",
                    "CorpusId": 251180588
                },
                "corpusId": 251180588,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/bc627bcef23336e32af91bb00a7a1429900a2749",
                "title": "Improving Zonal Fairness While Maintaining Efficiency in Rideshare Matching",
                "abstract": "Order dispatching algorithms, which match passenger requests with vehicles (agents) in ridesharing systems, are able to achieve high service rates (percentage of requests served) using deep reinforcement learning techniques to estimate the relative values of the different combinations of passenger-vehicle matches. While the goal of such algorithms is to maximize the service rate, this may lead to unintended fairness issues (e.g., high disparity between the service rates of geographic zones in a city). To remedy this limitation, researchers have recently proposed deep reinforcement learning based techniques that incorporates fairness components in the value function approximated. However, this approach suffers from the need to retrain should one wish to tune the degree of fairness or optimize for a different fairness function, which can be computationally expensive. Towards this end, we propose a simpler online approach that uses state-of-art deep reinforcement learning techniques and augments their value functions with fairness components during the matching optimization step. As no additional training is needed, this approach can be adapted to use any existing value function approximator and benefits from improved flexibility in evaluating different fairness objectives efficiently. In this paper, we describe several fairness functions that can be used by this approach and evaluate them against existing state-of-the-art deep RL based fairness techniques on standard ridesharing benchmarks. Our experiments show that our fairness functions outperform existing fairness techniques (i.e., it finds matching solutions that result in higher service rates and lower service rate disparity across zones), demonstrating the practical promise of this approach.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118070729",
                        "name": "Ashwin Kumar"
                    },
                    {
                        "authorId": "1699600",
                        "name": "Yevgeniy Vorobeychik"
                    },
                    {
                        "authorId": "1805457",
                        "name": "W. Yeoh"
                    }
                ]
            }
        }
    ]
}