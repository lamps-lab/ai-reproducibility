{
    "offset": 0,
    "data": [
        {
            "contexts": [
                "Many great efforts have been made in this field, including a few specific image datasets (Lake et al., 2019; Bertinetto et al., 2019; Triantafillou et al., 2019; Wah et al., 2011) (such as Omniglot, CIFAR-FS, CUB, and mini-ImageNet) and various approaches."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0aefa69e41012dffa7ddbac1cd1f1547276a7076",
                "externalIds": {
                    "DOI": "10.1016/j.engappai.2023.107078",
                    "CorpusId": 261592562
                },
                "corpusId": 261592562,
                "publicationVenue": {
                    "id": "1a24ea21-4c37-41d8-9e76-ab802d4afb3e",
                    "name": "Engineering applications of artificial intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "Eng appl artif intell",
                        "Eng Appl Artif Intell",
                        "Engineering Applications of Artificial Intelligence"
                    ],
                    "issn": "0952-1976",
                    "url": "http://www.sciencedirect.com/science/journal/09521976"
                },
                "url": "https://www.semanticscholar.org/paper/0aefa69e41012dffa7ddbac1cd1f1547276a7076",
                "title": "Few-shot learning for image-based bridge damage detection",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2256635894",
                        "name": "Yan Gao"
                    },
                    {
                        "authorId": "2238395084",
                        "name": "Haijiang Li"
                    },
                    {
                        "authorId": "2238254380",
                        "name": "Weiqi Fu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "59e35e1995f711edbf1e6300c74f29a9f82aedf7",
                "externalIds": {
                    "DBLP": "journals/tcsv/XuYYTCLL23",
                    "DOI": "10.1109/TCSVT.2023.3263593",
                    "CorpusId": 257882632
                },
                "corpusId": 257882632,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/59e35e1995f711edbf1e6300c74f29a9f82aedf7",
                "title": "Self-Paced Hard Task-Example Mining for Few-Shot Classification",
                "abstract": "In recent years, researchers have commonly employed assistant tasks to enhance the training phase of the few-shot classification models. Several methods have been proposed to exploit and optimize the training tasks, such as Curriculum Learning (CL) and Hard Example Mining (HEM). However, most of the existing strategies can not elaborately leverage the training tasks and share some common drawbacks, including 1) the ignorance of the target tasks\u2019 properties, and 2) the neglect of sample relationships. In this work, we propose a Self-Paced Hard tAsk-Example Mining (SP-HAEM) method to solve these problems. Specifically, the SP-HAEM automatically chooses hard examples via the similarity between training and target tasks to optimize the support set. To represent the property of target tasks, SP-HAEM obtains a representation of the dataset, called \u201cmeta-task\u201d. No need to apply an additional model to measure difficulty and choose hard examples like other HEM methods, SP-HAEM selects the tasks with large optimal transport distance to the meta-task as hard tasks. Thus, training with such hard tasks can not only enhances the generalization ability of the model but also eliminate the negative effect of redundancy tasks. To evaluate the effectiveness of SP-HAEM, we conduct extensive experiments on a variety of datasets, including MiniImageNet, TieredImageNet, and FC100. The results of the experiments show that SP-HAEM can achieve higher accuracy compared with the typical few-shot classification models, e.g., Prototypical Network, MAML, FEAT, and MTL.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2213692261",
                        "name": "Renjie Xu"
                    },
                    {
                        "authorId": "48520199",
                        "name": "Xinghao Yang"
                    },
                    {
                        "authorId": "2193486131",
                        "name": "Xingxing Yao"
                    },
                    {
                        "authorId": "1701119",
                        "name": "Dapeng Tao"
                    },
                    {
                        "authorId": "151482853",
                        "name": "Weijia Cao"
                    },
                    {
                        "authorId": "2152840019",
                        "name": "Xiaoping Lu"
                    },
                    {
                        "authorId": "2140409319",
                        "name": "Weifeng Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "shot learning methods [37], [38] use a meta-learning strategy, which extracts transferable knowledge from a set of tasks"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a79baa31d757e8a30cd4931ff776f2df87115939",
                "externalIds": {
                    "DBLP": "journals/tcsv/WangYQWWSQW23",
                    "DOI": "10.1109/TCSVT.2023.3262670",
                    "CorpusId": 257824610
                },
                "corpusId": 257824610,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a79baa31d757e8a30cd4931ff776f2df87115939",
                "title": "Task-Aware Dual-Representation Network for Few-Shot Action Recognition",
                "abstract": "Few-shot action recognition has attracted increasing attention in recent years, but it remains challenging due to the intrinsic difficulty in learning transferable knowledge to generalize to novel classes by using a few labeled samples. Although some successful progress has been made, most few-shot action recognition methods commonly focus on the global characteristics of samples while ignoring the local characteristics of samples, which results in the weak generalization ability of the model. In this paper, we propose a task-aware dual-representation network (TADRNet) for few-shot action recognition, which learns how to adapt video representations to novel tasks in a meta-learning manner. It mainly includes a global relational graph subnetwork (GRG) and a fine-grained local representation subnetwork (FLR). Our method simultaneously considers both global and local characteristics of samples for few-shot action recognition. From a global perspective, we propose GRG to explore the relations across support-query sample pairs by using the relational graph neural network. To facilitate the few-shot visual learning, we propose a novel hybrid semantic attention module (HSA) for enhancing the discriminability of support and query features. From a local perspective, we utilize FLR to fully exploit the local characteristics of samples, which can improve the classification results obtained by GRG and thus guarantee high classification accuracy. Extensive experiments on four challenging benchmarks show that the proposed TADRNet significantly outperforms a variety of state-of-the-art few-shot action recognition methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2144549969",
                        "name": "Xiao Wang"
                    },
                    {
                        "authorId": "2147205193",
                        "name": "Weirong Ye"
                    },
                    {
                        "authorId": "2539841",
                        "name": "Zhongang Qi"
                    },
                    {
                        "authorId": "2152582973",
                        "name": "Guangge Wang"
                    },
                    {
                        "authorId": "2158877245",
                        "name": "Jianping Wu"
                    },
                    {
                        "authorId": "1387190008",
                        "name": "Ying Shan"
                    },
                    {
                        "authorId": "3284850",
                        "name": "Xiaohu Qie"
                    },
                    {
                        "authorId": "2163741582",
                        "name": "Hanzi Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e63a0ebcbc26fa958e5897d916d10051607ce7fc",
                "externalIds": {
                    "ArXiv": "2310.00377",
                    "CorpusId": 263334304
                },
                "corpusId": 263334304,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e63a0ebcbc26fa958e5897d916d10051607ce7fc",
                "title": "Mitigating the Effect of Incidental Correlations on Part-based Learning",
                "abstract": "Intelligent systems possess a crucial characteristic of breaking complicated problems into smaller reusable components or parts and adjusting to new tasks using these part representations. However, current part-learners encounter difficulties in dealing with incidental correlations resulting from the limited observations of objects that may appear only in specific arrangements or with specific backgrounds. These incidental correlations may have a detrimental impact on the generalization and interpretability of learned part representations. This study asserts that part-based representations could be more interpretable and generalize better with limited data, employing two innovative regularization methods. The first regularization separates foreground and background information's generative process via a unique mixture-of-parts formulation. Structural constraints are imposed on the parts using a weakly-supervised loss, guaranteeing that the mixture-of-parts for foreground and background entails soft, object-agnostic masks. The second regularization assumes the form of a distillation loss, ensuring the invariance of the learned parts to the incidental background correlations. Furthermore, we incorporate sparse and orthogonal constraints to facilitate learning high-quality part representations. By reducing the impact of incidental background correlations on the learned parts, we exhibit state-of-the-art (SoTA) performance on few-shot learning tasks on benchmark datasets, including MiniImagenet, TieredImageNet, and FC100. We also demonstrate that the part-based representations acquired through our approach generalize better than existing techniques, even under domain shifts of the background and common data corruption on the ImageNet-9 dataset. The implementation is available on GitHub: https://github.com/GauravBh1010tt/DPViT.git",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2249763316",
                        "name": "Gaurav Bhatt"
                    },
                    {
                        "authorId": "2249784140",
                        "name": "Deepayan Das"
                    },
                    {
                        "authorId": "2249763332",
                        "name": "Leonid Sigal"
                    },
                    {
                        "authorId": "2227135768",
                        "name": "Vineeth N. Balasubramanian"
                    }
                ]
            }
        },
        {
            "contexts": [
                "One approach is to use meta-learning to learn how to learn new tasks from few examples [34, 43, 25, 49]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2c14f96e12da66189d1956670b6e663fa437cfe6",
                "externalIds": {
                    "ArXiv": "2309.14062",
                    "DBLP": "journals/corr/abs-2309-14062",
                    "DOI": "10.48550/arXiv.2309.14062",
                    "CorpusId": 262464670
                },
                "corpusId": 262464670,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2c14f96e12da66189d1956670b6e663fa437cfe6",
                "title": "FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning",
                "abstract": "Exemplar-free class-incremental learning (CIL) poses several challenges since it prohibits the rehearsal of data from previous tasks and thus suffers from catastrophic forgetting. Recent approaches to incrementally learning the classifier by freezing the feature extractor after the first task have gained much attention. In this paper, we explore prototypical networks for CIL, which generate new class prototypes using the frozen feature extractor and classify the features based on the Euclidean distance to the prototypes. In an analysis of the feature distributions of classes, we show that classification based on Euclidean metrics is successful for jointly trained features. However, when learning from non-stationary data, we observe that the Euclidean metric is suboptimal and that feature distributions are heterogeneous. To address this challenge, we revisit the anisotropic Mahalanobis distance for CIL. In addition, we empirically show that modeling the feature covariance relations is better than previous attempts at sampling features from normal distributions and training a linear classifier. Unlike existing methods, our approach generalizes to both many- and few-shot CIL settings, as well as to domain-incremental settings. Interestingly, without updating the backbone network, our method obtains state-of-the-art results on several standard continual learning benchmarks. Code is available at https://github.com/dipamgoswami/FeCAM.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2141570174",
                        "name": "Dipam Goswami"
                    },
                    {
                        "authorId": "2116382754",
                        "name": "Yuyang Liu"
                    },
                    {
                        "authorId": "2470703",
                        "name": "Bartlomiej Twardowski"
                    },
                    {
                        "authorId": "2820687",
                        "name": "Joost van de Weijer"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "de99baba2e6ec1c1e6df302686fb5c900e9959e7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-09276",
                    "ArXiv": "2309.09276",
                    "DOI": "10.48550/arXiv.2309.09276",
                    "CorpusId": 261891373
                },
                "corpusId": 261891373,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/de99baba2e6ec1c1e6df302686fb5c900e9959e7",
                "title": "MVP: Meta Visual Prompt Tuning for Few-Shot Remote Sensing Image Scene Classification",
                "abstract": "Vision Transformer (ViT) models have recently emerged as powerful and versatile models for various visual tasks. Recently, a work called PMF has achieved promising results in few-shot image classification by utilizing pre-trained vision transformer models. However, PMF employs full fine-tuning for learning the downstream tasks, leading to significant overfitting and storage issues, especially in the remote sensing domain. In order to tackle these issues, we turn to the recently proposed parameter-efficient tuning methods, such as VPT, which updates only the newly added prompt parameters while keeping the pre-trained backbone frozen. Inspired by VPT, we propose the Meta Visual Prompt Tuning (MVP) method. Specifically, we integrate the VPT method into the meta-learning framework and tailor it to the remote sensing domain, resulting in an efficient framework for Few-Shot Remote Sensing Scene Classification (FS-RSSC). Furthermore, we introduce a novel data augmentation strategy based on patch embedding recombination to enhance the representation and diversity of scenes for classification purposes. Experiment results on the FS-RSSC benchmark demonstrate the superior performance of the proposed MVP over existing methods in various settings, such as various-way-various-shot, various-way-one-shot, and cross-domain adaptation.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2146280437",
                        "name": "Junjie Zhu"
                    },
                    {
                        "authorId": "2241488738",
                        "name": "Yiying Li"
                    },
                    {
                        "authorId": "2239944099",
                        "name": "Chunping Qiu"
                    },
                    {
                        "authorId": "2239882376",
                        "name": "Ke Yang"
                    },
                    {
                        "authorId": "2239891839",
                        "name": "Naiyang Guan"
                    },
                    {
                        "authorId": "92450135",
                        "name": "Xiaodong Yi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We investigate the effect of label noise on two representative datasets, CifarFS [2] and Omniglot [10], in a (5, 5)-FSL setting with a query set of 15 samples per class."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2460923337bc5cb203de60db994b17bbbac67529",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-06046",
                    "ArXiv": "2309.06046",
                    "DOI": "10.48550/arXiv.2309.06046",
                    "CorpusId": 261696879
                },
                "corpusId": 261696879,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2460923337bc5cb203de60db994b17bbbac67529",
                "title": "BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise",
                "abstract": "The negative impact of label noise is well studied in classical supervised learning yet remains an open research question in meta-learning. Meta-learners aim to adapt to unseen learning tasks by learning a good initial model in meta-training and consecutively fine-tuning it according to new tasks during meta-testing. In this paper, we present the first extensive analysis of the impact of varying levels of label noise on the performance of state-of-the-art meta-learners, specifically gradient-based $N$-way $K$-shot learners. We show that the accuracy of Reptile, iMAML, and foMAML drops by up to 42% on the Omniglot and CifarFS datasets when meta-training is affected by label noise. To strengthen the resilience against label noise, we propose two sampling techniques, namely manifold (Man) and batch manifold (BatMan), which transform the noisy supervised learners into semi-supervised ones to increase the utility of noisy labels. We first construct manifold samples of $N$-way $2$-contrastive-shot tasks through augmentation, learning the embedding via a contrastive loss in meta-training, and then perform classification through zeroing on the embedding in meta-testing. We show that our approach can effectively mitigate the impact of meta-training label noise. Even with 60% wrong labels \\batman and \\man can limit the meta-testing accuracy drop to ${2.5}$, ${9.4}$, ${1.1}$ percent points, respectively, with existing meta-learners across the Omniglot, CifarFS, and MiniImagenet datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2105726156",
                        "name": "Jeroen Galjaard"
                    },
                    {
                        "authorId": "2010862",
                        "name": "R. Birke"
                    },
                    {
                        "authorId": "2239170684",
                        "name": "Juan Perez"
                    },
                    {
                        "authorId": "2239159327",
                        "name": "Lydia Y. Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "29c91f27b655204100d52f24e137d494a9bd0315",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2309-03360",
                    "ArXiv": "2309.03360",
                    "DOI": "10.48550/arXiv.2309.03360",
                    "CorpusId": 261582851
                },
                "corpusId": 261582851,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/29c91f27b655204100d52f24e137d494a9bd0315",
                "title": "ViewMix: Augmentation for Robust Representation in Self-Supervised Learning",
                "abstract": "Joint Embedding Architecture-based self-supervised learning methods have attributed the composition of data augmentations as a crucial factor for their strong representation learning capabilities. While regional dropout strategies have proven to guide models to focus on lesser indicative parts of the objects in supervised methods, it hasn't been adopted by self-supervised methods for generating positive pairs. This is because the regional dropout methods are not suitable for the input sampling process of the self-supervised methodology. Whereas dropping informative pixels from the positive pairs can result in inefficient training, replacing patches of a specific object with a different one can steer the model from maximizing the agreement between different positive pairs. Moreover, joint embedding representation learning methods have not made robustness their primary training outcome. To this end, we propose the ViewMix augmentation policy, specially designed for self-supervised learning, upon generating different views of the same image, patches are cut and pasted from one view to another. By leveraging the different views created by this augmentation strategy, multiple joint embedding-based self-supervised methodologies obtained better localization capability and consistently outperformed their corresponding baseline methods. It is also demonstrated that incorporating ViewMix augmentation policy promotes robustness of the representations in the state-of-the-art methods. Furthermore, our experimentation and analysis of compute times suggest that ViewMix augmentation doesn't introduce any additional overhead compared to other counterparts.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2107200061",
                        "name": "A. Das"
                    },
                    {
                        "authorId": "2238306372",
                        "name": "Xin Zhong"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", miniImageNet [7], CIFAR-FS [36] and MURA [37], are conducted.",
                "CIFAR-FS is also a well-known few-shot classi\ufb01cation database [36].",
                "To assess the performance of the proposed model by comparison with other methods in terms of inference accuracy, validations on three databases, i.e., miniImageNet [7], CIFAR-FS [36] and MURA [37], are conducted.",
                "It should be noted that on the miniImageNet database, the best performance is achieved with L \u00bc 2 , while on CIFAR-FS, it is better when L is 4.",
                "Speci\ufb01cally, MURA is a medical imaging database in e-healthcare and another two databases are more generic. miniImageNet and CIFAR-FS contain a wide variety of images with more complex backgrounds, which can help us more effectively examine the generalization ability of our proposed model under different e-healthcare scenarios.",
                "CIFAR-FS is also a well-known few-shot classification database [36]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "755dcec40ef447e2ab5f1aa1c958caf0b9f7f46a",
                "externalIds": {
                    "DBLP": "journals/tnse/RenYZFN23",
                    "DOI": "10.1109/TNSE.2022.3227317",
                    "CorpusId": 254428657
                },
                "corpusId": 254428657,
                "publicationVenue": {
                    "id": "83b61ff8-462d-4e1d-b43b-5d96fcc87766",
                    "name": "IEEE Transactions on Network Science and Engineering",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Netw Sci Eng"
                    ],
                    "issn": "2327-4697",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6488902"
                },
                "url": "https://www.semanticscholar.org/paper/755dcec40ef447e2ab5f1aa1c958caf0b9f7f46a",
                "title": "Blockchain-Powered Tensor Meta-Learning-Driven Intelligent Healthcare System With IoT Assistance",
                "abstract": "The rapid development and gradual integration of artificial intelligence and the Internet of Things have brought unprecedented opportunities for radically changing healthcare and treatments. However, the burgeoning in intelligent healthcare systems is severely bounded by data privacy and the security of AI models. Meanwhile, the limited local data forces conventional AI models to face the predicament in achieving personalized healthcare. Hence, we propose a blockchain-powered tensor meta-learning-driven intelligent healthcare system with IoT assistance. IoT devices as light nodes upload the local shareable data to the edge server(full node) for model training and perform the local private data by non-tampered model downloaded via smart contract. The system can not only use blockchain technology to ensure the strong consistency of the healthcare model but also protect private data from being leaked. Especially, we develop a tensor meta-learning model named tensor-prototype graph network to achieve efficient modeling of heterogeneous healthcare data. Building on the tensors and graph network, the model is conducive to capturing the data distribution when there are few labeled data. To evaluate our proposed approach, we have conducted experiments on three classic databases. The results demonstrate that our approach is capable of effectively promoting the performance of intelligent healthcare.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2194626384",
                        "name": "Bocheng Ren"
                    },
                    {
                        "authorId": "1690341",
                        "name": "L. Yang"
                    },
                    {
                        "authorId": "2108076070",
                        "name": "Qingchen Zhang"
                    },
                    {
                        "authorId": "2144086140",
                        "name": "Jun Feng"
                    },
                    {
                        "authorId": "2061056955",
                        "name": "Xin Nie"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "33fee8b6bea7ebb8ef2e3eff63e644aa619f23a3",
                "externalIds": {
                    "DBLP": "journals/ivc/CaoYYL23",
                    "DOI": "10.1016/j.imavis.2023.104757",
                    "CorpusId": 259715173
                },
                "corpusId": 259715173,
                "publicationVenue": {
                    "id": "6cc36eeb-d056-42c4-a306-7bcb239cc442",
                    "name": "Image and Vision Computing",
                    "type": "journal",
                    "alternate_names": [
                        "Image Vis Comput"
                    ],
                    "issn": "0262-8856",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525443/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/02628856",
                        "https://www.journals.elsevier.com/image-and-vision-computing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/33fee8b6bea7ebb8ef2e3eff63e644aa619f23a3",
                "title": "WPE: Weighted prototype estimation for few-shot learning",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2152964263",
                        "name": "Jiangzhong Cao"
                    },
                    {
                        "authorId": "2153932706",
                        "name": "Zijie Yao"
                    },
                    {
                        "authorId": "2222416932",
                        "name": "Lianggeng Yu"
                    },
                    {
                        "authorId": "2370219",
                        "name": "B. Ling"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5b3780939c795c5d6413ac82210246f5d7ec915f",
                "externalIds": {
                    "DBLP": "journals/ijmir/YuanLYL23",
                    "DOI": "10.1007/s13735-023-00281-w",
                    "CorpusId": 261432509
                },
                "corpusId": 261432509,
                "publicationVenue": {
                    "id": "d9c19003-0fdf-4501-b3cd-cf35b240bc6a",
                    "name": "International Journal of Multimedia Information Retrieval",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Multimedia Inf Retr"
                    ],
                    "issn": "2192-662X",
                    "url": "http://www.springer.com/computer/journal/13735",
                    "alternate_urls": [
                        "https://link.springer.com/journal/13735"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5b3780939c795c5d6413ac82210246f5d7ec915f",
                "title": "Decision fusion for few-shot image classification",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2218255198",
                        "name": "Tianhao Yuan"
                    },
                    {
                        "authorId": "1732108",
                        "name": "Weifeng Liu"
                    },
                    {
                        "authorId": "2236922112",
                        "name": "Fei Yan"
                    },
                    {
                        "authorId": "2155992419",
                        "name": "Baodi Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6977d8cc9d634b0ae836421351d82891b56db779",
                "externalIds": {
                    "DBLP": "journals/tcsv/ZhouWZZ23",
                    "DOI": "10.1109/TCSVT.2023.3248798",
                    "CorpusId": 257192100
                },
                "corpusId": 257192100,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/6977d8cc9d634b0ae836421351d82891b56db779",
                "title": "Learning to Class-Adaptively Manipulate Embeddings for Few-Shot Learning",
                "abstract": "In few-shot learning (FSL), meta-learning approach (MLA) mainly focuses on learning transferable knowledge from plenty of auxiliary FSL tasks to facilitate fast generalization to a new task. For a given FSL task, due to the inter-class distribution discrepancy, each class necessitates a specific embedding (i.e., a mapping function) to map samples into an ideal semantic space where samples from this class can be well separately from other classes. Moreover, these embeddings may vary with different tasks. Hence, one crucial knowledge for MLA is how to separately construct optimal embeddings for each class based on a few training samples given in a FSL task. However, most existing MLAs rarely consider this and thus show limited generalization capacity. To mitigate this problem, instead of directly construct class-adaptive embeddings, we present a new MLA that aims at learning to class-adaptively manipulate the features of samples for accurate classification in a new FSL task. In a specific, for a new FSL task, the proposed MLA first learns to generate some class-specific weights based on training samples via exploiting the inter-class distribution discrepancy between this class and the others. Then, the generated weights are utilized to compute the Hadamard product of features produced by a task-agnostic embedding module. By doing this, the proposed MLA can dynamically enhance or depress some specific semantic dimensions of sample features depending on the distribution of each class for accurate classification, and thus equals to constructing class-adaptive embeddings for each class but in a simpler way which can appropriately avoid over-fitting and is scalable to cases with extensive classes. To show its efficacy, we test the proposed MLA on four benchmark FSL datasets under various settings and report superior performance over existing state-of-the-arts.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2106043218",
                        "name": "Fei Zhou"
                    },
                    {
                        "authorId": "145673165",
                        "name": "Wei Wei"
                    },
                    {
                        "authorId": "50081808",
                        "name": "Lei Zhang"
                    },
                    {
                        "authorId": "2047640322",
                        "name": "Yanning Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We adhere to the widely used splitting protocol proposed in (Bertinetto et al. 2019; Oreshkin, L\u00f3pez, and Lacoste 2018; Ravi and Larochelle 2017) to ensure fair comparisons with baselines.",
                "Few-shot Learning Setting: We employ four prominent few-shot image classification benchmarks for our evaluations: CIFAR-FS (Bertinetto et al. 2019), FC100 (Oreshkin, L\u00f3pez, and Lacoste 2018), miniImageNet (Vinyals et al.",
                "32% in Top-1 accuracy on the CIFAR-FS (Bertinetto et al. 2019) dataset compared to the BEiT-3 baseline.",
                "Few-shot Learning Setting: We employ four prominent few-shot image classification benchmarks for our evaluations: CIFAR-FS (Bertinetto et al. 2019), FC100 (Oreshkin, Lo\u0301pez, and Lacoste 2018), miniImageNet (Vinyals et al. 2016), and tieredImageNet (Ren et al. 2018).",
                "We utilized the BEiT-3 backbone in all experiments and reported our findings on the CIFAR-FS dataset.",
                "Specifically, we observe a boost of up to 3.32% in Top-1 accuracy on the CIFAR-FS (Bertinetto et al. 2019) dataset compared to the BEiT-3 baseline."
            ],
            "intents": [
                "methodology",
                "result"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "c4ead49c06b164adf9229f90ad098f1e44885c38",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-14893",
                    "ArXiv": "2308.14893",
                    "DOI": "10.48550/arXiv.2308.14893",
                    "CorpusId": 261277165
                },
                "corpusId": 261277165,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c4ead49c06b164adf9229f90ad098f1e44885c38",
                "title": "When hard negative sampling meets supervised contrastive learning",
                "abstract": "State-of-the-art image models predominantly follow a two-stage strategy: pre-training on large datasets and fine-tuning with cross-entropy loss. Many studies have shown that using cross-entropy can result in sub-optimal generalisation and stability. While the supervised contrastive loss addresses some limitations of cross-entropy loss by focusing on intra-class similarities and inter-class differences, it neglects the importance of hard negative mining. We propose that models will benefit from performance improvement by weighting negative samples based on their dissimilarity to positive counterparts. In this paper, we introduce a new supervised contrastive learning objective, SCHaNe, which incorporates hard negative sampling during the fine-tuning phase. Without requiring specialized architectures, additional data, or extra computational resources, experimental results indicate that SCHaNe outperforms the strong baseline BEiT-3 in Top-1 accuracy across various benchmarks, with significant gains of up to $3.32\\%$ in few-shot learning settings and $3.41\\%$ in full dataset fine-tuning. Importantly, our proposed objective sets a new state-of-the-art for base models on ImageNet-1k, achieving an 86.14\\% accuracy. Furthermore, we demonstrate that the proposed objective yields better embeddings and explains the improved effectiveness observed in our experiments.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "114180634",
                        "name": "Zijun Long"
                    },
                    {
                        "authorId": "2154470235",
                        "name": "George Killick"
                    },
                    {
                        "authorId": "1740893",
                        "name": "R. McCreadie"
                    },
                    {
                        "authorId": "49375040",
                        "name": "Gerardo Aragon Camarasa"
                    },
                    {
                        "authorId": "3451645",
                        "name": "Zaiqiao Meng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Method Omniglot miniImageNet CIFAR-FS (5,1) (5,5) (20,1) (5,1) (5,5) (20,1) (5,1) (5,5) (20,1)\nTrain from scratch 50.29 72.82 26.20 24.20 38.84 16.29 31.12 44.89 20.32",
                "We evaluate BMSSL on three standard few-shot benchmarks of unsupervised meta-learning: Omniglot [30], miniImageNet [52], and CIFAR-FS [6]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "9cf6b6762ddc200d462977779412a354e8abc657",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-14267",
                    "ArXiv": "2308.14267",
                    "DOI": "10.48550/arXiv.2308.14267",
                    "CorpusId": 261242546
                },
                "corpusId": 261242546,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/9cf6b6762ddc200d462977779412a354e8abc657",
                "title": "Unleash Model Potential: Bootstrapped Meta Self-supervised Learning",
                "abstract": "The long-term goal of machine learning is to learn general visual representations from a small amount of data without supervision, mimicking three advantages of human cognition: i) no need for labels, ii) robustness to data scarcity, and iii) learning from experience. Self-supervised learning and meta-learning are two promising techniques to achieve this goal, but they both only partially capture the advantages and fail to address all the problems. Self-supervised learning struggles to overcome the drawbacks of data scarcity, while ignoring prior knowledge that can facilitate learning and generalization. Meta-learning relies on supervised information and suffers from a bottleneck of insufficient learning. To address these issues, we propose a novel Bootstrapped Meta Self-Supervised Learning (BMSSL) framework that aims to simulate the human learning process. We first analyze the close relationship between meta-learning and self-supervised learning. Based on this insight, we reconstruct tasks to leverage the strengths of both paradigms, achieving advantages i and ii. Moreover, we employ a bi-level optimization framework that alternates between solving specific tasks with a learned ability (first level) and improving this ability (second level), attaining advantage iii. To fully harness its power, we introduce a bootstrapped target based on meta-gradient to make the model its own teacher. We validate the effectiveness of our approach with comprehensive theoretical and empirical study.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2193098014",
                        "name": "Jingyao Wang"
                    },
                    {
                        "authorId": "2218933033",
                        "name": "Zeen Song"
                    },
                    {
                        "authorId": "2059455684",
                        "name": "Wenwen Qiang"
                    },
                    {
                        "authorId": "2153619515",
                        "name": "Changwen Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Nevertheless, having a closed-form expression for Ab enables us to exploit a meta-learning scheme like [57] to formulate a zero-shot prediction loss to learn them jointly with the rest of the parameters."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5cae3b36651b8f1be7a9f1961980b7f2dd2c9727",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-09228",
                    "ArXiv": "2308.09228",
                    "DOI": "10.48550/arXiv.2308.09228",
                    "CorpusId": 261030945
                },
                "corpusId": 261030945,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5cae3b36651b8f1be7a9f1961980b7f2dd2c9727",
                "title": "Generalized Sum Pooling for Metric Learning",
                "abstract": "A common architectural choice for deep metric learning is a convolutional neural network followed by global average pooling (GAP). Albeit simple, GAP is a highly effective way to aggregate information. One possible explanation for the effectiveness of GAP is considering each feature vector as representing a different semantic entity and GAP as a convex combination of them. Following this perspective, we generalize GAP and propose a learnable generalized sum pooling method (GSP). GSP improves GAP with two distinct abilities: i) the ability to choose a subset of semantic entities, effectively learning to ignore nuisance information, and ii) learning the weights corresponding to the importance of each entity. Formally, we propose an entropy-smoothed optimal transport problem and show that it is a strict generalization of GAP, i.e., a specific realization of the problem gives back GAP. We show that this optimization problem enjoys analytical gradients enabling us to use it as a direct learnable replacement for GAP. We further propose a zero-shot loss to ease the learning of GSP. We show the effectiveness of our method with extensive evaluations on 4 popular metric learning benchmarks. Code is available at: GSP-DML Framework",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2232607751",
                        "name": "\u2020. YetiZ.G\u00fcrb\u00fcz"
                    },
                    {
                        "authorId": "3114252",
                        "name": "Ozan Sener"
                    },
                    {
                        "authorId": "1612131339",
                        "name": "A. Aydin"
                    },
                    {
                        "authorId": "2232608267",
                        "name": "Alatan RSiM"
                    },
                    {
                        "authorId": "2101624135",
                        "name": "Tu Berlin"
                    },
                    {
                        "authorId": "112853320",
                        "name": "Intel Labs"
                    },
                    {
                        "authorId": "2232607579",
                        "name": "Ogam Metu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d5536f4090cedfe2d89d1b39ee39f923815dff00",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-07536",
                    "ArXiv": "2308.07536",
                    "DOI": "10.48550/arXiv.2308.07536",
                    "CorpusId": 260899906
                },
                "corpusId": 260899906,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d5536f4090cedfe2d89d1b39ee39f923815dff00",
                "title": "Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem",
                "abstract": "In this paper, we study a class of stochastic bilevel optimization problems, also known as stochastic simple bilevel optimization, where we minimize a smooth stochastic objective function over the optimal solution set of another stochastic convex optimization problem. We introduce novel stochastic bilevel optimization methods that locally approximate the solution set of the lower-level problem via a stochastic cutting plane, and then run a conditional gradient update with variance reduction techniques to control the error induced by using stochastic gradients. For the case that the upper-level function is convex, our method requires $\\tilde{\\mathcal{O}}(\\max\\{1/\\epsilon_f^{2},1/\\epsilon_g^{2}\\}) $ stochastic oracle queries to obtain a solution that is $\\epsilon_f$-optimal for the upper-level and $\\epsilon_g$-optimal for the lower-level. This guarantee improves the previous best-known complexity of $\\mathcal{O}(\\max\\{1/\\epsilon_f^{4},1/\\epsilon_g^{4}\\})$. Moreover, for the case that the upper-level function is non-convex, our method requires at most $\\tilde{\\mathcal{O}}(\\max\\{1/\\epsilon_f^{3},1/\\epsilon_g^{3}\\}) $ stochastic oracle queries to find an $(\\epsilon_f, \\epsilon_g)$-stationary point. In the finite-sum setting, we show that the number of stochastic oracle calls required by our method are $\\tilde{\\mathcal{O}}(\\sqrt{n}/\\epsilon)$ and $\\tilde{\\mathcal{O}}(\\sqrt{n}/\\epsilon^{2})$ for the convex and non-convex settings, respectively, where $\\epsilon=\\min \\{\\epsilon_f,\\epsilon_g\\}$.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "73205678",
                        "name": "Jincheng Cao"
                    },
                    {
                        "authorId": "2051263313",
                        "name": "Ruichen Jiang"
                    },
                    {
                        "authorId": "2171107359",
                        "name": "Nazanin Abolfazli"
                    },
                    {
                        "authorId": "7783772",
                        "name": "E. Y. Hamedani"
                    },
                    {
                        "authorId": "2706423",
                        "name": "Aryan Mokhtari"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[4] Luca Bertinetto, Joao F Henriques, Philip Torr, and Andrea Vedaldi.",
                ", meta-learning [4, 29], hyperparameter optimization [12, 3], reinforcement learning [59, 54] and neural architecture search [35, 8]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6f6e2139eb762f857ca1093e699de243fa0613dd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-03811",
                    "ArXiv": "2308.03811",
                    "DOI": "10.48550/arXiv.2308.03811",
                    "CorpusId": 260704567
                },
                "corpusId": 260704567,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6f6e2139eb762f857ca1093e699de243fa0613dd",
                "title": "Non-Convex Bilevel Optimization with Time-Varying Objective Functions",
                "abstract": "Bilevel optimization has become a powerful tool in a wide variety of machine learning problems. However, the current nonconvex bilevel optimization considers an offline dataset and static functions, which may not work well in emerging online applications with streaming data and time-varying functions. In this work, we study online bilevel optimization (OBO) where the functions can be time-varying and the agent continuously updates the decisions with online streaming data. To deal with the function variations and the unavailability of the true hypergradients in OBO, we propose a single-loop online bilevel optimizer with window averaging (SOBOW), which updates the outer-level decision based on a window average of the most recent hypergradient estimations stored in the memory. Compared to existing algorithms, SOBOW is computationally efficient and does not need to know previous functions. To handle the unique technical difficulties rooted in single-loop update and function variations for OBO, we develop a novel analytical technique that disentangles the complex couplings between decision variables, and carefully controls the hypergradient estimation error. We show that SOBOW can achieve a sublinear bilevel local regret under mild conditions. Extensive experiments across multiple domains corroborate the effectiveness of SOBOW.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3392299",
                        "name": "Sen-Fon Lin"
                    },
                    {
                        "authorId": "143827145",
                        "name": "Daouda Sow"
                    },
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "2397352",
                        "name": "Yitao Liang"
                    },
                    {
                        "authorId": "1750487",
                        "name": "N. Shroff"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6fd9ad81b777fd8b7bf52db6ac42a83e4081a33d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-03047",
                    "ArXiv": "2308.03047",
                    "DOI": "10.48550/arXiv.2308.03047",
                    "CorpusId": 260682655
                },
                "corpusId": 260682655,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6fd9ad81b777fd8b7bf52db6ac42a83e4081a33d",
                "title": "Prototypes-oriented Transductive Few-shot Learning with Conditional Transport",
                "abstract": "Transductive Few-Shot Learning (TFSL) has recently attracted increasing attention since it typically outperforms its inductive peer by leveraging statistics of query samples. However, previous TFSL methods usually encode uniform prior that all the classes within query samples are equally likely, which is biased in imbalanced TFSL and causes severe performance degradation. Given this pivotal issue, in this work, we propose a novel Conditional Transport (CT) based imbalanced TFSL model called {\\textbf P}rototypes-oriented {\\textbf U}nbiased {\\textbf T}ransfer {\\textbf M}odel (PUTM) to fully exploit unbiased statistics of imbalanced query samples, which employs forward and backward navigators as transport matrices to balance the prior of query samples per class between uniform and adaptive data-driven distributions. For efficiently transferring statistics learned by CT, we further derive a closed form solution to refine prototypes based on MAP given the learned navigators. The above two steps of discovering and transferring unbiased statistics follow an iterative manner, formulating our EM-based solver. Experimental results on four standard benchmarks including miniImageNet, tieredImageNet, CUB, and CIFAR-FS demonstrate superiority of our model in class-imbalanced generalization.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2087115586",
                        "name": "Long Tian"
                    },
                    {
                        "authorId": "2108686603",
                        "name": "Jing Feng"
                    },
                    {
                        "authorId": "2191036044",
                        "name": "Wenchao Chen"
                    },
                    {
                        "authorId": "2227989039",
                        "name": "Xiaoqiang Chai"
                    },
                    {
                        "authorId": "2116653363",
                        "name": "Liming Wang"
                    },
                    {
                        "authorId": "2108735694",
                        "name": "Xiyang Liu"
                    },
                    {
                        "authorId": "2152691280",
                        "name": "Bo Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "model uses a differentiable ridge regression (RR) layer in the inner loop to learn task-specific features [28]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "65de44a53289a58d277335de347fd30e1ad00570",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-02877",
                    "ArXiv": "2308.02877",
                    "DOI": "10.48550/arXiv.2308.02877",
                    "CorpusId": 260681080
                },
                "corpusId": 260681080,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/65de44a53289a58d277335de347fd30e1ad00570",
                "title": "Meta-learning in healthcare: A survey",
                "abstract": "As a subset of machine learning, meta-learning, or learning to learn, aims at improving the model's capabilities by employing prior knowledge and experience. A meta-learning paradigm can appropriately tackle the conventional challenges of traditional learning approaches, such as insufficient number of samples, domain shifts, and generalization. These unique characteristics position meta-learning as a suitable choice for developing influential solutions in various healthcare contexts, where the available data is often insufficient, and the data collection methodologies are different. This survey discusses meta-learning broad applications in the healthcare domain to provide insight into how and where it can address critical healthcare challenges. We first describe the theoretical foundations and pivotal methods of meta-learning. We then divide the employed meta-learning approaches in the healthcare domain into two main categories of multi/single-task learning and many/few-shot learning and survey the studies. Finally, we highlight the current challenges in meta-learning research, discuss the potential solutions and provide future perspectives on meta-learning in healthcare.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2005393724",
                        "name": "Alireza Rafiei"
                    },
                    {
                        "authorId": "2208701984",
                        "name": "Ronald Moore"
                    },
                    {
                        "authorId": "2223926664",
                        "name": "S. Jahromi"
                    },
                    {
                        "authorId": "3046235",
                        "name": "F. Hajati"
                    },
                    {
                        "authorId": "48074550",
                        "name": "R. Kamaleswaran"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al. (2017); Blanchet et al. (2017); Lin et al.",
                ", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al.",
                ", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al. (2017); Blanchet et al.",
                ", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate.",
                ", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al.",
                ", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al. (2017); Blanchet et al. (2017); Lin et al. (2020); Devraj & Chen (2019); Hu et al.",
                ", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions.",
                ", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al.",
                "\u2026tool to study many machine learning applications such as hyperparameter optimization (Franceschi et al., 2018; Shaban et al., 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et\u2026",
                ", 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate. Stochastic compositional optimization. Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al. (2017); Blanchet et al. (2017); Lin et al. (2020); Devraj & Chen (2019); Hu et al. (2019). A SCO reformulation has also been used to solve nonconvex distributionally robust optimization (DRO) Rahimian & Mehrotra (2019); Qian et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "f841610f31713dbd9ffb3cd7b1cca16a928ff20f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2308-00311",
                    "ArXiv": "2308.00311",
                    "DOI": "10.48550/arXiv.2308.00311",
                    "CorpusId": 260351224
                },
                "corpusId": 260351224,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f841610f31713dbd9ffb3cd7b1cca16a928ff20f",
                "title": "Doubly Robust Instance-Reweighted Adversarial Training",
                "abstract": "Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained by optimizing the KL-divergence regularized loss function, which allows us to devise new algorithms with a theoretical convergence guarantee. Experiments on standard classification datasets demonstrate that our proposed approach outperforms related state-of-the-art baseline methods in terms of average robust performance, and at the same time improves the robustness against attacks on the weakest data points. Codes will be available soon.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "143827145",
                        "name": "Daouda Sow"
                    },
                    {
                        "authorId": "3392299",
                        "name": "Sen-Fon Lin"
                    },
                    {
                        "authorId": "2156070723",
                        "name": "Zhangyang Wang"
                    },
                    {
                        "authorId": "2397352",
                        "name": "Yitao Liang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following [61], it is split into 64, 20 and 16 classes for training, validation and testing, respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "661b0eb92213674c60c69139fdbdb8d80755cd3e",
                "externalIds": {
                    "DBLP": "journals/tcsv/DangLJYCZ23",
                    "DOI": "10.1109/TCSVT.2023.3241651",
                    "CorpusId": 256539632
                },
                "corpusId": 256539632,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/661b0eb92213674c60c69139fdbdb8d80755cd3e",
                "title": "Counterfactual Generation Framework for Few-Shot Learning",
                "abstract": "Few-shot learning (FSL) that aims to recognize novel classes with few labeled samples is troubled by its data scarcity. Though recent works tackle FSL with data augmentation-based methods, these models fail to maintain the discrimination and diversity of the generated samples due to the distribution shift and intra-class bias caused by the data scarcity, therefore greatly undermining the performance. To this end, we use causal mechanisms, which are constant among independent variables across data distribution, to alleviate such effects. In this sense, we decompose the image information into two independent components: sample-specific and class-agnostic information, and further propose a novel Counterfactual Generation Framework (CGF) to learn the underlying causal mechanisms to synthesize faithful samples for FSL. Specifically, based on the counterfactual inference, we design a class-agnostic feature extractor to capture the sample-specific information, together with a counterfactual generation network to simulate the data generation process from a causal perspective. Moreover, to leverage the power of CGF in counterfactual inference, we further develop a novel classifier that classifies samples based on their distributions of counterfactual generations. Extensive experiments demonstrate the effectiveness of CGF on four FSL benchmarks, e.g., 80.12/86.13% accuracy on 5-way 1/5-shot miniImageNet FSL tasks, significantly improving the performance. Our codes and models are available at https://github.com/eric-hang/CGF.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2192703079",
                        "name": "Zhuohang Dang"
                    },
                    {
                        "authorId": "3326677",
                        "name": "Minnan Luo"
                    },
                    {
                        "authorId": "2147134586",
                        "name": "Chengyou Jia"
                    },
                    {
                        "authorId": "152299623",
                        "name": "Caixia Yan"
                    },
                    {
                        "authorId": "2840330",
                        "name": "Xiao Chang"
                    },
                    {
                        "authorId": "2152099796",
                        "name": "Qinghua Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7170a2807e2f79d5ee2f8562a1ccd6d6ae04e2bd",
                "externalIds": {
                    "DBLP": "journals/asc/WangDCLCFXLLL23",
                    "DOI": "10.1016/j.asoc.2023.110697",
                    "CorpusId": 260673153
                },
                "corpusId": 260673153,
                "publicationVenue": {
                    "id": "b1994124-f1e8-4f96-a165-b6f19a04fe7e",
                    "name": "Applied Soft Computing",
                    "type": "journal",
                    "alternate_names": [
                        "Appl Soft Comput"
                    ],
                    "issn": "1568-4946",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/621920/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/applied-soft-computing",
                        "http://www.sciencedirect.com/science/journal/15684946"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7170a2807e2f79d5ee2f8562a1ccd6d6ae04e2bd",
                "title": "Dual adversarial network with meta-learning for domain-generalized few-shot text classification",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2210362033",
                        "name": "Xuyang Wang"
                    },
                    {
                        "authorId": "2111935853",
                        "name": "Yajun Du"
                    },
                    {
                        "authorId": "2198683565",
                        "name": "Danroujing Chen"
                    },
                    {
                        "authorId": "2109417305",
                        "name": "Xianyong Li"
                    },
                    {
                        "authorId": "1569834719",
                        "name": "Xiaoliang Chen"
                    },
                    {
                        "authorId": "1485668568",
                        "name": "Yongquan Fan"
                    },
                    {
                        "authorId": "48927373",
                        "name": "Chunzhi Xie"
                    },
                    {
                        "authorId": "2211596480",
                        "name": "Yanli Li"
                    },
                    {
                        "authorId": "48210927",
                        "name": "Jia Liu"
                    },
                    {
                        "authorId": "2256782232",
                        "name": "Hui Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In other words, while FR is part of the whole network, its weights \u0398R are obtained by a direct least-squares type of solutions instead of by gradient descent, which has been used as a paradigm in [Bertinetto et al., 2018] for adaptation."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "49d7c024e2417022a02e38a3a1f1c6924a55f552",
                "externalIds": {
                    "DBLP": "conf/ijcai/LiXJ23",
                    "DOI": "10.24963/ijcai.2023/671",
                    "CorpusId": 260851554
                },
                "corpusId": 260851554,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/49d7c024e2417022a02e38a3a1f1c6924a55f552",
                "title": "Confidence-based Self-Corrective Learning: An Application in Height Estimation Using Satellite LiDAR and Imagery",
                "abstract": "Widespread, and rapid, environmental transformation is underway on Earth driven by human activities. Climate shifts such as global warming have led to massive and alarming loss of ice and snow in the high-latitude regions including the Arctic, causing many natural disasters due to sea-level rise, etc. Mitigating the impacts of climate change has also become a United Nations' Sustainable Development Goal for 2030. The recent launch of the ICESat-2 satellites target on heights in the polar regions. However, the observations are only available along very narrow scan lines, leaving large no-data gaps in-between. We aim to fill the gaps by combining the height observations with high-resolution satellite imagery that have large footprints (spatial coverage). The data expansion is a challenging task as the height data are often constrained on one or a few lines per image in real applications, and the images are highly noisy for height estimation. Related work on image-based height prediction and interpolation relies on specific types of images or does not consider the highly-localized height distribution. We propose a spatial self-corrective learning framework, which explicitly uses confidence-based pseudo-interpolation, recurrent self-refinement, and truth-based correction with a regression layer to address the challenges. We carry out experiments on different landscapes in the high-latitude regions and the proposed method shows stable improvements compared to the baseline methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46947989",
                        "name": "Zhili Li"
                    },
                    {
                        "authorId": "46269169",
                        "name": "Yiqun Xie"
                    },
                    {
                        "authorId": "38139853",
                        "name": "X. Jia"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[2020] use an attention mechanism based on word statistics that is trained on meta tasks to aggregate pre-trained embeddings for direct classification using a ridge regressor [Bertinetto et al., 2019] instead of predicting softmax parameters."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2b85568389746bff948a38f03dbb5abac8833d3f",
                "externalIds": {
                    "DBLP": "conf/ijcai/GriesshaberMV23",
                    "DOI": "10.24963/ijcai.2023/562",
                    "CorpusId": 260853684
                },
                "corpusId": 260853684,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/2b85568389746bff948a38f03dbb5abac8833d3f",
                "title": "Regularisation for Efficient Softmax Parameter Generation in Low-Resource Text Classifiers",
                "abstract": "Meta-learning has made tremendous progress in recent years and was demonstrated to be particularly suitable in low-resource settings where training data is very limited. However, meta-learning models still require large amounts of training tasks to achieve good generalisation. Since labelled training data may be sparse, self-supervision-based approaches are able to further improve performance on downstream tasks. Although no labelled data is necessary for this training, a large corpus of unlabelled text needs to be available.\n\nIn this paper, we improve on recent advances in meta-learning for natural language models that allow training on a diverse set of training tasks for few-shot, low-resource target tasks. We introduce a way to generate new training data with the need for neither more supervised nor unsupervised datasets. We evaluate the method on a diverse set of NLP tasks and show that the model decreases in performance when trained on this data without further adjustments. Therefore, we introduce and evaluate two methods for regularising the training process and show that they not only improve performance when used in conjunction with the new training data but also improve average performance when training only on the original data, compared to the baseline.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "51138239",
                        "name": "Daniel Grie\u00dfhaber"
                    },
                    {
                        "authorId": "2800610",
                        "name": "J. Maucher"
                    },
                    {
                        "authorId": "4160376",
                        "name": "Ngoc Thang Vu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "675e61ee6620fa743a631323404c32464555f441",
                "externalIds": {
                    "DBLP": "conf/ijcai/An0023",
                    "DOI": "10.24963/ijcai.2023/381",
                    "CorpusId": 260852033
                },
                "corpusId": 260852033,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/675e61ee6620fa743a631323404c32464555f441",
                "title": "Learning to Learn from Corrupted Data for Few-Shot Learning",
                "abstract": "Few-shot learning which aims to generalize knowledge learned from annotated base training data to recognize unseen novel classes has attracted considerable attention. Existing few-shot methods rely on completely clean training data. However, in the real world, the training data are always corrupted and accompanied by noise due to the disturbance in data transmission and low-quality annotation, which severely degrades the performance and generalization capability of few-shot models. To address the problem, we propose a unified peer-collaboration learning (PCL) framework to extract valid knowledge from corrupted data for few-shot learning. PCL leverages two modules to mimic the peer collaboration process which cooperatively evaluates the importance of each sample. Specifically, each module first estimates the importance weights of different samples by encoding the information provided by the other module from both global and local perspectives. Then, both modules leverage the obtained importance weights to guide the reevaluation of the loss value of each sample. In this way, the peers can mutually absorb knowledge to improve the robustness of few-shot models. Experiments verify that our framework combined with different few-shot methods can significantly improve the performance and robustness of original models.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "7686972",
                        "name": "Yuexuan An"
                    },
                    {
                        "authorId": "47039400",
                        "name": "Xingyu Zhao"
                    },
                    {
                        "authorId": "1645209767",
                        "name": "Hui Xue"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Next, we evaluate these two selection methods along with random selection by ap-\nplying them using the three representative networks in implementation settings, namely, P > M > F (Mini-I), RFS (S.S.), and R2-D2 (S.S.).",
                "To begin with, as indicated by the bold numbers, six out of the nine networks (RFS, Baseline, Baseline++, R2-D2, e3bm, SSL) performed better when trained with Snapshot Serengeti than when trained with mini-ImageNet.",
                "(a) Baseline (b) Baseline++ (c) e3bm\n(d) P > M > F (e) ProtoNet (f) R2-D2\n(g) RFS (h) RENet (i) SSL\nFigure A1.",
                "We have selected nine FSL networks: ProtoNet [13], RFS [14], Baseline and Baseline++ [15], R2-D2 [34], e3bm [17], RENet [35], SSL-FEW-SHOT [36], and P > M > F [37].",
                "Baseline [15], RFS [14], and R2-D2 [34] all use a form of linear classifier for their decision rule, while RENet uses a novel cross-correlational attention (CCA) module and e3bm [17] uses a more complex ensemble of classifiers.",
                "We conduct the same implementation test for the three representative networks (P > M > F (Mini-I), RFS (S.S.), R2-D2 (S.S.)), and the resulting comparisons are shown in Figure 7.",
                "(a) Baseline (b) Baseline++ (c) e3bm\n(d) P > M > F (e) ProtoNet (f) R2-D2\n(g) RFS (h) RENet (i) SSL Figure A2.",
                "The effect is not significant with R2-D2, and in the case of P > M > F it actually degrades the performance slightly."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "e463409287178741190246ac3864e87548c438bb",
                "externalIds": {
                    "DOI": "10.3390/ai4030031",
                    "CorpusId": 260399031
                },
                "corpusId": 260399031,
                "publicationVenue": {
                    "id": "b76366f5-0af9-45f3-8fe3-78fdb0114f67",
                    "name": "Applied Informatics",
                    "type": "conference",
                    "alternate_names": [
                        "Appl Informatics",
                        "Advances Argumentation Artificial Intelligence",
                        "AI",
                        "Can Conf Artif Intell",
                        "Adv Argum Artif Intell",
                        "Canadian Conference on Artificial Intelligence"
                    ],
                    "issn": "2196-0089",
                    "alternate_issns": [
                        "2673-2688"
                    ],
                    "url": "http://cscsi.org/",
                    "alternate_urls": [
                        "https://link.springer.com/journal/40535",
                        "http://www.applied-informatics-j.com/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e463409287178741190246ac3864e87548c438bb",
                "title": "Applying Few-Shot Learning for In-the-Wild Camera-Trap Species Classification",
                "abstract": "Few-shot learning (FSL) describes the challenge of learning a new task using a minimum amount of labeled data, and we have observed significant progress made in this area. In this paper, we explore the effectiveness of the FSL theory by considering a real-world problem where labels are hard to obtain. To assist a large study on chimpanzee hunting activities, we aim to classify various animal species that appear in our in-the-wild camera traps located in Senegal. Using the philosophy of FSL, we aim to train an FSL network to learn to separate animal species using large public datasets and implement the network on our data with its novel species/classes and unseen environments, needing only to label a few images per new species. Here, we first discuss constraints and challenges caused by having in-the-wild uncurated data, which are often not addressed in benchmark FSL datasets. Considering these new challenges, we create two experiments and corresponding evaluation metrics to determine a network\u2019s usefulness in a real-world implementation scenario. We then compare results from various FSL networks, and describe how factors may affect a network\u2019s potential real-world usefulness. We consider network design factors such as distance metrics or extra pre-training, and examine their roles in a real-world implementation setting. We also consider additional factors such as support set selection and ease of implementation, which are usually ignored when a benchmark dataset has been established.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2149051548",
                        "name": "Haoyu Chen"
                    },
                    {
                        "authorId": "4612644",
                        "name": "S. Lindshield"
                    },
                    {
                        "authorId": "7564333",
                        "name": "P. Ndiaye"
                    },
                    {
                        "authorId": "2226576856",
                        "name": "Yaya Hamady Ndiaye"
                    },
                    {
                        "authorId": "4852059",
                        "name": "J. Pruetz"
                    },
                    {
                        "authorId": "1708696",
                        "name": "A. Reibman"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The comparative evaluation results on MiniImageNet and Cifar-FS have been presented in Figure 5.",
                "On Cifar-FS and CUB-100-2011, PEMnE-BMS* is instead the best transductive approach.",
                "We report the evaluation results on the MiniImageNet and Cifar-FS workloads; the results on other workloads are similar, thus omitted here.",
                "All the images are of the size of 84\u00d784; \u2022 Cifar-FS[47]: it contains totally 100 classes, each of which contains 600 images with the size of 32\u00d732.",
                "The evaluation results on MiniImagenet and Cifar-FS have been presented in Table 4.",
                "All the images are of the size of 84\u00d784;\n\u2022 Cifar-FS[47]: it contains totally 100 classes, each of which contains 600 images with the size of 32\u00d732."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2023fe0565d51406319c111ddf6329ed74c088d1",
                "externalIds": {
                    "ArXiv": "2307.15524",
                    "DBLP": "journals/corr/abs-2307-15524",
                    "DOI": "10.48550/arXiv.2307.15524",
                    "CorpusId": 260315854
                },
                "corpusId": 260315854,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2023fe0565d51406319c111ddf6329ed74c088d1",
                "title": "Few-shot Image Classification based on Gradual Machine Learning",
                "abstract": "Few-shot image classification aims to accurately classify unlabeled images using only a few labeled samples. The state-of-the-art solutions are built by deep learning, which focuses on designing increasingly complex deep backbones. Unfortunately, the task remains very challenging due to the difficulty of transferring the knowledge learned in training classes to new ones. In this paper, we propose a novel approach based on the non-i.i.d paradigm of gradual machine learning (GML). It begins with only a few labeled observations, and then gradually labels target images in the increasing order of hardness by iterative factor inference in a factor graph. Specifically, our proposed solution extracts indicative feature representations by deep backbones, and then constructs both unary and binary factors based on the extracted features to facilitate gradual learning. The unary factors are constructed based on class center distance in an embedding space, while the binary factors are constructed based on k-nearest neighborhood. We have empirically validated the performance of the proposed approach on benchmark datasets by a comparative study. Our extensive experiments demonstrate that the proposed approach can improve the SOTA performance by 1-5% in terms of accuracy. More notably, it is more robust than the existing deep models in that its performance can consistently improve as the size of query set increases while the performance of deep models remains essentially flat or even becomes worse.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2163651971",
                        "name": "Nanway Chen"
                    },
                    {
                        "authorId": "1753652097",
                        "name": "Xianming Kuang"
                    },
                    {
                        "authorId": "2118168139",
                        "name": "Feiyu Liu"
                    },
                    {
                        "authorId": "104138391",
                        "name": "K. Wang"
                    },
                    {
                        "authorId": "2109397483",
                        "name": "Qun Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Metric-based models tend to achieve better results on tieredImageNet and CIFAR-FS with high-diversity task samplers, while they perform better on Omniglot with the Uniform Sampler.",
                "CIFAR-FS [6] comprises 100 classes with 600 images per class, split the same as miniImageNet."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b34e26f28956a73cb2c3795bcbbaa359b4a76c6f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-08924",
                    "ArXiv": "2307.08924",
                    "DOI": "10.48550/arXiv.2307.08924",
                    "CorpusId": 259950841
                },
                "corpusId": 259950841,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b34e26f28956a73cb2c3795bcbbaa359b4a76c6f",
                "title": "Learning to Sample Tasks for Meta Learning",
                "abstract": "Through experiments on various meta-learning methods, task samplers, and few-shot learning tasks, this paper arrives at three conclusions. Firstly, there are no universal task sampling strategies to guarantee the performance of meta-learning models. Secondly, task diversity can cause the models to either underfit or overfit during training. Lastly, the generalization performance of the models are influenced by task divergence, task entropy, and task difficulty. In response to these findings, we propose a novel task sampler called Adaptive Sampler (ASr). ASr is a plug-and-play task sampler that takes task divergence, task entropy, and task difficulty to sample tasks. To optimize ASr, we rethink and propose a simple and general meta-learning algorithm. Finally, a large number of empirical experiments demonstrate the effectiveness of the proposed ASr.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2193098014",
                        "name": "Jingyao Wang"
                    },
                    {
                        "authorId": "2218933033",
                        "name": "Zeen Song"
                    },
                    {
                        "authorId": "2186726895",
                        "name": "Xingzhe Su"
                    },
                    {
                        "authorId": "2114860376",
                        "name": "Lingyu Si"
                    },
                    {
                        "authorId": "39256302",
                        "name": "Hongwei Dong"
                    },
                    {
                        "authorId": "2059455684",
                        "name": "Wenwen Qiang"
                    },
                    {
                        "authorId": "2153619515",
                        "name": "Changwen Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For instance, [61] and [62] perform a closed-form or convex optimization on top of meta-learned features."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "03904430d2ecb0ac38846c74ce4a9f27e266689a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-04722",
                    "ArXiv": "2307.04722",
                    "DOI": "10.48550/arXiv.2307.04722",
                    "CorpusId": 259501767
                },
                "corpusId": 259501767,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/03904430d2ecb0ac38846c74ce4a9f27e266689a",
                "title": "Advances and Challenges in Meta-Learning: A Technical Review",
                "abstract": "Meta-learning empowers learning systems with the ability to acquire knowledge from multiple tasks, enabling faster adaptation and generalization to new tasks. This review provides a comprehensive technical overview of meta-learning, emphasizing its importance in real-world applications where data may be scarce or expensive to obtain. The paper covers the state-of-the-art meta-learning approaches and explores the relationship between meta-learning and multi-task learning, transfer learning, domain adaptation and generalization, self-supervised learning, personalized federated learning, and continual learning. By highlighting the synergies between these topics and the field of meta-learning, the paper demonstrates how advancements in one area can benefit the field as a whole, while avoiding unnecessary duplication of efforts. Additionally, the paper delves into advanced meta-learning topics such as learning from complex multi-modal task distributions, unsupervised meta-learning, learning to efficiently adapt to data distribution shifts, and continual meta-learning. Lastly, the paper highlights open problems and challenges for future research in the field. By synthesizing the latest research developments, this paper provides a thorough understanding of meta-learning and its potential impact on various machine learning applications. We believe that this technical overview will contribute to the advancement of meta-learning and its practical implications in addressing real-world problems.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2221852775",
                        "name": "Anna Vettoruzzo"
                    },
                    {
                        "authorId": "1848066",
                        "name": "Mohamed-Rafik Bouguelia"
                    },
                    {
                        "authorId": "1717534",
                        "name": "J. Vanschoren"
                    },
                    {
                        "authorId": "2588243",
                        "name": "Thorsteinn S. R\u00f6gnvaldsson"
                    },
                    {
                        "authorId": "144253310",
                        "name": "K. Santosh"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following the recent work of [46], we use the same training/validation/testing splits consisting of 64/16/20 classes respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "906534691a88998df1a687174991a7e7f5b4d9f9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2307-04114",
                    "ArXiv": "2307.04114",
                    "DOI": "10.48550/arXiv.2307.04114",
                    "CorpusId": 259501270
                },
                "corpusId": 259501270,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/906534691a88998df1a687174991a7e7f5b4d9f9",
                "title": "FILM: How can Few-Shot Image Classification Benefit from Pre-Trained Language Models?",
                "abstract": "Few-shot learning aims to train models that can be generalized to novel classes with only a few samples. Recently, a line of works are proposed to enhance few-shot learning with accessible semantic information from class names. However, these works focus on improving existing modules such as visual prototypes and feature extractors of the standard few-shot learning framework. This limits the full potential use of semantic information. In this paper, we propose a novel few-shot learning framework that uses pre-trained language models based on contrastive learning. To address the challenge of alignment between visual features and textual embeddings obtained from text-based pre-trained language model, we carefully design the textual branch of our framework and introduce a metric module to generalize the cosine similarity. For better transferability, we let the metric module adapt to different few-shot tasks and adopt MAML to train the model via bi-level optimization. Moreover, we conduct extensive experiments on multiple benchmarks to demonstrate the effectiveness of our method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1410198542",
                        "name": "Zihao Jiang"
                    },
                    {
                        "authorId": "2221574919",
                        "name": "Yunkai Dang"
                    },
                    {
                        "authorId": "2221574493",
                        "name": "Dong Pang"
                    },
                    {
                        "authorId": "2973831",
                        "name": "Huishuai Zhang"
                    },
                    {
                        "authorId": "8007867",
                        "name": "Weiran Huang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Implementation Details We study the classic FSL methods ProtoNet (Snell et al., 2017), MAML (Finn et al., 2017), R2D2 (Bertinetto et al., 2019), and Baseline(++) (Chen et al., 2019), using the implementations provided by the LibFewShot1.",
                ", 2017), R2D2 (Bertinetto et al., 2019), and Baseline(++) (Chen et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e3c78c437992b1f83fd460a856e54db90078b4a2",
                "externalIds": {
                    "ArXiv": "2307.02732",
                    "DBLP": "journals/corr/abs-2307-02732",
                    "DOI": "10.48550/arXiv.2307.02732",
                    "CorpusId": 259360580
                },
                "corpusId": 259360580,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e3c78c437992b1f83fd460a856e54db90078b4a2",
                "title": "Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit for Purpose?",
                "abstract": "Numerous benchmarks for Few-Shot Learning have been proposed in the last decade. However all of these benchmarks focus on performance averaged over many tasks, and the question of how to reliably evaluate and tune models trained for individual tasks in this regime has not been addressed. This paper presents the first investigation into task-level evaluation -- a fundamental step when deploying a model. We measure the accuracy of performance estimators in the few-shot setting, consider strategies for model selection, and examine the reasons for the failure of evaluators usually thought of as being robust. We conclude that cross-validation with a low number of folds is the best choice for directly estimating the performance of a model, whereas using bootstrapping or cross validation with a large number of folds is better for model selection purposes. Overall, we find that existing benchmarks for few-shot learning are not designed in such a way that one can get a reliable picture of how effectively methods can be used on individual tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2221227769",
                        "name": "Lu'isa Shimabucoro"
                    },
                    {
                        "authorId": "1697755",
                        "name": "Timothy M. Hospedales"
                    },
                    {
                        "authorId": "2319565",
                        "name": "H. Gouk"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6fbff140ad153fb985123d2648a096c2ae327d64",
                "externalIds": {
                    "DBLP": "journals/pr/DomingoAR23",
                    "DOI": "10.1016/j.patcog.2023.109797",
                    "CorpusId": 259610333
                },
                "corpusId": 259610333,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6fbff140ad153fb985123d2648a096c2ae327d64",
                "title": "One Shot Learning with class partitioning and cross validation voting (CP-CVV)",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3427017",
                        "name": "Jaime Duque Domingo"
                    },
                    {
                        "authorId": "145404966",
                        "name": "Roberto Medina Aparicio"
                    },
                    {
                        "authorId": "2135011394",
                        "name": "Luis Miguel Gonz\u00e1lez Rodrigo"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "947e08094eb7b0d39570492b86d277509b15ecc2",
                "externalIds": {
                    "DBLP": "conf/icmcs/DangSZCZWW23",
                    "DOI": "10.1109/ICME55011.2023.00494",
                    "CorpusId": 261128006
                },
                "corpusId": 261128006,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/947e08094eb7b0d39570492b86d277509b15ecc2",
                "title": "Multi-Level Correlation Network For Few-Shot Image Classification",
                "abstract": "Few-shot image classification(FSIC) aims to recognize novel classes given few labeled images from base classes. Recent works have achieved promising classification performance, especially for metric-learning methods, where a measure at only image feature level is usually used. In this paper, we argue that measure at such a level may not be effective enough to generalize from base to novel classes when using only a few images. Instead, a multi-level descriptor of an image is taken for consideration in this paper. We propose a multi-level correlation network (MLCN) for FSIC to tackle this problem by effectively capturing local information. Concretely, we present the self-correlation module and cross-correlation module to learn the semantic correspondence relation of local information based on learned representations. Moreover, we propose a pattern-correlation module to capture the pattern of fine-grained images and find relevant structural patterns between base classes and novel classes. Extensive experiments and analysis show the effectiveness of our proposed method on four widely-used FSIC benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2221574919",
                        "name": "Yunkai Dang"
                    },
                    {
                        "authorId": "2736861",
                        "name": "Meijun Sun"
                    },
                    {
                        "authorId": "2157502742",
                        "name": "Min Zhang"
                    },
                    {
                        "authorId": "2117202703",
                        "name": "Zhengyu Chen"
                    },
                    {
                        "authorId": null,
                        "name": "Xinliang Zhang"
                    },
                    {
                        "authorId": "50219447",
                        "name": "Zheng Wang"
                    },
                    {
                        "authorId": "2111224425",
                        "name": "Donglin Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "949ae56eeca757aeec1ef0f1f1fc83147bf7e40b",
                "externalIds": {
                    "DOI": "10.1117/1.JEI.32.4.043005",
                    "CorpusId": 259596925
                },
                "corpusId": 259596925,
                "publicationVenue": {
                    "id": "c677ab24-0c04-487d-83e2-c252af9479c8",
                    "name": "Journal of Electronic Imaging (JEI)",
                    "type": "journal",
                    "alternate_names": [
                        "J Electron Imaging (JEI",
                        "Journal of Electronic Imaging",
                        "J Electron Imaging"
                    ],
                    "issn": "1017-9909",
                    "url": "https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging",
                    "alternate_urls": [
                        "http://electronicimaging.spiedigitallibrary.org/journal.aspx"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/949ae56eeca757aeec1ef0f1f1fc83147bf7e40b",
                "title": "Transductive clustering optimization learning for few-shot image classification",
                "abstract": "Abstract. Few-shot image classification aims to perform image classification on new categories with only a small amount of labeled training data. However, it is difficult to complete such a task under the existing conditions. Therefore, the current few-shot learning methods are built on the paradigm of transfer learning, where the core idea is to learn a priori that can solve unknown new tasks. The idea of meta-learning is fast learning, which is similar to the idea of few-shot learning. Therefore, conventional few-shot learning methods generally adopt a meta-training approach with episodic training to construct knowledge prior. However, research work indicates that an embedding model with powerful feature representations is simpler and more effective than the existing sophisticated few-shot learning methods. Inspired by this insight, we propose a few-shot image classification method based on the transductive clustering optimization learning. First, memory block is introduced to store the internal feature structure of each category, namely comprehensive representation of various features. Second, during the training process, sample features are compared with the memory content to further expand the differences between different categories and improve the performance of feature extractor. Finally, in the transductive few-shot setting, a clustering optimization module has been introduced to select appropriate samples for clustering to alleviate the fundamental problem of sample scarcity. A large number of experimental results show that the proposed few-shot image classification method based on the transductive clustering optimization learning effectively improves the classification accuracy under various training conditions.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46396571",
                        "name": "Yang Wang"
                    },
                    {
                        "authorId": "2192289273",
                        "name": "Xiong Bian"
                    },
                    {
                        "authorId": "2508428",
                        "name": "Songhao Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recent algorithmic advances in this field have driven successful applications in areas such as meta-learning [3, 16, 24], reinforcement learning [21, 30, 46] and hyperparameter optimization [13, 20, 44]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6dae807729b9deec78a054de11f702ef6013881b",
                "externalIds": {
                    "ArXiv": "2307.00126",
                    "DBLP": "journals/corr/abs-2307-00126",
                    "DOI": "10.48550/arXiv.2307.00126",
                    "CorpusId": 259316951
                },
                "corpusId": 259316951,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6dae807729b9deec78a054de11f702ef6013881b",
                "title": "Accelerating Inexact HyperGradient Descent for Bilevel Optimization",
                "abstract": "We present a method for solving general nonconvex-strongly-convex bilevel optimization problems. Our method -- the \\emph{Restarted Accelerated HyperGradient Descent} (\\texttt{RAHGD}) method -- finds an $\\epsilon$-first-order stationary point of the objective with $\\tilde{\\mathcal{O}}(\\kappa^{3.25}\\epsilon^{-1.75})$ oracle complexity, where $\\kappa$ is the condition number of the lower-level objective and $\\epsilon$ is the desired accuracy. We also propose a perturbed variant of \\texttt{RAHGD} for finding an $\\big(\\epsilon,\\mathcal{O}(\\kappa^{2.5}\\sqrt{\\epsilon}\\,)\\big)$-second-order stationary point within the same order of oracle complexity. Our results achieve the best-known theoretical guarantees for finding stationary points in bilevel optimization and also improve upon the existing upper complexity bound for finding second-order stationary points in nonconvex-strongly-concave minimax optimization problems, setting a new state-of-the-art benchmark. Empirical studies are conducted to validate the theoretical results in this paper.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2203780474",
                        "name": "Hai-Long Yang"
                    },
                    {
                        "authorId": "2020695",
                        "name": "Luo Luo"
                    },
                    {
                        "authorId": "2109460766",
                        "name": "C. J. Li"
                    },
                    {
                        "authorId": "123333909",
                        "name": "Michael I. Jordan"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7f7c7e093e875a28c1d1ddce3d6d7f4c23c0c96b",
                "externalIds": {
                    "DOI": "10.1007/s13735-023-00279-4",
                    "CorpusId": 259289178
                },
                "corpusId": 259289178,
                "publicationVenue": {
                    "id": "d9c19003-0fdf-4501-b3cd-cf35b240bc6a",
                    "name": "International Journal of Multimedia Information Retrieval",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Multimedia Inf Retr"
                    ],
                    "issn": "2192-662X",
                    "url": "http://www.springer.com/computer/journal/13735",
                    "alternate_urls": [
                        "https://link.springer.com/journal/13735"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7f7c7e093e875a28c1d1ddce3d6d7f4c23c0c96b",
                "title": "Few-shot and meta-learning methods for image understanding: a survey",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2058350488",
                        "name": "Kai He"
                    },
                    {
                        "authorId": "39562998",
                        "name": "Nan Pu"
                    },
                    {
                        "authorId": "50974488",
                        "name": "Mingrui Lao"
                    },
                    {
                        "authorId": "1731570",
                        "name": "M. Lew"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The experiments are conducted on three widely used fewshot learning benchmarks, including miniImageNet (Vinyals et al. 2016), CUB (Wah et al. 2011), and CIFARFS (Bertinetto et al. 2019). miniImageNet is a mini-version\nof the ImageNet dataset (Russakovsky et al. 2015)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f8680befeea08e92981739a9cf68e3332f9fa7f5",
                "externalIds": {
                    "DBLP": "conf/aaai/0002DWM23",
                    "DOI": "10.1609/aaai.v37i9.26228",
                    "CorpusId": 259736871
                },
                "corpusId": 259736871,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/f8680befeea08e92981739a9cf68e3332f9fa7f5",
                "title": "Feature Distribution Fitting with Direction-Driven Weighting for Few-Shot Images Classification",
                "abstract": "Few-shot learning has received increasing attention and witnessed significant advances in recent years. However, most of the few-shot learning methods focus on the optimization of training process, and the learning of metric and sample generating networks. They ignore the importance of learning the ground-truth feature distributions of few-shot classes. This paper proposes a direction-driven weighting method to make the feature distributions of few-shot classes precisely fit the ground-truth distributions. The learned feature distributions can generate an unlimited number of training samples for the few-shot classes to avoid overfitting. Specifically, the proposed method consists of two optimization strategies. The direction-driven strategy is for capturing more complete direction information that can describe the feature distributions. The similarity-weighting strategy is proposed to estimate the impact of different classes in the fitting procedure and assign corresponding weights. Our method outperforms the current state-of-the-art performance by an average of 3% for 1-shot on standard few-shot learning benchmarks like miniImageNet, CIFAR-FS, and CUB. The excellent performance and compelling visualization show that our method can more accurately estimate the ground-truth distributions.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "49142159",
                        "name": "Xin Wei"
                    },
                    {
                        "authorId": "2072592314",
                        "name": "Wei Du"
                    },
                    {
                        "authorId": "144760098",
                        "name": "Huan Wan"
                    },
                    {
                        "authorId": "34924661",
                        "name": "Weidong Min"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2022 CAVDO stands for combining Cifar-fs (Bertinetto et al., 2019), FGVCAircraft (Maji et al., 2013), VGGFlower (Nilsback & Zisserman, 2006), DescribableTextures (Cimpoi et al., 2013), Omniglot (Lake et al., 2015).",
                "\u2022 MICOVA stands for combining MiniImagenet (Vinyals et al., 2017), Cifar-fs (Bertinetto et al., 2019), Omniglot (Lake et al., 2015), VGGFlower (Nilsback & Zisserman, 2006), FGVCAircraft (Maji et al., 2013).",
                "\u2022 CAVDO stands for combining Cifar-fs (Bertinetto et al., 2019), FGVCAircraft (Maji et al.",
                "\u2022 CADO stands for combining Cifar-fs (Bertinetto et al., 2019), FGVCAircraft (Maji et al.",
                "\u2022 CADO stands for combining Cifar-fs (Bertinetto et al., 2019), FGVCAircraft (Maji et al., 2013), Delaunay (Gontier et al., 2022), and Omniglot (Lake et al., 2015).",
                ", 2017), Cifar-fs (Bertinetto et al., 2019), Omniglot (Lake et al.",
                "\u2022 MICOD stands for combining MiniImagenet (Vinyals et al., 2017), Cifar-fs (Bertinetto et al., 2019), Omniglot (Lake et al., 2015), and Delaunay (Gontier et al., 2022)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "ee68edb0def84e7438feb82a44b5bd9878bf56d8",
                "externalIds": {
                    "ArXiv": "2306.13841",
                    "DBLP": "journals/corr/abs-2306-13841",
                    "DOI": "10.48550/arXiv.2306.13841",
                    "CorpusId": 259252070
                },
                "corpusId": 259252070,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/ee68edb0def84e7438feb82a44b5bd9878bf56d8",
                "title": "Is Pre-training Truly Better Than Meta-Learning?",
                "abstract": "In the context of few-shot learning, it is currently believed that a fixed pre-trained (PT) model, along with fine-tuning the final layer during evaluation, outperforms standard meta-learning algorithms. We re-evaluate these claims under an in-depth empirical examination of an extensive set of formally diverse datasets and compare PT to Model Agnostic Meta-Learning (MAML). Unlike previous work, we emphasize a fair comparison by using: the same architecture, the same optimizer, and all models trained to convergence. Crucially, we use a more rigorous statistical tool -- the effect size (Cohen's d) -- to determine the practical significance of the difference between a model trained with PT vs. a MAML. We then use a previously proposed metric -- the diversity coefficient -- to compute the average formal diversity of a dataset. Using this analysis, we demonstrate the following: 1. when the formal diversity of a data set is low, PT beats MAML on average and 2. when the formal diversity is high, MAML beats PT on average. The caveat is that the magnitude of the average difference between a PT vs. MAML using the effect size is low (according to classical statistical thresholds) -- less than 0.2. Nevertheless, this observation is contrary to the currently held belief that a pre-trained model is always better than a meta-learning model. Our extensive experiments consider 21 few-shot learning benchmarks, including the large-scale few-shot learning dataset Meta-Data set. We also show no significant difference between a MAML model vs. a PT model with GPT-2 on Openwebtext. We, therefore, conclude that a pre-trained model does not always beat a meta-learned model and that the formal diversity of a dataset is a driving factor.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "33528206",
                        "name": "B. Miranda"
                    },
                    {
                        "authorId": "2114103434",
                        "name": "P. Yu"
                    },
                    {
                        "authorId": "2143536008",
                        "name": "Saumya Goyal"
                    },
                    {
                        "authorId": "2302062",
                        "name": "Yu-Xiong Wang"
                    },
                    {
                        "authorId": "143812875",
                        "name": "O. Koyejo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS MiniImagenet FC100\n5w1s 5w5s 5w1s 5w5s 5w1s 5w5s\nMatching Networks(CNN-4-64) - - 43.5 55.3 - - MAML(CNN-4-64) - - 48.7 63.1 - -\nProtoNet (CNN-4-64) 55.5 72.0 49.4 68.2 37.5 51.4 MetaOpt-SVM (ResNet12) 72.0 84.2 62.6 78.6 49.8 67.2 Meta-Baseline (ResNet12) - - 68.6 83.7 - - EASY 3xResNet12(ResNet12) 75.24 89.0 71.75 87.15 48.0 64.7\nBaseline++ (WRN-28-10) 67.5 80.1 57.5 73.0 - - S2M2R(WRN-28-10) 74.8 87.5 64.9 83.2 - -\nAMDIM (AmdimNet) - - 76.8 91.0 - -\nHCTransformers(ViT-S) 79.9 90.5 74.7 89.2 48.3 66.4 P>M>F (IN1K, Sup., RN50)\u2020 76.73 87.60 85.74 94.33 58.91 75.14\nP>M>F (IN1K, Sup., Swin-S)\u2020 84.61 92.62 95.83 98.20 70.92 83.98\nOURS(1N1K, Sup., RN50) 78.32 89.13 86.68 96.31 60.74 78.54 OURS(1N1K, Sup., Swin-S) 86.52 93.64 96.44 98.82 72.81 85.22\nFig.",
                "We evaluate our proposed method on three standard within-\ndomain benchmarks: MiniImagenet [11], CIFAR-FS [1], and\nFC100 [8].",
                "We evaluate our proposed method on three standard withindomain benchmarks: MiniImagenet [11], CIFAR-FS [1], and FC100 [8]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "5b870ae3f131b19a240ea3619b32cae55b18613b",
                "externalIds": {
                    "DOI": "10.1109/ICCCI59363.2023.10210176",
                    "CorpusId": 260909528
                },
                "corpusId": 260909528,
                "publicationVenue": {
                    "id": "66c268f7-ba60-443f-919d-e2c297910401",
                    "name": "International Conference on Computational Collective Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Computer Communication and Informatics",
                        "Int Conf Comput Commun Informatics",
                        "IEEE International Conference on Computer Communication and Internet",
                        "Int Conf Comput Collect Intell",
                        "ICCCI",
                        "IEEE Int Conf Comput Commun Internet"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1302"
                },
                "url": "https://www.semanticscholar.org/paper/5b870ae3f131b19a240ea3619b32cae55b18613b",
                "title": "Strengthening Spatial Relations to Multi-scale Features for Few-Shot Learning",
                "abstract": "Few-Shot Learning (FSL) is challenging due to limited training samples, hindering Convolutional Neural Networks (CNNs) from capturing discriminative object features. Recent approaches combine transfer learning and meta-learning, pre-training feature backbones on labeled base data and fine-tuning on novel data. In this work, we propose a CNN architecture with a cross-scale view of objects and introduce a spatial attention module to mitigate the impact of global average pooling. Our method achieves state-of-the-art results on standard benchmark for the cross-domain (CDFSL) few-shot task, demonstrating its effectiveness.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2189846863",
                        "name": "Yi-Kuan Hsieh"
                    },
                    {
                        "authorId": "144717607",
                        "name": "J. Hsieh"
                    },
                    {
                        "authorId": "2109346348",
                        "name": "Ying-Yu Chen"
                    },
                    {
                        "authorId": "1683948",
                        "name": "Y. Tseng"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5c93b3448f5fcf2a7b7f53644e147b98082acfdf",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-12067",
                    "ArXiv": "2306.12067",
                    "DOI": "10.48550/arXiv.2306.12067",
                    "CorpusId": 259212130
                },
                "corpusId": 259212130,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5c93b3448f5fcf2a7b7f53644e147b98082acfdf",
                "title": "Optimal Algorithms for Stochastic Bilevel Optimization under Relaxed Smoothness Conditions",
                "abstract": "Stochastic Bilevel optimization usually involves minimizing an upper-level (UL) function that is dependent on the arg-min of a strongly-convex lower-level (LL) function. Several algorithms utilize Neumann series to approximate certain matrix inverses involved in estimating the implicit gradient of the UL function (hypergradient). The state-of-the-art StOchastic Bilevel Algorithm (SOBA) [16] instead uses stochastic gradient descent steps to solve the linear system associated with the explicit matrix inversion. This modification enables SOBA to match the lower bound of sample complexity for the single-level counterpart in non-convex settings. Unfortunately, the current analysis of SOBA relies on the assumption of higher-order smoothness for the UL and LL functions to achieve optimality. In this paper, we introduce a novel fully single-loop and Hessian-inversion-free algorithmic framework for stochastic bilevel optimization and present a tighter analysis under standard smoothness assumptions (first-order Lipschitzness of the UL function and second-order Lipschitzness of the LL function). Furthermore, we show that by a slight modification of our approach, our algorithm can handle a more general multi-objective robust bilevel optimization problem. For this case, we obtain the state-of-the-art oracle complexity results demonstrating the generality of both the proposed algorithmic and analytic frameworks. Numerical experiments demonstrate the performance gain of the proposed algorithms over existing ones.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2170123588",
                        "name": "Xuxing Chen"
                    },
                    {
                        "authorId": "134815477",
                        "name": "Tesi Xiao"
                    },
                    {
                        "authorId": "1682978",
                        "name": "K. Balasubramanian"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bc46f63ac3ced5a036c889a4d7ffa237e1014bc6",
                "externalIds": {
                    "ArXiv": "2306.11211",
                    "CorpusId": 259204122
                },
                "corpusId": 259204122,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/bc46f63ac3ced5a036c889a4d7ffa237e1014bc6",
                "title": "A New Simple Stochastic Gradient Descent Type Algorithm With Lower Computational Complexity for Bilevel Optimization",
                "abstract": "Bilevel optimization has been widely used in many machine learning applications such as hyperparameter optimization and meta learning. Recently, many simple stochastic gradient descent(SGD) type algorithms(without using momentum and variance techniques) have been proposed to solve the bilevel optimization problems. However, all the existing simple SGD type algorithms estimate the hypergradient via stochastic estimation of Neumann series. In the paper, we propose to estimate the hypergradient via SGD-based Estimation(i.e., solving the linear system with SGD). By using warm start initialization strategy, a new simple SGD type algorithm SSGD based on SGD-based Estimation is proposed. We provide the convergence rate guarantee for SSGD and show that SSGD outperforms the best known computational complexity achieved by the existing simple SGD type algorithms. Our experiments validate our theoretical results and demonstrate the efficiency of our proposed algorithm SSGD in hyperparameter optimization applications.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2047188524",
                        "name": "Haimei Huo"
                    },
                    {
                        "authorId": "34469457",
                        "name": "Risheng Liu"
                    },
                    {
                        "authorId": "4642456",
                        "name": "Zhixun Su"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "788641d00e7146554c82d586e65a65f50bec5974",
                "externalIds": {
                    "DBLP": "conf/ijcnn/SuC23",
                    "DOI": "10.1109/IJCNN54540.2023.10191886",
                    "CorpusId": 260386427
                },
                "corpusId": 260386427,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/788641d00e7146554c82d586e65a65f50bec5974",
                "title": "CTVAE: Current Task Variational Auto-Encoder with Dynamic Ensemble Loss for Few-Shot Learning",
                "abstract": "Few-shot learning is a challenging task in which a classifier needs to quickly adapt to new classes. These new classes are unseen in the training stage, and there are only very few samples (e.g., five images) provided for learning each new class in the testing stage. When the existing methods learn with such a small amount of samples, they could easily be affected by the outliers. Moreover, the category center calculated from those few samples may deviate from the true center. To address these issues, we propose a novel approach called Current Task Variational Auto-Encoder (CTVAE) for few-shot learning. In our framework, a trained feature extractor first produces the features of the current task, and these features are used to repeatedly train the generator in CTVAE. After that, we can use CTVAE to generate additional features of samples, and then find a new center of the category based on these newly generated features. Compared with the original center, the new center tends to be closer to the true center in vector space. CTVAE can break the limitation of traditional few-shot learning methods, which can only fine-tune the model with very few samples in the testing stage. Moreover, by generating the features directly without producing the images first, the training process of the generator in CTVAE is simplified and becomes more efficient, and the features can be generated faster and more precisely. According to the experiments on benchmark datasets (i.e., Mini-ImageNet, CUB, and CIFAR-FS), our proposed framework is able to outperform the state-of-the-art methods and improves the accuracy by 1\u20134%. We also conduct experiments on the cross-domain tasks, and the results show that the proposed framework can bring 1-5% accuracy improvements.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2093560213",
                        "name": "H. Su"
                    },
                    {
                        "authorId": "2109182290",
                        "name": "Yi-Ling Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There are six methods based on meta-learning, named MAML [23], Versa [24], R2D2 [25], MTL [26], Leo [27],\nand ANIL [28].",
                "The R2D2 [25] proposed used the main adaptation mechanism which based on some fast convergent methods for few-shot learning.",
                "There are six methods based on meta-learning, named MAML [23], Versa [24], R2D2 [25], MTL [26], Leo [27],"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a20dfa9fe97b707333d7c11c26755c06d69a3139",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-09592",
                    "ArXiv": "2306.09592",
                    "DOI": "10.48550/arXiv.2306.09592",
                    "CorpusId": 259187999
                },
                "corpusId": 259187999,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a20dfa9fe97b707333d7c11c26755c06d69a3139",
                "title": "FewSAR: A Few-shot SAR Image Classification Benchmark",
                "abstract": "Few-shot learning (FSL) is one of the significant and hard problems in the field of image classification. However, in contrast to the rapid development of the visible light dataset, the progress in SAR target image classification is much slower. The lack of unified benchmark is a key reason for this phenomenon, which may be severely overlooked by the current literature. The researchers of SAR target image classification always report their new results on their own datasets and experimental setup. It leads to inefficiency in result comparison and impedes the further progress of this area. Motivated by this observation, we propose a novel few-shot SAR image classification benchmark (FewSAR) to address this issue. FewSAR consists of an open-source Python code library of 15 classic methods in three categories for few-shot SAR image classification. It provides an accessible and customizable testbed for different few-shot SAR image classification task. To further understanding the performance of different few-shot methods, we establish evaluation protocols and conduct extensive experiments within the benchmark. By analyzing the quantitative results and runtime under the same setting, we observe that the accuracy of metric learning methods can achieve the best results. Meta-learning methods and fine-tuning methods perform poorly on few-shot SAR images, which is primarily due to the bias of existing datasets. We believe that FewSAR will open up a new avenue for future research and development, on real-world challenges at the intersection of SAR image classification and few-shot deep learning. We will provide our code for the proposed FewSAR at https://github.com/solarlee/FewSAR.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2118404109",
                        "name": "Rui Zhang"
                    },
                    {
                        "authorId": "2117428113",
                        "name": "Ziqi Wang"
                    },
                    {
                        "authorId": "98177814",
                        "name": "Y. Li"
                    },
                    {
                        "authorId": "2115640316",
                        "name": "Jiabao Wang"
                    },
                    {
                        "authorId": "48707983",
                        "name": "Zhiteng Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "A similar model was introduced in [2] but mainly repurposed for classification."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e63ad8570c4f221eed8161f369d348408c0a87b5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-09702",
                    "ArXiv": "2306.09702",
                    "DOI": "10.48550/arXiv.2306.09702",
                    "CorpusId": 259188086
                },
                "corpusId": 259188086,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e63ad8570c4f221eed8161f369d348408c0a87b5",
                "title": "A Hierarchical Bayesian Model for Deep Few-Shot Meta Learning",
                "abstract": "We propose a novel hierarchical Bayesian model for learning with a large (possibly infinite) number of tasks/episodes, which suits well the few-shot meta learning problem. We consider episode-wise random variables to model episode-specific target generative processes, where these local random variables are governed by a higher-level global random variate. The global variable helps memorize the important information from historic episodes while controlling how much the model needs to be adapted to new episodes in a principled Bayesian manner. Within our model framework, the prediction on a novel episode/task can be seen as a Bayesian inference problem. However, a main obstacle in learning with a large/infinite number of local random variables in online nature, is that one is not allowed to store the posterior distribution of the current local random variable for frequent future updates, typical in conventional variational inference. We need to be able to treat each local variable as a one-time iterate in the optimization. We propose a Normal-Inverse-Wishart model, for which we show that this one-time iterate optimization becomes feasible due to the approximate closed-form solutions for the local posterior distributions. The resulting algorithm is more attractive than the MAML in that it is not required to maintain computational graphs for the whole gradient optimization steps per episode. Our approach is also different from existing Bayesian meta learning methods in that unlike dealing with a single random variable for the whole episodes, our approach has a hierarchical structure that allows one-time episodic optimization, desirable for principled Bayesian learning with many/infinite tasks. The code is available at \\url{https://github.com/minyoungkim21/niwmeta}.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2918263",
                        "name": "Minyoung Kim"
                    },
                    {
                        "authorId": "1697755",
                        "name": "Timothy M. Hospedales"
                    }
                ]
            }
        },
        {
            "contexts": [
                "NAO consistently outperforms all few-shot methods on CUB [63] and miniImageNet [62], and reaches comparable results to SeedSelect [49] on CIFARFS [8].",
                "Tables 3a and 3b compare NAO with SoTA approaches on few-shot classification benchmarks: CUB, miniImageNet, and CIFAR-FS.",
                "(3) CIFAR-FS [8]: Created from CIFAR-100 [31] by using the sampling criteria as miniImageNet."
            ],
            "intents": [
                "methodology",
                "result"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6564df461566bec6e5a4debd903933c3d7d5d9b3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-08687",
                    "ArXiv": "2306.08687",
                    "DOI": "10.48550/arXiv.2306.08687",
                    "CorpusId": 259164764
                },
                "corpusId": 259164764,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6564df461566bec6e5a4debd903933c3d7d5d9b3",
                "title": "Norm-guided latent space exploration for text-to-image generation",
                "abstract": "Text-to-image diffusion models show great potential in synthesizing a large variety of concepts in new compositions and scenarios. However, their latent seed space is still not well understood and has been shown to have an impact in generating new and rare concepts. Specifically, simple operations like interpolation and centroid finding work poorly with the standard Euclidean and spherical metrics in the latent space. This paper makes the observation that current training procedures make diffusion models biased toward inputs with a narrow range of norm values. This has strong implications for methods that rely on seed manipulation for image generation that can be further applied to few-shot and long-tail learning tasks. To address this issue, we propose a novel method for interpolating between two seeds and demonstrate that it defines a new non-Euclidean metric that takes into account a norm-based prior on seeds. We describe a simple yet efficient algorithm for approximating this metric and use it to further define centroids in the latent seed space. We show that our new interpolation and centroid evaluation techniques significantly enhance the generation of rare concept images. This further leads to state-of-the-art performance on few-shot and long-tail benchmarks, improving prior approach in terms of generation speed, image quality, and semantic content.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1612410686",
                        "name": "Dvir Samuel"
                    },
                    {
                        "authorId": "1397958297",
                        "name": "Rami Ben-Ari"
                    },
                    {
                        "authorId": "8684542",
                        "name": "N. Darshan"
                    },
                    {
                        "authorId": "2118871788",
                        "name": "Haggai Maron"
                    },
                    {
                        "authorId": "2065001062",
                        "name": "Gal Chechik"
                    }
                ]
            }
        },
        {
            "contexts": [
                "1) More meta-learning instances: We first supplement the results of FoMAML and ProtoNet with a Conv-4 backbone on the mini-ImageNet dataset in Table VI, and then integrate MGAug into more meta-baselines, including Reptile [58], CAVIA [59], MAML [35], R2-D2 [38], and MetaOptNet [39].",
                "This paper focuses on these two meta-learning branches, but our MGAug can also be used for other branches and methods [10] derived from this two-loop framework, such as R2-D2 [38] and MetaOptNet [39]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "65f9782423cc015bab4dcff64a13b6986f925bfb",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-08460",
                    "ArXiv": "2306.08460",
                    "DOI": "10.48550/arXiv.2306.08460",
                    "CorpusId": 259164461
                },
                "corpusId": 259164461,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/65f9782423cc015bab4dcff64a13b6986f925bfb",
                "title": "Improving Generalization in Meta-Learning via Meta-Gradient Augmentation",
                "abstract": "Meta-learning methods typically follow a two-loop framework, where each loop potentially suffers from notorious overfitting, hindering rapid adaptation and generalization to new tasks. Existing schemes solve it by enhancing the mutual-exclusivity or diversity of training samples, but these data manipulation strategies are data-dependent and insufficiently flexible. This work alleviates overfitting in meta-learning from the perspective of gradient regularization and proposes a data-independent \\textbf{M}eta-\\textbf{G}radient \\textbf{Aug}mentation (\\textbf{MGAug}) method. The key idea is to first break the rote memories by network pruning to address memorization overfitting in the inner loop, and then the gradients of pruned sub-networks naturally form the high-quality augmentation of the meta-gradient to alleviate learner overfitting in the outer loop. Specifically, we explore three pruning strategies, including \\textit{random width pruning}, \\textit{random parameter pruning}, and a newly proposed \\textit{catfish pruning} that measures a Meta-Memorization Carrying Amount (MMCA) score for each parameter and prunes high-score ones to break rote memories as much as possible. The proposed MGAug is theoretically guaranteed by the generalization bound from the PAC-Bayes framework. In addition, we extend a lightweight version, called MGAug-MaxUp, as a trade-off between performance gains and resource overhead. Extensive experiments on multiple few-shot learning benchmarks validate MGAug's effectiveness and significant improvement over various meta-baselines. The code is publicly available at \\url{https://github.com/xxLifeLover/Meta-Gradient-Augmentation}.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108876280",
                        "name": "Ren Wang"
                    },
                    {
                        "authorId": "2776765",
                        "name": "Haoliang Sun"
                    },
                    {
                        "authorId": "2114826675",
                        "name": "Qi Wei"
                    },
                    {
                        "authorId": "3082612",
                        "name": "Xiushan Nie"
                    },
                    {
                        "authorId": "1998921670",
                        "name": "Yuling Ma"
                    },
                    {
                        "authorId": "102446355",
                        "name": "Yilong Yin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In the main text, we show examples where the estimand is a given coefficient of a linear regression model (implemented by differentiating through a least-squares solution), and in the Appendix we show results for bounding the coefficient of a logistic regression (implemented via differentiating through an iteratively reweighted least squares solver [31])."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "99c287466a27c91c7f01cee5c2ac564ffccc2a3c",
                "externalIds": {
                    "ArXiv": "2306.03302",
                    "DBLP": "journals/corr/abs-2306-03302",
                    "DOI": "10.48550/arXiv.2306.03302",
                    "CorpusId": 259089208
                },
                "corpusId": 259089208,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/99c287466a27c91c7f01cee5c2ac564ffccc2a3c",
                "title": "Inference under constrained distribution shifts",
                "abstract": "Large-scale administrative or observational datasets are increasingly used to inform decision making. While this effort aims to ground policy in real-world evidence, challenges have arise as that selection bias and other forms of distribution shift often plague observational data. Previous attempts to provide robust inferences have given guarantees depending on a user-specified amount of possible distribution shift (e.g., the maximum KL divergence between the observed and target distributions). However, decision makers will often have additional knowledge about the target distribution which constrains the kind of shifts which are possible. To leverage such information, we proposed a framework that enables statistical inference in the presence of distribution shifts which obey user-specified constraints in the form of functions whose expectation is known under the target distribution. The output is high-probability bounds on the value an estimand takes on the target distribution. Hence, our method leverages domain knowledge in order to partially identify a wide class of estimands. We analyze the computational and statistical properties of methods to estimate these bounds, and show that our method can produce informative bounds on a variety of simulated and semisynthetic tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2219050489",
                        "name": "Santiago Cortes-Gomez"
                    },
                    {
                        "authorId": "47487292",
                        "name": "M. Dulce"
                    },
                    {
                        "authorId": "38105796",
                        "name": "B. Wilder"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In particular, our method is similar to [33] which employ KRR on top of a meta-learned feature map but they do not focus on instances that are sets."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "615543d0a38a0f2e33c268486775607da48f7c35",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-01589",
                    "ArXiv": "2306.01589",
                    "DOI": "10.48550/arXiv.2306.01589",
                    "CorpusId": 259063984
                },
                "corpusId": 259063984,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/615543d0a38a0f2e33c268486775607da48f7c35",
                "title": "Transfer learning for atomistic simulations using GNNs and kernel mean embeddings",
                "abstract": "Interatomic potentials learned using machine learning methods have been successfully applied to atomistic simulations. However, deep learning pipelines are notoriously data-hungry, while generating reference calculations is computationally demanding. To overcome this difficulty, we propose a transfer learning algorithm that leverages the ability of graph neural networks (GNNs) in describing chemical environments, together with kernel mean embeddings. We extract a feature map from GNNs pre-trained on the OC20 dataset and use it to learn the potential energy surface from system-specific datasets of catalytic processes. Our method is further enhanced by a flexible kernel function that incorporates chemical species information, resulting in improved performance and interpretability. We test our approach on a series of realistic datasets of increasing complexity, showing excellent generalization and transferability performance, and improving on methods that rely on GNNs or ridge regression alone, as well as similar fine-tuning approaches. We make the code available to the community at https://github.com/IsakFalk/atomistic_transfer_mekrr.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2155835758",
                        "name": "Johannes Falk"
                    },
                    {
                        "authorId": "4931649",
                        "name": "L. Bonati"
                    },
                    {
                        "authorId": "102491837",
                        "name": "P. Novelli"
                    },
                    {
                        "authorId": "1398372191",
                        "name": "Michele Parinello"
                    },
                    {
                        "authorId": "1704699",
                        "name": "M. Pontil"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Before CLIP emerged, Jeong et al. [20] addressed the few-shot OOD detection, using only a few ID training data for OOD detection, but their experiments have only been done on small data sets (e.g., Omniglot [25], CIFAR-FS [3]), showing the limitations of the performances of few-shot learning methods without CLIP.",
                ", Omniglot [25], CIFAR-FS [3]), showing the limitations of the performances of few-shot learning methods without CLIP."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "89fcc2901981a7b6462f874894688dd2a3ce9095",
                "externalIds": {
                    "ArXiv": "2306.01293",
                    "DBLP": "journals/corr/abs-2306-01293",
                    "DOI": "10.48550/arXiv.2306.01293",
                    "CorpusId": 259063871
                },
                "corpusId": 259063871,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/89fcc2901981a7b6462f874894688dd2a3ce9095",
                "title": "LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning",
                "abstract": "We present a novel vision-language prompt learning approach for few-shot out-of-distribution (OOD) detection. Few-shot OOD detection aims to detect OOD images from classes that are unseen during training using only a few labeled in-distribution (ID) images. While prompt learning methods such as CoOp have shown effectiveness and efficiency in few-shot ID classification, they still face limitations in OOD detection due to the potential presence of ID-irrelevant information in text embeddings. To address this issue, we introduce a new approach called Local regularized Context Optimization (LoCoOp), which performs OOD regularization that utilizes the portions of CLIP local features as OOD features during training. CLIP's local features have a lot of ID-irrelevant nuisances (e.g., backgrounds), and by learning to push them away from the ID class text embeddings, we can remove the nuisances in the ID class text embeddings and enhance the separation between ID and OOD. Experiments on the large-scale ImageNet OOD detection benchmarks demonstrate the superiority of our LoCoOp over zero-shot, fully supervised detection methods and prompt learning methods. Notably, even in a one-shot setting -- just one label per class, LoCoOp outperforms existing zero-shot and fully supervised detection methods. The code will be available via https://github.com/AtsuMiyai/LoCoOp.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2188735058",
                        "name": "Atsuyuki Miyai"
                    },
                    {
                        "authorId": "2087411522",
                        "name": "Qing Yu"
                    },
                    {
                        "authorId": "144990548",
                        "name": "Go Irie"
                    },
                    {
                        "authorId": "1712839",
                        "name": "K. Aizawa"
                    }
                ]
            }
        },
        {
            "contexts": [
                "tion networks [17], R2D2 [62], SNAIL [63], AdaResNet [64], and RFS [21].",
                "The contrasted\nones include MAML [56], Matching networks [12], IMP [18], Prototypical networks [7], TAML [57], SAML [19], GCR [58], KTN (Visual) [59], PARN [60], Dynamic few-shot [61], Relation networks [17], R2D2 [62], SNAIL [63], AdaResNet [64], and RFS [21]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d4f87aec1c491c4f68a460ffc734d756f660aa46",
                "externalIds": {
                    "DBLP": "journals/tai/LiWSYW23",
                    "DOI": "10.1109/TAI.2022.3169463",
                    "CorpusId": 258870210
                },
                "corpusId": 258870210,
                "publicationVenue": {
                    "id": "3c27e831-750f-45bc-9914-2148a5259eba",
                    "name": "IEEE Transactions on Artificial Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Artif Intell"
                    ],
                    "issn": "2691-4581",
                    "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=9078688"
                },
                "url": "https://www.semanticscholar.org/paper/d4f87aec1c491c4f68a460ffc734d756f660aa46",
                "title": "Efficient Few-Shot Classification via Contrastive Pretraining on Web Data",
                "abstract": "Few-shot classification is challenging due to the limited data and labels. The existing algorithms usually resolve this problem by pretraining models with a considerable amount of annotated data, which share knowledge with the target domain. Nevertheless, large quantities of homogenous data samples are not always available. To tackle this obstacle, we develop a few-shot learning framework that prepares data automatically and still produces well-behaved models. This framework is implemented through conducting contrastive learning on unlabeled web images. Instead of requiring manually annotated data, this framework trains models via constructing pseudolabels. Additionally, since online data are virtually limitless and continue to be generated, the model can, thus, be empowered to constantly obtain up-to-date knowledge from the Internet. Furthermore, we observe that the generalization ability of learned representation is crucial for self-supervised learning. To present its importance, a naive yet efficient normalization strategy is proposed. Consequentially, this strategy boosts the accuracy of trained models significantly. We demonstrate the superiority of the proposed framework with experiments on miniImageNet, tieredImageNet, and Omniglot. The results indicate that our method has surpassed previous unsupervised counterparts by large margins and obtained performance comparable with some supervised ones.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2118390512",
                        "name": "Zhuoling Li"
                    },
                    {
                        "authorId": "49528192",
                        "name": "Haohan Wang"
                    },
                    {
                        "authorId": "2051501958",
                        "name": "Tymoteusz \u015awistek"
                    },
                    {
                        "authorId": "2054414548",
                        "name": "En Yu"
                    },
                    {
                        "authorId": "2143410777",
                        "name": "Haoqian Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a557f42eb0e32e9614d631b2271b36c5cea707d2",
                "externalIds": {
                    "ArXiv": "2306.00618",
                    "DBLP": "journals/corr/abs-2306-00618",
                    "DOI": "10.48550/arXiv.2306.00618",
                    "CorpusId": 258999878
                },
                "corpusId": 258999878,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a557f42eb0e32e9614d631b2271b36c5cea707d2",
                "title": "Effective Structured Prompting by Meta-Learning and Representative Verbalizer",
                "abstract": "Prompt tuning for pre-trained masked language models (MLM) has shown promising performance in natural language processing tasks with few labeled examples. It tunes a prompt for the downstream task, and a verbalizer is used to bridge the predicted token and label prediction. Due to the limited training data, prompt initialization is crucial for prompt tuning. Recently, MetaPrompting (Hou et al., 2022) uses meta-learning to learn a shared initialization for all task-specific prompts. However, a single initialization is insufficient to obtain good prompts for all tasks and samples when the tasks are complex. Moreover, MetaPrompting requires tuning the whole MLM, causing a heavy burden on computation and memory as the MLM is usually large. To address these issues, we use a prompt pool to extract more task knowledge and construct instance-dependent prompts via attention. We further propose a novel soft verbalizer (RepVerb) which constructs label embedding from feature embeddings directly. Combining meta-learning the prompt pool and RepVerb, we propose MetaPrompter for effective structured prompting. MetaPrompter is parameter-efficient as only the pool is required to be tuned. Experimental results demonstrate that MetaPrompter performs better than the recent state-of-the-arts and RepVerb outperforms existing soft verbalizers.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2152123946",
                        "name": "Weisen Jiang"
                    },
                    {
                        "authorId": "2153638098",
                        "name": "Yu Zhang"
                    },
                    {
                        "authorId": "145193332",
                        "name": "J. Kwok"
                    }
                ]
            }
        },
        {
            "contexts": [
                "10 Effective for Other FSL Classifiers?: In Table V, we additional select three FSL classifiers, including logistic regression [9], ridge regression [57], and SVM [67], to analyze the effectiveness of the proposed fusion strategy.",
                "HERE, \u201cCC\u201d, \u201cLR\u201d, \u201cRR\u201d, AND \u201cSVM\u201d DENOTES THE COSINE [11], LOGISTIC REGRESSION [9], RIDGE REGRESSION [57], AND SVM [67] CLASSIFIERS, RESPECTIVELY",
                "Following [57], we split it into 64 classes for training, 16 classes for validation, and 20 classes for test, respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5a35808999e06f617753c4a878f50e55375602f0",
                "externalIds": {
                    "DBLP": "journals/tcsv/ZhangJLFYLY23",
                    "DOI": "10.1109/TCSVT.2022.3227574",
                    "CorpusId": 254492599
                },
                "corpusId": 254492599,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/5a35808999e06f617753c4a878f50e55375602f0",
                "title": "MetaDT: Meta Decision Tree With Class Hierarchy for Interpretable Few-Shot Learning",
                "abstract": "Few-Shot Learning (FSL) is a challenging task, which aims to recognize novel classes with few examples. Recently, lots of methods have been proposed from the perspective of meta-learning and representation learning. However, few works focus on the interpretability of FSL decision process. In this paper, we take a step towards the interpretable FSL by proposing a novel meta-learning based decision tree framework, namely, MetaDT. In particular, the FSL interpretability is achieved from two aspects, i.e., a concept aspect and a visual aspect. On the concept aspect, we first introduce a tree-like concept hierarchy as FSL prior. Then, resorting to the prior, we split each few-shot task to a set of subtasks with different concept levels and then perform class prediction via a model of decision tree. The advantage of such design is that a sequence of high-level concept decisions that lead up to a final class prediction can be obtained, which clarifies the FSL decision process. On the visual aspect, a set of subtask-specific classifiers with visual attention mechanism is designed to perform decision at each node of the decision tree. As a result, a subtask-specific heatmap visualization can be obtained to achieve the decision interpretability of each tree node. At last, to alleviate the data scarcity issue of FSL, we regard the prior of concept hierarchy as an undirected graph, and then design a graph convolution-based decision tree inference network as our meta-learner to infer parameters of the decision tree. Extensive experiments on performance comparison and interpretability analysis show superiority of our MetaDT.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "121178411",
                        "name": "Baoquan Zhang"
                    },
                    {
                        "authorId": "47067803",
                        "name": "Hao Jiang"
                    },
                    {
                        "authorId": "48569885",
                        "name": "Xutao Li"
                    },
                    {
                        "authorId": "2903685",
                        "name": "Shanshan Feng"
                    },
                    {
                        "authorId": "144782498",
                        "name": "Yunming Ye"
                    },
                    {
                        "authorId": "2112753771",
                        "name": "Chen Luo"
                    },
                    {
                        "authorId": "143932236",
                        "name": "Rui Ye"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "34cef1657203059ac509db43e92db4341aaa030f",
                "externalIds": {
                    "DBLP": "journals/tamd/WangLZ0LSZZ23",
                    "DOI": "10.1109/TCDS.2022.3187216",
                    "CorpusId": 259123262
                },
                "corpusId": 259123262,
                "publicationVenue": {
                    "id": "f35f148a-0a3c-45db-b610-3d89e09ddf21",
                    "name": "IEEE Transactions on Cognitive and Developmental Systems",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Cogn Dev Syst"
                    ],
                    "issn": "2379-8920",
                    "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7274989"
                },
                "url": "https://www.semanticscholar.org/paper/34cef1657203059ac509db43e92db4341aaa030f",
                "title": "Bidirectional Gated Edge-Labeling Graph Recurrent Neural Network for Few-Shot Learning",
                "abstract": "Many existing graph-based methods for few-shot learning problem focused on either separately learning node features or edge features or simply utilizing graph convolution, failing to fully retain or exploit graph structure information. In this article, we proposed a bidirectional gated edge-labeling graph recurrent neural network (bi-GEGRN) which adopts both edge-labeling graph framework and graph convolution operation in the meta-learning scheme. We modified the gated graph neural network to adjacency matrix generator-based bidirectional formation which is able to process sequence graph data in two directions and then organically combined it with edge-labeled graph framework to cyclically upgrade features meanwhile aggregate graph structure information. In view of the excellent aggregating capability of graph convolution and good performance of the alternately cyclic update strategy, bi-GEGRN improves the information transferring between tasks in meta learning. To verify the validity and universality on both supervised and semi-supervised regimes, extensive experiments were conducted on three few-shot benchmark data sets and bi-GEGRN showed a good performance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2208546595",
                        "name": "Qian Wang"
                    },
                    {
                        "authorId": "144125487",
                        "name": "H. Ling"
                    },
                    {
                        "authorId": "2118874391",
                        "name": "Baiyan Zhang"
                    },
                    {
                        "authorId": "144785138",
                        "name": "Ping Li"
                    },
                    {
                        "authorId": "2118207869",
                        "name": "Zongyi Li"
                    },
                    {
                        "authorId": "1753219181",
                        "name": "Yuxuan Shi"
                    },
                    {
                        "authorId": "103941067",
                        "name": "Chengxin Zhao"
                    },
                    {
                        "authorId": "2152873060",
                        "name": "Chuang Zhao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "338ec864a6a184269a627850c6d266bf3b8bddbc",
                "externalIds": {
                    "DOI": "10.1016/j.saa.2023.123085",
                    "CorpusId": 259583417,
                    "PubMed": "37454497"
                },
                "corpusId": 259583417,
                "publicationVenue": {
                    "id": "5bc5dd42-09ab-4ce7-bf5b-8355ee95577c",
                    "name": "Spectrochimica Acta Part A - Molecular and Biomolecular Spectroscopy",
                    "type": "journal",
                    "alternate_names": [
                        "Spectrochim Acta Part  Mol Biomol Spectrosc",
                        "Spectrochim Acta Part Mol Biomol Spectrosc",
                        "Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy"
                    ],
                    "issn": "1386-1425",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525436/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/13861425",
                        "http://www.journals.elsevier.com/spectrochimica-acta-part-a-molecular-and-biomolecular-spectroscopy",
                        "https://www.journals.elsevier.com/spectrochimica-acta-part-a-molecular-and-biomolecular-spectroscopy"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/338ec864a6a184269a627850c6d266bf3b8bddbc",
                "title": "Deep metric learning framework combined with Gramian angular difference field image generation for Raman spectra classification based on a handheld Raman spectrometer.",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "9310153",
                        "name": "Yaoyi Cai"
                    },
                    {
                        "authorId": "2192040187",
                        "name": "Zekai Yao"
                    },
                    {
                        "authorId": "2221869851",
                        "name": "Xi Cheng"
                    },
                    {
                        "authorId": "2118917694",
                        "name": "Yixuan He"
                    },
                    {
                        "authorId": "1998361676",
                        "name": "Shiwen Li"
                    },
                    {
                        "authorId": "2222409116",
                        "name": "Jiaji Pan"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "229ac65cace43acfbf2b27d0f36b2865845e0183",
                "externalIds": {
                    "DBLP": "conf/cvpr/WangZZCC023",
                    "DOI": "10.1109/CVPR52729.2023.00756",
                    "CorpusId": 261081689
                },
                "corpusId": 261081689,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/229ac65cace43acfbf2b27d0f36b2865845e0183",
                "title": "Improving Generalization of Meta-Learning with Inverted Regularization at Inner-Level",
                "abstract": "Despite the broad interest in meta-learning, the generalization problem remains one of the significant challenges in this field. Existing works focus on meta-generalization to unseen tasks at the meta-level by regularizing the meta-loss, while ignoring that adapted models may not generalize to the task domains at the adaptation level. In this paper, we propose a new regularization mechanism for meta-learning - Minimax-Meta Regularization, which employs inverted regularization at the inner loop and ordinary regularization at the outer loop during training. In particular, the inner inverted regularization makes the adapted model more difficult to generalize to task domains; thus, optimizing the outer-loop loss forces the meta-model to learn meta-knowledge with better generalization. Theoretically, we prove that inverted regularization improves the meta-testing performance by reducing generalization errors. We conduct extensive experiments on the representative scenarios, and the results show that our method consistently improves the performance of meta-learning algorithms.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2233281230",
                        "name": "Lianzhe Wang"
                    },
                    {
                        "authorId": "2149195194",
                        "name": "Shiji Zhou"
                    },
                    {
                        "authorId": "2437353",
                        "name": "Shanghang Zhang"
                    },
                    {
                        "authorId": "2056598391",
                        "name": "Xu Chu"
                    },
                    {
                        "authorId": "144188238",
                        "name": "Heng Chang"
                    },
                    {
                        "authorId": "2156154955",
                        "name": "Wenwu Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The CIFAR-FS [40] contains 32 \u00d7 32 images from CIFAR-100 [41] that are divided into 100 classes and each class contains 600 images.",
                "We use miniImageNet [4], tiered-ImageNet [45] and CIFAR-FS [40] as the datasets in our experiments."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8ea3da744caaa48eb5b5d342d8e80f38de07bb52",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-18970",
                    "ArXiv": "2305.18970",
                    "DOI": "10.48550/arXiv.2305.18970",
                    "CorpusId": 258967514
                },
                "corpusId": 258967514,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8ea3da744caaa48eb5b5d342d8e80f38de07bb52",
                "title": "Few-shot Classification with Shrinkage Exemplars",
                "abstract": "Prototype is widely used to represent internal structure of category for few-shot learning, which was proposed as a simple inductive bias to address the issue of overfitting. However, since prototype representation is normally averaged from individual samples, it cannot flexibly adjust the retention ability of sample differences that may leads to underfitting in some cases of sample distribution. To address this problem, in this work, we propose Shrinkage Exemplar Networks (SENet) for few-shot classification. SENet balances the prototype representations (high-bias, low-variance) and example representations (low-bias, high-variance) using a shrinkage estimator, where the categories are represented by the embedings of samples that shrink to their mean via spectral filtering. Furthermore, a shrinkage exemplar loss is proposed to replace the widely used cross entropy loss for capturing the information of individual shrinkage samples. Several experiments were conducted on miniImageNet, tiered-ImageNet and CIFAR-FS datasets. We demonstrate that our proposed model is superior to the example model and the prototype model for some tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2146342045",
                        "name": "Tao Zhang"
                    },
                    {
                        "authorId": "9393382",
                        "name": "Wu Huang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2022 CIFAR100 Few-Shots (CIFAR-FS) [33] is randomly split from CIFAR-100 [34] dataset.",
                "The study evaluated the effectiveness of the bias prediction network across multiple benchmark datasets, including miniImageNet, CIFAR-FS, FC-100, and Adience , employing five-way one-shot and five-way five-shot learning settings."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fe832d3090a06a40412ef7855813b59282e073c0",
                "externalIds": {
                    "DOI": "10.3390/electronics12112470",
                    "CorpusId": 259005472
                },
                "corpusId": 259005472,
                "publicationVenue": {
                    "id": "ccd8e532-73c6-414f-bc91-271bbb2933e2",
                    "name": "Electronics",
                    "type": "journal",
                    "issn": "1450-5843",
                    "alternate_issns": [
                        "2079-9292",
                        "0883-4989"
                    ],
                    "url": "http://www.electronics.etfbl.net/",
                    "alternate_urls": [
                        "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-247562",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-247562",
                        "https://www.mdpi.com/journal/electronics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fe832d3090a06a40412ef7855813b59282e073c0",
                "title": "Dataset Bias Prediction for Few-Shot Image Classification",
                "abstract": "Dataset bias is a significant obstacle that negatively affects image classification performance, especially in few-shot learning, where datasets have limited samples per class. However, few studies have focused on this issue. To address this, we propose a bias prediction network that recovers biases such as color from the extracted features of image data, resulting in performance improvement in few-shot image classification. If the network can easily recover the bias, the extracted features may contain the bias. Therefore, the whole framework is trained to extract features that are difficult for the bias prediction network to recover. We evaluate our method by integrating it with several existing few-shot learning models across multiple benchmark datasets. The results show that the proposed network can improve the performance in different scenarios. The proposed approach effectively reduces the negative effect of the dataset bias, resulting in the performance improvements in few-shot image classification. The proposed bias prediction model is easily compatible with other few-shot learning models, and applicable to various real-world applications where biased samples are prevalent, such as VR/AR systems and computer vision applications.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2218843594",
                        "name": "Jang Wook Kim"
                    },
                    {
                        "authorId": "2110044122",
                        "name": "S. Kim"
                    },
                    {
                        "authorId": "2892216",
                        "name": "Kyung-ah Sohn"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We evaluate our BiDfMKD framework on the meta-testing subsets of CIFARFS (Bertinetto et al., 2018), MiniImageNet (Vinyals et al.",
                "Datasets for Meta Testing\nCIFAR-FS (Bertinetto et al., 2018), MiniImageNet (Vinyals et al., 2016) are commonly used in meta-learning, consisting of 100 classes with 600 images per class.",
                "We evaluate our BiDfMKD framework on the meta-testing subsets of CIFARFS (Bertinetto et al., 2018), MiniImageNet (Vinyals et al., 2016), and CUB-200-2011 (CUB) (Wah et al., 2011).",
                "For benchmarks of three scenarios on CIFARFS, MiniImageNet and CUB, our framework achieves significant performance gains in the range of 8.09% to 21.46%."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "a81f15cac6934323b70ea129fff90724f0d97525",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-18413",
                    "ArXiv": "2305.18413",
                    "DOI": "10.48550/arXiv.2305.18413",
                    "CorpusId": 258967892
                },
                "corpusId": 258967892,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a81f15cac6934323b70ea129fff90724f0d97525",
                "title": "Learning to Learn from APIs: Black-Box Data-Free Meta-Learning",
                "abstract": "Data-free meta-learning (DFML) aims to enable efficient learning of new tasks by meta-learning from a collection of pre-trained models without access to the training data. Existing DFML work can only meta-learn from (i) white-box and (ii) small-scale pre-trained models (iii) with the same architecture, neglecting the more practical setting where the users only have inference access to the APIs with arbitrary model architectures and model scale inside. To solve this issue, we propose a Bi-level Data-free Meta Knowledge Distillation (BiDf-MKD) framework to transfer more general meta knowledge from a collection of black-box APIs to one single meta model. Specifically, by just querying APIs, we inverse each API to recover its training data via a zero-order gradient estimator and then perform meta-learning via a novel bi-level meta knowledge distillation structure, in which we design a boundary query set recovery technique to recover a more informative query set near the decision boundary. In addition, to encourage better generalization within the setting of limited API budgets, we propose task memory replay to diversify the underlying task distribution by covering more interpolated tasks. Extensive experiments in various real-world scenarios show the superior performance of our BiDf-MKD framework.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1557412467",
                        "name": "Zixuan Hu"
                    },
                    {
                        "authorId": "2144035454",
                        "name": "Li Shen"
                    },
                    {
                        "authorId": "2920297",
                        "name": "Zhenyi Wang"
                    },
                    {
                        "authorId": "143905981",
                        "name": "Baoyuan Wu"
                    },
                    {
                        "authorId": "2117728946",
                        "name": "Chun Yuan"
                    },
                    {
                        "authorId": "2135519749",
                        "name": "Dacheng Tao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS (CIFAR100 few-shots) [63] is randomly sampled from CIFAR-100 [64] in the same way that miniImageNet has been generated."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "cd85303ebd0e73e70416623044c1615911f4e418",
                "externalIds": {
                    "DBLP": "journals/nca/ZhangG23",
                    "DOI": "10.1007/s00521-023-08645-3",
                    "CorpusId": 258963547
                },
                "corpusId": 258963547,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/cd85303ebd0e73e70416623044c1615911f4e418",
                "title": "Task-aware prototype refinement for improved few-shot learning",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "143715293",
                        "name": "W. Zhang"
                    },
                    {
                        "authorId": "2118712301",
                        "name": "X. Gu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9449fa15622257e81e429903535433d3a2ece6f6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-17368",
                    "ArXiv": "2305.17368",
                    "DOI": "10.48550/arXiv.2305.17368",
                    "CorpusId": 258960645
                },
                "corpusId": 258960645,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/9449fa15622257e81e429903535433d3a2ece6f6",
                "title": "Instance-based Max-margin for Practical Few-shot Recognition",
                "abstract": "In order to mimic the human few-shot learning (FSL) ability better and to make FSL closer to real-world applications, this paper proposes a practical FSL (pFSL) setting. pFSL is based on unsupervised pretrained models (analogous to human prior knowledge) and recognizes many novel classes simultaneously. Compared to traditional FSL, pFSL is simpler in its formulation, easier to evaluate, more challenging and more practical. To cope with the rarity of training examples, this paper proposes IbM2, an instance-based max-margin method not only for the new pFSL setting, but also works well in traditional FSL scenarios. Based on the Gaussian Annulus Theorem, IbM2 converts random noise applied to the instances into a mechanism to achieve maximum margin in the many-way pFSL (or traditional FSL) recognition task. Experiments with various self-supervised pretraining methods and diverse many- or few-way FSL tasks show that IbM2 almost always leads to improvements compared to its respective baseline methods, and in most cases the improvements are significant. With both the new pFSL setting and novel IbM2 method, this paper shows that practical few-shot learning is both viable and promising.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2158818865",
                        "name": "Minghao Fu"
                    },
                    {
                        "authorId": "2113841905",
                        "name": "Kevin Zhu"
                    },
                    {
                        "authorId": "2155449887",
                        "name": "Jianxin Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Datasets: We validate our framework on the following datasets, i.e., miniImageNet[13], CUB-200-2001[14], and CIFAR-FS[15].",
                "Moreover, our network is better for both coarse-grained classification[13, 15] and fine-grained classification[14].",
                "Restrictions apply.\nwe also used the CIFAR-FS datasets, a variant of the CIFAR100 datasets.",
                ", miniImageNet[13], CUB-200-2001[14], and CIFAR-FS[15]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "a612698c8fdd031d0c267709ee1ba44076314522",
                "externalIds": {
                    "DBLP": "conf/cscwd/LiH023",
                    "DOI": "10.1109/CSCWD57460.2023.10152000",
                    "CorpusId": 259235420
                },
                "corpusId": 259235420,
                "publicationVenue": {
                    "id": "a966c5e8-76dc-45c0-942a-3c7e41ac9b1a",
                    "name": "International Conference on Computer Supported Cooperative Work in Design",
                    "type": "conference",
                    "alternate_names": [
                        "Computer Supported Cooperative Work in Design",
                        "Int Conf Comput Support Cooperative Work Des",
                        "CSCWD",
                        "Comput Support Cooperative Work Des"
                    ],
                    "url": "http://www.cscwd.org/"
                },
                "url": "https://www.semanticscholar.org/paper/a612698c8fdd031d0c267709ee1ba44076314522",
                "title": "A Self-Attention Based Task-Adaptive Integration of Pre-trained Global and Local Classifiers for Few-Shot Classification",
                "abstract": "The few-shot image classification task aims to train a model to correctly classify unlabeled samples when only a few example images are available. Most current metric-based approaches consider only a single task and ignore the variability between tasks. In this paper, we extract potential information of images from both local and global levels by training feature extractors sensitive to global and local features. Then, the multilevel features are optimized further by employing a self-attention mechanism to assign suitable weights based on the target tasks\u2019 characteristics. Extensive experiments on several benchmark datasets show that the proposed model has better generalization ability for different tasks, and our strategy improves by 4%~6% over the baseline, showing satisfactory results. Our code is available at: https://github.com/XiangLi0503/MTnet.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2144438953",
                        "name": "Xiang Li"
                    },
                    {
                        "authorId": "34172443",
                        "name": "Renjie Huang"
                    },
                    {
                        "authorId": "1767696",
                        "name": "Guoqiang Xiao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As expected, the imbalance is severe; yet such condition is rare in computer vision scenarios, especially in metalearning settings\u2014typical FSL datasets like Omniglot [39], miniImageNet [40] and CIFAR-FS [41] have all \u03c1=1."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dea00783b876b41e852adc0ad1954e1005324edd",
                "externalIds": {
                    "ArXiv": "2305.12432",
                    "DBLP": "conf/tma/GuarinoWFPR23",
                    "DOI": "10.23919/TMA58422.2023.10198965",
                    "CorpusId": 258833374
                },
                "corpusId": 258833374,
                "publicationVenue": {
                    "id": "f3f5580f-aba5-410b-921c-971d6f31b7b1",
                    "name": "Traffic Monitoring and Analysis",
                    "type": "conference",
                    "alternate_names": [
                        "Traffic Monit Anal",
                        "TMA"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dea00783b876b41e852adc0ad1954e1005324edd",
                "title": "Many or Few Samples?: Comparing Transfer, Contrastive and Meta-Learning in Encrypted Traffic Classification",
                "abstract": "The popularity of Deep Learning (DL), coupled with network traffic visibility reduction due to the increased adoption of HTTPS, QUIC, and DNS-SEC, re-ignited interest towards Traffic Classification (TC). However, to tame the dependency from task-specific large labeled datasets, we need to find better ways to learn representations that are valid across tasks. In this work we investigate this problem comparing transfer learning, meta-learning and contrastive learning against reference Machine Learning (ML) tree-based and monolithic DL models (16 methods total). Using two publicly available datasets, namely MIRAGE19 (40 classes) and AppClassNet (500 classes), we show that ($i$) by using DL methods on large datasets we can obtain more general representations with (i i) contrastive learning methods yielding the best performance and (iii) meta-learning the worst one. While (iv) tree-based models can be impractical for large tasks but fit well small tasks, (v) DL methods that reuse better learned representations are closing their performance gap against trees also for small tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2140634714",
                        "name": "Idio Guarino"
                    },
                    {
                        "authorId": "2144447867",
                        "name": "Chao Wang"
                    },
                    {
                        "authorId": "2835398",
                        "name": "A. Finamore"
                    },
                    {
                        "authorId": "30487203",
                        "name": "A. Pescap\u00e9"
                    },
                    {
                        "authorId": "1878342442",
                        "name": "Dario Rossi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Here, Ours, DR-CFS, DR-ML, and Meta-CI perform meta-learning; DR-ML and Meta-CI employ model-agnostic meta-learning [11], Ours and DR-CFS are founded on the model choice that yields closed-form solvers for task adaptation [5, 35].",
                "We formulate outcome model \u03bca and pseudo outcome model \u03c4 using task-shared encoders with the task-specific last linear layer [5]:",
                "This advantage is crucial in meta-learning because the recent studies show that the closed-form solvers for task adaptation can greatly improve the classification and regression performances [35, 5].",
                "Whereas there are several closed-form solvers in the field of meta-learning [35, 5, 26, 16], none of them can be directly applied to training the models in meta-learners, which are founded on the two-stage-based estimation, where the outputs of one regression model are used for training another regression model.",
                "(13, 14), which can be O(N s3 a ) and O(N ) using the Woodbury formula [5]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "4d0a6ff6066c017f45b8954d9fdbbfa45c7765c0",
                "externalIds": {
                    "ArXiv": "2305.11353",
                    "DBLP": "journals/corr/abs-2305-11353",
                    "DOI": "10.48550/arXiv.2305.11353",
                    "CorpusId": 258823406
                },
                "corpusId": 258823406,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4d0a6ff6066c017f45b8954d9fdbbfa45c7765c0",
                "title": "Meta-learning for heterogeneous treatment effect estimation with closed-form solvers",
                "abstract": "This article proposes a meta-learning method for estimating the conditional average treatment effect (CATE) from a few observational data. The proposed method learns how to estimate CATEs from multiple tasks and uses the knowledge for unseen tasks. In the proposed method, based on the meta-learner framework, we decompose the CATE estimation problem into sub-problems. For each sub-problem, we formulate our estimation models using neural networks with task-shared and task-specific parameters. With our formulation, we can obtain optimal task-specific parameters in a closed form that are differentiable with respect to task-shared parameters, making it possible to perform effective meta-learning. The task-shared parameters are trained such that the expected CATE estimation performance in few-shot settings is improved by minimizing the difference between a CATE estimated with a large amount of data and one estimated with just a few data. Our experimental results demonstrate that our method outperforms the existing meta-learning approaches and CATE estimation methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2664600",
                        "name": "Tomoharu Iwata"
                    },
                    {
                        "authorId": "3149225",
                        "name": "Yoichi Chikahara"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Researchers explore meta-learning to find well-initialized models suitable for adaptation [5,31,66], or compensate for the data insufficiency in few-shot settings by data augmentation [3, 40]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "02e376e249166b1981cb1bafa79e45ac26a41576",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-11439",
                    "ArXiv": "2305.11439",
                    "DOI": "10.1109/CVPR52729.2023.02245",
                    "CorpusId": 258823403
                },
                "corpusId": 258823403,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/02e376e249166b1981cb1bafa79e45ac26a41576",
                "title": "Few-Shot Learning with Visual Distribution Calibration and Cross-Modal Distribution Alignment",
                "abstract": "Pre-trained vision-language models have inspired much research on few-shot learning. However, with only a few training images, there exist two crucial problems: (1) the visual feature distributions are easily distracted by class-irrelevant information in images, and (2) the alignment between the visual and language feature distributions is difficult. To deal with the distraction problem, we propose a Selective Attack module, which consists of trainable adapters that generate spatial attention maps of images to guide the attacks on class-irrelevant image areas. By messing up these areas, the critical features are captured and the visual distributions of image features are calibrated. To better align the visual and language feature distributions that describe the same object class, we propose a cross-modal distribution alignment module, in which we introduce a vision-language prototype for each class to align the distributions, and adopt the Earth Mover's Distance (EMD) to optimize the prototypes. For efficient computation, the upper bound of EMD is derived. In addition, we propose an augmentation strategy to increase the diversity of the images and the text prompts, which can reduce overfitting to the few-shot training images. Extensive experiments on 11 datasets demonstrate that our method consistently outperforms prior arts in few-shot learning. The implementation code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/SADA.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2041702379",
                        "name": "Runqi Wang"
                    },
                    {
                        "authorId": "152514378",
                        "name": "Hao Zheng"
                    },
                    {
                        "authorId": "2067781481",
                        "name": "Xiaoyue Duan"
                    },
                    {
                        "authorId": "2144167531",
                        "name": "Jianzhuang Liu"
                    },
                    {
                        "authorId": "2159316456",
                        "name": "Yuning Lu"
                    },
                    {
                        "authorId": "2155412746",
                        "name": "Tian Wang"
                    },
                    {
                        "authorId": "2110690539",
                        "name": "Songcen Xu"
                    },
                    {
                        "authorId": "1740430",
                        "name": "Baochang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Another model with an embedded differentiable iterative solver is introduced by (Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "38a5867c87a4a26e8757c975a3349bc0302e640c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-10203",
                    "ArXiv": "2305.10203",
                    "DOI": "10.48550/arXiv.2305.10203",
                    "CorpusId": 258741285
                },
                "corpusId": 258741285,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/38a5867c87a4a26e8757c975a3349bc0302e640c",
                "title": "Exploring the Space of Key-Value-Query Models with Intention",
                "abstract": "Attention-based models have been a key element of many recent breakthroughs in deep learning. Two key components of Attention are the structure of its input (which consists of keys, values and queries) and the computations by which these three are combined. In this paper we explore the space of models that share said input structure but are not restricted to the computations of Attention. We refer to this space as Keys-Values-Queries (KVQ) Space. Our goal is to determine whether there are any other stackable models in KVQ Space that Attention cannot efficiently approximate, which we can implement with our current deep learning toolbox and that solve problems that are interesting to the community. Maybe surprisingly, the solution to the standard least squares problem satisfies these properties. A neural network module that is able to compute this solution not only enriches the set of computations that a neural network can represent but is also provably a strict generalisation of Linear Attention. Even more surprisingly the computational complexity of this module is exactly the same as that of Attention, making it a suitable drop in replacement. With this novel connection between classical machine learning (least squares) and modern deep learning (Attention) established we justify a variation of our model which generalises regular Attention in the same way. Both new modules are put to the test an a wide spectrum of tasks ranging from few-shot learning to policy distillation that confirm their real-worlds applicability.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3468254",
                        "name": "M. Garnelo"
                    },
                    {
                        "authorId": "144792148",
                        "name": "Wojciech M. Czarnecki"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In addition to comparing with ProtoNet [18] and R2D2 [109] on their original small backbones, we also compare with\nboth methods with larger convolutional backbones, i.e., ResNet-12.",
                "Interestingly, ProtoNet and R2D2 both show competitive results, and especially R2D2 already performs better than MetaOptNet on CIFAR-FS.",
                "We consider four typical meta-learning methods: MAML [17], ProtoNet [18], R2D2 [109], and MetaOptNet [119] with SOTA performance.",
                "In addition to comparing with ProtoNet [18] and R2D2 [109] on their original small backbones, we also compare with both methods with larger convolutional backbones, i.",
                "Then, DAC-MR can still consistently provide improvements to both (enhanced) baselines with an obvious gap, which yields at least 1.5% and 2.4% 1-shot accuracy improvement for ProtoNet and R2D2, respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "98ec1fef41959c458a9f18b4ab5812dc7c99a921",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2305-07892",
                    "ArXiv": "2305.07892",
                    "DOI": "10.48550/arXiv.2305.07892",
                    "CorpusId": 258685501
                },
                "corpusId": 258685501,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/98ec1fef41959c458a9f18b4ab5812dc7c99a921",
                "title": "DAC-MR: Data Augmentation Consistency Based Meta-Regularization for Meta-Learning",
                "abstract": "Meta learning recently has been heavily researched and helped advance the contemporary machine learning. However, achieving well-performing meta-learning model requires a large amount of training tasks with high-quality meta-data representing the underlying task generalization goal, which is sometimes difficult and expensive to obtain for real applications. Current meta-data-driven meta-learning approaches, however, are fairly hard to train satisfactory meta-models with imperfect training tasks. To address this issue, we suggest a meta-knowledge informed meta-learning (MKIML) framework to improve meta-learning by additionally integrating compensated meta-knowledge into meta-learning process. We preliminarily integrate meta-knowledge into meta-objective via using an appropriate meta-regularization (MR) objective to regularize capacity complexity of the meta-model function class to facilitate better generalization on unseen tasks. As a practical implementation, we introduce data augmentation consistency to encode invariance as meta-knowledge for instantiating MR objective, denoted by DAC-MR. The proposed DAC-MR is hopeful to learn well-performing meta-models from training tasks with noisy, sparse or unavailable meta-data. We theoretically demonstrate that DAC-MR can be treated as a proxy meta-objective used to evaluate meta-model without high-quality meta-data. Besides, meta-data-driven meta-loss objective combined with DAC-MR is capable of achieving better meta-level generalization. 10 meta-learning tasks with different network architectures and benchmarks substantiate the capability of our DAC-MR on aiding meta-model learning. Fine performance of DAC-MR are obtained across all settings, and are well-aligned with our theoretical insights. This implies that our DAC-MR is problem-agnostic, and hopeful to be readily applied to extensive meta-learning problems and tasks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "38741604",
                        "name": "Jun Shu"
                    },
                    {
                        "authorId": "2151461389",
                        "name": "Xiang Yuan"
                    },
                    {
                        "authorId": "1803714",
                        "name": "Deyu Meng"
                    },
                    {
                        "authorId": "98220533",
                        "name": "Zongben Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "An elegant property of DDRR methods is that they naturally address regression tasks, although they have been repurposed for classification [6] by conducting MSE-loss regression to a target 1-hot vector.",
                "Further, we calibrate the prediction for binary cross entropy loss with a learnable scale and bias following [6].",
                "DDRR Deep differentiable ridge-regression has been considered for few-shot recognition [6], tracking [82], and other tasks."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e3df7070d0727fbf840e644367e11b5db720859f",
                "externalIds": {
                    "ArXiv": "2305.07625",
                    "DBLP": "conf/cvpr/BohdalTZC0GGH23",
                    "DOI": "10.1109/CVPR52729.2023.00743",
                    "CorpusId": 258676154
                },
                "corpusId": 258676154,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e3df7070d0727fbf840e644367e11b5db720859f",
                "title": "Meta Omnium: A Benchmark for General-Purpose Learning-to-Learn",
                "abstract": "Meta-learning and other approaches to few-shot learning are widely studied for image recognition, and are increasingly applied to other vision tasks such as pose estimation and dense prediction. This naturally raises the question of whether there is any fewshot metalearning algorithm capable of generalizing across these diverse task types? To support the community in answering this question, we introduce Meta Omnium, a dataset-of-datasets spanning multiple vision tasks including recognition, keypoint localization, semantic segmentation and regression. We experiment with popular fewshot metalearning baselines and analyze their ability to generalize across tasks and to transfer knowledge between them. Meta Omnium enables metalearning researchers to evaluate model generalization to a much wider array of tasks than previously possible, and provides a single framework for evaluating meta-learners across a wide suite of vision applications in a consistent manner. Code and dataset are available at https://github.com/edi-meta-learning/meta-omnium.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1749549997",
                        "name": "Ondrej Bohdal"
                    },
                    {
                        "authorId": "2125588104",
                        "name": "Yinbing Tian"
                    },
                    {
                        "authorId": "152218610",
                        "name": "Yongshuo Zong"
                    },
                    {
                        "authorId": "1986560192",
                        "name": "Ruchika Chavhan"
                    },
                    {
                        "authorId": "2108338672",
                        "name": "Da Li"
                    },
                    {
                        "authorId": "2319565",
                        "name": "H. Gouk"
                    },
                    {
                        "authorId": "2217902470",
                        "name": "Li Guo"
                    },
                    {
                        "authorId": "1697755",
                        "name": "Timothy M. Hospedales"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fe1d5b748a5b524e1070c0be8f2ae8f89019d697",
                "externalIds": {
                    "DBLP": "journals/jrtip/KimK23",
                    "DOI": "10.1007/s11554-023-01310-x",
                    "CorpusId": 258510070
                },
                "corpusId": 258510070,
                "publicationVenue": {
                    "id": "f62e30c1-d856-4a50-819b-551249ecf5dc",
                    "name": "Journal of Real-Time Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "Journal of Real-time Image Processing",
                        "J Real-time Image Process"
                    ],
                    "issn": "1861-8200",
                    "url": "https://link.springer.com/journal/11554"
                },
                "url": "https://www.semanticscholar.org/paper/fe1d5b748a5b524e1070c0be8f2ae8f89019d697",
                "title": "Few-shot learning for facial expression recognition: a comprehensive survey",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2216309675",
                        "name": "Chae-Lin Kim"
                    },
                    {
                        "authorId": "2151899589",
                        "name": "Byung-Gyu Kim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "when encountering adversarial samples, AQ focuses only on the case when the query sample is attacked, this paper aims to improve R2D2\u2019s performance under adversarial attacks [9].",
                "Meta-learning methods based on optimization aim to find a set of initialization parameters which can quickly adapt to the basic model, including MAML [3] , LEO [4], R2D2 [9], MetaOptNet [14] and a series of methods.",
                "In this section, we verify the performance of DeR2D2 on two benchmark datasets: MiniImageNet [10] and CIFAR-FS [9]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "284ebb22c264ada1537824993422d0acc6a18c16",
                "externalIds": {
                    "DBLP": "conf/icaci/XuW23",
                    "DOI": "10.1109/ICACI58115.2023.10146130",
                    "CorpusId": 259152293
                },
                "corpusId": 259152293,
                "publicationVenue": {
                    "id": "3ced5c3e-6001-4714-ba20-5f04c798a081",
                    "name": "International Conference on Advanced Computational Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "ICACI",
                        "Int Conf Adv Comput Intell",
                        "IEEE International Conference on Advanced Computational Intelligence",
                        "IEEE Int Conf Adv Comput Intell"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/284ebb22c264ada1537824993422d0acc6a18c16",
                "title": "Sharpness-Aware Minimization Leads to Better Robustness in Meta-learning",
                "abstract": "Transforming few-shot learning into meta-learning is an important way to narrow the gap between human ability and machine learning. In this paper, we study the adversarial robustness of meta-learning model and propose Defending R2D2 algorithm (DeR2D2) to resist attacks. We pay more attention to the two problems of adversarial meta-learning: the high training cost and the significant decrease of classification accuracy on clean samples. First, we demonstrate that the introduction of adversarial samples in R2D2 training can improve its adversarial robustness. Second, we choose Randomized Fast Gradient Sign Method (R+FGSM) instead of Projected Gradient Descent (PGD) as the adversarial training method, which significantly reduces the training cost. Finally, due to the Sharpness-Aware Minimization (SAM), our method further reduces adversarial training time and significantly improves the classification accuracy on clean samples. In addition, we verify that in most cases, DeR2D2 also has a strong ability to defend against attacks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "51424419",
                        "name": "Mengke Xu"
                    },
                    {
                        "authorId": "2220129219",
                        "name": "Huiwei Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Pioneer works [24], [25] have shown their effectiveness by using a closed-form solution for prototypical reprojection, which performs the conventional Ridge regression:",
                "This new learning space ensures a differentiable closedform solution with ridge regression [24], [25] to reduce the",
                "distance measurements [17], [18], [24], [25], [35], [36]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "340089ced3bff279400cda391583a2e20cc38b29",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2306-10511",
                    "ArXiv": "2306.10511",
                    "DOI": "10.1109/TPAMI.2023.3272697",
                    "CorpusId": 258462721,
                    "PubMed": "37134032"
                },
                "corpusId": 258462721,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/340089ced3bff279400cda391583a2e20cc38b29",
                "title": "Dual Adaptive Representation Alignment for Cross-Domain Few-Shot Learning",
                "abstract": "Few-shot learning aims to recognize novel queries with limited support samples by learning from base knowledge. Recent progress in this setting assumes that the base knowledge and novel query samples are distributed in the same domains, which are usually infeasible for realistic applications. Toward this issue, we propose to address the cross-domain few-shot learning problem where only extremely few samples are available in target domains. Under this realistic setting, we focus on the fast adaptation capability of meta-learners by proposing an effective dual adaptive representation alignment approach. In our approach, a prototypical feature alignment is first proposed to recalibrate support instances as prototypes and reproject these prototypes with a differentiable closed-form solution. Therefore feature spaces of learned knowledge can be adaptively transformed to query spaces by the cross-instance and cross-prototype relations. Besides the feature alignment, we further present a normalized distribution alignment module, which exploits prior statistics of query samples for solving the covariant shifts among the support and query samples. With these two modules, a progressive meta-learning framework is constructed to perform the fast adaptation with extremely few-shot samples while maintaining its generalization capabilities. Experimental evidence demonstrates our approach achieves new state-of-the-art results on 4 CDFSL benchmarks and 4 fine-grained cross-domain benchmarks.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "151469503",
                        "name": "Yifan Zhao"
                    },
                    {
                        "authorId": "38144094",
                        "name": "T. Zhang"
                    },
                    {
                        "authorId": "2118372693",
                        "name": "Jia Li"
                    },
                    {
                        "authorId": "40161651",
                        "name": "Yonghong Tian"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "878418790785fa9e5604f2279f70d8cb84298848",
                "externalIds": {
                    "DBLP": "journals/tcsv/ShaoXWLLZ23",
                    "DOI": "10.1109/TCSVT.2022.3224003",
                    "CorpusId": 253784695
                },
                "corpusId": 253784695,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/878418790785fa9e5604f2279f70d8cb84298848",
                "title": "Attention-Based Multi-View Feature Collaboration for Decoupled Few-Shot Learning",
                "abstract": "Decoupled Few-shot learning (FSL) is an effective methodology that deals with the problem of data-scarce. Its standard paradigm includes two phases: (1) Pre-train. Generating a CNN-based feature extraction model (FEM) via base data. (2) Meta-test. Employing the frozen FEM to obtain the novel data features, then classifying them. Obviously, one crucial factor, the category gap, prevents the development of FSL, i.e., it is challenging for the pre-trained FEM to adapt to the novel class flawlessly. Inspired by a common-sense theory: the FEMs based on different strategies focus on different priorities, we attempt to address this problem from the multi-view feature collaboration (MVFC) perspective. Specifically, we first denoise the multi-view features by subspace learning method, then design three attention blocks (loss-attention block, self-attention block and graph-attention block) to balance the representation between different views. The proposed method is evaluated on four benchmark datasets and achieves significant improvements of 0.9%-5.6% compared with SOTAs.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "47975317",
                        "name": "Shuai Shao"
                    },
                    {
                        "authorId": "2053893677",
                        "name": "Lei Xing"
                    },
                    {
                        "authorId": "7707388",
                        "name": "Yanjiang Wang"
                    },
                    {
                        "authorId": "2155992419",
                        "name": "Baodi Liu"
                    },
                    {
                        "authorId": "2109174226",
                        "name": "Weifeng Liu"
                    },
                    {
                        "authorId": "3049217",
                        "name": "Yicong Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f320b487a4a28c257d39bc8464bb9d6d85bef0b2",
                "externalIds": {
                    "DBLP": "journals/pr/ChenLHLZHFX23",
                    "DOI": "10.1016/j.patcog.2023.109677",
                    "CorpusId": 258606213
                },
                "corpusId": 258606213,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f320b487a4a28c257d39bc8464bb9d6d85bef0b2",
                "title": "Multi-semantic hypergraph neural network for effective few-shot learning",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2149052114",
                        "name": "Hao Chen"
                    },
                    {
                        "authorId": "2134838910",
                        "name": "Linyan Li"
                    },
                    {
                        "authorId": "2348236",
                        "name": "Fuyuan Hu"
                    },
                    {
                        "authorId": "12358136",
                        "name": "Fan Lyu"
                    },
                    {
                        "authorId": "2136130424",
                        "name": "Liuqing Zhao"
                    },
                    {
                        "authorId": "5380819",
                        "name": "Kaizhu Huang"
                    },
                    {
                        "authorId": "2165578101",
                        "name": "Wei Feng"
                    },
                    {
                        "authorId": "31139942",
                        "name": "Zhenping Xia"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "606bb7b28e27f331c29dd4f819337c07940fab5a",
                "externalIds": {
                    "DBLP": "journals/cg/GamaOSC23",
                    "DOI": "10.2139/ssrn.4374390",
                    "CorpusId": 257303673
                },
                "corpusId": 257303673,
                "publicationVenue": {
                    "id": "ca858314-5beb-4241-a7e4-f7748b3f2081",
                    "name": "Computers & graphics",
                    "type": "journal",
                    "alternate_names": [
                        "Computer Graphics",
                        "Comput graph",
                        "Computers & Graphics",
                        "Comput  Graph",
                        "Comput Graph",
                        "Computer graphics",
                        "Comput  graph"
                    ],
                    "issn": "0097-8493",
                    "alternate_issns": [
                        "0097-8930",
                        "1558-4569"
                    ],
                    "url": "https://www.sciencedirect.com/journal/computers-and-graphics",
                    "alternate_urls": [
                        "http://portal.acm.org/siggraph/newsletter",
                        "https://dl.acm.org/newsletter/siggraph",
                        "http://www.sciencedirect.com/science/journal/00978493"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/606bb7b28e27f331c29dd4f819337c07940fab5a",
                "title": "An overview on Meta-learning approaches for Few-shot Weakly-supervised Segmentation",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1388176432",
                        "name": "P. H. T. Gama"
                    },
                    {
                        "authorId": "10009581",
                        "name": "H. Oliveira"
                    },
                    {
                        "authorId": "2116663801",
                        "name": "J. D. Santos"
                    },
                    {
                        "authorId": "1759917",
                        "name": "R. M. C. Junior"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9fb4e8392aba28dfb0caf710b604878ae1d5b058",
                "externalIds": {
                    "DBLP": "journals/pr/ShiLHZWG23",
                    "DOI": "10.2139/ssrn.4362435",
                    "CorpusId": 257011293
                },
                "corpusId": 257011293,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9fb4e8392aba28dfb0caf710b604878ae1d5b058",
                "title": "Global- and local-aware feature augmentation with semantic orthogonality for few-shot image classification",
                "abstract": "As for few-shot image classification, recently, some works revisit the standard transfer learning paradigm, i.e., pre-training and fine-tuning, and have achieved some success. However, we find that this kind of methods heavily relies on a naive image-level data augmentation (e.g., cropping and flipping) at the fine-tuning stage, which will easily suffer from the overfitting problem because of the limited-data regime. To tackle this issue, in this paper, we attempt to perform a novel feature-level semantic augmentation at the fine-tuning stage and propose a Globaland Local-aware Feature Augmentation method (GLFA) from both the channeland spatial-wise perspectives. In addition, at the pre-training stage, we further propose a Semantic Orthogonal Learning Framework (SOLF) to make the learned feature channels more independently, orthogonal and diverse. Extensive experiments demonstrate that the proposed method can obtain significant performance improvements over the state of the arts. Code is available at https://github.com/onlyyao/GLFA-SOLF. \u00a9 2023 Elsevier Ltd. All rights reserved.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2208187727",
                        "name": "Boyao Shi"
                    },
                    {
                        "authorId": "35660603",
                        "name": "Wenbin Li"
                    },
                    {
                        "authorId": "2055851838",
                        "name": "Jing Huo"
                    },
                    {
                        "authorId": "145463313",
                        "name": "Pengfei Zhu"
                    },
                    {
                        "authorId": "46659935",
                        "name": "Lei Wang"
                    },
                    {
                        "authorId": "49658113",
                        "name": "Yang Gao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "17d4bb06841e7e54cec3a43dc0ca5be39d21ae4d",
                "externalIds": {
                    "ArXiv": "2305.00454",
                    "DBLP": "conf/ijcai/YangLCZ23",
                    "DOI": "10.48550/arXiv.2305.00454",
                    "CorpusId": 258426672
                },
                "corpusId": 258426672,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/17d4bb06841e7e54cec3a43dc0ca5be39d21ae4d",
                "title": "Few-shot Classification via Ensemble Learning with Multi-Order Statistics",
                "abstract": "Transfer learning has been widely adopted for few-shot classification. Recent studies reveal that obtaining good generalization representation of images on novel classes is the key to improving the few-shot classification accuracy. To address this need, we prove theoretically that leveraging ensemble learning on the base classes can correspondingly reduce the true error in the novel classes. Following this principle, a novel method named Ensemble Learning with Multi-Order Statistics (ELMOS) is proposed in this paper. In this method, after the backbone network, we use multiple branches to create the individual learners in the ensemble learning, with the goal to reduce the storage cost. We then introduce different order statistics pooling in each branch to increase the diversity of the individual learners. The learners are optimized with supervised losses during the pre-training phase. After pre-training, features from different branches are concatenated for classifier evaluation. Extensive experiments demonstrate that each branch can complement the others and our method can produce a state-of-the-art performance on multiple few-shot classification benchmark datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2071594",
                        "name": "Sai Yang"
                    },
                    {
                        "authorId": "153035664",
                        "name": "Fan Liu"
                    },
                    {
                        "authorId": "94210578",
                        "name": "Delong Chen"
                    },
                    {
                        "authorId": "2151548966",
                        "name": "Jun Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This is the case in applications where the data is scarce, for example in rare animal species [1].",
                "Optimization-based methods focus on learning a robust model initialization, through gradientbased solutions [9, 27], closed-form solutions [1] or an LSTM [31]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "82dabfc26c1e677ed7d347520059ecd954deca07",
                "externalIds": {
                    "ArXiv": "2304.14281",
                    "DBLP": "journals/corr/abs-2304-14281",
                    "DOI": "10.48550/arXiv.2304.14281",
                    "CorpusId": 258352671
                },
                "corpusId": 258352671,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/82dabfc26c1e677ed7d347520059ecd954deca07",
                "title": "Adaptive manifold for imbalanced transductive few-shot learning",
                "abstract": "Transductive few-shot learning algorithms have showed substantially superior performance over their inductive counterparts by leveraging the unlabeled queries. However, the vast majority of such methods are evaluated on perfectly class-balanced benchmarks. It has been shown that they undergo remarkable drop in performance under a more realistic, imbalanced setting. To this end, we propose a novel algorithm to address imbalanced transductive few-shot learning, named Adaptive Manifold. Our method exploits the underlying manifold of the labeled support examples and unlabeled queries by using manifold similarity to predict the class probability distribution per query. It is parameterized by one centroid per class as well as a set of graph-specific parameters that determine the manifold. All parameters are optimized through a loss function that can be tuned towards class-balanced or imbalanced distributions. The manifold similarity shows substantial improvement over Euclidean distance, especially in the 1-shot setting. Our algorithm outperforms or is on par with other state of the art methods in three benchmark datasets, namely miniImageNet, tieredImageNet and CUB, and three different backbones, namely ResNet-18, WideResNet-28-10 and DenseNet-121. In certain cases, our algorithm outperforms the previous state of the art by as much as 4.2%.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46973863",
                        "name": "Michalis Lazarou"
                    },
                    {
                        "authorId": "1744904",
                        "name": "Yannis Avrithis"
                    },
                    {
                        "authorId": "1783374",
                        "name": "T. Stathaki"
                    }
                ]
            }
        },
        {
            "contexts": [
                "First, for semantic data augmentation, where we reach SoTA for both few-shot classification and long-tail learning on miniImageNet [63], CUB [64], CIFAR-FS [4], ImageNet-LT [39] and iNaturalist [62].",
                "Tables 1a and 1b compare SeedSelect with SoTA approaches for few-shot classification and semantic data augmentation, for CUB, miniImageNet, and CIFAR-FS.",
                "(3) CIFAR-FS [4]: Obtained from CIFAR-100 dataset [33] using the same criteria used for sampling miniImageNet."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8ce03b0d4ab25f2f2fea056370d3b3f5e938c6d6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-14530",
                    "ArXiv": "2304.14530",
                    "DOI": "10.48550/arXiv.2304.14530",
                    "CorpusId": 258418154
                },
                "corpusId": 258418154,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8ce03b0d4ab25f2f2fea056370d3b3f5e938c6d6",
                "title": "It is all about where you start: Text-to-image generation with seed selection",
                "abstract": "Text-to-image diffusion models can synthesize a large variety of concepts in new compositions and scenarios. However, they still struggle with generating uncommon concepts, rare unusual combinations, or structured concepts like hand palms. Their limitation is partly due to the long-tail nature of their training data: web-crawled data sets are strongly unbalanced, causing models to under-represent concepts from the tail of the distribution. Here we characterize the effect of unbalanced training data on text-to-image models and offer a remedy. We show that rare concepts can be correctly generated by carefully selecting suitable generation seeds in the noise space, a technique that we call SeedSelect. SeedSelect is efficient and does not require retraining the diffusion model. We evaluate the benefit of SeedSelect on a series of problems. First, in few-shot semantic data augmentation, where we generate semantically correct images for few-shot and long-tail benchmarks. We show classification improvement on all classes, both from the head and tail of the training data of diffusion models. We further evaluate SeedSelect on correcting images of hands, a well-known pitfall of current diffusion models, and show that it improves hand generation substantially.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1612410686",
                        "name": "Dvir Samuel"
                    },
                    {
                        "authorId": "1397958297",
                        "name": "Rami Ben-Ari"
                    },
                    {
                        "authorId": "2215802451",
                        "name": "Simon Raviv"
                    },
                    {
                        "authorId": "8684542",
                        "name": "N. Darshan"
                    },
                    {
                        "authorId": "2065001062",
                        "name": "Gal Chechik"
                    }
                ]
            }
        },
        {
            "contexts": [
                "2021), ridge/logistic regression (Chen et al. 2019; Bertinetto et al. 2019; Tian et al. 2020), and graph neural networks (Satorras and Estrach 2018; Tang et al.",
                "2016) with the same architecture as previous works (Bertinetto et al. 2019; Ye et al. 2020) is used as the feature extractor f\u03b8 of our model."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0a52f77490300be671942909e09b4ee87e7f23a0",
                "externalIds": {
                    "ArXiv": "2304.13287",
                    "DBLP": "journals/corr/abs-2304-13287",
                    "DOI": "10.48550/arXiv.2304.13287",
                    "CorpusId": 258331836
                },
                "corpusId": 258331836,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/0a52f77490300be671942909e09b4ee87e7f23a0",
                "title": "ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning",
                "abstract": "Self-supervised learning (SSL) techniques have recently been integrated into the few-shot learning (FSL) framework and have shown promising results in improving the few-shot image classification performance. However, existing SSL approaches used in FSL typically seek the supervision signals from the global embedding of every single image. Therefore, during the episodic training of FSL, these methods cannot capture and fully utilize the local visual information in image samples and the data structure information of the whole episode, which are beneficial to FSL. To this end, we propose to augment the few-shot learning objective with a novel self-supervised Episodic Spatial Pretext Task (ESPT). Specifically, for each few-shot episode, we generate its corresponding transformed episode by applying a random geometric transformation to all the images in it. Based on these, our ESPT objective is defined as maximizing the local spatial relationship consistency between the original episode and the transformed one. With this definition, the ESPT-augmented FSL objective promotes learning more transferable feature representations that capture the local spatial features of different images and their inter-relational structural information in each input episode, thus enabling the model to generalize better to new categories with only a few samples. Extensive experiments indicate that our ESPT method achieves new state-of-the-art performance for few-shot image classification on three mainstay benchmark datasets. The source code will be available at: https://github.com/Whut-YiRong/ESPT.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "145872629",
                        "name": "Yi Rong"
                    },
                    {
                        "authorId": "151480853",
                        "name": "Xiongbo Lu"
                    },
                    {
                        "authorId": "1491623345",
                        "name": "Zhaoyang Sun"
                    },
                    {
                        "authorId": "9407523",
                        "name": "Yaxiong Chen"
                    },
                    {
                        "authorId": "2135639762",
                        "name": "Shengwu Xiong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Some of the other notable approaches include learning to generate synthetic data for novel classes [23, 33, 68], using better feature representations [1, 2, 19, 28, 41, 63, 67] or utilizing differentiable convex solvers [3, 34]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "19cf89caa9254bddad7503c76d946438751aefd5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-12161",
                    "ArXiv": "2304.12161",
                    "DOI": "10.1109/CVPR52729.2023.00709",
                    "CorpusId": 258298938
                },
                "corpusId": 258298938,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/19cf89caa9254bddad7503c76d946438751aefd5",
                "title": "Meta-Tuning Loss Functions and Data Augmentation for Few-Shot Object Detection",
                "abstract": "Few-shot object detection, the problem of modelling novel object detection categories with few training instances, is an emerging topic in the area of few-shot learning and object detection. Contemporary techniques can be divided into two groups: fine-tuning based and meta-learning based approaches. While meta-learning approaches aim to learn dedicated meta-models for mapping samples to novel class models, fine-tuning approaches tackle few-shot detection in a simpler manner, by adapting the detection model to novel classes through gradient based optimization. Despite their simplicity, fine-tuning based approaches typically yield competitive detection results. Based on this observation, we focus on the role of loss functions and augmentations as the force driving the fine-tuning process, and propose to tune their dynamics through meta-learning principles. The proposed training scheme, therefore, allows learning inductive biases that can boost few-shot detection, while keeping the advantages of fine-tuning based approaches. In addition, the proposed approach yields interpretable loss functions, as opposed to highly parametric and complex few-shot meta-models. The experimental results highlight the merits of the proposed scheme, with significant improvements over the strong fine-tuning based few-shot detection baselines on benchmark Pascal VOC and MS-COCO datasets, in terms of both standard and generalized few-shot performance metrics.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "9424554",
                        "name": "B. Demirel"
                    },
                    {
                        "authorId": "1505785792",
                        "name": "Orhun Bugra Baran"
                    },
                    {
                        "authorId": "1939006",
                        "name": "R. G. Cinbis"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS is the subsets of CIFAR100 [17].",
                "We use the source code of FEAT and SnaTCHer-F from github to do the experiment on the CIFAR-FS.",
                "We use miniImageNet [37], tieredImageNet [24] and CIFAR-FS [4] to evaluate the performance of the model."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bdf3c833b4c08f880378a2b97c891a61e569d920",
                "externalIds": {
                    "ArXiv": "2304.11855",
                    "DBLP": "journals/corr/abs-2304-11855",
                    "DOI": "10.1109/CVPR52729.2023.00725",
                    "CorpusId": 258298986
                },
                "corpusId": 258298986,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/bdf3c833b4c08f880378a2b97c891a61e569d920",
                "title": "Glocal Energy-based Learning for Few-Shot Open-Set Recognition",
                "abstract": "Few-shot open-set recognition (FSOR) is a challenging task of great practical value. It aims to categorize a sample to one of the predefined, closed-set classes illustrated by few examples while being able to reject the sample from unknown classes. In this work, we approach the FSOR task by proposing a novel energy-based hybrid model. The model is composed of two branches, where a classification branch learns a metric to classify a sample to one of closed-set classes and the energy branch explicitly estimates the open-set probability. To achieve holistic detection of open-set samples, our model leverages both class-wise and pixel-wise features to learn a glocal energy-based score, in which a global energy score is learned using the class-wise features, while a local energy score is learned using the pixel-wise features. The model is enforced to assign large energy scores to samples that are deviated from the few-shot examples in either the class-wise features or the pixel-wise features, and to assign small energy scores otherwise. Experiments on three standard FSOR datasets show the superior performance of our model.11Code is available at https://github.com/00why00/Glocal",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2109571594",
                        "name": "Haoyu Wang"
                    },
                    {
                        "authorId": "3224619",
                        "name": "Guansong Pang"
                    },
                    {
                        "authorId": "2155302795",
                        "name": "Peng Wang"
                    },
                    {
                        "authorId": "50081808",
                        "name": "Lei Zhang"
                    },
                    {
                        "authorId": "2149193203",
                        "name": "Wei Wei"
                    },
                    {
                        "authorId": "2047640322",
                        "name": "Yanning Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, scaling&&shift and full-tuning both do not\nget consistent improvements on five benchmarks against directly test without meta-training, even having a large margin on CIFAR-FS.",
                "Although typically input image size of few-shot setting is smaller than that in large-scaled pretraining, e.g. 84 for miniImageNet and 32 for CIFAR-FS, the emphasis of our pipeline is not to make comparisons with other few-shot algorithms but to explore how to better leveraging pretrained models against full-tuning.",
                "We use five frequently-used datasets to evaluate our pipeline: miniImageNet[9], CUB[25], CIFAR-FS[23], clipart[24] and sketch[24].",
                "2 has 0.3M parameters updated that is 78 times as that of VPT-SHALLOW with 10 tokens but the latter gets obviously better performance except on 1 shot tasks of CIFAR-FS.",
                "3 VPT-DEEP is compared with VPT-SHALLOW and VPT-ADD on CIFAR-FS.",
                "We use five frequently-used datasets to evaluate our pipeline: miniImageNet[9], CUB[25], CIFAR-FS[23], clipart[24] and sketch[24]. miniImageNet is from ImageNet-1K[19] and is the most common benchmark of few-shot learning.",
                "CIFAR-FS has the same structure as miniImageNet which has 64 classes of 100 as training split, 16 classes as validation split and 20 classes as test split."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "fecb1a655cbea6bb70a246d332abd52c9061b14f",
                "externalIds": {
                    "DOI": "10.1117/12.2668153",
                    "CorpusId": 258280367
                },
                "corpusId": 258280367,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/fecb1a655cbea6bb70a246d332abd52c9061b14f",
                "title": "How to make use of pretrained models in few-shot classification",
                "abstract": "Few-shot learning(FSL) aims to generalize model to novel categoeries by few labelled samples, which is challenging for machine. Large-scaled pretrained models, especially vision transformers achieve excellent performances benefiting from numerous and diverse data. Researchers have exploited pretrained models in few-shot classification by simply updating the whole parameters and finetuning on few samples. In this paper, we explore two methods: vision prompt tuning and a reparameterization method called \u2018scaling&&shift\u2019 to leverage pretrained models in few-shot classification. Vision prompt tuning is for vision transformer only and we first evaluate the method in few-shot setting. \u2018Scaling&&shift\u2019 is originally applied in convolution neural networks(CNN). We extend it to vision transformer. The two methods are evaluated on standard benchmarks such as miniImageNet, CUB, CIFAR-FS, clipart and sketch. The results show that \u2018scaling&&shift\u2019 reaches the same level compared to updating the whole parameters. Vision prompt tuning is 0%~5% lower than updating the whole parameters over five datasets while it has quite smaller amount of parameters updated.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2215111866",
                        "name": "Mingyu Fu"
                    },
                    {
                        "authorId": "2162642858",
                        "name": "Peng Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2019) and meta-learning (Bertinetto et al., 2018; Finn, 2018; Finn et al., 2018)), RNN training (Merity et al."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2f5843d6ef9cf151c033452966a0c367c104a0d8",
                "externalIds": {
                    "ArXiv": "2304.11153",
                    "DBLP": "conf/icml/Vicol23",
                    "DOI": "10.48550/arXiv.2304.11153",
                    "CorpusId": 258291565
                },
                "corpusId": 258291565,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2f5843d6ef9cf151c033452966a0c367c104a0d8",
                "title": "Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single",
                "abstract": "We propose an evolution strategies-based algorithm for estimating gradients in unrolled computation graphs, called ES-Single. Similarly to the recently-proposed Persistent Evolution Strategies (PES), ES-Single is unbiased, and overcomes chaos arising from recursive function applications by smoothing the meta-loss landscape. ES-Single samples a single perturbation per particle, that is kept fixed over the course of an inner problem (e.g., perturbations are not re-sampled for each partial unroll). Compared to PES, ES-Single is simpler to implement and has lower variance: the variance of ES-Single is constant with respect to the number of truncated unrolls, removing a key barrier in applying ES to long inner problems using short truncations. We show that ES-Single is unbiased for quadratic inner problems, and demonstrate empirically that its variance can be substantially lower than that of PES. ES-Single consistently outperforms PES on a variety of tasks, including a synthetic benchmark task, hyperparameter optimization, training recurrent neural networks, and training learned optimizers.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2039154",
                        "name": "Paul Vicol"
                    },
                    {
                        "authorId": "117539586",
                        "name": "Zico Kolter"
                    },
                    {
                        "authorId": "1754860",
                        "name": "Kevin Swersky"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026baselines\nIn Table 14, we further compare our method on meta learning benchmarks, namely Mini Imagenet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019) with different approaches in the literature based on meta learning (Snell et al., 2017; Oreshkin et al., 2018; Dhillon et\u2026",
                "Comparison with metalearning baselines\nIn Table 14, we further compare our method on meta learning benchmarks, namely Mini Imagenet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019) with different approaches in the literature based on meta learning (Snell et al., 2017; Oreshkin et al., 2018; Dhillon et al., 2020; Lachapelle et al., 2022a).",
                "Other approaches that leverage a meta-learning objective for multi-task learning have been formulated (Dhillon et al., 2020; Snell et al., 2017; Lee et al., 2019; Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d32a0fdd974badf6bf5529e11c6776fe5ed88d00",
                "externalIds": {
                    "ArXiv": "2304.07939",
                    "DBLP": "journals/corr/abs-2304-07939",
                    "DOI": "10.48550/arXiv.2304.07939",
                    "CorpusId": 258180537
                },
                "corpusId": 258180537,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d32a0fdd974badf6bf5529e11c6776fe5ed88d00",
                "title": "Leveraging sparse and shared feature activations for disentangled representation learning",
                "abstract": "Recovering the latent factors of variation of high dimensional data has so far focused on simple synthetic settings. Mostly building on unsupervised and weakly-supervised objectives, prior work missed out on the positive implications for representation learning on real world data. In this work, we propose to leverage knowledge extracted from a diversified set of supervised tasks to learn a common disentangled representation. Assuming each supervised task only depends on an unknown subset of the factors of variation, we disentangle the feature space of a supervised multi-task model, with features activating sparsely across different tasks and information being shared as appropriate. Importantly, we never directly observe the factors of variations but establish that access to multiple tasks is sufficient for identifiability under sufficiency and minimality assumptions. We validate our approach on six real world distribution shift benchmarks, and different data modalities (images, text), demonstrating how disentangled representations can be transferred to real settings.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1931675362",
                        "name": "Marco Fumero"
                    },
                    {
                        "authorId": "39798982",
                        "name": "F. Wenzel"
                    },
                    {
                        "authorId": "1914913470",
                        "name": "L. Zancato"
                    },
                    {
                        "authorId": "16163297",
                        "name": "A. Achille"
                    },
                    {
                        "authorId": "1796150",
                        "name": "E. Rodol\u00e0"
                    },
                    {
                        "authorId": "2075295257",
                        "name": "S. Soatto"
                    },
                    {
                        "authorId": "1707625",
                        "name": "B. Sch\u00f6lkopf"
                    },
                    {
                        "authorId": "2112584507",
                        "name": "Francesco Locatello"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We report results on the following FSL benchmark datasets: miniImageNet [54], tieredImageNet [39], CIFARFS [8], and FC100 [33].",
                "We report results on the following FSL benchmark datasets: miniImageNet [54], tieredImageNet [39], CIFARFS [8], and FC100 [33].\nminiImageNet incorporates 100 randomly sampled categories from ImageNet and 600 images per category."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f998b274edc7ecf0bfb9d2276207effb1aff2d90",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2304-06672",
                    "ArXiv": "2304.06672",
                    "DOI": "10.1109/CVPRW59228.2023.00525",
                    "CorpusId": 258108188
                },
                "corpusId": 258108188,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f998b274edc7ecf0bfb9d2276207effb1aff2d90",
                "title": "LSFSL: Leveraging Shape Information in Few-shot Learning",
                "abstract": "Few-shot learning (FSL) techniques seek to learn the underlying patterns in data using fewer samples, analogous to how humans learn from limited experience. In this limiteddata scenario, the challenges associated with deep neural networks, such as shortcut learning and texture bias behaviors, are further exacerbated. Moreover, the significance of addressing shortcut learning is not yet fully explored in the few-shot setup. To address these issues, we propose LSFSL, which enforces the model to learn more generalizable features utilizing the implicit prior information present in the data. Through comprehensive analyses, we demonstrate that LSFSL-trained models are less vulnerable to alteration in color schemes, statistical correlations, and adversarial perturbations leveraging the global semantics in the data. Our findings highlight the potential of incorporating relevant priors in few-shot approaches to increase robustness and generalization.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1454595022",
                        "name": "Deepan Padmanabhan"
                    },
                    {
                        "authorId": "2107080237",
                        "name": "Shruthi Gowda"
                    },
                    {
                        "authorId": "51109237",
                        "name": "E. Arani"
                    },
                    {
                        "authorId": "2107033749",
                        "name": "Bahram Zonooz"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "00ef56f4b0dbbb3697bb30f03aef3fc7e17dfbad",
                "externalIds": {
                    "DBLP": "journals/ml/ChenKZ23",
                    "DOI": "10.1007/s10994-023-06329-6",
                    "CorpusId": 258039669
                },
                "corpusId": 258039669,
                "publicationVenue": {
                    "id": "22c9862f-a25e-40cd-9d31-d09e68a293e6",
                    "name": "Machine-mediated learning",
                    "type": "journal",
                    "alternate_names": [
                        "Mach learn",
                        "Machine Learning",
                        "Mach Learn"
                    ],
                    "issn": "0732-6718",
                    "alternate_issns": [
                        "0885-6125"
                    ],
                    "url": "http://www.springer.com/computer/artificial/journal/10994",
                    "alternate_urls": [
                        "https://link.springer.com/journal/10994",
                        "http://www.springer.com/west/home/computer/artificial?SGWID=4-147-70-35726603-0"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/00ef56f4b0dbbb3697bb30f03aef3fc7e17dfbad",
                "title": "An accelerated proximal algorithm for regularized nonconvex and nonsmooth bi-level optimization",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2144251699",
                        "name": "Ziyi Chen"
                    },
                    {
                        "authorId": "1749353",
                        "name": "B. Kailkhura"
                    },
                    {
                        "authorId": "2118765295",
                        "name": "Yi Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5fe9100eae55799114b2a01c2e8271c9ce79ca86",
                "externalIds": {
                    "DOI": "10.1109/ICCEA58433.2023.10135484",
                    "CorpusId": 259028759
                },
                "corpusId": 259028759,
                "publicationVenue": {
                    "id": "0a4491c0-572b-484b-b6d1-191b75b000fe",
                    "name": "International Conference Civil Engineering and Architecture",
                    "type": "conference",
                    "alternate_names": [
                        "ICCEA",
                        "Int Conf Civ Eng Archit"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5fe9100eae55799114b2a01c2e8271c9ce79ca86",
                "title": "Deep search based prototype estimation method for few-shot image classification",
                "abstract": "Few-shot learning aims to transfer training models for base classes with sufficient labeled data to adapt to novel classes with only a few training examples. In this paper, we propose a deep search based prototype estimation method to improve few-shot learning. Based on the deep search, the similarity between the data in the base class can be used to better complete the prototype of the support set category. After obtaining similar samples, we can generate a prototype and then use it to estimate the distribution of the category to improve the few-shot learning task. A comparative experiment is carried out on three benchmark datasets to evaluate the effectiveness of our algorithm for few-shot learning. The results show that our method can generate more robust samples and significantly improve the few-shot learning, which is superior to the most advanced methods on these datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2153932706",
                        "name": "Zijie Yao"
                    },
                    {
                        "authorId": "2152964263",
                        "name": "Jiangzhong Cao"
                    },
                    {
                        "authorId": "48668860",
                        "name": "Sifan Huang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The Cars [30] dataset consists of 16,185 images of 196 classes of cars; it is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in 50-50.",
                "The mini-ImageNet is used for the meta-train task, and the tiered-ImageNet [52], CUB-200-2011 [58], Cars [11] datasets are used for the metatest task."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e48e8fac6e870f9f4875fd69248f8038451e075c",
                "externalIds": {
                    "DBLP": "conf/cvpr/KangHEKR23",
                    "ArXiv": "2304.01552",
                    "DOI": "10.1109/CVPR52729.2023.01543",
                    "CorpusId": 257921775
                },
                "corpusId": 257921775,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e48e8fac6e870f9f4875fd69248f8038451e075c",
                "title": "Meta-Learning with a Geometry-Adaptive Preconditioner",
                "abstract": "Model-agnostic meta-learning (MAML) is one of the most successful meta-learning algorithms. It has a bi-level optimization structure where the outer-loop process learns a shared initialization and the inner-loop process optimizes task-specific weights. Although MAML relies on the standard gradient descent in the inner-loop, recent studies have shown that controlling the inner-loop's gradient descent with a meta-learned preconditioner can be beneficial. Existing preconditioners, however, cannot simultaneously adapt in a task-specific and path-dependent way. Additionally, they do not satisfy the Riemannian metric condition, which can enable the steepest descent learning with preconditioned gradient. In this study, we propose Geometry-Adaptive Preconditioned gradient descent (GAP) that can overcome the limitations in MAML; GAP can efficiently meta-learn a preconditioner that is dependent on task-specific parameters, and its preconditioner can be shown to be a Riemannian metric. Thanks to the two properties, the geometry-adaptive preconditioner is effective for improving the inner-loop optimization. Experiment results show that GAP outperforms the state-of-the-art MAML family and preconditioned gradient descent-MAML (PGD-MAML) family in a variety of few-shot learning tasks. Code is available at: https://github.com/Suhyun777/CVPR23-GAP.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "15230387",
                        "name": "Suhyun Kang"
                    },
                    {
                        "authorId": "2030714842",
                        "name": "Duhun Hwang"
                    },
                    {
                        "authorId": "9819749",
                        "name": "Moonjung Eo"
                    },
                    {
                        "authorId": "3307885",
                        "name": "Taesup Kim"
                    },
                    {
                        "authorId": "143884871",
                        "name": "Wonjong Rhee"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fe6310bee7c368654de55d074c3efa2a07d3c25b",
                "externalIds": {
                    "DBLP": "journals/pr/PanXXS23",
                    "DOI": "10.1016/j.patcog.2023.109594",
                    "CorpusId": 257972635
                },
                "corpusId": 257972635,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fe6310bee7c368654de55d074c3efa2a07d3c25b",
                "title": "Few-shot classification with task-adaptive semantic feature learning",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2213588813",
                        "name": "Mei-hong Pan"
                    },
                    {
                        "authorId": "2057309707",
                        "name": "Hong Xin"
                    },
                    {
                        "authorId": "146450368",
                        "name": "Chun-Qiu Xia"
                    },
                    {
                        "authorId": "1796593",
                        "name": "Hongbin Shen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c0ea5cecc9669ec0a00f05821f98ee44854a7230",
                "externalIds": {
                    "DBLP": "journals/pr/LiLJLLLH23",
                    "DOI": "10.1016/j.patcog.2023.109652",
                    "CorpusId": 258423748
                },
                "corpusId": 258423748,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c0ea5cecc9669ec0a00f05821f98ee44854a7230",
                "title": "Knowledge transduction for cross-domain few-shot learning",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "96874242",
                        "name": "Pengfang Li"
                    },
                    {
                        "authorId": "70448703",
                        "name": "F. Liu"
                    },
                    {
                        "authorId": "2143819911",
                        "name": "Licheng Jiao"
                    },
                    {
                        "authorId": "40804183",
                        "name": "S. Li"
                    },
                    {
                        "authorId": "47681424",
                        "name": "Lingling Li"
                    },
                    {
                        "authorId": "2110952179",
                        "name": "Xu Liu"
                    },
                    {
                        "authorId": "2215862040",
                        "name": "Xinyan Huang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e960e12a260556cea93ca4e02450a5edc7e30d7c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2303-17768",
                    "ArXiv": "2303.17768",
                    "DOI": "10.48550/arXiv.2303.17768",
                    "CorpusId": 257900799
                },
                "corpusId": 257900799,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/e960e12a260556cea93ca4e02450a5edc7e30d7c",
                "title": "Scalable Bayesian Meta-Learning through Generalized Implicit Gradients",
                "abstract": "Meta-learning owns unique effectiveness and swiftness in tackling emerging tasks with limited data. Its broad applicability is revealed by viewing it as a bi-level optimization problem. The resultant algorithmic viewpoint however, faces scalability issues when the inner-level optimization relies on gradient-based iterations. Implicit differentiation has been considered to alleviate this challenge, but it is restricted to an isotropic Gaussian prior, and only favors deterministic meta-learning approaches. This work markedly mitigates the scalability bottleneck by cross-fertilizing the benefits of implicit differentiation to probabilistic Bayesian meta-learning. The novel implicit Bayesian meta-learning (iBaML) method not only broadens the scope of learnable priors, but also quantifies the associated uncertainty. Furthermore, the ultimate complexity is well controlled regardless of the inner-level optimization trajectory. Analytical error bounds are established to demonstrate the precision and efficiency of the generalized implicit gradient over the explicit one. Extensive numerical tests are also carried out to empirically validate the performance of the proposed method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1591119505",
                        "name": "Yilang Zhang"
                    },
                    {
                        "authorId": "2145726951",
                        "name": "Bingcong Li"
                    },
                    {
                        "authorId": "1836362",
                        "name": "Shi-Ji Gao"
                    },
                    {
                        "authorId": "144321300",
                        "name": "G. Giannakis"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "362e7184fcec5e3daf52cf5fb993799e457ba1c5",
                "externalIds": {
                    "ArXiv": "2303.15466",
                    "DBLP": "conf/cvpr/LinHMH0C23",
                    "DOI": "10.1109/CVPR52729.2023.01882",
                    "CorpusId": 257771519
                },
                "corpusId": 257771519,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/362e7184fcec5e3daf52cf5fb993799e457ba1c5",
                "title": "Supervised Masked Knowledge Distillation for Few-Shot Transformers",
                "abstract": "Vision Transformers (ViTs) emerge to achieve impressive performance on many data-abundant computer vision tasks by capturing long-range dependencies among local features. However, under few-shot learning (FSL) settings on small datasets with only a few labeled data, ViT tends to overfit and suffers from severe performance degradation due to its absence of CNN-alike inductive bias. Previous works in FSL avoid such problem either through the help of self-supervised auxiliary losses, or through the dextile uses of label information under supervised settings. But the gap between self-supervised and supervised few-shot Transformers is still unfilled. Inspired by recent advances in self-supervised knowledge distillation and masked image modeling (MIM), we propose a novel Supervised Masked Knowledge Distillation model (SMKD) for few-shot Transformers which incorporates label information into self-distillation frameworks. Compared with previous self-supervised methods, we allow intra-class knowledge distillation on both class and patch tokens, and introduce the challenging task of masked patch tokens reconstruction across intra-class images. Experimental results on four few-shot classification benchmark datasets show that our method with simple design outperforms previous methods by a large margin and achieves a new start-of-the-art. Detailed ablation studies confirm the effectiveness of each component of our model. Code for this paper is available here: https://github.com/HL-hanlin/SMKD.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2152782999",
                        "name": "Hanxi Lin"
                    },
                    {
                        "authorId": "2067641876",
                        "name": "G. Han"
                    },
                    {
                        "authorId": "152320135",
                        "name": "Jiawei Ma"
                    },
                    {
                        "authorId": "2110443113",
                        "name": "Shiyuan Huang"
                    },
                    {
                        "authorId": "48030192",
                        "name": "Xudong Lin"
                    },
                    {
                        "authorId": "2122374530",
                        "name": "Shih-Fu Chang"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", miniImageNet [1], tieredImageNet [30] and CIFAR-FS [31], utilizing Pytorch on NVIDIA Geforce RTX 3090 with 24G VRAM.",
                "Assuming that M tasks are fed to the model at an episodic training, the corresponding loss function is CIFAR-FS is a subset of the CIFAR-100 dataset with 100 different classes and 600 color images in every class.",
                "We analyze the computational complexity and conduct the \ufb01ve-way \ufb01ve-shot streaming tasks on miniImageNet, tieredImageNet, and CIFAR-FS."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4910051db9c243b1deab7f6707ba29113b14038f",
                "externalIds": {
                    "DOI": "10.1109/TNNLS.2022.3227267",
                    "CorpusId": 257701137,
                    "PubMed": "37030753"
                },
                "corpusId": 257701137,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4910051db9c243b1deab7f6707ba29113b14038f",
                "title": "Tensor-Empowered Adaptive Learning for Few-Shot Streaming Tasks",
                "abstract": "Various stream learning methods are emerging in an endless stream to provide a wealth of solutions for artificial intelligence in streaming data scenarios. However, when each data stream is oriented to a different target space, it forces stream learning approaches oriented to the same task to be no longer applicable. Due to inconsistent target spaces for different tasks, the previous approaches fail on the new streaming tasks or it is impracticable to be trained from scratch with few labeled samples at the beginning. To this end, we have proposed an adaptive learning scheme for few-shot streaming tasks with the contributions of tensor and meta-learning. This adaptive scheme is conducive to mitigating the domain shift when a new task has few labeled samples. We elaborate a novel tensor-empowered attention mechanism derived from nonlocal neural networks, which enables to capture long-range dependency and preserve the high-dimensional structure to refine the global features of streaming tasks. Furthermore, we develop a fine-grained similarity computing approach, which is prone to better characterize the difference across few-shot streaming tasks. To show the superiority of our method, we have carried out extensive experiments on three popular few-shot datasets to simulate streaming tasks and evaluate the performance of adaptation. The results show that our proposed method has achieved competitive performance for few-shot streaming tasks compared with the state-of-the-art (SOTA).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2194626384",
                        "name": "Bocheng Ren"
                    },
                    {
                        "authorId": "1690341",
                        "name": "L. Yang"
                    },
                    {
                        "authorId": "2108076070",
                        "name": "Qingchen Zhang"
                    },
                    {
                        "authorId": "2144086140",
                        "name": "Jun Feng"
                    },
                    {
                        "authorId": "2061056955",
                        "name": "Xin Nie"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4b1c9405949053f7a1694aa343cdc3e0f10c5309",
                "externalIds": {
                    "DOI": "10.1007/s11431-022-2133-1",
                    "CorpusId": 257747851
                },
                "corpusId": 257747851,
                "publicationVenue": {
                    "id": "e66be951-1e6a-417b-b768-fa43c83c31f6",
                    "name": "Science China Technological Sciences",
                    "type": "journal",
                    "alternate_names": [
                        "Sci China Technol Sci",
                        "Sci China-technological Sci",
                        "Science China-technological Sciences"
                    ],
                    "issn": "1869-1900",
                    "url": "https://link.springer.com/journal/volumesAndIssues/11431"
                },
                "url": "https://www.semanticscholar.org/paper/4b1c9405949053f7a1694aa343cdc3e0f10c5309",
                "title": "Recent advances of few-shot learning methods and applications",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2109084646",
                        "name": "Jianyuan Wang"
                    },
                    {
                        "authorId": "49600047",
                        "name": "Kexin Liu"
                    },
                    {
                        "authorId": "2119590915",
                        "name": "Yucheng Zhang"
                    },
                    {
                        "authorId": "2858789",
                        "name": "B. Leng"
                    },
                    {
                        "authorId": "2205846604",
                        "name": "Jinhu Lu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bdd12d8112c7a6c8ffc15a7bde6395714b0a4b7d",
                "externalIds": {
                    "DBLP": "conf/cvpr/HuSWLYT23",
                    "ArXiv": "2303.11183",
                    "DOI": "10.1109/CVPR52729.2023.00747",
                    "CorpusId": 257631876
                },
                "corpusId": 257631876,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/bdd12d8112c7a6c8ffc15a7bde6395714b0a4b7d",
                "title": "Architecture, Dataset and Model-Scale Agnostic Data-free Meta-Learning",
                "abstract": "The goal of data-free meta-learning is to learn useful prior knowledge from a collection of pre-trained models without accessing their training data. However, existing works only solve the problem in parameter space, which (i) ignore the fruitful data knowledge contained in the pretrained models; (ii) can not scale to large-scale pre-trained models; (iii) can only meta-learn pre-trained models with the same network architecture. To address those issues, we propose a unified framework, dubbed PURER, which contains: (1) ePisode cUrriculum inveRsion (ECI) during data-free meta training; and (2) invErsion calibRation following inner loop (ICFIL) during meta testing. During meta training, we propose ECI to perform pseudo episode training for learning to adapt fast to new unseen tasks. Specifically, we progressively synthesize a sequence of pseudo episodes by distilling the training data from each pre-trained model. The ECI adaptively increases the difficulty level of pseudo episodes according to the real-time feedback of the meta model. We formulate the optimization process of meta training with ECI as an adversarial form in an end-to-end manner. During meta testing, we further propose a simple plug-and-play supplement\u2014ICFIL\u2014only used during meta testing to narrow the gap between meta training and meta testing task distribution. Extensive experiments in various real-world scenarios show the superior performance of ours.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1557412467",
                        "name": "Zixuan Hu"
                    },
                    {
                        "authorId": "2144035454",
                        "name": "Li Shen"
                    },
                    {
                        "authorId": "2920297",
                        "name": "Zhenyi Wang"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    },
                    {
                        "authorId": "2117728946",
                        "name": "Chun Yuan"
                    },
                    {
                        "authorId": "2135519749",
                        "name": "Dacheng Tao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fd8b40bd4aaf87256be8e933253f6c5c40c647f4",
                "externalIds": {
                    "ArXiv": "2303.08129",
                    "DBLP": "conf/cvpr/ChenZZWLGZ23",
                    "DOI": "10.1109/CVPR52729.2023.00512",
                    "CorpusId": 257505114
                },
                "corpusId": 257505114,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fd8b40bd4aaf87256be8e933253f6c5c40c647f4",
                "title": "PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection",
                "abstract": "Masked Autoencoders learn strong visual representations and achieve state-of-the-art results in several independent modalities, yet very few works have addressed their capabilities in multi-modality settings. In this work, we focus on point cloud and RGB image data, two modalities that are often presented together in the real world, and explore their meaningful interactions. To improve upon the cross-modal synergy in existing works, we propose Pi-MAE, a self-supervised pre-training framework that promotes 3D and 2D interaction through three aspects. Specifically, we first notice the importance of masking strategies between the two sources and utilize a projection module to complementarily align the mask and visible tokens of the two modalities. Then, we utilize a well-crafted two-branch MAE pipeline with a novel shared decoder to promote cross-modality interaction in the mask tokens. Finally, we design a unique cross-modal reconstruction module to enhance representation learning for both modalities. Through extensive experiments performed on large-scale RGB-D scene understanding benchmarks (SUN RGB-D and ScannetV2), we discover it is nontrivial to interactively learn point-image features, where we greatly improve multiple 3D detectors, 2D detectors, and few-shot classifiers by 2.9%, 6.7%, and 2.4%, respectively. Code is available at https://github.com/BLVLab/PiMAE.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2111074459",
                        "name": "Anthony Chen"
                    },
                    {
                        "authorId": "46459444",
                        "name": "Kevin Zhang"
                    },
                    {
                        "authorId": "2115713503",
                        "name": "Renrui Zhang"
                    },
                    {
                        "authorId": "2189474881",
                        "name": "Zihan Wang"
                    },
                    {
                        "authorId": "30963251",
                        "name": "Yuheng Lu"
                    },
                    {
                        "authorId": "3133575",
                        "name": "Yandong Guo"
                    },
                    {
                        "authorId": "2437353",
                        "name": "Shanghang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[90] introduced a new idea about the existing learning the optimizer methods, that is using a non-deep machine learning algorithm to adapt new tasks from few samples."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e873d79f35633f488082dac7e6a004c3fe8c9e92",
                "externalIds": {
                    "ArXiv": "2303.07502",
                    "DBLP": "journals/corr/abs-2303-07502",
                    "DOI": "10.48550/arXiv.2303.07502",
                    "CorpusId": 257504758
                },
                "corpusId": 257504758,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e873d79f35633f488082dac7e6a004c3fe8c9e92",
                "title": "Meta-learning approaches for few-shot learning: A survey of recent advances",
                "abstract": "Despite its astounding success in learning deeper multi-dimensional data, the performance of deep learning declines on new unseen tasks mainly due to its focus on same-distribution prediction. Moreover, deep learning is notorious for poor generalization from few samples. Meta-learning is a promising approach that addresses these issues by adapting to new tasks with few-shot datasets. This survey first briefly introduces meta-learning and then investigates state-of-the-art meta-learning methods and recent advances in: (I) metric-based, (II) memory-based, (III), and learning-based methods. Finally, current challenges and insights for future researches are discussed.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "74989440",
                        "name": "Hassan Gharoun"
                    },
                    {
                        "authorId": "2211475872",
                        "name": "Fereshteh Momenifar"
                    },
                    {
                        "authorId": "2149500413",
                        "name": "Fang Chen"
                    },
                    {
                        "authorId": "2152274275",
                        "name": "A. Gandomi"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2018), CIFARFS (Bertinetto et al., 2018), focus on the meta-learning N-way K-shot setting, but this setting is less applicable to transfer learning models (Dumoulin et al.",
                "Traditional few-shot learning benchmarks, i.e. miniImageNet (Cai et al., 2018), CIFARFS (Bertinetto et al., 2018), focus on the meta-learning N-way K-shot setting, but this setting is less applicable to transfer learning models (Dumoulin et al., 2021) and was demonstrated not challenging enough for\u2026",
                "Traditional few-shot learning benchmarks, i.e. miniImageNet (Cai et al., 2018), CIFARFS (Bertinetto et al., 2018), focus on the meta-learning N-way K-shot setting, but this setting is less applicable to transfer learning models (Dumoulin et al., 2021) and was demonstrated not challenging enough for large pretrained models (Dhillon et al., 2019)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a3a5770f06a36e11bdc5cc28607da640b4451b59",
                "externalIds": {
                    "ArXiv": "2303.03840",
                    "DBLP": "journals/corr/abs-2303-03840",
                    "DOI": "10.48550/arXiv.2303.03840",
                    "CorpusId": 257378516
                },
                "corpusId": 257378516,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a3a5770f06a36e11bdc5cc28607da640b4451b59",
                "title": "A Challenging Benchmark for Low-Resource Learning",
                "abstract": "With promising yet saturated results in high-resource settings, low-resource datasets have gradually become popular benchmarks for evaluating the learning ability of advanced neural networks (e.g., BigBench, superGLUE). Some models even surpass humans according to benchmark test results. However, we find that there exists a set of hard examples in low-resource settings that challenge neural networks but are not well evaluated, which causes over-estimated performance. We first give a theoretical analysis on which factors bring the difficulty of low-resource learning. It then motivate us to propose a challenging benchmark hardBench to better evaluate the learning ability, which covers 11 datasets, including 3 computer vision (CV) datasets and 8 natural language process (NLP) datasets. Experiments on a wide range of models show that neural networks, even pre-trained language models, have sharp performance drops on our benchmark, demonstrating the effectiveness on evaluating the weaknesses of neural networks. On NLP tasks, we surprisingly find that despite better results on traditional low-resource benchmarks, pre-trained networks, does not show performance improvements on our benchmarks. These results demonstrate that there are still a large robustness gap between existing models and human-level performance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2210251162",
                        "name": "Yudong Wang"
                    },
                    {
                        "authorId": "2155067678",
                        "name": "Chang Ma"
                    },
                    {
                        "authorId": "2047143813",
                        "name": "Qingxiu Dong"
                    },
                    {
                        "authorId": "47648549",
                        "name": "Lingpeng Kong"
                    },
                    {
                        "authorId": "47883405",
                        "name": "Jingjing Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "the MAML-based methods on miniImageNet [7], tieredImageNet [53] and CIFAR-FS [54], which are public benchmarks",
                "on 3 popular few-shot benchmarks: miniImageNet [7], tieredImageNet [53] and CIFAR-FS [54], where for each experiment, tasks are drawn from only one underlying distribution.",
                "For task-homogeneous setting, we conduct experiments on 3 popular few-shot benchmarks: miniImageNet [7], tieredImageNet [53] and CIFAR-FS [54], where for each experiment, tasks are drawn from only one underlying distribution.",
                "The number of metaupdate iterations is set to be 60,000 for Mixture-of-Datasets and miniImageNet, 80,000 for tieredImageNet and Meta-Dataset, and 40,000 for CIFAR-FS.",
                "5) Results on Public Benchmarks: Task-Homogeneous Benchmarks We further conduct experiments to compare the MAML-based methods on miniImageNet [7], tieredImageNet [53] and CIFAR-FS [54], which are public benchmarks following task-homogeneous setting."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "08574724ebf1db7c3b98dc819216c6c5c23fb921",
                "externalIds": {
                    "DBLP": "journals/pami/PengP23",
                    "DOI": "10.1109/TPAMI.2023.3250323",
                    "CorpusId": 257395241,
                    "PubMed": "37028045"
                },
                "corpusId": 257395241,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/08574724ebf1db7c3b98dc819216c6c5c23fb921",
                "title": "Clustered Task-Aware Meta-Learning by Learning From Learning Paths",
                "abstract": "To enable effective learning of new tasks with only a few examples, meta-learning acquires common knowledge from the existing tasks with a globally shared meta-learner. To further address the problem of task heterogeneity, recent developments balance between customization and generalization by incorporating task clustering to generate task-aware modulation to be applied to the global meta-learner. However, these methods learn task representation mostly from the features ofinput data, while the task-specific optimization process with respect to the base-learner is often neglected. In this work, we propose a Clustered Task-Aware Meta-Learning (CTML) framework with task representation learned from both features and learning paths. We first conduct rehearsed task learning from the common initialization, and collect a set of geometric quantities that adequately describes this learning path. By inputting this set of values into a meta path learner, we automatically abstract path representation optimized for downstream clustering and modulation. Aggregating the path and feature representations results in an improved task representation. To further improve inference efficiency, we devise a shortcut tunnel to bypass the rehearsed learning process at a meta-testing time. Extensive experiments on two real-world application domains: few-shot image classification and cold-start recommendation demonstrate the superiority of CTML compared to state-of-the-art methods. We provide our code at https://github.com/didiya0825.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2067915595",
                        "name": "Danni Peng"
                    },
                    {
                        "authorId": "1746914",
                        "name": "Sinno Jialin Pan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Meta-Album will further challenge the research community by being considerably larger and by mixing tasks from multiple domains, in [2-20]-way [1-20]-shot settings.",
                "CIFAR-FS [2] and FC100 [45] are remodeled from CIFAR-100 [30] for few-shot settings.",
                "Meta-Album allows us to choose N \u2208 [2, 20] and k \u2208 [1, 20]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6856ca0f0319981c40aae7cd3a68fad893d9365b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-08909",
                    "ArXiv": "2302.08909",
                    "DOI": "10.48550/arXiv.2302.08909",
                    "CorpusId": 257020005
                },
                "corpusId": 257020005,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/6856ca0f0319981c40aae7cd3a68fad893d9365b",
                "title": "Meta-Album: Multi-domain Meta-Dataset for Few-Shot Image Classification",
                "abstract": "We introduce Meta-Album, an image classification meta-dataset designed to facilitate few-shot learning, transfer learning, meta-learning, among other tasks. It includes 40 open datasets, each having at least 20 classes with 40 examples per class, with verified licences. They stem from diverse domains, such as ecology (fauna and flora), manufacturing (textures, vehicles), human actions, and optical character recognition, featuring various image scales (microscopic, human scales, remote sensing). All datasets are preprocessed, annotated, and formatted uniformly, and come in 3 versions (Micro $\\subset$ Mini $\\subset$ Extended) to match users' computational resources. We showcase the utility of the first 30 datasets on few-shot learning problems. The other 10 will be released shortly after. Meta-Album is already more diverse and larger (in number of datasets) than similar efforts, and we are committed to keep enlarging it via a series of competitions. As competitions terminate, their test data are released, thus creating a rolling benchmark, available through OpenML.org. Our website https://meta-album.github.io/ contains the source code of challenge winning methods, baseline methods, data loaders, and instructions for contributing either new datasets or algorithms to our expandable meta-dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1758125",
                        "name": "I. Ullah"
                    },
                    {
                        "authorId": "2183483246",
                        "name": "Dustin Carri'on-Ojeda"
                    },
                    {
                        "authorId": "7855312",
                        "name": "Sergio Escalera"
                    },
                    {
                        "authorId": "1743797",
                        "name": "Isabelle M Guyon"
                    },
                    {
                        "authorId": "1990802181",
                        "name": "M. Huisman"
                    },
                    {
                        "authorId": "33303942",
                        "name": "F. Mohr"
                    },
                    {
                        "authorId": "1764155",
                        "name": "J. N. Rijn"
                    },
                    {
                        "authorId": "2156232108",
                        "name": "Haozhe Sun"
                    },
                    {
                        "authorId": "1717534",
                        "name": "J. Vanschoren"
                    },
                    {
                        "authorId": "2207709076",
                        "name": "P. Vu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "3) Datasets: CIFAR-FS [64] is a few-shot dataset created by dividing the 100 classes of CIFAR-100 into 64 base classes, 16 validation classes, and 20 novel test classes.",
                "The last column denotes the OOD noise from CIFAR-FS dataset.\nis from miniImageNet.",
                "CIFAR-FS+miniImagenet in the second column represents that OOD noise is a sample from miniImageNet while replacing the sample in CIFAR-FS.",
                "In experiments, we adopt four standard few-shot classification datasets, including CIFAR-FS [64], FC-100 [65], miniImagenet [19] and tieredImagenet [63].",
                "The evaluations are conducted on 5-way 5-shot open-world settings on the CIFAR-FS dataset."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "cfcea3aafceee8be78ca04c43e2b906d9aff8409",
                "externalIds": {
                    "DBLP": "journals/pami/AnXZW23",
                    "DOI": "10.1109/TPAMI.2023.3244023",
                    "CorpusId": 256781512,
                    "PubMed": "37022893"
                },
                "corpusId": 256781512,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/cfcea3aafceee8be78ca04c43e2b906d9aff8409",
                "title": "From Instance to Metric Calibration: A Unified Framework for Open-World Few-Shot Learning",
                "abstract": "Robust few-shot learning (RFSL), which aims to address noisy labels in few-shot learning, has recently gained considerable attention. Existing RFSL methods are based on the assumption that the noise comes from known classes (in-domain), which is inconsistent with many real-world scenarios where the noise does not belong to any known classes (out-of-domain). We refer to this more complex scenario as open-world few-shot learning (OFSL), where in-domain and out-of-domain noise simultaneously exists in few-shot datasets. To address the challenging problem, we propose a unified framework to implement comprehensive calibration from instance to metric. Specifically, we design a dual-networks structure composed of a contrastive network and a meta network to respectively extract feature-related intra-class information and enlarged inter-class variations. For instance-wise calibration, we present a novel prototype modification strategy to aggregate prototypes with intra-class and inter-class instance reweighting. For metric-wise calibration, we present a novel metric to implicitly scale the per-class prediction by fusing two spatial metrics respectively constructed by the two networks. In this way, the impact of noise in OFSL can be effectively mitigated from both feature space and label space. Extensive experiments on various OFSL settings demonstrate the robustness and superiority of our method. Our source codes is available at https://github.com/anyuexuan/IDEAL.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "7686972",
                        "name": "Yuexuan An"
                    },
                    {
                        "authorId": "2190300391",
                        "name": "Hui Xue"
                    },
                    {
                        "authorId": "47039400",
                        "name": "Xingyu Zhao"
                    },
                    {
                        "authorId": "2152437139",
                        "name": "Jing Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, Omniglot is not a challenging image dataset and models can easily get near-perfect performance (Mishra et al., 2018; Miconi et al., 2018); therefore, recent works tend to choose MiniImageNet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019) instead.",
                "Here we consider the sequential version of 5-way one-shot image classification on MiniImageNet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "989830e67b55120b098afe12958b8c53d1b49f5b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-03235",
                    "ArXiv": "2302.03235",
                    "DOI": "10.48550/arXiv.2302.03235",
                    "CorpusId": 256627465
                },
                "corpusId": 256627465,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/989830e67b55120b098afe12958b8c53d1b49f5b",
                "title": "Hebbian and Gradient-based Plasticity Enables Robust Memory and Rapid Learning in RNNs",
                "abstract": "Rapidly learning from ongoing experiences and remembering past events with a flexible memory system are two core capacities of biological intelligence. While the underlying neural mechanisms are not fully understood, various evidence supports that synaptic plasticity plays a critical role in memory formation and fast learning. Inspired by these results, we equip Recurrent Neural Networks (RNNs) with plasticity rules to enable them to adapt their parameters according to ongoing experiences. In addition to the traditional local Hebbian plasticity, we propose a global, gradient-based plasticity rule, which allows the model to evolve towards its self-determined target. Our models show promising results on sequential and associative memory tasks, illustrating their ability to robustly form and retain memories. In the meantime, these models can cope with many challenging few-shot learning problems. Comparing different plasticity rules under the same framework shows that Hebbian plasticity is well-suited for several memory and associative learning tasks; however, it is outperformed by gradient-based plasticity on few-shot regression tasks which require the model to infer the underlying mapping. Code is available at https://github.com/yuvenduan/PlasticRNNs.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2087104528",
                        "name": "Y. Duan"
                    },
                    {
                        "authorId": "2072783663",
                        "name": "Zhongfan Jia"
                    },
                    {
                        "authorId": "2117125722",
                        "name": "Qian Li"
                    },
                    {
                        "authorId": "2112889691",
                        "name": "Yi Zhong"
                    },
                    {
                        "authorId": "2075321204",
                        "name": "Kaisheng Ma"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In the experiment, we compare our algorithm with the optimization in MetaOptNet on datasets CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, Rodr\u00edguez L\u00f3pez, and Lacoste 2018), which are widely used for few-shot learning.",
                "The comparison to previous work on CIFAR-FS and FC100 in the aspect of prediction accuracy is shown in Table 1.",
                "However, its optimization does not explicitly consider the\n0 500 1000 1500 2000 2500 3000 3500 Running time /s\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4\nTr ai\nni ng\nlo ss\nDataset: CIFAR-FS (5-way 5-shot) GAM MetaOptNet\n500 1000 1500 2000 2500 3000 3500 Running time /s\n0.76\n0.78\n0.80\n0.82\n0.84\nTe st\na cc\nur ac\ny\nDataset: CIFAR-FS (5-way 5-shot) GAM MetaOptNet\n0 200 400 600 800 1000 Running time /s\n0.6\n0.8\n1.0\n1.2\n1.4\nTr ai\nni ng\nlo ss\nDataset: FC100 (5-way 5-shot) GAM MetaOptNet\n0 200 400 600 800 1000 Running time /s\n0.49\n0.50\n0.51\n0.52\n0.53\n0.54\n0.55\n0.56\nTe st\na cc\nur ac\ny\nDataset: FC100 (5-way 5-shot) GAM MetaOptNet\nFigure 7: Comparison of MetaOptNet and gradient approximation method (GAM).",
                "For both CIFAR-FS and FC100 datasets, our method converges faster than the optimization in MetaOptNet in terms of the training loss and test accuracy, and achieves a higher final test accuracy."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "f23bff48ad4da52684fa983e8188343385be7a4b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2302-01970",
                    "ArXiv": "2302.01970",
                    "DOI": "10.1609/aaai.v37i10.26473",
                    "CorpusId": 256616240
                },
                "corpusId": 256616240,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/f23bff48ad4da52684fa983e8188343385be7a4b",
                "title": "Efficient Gradient Approximation Method for Constrained Bilevel Optimization",
                "abstract": "Bilevel optimization has been developed for many machine learning tasks with large-scale and high-dimensional data. This paper considers a constrained bilevel optimization problem, where the lower-level optimization problem is convex with equality and inequality constraints and the upper-level optimization problem is non-convex. The overall objective function is non-convex and non-differentiable. To solve the problem, we develop a gradient-based approach, called gradient approximation method, which determines the descent direction by computing several representative gradients of the objective function inside a neighborhood of the current estimate. We show that the algorithm asymptotically converges to the set of Clarke stationary points, and demonstrate the efficacy of the algorithm by the experiments on hyperparameter optimization and meta-learning.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2180512",
                        "name": "Siyuan Xu"
                    },
                    {
                        "authorId": "1771269",
                        "name": "Minghui Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Other approaches are essentially model based (Santoro et al., 2016; Bertinetto et al., 2018; Ravi & Larochelle, 2016; Munkhdalai & Yu, 2017) and metric space based (Koch et al.",
                "Other approaches are essentially model based (Santoro et al., 2016; Bertinetto et al., 2018; Ravi & Larochelle, 2016; Munkhdalai & Yu, 2017) and metric space based (Koch et al., 2015; Vinyals et al., 2016; Snell et al., 2017; Sung et al., 2018)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "82d5f1b40b26f1889212f0b13aa735ff221f6cff",
                "externalIds": {
                    "ArXiv": "2302.00857",
                    "DBLP": "journals/corr/abs-2302-00857",
                    "DOI": "10.48550/arXiv.2302.00857",
                    "CorpusId": 256503478
                },
                "corpusId": 256503478,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/82d5f1b40b26f1889212f0b13aa735ff221f6cff",
                "title": "Algorithm Design for Online Meta-Learning with Task Boundary Detection",
                "abstract": "Online meta-learning has recently emerged as a marriage between batch meta-learning and online learning, for achieving the capability of quick adaptation on new tasks in a lifelong manner. However, most existing approaches focus on the restrictive setting where the distribution of the online tasks remains fixed with known task boundaries. In this work, we relax these assumptions and propose a novel algorithm for task-agnostic online meta-learning in non-stationary environments. More specifically, we first propose two simple but effective detection mechanisms of task switches and distribution shift based on empirical observations, which serve as a key building block for more elegant online model updates in our algorithm: the task switch detection mechanism allows reusing of the best model available for the current task at hand, and the distribution shift detection mechanism differentiates the meta model update in order to preserve the knowledge for in-distribution tasks and quickly learn the new knowledge for out-of-distribution tasks. In particular, our online meta model updates are based only on the current data, which eliminates the need of storing previous data as required in most existing methods. We further show that a sublinear task-averaged regret can be achieved for our algorithm under mild conditions. Empirical studies on three different benchmarks clearly demonstrate the significant advantage of our algorithm over related baseline approaches.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "143827145",
                        "name": "Daouda Sow"
                    },
                    {
                        "authorId": "1641386905",
                        "name": "Sen Lin"
                    },
                    {
                        "authorId": "2397352",
                        "name": "Yitao Liang"
                    },
                    {
                        "authorId": "2144124930",
                        "name": "Junshan Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "63ad03f31c4f01a4e33774cf13ed10a8a308bc61",
                "externalIds": {
                    "DBLP": "journals/pr/LiuLLZ23",
                    "DOI": "10.1016/j.patcog.2023.109371",
                    "CorpusId": 256597063
                },
                "corpusId": 256597063,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/63ad03f31c4f01a4e33774cf13ed10a8a308bc61",
                "title": "Capturing the few-shot class distribution: Transductive distribution optimization",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46522339",
                        "name": "Xinyue Liu"
                    },
                    {
                        "authorId": "2154526114",
                        "name": "Ligang Liu"
                    },
                    {
                        "authorId": "48447230",
                        "name": "Han Liu"
                    },
                    {
                        "authorId": "2108015607",
                        "name": "Xiaotong Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [4], a variant of Ci-\nfar100 [24], contains 64, 16, and 20 categories for training, validation, and test, respectively.",
                "CIFAR-FS [4], a variant of Cifar100 [24], contains 64, 16, and 20 categories for training, validation, and test, respectively.",
                "We used two popular few-shot benchmark CIFAR-FS [4] and MiniImageNet [24] for comparison with other few-shot methods.",
                "7 shows the results of the two image models on CIFAR-FS.",
                "To validate this, we computed the average CoS between GT anchors and the output visual features of the two models trained on CIFAR-FS in Tab."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "e6133a72012f69caf6876e6b135b93d870e441be",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2301-13096",
                    "ArXiv": "2301.13096",
                    "DOI": "10.48550/arXiv.2301.13096",
                    "CorpusId": 258060158
                },
                "corpusId": 258060158,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e6133a72012f69caf6876e6b135b93d870e441be",
                "title": "Language-Driven Anchors for Zero-Shot Adversarial Robustness",
                "abstract": "Deep neural networks are known to be susceptible to adversarial attacks. In this work, we focus on improving adversarial robustness in the challenging zero-shot image classification setting. To address this issue, we propose LAAT, a novel Language-driven, Anchor-based Adversarial Training strategy. LAAT utilizes a text encoder to generate fixed anchors (normalized feature embeddings) for each category and then uses these anchors for adversarial training. By leveraging the semantic consistency of the text encoders, LAAT can enhance the adversarial robustness of the image model on novel categories without additional examples. We identify the large cosine similarity problem of recent text encoders and design several effective techniques to address it. The experimental results demonstrate that LAAT significantly improves zero-shot adversarial performance, outperforming previous state-of-the-art adversarially robust one-shot methods. Moreover, our method produces substantial zero-shot adversarial robustness when models are trained on large datasets such as ImageNet-1K and applied to several downstream datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108790183",
                        "name": "Xiao Li"
                    },
                    {
                        "authorId": "47528139",
                        "name": "Wei Zhang"
                    },
                    {
                        "authorId": "2108140808",
                        "name": "Yining Liu"
                    },
                    {
                        "authorId": "2110918716",
                        "name": "Zhan Hu"
                    },
                    {
                        "authorId": "2208118592",
                        "name": "Bo Zhang"
                    },
                    {
                        "authorId": "2148967005",
                        "name": "Xiaolin Hu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c577b9f521a111e416610ba3f13bb553504a5de0",
                "externalIds": {
                    "PubMedCentral": "9876891",
                    "DOI": "10.1038/s41598-023-28588-y",
                    "CorpusId": 256266999,
                    "PubMed": "36697442"
                },
                "corpusId": 256266999,
                "publicationVenue": {
                    "id": "f99f77b7-b1b6-44d3-984a-f288e9884b9b",
                    "name": "Scientific Reports",
                    "type": "journal",
                    "alternate_names": [
                        "Sci Rep"
                    ],
                    "issn": "2045-2322",
                    "url": "http://www.nature.com/srep/",
                    "alternate_urls": [
                        "http://www.nature.com/srep/index.html"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c577b9f521a111e416610ba3f13bb553504a5de0",
                "title": "Cross-domain few-shot learning based on pseudo-Siamese neural network",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2114983464",
                        "name": "Yuxuan Gong"
                    },
                    {
                        "authorId": "2202573416",
                        "name": "Yuqi Yue"
                    },
                    {
                        "authorId": "2170781590",
                        "name": "Weidong Ji"
                    },
                    {
                        "authorId": "2110808987",
                        "name": "Guohui Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2022 ProtoNet [6] is one of the most iconic and well-recognized few-shot learning structures; \u2022 Baseline and Baseline++ are proposed in [16] and are reported to be effective at cross-domain few-shot learning cases; \u2022 RFS [9] discarded the commonly used episodic training scheme in few-shot learning and achieved good results; \u2022 R2-D2 [8] is the representative of meta-learning, where fewshot learning is only one of many potential applications of the network.",
                "As can be seen, four out of five networks (RFS, Baseline, Baseline++, R2-D2) performed better when trained with Snapshot Serengeti than when trained with mini-ImageNet.",
                "Hence, meta-learning networks such as [7] and [8] are also used for few-shot learning tasks.",
                "When trained with mini-ImageNet, R2-D2 obtained best overall performance, and RFS is a close second."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "9a2457ea4480b25ce077e8938a36854773cd0ef7",
                "externalIds": {
                    "DBLP": "conf/ei-imawm/ChenLR23",
                    "DOI": "10.2352/ei.2023.35.7.image-280",
                    "CorpusId": 256156921
                },
                "corpusId": 256156921,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/9a2457ea4480b25ce077e8938a36854773cd0ef7",
                "title": "Challenges and constraints when applying few shot learning to a real-world scenario: In-the-wild camera-trap species classification",
                "abstract": "Few shot learning (FSL) describes the challenge of learning to classify when there are only a few labeled examples. The goal is to adapt to a new classification task using a minimum amount of new data. However, when applying FSL to real-world problems, there exist a number of constraints and challenges that are not addressed in benchmark datasets. In this paper, we consider a realistic problem that fits perfectly with the narratives of FSL: to classify animal species that appear in our in-the-wild camera traps located in Senegal, when these species have yet to appear in popular animal datasets. Using the philosophy of FSL, we would train a FSL network to learn to separate animal species, using large public datasets, and then implement the network with our data where there are fewer labeled images. To explore this framework, we construct two separate testing datasets using our data, to reflect 1) challenges due to our unique imagery properties and environments, and 2) assumptions made in benchmark datasets that do not hold in real-world scenarios. We then conduct a comparison between FSL models, which illustrates the drastic difference between testing in benchmark settings and potential implementation on real data.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1471684559",
                        "name": "Haoyu Chen"
                    },
                    {
                        "authorId": "4612644",
                        "name": "S. Lindshield"
                    },
                    {
                        "authorId": "1708696",
                        "name": "A. Reibman"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d579e4e36c0929f45048b5897bf8304cffae68dc",
                "externalIds": {
                    "DBLP": "journals/apin/ZhangWZCLW23",
                    "DOI": "10.1007/s10489-022-04409-z",
                    "CorpusId": 255927563
                },
                "corpusId": 255927563,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d579e4e36c0929f45048b5897bf8304cffae68dc",
                "title": "Robust variable structure discovery based on tilted empirical risk minimization",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2181561265",
                        "name": "Xuelin Zhang"
                    },
                    {
                        "authorId": "2130385512",
                        "name": "Yingjie Wang"
                    },
                    {
                        "authorId": "2181792016",
                        "name": "Liangxuan Zhu"
                    },
                    {
                        "authorId": "2118060529",
                        "name": "Hong Chen"
                    },
                    {
                        "authorId": "2118385191",
                        "name": "Han Li"
                    },
                    {
                        "authorId": "2116667005",
                        "name": "Ling Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4de7e0a06280dce9b997aac24e3d04446c724b88",
                "externalIds": {
                    "DBLP": "conf/icigp/0007TGX23",
                    "DOI": "10.1145/3582649.3582661",
                    "CorpusId": 258009242
                },
                "corpusId": 258009242,
                "publicationVenue": {
                    "id": "96e22978-8ca4-40ad-a4e5-c8d9b7b05471",
                    "name": "International Conference on Image and Graphics Processing",
                    "type": "conference",
                    "alternate_names": [
                        "ICIGP",
                        "Int Conf Image Graph Process"
                    ],
                    "url": "https://dl.acm.org/conference/icigp"
                },
                "url": "https://www.semanticscholar.org/paper/4de7e0a06280dce9b997aac24e3d04446c724b88",
                "title": "Attention-enhanced Relation Network for Few-shot Image Classification",
                "abstract": "Traditional deep learning models firmly rely on a large amount of labeled data during pre-training. Whereas it lacks generalization in the face of unfamiliar categories. Recently, few-shot learning is a hot topic in computer vision to classify unseen classes with limited labels. A representative approach is to extract features from the support and query sets, respectively, and compare similarities via metric learning. However, convolutional neural networks often focus only on a local region and ignore the global region, which severely reduces the accuracy of the matching. Specifically, in this paper, we pile lightweight attention-based blocks in the embedding module, which combines an adaptive kernel size 2D convolutional network with a cross-channel attention mechanism to encode multi-scale features and implicitly increase the receptive field. The SE-relation module chooses to construct learnable non-linear comparators to compare the relationship utilizing channel information. Finally, we show experimental results on standard few-shot testing benchmarks such as mini-ImageNet and tiered-ImageNet to demonstrate effectiveness.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2154860569",
                        "name": "Jinyang Li"
                    },
                    {
                        "authorId": "2147339972",
                        "name": "Jiahui Tong"
                    },
                    {
                        "authorId": "36264491",
                        "name": "Guangyu Gao"
                    },
                    {
                        "authorId": "23664353",
                        "name": "Wenbin Xu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4345f4343a5287b8e20b39104b66bcf3f31523bd",
                "externalIds": {
                    "DOI": "10.1109/ICCECE58074.2023.10135472",
                    "CorpusId": 259027632
                },
                "corpusId": 259027632,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/4345f4343a5287b8e20b39104b66bcf3f31523bd",
                "title": "Gradient-Based Meta-Learning Using Adaptive Multiple Loss Weighting and Homoscedastic Uncertainty",
                "abstract": "Model-agnostic meta-learning schemes adopt gradient descent to learn task commonalities and obtain the initialization parameters of the meta-model to rapidly adjust to new tasks with only a few training samples. Therefore, such schemes have become the mainstream meta-learning approach for studying few shot learning problems. This study mainly addresses the challenge of task uncertainty in few-shot learning and proposes an improved meta-learning approach, which first enables a task specific learner to select the initial parameter that minimize the loss of a new task, then generates weights by comparing meta-loss differences, and finally leads into the homoscedastic uncertainty of the task to weight the diverse losses. Our model conducts superior on few shot learning task than previous meta learning approach and improves its robustness regardless of the initial learning rates and query sets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2181814102",
                        "name": "Lin Ding"
                    },
                    {
                        "authorId": "2149662002",
                        "name": "Wenfeng Shen"
                    },
                    {
                        "authorId": "1865353860",
                        "name": "Weijia Lu"
                    },
                    {
                        "authorId": "145779142",
                        "name": "Peng Liu"
                    },
                    {
                        "authorId": "2145396599",
                        "name": "Shengbo Chen"
                    },
                    {
                        "authorId": "2156091020",
                        "name": "Sisi Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In addition, DSMNet outperforms or matches the previous state-ofthe-art models on miniImagenet, CUB-200, Stanford-Dogs, and CIFAR-FS datasets.",
                "To evaluate the performance of DSMNet on fine-grained datasets, we conducted experiments on CUB-200, StanfordDogs, and CIFAR-FS datasets.",
                "All images in CIFAR-FS have the same resolution of 32 \u00d7 32.",
                "Under the 5-way 1-shot setting, our DSMNet achieves competitive results on CIFAR-FS dataset, whereas the results on the Stanford Dogs dataset are somewhat less satisfactory, which can be attributed to two possible reasons.",
                "As shown in Tables 4 and 5, under the 5-way 5-shot setting, our DSMNet achieves the highest results on both Stanford Dogs\nand CIFAR-FS datasets.",
                "In this experiment, we select four benchmark datasets including miniImagenet [18], and three fine-grained datasets that are Caltech-UCSD Birds-200-2011 (CUB200) [51], Stanford-Dogs [52], and CIFAR100 few-shots (CIFAR-FS) [53].",
                "CIFAR-FS: This dataset [53] is sampled from CIFAR100 dataset [55].",
                "To investigate the effects of different backbones on DSMNet, we used ResNet10 [65], ResNet12 [47], ResNet18 [65], ResNet34 [65], and WRN-28-10 [66] as embedding module respectively, and conducted experiments on miniImagenet, CUB-200, Stanford-Dogs, and CIFAR-FS datasets.",
                "To verify the effectiveness of the adaptation strategy, we conducted two sets of experiments on miniImagenet, CUB200, Stanford-Dogs, and CIFAR-FS datasets.",
                "We show some of the representative images from miniImagenet, CUB-200, Stanford-Dogs, and CIFAR-FS in Fig."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "e1daa9bf4f6118d40774be3fca2b4b6975582d58",
                "externalIds": {
                    "DBLP": "journals/apin/YanLZZ23",
                    "DOI": "10.1007/s10489-022-04413-3",
                    "CorpusId": 255690719
                },
                "corpusId": 255690719,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e1daa9bf4f6118d40774be3fca2b4b6975582d58",
                "title": "Discriminant space metric network for few-shot image classification",
                "abstract": null,
                "year": 2023,
                "authors": [
                    {
                        "authorId": "48028055",
                        "name": "Leilei Yan"
                    },
                    {
                        "authorId": "2314391",
                        "name": "Fanzhang Li"
                    },
                    {
                        "authorId": "2152827162",
                        "name": "Li Zhang"
                    },
                    {
                        "authorId": "2004974199",
                        "name": "Xiaohan Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Optimization-based methods (Bertinetto et al. 2019)(Finn, Abbeel, and Levine 2017)(Ravi and Larochelle 2017) usually train a meta learner over auxiliary dataset to learn a general initialization model, which can fine-tune and adapt to new tasks very soon."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "01b14c1c3e2b5b4042d57f1a2be47d423c7fd68b",
                "externalIds": {
                    "ArXiv": "2301.01956",
                    "DBLP": "conf/aaai/YuYH0023",
                    "DOI": "10.48550/arXiv.2301.01956",
                    "CorpusId": 255440408
                },
                "corpusId": 255440408,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/01b14c1c3e2b5b4042d57f1a2be47d423c7fd68b",
                "title": "High-level semantic feature matters few-shot unsupervised domain adaptation",
                "abstract": "In few-shot unsupervised domain adaptation (FS-UDA), most existing methods followed the few-shot learning (FSL) methods to leverage the low-level local features (learned from conventional convolutional models, e.g., ResNet) for classification. However, the goal of FS-UDA and FSL are relevant yet distinct, since FS-UDA aims to classify the samples in target domain rather than source domain. We found that the local features are insufficient to FS-UDA, which could introduce noise or bias against classification, and not be used to effectively align the domains. To address the above issues, we aim to refine the local features to be more discriminative and relevant to classification. Thus, we propose a novel task-specific semantic feature learning method (TSECS) for FS-UDA. TSECS learns high-level semantic features for image-to-class similarity measurement. Based on the high-level features, we design a cross-domain self-training strategy to leverage the few labeled samples in source domain to build the classifier in target domain. In addition, we minimize the KL divergence of the high-level feature distributions between source and target domains to shorten the distance of the samples between the two domains. Extensive experiments on DomainNet show that the proposed method significantly outperforms SOTA methods in FS-UDA by a large margin (i.e., ~10%).",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2109352322",
                        "name": "Lei Yu"
                    },
                    {
                        "authorId": "3183928",
                        "name": "Wanqi Yang"
                    },
                    {
                        "authorId": "2149206104",
                        "name": "Sheng Huang"
                    },
                    {
                        "authorId": "36547165",
                        "name": "Lei Wang"
                    },
                    {
                        "authorId": "2150425915",
                        "name": "Ming Yang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "df35736a2fb8fbe740abf232c878771d56fbbd4f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2301-01716",
                    "ArXiv": "2301.01716",
                    "DOI": "10.48550/arXiv.2301.01716",
                    "CorpusId": 255416086
                },
                "corpusId": 255416086,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/df35736a2fb8fbe740abf232c878771d56fbbd4f",
                "title": "First-order penalty methods for bilevel optimization",
                "abstract": "In this paper we study a class of unconstrained and constrained bilevel optimization problems in which the lower-level part is a convex optimization problem, while the upper-level part is possibly a nonconvex optimization problem. In particular, we propose penalty methods for solving them, whose subproblems turn out to be a structured minimax problem and are suitably solved by a first-order method developed in this paper. Under some suitable assumptions, an \\emph{operation complexity} of ${\\cal O}(\\varepsilon^{-4}\\log\\varepsilon^{-1})$ and ${\\cal O}(\\varepsilon^{-7}\\log\\varepsilon^{-1})$, measured by their fundamental operations, is established for the proposed penalty methods for finding an $\\varepsilon$-KKT solution of the unconstrained and constrained bilevel optimization problems, respectively. To the best of our knowledge, the methodology and results in this paper are new.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "6201715",
                        "name": "Zhaosong Lu"
                    },
                    {
                        "authorId": "2167582713",
                        "name": "Sanyou Mei"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Way 1-Shot accuracy of different P on validation set of miniImageNet and CIFAR-FS.",
                "MiniImageNet and tieredImageNet are derivatives of ImageNet dataset [36], CIFAR-FS is derived from CIFAR-100 dataset [20,43].",
                "We conduct our experiments on 4 widely used FSL benchmarks, i.e., miniImageNet [44], tieredImageNet [34], CIFAR-FS [4], and CUB [45].",
                "Way 1-Shot results when setting different weight coefficients \u03bb on the validation set of miniImageNet and CIFAR-FS.",
                ", miniImageNet [44], tieredImageNet [34], CIFAR-FS [4], and CUB [45].",
                "In addition, as shown in Tab.6, our method also gets competitive results on CIFAR-FS.",
                "As for benchmarks without semantic knowledge annotations (e.g., class-aware attributes annotations) such as miniImageNet, tieredImageNet, and CIFAR-FS, previous works always leverage pretrained Word2Vec models such as GloVe [29] as the semantic source."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "c3e0c9abf233397f2a709c675e745e22bcd78919",
                "externalIds": {
                    "DBLP": "conf/wacv/YangWC23",
                    "DOI": "10.1109/WACV56688.2023.00541",
                    "CorpusId": 256648976
                },
                "corpusId": 256648976,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/c3e0c9abf233397f2a709c675e745e22bcd78919",
                "title": "Semantic Guided Latent Parts Embedding for Few-Shot Learning",
                "abstract": "The ability of few-shot learning (FSL) is a basic requirement of intelligent agent learning in the open visual world. However, existing deep learning systems rely too heavily on large numbers of training samples, making it hard to learn new categories efficiently from limited size of training data. Two key challenges of FSL are insufficient comprehension and imperfect modeling of the few-shot novel class. For insufficient visual comprehension, semantic knowledge which is information from other modalities can help replenish the understanding of novel classes. But even so, most works still suffer from the second challenge because the single global class prototype they adopted is extremely unstable and imperfect given the larger intra-class variation and harder inter-class discrimination in FSL scenario. Thus, we propose to represent each class by its several different parts with the help of class semantic knowledge. Since we can never pre-define parts for unknown novel classes, we embed them in a latent manner. Concretely, we train a generator that takes the class semantic knowledge as input and outputs several filters of class-specific semantic latent parts. By applying each part filter, our model can pay attention to corresponding local regions containing each part. At the inference stage, the classification is conducted by comparing the similarities between those parts. Experiments on several FSL benchmarks demonstrate the effectiveness of our proposed method and show its potential to go beyond class recognition to class understanding. Furthermore, we also find when semantic knowledge is more visualized and customized, it will be more helpful in the FSL task.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2156127601",
                        "name": "Fengyuan Yang"
                    },
                    {
                        "authorId": "2108681349",
                        "name": "Ruiping Wang"
                    },
                    {
                        "authorId": "2118026024",
                        "name": "Xilin Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "And R2-D2 [4] learns the feature extractor that adapts well to closed-formed linear classifiers.",
                "The adaptation of the entire network makes it hard to be scaled to large networks, and many recent efforts focus on adapting the last classification layer only [12, 4], while assuming a universal feature extractor that is shared across all tasks."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b9cd098485c14e33ffdbb29ce8962c57f9d5e99b",
                "externalIds": {
                    "DBLP": "conf/wacv/WangLQ23",
                    "DOI": "10.1109/WACV56688.2023.00527",
                    "CorpusId": 256652525
                },
                "corpusId": 256652525,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/b9cd098485c14e33ffdbb29ce8962c57f9d5e99b",
                "title": "Meta-OLE: Meta-learned Orthogonal Low-Rank Embedding",
                "abstract": "We introduce Meta-OLE, a new geometry-regularized method for fast adaptation to novel tasks in few-shot image classification. The proposed method learns to adapt for each few-shot classification task a feature space with simultaneous inter-class orthogonality and intra-class low-rankness. Specifically, a deep feature extractor is trained by explicitly imposing orthogonal low-rank subspace structures among features corresponding to different classes within a given task. To adapt to novel tasks with unseen categories, we further meta-learn a light-weight transformation to enhance the inter-class margins. As an additional benefit, this light-weight transformation lets us exploit the query data for label propagation from labeled to unlabeled data without any auxiliary network components. The explicitly geometry-regularized feature subspaces allow the classifiers on novel tasks to be inferred in a closed form, with an adaptive subspace truncation that selectively discards non-discriminative dimensions. We perform experiments on standard few-shot image classification tasks, and observe performance superior to state-of-the-art meta-learning methods.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108725378",
                        "name": "Ze Wang"
                    },
                    {
                        "authorId": "2140029375",
                        "name": "Yue Lu"
                    },
                    {
                        "authorId": "2077648",
                        "name": "Qiang Qiu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "819f986d6ad4d3902e38d0226132cf35059f0b84",
                "externalIds": {
                    "DBLP": "conf/wacv/ChungP23",
                    "DOI": "10.1109/WACVW58289.2023.00046",
                    "CorpusId": 256669550
                },
                "corpusId": 256669550,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/819f986d6ad4d3902e38d0226132cf35059f0b84",
                "title": "Is Meta-Learning Always Necessary?: A Practical ML Framework Solving Novel Tasks at Large-scale Car Sharing Platform",
                "abstract": "While the deep neural networks achieved superior performance in various tasks under the supervised regime, the ML practitioners in the real world frequently encounter a novel task that cannot acquire the labeled dataset shortly. Even if they have become available in acquiring the target samples from the unlabeled dataset, conventional labeling procedures require the practitioners to invest in resource consumption. Pursuing an effective solution to these problems, our study proposes a practical ML framework that efficiently enables practitioners to solve novel tasks. Our ML framework consists of two solutions consisting of early and mature stages. First, the early stage solution lets the practitioners solve the novel task under the few-shot classification setting. Second, the mature stage solution enhances the labeling efficiency by retrieving samples that seem relevant to the target. Upon these solutions, acquiring a qualified representation power is the most important job. Under the public benchmark datasets and image recognition tasks in a large-scale car-sharing platform, we examined that the paradigm of supervised learning, surprisingly not meta-learning, produces the most beneficial representation power to solve novel tasks. We further scrutinized the supremacy of supervised representation derives from broader, nourished high-level representations in the neural networks. We highly expect our analyses can be a concrete benchmark to the ML practitioners who solve novel tasks in their domain.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "97942821",
                        "name": "Hyun-Kyo Chung"
                    },
                    {
                        "authorId": "1994417846",
                        "name": "Kyungchul Park"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Table 3 displays the results on CIFAR-FS.",
                "Datasets The experiments are conducted on three few-shot learning benchmarks, including miniImageNet [6], CUB-200-2011 [31], and CIFAR-FS [32].",
                "The experiments are conducted on three few-shot learning benchmarks, including miniImageNet [6], CUB-200-2011 [31], and CIFAR-FS [32]. miniImageNet is a mini-version of the ImageNet dataset [33], which contains 100 classes with 600 images per class, and the image size is 84 \u00d7 84 \u00d7 3. miniImageNet is divided into 64 base classes, 16 validation classes,\nand 20 novel classes in all experiments.",
                "%) on CIFAR-FS with 95% confidence intervals.",
                "All tables show that our framework achieves the best performance for 1-shot and 5-shot compared with the other state-of-the-art on miniImageNet, CUB-200-2011, and CIFAR-FS.",
                "Extensive experiments are conducted on the miniImageNet, CUB-200-2011, and CIFAR-FS.",
                "CIFAR-FS is created by randomly splitting 100 classes of CIFAR-100 [34] into 64 base classes, 16 validation classes, and 20 novel classes.",
                "Method CIFAR-FS\n5-way-1-shot 5-way-5-shot\nOptimization-based ICML17\u2019 MAML [4] 58.9\u00b1 1.9 71.5\u00b1 1.0 ICLR19\u2019 R2D2 [32] 65.4\u00b1 0.2 79.4\u00b1 0.2 CVPR19\u2019 MetaOptNet [46] 72.8\u00b1 0.7 85.0\u00b1 0.5\nMetric-based\nNIPS17\u2019 ProtoNet [14] 55.5\u00b1 0.7 72.0\u00b1 0.6 CVPR18\u2019 RelationNet [40] 55.0\u00b1 1.0 69.3\u00b1 0.8 AAAI22\u2019 AAP2S [42] 73.12\u00b1 0.22 85.69\u00b1 0.16 CVPR19\u2019 Shot-Free [47] 69.15 84.70\nFine-tuning-based ICLR19\u2019 Baseline++ [15] 67.50\u00b1 0.64 80.08\u00b1 0.32\nOurs PSDC 74.66 \u00b1 0.21 86.37 \u00b1 0.15"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1891d0ed7bfc3704e3eae6768731ea07f21b11b3",
                "externalIds": {
                    "DOI": "10.3390/electronics12010134",
                    "CorpusId": 255258458
                },
                "corpusId": 255258458,
                "publicationVenue": {
                    "id": "ccd8e532-73c6-414f-bc91-271bbb2933e2",
                    "name": "Electronics",
                    "type": "journal",
                    "issn": "1450-5843",
                    "alternate_issns": [
                        "2079-9292",
                        "0883-4989"
                    ],
                    "url": "http://www.electronics.etfbl.net/",
                    "alternate_urls": [
                        "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-247562",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-247562",
                        "https://www.mdpi.com/journal/electronics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1891d0ed7bfc3704e3eae6768731ea07f21b11b3",
                "title": "Prototype-Based Self-Adaptive Distribution Calibration for Few-Shot Image Classification",
                "abstract": "Deep learning has flourished in large-scale supervised tasks. However, in many practical conditions, rich and available labeled data are a luxury. Thus, few-shot learning (FSL) has recently received boosting interest and achieved significant progress, which can learn new classes from several labeled samples. The advanced distribution calibration approach estimates the ground-truth distribution of few-shot classes by reusing the statistics of auxiliary data. However, there is still a significant discrepancy between the estimated distributions and ground-truth distributions, and artificially set hyperparameters cannot be adapted to different application scenarios (i.e., datasets). This paper proposes a prototype-based self-adaptive distribution calibration framework for estimating ground-truth distribution accurately and self-adaptive hyperparameter optimization for different application scenarios. Specifically, the proposed method is divided into two components. The prototype-based representative mechanism is for obtaining and utilizing more global information about few-shot classes and improving classification performance. The self-adaptive hyperparameter optimization algorithm searches robust hyperparameters for the distribution calibration of different application scenarios. The ablation studies verify the effectiveness of the various components of the proposed framework. Enormous experiments are conducted on three standard benchmarks such as miniImageNet, CUB-200-2011, and CIFAR-FS. The competitive results and compelling visualizations indicate that the proposed framework achieves state-of-the-art performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2072592314",
                        "name": "Wei Du"
                    },
                    {
                        "authorId": "2109788106",
                        "name": "Xiao Hu"
                    },
                    {
                        "authorId": "2110847861",
                        "name": "Xin Wei"
                    },
                    {
                        "authorId": "2060131065",
                        "name": "K. Zuo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We evaluate our approach using four datasets: (i) Mini-ImageNet (Vinyals et al., 2016), (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al., 2018), (iv) and EMNIST (balanced) (Cohen et al., 2017).",
                "This occurred around iteration 16,000 for CIFAR-FS and around iteration 20,000 for Mini-ImageNet, slightly after the first learning rate decay (at 15,000 and 18,000 steps, respectively).",
                "CIFAR-FS consists of a random split of the CIFAR-100 classes into 64 meta-train classes, 14 meta-validation classes, and 20 meta-test classes.",
                "CIFAR-FS and FC-100 are both derived from the CIFAR-100 dataset (Krizhevsky, 2012).",
                "To demonstrate this, we compared the 1- and 5-shot performance of our approach to several other few-shot learning algorithms on the Mini-ImageNet, CIFAR-FS, and FC-100 datasets, as summarized in Table 1.",
                ", 2016), (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al.",
                "Therefore, we empirically investigated the dynamics of mini 6=j\u2208[l] \u2016\u00b5f (S\u0303i)\u2212\u00b5f (S\u0303j)\u2016 during training in our standard setting (WRN-28-4 with the default hyperparameters, see Section 2) on CIFAR-FS, considering a varying number source classes (l \u2208 {5, 10, 20, 30, 40, 50, 60}) and learning rates (\u03b7 \u2208 {2\u22122i\u22122}4i=1)."
            ],
            "intents": [],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "62147e4f02b1ba50c8aa635c134bde110d1b8031",
                "externalIds": {
                    "ArXiv": "2212.12532",
                    "CorpusId": 259937296
                },
                "corpusId": 259937296,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/62147e4f02b1ba50c8aa635c134bde110d1b8031",
                "title": "Generalization Bounds for Few-Shot Transfer Learning with Pretrained Classifiers",
                "abstract": "We study the ability of foundation models to learn representations for classification that are transferable to new, unseen classes. Recent results in the literature show that representations learned by a single classifier over many classes are competitive on few-shot learning problems with representations learned by special-purpose algorithms designed for such problems. We offer a theoretical explanation for this behavior based on the recently discovered phenomenon of class-feature-variability collapse, that is, that during the training of deep classification networks the feature embeddings of samples belonging to the same class tend to concentrate around their class means. More specifically, we show that the few-shot error of the learned feature map on new classes (defined as the classification error of the nearest class-center classifier using centers learned from a small number of random samples from each new class) is small in case of class-feature-variability collapse, under the assumption that the classes are selected independently from a fixed distribution. This suggests that foundation models can provide feature maps that are transferable to new downstream tasks, even with very few samples; to our knowledge, this is the first performance bound for transfer-learning that is non-vacuous in the few-shot setting.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "9923405",
                        "name": "Tomer Galanti"
                    },
                    {
                        "authorId": "2090601385",
                        "name": "Andr'as Gyorgy"
                    },
                    {
                        "authorId": "144154444",
                        "name": "Marcus Hutter"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Additionally, [17] showed that meta fine-tuning the entire representation model using MetaOptNet [31] or R2D2 [4] lead to worse performance compared to standard meta-learning, negating the advantages of pre-training completely.",
                "Similarly, while RFS and R2D2 both learn a fixed representation and only adapt the classifier based on each task, RFS\u2019s pre-trained representation clearly outperforms R2D2\u2019s meta-learned representation.",
                "Our proposed method is most closely related to meta-representation learning [4, 15, 32, 48], which parametrizes the base learner as A(\u03b8,D) = w(g\u03b8(D))g\u03b8(\u00b7), separating it into parts of a global feature extractor g\u03b8 : X \u2192 Rm and a task-adaptive classifier w : D \u2192 {f : Rm \u2192 Y} resulting in the optimization problem",
                "The task-adaptive classifier w(\u00b7) may take various forms, including nearest neighbor [59], ridge regression classifier [4], embedding adaptation with transformer models [73], and Wasserstein distance metric [74].",
                "R2D2 [4], ProtoNet [42]) learn classifiers by minimizing some loss over support sets, losing out on the access to the contextual information provided by global labels.",
                "1-shot 5-shot\nProtoNet 47.8\u00b1 0.5 66.8\u00b1 0.5 MatchNet 65.6\u00b1 0.2 78.7\u00b1 0.2 R2D2 75.1\u00b1 0.3 86.4\u00b1 0.2 DeepEMD 51.3\u00b1 0.5 65.6\u00b1 0.8 FEAT 77.6\u00b1 0.6 87.3\u00b1 0.4 FRN 81.9\u00b1 0.4 91.0\u00b1 0.2 MeLa 84.8\u00b1 0.3 92.9\u00b1 0.2\nOracle 84.4\u00b1 0.3 93.1\u00b1 0.2\nfurther improved, since the pre-trained representation is not explicitly optimized for handling novel classes.",
                "In contrast, unconditional approaches (e.g. R2D2 [4], ProtoNet [42]) learn classifiers by minimizing some loss over support sets, losing out on the access to the contextual information provided by global labels."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "13388109ea0d1e332f11647f2d24655bfe08a5f3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-11702",
                    "ArXiv": "2212.11702",
                    "DOI": "10.48550/arXiv.2212.11702",
                    "CorpusId": 254974049
                },
                "corpusId": 254974049,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/13388109ea0d1e332f11647f2d24655bfe08a5f3",
                "title": "Robust Meta-Representation Learning via Global Label Inference and Classification",
                "abstract": "Few-shot learning (FSL) is a central problem in meta-learning, where learners must e\ufb03ciently learn from few labeled examples. Within FSL, feature pre-training has recently become an increasingly popular strategy to signi\ufb01cantly improve generalization performance. However, the contribution of pre-training is often overlooked and understudied, with limited theoretical understanding of its impact on meta-learning performance. Further, pre-training requires a consistent set of global labels shared across training tasks, which may be unavailable in practice. In this work, we address the above issues by \ufb01rst showing the connection between pre-training and meta-learning. We discuss why pre-training yields more robust meta-representation and connect the theoretical analysis to existing works and empirical results. Secondly, we introduce Meta Label Learning (MeLa), a novel meta-learning algorithm that learns task relations by inferring global labels across tasks. This allows us to exploit pre-training for FSL even when global labels are unavailable or ill-de\ufb01ned. Lastly, we introduce an augmented pre-training procedure that further improves the learned meta-representation. Empirically, MeLa outperforms existing methods across a diverse range of benchmarks, in particular under a more challenging setting where the number of training tasks is limited and labels are task-speci\ufb01c. We also provide extensive ablation study to highlight its key properties.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3368222",
                        "name": "Ruohan Wang"
                    },
                    {
                        "authorId": "2024989125",
                        "name": "Isak Falk"
                    },
                    {
                        "authorId": "1704699",
                        "name": "M. Pontil"
                    },
                    {
                        "authorId": "7666146",
                        "name": "C. Ciliberto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[67] Luca Bertinetto, Joao F Henriques, Philip Torr, and Andrea Vedaldi.",
                "And we compare the proposed CPBO with baseline algorithms MAML [64], iMAML [63], and ANIL [65] on Omniglot [66] and CIFAR-FS [67] datasets."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0fe9f385491619f6db18b10ce574a6eb6f702562",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-10048",
                    "ArXiv": "2212.10048",
                    "DOI": "10.48550/arXiv.2212.10048",
                    "CorpusId": 254877249
                },
                "corpusId": 254877249,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0fe9f385491619f6db18b10ce574a6eb6f702562",
                "title": "Asynchronous Distributed Bilevel Optimization",
                "abstract": "Bilevel optimization plays an essential role in many machine learning tasks, ranging from hyperparameter optimization to meta-learning. Existing studies on bilevel optimization, however, focus on either centralized or synchronous distributed setting. The centralized bilevel optimization approaches require collecting massive amount of data to a single server, which inevitably incur significant communication expenses and may give rise to data privacy risks. Synchronous distributed bilevel optimization algorithms, on the other hand, often face the straggler problem and will immediately stop working if a few workers fail to respond. As a remedy, we propose Asynchronous Distributed Bilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel optimization problems with both nonconvex upper-level and lower-level objective functions, and its convergence is theoretically guaranteed. Furthermore, it is revealed through theoretic analysis that the iteration complexity of ADBO to obtain the $\\epsilon$-stationary point is upper bounded by $\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public datasets have been conducted to elucidate the effectiveness and efficiency of the proposed ADBO.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2055181125",
                        "name": "Yang Jiao"
                    },
                    {
                        "authorId": "2163436495",
                        "name": "Kai Yang"
                    },
                    {
                        "authorId": "2116518438",
                        "name": "Tiancheng Wu"
                    },
                    {
                        "authorId": "2451800",
                        "name": "Dongjin Song"
                    },
                    {
                        "authorId": "2142035704",
                        "name": "Chen Jian"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The way MLPs transform data in Transformers diverges from the standard meta-learning approach, where a task-shared input embedding network is optimized by backpropagation-through-training to improve the learning performance of a task-specific readout (e.g., Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019).",
                "\u2026data in Transformers diverges from the standard meta-learning approach, where a task-shared input embedding network is optimized by backpropagation-through-training to improve the learning performance of a task-specific readout (e.g., Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "525d93a382f6e7873b5d8a2e0713eb3dff7fb250",
                "externalIds": {
                    "DBLP": "conf/icml/OswaldNRSMZV23",
                    "ArXiv": "2212.07677",
                    "DOI": "10.48550/arXiv.2212.07677",
                    "CorpusId": 254685643
                },
                "corpusId": 254685643,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/525d93a382f6e7873b5d8a2e0713eb3dff7fb250",
                "title": "Transformers learn in-context by gradient descent",
                "abstract": "At present, the mechanisms of in-context learning in Transformers are not well understood and remain mostly an intuition. In this paper, we suggest that training Transformers on auto-regressive objectives is closely related to gradient-based meta-learning formulations. We start by providing a simple weight construction that shows the equivalence of data transformations induced by 1) a single linear self-attention layer and by 2) gradient-descent (GD) on a regression loss. Motivated by that construction, we show empirically that when training self-attention-only Transformers on simple regression tasks either the models learned by GD and Transformers show great similarity or, remarkably, the weights found by optimization match the construction. Thus we show how trained Transformers become mesa-optimizers i.e. learn models by gradient descent in their forward pass. This allows us, at least in the domain of regression problems, to mechanistically understand the inner workings of in-context learning in optimized Transformers. Building on this insight, we furthermore identify how Transformers surpass the performance of plain gradient descent by learning an iterative curvature correction and learn linear models on deep data representations to solve non-linear regression tasks. Finally, we discuss intriguing parallels to a mechanism identified to be crucial for in-context learning termed induction-head (Olsson et al., 2022) and show how it could be understood as a specific case of in-context learning by gradient descent learning within Transformers. Code to reproduce the experiments can be found at https://github.com/google-research/self-organising-systems/tree/master/transformers_learn_icl_by_gd .",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145167136",
                        "name": "J. Oswald"
                    },
                    {
                        "authorId": "51440033",
                        "name": "Eyvind Niklasson"
                    },
                    {
                        "authorId": "72142084",
                        "name": "E. Randazzo"
                    },
                    {
                        "authorId": "3105061",
                        "name": "J. Sacramento"
                    },
                    {
                        "authorId": "2050989525",
                        "name": "A. Mordvintsev"
                    },
                    {
                        "authorId": "3422677",
                        "name": "A. Zhmoginov"
                    },
                    {
                        "authorId": "3316311",
                        "name": "Max Vladymyrov"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f451f5c07245affbdb774c5c0f326372495cacd4",
                "externalIds": {
                    "DBLP": "journals/mlc/WangWC23",
                    "DOI": "10.1007/s13042-022-01727-z",
                    "CorpusId": 254613959
                },
                "corpusId": 254613959,
                "publicationVenue": {
                    "id": "a0c45882-7c78-4f0c-8886-d3481ba02586",
                    "name": "International Journal of Machine Learning and Cybernetics",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Mach Learn Cybern"
                    ],
                    "issn": "1868-8071",
                    "url": "http://www.springer.com/engineering/mathematical/journal/13042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/13042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f451f5c07245affbdb774c5c0f326372495cacd4",
                "title": "Few-shot learning based on enhanced pseudo-labels and graded pseudo-labeled data selection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2186273993",
                        "name": "Kang Wang"
                    },
                    {
                        "authorId": "153316233",
                        "name": "Xuesong Wang"
                    },
                    {
                        "authorId": "33718755",
                        "name": "Yuhu Cheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "DiffAlign has outperformed state-of-the-art approaches on standard few-show classification benchmarks, such as FC100, CIFAR-FS, miniImageNet, tieredImageNet, in both 5- shot and 1-shot setups.",
                "Ablation on losses\nLosses FC-100 CIFAR-FS miniImageNet\n5w1s 5w5s 5w1s 5w5s 5w1s 5w5s Lnovel 48.1 \u00b1 0.8 65.0 \u00b1 0.7 77.6 \u00b1 1.0 89.71 \u00b1 0.6 66.85 \u00b1 0.76 84.50 \u00b1 0.53 Lnovel + Lsyn 67.33 \u00b1 0.7 73.11 \u00b1 0.7 86.33 \u00b1 0.8 90.87 \u00b1 0.5 80.92 \u00b1 0.7 85.05 \u00b1 0.48 Lnovel + Lsyn + Lbase 69.18 \u00b1 0.7 75.99 \u00b1 0.7 88.9 \u00b1 0.8 91.83 \u00b1 0.5 82.16 \u00b1 0.7 87.88 \u00b1 0.5 Lnovel + Lsyn + Lbase + LMMD 69.37 \u00b1 0.7 76.12 \u00b1 0.7 88.99 \u00b1 0.8 91.96 \u00b1 0.5 82.81 \u00b1 0.8 88.63 \u00b1 0.3\nFigure 3.",
                "Comparisons on CIFAR-FS, FC-100, miniImageNet, and tieredImageNet in both 5-way 1-shot and 5-way 5-shot settings are provided in Table.",
                "CIFAR-FS is also obtained from CIFAR-100, containing 64 classes for meta-training, 16 classes for metavalidation and 20 classes for meta-testing. miniImageNet is derived from ImageNet with images downsampled to a resolution of 84\u00d7 84 pixels.",
                "We experiment on the four common few-shot benchmarks : FC-100 [33], CIFAR-FS [5], miniImageNet [51] and tieredImageNet [39].",
                "\u2022 We validate our approach on standard few-shot benchmarks: CIFAR-FS, FC-100, miniImageNet, and tieredImageNet and achieve state-of-the-art performance in both 5-shot and 1-shot setups."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "aae461e1b39641dcc8406a903692f4885bbf2782",
                "externalIds": {
                    "ArXiv": "2212.05404",
                    "DBLP": "journals/corr/abs-2212-05404",
                    "DOI": "10.48550/arXiv.2212.05404",
                    "CorpusId": 254564034
                },
                "corpusId": 254564034,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/aae461e1b39641dcc8406a903692f4885bbf2782",
                "title": "DiffAlign : Few-shot learning using diffusion based synthesis and alignment",
                "abstract": "We address the problem of few-shot classification where the goal is to learn a classifier from a limited set of samples. While data-driven learning is shown to be effective in various applications, learning from less data still remains challenging. To address this challenge, existing approaches consider various data augmentation techniques for increasing the number of training samples. Pseudo-labeling is commonly used in a few-shot setup, where approximate labels are estimated for a large set of unlabeled images. We propose DiffAlign which focuses on generating images from class labels. Specifically, we leverage the recent success of the generative models (e.g., DALL-E and diffusion models) that can generate realistic images from texts. However, naive learning on synthetic images is not adequate due to the domain gap between real and synthetic images. Thus, we employ a maximum mean discrepancy (MMD) loss to align the synthetic images to the real images minimizing the domain gap. We evaluate our method on the standard few-shot classification benchmarks: CIFAR-FS, FC100, miniImageNet, tieredImageNet and a cross-domain few-shot classification benchmark: miniImageNet to CUB. The proposed approach significantly outperforms the stateof-the-art in both 5-shot and 1-shot setups on these benchmarks. Our approach is also shown to be effective in the zero-shot classification setup",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40003133",
                        "name": "A. Roy"
                    },
                    {
                        "authorId": "47287725",
                        "name": "Anshul B. Shah"
                    },
                    {
                        "authorId": "2053917247",
                        "name": "Ketul Shah"
                    },
                    {
                        "authorId": "145149308",
                        "name": "Anirban Roy"
                    },
                    {
                        "authorId": "69416958",
                        "name": "Ramalingam Chellappa"
                    }
                ]
            }
        },
        {
            "contexts": [
                "IV, we show the classification accuracies on popular datasets including miniImageNet, tieredImageNet, CIFAR-FS and CUB-2002011 datasets.",
                "4) CIFAR-FS: CIFAR-FS a subset of CIFAR-100 [24] for few-shot classification.",
                "In this section, we show the results on four standard few-shot learning benchmarks: miniImageNet [13], tieredImageNet [18], CUB-200-2011 [21] and CIFAR-FS [22]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "31c21ff380c2f8725de0f4078f237e15b44aad8a",
                "externalIds": {
                    "DOI": "10.1109/ICCC56324.2022.10065971",
                    "CorpusId": 257658776
                },
                "corpusId": 257658776,
                "publicationVenue": {
                    "id": "5758d639-a450-4152-901d-7a78c8715aa7",
                    "name": "International Conference on Innovative Computing and Cloud Computing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Control Commun  Comput India",
                        "IEEE Int Conf Cogn Comput",
                        "IEEE International Conference Computer and Communications",
                        "Int Carpathian Control Conf",
                        "Int Conf Cogn Comput [services Soc",
                        "Int Conf Comput Cybern",
                        "IEEE International Conference on Cognitive Computing",
                        "IEEE Int Conf Comput Commun",
                        "International Conference on Computer Communication",
                        "Int Conf Innov Comput Cloud Comput",
                        "International Carpathian Control Conference",
                        "International Conference on Computational Creativity",
                        "Int Conf Comput Commun",
                        "International Conference on Control Communication & Computing India",
                        "ICCC",
                        "International Conference on Computational Cybernetics",
                        "Int Conf Comput Creativity",
                        "International Conference on Cognitive Computing [Services Society]",
                        "IEEE Int Conf Commun China",
                        "IEEE International Conference on Communications in China"
                    ],
                    "url": "http://computationalcreativity.net/",
                    "alternate_urls": [
                        "http://www.icccgovernors.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/31c21ff380c2f8725de0f4078f237e15b44aad8a",
                "title": "Subgraph Propagation Network for Few-shot Learning",
                "abstract": "Few-shot classification is valuable because in some scenarios only a few images are provided. Many graph-network-based few-shot classification approaches obtain better features and smoother decision boundaries by using graph networks. However, using graph networks to propagate information be-tween labels tends to produce over-assimilation of features or introduce too much information of other classes. In this work, we propose a novel approach named subgraph propagation network (SPN) for few-shot classification. It leverages subgraph to improve the propagation of the features and makes it easier for classifiers to classify features without large number of parame-ters. The proposed subgraph propagation is a non-parametric operation which can be inserted after the feature extractor to produce better feature embeddings. Extensive experiments show that subgraph propagation network significantly improves the performance on few-shot classification benchmarks. We also show subgraph propagation improves the results under semi-supervised settings.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2212133237",
                        "name": "Jiongchen Hu"
                    },
                    {
                        "authorId": "2115460273",
                        "name": "Yuan Dong"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2e20a038b09bb93c724f187ec37b91b6713f5a98",
                "externalIds": {
                    "ArXiv": "2212.04196",
                    "DBLP": "journals/corr/abs-2212-04196",
                    "DOI": "10.48550/arXiv.2212.04196",
                    "CorpusId": 254408804
                },
                "corpusId": 254408804,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2e20a038b09bb93c724f187ec37b91b6713f5a98",
                "title": "Learning Domain Invariant Prompt for Vision-Language Models",
                "abstract": "Prompt learning is one of the most effective and trending ways to adapt powerful vision-language foundation models like CLIP to downstream datasets by tuning learnable prompt vectors with very few samples. However, although prompt learning achieves excellent performance over in-domain data, it still faces the major challenge of generalizing to unseen classes and domains. Some existing prompt learning methods tackle this issue by adaptively generating different prompts for different tokens or domains but neglecting the ability of learned prompts to generalize to unseen domains. In this paper, we propose a novel prompt learning paradigm that directly generates \\emph{domain invariant} prompt that can be generalized to unseen domains, called MetaPrompt. Specifically, a dual-modality prompt tuning network is proposed to generate prompts for input from both image and text modalities. With a novel asymmetric contrastive loss, the representation from the original pre-trained vision-language model acts as supervision to enhance the generalization ability of the learned prompt. More importantly, we propose a meta-learning-based prompt tuning algorithm that explicitly constrains the task-specific prompt tuned for one domain or class to also achieve good performance in another domain or class. Extensive experiments on 11 datasets for base-to-new generalization and 4 datasets for domain generalization demonstrate that our method consistently and significantly outperforms existing methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2050550",
                        "name": "Cairong Zhao"
                    },
                    {
                        "authorId": "2115721575",
                        "name": "Yubin Wang"
                    },
                    {
                        "authorId": "2046022",
                        "name": "Xinyang Jiang"
                    },
                    {
                        "authorId": "2152966656",
                        "name": "Yifei Shen"
                    },
                    {
                        "authorId": "50982078",
                        "name": "Kaitao Song"
                    },
                    {
                        "authorId": "2119081394",
                        "name": "Dongsheng Li"
                    },
                    {
                        "authorId": "145166399",
                        "name": "D. Miao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In our paper, we propose to employ meta-learning [4, 9, 26] to learn a parameter initialization.",
                "For the experiment, we simulated federated meta-learning using data from three popular datasets, including Omniglot [13], CIFARFS [4], and Mini-ImageNet [25].",
                "Meta-learning [4, 9, 26] learns common knowledge across a large number of tasks which is an optimized starting point for various new tasks as it can fast adapt to unseen tasks."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5a88f5b6f3dd6ca68f24194ffc2bfd271194a268",
                "externalIds": {
                    "DBLP": "conf/acsac/0022X00LH22",
                    "DOI": "10.1145/3564625.3564652",
                    "CorpusId": 254151732
                },
                "corpusId": 254151732,
                "publicationVenue": {
                    "id": "91d4ecad-d022-4953-901e-c5c57c614f72",
                    "name": "Asia-Pacific Computer Systems Architecture Conference",
                    "type": "conference",
                    "alternate_names": [
                        "ACSAC",
                        "Asia-pacific Comput Syst Archit Conf",
                        "Annu Comput Secur Appl Conf",
                        "Annual Computer Security Applications Conference"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=46",
                    "alternate_urls": [
                        "http://www.acsac.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5a88f5b6f3dd6ca68f24194ffc2bfd271194a268",
                "title": "Squeezing More Utility via Adaptive Clipping on Differentially Private Gradients in Federated Meta-Learning",
                "abstract": "Federated meta-learning has emerged as a promising AI framework for today\u2019s mobile computing scenes involving distributed clients. It enables collaborative model training using the data located at distributed mobile clients and accommodates clients that need fast model customization with limited new data. However, federated meta-learning solutions are susceptible to inference-based privacy attacks since the global model encoded with clients\u2019 training data is open to all clients and the central server. Meanwhile, differential privacy (DP) has been widely used as a countermeasure against privacy inference attacks in federated learning. The adoption of DP in federated meta-learning is complicated by the model accuracy-privacy trade-off and the model hierarchy attributed to the meta-learning component. In this paper, we introduce DP-FedMeta, a new differentially private federated meta-learning architecture that addresses such data privacy challenges. DP-FedMeta features an adaptive gradient clipping method and a one-pass meta-training process to improve the model utility-privacy trade-off. At the core of DP-FedMeta are two DP mechanisms, namely DP-AGR and DP-AGRLR, to provide two notions of privacy protection for the hierarchical models. Extensive experiments in an emulated federated meta-learning scenario on well-known datasets (Omniglot, CIFAR-FS, and Mini-ImageNet) demonstrate that DP-FedMeta accomplishes better privacy protection while maintaining comparable model accuracy compared to the state-of-the-art solution that directly applies DP-based meta-learning to the federated setting.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2152170662",
                        "name": "Ning Wang"
                    },
                    {
                        "authorId": "2116642852",
                        "name": "Yang Xiao"
                    },
                    {
                        "authorId": "2162478260",
                        "name": "Yimin Chen"
                    },
                    {
                        "authorId": "144465144",
                        "name": "Ning Zhang"
                    },
                    {
                        "authorId": "153502684",
                        "name": "W. Lou"
                    },
                    {
                        "authorId": "2118737136",
                        "name": "Y. T. Hou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The second method is optimizationbased approach [37]\u2013[40], which uses base categories to learn a good feature space as initialization."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7f4a758d8f92ee7457392160e4ae159032245fad",
                "externalIds": {
                    "ArXiv": "2212.01131",
                    "DBLP": "journals/corr/abs-2212-01131",
                    "DOI": "10.48550/arXiv.2212.01131",
                    "CorpusId": 254220917
                },
                "corpusId": 254220917,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7f4a758d8f92ee7457392160e4ae159032245fad",
                "title": "Activating the Discriminability of Novel Classes for Few-shot Segmentation",
                "abstract": "Despite the remarkable success of existing methods for few-shot segmentation, there remain two crucial challenges. First, the feature learning for novel classes is suppressed during the training on base classes in that the novel classes are always treated as background. Thus, the semantics of novel classes are not well learned. Second, most of existing methods fail to consider the underlying semantic gap between the support and the query resulting from the representative bias by the scarce support samples. To circumvent these two challenges, we propose to activate the discriminability of novel classes explicitly in both the feature encoding stage and the prediction stage for segmentation. In the feature encoding stage, we design the Semantic-Preserving Feature Learning module (SPFL) to first exploit and then retain the latent semantics contained in the whole input image, especially those in the background that belong to novel classes. In the prediction stage for segmentation, we learn an Self-Refined Online Foreground-Background classifier (SROFB), which is able to refine itself using the high-confidence pixels of query image to facilitate its adaptation to the query image and bridge the support-query semantic gap. Extensive experiments on PASCAL-5$^i$ and COCO-20$^i$ datasets demonstrates the advantages of these two novel designs both quantitatively and qualitatively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2178994659",
                        "name": "Dianwen Mei"
                    },
                    {
                        "authorId": "145268389",
                        "name": "Wei Zhuo"
                    },
                    {
                        "authorId": "1774000",
                        "name": "Jiandong Tian"
                    },
                    {
                        "authorId": "2114182496",
                        "name": "Guangming Lu"
                    },
                    {
                        "authorId": "1678473",
                        "name": "Wenjie Pei"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "025821369f49fbdb4de28b39800798b5de2d9ae8",
                "externalIds": {
                    "DBLP": "conf/hpcc/ZhangWHKQCX22",
                    "DOI": "10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00262",
                    "CorpusId": 257808628
                },
                "corpusId": 257808628,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/025821369f49fbdb4de28b39800798b5de2d9ae8",
                "title": "Supervised Contrastive Meta-learning for Few-Shot Classification",
                "abstract": "Many works have demonstrated that it is important to learn good representations for few-shot classification (FSC) problem. Contrastive learning produces encouraging results in unsupervised representation learning which aims at providing a good pre-trained feature extractor for the downstream tasks. It is a feasible way to utilize contrastive learning methods to provide a good pre-trained feature extractor for few-shot classification tasks. However, standard contrastive learning approaches do not achieve adequate results. On the one hand, contrastive learning can only perform instance-level learning due to the inability to use label information. On the other hand, existing contrastive learning lacks generalization ability while the class of downstream tasks is unseen. Meta-learning provides an approach to increase the model's capacity for generalization. We provide a supervised contrastive meta-learning model (SCML) which takes advantage of the capacity of meta-learning to swiftly adjust to novel tasks to improving the generalization ability of contrastive learning while utilizing the label information of the data for learning better representations. The result of experiments on different benchmarks shows the superior performance of the supervised contrastive meta-learning in terms of generalization ability for novel tasks. Furthermore, compared with the typical methods of meta-learning, our model SCML demonstrates appealing performance on MiniImagenet and CIFAR-FS.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2213132458",
                        "name": "Chuanyao Zhang"
                    },
                    {
                        "authorId": "66063851",
                        "name": "Jianzong Wang"
                    },
                    {
                        "authorId": "1443734040",
                        "name": "Zhangcheng Huang"
                    },
                    {
                        "authorId": "2004636073",
                        "name": "Lingwei Kong"
                    },
                    {
                        "authorId": "2624637",
                        "name": "Xiaoyang Qu"
                    },
                    {
                        "authorId": "145292435",
                        "name": "Ning Cheng"
                    },
                    {
                        "authorId": "91353860",
                        "name": "Jing Xiao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "92dc9b46ea723fd28e8c2698a417760fceb1a8d1",
                "externalIds": {
                    "DOI": "10.1109/acmlc58173.2022.00019",
                    "CorpusId": 261127190
                },
                "corpusId": 261127190,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/92dc9b46ea723fd28e8c2698a417760fceb1a8d1",
                "title": "Prototype and Metric Based Prediction for Data-Efficient Training",
                "abstract": "We propose a prototype- and metric-based prediction method together with several training pipelines suitable for training a network without using any additional data in the few-shot learning tasks with different intra-class variances. Being tested on two datasets commonly used for few-shot learning, our method has shown satisfactory ability to improve data efficiency and prevent overfitting. It even competes with the meta-learning-based method trained with a lot of extra labeled samples on the dataset with low intra-class variance and shows no significant performance gap when it comes to the dataset with a high intra-class variance. We reported 99.0% acc on the Omniglot dataset and 48.0% acc on the mini-ImageNet for 5-way 5-shot tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "98423960",
                        "name": "Gaowei Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For fair comparison, we follow previous works (Vinyals et al. 2016; Ren et al. 2018; Bertinetto et al. 2018) to split these datasets into training, validation and testing subsets, respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a0cf34df198f4ec1558a557e8d3065f873fe7df9",
                "externalIds": {
                    "ArXiv": "2211.16185",
                    "DBLP": "journals/corr/abs-2211-16185",
                    "DOI": "10.48550/arXiv.2211.16185",
                    "CorpusId": 254069475
                },
                "corpusId": 254069475,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a0cf34df198f4ec1558a557e8d3065f873fe7df9",
                "title": "Disentangled Generation with Information Bottleneck for Few-Shot Learning",
                "abstract": "Few-shot learning (FSL), which aims to classify unseen classes with few samples, is challenging due to data scarcity. Although various generative methods have been explored for FSL, the entangled generation process of these methods exacerbates the distribution shift in FSL, thus greatly limiting the quality of generated samples. To these challenges, we propose a novel Information Bottleneck (IB) based Disentangled Generation Framework for FSL, termed as DisGenIB, that can simultaneously guarantee the discrimination and diversity of generated samples. Specifically, we formulate a novel framework with information bottleneck that applies for both disentangled representation learning and sample generation. Different from existing IB-based methods that can hardly exploit priors, we demonstrate our DisGenIB can effectively utilize priors to further facilitate disentanglement. We further prove in theory that some previous generative and disentanglement methods are special cases of our DisGenIB, which demonstrates the generality of the proposed DisGenIB. Extensive experiments on challenging FSL benchmarks confirm the effectiveness and superiority of DisGenIB, together with the validity of our theoretical analyses. Our codes will be open-source upon acceptance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2192703079",
                        "name": "Zhuohang Dang"
                    },
                    {
                        "authorId": "2109656535",
                        "name": "Jihong Wang"
                    },
                    {
                        "authorId": "3326677",
                        "name": "Minnan Luo"
                    },
                    {
                        "authorId": "2147134586",
                        "name": "Chengyou Jia"
                    },
                    {
                        "authorId": "152299623",
                        "name": "Caixia Yan"
                    },
                    {
                        "authorId": "2152099796",
                        "name": "Qinghua Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "On the CIFAR-FS, where images have a very low resolution, RankDNN with the IE backbone surpasses its baseline, which is also the recent best, by 1.14% and 0.90% under 5-way-1-shot and 5-way-5shot settings, respectively (Table 3).",
                "We use four popular benchmark datasets in our experiments: miniImageNet(Vinyals et al. 2016), tieredImageNet (Ren et al. 2018), Caltech-UCSD Birds-200-2011 (CUB)(Chen et al. 2019b), and CIFAR-FS(Bertinetto et al. 2018)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "f9c63c1de8de192c62d334eb97bdff30c2f6fc64",
                "externalIds": {
                    "ArXiv": "2211.15320",
                    "DBLP": "journals/corr/abs-2211-15320",
                    "DOI": "10.48550/arXiv.2211.15320",
                    "CorpusId": 254043968
                },
                "corpusId": 254043968,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/f9c63c1de8de192c62d334eb97bdff30c2f6fc64",
                "title": "RankDNN: Learning to Rank for Few-shot Learning",
                "abstract": "This paper introduces a new few-shot learning pipeline that\ncasts relevance ranking for image retrieval as binary ranking\nrelation classification. In comparison to image classification,\nranking relation classification is sample efficient and\ndomain agnostic. Besides, it provides a new perspective on\nfew-shot learning and is complementary to state-of-the-art\nmethods. The core component of our deep neural network is\na simple MLP, which takes as input an image triplet encoded\nas the difference between two vector-Kronecker products,\nand outputs a binary relevance ranking order. The proposed\nRankMLP can be built on top of any state-of-the-art feature\nextractors, and our entire deep neural network is called\nthe ranking deep neural network, or RankDNN. Meanwhile,\nRankDNN can be flexibly fused with other post-processing\nmethods. During the meta test, RankDNN ranks support images\naccording to their similarity with the query samples,\nand each query sample is assigned the class label of its\nnearest neighbor. Experiments demonstrate that RankDNN\ncan effectively improve the performance of its baselines\nbased on a variety of backbones and it outperforms previous\nstate-of-the-art algorithms on multiple few-shot learning\nbenchmarks, including miniImageNet, tieredImageNet,\nCaltech-UCSD Birds, and CIFAR-FS. Furthermore, experiments\non the cross-domain challenge demonstrate the superior\ntransferability of RankDNN.The code is available at:\nhttps://github.com/guoqianyu-alberta/RankDNN.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1491102079",
                        "name": "Qianyu Guo"
                    },
                    {
                        "authorId": "2192605030",
                        "name": "Hongtong Gong"
                    },
                    {
                        "authorId": "2115325401",
                        "name": "Xu Wei"
                    },
                    {
                        "authorId": "35782003",
                        "name": "Yanwei Fu"
                    },
                    {
                        "authorId": "2390300",
                        "name": "Weifeng Ge"
                    },
                    {
                        "authorId": "1841911",
                        "name": "Yizhou Yu"
                    },
                    {
                        "authorId": "2159070511",
                        "name": "Wenqiang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We build on the ProtoNet [26] and the R2D2 [96] methods, and evaluate on FC100 [58] and CIFAR-\nFS [96] datasets.",
                "R2D2 [96] methods, and evaluate on FC100 [58] and CIFARFS [96] datasets."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bce31b5db69e6caea6b70455b499d1db188341ab",
                "externalIds": {
                    "DBLP": "journals/pami/ZhuZWL23",
                    "DOI": "10.1109/TPAMI.2022.3225117",
                    "CorpusId": 254068790,
                    "PubMed": "36441890"
                },
                "corpusId": 254068790,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/bce31b5db69e6caea6b70455b499d1db188341ab",
                "title": "Learning by Seeing More Classes",
                "abstract": "Traditional pattern recognition models usually assume a fixed and identical number of classes during both training and inference stages. In this paper, we study an interesting but ignored question: can increasing the number of classes during training improve the generalization and reliability performance? For a <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"zhang-ieq1-3225117.gif\"/></alternatives></inline-formula>-class problem, instead of training with only these <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"zhang-ieq2-3225117.gif\"/></alternatives></inline-formula> classes, we propose to learn with <inline-formula><tex-math notation=\"LaTeX\">$k+m$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=\"zhang-ieq3-3225117.gif\"/></alternatives></inline-formula> classes, where the additional <inline-formula><tex-math notation=\"LaTeX\">$m$</tex-math><alternatives><mml:math><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href=\"zhang-ieq4-3225117.gif\"/></alternatives></inline-formula> classes can be either real classes from other datasets or synthesized from known classes. Specifically, we propose two strategies for constructing new classes from known classes. By making the model see more classes during training, we can obtain several advantages. First, the added <inline-formula><tex-math notation=\"LaTeX\">$m$</tex-math><alternatives><mml:math><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href=\"zhang-ieq5-3225117.gif\"/></alternatives></inline-formula> classes serve as a regularization which is helpful to improve the generalization accuracy on the original <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"zhang-ieq6-3225117.gif\"/></alternatives></inline-formula> classes. Second, this will alleviate the overconfident phenomenon and produce more reliable confidence estimation for different tasks like misclassification detection, confidence calibration, and out-of-distribution detection. Lastly, the additional classes can also improve the learned feature representation, which is beneficial for new classes generalization in few-shot learning and class-incremental learning. Compared with the widely proved concept of data augmentation (dataAug), our method is driven from another dimension of augmentation based on additional classes (classAug). Comprehensive experiments demonstrated the superiority of our classAug under various open-environment metrics on benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2075372121",
                        "name": "Fei Zhu"
                    },
                    {
                        "authorId": "2870877",
                        "name": "Xu-Yao Zhang"
                    },
                    {
                        "authorId": "2109050605",
                        "name": "Rui-Qi Wang"
                    },
                    {
                        "authorId": "1689269",
                        "name": "Cheng-Lin Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", miniImageNet [23], CIFAR-FS [24], and Omniglot [25].",
                "Extensive experiments on miniImageNet [23], CIFAR-FS [24], and Omniglot [25] demonstrate that our method performs favourably against previous robust MAML methods considering both clean accuracy and robustness.",
                ", miniImageNet [23], CIFAR-FS [24], and Omniglot [25], demonstrate that our method performs favourably against previous robust MAML methods"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5f1d9bfe4a8b7fb91062d00b512fe38ff7ebfcf6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-15180",
                    "ArXiv": "2211.15180",
                    "DOI": "10.48550/arXiv.2211.15180",
                    "CorpusId": 254044372
                },
                "corpusId": 254044372,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5f1d9bfe4a8b7fb91062d00b512fe38ff7ebfcf6",
                "title": "Rethinking the Number of Shots in Robust Model-Agnostic Meta-Learning",
                "abstract": "Robust Model-Agnostic Meta-Learning (MAML) is usually adopted to train a meta-model which may fast adapt to novel classes with only a few exemplars and meanwhile remain robust to adversarial attacks. The conventional solution for robust MAML is to introduce robustness-promoting regularization during meta-training stage. With such a regularization, previous robust MAML methods simply follow the typical MAML practice that the number of training shots should match with the number of test shots to achieve an optimal adaptation performance. However, although the robustness can be largely improved, previous methods sacrifice clean accuracy a lot. In this paper, we observe that introducing robustness-promoting regularization into MAML reduces the intrinsic dimension of clean sample features, which results in a lower capacity of clean representations. This may explain why the clean accuracy of previous robust MAML methods drops severely. Based on this observation, we propose a simple strategy, i.e., increasing the number of training shots, to mitigate the loss of intrinsic dimension caused by robustness-promoting regularization. Though simple, our method remarkably improves the clean accuracy of MAML without much loss of robustness, producing a robust yet accurate model. Extensive experiments demonstrate that our method outperforms prior arts in achieving a better trade-off between accuracy and robustness. Besides, we observe that our method is less sensitive to the number of fine-tuning steps during meta-training, which allows for a reduced number of fine-tuning steps to improve training efficiency.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2067781481",
                        "name": "Xiaoyue Duan"
                    },
                    {
                        "authorId": "3374337",
                        "name": "Guoliang Kang"
                    },
                    {
                        "authorId": "2041702379",
                        "name": "Runqi Wang"
                    },
                    {
                        "authorId": "1488666685",
                        "name": "Shumin Han"
                    },
                    {
                        "authorId": "3324218",
                        "name": "Shenjun Xue"
                    },
                    {
                        "authorId": "2155412746",
                        "name": "Tian Wang"
                    },
                    {
                        "authorId": "1740430",
                        "name": "Baochang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The bi-level formulation Problem (6) is closely related to metric-based meta-learning methods (Snell et al., 2017; Bertinetto et al., 2019), where a shared representation f\u03b8\u0302 is learned across all tasks via simple task-specific predictors, such as linear classifiers."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4ece7149c5f3d9e630ac6b04ccb9b0789e6b899f",
                "externalIds": {
                    "DBLP": "conf/icml/LachapelleDMMBL23",
                    "ArXiv": "2211.14666",
                    "CorpusId": 259096048
                },
                "corpusId": 259096048,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/4ece7149c5f3d9e630ac6b04ccb9b0789e6b899f",
                "title": "Synergies between Disentanglement and Sparsity: Generalization and Identifiability in Multi-Task Learning",
                "abstract": "Although disentangled representations are often said to be beneficial for downstream tasks, current empirical and theoretical understanding is limited. In this work, we provide evidence that disentangled representations coupled with sparse base-predictors improve generalization. In the context of multi-task learning, we prove a new identifiability result that provides conditions under which maximally sparse base-predictors yield disentangled representations. Motivated by this theoretical result, we propose a practical approach to learn disentangled representations based on a sparsity-promoting bi-level optimization problem. Finally, we explore a meta-learning version of this algorithm based on group Lasso multiclass SVM base-predictors, for which we derive a tractable dual formulation. It obtains competitive results on standard few-shot classification benchmarks, while each task is using only a fraction of the learned representations.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "134730235",
                        "name": "S\u00e9bastien Lachapelle"
                    },
                    {
                        "authorId": "7636193",
                        "name": "T. Deleu"
                    },
                    {
                        "authorId": "133841722",
                        "name": "Divyat Mahajan"
                    },
                    {
                        "authorId": "2065139188",
                        "name": "Ioannis Mitliagkas"
                    },
                    {
                        "authorId": "1865800402",
                        "name": "Y. Bengio"
                    },
                    {
                        "authorId": "1388317459",
                        "name": "S. Lacoste-Julien"
                    },
                    {
                        "authorId": "14205549",
                        "name": "Quentin Bertrand"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The experiments are implemented on CIFAR-FS, FC-100, mini-ImageNet and tiered-ImageNet datasets with Conv-4 backbone.",
                "We first implement the proposed IMC hybrid model on mini-ImageNet to compare with the state-of-the-art works including MatchingNet [39], ProtoNet [32], LSTM [28], MAML [7],\nRelationNet [33], R2-D2 [2] and LMPNet [9] etc.",
                "Besides, we implement the proposed method in other common FSL datasets including CIFAR-FS, FC100 and tiered-ImageNet.",
                "RelationNet [33], R2-D2 [2] and LMPNet [9] etc.",
                "CIFAR-FS Constructed from CIFAR-100 [15], CIFAR-FS [2] is a common few-shot learning dataset that contains 100 classes and 60,000 images.",
                "We report the experiments on CIFAR-FS, FC100, mini-ImageNet and tiered-ImageNet datasets in 5-way 5-shot and 5-way 1-shot settings respectively.",
                "For example, L2 normalization brings +6.76% improvements in 1-shot setting and + 1.75% in 5-shot setting on CIFAR-FS dataset.",
                "According to FSL criteria, CIFAR-FS randomly samples 64, 16 and 20 classes for the training, validation and testing sets respectively from CIFAR-100 and each class has 600 images with the size of 32 \u00d7 32.",
                "From the results, we can find that, compared with the reproduced ProtoNet, our proposed method has better performance on CIFAR-FS with +14.08% and + 6.97% performance improvements on 1-\nProtoNet* 46.32 \u00b1 0.82 70.43 \u00b1 0.73 36.83 \u00b1 0.74 50.92 \u00b1 0.71 43.13 \u00b1 0.83 65.88 \u00b1 0.76 OM 52.97 \u00b1 0.86 74.44 \u00b1 0.70 38.33 \u00b1 0.71 52.43 \u00b1 0.72 46.24 \u00b1 0.89 67.13 \u00b1 0.74 OC 59.68 \u00b1 0.85 75.65 \u00b1 0.68 38.78 \u00b1 0.70 50.16 \u00b1 0.70 53.79 \u00b1 0.91 70.05 \u00b1 0.75 IMC (Ours) 60.40 \u00b1 0.86 77.40 \u00b1 0.68 39.41 \u00b1 0.74 53.50 \u00b1 0.72 51.55 \u00b1 0.90 69.96 \u00b1 0.74\nThe best performances are highlighted\nshot and 5-shot settings respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "d1edd31bd7c84a041d47fddbf3e00581d89dc76d",
                "externalIds": {
                    "DBLP": "journals/mta/LiuYLLHL23",
                    "DOI": "10.1007/s11042-022-14218-8",
                    "CorpusId": 253902992
                },
                "corpusId": 253902992,
                "publicationVenue": {
                    "id": "477368e9-7a8e-475a-8c93-6d623797fd06",
                    "name": "Multimedia tools and applications",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Tools and Applications",
                        "Multimedia Tool Appl",
                        "Multimedia tool appl"
                    ],
                    "issn": "1380-7501",
                    "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d1edd31bd7c84a041d47fddbf3e00581d89dc76d",
                "title": "A hybrid deep model with cumulative learning for few-shot learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2146653122",
                        "name": "Jiehao Liu"
                    },
                    {
                        "authorId": "2116370920",
                        "name": "Zhao Yang"
                    },
                    {
                        "authorId": "2192242351",
                        "name": "Liufei Luo"
                    },
                    {
                        "authorId": "2184621303",
                        "name": "Mingkai Luo"
                    },
                    {
                        "authorId": "2192280224",
                        "name": "Luyu Hu"
                    },
                    {
                        "authorId": "3392041",
                        "name": "Jiahao Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In order to validate the efficacy of our method, we conduct experiments on single-domain, cross-domain and unsupervised FSL with a wide range of benchmark datasets including miniImageNet, tieredImageNet, CIFAR-FS and CUB.",
                "The utility of our method is demonstrated on the state-of-the-art results consistently achieved on several benchmarks includingminiImageNet, tieredImageNet, CIFAR-FS, CUB, Cars, Places and Plantae, in all settings of single-domain, cross-domain and unsupervised FSL.",
                "These categories are further broken into 608 categories, where 351 categories are used for training, 97 for validation and 160 for testing. iii) CIFAR-FS [72] divides CIFAR-100 into 64 meta-train categories, 16 meta-val categories and 20 meta-test categories. iv) CUB [73], a bird dataset with 200 total categories and 6033 total images.",
                "For miniImageNet and CIFAR-FS, the initial learning rate is set as 0.15 and 0.05 for\ntieredImageNet.",
                "TABLE 6 Ablation Study of CGR and Hardness-Aware PatchMix on tieredImageNet and CIFAR-FS\nModel tieredImageNet CIFAR-FS\n1-shot 5-shot 1-shot 5-shot\nw/o 72.28 86.24 76.57 88.15 vanilla 72.13 86.71 76.42 88.21 Softmax 72.54 86.78 77.06 87.27 CGR 73.48 87.35 77.87 88.94 vanilla 72.56 86.39 76.97 87.83 w/o H 72.78 86.67 77.02 88.10 local 72.81 86.81 77.30 88.52 global 73.48 87.35 77.87 88.94\nAuthorized licensed use limited to the terms of the applicable license agreement with IEEE.",
                "iii) CIFAR-FS [72] divides CIFAR-100 into 64 meta-train categories, 16 meta-val categories and 20 meta-test categories.",
                "This result, together with the comparison between baseline and PatchMix on CIFAR-FS in Fig.",
                "(3) Our final choice of gumbel-softmax benefits the model with 0.53% and 0.52% higher accuracies on 1-shot and 5-shot tasks onminiImageNet, and consistent improvement on CIFAR-FS and tieredImageNet.",
                "We adopt three datasets including miniImageNet, tieredImageNet and CIFAR-FS in the single domain setting, where the model is trained on the metatrain set of each dataset and tested on the corresponding meta-test set.",
                "On tieredImageNet and CIFAR-FS the results are nearly consistent with those on miniImageNet (e.g., our model leads by 2.47% and 1.69% in 1-shot and 5-shot on CIFARFS)."
            ],
            "intents": [],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "176d9b627dbee0495db86d8e7b7961bba360845c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-16019",
                    "ArXiv": "2211.16019",
                    "DOI": "10.1109/TPAMI.2022.3223784",
                    "CorpusId": 253759250,
                    "PubMed": "36409816"
                },
                "corpusId": 253759250,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/176d9b627dbee0495db86d8e7b7961bba360845c",
                "title": "PatchMix Augmentation to Identify Causal Features in Few-Shot Learning",
                "abstract": "The task of Few-shot learning (FSL) aims to transfer the knowledge learned from base categories with sufficient labelled data to novel categories with scarce known information. It is currently an important research question and has great practical values in the real-world applications. Despite extensive previous efforts are made on few-shot learning tasks, we emphasize that most existing methods did not take into account the distributional shift caused by sample selection bias in the FSL scenario. Such a selection bias can induce spurious correlation between the semantic causal features, that are causally and semantically related to the class label, and the other non-causal features. Critically, the former ones should be invariant across changes in distributions, highly related to the classes of interest, and thus well generalizable to novel classes, while the latter ones are not stable to changes in the distribution. To resolve this problem, we propose a novel data augmentation strategy dubbed as PatchMix that can break this spurious dependency by replacing the patch-level information and supervision of the query images with random gallery images from different classes from the query ones. We theoretically show that such an augmentation mechanism, different from existing ones, is able to identify the causal features. To further make these features to be discriminative enough for classification, we propose Correlation-guided Reconstruction (CGR) and Hardness-Aware module for instance discrimination and easier discrimination between similar classes. Moreover, such a framework can be adapted to the unsupervised FSL scenario. The utility of our method is demonstrated on the state-of-the-art results consistently achieved on several benchmarks including miniImageNet, tieredImageNet, CIFAR-FS, CUB, Cars, Places and Plantae, in all settings of single-domain, cross-domain and unsupervised FSL. By studying the intra-variance property of learned features and visualizing the learned features, we further quantitatively and qualitatively show that such a promising result is due to the effectiveness in learning causal features.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2708397",
                        "name": "C. Xu"
                    },
                    {
                        "authorId": "2108118336",
                        "name": "Chen Liu"
                    },
                    {
                        "authorId": "8283163",
                        "name": "Xinwei Sun"
                    },
                    {
                        "authorId": "2187419298",
                        "name": "Siqian Yang"
                    },
                    {
                        "authorId": "2628601",
                        "name": "Yabiao Wang"
                    },
                    {
                        "authorId": "1978245",
                        "name": "Chengjie Wang"
                    },
                    {
                        "authorId": "35782003",
                        "name": "Yanwei Fu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To verify the effectiveness of the proposed method, the CIFAR-FS dataset [17] is used to evaluate the performance of the proposed method."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0aed186b989d6e236df0b12603127168b1e0e535",
                "externalIds": {
                    "DOI": "10.1109/YAC57282.2022.10023589",
                    "CorpusId": 256453207
                },
                "corpusId": 256453207,
                "publicationVenue": {
                    "id": "7e280d98-c90c-428c-baba-a46e4abde912",
                    "name": "Youth Academic Annual Conference of Chinese Association of Automation",
                    "type": "conference",
                    "alternate_names": [
                        "YAC",
                        "Youth Acad Annu Conf Chin Assoc Autom"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0aed186b989d6e236df0b12603127168b1e0e535",
                "title": "Variational Inference on Decomposition of Conceptual Knowledge for Few-Shot Learning",
                "abstract": "Few-shot learning (FSL) aims at learning a model to generalize well on new tasks with limited training examples. In this paper, we propose a new FSL model called Variational Conceptual Decomposition Network (VCDNet) that learns to decompose the image representation from the conceptual level for maintaining both generalization and discrimination capabilities when adapting to new data. Specifically, the decomposition is accomplished by variational inference on the disentanglement of a frame feature and a salient feature that represent the conceptual structure and the discriminative detailed information for generating the distribution over the images, respectively. In addition, we introduce an adversarial classification method to further guide the decomposition conducted on the conceptual knowledge level. Our experiments on the CIFAR-FS dataset demonstrate that the proposed VCDNet outperforms many competitive baselines.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2069855841",
                        "name": "Lei Su"
                    },
                    {
                        "authorId": "5046971",
                        "name": "Zhaoyi Jiang"
                    },
                    {
                        "authorId": "2199809361",
                        "name": "Jingyi Hou"
                    },
                    {
                        "authorId": "2203734223",
                        "name": "Zhijie Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "344a98afe0d05a56d984e340c558c5d8962f3218",
                "externalIds": {
                    "ArXiv": "2211.06828",
                    "DBLP": "journals/access/NguyenNLP23",
                    "DOI": "10.1109/ACCESS.2023.3298299",
                    "CorpusId": 253510640
                },
                "corpusId": 253510640,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/344a98afe0d05a56d984e340c558c5d8962f3218",
                "title": "Enhancing Few-Shot Image Classification With Cosine Transformer",
                "abstract": "This paper addresses the few-shot image classification problem, where the classification task is performed on unlabeled query samples given a small amount of labeled support samples only. One major challenge of the few-shot learning problem is the large variety of object visual appearances that prevents the support samples to represent that object comprehensively. This might result in a significant difference between support and query samples, therefore undermining the performance of few-shot algorithms. In this paper, we tackle the problem by proposing Few-shot Cosine Transformer (FS-CT), where the relational map between supports and queries is effectively obtained for the few-shot tasks. The FS-CT consists of two parts, a learnable prototypical embedding network to obtain categorical representations from support samples with hard cases, and a transformer encoder to effectively achieve the relational map from two different support and query samples. We introduce Cosine Attention, a more robust and stable attention module that enhances the transformer module significantly and therefore improves FS-CT performance from 5% to over 20% in accuracy compared to the default scaled dot-product mechanism. Our method performs competitive results in mini -ImageNet, CUB-200, and CIFAR-FS on 1-shot learning and 5-shot learning tasks across backbones and few-shot configurations. We also developed a custom few-shot dataset for Yoga pose recognition to demonstrate the potential of our algorithm for practical application. Our FS-CT with cosine attention is a lightweight, simple few-shot algorithm that can be applied for a wide range of applications, such as healthcare, medical, and security surveillance. The official implementation code of our Few-shot Cosine Transformer is available at https://github.com/vinuni-vishc/Few-Shot-Cosine-Transformer.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2190753406",
                        "name": "Quang-Huy Nguyen"
                    },
                    {
                        "authorId": "2153425277",
                        "name": "Cuong Q. Nguyen"
                    },
                    {
                        "authorId": "3460636",
                        "name": "Dung D. Le"
                    },
                    {
                        "authorId": "143950636",
                        "name": "Hieu Pham"
                    },
                    {
                        "authorId": "1834451",
                        "name": "M. Do"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6e84fa79851287e4bae8ee43064cf83e3c00b829",
                "externalIds": {
                    "DOI": "10.23919/APSIPAASC55919.2022.9979971",
                    "CorpusId": 254931721
                },
                "corpusId": 254931721,
                "publicationVenue": {
                    "id": "5b924e1a-30f3-4275-bdb8-5a15517c0fde",
                    "name": "Asia-Pacific Signal and Information Processing Association Annual Summit and Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Asia-pacific Signal Inf Process Assoc Annu Summit Conf",
                        "APSIPA"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6e84fa79851287e4bae8ee43064cf83e3c00b829",
                "title": "Semantics-Guided Knowledge Integration for Domain Adaptation Few-shot Relation Extraction",
                "abstract": "Few-shot relation extraction achieves great progress by incorporating meta-learning with knowledge. Most of the recent works focus on integrating different types of knowledge, which ignored that there would be a huge knowledge gap in the application, especially facing domain adaptation. In this paper, we explore the effective way to integrate different forms of knowledge for domain adaptation few-shot relation extraction, and we face up to the problem of knowledge gap between training and testing. To be specific, we take the entity concept as the integrated knowledge, and the concept representation can be obtained from two sources, including textual label and concept graph. For the textual label, we evaluate the model's perception of concepts in different types of text fusion. For the concept graph, we pursue an effective integration method to adapt the modal gap and knowledge gap. Extensive experiments on the Few Rei domain adaptation dataset show that textual knowledge with language models and graph knowledge with a distance scorer are easy for transferring, and semantic information can effectively guide the integration process.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2088511",
                        "name": "Zeyuan Wang"
                    },
                    {
                        "authorId": null,
                        "name": "Yifan Du"
                    },
                    {
                        "authorId": "2119057514",
                        "name": "Guangwei Zhang"
                    },
                    {
                        "authorId": "2462591",
                        "name": "Ruifan Li"
                    },
                    {
                        "authorId": "48935767",
                        "name": "Yongping Xiong"
                    },
                    {
                        "authorId": "2197643454",
                        "name": "Chuang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The\nvanilla network achieves decent 1-SHOT and 5-SHOT clean accuracies on the CIFAR-FS dataset, however, it\u2019s extremely vulnerable to adversarial perturbations.",
                "Apart from [n/2,2], we took [n-1, 2] as rrange, and performed experiments on the CIFAR-FS dataset with rrange equals to [31,2].",
                "Recently, the few-shot-learning community has shifted its attention to metalearning, which attempts to \u2018learn\u2019 the \u2018learning-algorithm\u2019 itself over a distribution of tasks, such that it can quickly adapt to novel tasks using finetuning [9, 15, 27, 11].",
                "(in main draft) where the the radius corresponding to highest weight (peak radius rp) is at n/2 (16 in the case of CIFAR-FS dataset).",
                "This is especially important as selecting a fixed radius (for e.g. r = 2) might work well for certain dataset (for instance CIFAR-FS) but can yield suboptimal performance on others\n(for e.g. Mini-ImageNet).",
                "We perform experiments on CIFAR-FS dataset and fix the number of classes i.e. k as 5 and query set size as 75 (15 query samples per class).",
                "Specifically, we repeat our experiments using WRN-28-10 (Wide Resnet with width 28 and depth 10) [34] and conv (64)\u00d74 (CNN with 4 layers and 64k channels in the kth layer) [14] on CIFAR-FS [27] for both 1-shot and 5-shot settings and report their results in Table II.",
                "We demonstrate the effectiveness of our technique by performing experiments on two benchmarks datasets in few-shot-learning, specifically, CIFAR-FS [27] and MiniImageNet [14].",
                "On CIFAR-FS dataset, our method yields significant improvement of \u2248 11 \u2212 29% on clean data and \u2248 28\u221235% on adversarial data for 1-shot while \u2248 8\u221232% on clean data and \u2248 31\u2212 40% on adversarial data for 5-shot settings), over existing state-of-the-art methods.",
                "In Table VII we vary the quantity of the query set from 5 samples per class (i.e. query set size = 25) to 25 samples per class (i.e. query set size = 125) on CIFAR-FS for 5- way 1-shot setting.",
                ", t as 98 and 90 for CIFAR-FS and Mini-ImageNet, respectively."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "eebb67074ec783cbbda23163f4ceb20ce10d37a4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-01598",
                    "ArXiv": "2211.01598",
                    "DOI": "10.48550/arXiv.2211.01598",
                    "CorpusId": 253264794
                },
                "corpusId": 253264794,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/eebb67074ec783cbbda23163f4ceb20ce10d37a4",
                "title": "Robust Few-shot Learning Without Using any Adversarial Samples",
                "abstract": "The high cost of acquiring and annotating samples has made the `few-shot' learning problem of prime importance. Existing works mainly focus on improving performance on clean data and overlook robustness concerns on the data perturbed with adversarial noise. Recently, a few efforts have been made to combine the few-shot problem with the robustness objective using sophisticated Meta-Learning techniques. These methods rely on the generation of adversarial samples in every episode of training, which further adds a computational burden. To avoid such time-consuming and complicated procedures, we propose a simple but effective alternative that does not require any adversarial samples. Inspired by the cognitive decision-making process in humans, we enforce high-level feature matching between the base class data and their corresponding low-frequency samples in the pretraining stage via self distillation. The model is then fine-tuned on the samples of novel classes where we additionally improve the discriminability of low-frequency query set features via cosine similarity. On a 1-shot setting of the CIFAR-FS dataset, our method yields a massive improvement of $60.55\\%$&$62.05\\%$ in adversarial accuracy on the PGD and state-of-the-art Auto Attack, respectively, with a minor drop in clean accuracy compared to the baseline. Moreover, our method only takes $1.69\\times$ of the standard training time while being $\\approx$ $5\\times$ faster than state-of-the-art adversarial meta-learning methods. The code is available at https://github.com/vcl-iisc/robust-few-shot-learning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "143747407",
                        "name": "Gaurav Kumar Nayak"
                    },
                    {
                        "authorId": "1658305348",
                        "name": "Ruchit Rawal"
                    },
                    {
                        "authorId": "2044355793",
                        "name": "Inder Khatri"
                    },
                    {
                        "authorId": "1429640900",
                        "name": "Anirban Chakraborty"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "94b34d60bc264dbcb7486b8194660e234c4db8d4",
                "externalIds": {
                    "DBLP": "journals/ijon/LiLZZMXC23",
                    "DOI": "10.1016/j.neucom.2022.11.082",
                    "CorpusId": 254176678
                },
                "corpusId": 254176678,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/94b34d60bc264dbcb7486b8194660e234c4db8d4",
                "title": "ReNAP: Relation network with adaptiveprototypical learning for few-shot classification",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145074587",
                        "name": "Xiaoxu Li"
                    },
                    {
                        "authorId": "2110479738",
                        "name": "Yalan Li"
                    },
                    {
                        "authorId": "113048818",
                        "name": "Yixiao Zheng"
                    },
                    {
                        "authorId": "145295710",
                        "name": "Rui Zhu"
                    },
                    {
                        "authorId": "1755773",
                        "name": "Zhanyu Ma"
                    },
                    {
                        "authorId": "1891766",
                        "name": "Jing-Hao Xue"
                    },
                    {
                        "authorId": "2109811729",
                        "name": "Jie Cao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(3) It can be seen from the second row in Table 5 that on the one hand supervised contrastive loss has little effect on the improvement of classification performance on CIFAR-FS and MiniImageNet datasets, where the reason is that there are 64 categories in both CIFAR-FS and MiniImageNet datasets and the number of positive and negative sample pairs in the training process are not enough, resulting in the molecular terms of supervised contrast loss function almost be zero.",
                "EQ-TARGET;temp:intralink-;e003;116;169 rgmin\u03b8;\u03c6Lb\u00fer\u00f0Dbase\u00de \u00fe R\u00f0\u03b8\u00de \u00fe R\u00f0\u03c6\u00de; (3)"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "87b8cda4c152b8973b2271e1ab111d35ade4bd77",
                "externalIds": {
                    "DOI": "10.1117/1.JEI.31.6.063029",
                    "CorpusId": 253903008
                },
                "corpusId": 253903008,
                "publicationVenue": {
                    "id": "c677ab24-0c04-487d-83e2-c252af9479c8",
                    "name": "Journal of Electronic Imaging (JEI)",
                    "type": "journal",
                    "alternate_names": [
                        "J Electron Imaging (JEI",
                        "Journal of Electronic Imaging",
                        "J Electron Imaging"
                    ],
                    "issn": "1017-9909",
                    "url": "https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging",
                    "alternate_urls": [
                        "http://electronicimaging.spiedigitallibrary.org/journal.aspx"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/87b8cda4c152b8973b2271e1ab111d35ade4bd77",
                "title": "Dual spatial constraints-based few-shot image classification",
                "abstract": "Abstract. As one of the development directions of artificial intelligence in the future, few-shot learning has attracted more and more attention in recent years. How to make full use of the information of a small amount of samples is one of the main difficulties in the field of few-shot learning. Most of the research work utilizes the meta-learning mechanism to alleviate the negative impact of insufficient samples on model performance. However, the training between subtasks also makes it difficult for meta-learning models to obtain general feature representations between samples. Therefore, researchers are turning their research perspective to supervised learning, and they have drawn a conclusion that embedding models with good performance are simpler and more effective than complex meta-learning models. Recent research work has also proved the importance of feature representation. Based on the above view points and analysis, we propose a few-shot image classification method, which strengthens the difference of samples from different categories and the similarity of samples from the same category and realizes dual constraints in high-dimensional feature space and low-dimensional feature space. Experimental results on four public datasets demonstrate that the proposed method effectively improves the accuracy of image classification with few-shot learning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2508428",
                        "name": "Songhao Zhu"
                    },
                    {
                        "authorId": "2192289273",
                        "name": "Xiong Bian"
                    },
                    {
                        "authorId": "2922281",
                        "name": "Zhiwei Liang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "22191f02ee6c8b22a29a6c337a1e73d313e7c19d",
                "externalIds": {
                    "DBLP": "journals/ijcv/WangLZGD23",
                    "DOI": "10.1007/s11263-022-01700-x",
                    "CorpusId": 253333424
                },
                "corpusId": 253333424,
                "publicationVenue": {
                    "id": "939ee07c-6009-43f8-b884-69238b40659e",
                    "name": "International Journal of Computer Vision",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Comput Vis"
                    ],
                    "issn": "0920-5691",
                    "url": "https://www.springer.com/computer/image+processing/journal/11263",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11263",
                        "http://link.springer.com/journal/11263"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/22191f02ee6c8b22a29a6c337a1e73d313e7c19d",
                "title": "Few-Shot Learning with Complex-Valued Neural Networks and Dependable Learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2041702379",
                        "name": "Runqi Wang"
                    },
                    {
                        "authorId": "2109343010",
                        "name": "Zhen Liu"
                    },
                    {
                        "authorId": "1740430",
                        "name": "Baochang Zhang"
                    },
                    {
                        "authorId": "2067614206",
                        "name": "Guodong Guo"
                    },
                    {
                        "authorId": "48471936",
                        "name": "D. Doermann"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The second few-shot learning dataset was CIFAR-FS [17], containing 60,000 images collected from CIFAR100."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "041d1f470cc2e150bfefae3ec1aeb206f02fdc9b",
                "externalIds": {
                    "DOI": "10.3390/electronics11213502",
                    "CorpusId": 253208085
                },
                "corpusId": 253208085,
                "publicationVenue": {
                    "id": "ccd8e532-73c6-414f-bc91-271bbb2933e2",
                    "name": "Electronics",
                    "type": "journal",
                    "issn": "1450-5843",
                    "alternate_issns": [
                        "2079-9292",
                        "0883-4989"
                    ],
                    "url": "http://www.electronics.etfbl.net/",
                    "alternate_urls": [
                        "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-247562",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-247562",
                        "https://www.mdpi.com/journal/electronics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/041d1f470cc2e150bfefae3ec1aeb206f02fdc9b",
                "title": "Few-Shot Classification with Dual-Model Deep Feature Extraction and Similarity Measurement",
                "abstract": "From traditional machine learning to the latest deep learning classifiers, most models require a large amount of labeled data to perform optimal training and obtain the best performance. Yet, when limited training samples are available or when accompanied by noisy labels, severe degradation in accuracy can arise. The proposed work mainly focusses on these practical issues. Herein, standard datasets, i.e., Mini-ImageNet, CIFAR-FS, and CUB 200, are considered, which also have similar issues. The main goal is to utilize a few labeled data in the training stage, extracting image features and then performing feature similarity analysis across all samples. The highlighted aspects of the proposed method are as follows. (1) The main self-supervised learning strategies and augmentation techniques are exploited to obtain the best pretrained model. (2) An improved dual-model mechanism is proposed to train the support and query datasets with multiple training configurations. As examined in the experiments, the dual-model approach obtains superior performance of few-shot classification compared with all of the state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "8572939",
                        "name": "Jingcai Guo"
                    },
                    {
                        "authorId": "13285247",
                        "name": "Sankarasrinivasan Seshathiri"
                    },
                    {
                        "authorId": "2190903985",
                        "name": "Wen-Hsiang Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The same formulation applies to optimization-based [10], [36], metricbased [41], and fusion-based [1], [23], [47] algorithms, as shown in Figures 3a, 3b and 3c, respectively.",
                "output the parameters of a neural network specialized for target tasks [31], [39]; 2) metric-learning for similarity-based learning-to-learn in a highly efficient manner [41]; 3) the highly successful gradient-based ML paradigm [10], [36]; 4) data fusion approaches [1], [23], [37], [47] that \u201cguide\u201d the learning on the query set through the support features; and",
                "ML: optimization- [10], [25], [33], [36], metric- [13], [41], [49] and fusion-based [1], [23], [37] strategies.",
                "Following the schema presented in Figure 4c, a whole family of fusion-based meta-learners can be implemented, including methods traditionally proposed for classification, such as MetaOptNet [23] and R2D2 [1].",
                "In this tutorial we introduced a novel taxonomy for categorizing ML algorithms for few-shot image classification [1], [10], [23], [25], [33], [36], [41], [47] and FSWS segmentation [12], [12], [37], [49]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "7e78dd763d3ccfcd7bc7dfa45d0117ac385a91c6",
                "externalIds": {
                    "DBLP": "conf/sibgrapi/OliveiraCGS22",
                    "DOI": "10.1109/SIBGRAPI55357.2022.9991767",
                    "CorpusId": 255171765
                },
                "corpusId": 255171765,
                "publicationVenue": {
                    "id": "e8fb3e28-e9d7-4585-9e72-660cef7f6802",
                    "name": "SIBGRAPI Conference on Graphics, Patterns and Images",
                    "type": "conference",
                    "alternate_names": [
                        "SIBGRAPI Conf Graph Pattern Image",
                        "Braz Symp Comput Graph Image Process",
                        "SIBGRAPI",
                        "Brazilian Symposium on Computer Graphics and Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7e78dd763d3ccfcd7bc7dfa45d0117ac385a91c6",
                "title": "Domain Generalization in Medical Image Segmentation via Meta-Learners",
                "abstract": "Automatic and semi-automatic radiological image segmentation can help physicians in the processing of real-world medical data for several tasks such as detection/diagnosis of diseases and surgery planning. Current segmentation methods based on neural networks are highly data-driven, often requiring hundreds of laborious annotations to properly converge. The generalization capabilities of traditional supervised deep learning are also limited by the insufficient variability present in the training dataset. One very proliferous research field that aims to alleviate this dependence on large numbers of labeled data is Meta-Learning. Meta-Learning aims to improve the generalization capabilities of traditional supervised learning by training models to learn in a label efficient manner. In this tutorial we present an overview of the literature and proposed ways of merging this body of knowledge with deep segmentation architectures to produce highly adaptable multi-task meta-models for few-shot weakly-supervised semantic segmentation. We introduce a taxonomy to categorize Meta-Learning methods for both classification and segmentation, while also discussing how to adapt potentially any few-shot meta-learner to a weakly-supervised segmentation task.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "10009581",
                        "name": "H. Oliveira"
                    },
                    {
                        "authorId": "49403484",
                        "name": "R. M. Cesar"
                    },
                    {
                        "authorId": "1388176432",
                        "name": "P. H. T. Gama"
                    },
                    {
                        "authorId": "2116663801",
                        "name": "J. D. Santos"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Different from classical constrained optimization, bilevel optimization restricts certain variables to be the minimizer of the lower level function, which is more applicable in modern machine learning problems like meta learning (Snell et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019) and hyperparameter optimization (Pedregosa, 2016; Franceschi et al.",
                ", 2020), meta learning (Snell et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020), hyperparameter optimization (Pedregosa, 2016; Franceschi et al.",
                "\u2026certain variables\nto be the minimizer of the lower level function, which is more applicable in modern machine learning problems like meta learning (Snell et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019) and hyperparameter optimization (Pedregosa, 2016; Franceschi et al., 2018).",
                "\u2026(Chen et al., 2021) to modern machine learning problems such as reinforcement learning (Hong et al., 2020), meta learning (Snell et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020), hyperparameter optimization (Pedregosa, 2016; Franceschi et al., 2018), etc.\u2026"
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0cb94a05cfc614acbe42c85cfd864f7c7bee9b26",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-12839",
                    "ArXiv": "2210.12839",
                    "DOI": "10.48550/arXiv.2210.12839",
                    "CorpusId": 253098835
                },
                "corpusId": 253098835,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0cb94a05cfc614acbe42c85cfd864f7c7bee9b26",
                "title": "Decentralized Stochastic Bilevel Optimization with Improved Per-Iteration Complexity",
                "abstract": "Bilevel optimization recently has received tremendous attention due to its great success in solving important machine learning problems like meta learning, reinforcement learning, and hyperparameter optimization. Extending single-agent training on bilevel problems to the decentralized setting is a natural generalization, and there has been a flurry of work studying decentralized bilevel optimization algorithms. However, it remains unknown how to design the distributed algorithm with sample complexity and convergence rate comparable to SGD for stochastic optimization, and at the same time without directly computing the exact Hessian or Jacobian matrices. In this paper we propose such an algorithm. More specifically, we propose a novel decentralized stochastic bilevel optimization (DSBO) algorithm that only requires first order stochastic oracle, Hessian-vector product and Jacobian-vector product oracle. The sample complexity of our algorithm matches the currently best known results for DSBO, and the advantage of our algorithm is that it does not require estimating the full Hessian and Jacobian matrices, thereby having improved per-iteration complexity.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2170123588",
                        "name": "Xuxing Chen"
                    },
                    {
                        "authorId": "14252014",
                        "name": "Minhui Huang"
                    },
                    {
                        "authorId": "51152107",
                        "name": "Shiqian Ma"
                    },
                    {
                        "authorId": "1682978",
                        "name": "K. Balasubramanian"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026and (3) bi-level optimization where the outer level optimizes the hyperparameters and the inner level optimizes the model parameters given the hyperparameters (Finn et al., 2017; Finn, 2018; Bertinetto et al., 2018; Lee et al., 2019; Zintgraf et al., 2019; Li et al., 2017; Zhou et al., 2018).",
                ", 2017), and (3) bi-level optimization where the outer level optimizes the hyperparameters and the inner level optimizes the model parameters given the hyperparameters (Finn et al., 2017; Finn, 2018; Bertinetto et al., 2018; Lee et al., 2019; Zintgraf et al., 2019; Li et al., 2017; Zhou et al., 2018)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dcc9f29ca9d37763c84c2f69ea01110970cfb3c8",
                "externalIds": {
                    "ArXiv": "2210.12669",
                    "DBLP": "journals/corr/abs-2210-12669",
                    "DOI": "10.48550/arXiv.2210.12669",
                    "CorpusId": 253098776
                },
                "corpusId": 253098776,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/dcc9f29ca9d37763c84c2f69ea01110970cfb3c8",
                "title": "Meta Learning of Interface Conditions for Multi-Domain Physics-Informed Neural Networks",
                "abstract": "Physics-informed neural networks (PINNs) are emerging as popular mesh-free solvers for partial differential equations (PDEs). Recent extensions decompose the domain, apply different PINNs to solve the problem in each subdomain, and stitch the subdomains at the interface. Thereby, they can further alleviate the problem complexity, reduce the computational cost, and allow parallelization. However, the performance of multi-domain PINNs is sensitive to the choice of the interface conditions. While quite a few conditions have been proposed, there is no suggestion about how to select the conditions according to specific problems. To address this gap, we propose META Learning of Interface Conditions (METALIC), a simple, efficient yet powerful approach to dynamically determine appropriate interface conditions for solving a family of parametric PDEs. Specifically, we develop two contextual multi-arm bandit (MAB) models. The first one applies to the entire training course, and online updates a Gaussian process (GP) reward that given the PDE parameters and interface conditions predicts the performance. We prove a sub-linear regret bound for both UCB and Thompson sampling, which in theory guarantees the effectiveness of our MAB. The second one partitions the training into two stages, one is the stochastic phase and the other deterministic phase; we update a GP reward for each phase to enable different condition selections at the two stages to further bolster the flexibility and performance. We have shown the advantage of METALIC on four bench-mark PDE families.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118056567",
                        "name": "Shibo Li"
                    },
                    {
                        "authorId": "2115147703",
                        "name": "Michael Penwarden"
                    },
                    {
                        "authorId": "152534535",
                        "name": "Robert M. Kirby"
                    },
                    {
                        "authorId": "2390798",
                        "name": "Shandian Zhe"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1838ecac886b78f2521f5c5949034647350a3522",
                "externalIds": {
                    "DOI": "10.1109/ICSP56322.2022.9965273",
                    "CorpusId": 254152864
                },
                "corpusId": 254152864,
                "publicationVenue": {
                    "id": "63410070-a9b9-46ac-bdec-92b016246795",
                    "name": "International Conference on the Software Process",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Signal Process",
                        "ICSP",
                        "Int Conf Softw Process",
                        "International Conference on Signal Processing"
                    ],
                    "url": "http://www.ece.utexas.edu/~perry/prof/ispa/index.html"
                },
                "url": "https://www.semanticscholar.org/paper/1838ecac886b78f2521f5c5949034647350a3522",
                "title": "Affine Non-negative Representation for Few-Shot Remote Sensing Scene Classification",
                "abstract": "It is hard to acquire plenty of labeled samples in remote sensing due to the limitations of the imaging environment and the imaging equipment. Recently, few-shot learning, which attempts to identify invisible categories with restricted labeled samples, has shown tremendous potential to address this issue. The Remote Sensing Scene Classification (RSSC) based on fewshot learning generally involves two steps: the pre-training phase and the meta-test phase. Nevertheless, since the sample categories in these two stages are disjoint and only one or a few labeled samples per class are given for training in the meta-testing phase, which causes an \u201coverfitting\u201d problem and thus limits the model\u2019s generalization ability. To overcome the challenge, we propose an Affine Non-negative Representation for Few-Shot RSSC (ANRRSSC). Specifically, we design a representation-based classifier with affine non-negative constraints to prevent \u201coverfitting\u201d by reducing model parameters. Further, the proposed method maps the extracted features into Radial Basis Function (RBF) kernel space to rehabilitate more discriminating features making the data more linearly separable. Extensive experiments on NWPURESISC45 and RSD46-WHU remote sensing image datasets show the merits of the proposed method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2045384708",
                        "name": "Chunyu Du"
                    },
                    {
                        "authorId": "2155992419",
                        "name": "Baodi Liu"
                    },
                    {
                        "authorId": "7707388",
                        "name": "Yanjiang Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Few-Shot learning (FSL) Existing FSL approaches can be categorized into metric-learning methods that learn an embedding space to compare query and support samples [24, 34, 45, 54], meta-learning approaches that adapt a base learner to new classes [7, 15, 21, 26, 28, 39, 43], or a combination of both [52]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5ade28cabb1db7ec88c1cca864dff3a332761fb5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-10317",
                    "ArXiv": "2210.10317",
                    "DOI": "10.1109/WACV56688.2023.00023",
                    "CorpusId": 252992765
                },
                "corpusId": 252992765,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/5ade28cabb1db7ec88c1cca864dff3a332761fb5",
                "title": "LAVA:Label-efficient Visual Learning and Adaptation",
                "abstract": "We present LAVA, a simple yet effective method for multi-domain visual transfer learning with limited data. LAVA builds on a few recent innovations to enable adapting to partially labelled datasets with class and domain shifts. First, LAVA learns self-supervised visual representations on the source dataset and ground them using class label semantics to overcome transfer collapse problems associated with supervised pretraining. Secondly, LAVA maximises the gains from unlabelled target data via a novel method which uses multi-crop augmentations to obtain highly robust pseudo-labels. By combining these ingredients, LAVA achieves a new state-of-the-art on ImageNet semi-supervised protocol, as well as on 7 out of 10 datasets in multi-domain few-shot learning on the Meta-dataset.1",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47257217",
                        "name": "Islam Nassar"
                    },
                    {
                        "authorId": "145684318",
                        "name": "Munawar Hayat"
                    },
                    {
                        "authorId": "8088602",
                        "name": "Ehsan Abbasnejad"
                    },
                    {
                        "authorId": "1387977754",
                        "name": "Hamid Rezatofighi"
                    },
                    {
                        "authorId": "23911916",
                        "name": "Mehrtash Harandi"
                    },
                    {
                        "authorId": "2561045",
                        "name": "Gholamreza Haffari"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We validate our model on 6 benchmark few-shot datasets: CIFAR-FS (Bertinetto et al., 2019), Mini-ImageNet (Russakovsky et al., 2015), Tiered-ImageNet (Russakovsky et al., 2015), Cars, CUB and VGG-Flower, for few-shot classification and 3 additional benchmark standard image classification datasets:\u2026",
                "For meta-training, we use CIFAR-FS (Bertinetto et al., 2019) and Mini-ImageNet (Russakovsky et al., 2015)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "41542fe2ebf7e884871091ed1a0c6166a5ec1d49",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-10485",
                    "ArXiv": "2210.10485",
                    "DOI": "10.48550/arXiv.2210.10485",
                    "CorpusId": 252992903
                },
                "corpusId": 252992903,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/41542fe2ebf7e884871091ed1a0c6166a5ec1d49",
                "title": "Few-shot Transferable Robust Representation Learning via Bilevel Attacks",
                "abstract": "Existing adversarial learning methods for enhancing the robustness of deep neural networks assume the availability of a large amount of data from which we can generate adversarial examples. However, in an adversarial meta-learning setting, the model needs to train with only a few adversarial examples to learn a robust model for unseen tasks, which is a very difficult goal to achieve. Further, learning transferable robust representations for unseen domains is a difficult problem even with a large amount of data. To tackle such a challenge, we propose a novel adversarial self-supervised meta-learning framework with bilevel attacks which aims to learn robust representations that can generalize across tasks and domains. Specifically, in the inner loop, we update the parameters of the given encoder by taking inner gradient steps using two different sets of augmented samples, and generate adversarial examples for each view by maximizing the instance classification loss. Then, in the outer loop, we meta-learn the encoder parameter to maximize the agreement between the two adversarial examples, which enables it to learn robust representations. We experimentally validate the effectiveness of our approach on unseen domain adaptation tasks, on which it achieves impressive performance. Specifically, our method significantly outperforms the state-of-the-art meta-adversarial learning methods on few-shot learning tasks, as well as self-supervised learning baselines in standard learning settings with large-scale datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2116505846",
                        "name": "Minseon Kim"
                    },
                    {
                        "authorId": "2188241709",
                        "name": "Hyeonjeong Ha"
                    },
                    {
                        "authorId": "35788904",
                        "name": "Sung Ju Hwang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "ANIL [32], R2D2 [31] and MTL [17] are obtained from the work [27] which implemented open-sourced codes using the original paper settings.",
                "From Table VI, we can observe that FSL methods, including ProtoNet, R2D2, MTL, and Ours, acquire significant performance promotion with larger image size.",
                "In addition, the evaluation results of Versa [30], ANIL [32], R2D2 [31] and MTL [17] are obtained from the work [27] which implemented open-sourced codes using the original paper settings."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "13c99ec91575d02d2aaae516ee08bf2921bea14c",
                "externalIds": {
                    "DBLP": "journals/titb/JiangGLJML23",
                    "DOI": "10.1109/JBHI.2022.3215147",
                    "CorpusId": 252971146,
                    "PubMed": "36251917"
                },
                "corpusId": 252971146,
                "publicationVenue": {
                    "id": "eac74c9c-a5c0-417d-8088-8164a6a8bfb3",
                    "name": "IEEE journal of biomedical and health informatics",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Journal of Biomedical and Health Informatics",
                        "IEEE j biomed health informatics",
                        "IEEE J Biomed Health Informatics"
                    ],
                    "issn": "2168-2194",
                    "url": "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6221020",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/13c99ec91575d02d2aaae516ee08bf2921bea14c",
                "title": "Multi-Learner Based Deep Meta-Learning for Few-Shot Medical Image Classification",
                "abstract": "Few-shot learning (FSL) is promising in the field of medical image analysis due to high cost of establishing high-quality medical datasets. Many FSL approaches have been proposed in natural image scenes. However, present FSL methods are rarely evaluated on medical images and the FSL technology applicable to medical scenarios need to be further developed. Meta-learning has supplied an optional framework to address the challenging FSL setting. In this paper, we propose a novel multi-learner based FSL method for multiple medical image classification tasks, combining meta-learning with transfer-learning and metric-learning. Our designed model is composed of three learners, including auto-encoder, metric-learner and task-learner. In transfer-learning, all the learners are trained on the base classes. In the ensuing meta-learning, we leverage multiple novel tasks to fine-tune the metric-learner and task-learner in order to fast adapt to unseen tasks. Moreover, to further boost the learning efficiency of our model, we devised real-time data augmentation and dynamic Gaussian disturbance soft label (GDSL) scheme as effective generalization strategies of few-shot classification tasks. We have conducted experiments for three-class few-shot classification tasks on three newly-built challenging medical benchmarks, BLOOD, PATH and CHEST. Extensive comparisons to related works validated that our method achieved top performance both on homogeneous medical datasets and cross-domain datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1387858859",
                        "name": "Hongyang Jiang"
                    },
                    {
                        "authorId": "2147414869",
                        "name": "Mengdi Gao"
                    },
                    {
                        "authorId": "2153612686",
                        "name": "Heng Li"
                    },
                    {
                        "authorId": "2140636595",
                        "name": "Richu Jin"
                    },
                    {
                        "authorId": "152587754",
                        "name": "Hanpei Miao"
                    },
                    {
                        "authorId": "2155403819",
                        "name": "Jiang Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b83c62f3875a649aeafb22ff1c380a7bdd744b43",
                "externalIds": {
                    "ArXiv": "2210.08942",
                    "CorpusId": 256416107
                },
                "corpusId": 256416107,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b83c62f3875a649aeafb22ff1c380a7bdd744b43",
                "title": "Meta-Learning via Classifier(-free) Diffusion Guidance",
                "abstract": "We introduce meta-learning algorithms that perform zero-shot weight-space adaptation of neural network models to unseen tasks. Our methods repurpose the popular generative image synthesis techniques of natural language guidance and diffusion models to generate neural network weights adapted for tasks. We first train an unconditional generative hypernetwork model to produce neural network weights; then we train a second\"guidance\"model that, given a natural language task description, traverses the hypernetwork latent space to find high-performance task-adapted weights in a zero-shot manner. We explore two alternative approaches for latent space guidance:\"HyperCLIP\"-based classifier guidance and a conditional Hypernetwork Latent Diffusion Model (\"HyperLDM\"), which we show to benefit from the classifier-free guidance technique common in image generation. Finally, we demonstrate that our approaches outperform existing multi-task and meta-learning methods in a series of zero-shot learning experiments on our Meta-VQA dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2129786387",
                        "name": "Elvis Nava"
                    },
                    {
                        "authorId": "51194506",
                        "name": "Seijin Kobayashi"
                    },
                    {
                        "authorId": "2023392128",
                        "name": "Yifei Yin"
                    },
                    {
                        "authorId": "50191333",
                        "name": "Robert K. Katzschmann"
                    },
                    {
                        "authorId": "48117063",
                        "name": "B. Grewe"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0b09950a6f4c48277d04c4754d70daa3b0712f70",
                "externalIds": {
                    "DBLP": "conf/icip/RheeC22",
                    "DOI": "10.1109/ICIP46576.2022.9897320",
                    "CorpusId": 253328316
                },
                "corpusId": 253328316,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0b09950a6f4c48277d04c4754d70daa3b0712f70",
                "title": "Episode Difficulty Based Sampling Method for Few-Shot Classification",
                "abstract": "Most methods in few-shot learning adopt episodic training, where classes for generating episodes are randomly sampled. Here, most of the episodes are easily solvable, i.e., the dataset in terms of the episodes becomes biased towards easy ones. In this paper, we propose a novel sampling method named Episode Difficulty Based Sampling (EDBS) that aims to remove the dataset bias in terms of episode difficulty. We define the episode difficulty to be proportional to the similarity between the classes composing the episode. Then we determine an episode as easy or hard depending on their episode difficulty and design a balanced episode dataset in terms of the difficulty. Through our EDBS, few-shot networks become less biased to the easy episodes and learn detailed features necessary for solving challenging episodes. Experiments demonstrate that our sampling method is widely applicable and achieves state-of-the-art performance in the benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1557389407",
                        "name": "Hochang Rhee"
                    },
                    {
                        "authorId": "1707645",
                        "name": "N. Cho"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f66014a6a2fc810033a195783c17956f4fff746b",
                "externalIds": {
                    "DBLP": "journals/iet-cvi/ZhangYLWLM23",
                    "DOI": "10.1049/cvi2.12150",
                    "CorpusId": 252906748
                },
                "corpusId": 252906748,
                "publicationVenue": {
                    "id": "d8f7a93a-ec60-4a71-a085-6891d8652e03",
                    "name": "IET Computer Vision",
                    "type": "journal",
                    "alternate_names": [
                        "Iet Computer Vision",
                        "Iet Comput Vis",
                        "IET Comput Vis"
                    ],
                    "issn": "1751-9632",
                    "url": "http://www.iee.org/Publish/Journals/Profjourn/Proc/vis/",
                    "alternate_urls": [
                        "http://www.ietdl.org/IET-CVI"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f66014a6a2fc810033a195783c17956f4fff746b",
                "title": "Multi-task few-shot learning with composed data augmentation for image classification",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118404109",
                        "name": "Rui Zhang"
                    },
                    {
                        "authorId": "2157154803",
                        "name": "Yixin Yang"
                    },
                    {
                        "authorId": "47002590",
                        "name": "Yang Li"
                    },
                    {
                        "authorId": "2115640316",
                        "name": "Jiabao Wang"
                    },
                    {
                        "authorId": "2118384519",
                        "name": "Hang Li"
                    },
                    {
                        "authorId": "1708071",
                        "name": "Zhuang Miao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In line with recent meta-learning strategies (e.g. Bertinetto et al., 2019; Raghu et al., 2020), we keep \u03c8 fixed during our method\u2019s first stage while only adapting the classifier \u03c6 to learn from data streams."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b5a73adeaafd9180088588c717afd253c41c9825",
                "externalIds": {
                    "ArXiv": "2210.05561",
                    "DBLP": "journals/corr/abs-2210-05561",
                    "DOI": "10.48550/arXiv.2210.05561",
                    "CorpusId": 252815585
                },
                "corpusId": 252815585,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b5a73adeaafd9180088588c717afd253c41c9825",
                "title": "Schedule-Robust Online Continual Learning",
                "abstract": "A continual learning (CL) algorithm learns from a non-stationary data stream. The non-stationarity is modeled by some schedule that determines how data is presented over time. Most current methods make strong assumptions on the schedule and have unpredictable performance when such requirements are not met. A key challenge in CL is thus to design methods robust against arbitrary schedules over the same underlying data, since in real-world scenarios schedules are often unknown and dynamic. In this work, we introduce the notion of schedule-robustness for CL and a novel approach satisfying this desirable property in the challenging online class-incremental setting. We also present a new perspective on CL, as the process of learning a schedule-robust predictor, followed by adapting the predictor using only replay data. Empirically, we demonstrate that our approach outperforms existing methods on CL benchmarks for image classification by a large margin.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3368222",
                        "name": "Ruohan Wang"
                    },
                    {
                        "authorId": "153738445",
                        "name": "Marco Ciccone"
                    },
                    {
                        "authorId": "46258846",
                        "name": "Giulia Luise"
                    },
                    {
                        "authorId": "1704699",
                        "name": "M. Pontil"
                    },
                    {
                        "authorId": "72161401",
                        "name": "A. Yapp"
                    },
                    {
                        "authorId": "7666146",
                        "name": "C. Ciliberto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[4] noted that updating only the parameters sensitive to specific classes for few-shot classification task leads to a"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7969c75e863dc6ed815da6cd4dd63e1e4bd848da",
                "externalIds": {
                    "DBLP": "conf/iros/SheBDY22",
                    "ArXiv": "2210.05008",
                    "DOI": "10.1109/IROS47612.2022.9981327",
                    "CorpusId": 252815980
                },
                "corpusId": 252815980,
                "publicationVenue": {
                    "id": "37275deb-3fcf-4d16-ae77-95db9899b1f3",
                    "name": "IEEE/RJS International Conference on Intelligent RObots and Systems",
                    "type": "conference",
                    "alternate_names": [
                        "IROS",
                        "Intelligent Robots and Systems",
                        "Intell Robot Syst",
                        "IEEE/RJS Int Conf Intell Robot Syst"
                    ],
                    "url": "http://www.iros.org/"
                },
                "url": "https://www.semanticscholar.org/paper/7969c75e863dc6ed815da6cd4dd63e1e4bd848da",
                "title": "Fast Hierarchical Learning for Few-Shot Object Detection",
                "abstract": "Transfer learning based approaches have recently achieved promising results on the few-shot detection task. These approaches however suffer from \u201ccatastrophic forgetting\u201d issue due to finetuning of base detector, leading to sub-optimal performance on the base classes. Furthermore, the slow convergence rate of stochastic gradient descent (SGD) results in high latency and consequently restricts real-time applications. We tackle the aforementioned issues in this work. We pose few-shot detection as a hierarchical learning problem, where the novel classes are treated as the child classes of existing base classes and the background class. The detection heads for the novel classes are then trained using a specialized optimization strategy, leading to significantly lower training times compared to SGD. Our approach obtains competitive novel class performance on few-shot MS-COCO benchmark, while completely retaining the performance of the initial model on the base classes. We further demonstrate the application of our approach to a new class-refined few-shot detection task.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2107085326",
                        "name": "Yihang She"
                    },
                    {
                        "authorId": "49922196",
                        "name": "Goutam Bhat"
                    },
                    {
                        "authorId": "2129520569",
                        "name": "Martin Danelljan"
                    },
                    {
                        "authorId": "1807197",
                        "name": "F. Yu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We sample B base classes from CIFAR-FS to build the base dataset.",
                "Free-lunch did not share the features on tieredImageNet and CIFAR-FS, thus we have taken the pre-trained WRN28+RTloss backbone of Mangla et al. [39] to extract the features, where we use this same backbone to implement Free-lunch with its official code and we have explored and selected an appropriate w for Free-lunch.",
                "Here, the number B of base classes of miniImageNet, CIFAR-FS, CUB, and tieredImageNet is 64, 64, 100, and 351, respectively.",
                "We design two cross-domain scenarios: miniImageNet \u2192 CUB, CIFAR-FS \u2192 CUB, where CUB is the target domain while both miniImageNet and CIFAR-FS are the source domains.",
                "10, we consider in-domain setting (CUB, top) and cross-domain setting (CIFAR-FS \u2192 CUB, bottom), both of which adopt same 5way1shot novel task from CUB.",
                "The CIFAR-FS dataset is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100 [38].",
                "B.6 Learned transport plan based on low-level OT\nTaking the 5way1shot task on CIFAR-FS as an example, we further explore the per-example weights learned by our low-level OT.",
                "Datasets We evaluate our proposed method on several standard few-shot classification datasets with different levels of granularity, including miniImageNet [33], tieredImageNet [34], CUB [35], and CIFAR-FS [36].",
                "Here, miniImageNet, tieredImageNet, and CIFAR-FS have a broad range of classes including various animals and objects while CUB is a more fine-grained dataset that includes various species of birds.",
                "Moreover, H-OT under the CIFAR-FS\u2192 CUB (blue bar in the 3rd column) scenario still outperforms Free-Lunch under CUB (orange bar in the 1st column).",
                "B.1 Summary of the test results\nTo explore how our proposed model improves its baseline (Free-Lunch), we perform the experiments on 10,000 tasks from CIFAR-FS dataset using these two distribution calibration models, where the statistics about the classification results are shown in Fig.",
                "We now conduct experiments on the most common setting in few-shot classification, 1-shot and 5-shot classification, where the results of different models on miniImageNet, tieredImagenet, CUB and CIFAR-FS are shown in Tables 1 and 2.",
                "We use the same hyperparameter value for all datasets except for \u03bb. Specifically, the number of generated features is 750, the in Sinkhorn algorithm is 0.01, the \u03b1 in (10) is 0.21; and \u03bb is 0.5, 1, 1 and 0.8 for miniImageNet, tieredImageNet, CUB, and CIFAR-FS, respectively, selected by a grid search using the validation set.",
                "8, we visualize the adaptive cost learned from low-level OT and the transport plan learned from the high-level OT given the adaptive cost on CIFAR-FS for 5way1shot task."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "3038a60e83ab19e9c9f5af1a57325ab798102393",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-04144",
                    "ArXiv": "2210.04144",
                    "DOI": "10.48550/arXiv.2210.04144",
                    "CorpusId": 252780538
                },
                "corpusId": 252780538,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/3038a60e83ab19e9c9f5af1a57325ab798102393",
                "title": "Adaptive Distribution Calibration for Few-Shot Learning with Hierarchical Optimal Transport",
                "abstract": "Few-shot classification aims to learn a classifier to recognize unseen classes during training, where the learned model can easily become over-fitted based on the biased distribution formed by only a few training examples. A recent solution to this problem is calibrating the distribution of these few sample classes by transferring statistics from the base classes with sufficient examples, where how to decide the transfer weights from base classes to novel classes is the key. However, principled approaches for learning the transfer weights have not been carefully studied. To this end, we propose a novel distribution calibration method by learning the adaptive weight matrix between novel samples and base classes, which is built upon a hierarchical Optimal Transport (H-OT) framework. By minimizing the high-level OT distance between novel samples and base classes, we can view the learned transport plan as the adaptive weight information for transferring the statistics of base classes. The learning of the cost function between a base class and novel class in the high-level OT leads to the introduction of the low-level OT, which considers the weights of all the data samples in the base class. Experimental results on standard benchmarks demonstrate that our proposed plug-and-play model outperforms competing approaches and owns desired cross-domain generalization ability, indicating the effectiveness of the learned adaptive weights.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "143860661",
                        "name": "D. Guo"
                    },
                    {
                        "authorId": "2115832800",
                        "name": "Longlong Tian"
                    },
                    {
                        "authorId": "1643682004",
                        "name": "He Zhao"
                    },
                    {
                        "authorId": "38026572",
                        "name": "Mingyuan Zhou"
                    },
                    {
                        "authorId": "145203884",
                        "name": "H. Zha"
                    }
                ]
            }
        },
        {
            "contexts": [
                "2, we now compare the performance of the hybrid fine-tuning strategy (HFT-Last1/HFT-All) with that of the traditional finetuning strategy (FT-Last1/FT-All) under different pretraining methods including RFS-simple [29], SKD-GEN0 [41], and R2D2 [42].",
                "Based on the hands-on hybrid fine-tuning strategy obtained in Section 4.2, we now compare the performance of the hybrid fine-tuning strategy (HFT-Last1/HFT-All) with that of the traditional finetuning strategy (FT-Last1/FT-All) under different pretraining methods including RFS-simple [29], SKD-GEN0 [41], and R2D2 [42]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "72dd59c2b912678845a0b119c86bc0e31a72f59f",
                "externalIds": {
                    "PubMedCentral": "9569229",
                    "DOI": "10.1155/2022/9620755",
                    "CorpusId": 252855544,
                    "PubMed": "36254202"
                },
                "corpusId": 252855544,
                "publicationVenue": {
                    "id": "f32b7322-b69c-4e63-801d-8f50784ef778",
                    "name": "Computational Intelligence and Neuroscience",
                    "type": "journal",
                    "alternate_names": [
                        "Comput Intell Neurosci"
                    ],
                    "issn": "1687-5265",
                    "url": "https://www.hindawi.com/journals/cin/"
                },
                "url": "https://www.semanticscholar.org/paper/72dd59c2b912678845a0b119c86bc0e31a72f59f",
                "title": "Hybrid Fine-Tuning Strategy for Few-Shot Classification",
                "abstract": "Few-shot classification aims to enable the network to acquire the ability of feature extraction and label prediction for the target categories given a few numbers of labeled samples. Current few-shot classification methods focus on the pretraining stage while fine-tuning by experience or not at all. No fine-tuning or insufficient fine-tuning may get low accuracy for the given tasks, while excessive fine-tuning will lead to poor generalization for unseen samples. To solve the above problems, this study proposes a hybrid fine-tuning strategy (HFT), including a few-shot linear discriminant analysis module (FSLDA) and an adaptive fine-tuning module (AFT). FSLDA constructs the optimal linear classification function under the few-shot conditions to initialize the last fully connected layer parameters, which fully excavates the professional knowledge of the given tasks and guarantees the lower bound of the model accuracy. AFT adopts an adaptive fine-tuning termination rule to obtain the optimal training epochs to prevent the model from overfitting. AFT is also built on FSLDA and outputs the final optimum hybrid fine-tuning strategy for a given sample size and layer frozen policy. We conducted extensive experiments on mini-ImageNet and tiered-ImageNet to prove the effectiveness of our proposed method. It achieves consistent performance improvements compared to existing fine-tuning methods under different sample sizes, layer frozen policies, and few-shot classification frameworks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2111486613",
                        "name": "Lei Zhao"
                    },
                    {
                        "authorId": "4904049",
                        "name": "Zhonghua Ou"
                    },
                    {
                        "authorId": "50082126",
                        "name": "Lixun Zhang"
                    },
                    {
                        "authorId": "2304137",
                        "name": "Shuxiao Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Few-shot learning is cast to optimization-based (Antoniou et al., 2018, Bertinetto et al., 2019, Finn et al., 2017, Flennerhag et al., 2020, Lee and Choi, 2018, Nichol et al., 2018, Park and Oliva, 2019, Ravi and Larochelle, 2017, Rusu et al., 2019) or metric-based (Koch et al., 2015, Oreshkin et\u2026"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "48bf7949fa0b99de39e0f09439295f7dd07d85a8",
                "externalIds": {
                    "ArXiv": "2210.03595",
                    "DBLP": "journals/corr/abs-2210-03595",
                    "DOI": "10.48550/arXiv.2210.03595",
                    "CorpusId": 252762664
                },
                "corpusId": 252762664,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/48bf7949fa0b99de39e0f09439295f7dd07d85a8",
                "title": "Unsupervised Few-shot Learning via Deep Laplacian Eigenmaps",
                "abstract": "Learning a new task from a handful of examples remains an open challenge in machine learning. Despite the recent progress in few-shot learning, most methods rely on supervised pretraining or meta-learning on labeled meta-training data and cannot be applied to the case where the pretraining data is unlabeled. In this study, we present an unsupervised few-shot learning method via deep Laplacian eigenmaps. Our method learns representation from unlabeled data by grouping similar samples together and can be intuitively interpreted by random walks on augmented training data. We analytically show how deep Laplacian eigenmaps avoid collapsed representation in unsupervised learning without explicit comparison between positive and negative samples. The proposed method significantly closes the performance gap between supervised and unsupervised few-shot learning. Our method also achieves comparable performance to current state-of-the-art self-supervised learning methods under linear evaluation protocol.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3289893",
                        "name": "Kuilin Chen"
                    },
                    {
                        "authorId": "2143724945",
                        "name": "Chi-Guhn Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026in machine learning such as hyper-parameter optimization (Franceschi et al., 2018; Lorraine & Duvenaud, 2018; Okuno et al., 2021), meta learning (Bertinetto et al., 2018; Rajeswaran et al., 2019; Soh et al., 2020) and reinforcement learning (Yang et al., 2018; Tschiatschek et al., 2019).",
                "\u2026bilevel optimization is a widely confronted problem in machine learning with various applications such as meta-learning (Finn et al., 2017; Bertinetto et al., 2018; Rajeswaran et al., 2019), hyper-parameter optimization (Franceschi et al., 2018; Shaban et al., 2019; Baydin et al., 2017;\u2026"
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e587e32c0a54fb9c192964ec022e4144bbcdf10b",
                "externalIds": {
                    "ArXiv": "2210.01063",
                    "DBLP": "journals/corr/abs-2210-01063",
                    "DOI": "10.48550/arXiv.2210.01063",
                    "CorpusId": 252683678
                },
                "corpusId": 252683678,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e587e32c0a54fb9c192964ec022e4144bbcdf10b",
                "title": "On Stability and Generalization of Bilevel Optimization Problem",
                "abstract": "(Stochastic) bilevel optimization is a frequently encountered problem in machine learning with a wide range of applications such as meta-learning, hyper-parameter optimization, and reinforcement learning. Most of the existing studies on this problem only focused on analyzing the convergence or improving the convergence rate, while little effort has been devoted to understanding its generalization behaviors. In this paper, we conduct a thorough analysis on the generalization of first-order (gradient-based) methods for the bilevel optimization problem. We first establish a fundamental connection between algorithmic stability and generalization error in different forms and give a high probability generalization bound which improves the previous best one from $\\bigO(\\sqrt{n})$ to $\\bigO(\\log n)$, where $n$ is the sample size. We then provide the first stability bounds for the general case where both inner and outer level parameters are subject to continuous update, while existing work allows only the outer level parameter to be updated. Our analysis can be applied in various standard settings such as strongly-convex-strongly-convex (SC-SC), convex-convex (C-C), and nonconvex-nonconvex (NC-NC). Our analysis for the NC-NC setting can also be extended to a particular nonconvex-strongly-convex (NC-SC) setting that is commonly encountered in practice. Finally, we corroborate our theoretical analysis and demonstrate how iterations can affect the generalization error by experiments on meta-learning and hyper-parameter optimization.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2186828915",
                        "name": "Meng Ding"
                    },
                    {
                        "authorId": "2054182773",
                        "name": "Ming Lei"
                    },
                    {
                        "authorId": "2365013",
                        "name": "Yunwen Lei"
                    },
                    {
                        "authorId": "144629030",
                        "name": "Di Wang"
                    },
                    {
                        "authorId": "2146061048",
                        "name": "Jinhui Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS is a variant of CIFAR-100 [13] with low resolution, which has 100 classes and each of them has 600 samples of 32 \u00d7 32 size.",
                "We conduct experiments on four widely-used few-shot learning benchmark datasets for general object recognition and fine-grained classification, including miniImageNet [25], tieredImageNet [26], CIFAR-FS [2] and CUB [34].",
                "\u2022 We conduct comprehensive experiments on four few-shot benchmark datasets, i.e., miniImageNet, tieredImageNet, CIFAR-FS and CUB, for demonstrating our superiority over state-of-the-art FSL and SSFSL methods."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9580663d9cdd8ba371b6a96e8dfd38effe3bb84d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-13777",
                    "ArXiv": "2209.13777",
                    "DOI": "10.48550/arXiv.2209.13777",
                    "CorpusId": 252568070
                },
                "corpusId": 252568070,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/9580663d9cdd8ba371b6a96e8dfd38effe3bb84d",
                "title": "An Embarrassingly Simple Approach to Semi-Supervised Few-Shot Learning",
                "abstract": "Semi-supervised few-shot learning consists in training a classifier to adapt to new tasks with limited labeled data and a fixed quantity of unlabeled data. Many sophisticated methods have been developed to address the challenges this problem comprises. In this paper, we propose a simple but quite effective approach to predict accurate negative pseudo-labels of unlabeled data from an indirect learning perspective, and then augment the extremely label-constrained support set in few-shot classification tasks. Our approach can be implemented in just few lines of code by only using off-the-shelf operations, yet it is able to outperform state-of-the-art methods on four benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2126047",
                        "name": "Xiu-Shen Wei"
                    },
                    {
                        "authorId": "2159405382",
                        "name": "Hesheng Xu"
                    },
                    {
                        "authorId": "2051454720",
                        "name": "Faen Zhang"
                    },
                    {
                        "authorId": "143753918",
                        "name": "Yuxin Peng"
                    },
                    {
                        "authorId": "101829183",
                        "name": "Wei Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "RR (Bertinetto et al., 2019) adopts ridge regression (RR) for classification."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0ade637337402b3a2270e75fd3869392937212dd",
                "externalIds": {
                    "ACL": "2022.coling-1.287",
                    "ArXiv": "2209.11486",
                    "DBLP": "conf/coling/HouDWLC22",
                    "DOI": "10.48550/arXiv.2209.11486",
                    "CorpusId": 252519660
                },
                "corpusId": 252519660,
                "publicationVenue": {
                    "id": "f51ff783-cdff-4e22-94fb-28e6336d17b3",
                    "name": "International Conference on Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Comput Linguistics",
                        "COLING"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/coling/"
                },
                "url": "https://www.semanticscholar.org/paper/0ade637337402b3a2270e75fd3869392937212dd",
                "title": "MetaPrompting: Learning to Learn Better Prompts",
                "abstract": "Prompting method is regarded as one of the crucial progress for few-shot nature language processing. Recent research on prompting moves from discrete tokens based \u201chard prompts\u201d to continuous \u201csoft prompts\u201d, which employ learnable vectors as pseudo prompt tokens and achieve better performance. Though showing promising prospects, these soft-prompting methods are observed to rely heavily on good initialization to take effect. Unfortunately, obtaining a perfect initialization for soft prompts requires understanding of inner language models working and elaborate design, which is no easy task and has to restart from scratch for each new task. To remedy this, we propose a generalized soft prompting method called MetaPrompting, which adopts the well-recognized model-agnostic meta-learning algorithm to automatically find better prompt initialization that facilitates fast adaptation to new prompting tasks. Extensive experiments show MetaPrompting tackles soft prompt initialization problem and brings significant improvement on three different datasets (over 6 points improvement in accuracy for 1-shot setting), achieving new state-of-the-art performance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "8471176",
                        "name": "Yutai Hou"
                    },
                    {
                        "authorId": "71150245",
                        "name": "Hongyuan Dong"
                    },
                    {
                        "authorId": "2144801098",
                        "name": "Xinghao Wang"
                    },
                    {
                        "authorId": "2905344",
                        "name": "Bohan Li"
                    },
                    {
                        "authorId": "2256319",
                        "name": "Wanxiang Che"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To solve the problem of lack of large-scale labeled data, many researchers have proposed effective few-shot learning methods, including optimization-based [9-11], meta-learning-based [12-15], and metric-based learning [16-21] methods."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "34e8e29e02643f7e16b9cda0275b22f854cd0e50",
                "externalIds": {
                    "DBLP": "conf/aipr2/LiuBZ022",
                    "DOI": "10.1145/3573942.3574099",
                    "CorpusId": 258718328
                },
                "corpusId": 258718328,
                "publicationVenue": {
                    "id": "596979b9-69c7-4a3a-ac4d-c70580b8fd80",
                    "name": "International Conference on Artificial Intelligence and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Appl Imag Pattern Recognit Workshop",
                        "Int Conf Artif Intell Pattern Recognit",
                        "AIPR",
                        "Applied Imagery Pattern Recognition Workshop",
                        "Artificial Intelligence and Pattern Recognition",
                        "Artif Intell Pattern Recognit"
                    ],
                    "url": "http://www.aipr-workshop.org/"
                },
                "url": "https://www.semanticscholar.org/paper/34e8e29e02643f7e16b9cda0275b22f854cd0e50",
                "title": "Few-Shot Image Classification Based on Cross-Dimensional Interactive Attention",
                "abstract": "In recent years, deep learning techniques have achieved great success in traditional image classification tasks, however, it is often difficult to achieve good results with a small amount of labeled data and prone to overfitting. Therefore, scholars have started to focus on image classification methods based on few-shot learning. The prototype network uses the mean value of the support set samples as the prototype, and achieves classification by calculating the distance between the query set samples and the prototype. To enhance the feature representation capability of the prototype network, this paper proposes a few-shot image classification method based on cross-dimensional interactive attention. The algorithm uses the pre-trained model Resnet-12 to extract deep features of images and introduces the cross-dimensional interactive attention mechanism to link the information between channel and spatial dimensions through triple attention, which enhances the information interaction of each dimension. Meanwhile, in order to improve the problem of insufficient generalization ability of the prototype network, this algorithm uses a gradient-centered optimization algorithm to zero-mean the weight gradient, which improves the generalization ability of the network and improves the classification accuracy. Extensive experimental results show that the proposed algorithm performs well in the few-shot image classification task.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1679704",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2185471619",
                        "name": "Yilun Bai"
                    },
                    {
                        "authorId": "2153528246",
                        "name": "Hengchang Zhang"
                    },
                    {
                        "authorId": "2156122725",
                        "name": "Xin Che"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[28] Luca Bertinetto, Jo\u00e3o F Henriques, Philip HS Torr, and Andrea Vedaldi.",
                "However, works that integrate algorithmic inductive biases\u2014for example by exploiting gradient descent [24, 25], metric learning [26, 27], convex optimization [28, 29], exact or approximate Bayesian inference [30\u2013 32], changepoint detection [33, 34], and other algorithmic primitives\u2014have been highly successful when applied to few-shot learning."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2d59b386a6037a895edf72c4420b76f64d921ee4",
                "externalIds": {
                    "DBLP": "conf/nips/HarrisonMS22",
                    "ArXiv": "2209.11208",
                    "DOI": "10.48550/arXiv.2209.11208",
                    "CorpusId": 252438871
                },
                "corpusId": 252438871,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2d59b386a6037a895edf72c4420b76f64d921ee4",
                "title": "A Closer Look at Learned Optimization: Stability, Robustness, and Inductive Biases",
                "abstract": "Learned optimizers -- neural networks that are trained to act as optimizers -- have the potential to dramatically accelerate training of machine learning models. However, even when meta-trained across thousands of tasks at huge computational expense, blackbox learned optimizers often struggle with stability and generalization when applied to tasks unlike those in their meta-training set. In this paper, we use tools from dynamical systems to investigate the inductive biases and stability properties of optimization algorithms, and apply the resulting insights to designing inductive biases for blackbox optimizers. Our investigation begins with a noisy quadratic model, where we characterize conditions in which optimization is stable, in terms of eigenvalues of the training dynamics. We then introduce simple modifications to a learned optimizer's architecture and meta-training procedure which lead to improved stability, and improve the optimizer's inductive bias. We apply the resulting learned optimizer to a variety of neural network training tasks, where it outperforms the current state of the art learned optimizer -- at matched optimizer computational overhead -- with regard to optimization performance and meta-training speed, and is capable of generalization to tasks far different from those it was meta-trained on.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2106702981",
                        "name": "James Harrison"
                    },
                    {
                        "authorId": "2096458",
                        "name": "Luke Metz"
                    },
                    {
                        "authorId": "1407546424",
                        "name": "Jascha Narain Sohl-Dickstein"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The second design is a ridge-regression predictor with differentiable closed-form solvers [6].",
                "To avoid expensive training from scratch or fine-tuning over the support set per task, we employ ridge regression that admits a closed form solution [6] that can be computed directly in the inner loop of meta-learning."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4e8659fdd87e888d5dd6c85accfea0a8528d57c6",
                "externalIds": {
                    "ArXiv": "2210.16080",
                    "DBLP": "journals/corr/abs-2210-16080",
                    "DOI": "10.1145/3564283",
                    "CorpusId": 252356741
                },
                "corpusId": 252356741,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/4e8659fdd87e888d5dd6c85accfea0a8528d57c6",
                "title": "RESUS: Warm-up Cold Users via Meta-learning Residual User Preferences in CTR Prediction",
                "abstract": "Click-through Rate (CTR) prediction on cold users is a challenging task in recommender systems. Recent researches have resorted to meta-learning to tackle the cold-user challenge, which either perform few-shot user representation learning or adopt optimization-based meta-learning. However, existing methods suffer from information loss or inefficient optimization process, and they fail to explicitly model global user preference knowledge, which is crucial to complement the sparse and insufficient preference information of cold users. In this article, we propose a novel and efficient approach named RESUS, which decouples the learning of global preference knowledge contributed by collective users from the learning of residual preferences for individual users. Specifically, we employ a shared predictor to infer basis user preferences, which acquires global preference knowledge from the interactions of different users. Meanwhile, we develop two efficient algorithms based on the nearest neighbor and ridge regression predictors, which infer residual user preferences via learning quickly from a few user-specific interactions. Extensive experiments on three public datasets demonstrate that our RESUS approach is efficient and effective in improving CTR prediction accuracy on cold users, compared with various state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2923152",
                        "name": "Yanyan Shen"
                    },
                    {
                        "authorId": "2111192570",
                        "name": "Lifan Zhao"
                    },
                    {
                        "authorId": "24450492",
                        "name": "Weiyu Cheng"
                    },
                    {
                        "authorId": "2185461817",
                        "name": "Zibin Zhang"
                    },
                    {
                        "authorId": "2185371810",
                        "name": "Wenwen Zhou"
                    },
                    {
                        "authorId": "2151795425",
                        "name": "Kangyi Lin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In Table 6 below we report the accuracy of our proposed method on all benchmarks, note that for FC100 and CIFAR-FS we believe to be among the first to conduct experiments in the unbalanced setting.",
                "In Appendix we also show the performance of our proposed method on other benchmarks such as FC100 (Oreshkin et al., 2018) and CIFAR-FS (Bertinetto et al., 2019).",
                "In this section we further conduct experiments on two other well-known Few-Shot datasets: 1) FC100 (https://github.com/ElementAI/TADAM) is a recent split dataset based on CIFAR-100 (Krizhevsky et al., 2009) that contains 60 base classes for training, 20 classes for validation and 20 novel classes for evaluation, each class is composed of 600 images of size 32x32 pixels; 2) CIFAR-FS (https://github.com/bertinetto/r2d2) is also sampled from CIFAR-100 and shares the same quantity of classes in the base-validation-novel splits as for mini-Imagenet.",
                "For tiered-Imagenet we set Tkm, Tvb and smax to be 10, 100, 2 in the balanced setting, 100, 100, 1 in the unbalanced setting; for CUB we set them to be 10, 5, 5 in both balanced and unbalanced settings; and for FC100 and CIFAR-FS we set the hyperparameters to be the same as mini-Imagenet.",
                "In Appendix we also show the performance of our proposed method on other well-known Few-Shot benchmarks such as FC100 [30] and CIFAR-FS [4]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "988f3a204ea20c9c85d23f2ba52e7aa9c7ab1cb5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-08527",
                    "ArXiv": "2209.08527",
                    "DOI": "10.48550/arXiv.2209.08527",
                    "CorpusId": 252368317
                },
                "corpusId": 252368317,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/988f3a204ea20c9c85d23f2ba52e7aa9c7ab1cb5",
                "title": "Adaptive Dimension Reduction and Variational Inference for Transductive Few-Shot Classification",
                "abstract": "Transductive Few-Shot learning has gained increased attention nowadays considering the cost of data annotations along with the increased accuracy provided by unlabelled samples in the domain of few shot. Especially in Few-Shot Classification (FSC), recent works explore the feature distributions aiming at maximizing likelihoods or posteriors with respect to the unknown parameters. Following this vein, and considering the parallel between FSC and clustering, we seek for better taking into account the uncertainty in estimation due to lack of data, as well as better statistical properties of the clusters associated with each class. Therefore in this paper we propose a new clustering method based on Variational Bayesian inference, further improved by Adaptive Dimension Reduction based on Probabilistic Linear Discriminant Analysis. Our proposed method significantly improves accuracy in the realistic unbalanced transductive setting on various Few-Shot benchmarks when applied to features used in previous studies, with a gain of up to $6\\%$ in accuracy. In addition, when applied to balanced setting, we obtain very competitive results without making use of the class-balance artefact which is disputable for practical use cases. We also provide the performance of our method on a high performing pretrained backbone, with the reported results further surpassing the current state-of-the-art accuracy, suggesting the genericity of the proposed method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2143462361",
                        "name": "Yuqing Hu"
                    },
                    {
                        "authorId": "2642628",
                        "name": "S. Pateux"
                    },
                    {
                        "authorId": "144916029",
                        "name": "Vincent Gripon"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The CIFAR-FS dataset [2] contains 100 classes with 600 images per class."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3bf3c0b6b25994038bfb4e07b07af6c51ab960e4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-08224",
                    "ArXiv": "2209.08224",
                    "DOI": "10.48550/arXiv.2209.08224",
                    "CorpusId": 252367908
                },
                "corpusId": 252367908,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/3bf3c0b6b25994038bfb4e07b07af6c51ab960e4",
                "title": "Few-Shot Classification with Contrastive Learning",
                "abstract": "A two-stage training paradigm consisting of sequential pre-training and meta-training stages has been widely used in current few-shot learning (FSL) research. Many of these methods use self-supervised learning and contrastive learning to achieve new state-of-the-art results. However, the potential of contrastive learning in both stages of FSL training paradigm is still not fully exploited. In this paper, we propose a novel contrastive learning-based framework that seamlessly integrates contrastive learning into both stages to improve the performance of few-shot classification. In the pre-training stage, we propose a self-supervised contrastive loss in the forms of feature vector vs. feature map and feature map vs. feature map, which uses global and local information to learn good initial representations. In the meta-training stage, we propose a cross-view episodic training mechanism to perform the nearest centroid classification on two different views of the same episode and adopt a distance-scaled contrastive loss based on them. These two strategies force the model to overcome the bias between views and promote the transferability of representations. Extensive experiments on three benchmark datasets demonstrate that our method achieves competitive results.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "66591757",
                        "name": "Zhanyuan Yang"
                    },
                    {
                        "authorId": "46585071",
                        "name": "Jinghua Wang"
                    },
                    {
                        "authorId": "40592392",
                        "name": "Ying J. Zhu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Thus, \"DS+R2D2\" performs better on Huffpost than \"BERT+R2D2\", but worse on Banking77 and Clinc150.",
                "The base learner used by Ridge Regression Differentiable Discriminator (R2D2) (Bertinetto et al., 2019) is ridge regression based on linear regression model.",
                "For the sake of fairness, the classifiers of these two algorithms use R2D2, so we constructed a comparison item with BERT as encoder."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "59a63b72ed0634cd08abdea66336b5e8b6bb0fa8",
                "externalIds": {
                    "DBLP": "conf/coling/LeiHLP022",
                    "ArXiv": "2209.04702",
                    "ACL": "2022.coling-1.431",
                    "DOI": "10.48550/arXiv.2209.04702",
                    "CorpusId": 252199452
                },
                "corpusId": 252199452,
                "publicationVenue": {
                    "id": "f51ff783-cdff-4e22-94fb-28e6336d17b3",
                    "name": "International Conference on Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Comput Linguistics",
                        "COLING"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/coling/"
                },
                "url": "https://www.semanticscholar.org/paper/59a63b72ed0634cd08abdea66336b5e8b6bb0fa8",
                "title": "Adaptive Meta-learner via Gradient Similarity for Few-shot Text Classification",
                "abstract": "Few-shot text classification aims to classify the text under the few-shot scenario. Most of the previous methods adopt optimization-based meta learning to obtain task distribution. However, due to the neglect of matching between the few amount of samples and complicated models, as well as the distinction between useful and useless task features, these methods suffer from the overfitting issue. To address this issue, we propose a novel Adaptive Meta-learner via Gradient Similarity (AMGS) method to improve the model generalization ability to a new task. Specifically, the proposed AMGS alleviates the overfitting based on two aspects: (i) acquiring the potential semantic representation of samples and improving model generalization through the self-supervised auxiliary task in the inner loop, (ii) leveraging the adaptive meta-learner via gradient similarity to add constraints on the gradient obtained by base-learner in the outer loop. Moreover, we make a systematic analysis of the influence of regularization on the entire framework. Experimental results on several benchmarks demonstrate that the proposed AMGS consistently improves few-shot text classification performance compared with the state-of-the-art optimization-based meta-learning approaches. The code is available at: https://github.com/Tianyi-Lei.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2156742878",
                        "name": "Tianyi Lei"
                    },
                    {
                        "authorId": "2184695693",
                        "name": "Honghui Hu"
                    },
                    {
                        "authorId": "2125648143",
                        "name": "Qiaoyang Luo"
                    },
                    {
                        "authorId": "1800117",
                        "name": "Dezhong Peng"
                    },
                    {
                        "authorId": "50141074",
                        "name": "Xu Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For the CIFAR-FS dataset, our method outperforms the sub-optimal method by 0.4% on 1-shot and 0.5% on 5- shot.",
                "Our method also consistently outperforms the other state-of-the-arts methods under both 1-shot and 5-shot settings on the CIFAR-FS and FC100 datasets.",
                "To evaluate the effectiveness of the ICRL-Net, we conducted extensive experiments on four publicly available and widely used few-shot visual recognition benchmarks, i.e., miniImageNet, tieredImageNet, CIFAR-FS, and FC100 datasets.",
                "We conducted extensive experiments on four popular fewshot benchmarks: miniImageNet [21], tieredImageNet [31], CIFAR-FS [32], and FC100 [33] datasets.",
                "2) Performance on CIFAR-FS and FC100: Experimental results on CIFAR-FS and FC100 are shown in Table II.",
                "We conduct extensive experiments on four commonly adopted few-shot benchmarks: miniImageNet, tieredImageNet, CIFAR-FS, and FC100 datasets.",
                "Similar to the CIFAR-FS dataset,\nevery class has 600 images of size 32 \u00d7 32.",
                "3) CIFAR-FS: The CIFAR-FS dataset [32] is a recently proposed few-shot visual recognition benchmark, consisting of all 100 classes from CIFAR-100 [71]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "3a988f4b517454e42671212b0171b4cf384d8a56",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-03034",
                    "ArXiv": "2209.03034",
                    "DOI": "10.1109/TNNLS.2022.3204684",
                    "CorpusId": 252111187,
                    "PubMed": "36136920"
                },
                "corpusId": 252111187,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3a988f4b517454e42671212b0171b4cf384d8a56",
                "title": "Not All Instances Contribute Equally: Instance-adaptive Class Representation Learning for Few-Shot Visual Recognition",
                "abstract": "Few-shot visual recognition refers to recognize novel visual concepts from a few labeled instances. Many few-shot visual recognition methods adopt the metric-based meta-learning paradigm by comparing the query representation with class representations to predict the category of query instance. However, the current metric-based methods generally treat all instances equally and consequently often obtain biased class representation, considering not all instances are equally significant when summarizing the instance-level representations for the class-level representation. For example, some instances may contain unrepresentative information, such as too much background and information of unrelated concepts, which skew the results. To address the above issues, we propose a novel metric-based meta-learning framework termed instance-adaptive class representation learning network (ICRL-Net) for few-shot visual recognition. Specifically, we develop an adaptive instance revaluing network (AIRN) with the capability to address the biased representation issue when generating the class representation, by learning and assigning adaptive weights for different instances according to their relative significance in the support set of corresponding class. In addition, we design an improved bilinear instance representation and incorporate two novel structural losses, i.e., intraclass instance clustering loss and interclass representation distinguishing loss, to further regulate the instance revaluation process and refine the class representation. We conduct extensive experiments on four commonly adopted few-shot benchmarks: miniImageNet, tieredImageNet, CIFAR-FS, and FC100 datasets. The experimental results compared with the state-of-the-art approaches demonstrate the superiority of our ICRL-Net.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2111763556",
                        "name": "M. Han"
                    },
                    {
                        "authorId": "1895813",
                        "name": "Yibing Zhan"
                    },
                    {
                        "authorId": "143610445",
                        "name": "Yong Luo"
                    },
                    {
                        "authorId": "2142452296",
                        "name": "Bo Du"
                    },
                    {
                        "authorId": "46177189",
                        "name": "Han Hu"
                    },
                    {
                        "authorId": "2114783695",
                        "name": "Yonggang Wen"
                    },
                    {
                        "authorId": "2140448089",
                        "name": "Dacheng Tao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Two common datasets are used: the CIFAR-FS (Bertinetto et al., 2019) and Mini-ImageNet (Vinyals et al.",
                "Notes: This table shows the performance of three state-of-the-art few-shot classifiers applied to the CIFAR-FS (Bertinetto et al., 2019) and Mini-ImageNet (Vinyals et al.",
                "Two common datasets are used: the CIFAR-FS (Bertinetto et al., 2019) and Mini-ImageNet (Vinyals et al., 2016)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1b2ed5f5fb007507d7150b00d36c910a49eb2ba3",
                "externalIds": {
                    "ArXiv": "2209.01610",
                    "DBLP": "journals/corr/abs-2209-01610",
                    "DOI": "10.48550/arXiv.2209.01610",
                    "CorpusId": 252089037
                },
                "corpusId": 252089037,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1b2ed5f5fb007507d7150b00d36c910a49eb2ba3",
                "title": "Generalization in Neural Networks: A Broad Survey",
                "abstract": "This paper reviews concepts, modeling approaches, and recent findings along a spectrum of different levels of abstraction of neural network models including generalization across (1) Samples, (2) Distributions, (3) Domains, (4) Tasks, (5) Modalities, and (6) Scopes. Results on (1) sample generalization show that, in the case of ImageNet, nearly all the recent improvements reduced training error while overfitting stayed flat; with nearly all the training error eliminated, future progress will require a focus on reducing overfitting. Perspectives from statistics highlight how (2) distribution generalization can be viewed alternately as a change in sample weights or a change in the input-output relationship; thus, techniques that have been successful in domain generalization have the potential to be applied to difficult forms of sample or distribution generalization. Transfer learning approaches to (3) domain generalization are summarized, as are recent advances and the wealth of domain adaptation benchmark datasets available. Recent breakthroughs surveyed in (4) task generalization include few-shot meta-learning approaches and the BERT NLP engine, and recent (5) modality generalization studies are discussed that integrate image and text data and that apply a biologically-inspired network across olfactory, visual, and auditory modalities. Recent (6) scope generalization results are reviewed that embed knowledge graphs into deep NLP approaches. Additionally, concepts from neuroscience are discussed on the modular architecture of brains and the steps by which dopamine-driven conditioning leads to abstract thinking.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "19236748",
                        "name": "Chris Rohlfs"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To simulate realistic evolving semi-supervised task distributions, we construct a new large-scale dataset and collect 6 datasets, including CIFARFS [12], AIRCRAFT [38], CUB [67], Miniimagenet [56], Butterfly [16] and Plantae [28].",
                "To simulate the task distribution shift in SETS, we construct a dataset by composing 6 datasets, including CIFARFS [12], AIRCRAFT [38], CUB [67], Miniimagenet [56], Butterfly [16] and Plantae [28].",
                "To investigate the sensitivity of baselines and our method to dataset order, we also performed comparisons on two other dataset sequences, including (i) Butterfly, CUB, CIFARFS, Plantae, MiniImagenet, Aircraft and (ii) CUB, CIFARFS, Plantae, MiniImagenet, Butterfly, Aircraft."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dd3d1000f7a2be0a71b12903a5bc5a20b7b565dd",
                "externalIds": {
                    "ArXiv": "2209.01501",
                    "DBLP": "journals/corr/abs-2209-01501",
                    "DOI": "10.48550/arXiv.2209.01501",
                    "CorpusId": 252090405
                },
                "corpusId": 252090405,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/dd3d1000f7a2be0a71b12903a5bc5a20b7b565dd",
                "title": "Meta-Learning with Less Forgetting on Large-Scale Non-Stationary Task Distributions",
                "abstract": ". The paradigm of machine intelligence moves from purely supervised learning to a more practical scenario when many loosely related unlabeled data are available and labeled data is scarce. Most existing algo-rithms assume that the underlying task distribution is stationary. Here we consider a more realistic and challenging setting in that task distributions evolve over time. We name this problem as S emi-supervised meta-learning with E volving T ask di S tributions, abbreviated as SETS . Two key challenges arise in this more realistic setting: (i) how to use unlabeled data in the presence of a large amount of unlabeled out-of-distribution (OOD) data; and (ii) how to prevent catastrophic forgetting on previously learned task distributions due to the task distribution shift. We propose an O OD R obust and knowle D ge pres E rved semi-supe R vised meta-learning approach ( ORDER ) \u2021 , to tackle these two major challenges. Specifically, our ORDER introduces a novel mutual information regularization to robustify the model with unlabeled OOD data and adopts an optimal transport regularization to remember previously learned knowledge in feature space. In addition, we test our method on a very challenging dataset: SETS on large-scale non-stationary semi-supervised task distributions consisting of (at least) 72K tasks. With extensive experiments, we demonstrate the proposed ORDER alleviates forgetting on evolving task distributions and is more robust to OOD data than related strong baselines.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2920297",
                        "name": "Zhenyi Wang"
                    },
                    {
                        "authorId": "2172820082",
                        "name": "Li Shen"
                    },
                    {
                        "authorId": "2153679931",
                        "name": "Le Fang"
                    },
                    {
                        "authorId": "7623895",
                        "name": "Qiuling Suo"
                    },
                    {
                        "authorId": "2064372193",
                        "name": "Dongling Zhan"
                    },
                    {
                        "authorId": "3449409",
                        "name": "Tiehang Duan"
                    },
                    {
                        "authorId": "50987693",
                        "name": "Mingchen Gao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Category shift exists in datasets while the categories are disjoint between training and testing sets, such as miniImagenet (Vinyals et al. 2016) and CIFAR-FS (Bertinetto et al. 2018).",
                "We evaluate our proposed method on four standard benchmarks: miniImagenet (Vinyals et al. 2016), Tiered-ImageNet (Ren et al. 2018), CIFAR-FS (Bertinetto et al. 2018), and CUB-200-2011 (Wah et al. 2011). miniImagenet contains 100 randomly chosen classes from\nAlgorithm 2: Evaluate the CSCA module\u2026",
                "2018), CIFAR-FS (Bertinetto et al. 2018), and CUB-200-2011 (Wah et al."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3255077795b27678d5c88207e267e9fe186fafe3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2209-01332",
                    "ArXiv": "2209.01332",
                    "DOI": "10.48550/arXiv.2209.01332",
                    "CorpusId": 252090106
                },
                "corpusId": 252090106,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3255077795b27678d5c88207e267e9fe186fafe3",
                "title": "Class-Specific Channel Attention for Few-Shot Learning",
                "abstract": "Few-Shot Learning (FSL) has attracted growing attention in computer vision due to its capability in model training without the need for excessive data. FSL is challenging because the training and testing categories (the base vs. novel sets) can be largely diversified. Conventional transfer-based solutions that aim to transfer knowledge learned from large labeled training sets to target testing sets are limited, as critical adverse impacts of the shift in task distribution are not adequately addressed. In this paper, we extend the solution of transfer-based methods by incorporating the concept of metric-learning and channel attention. To better exploit the feature representations extracted by the feature backbone, we propose Class-Specific Channel Attention (CSCA) module, which learns to highlight the discriminative channels in each class by assigning each class one CSCA weight vector. Unlike general attention modules designed to learn global-class features, the CSCA module aims to learn local and class-specific features with very effective computation. We evaluated the performance of the CSCA module on standard benchmarks including miniImagenet, Tiered-ImageNet, CIFAR-FS, and CUB-200-2011. Experiments are performed in inductive and in/cross-domain settings. We achieve new state-of-the-art results.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118426969",
                        "name": "Ying Chen"
                    },
                    {
                        "authorId": "144717607",
                        "name": "J. Hsieh"
                    },
                    {
                        "authorId": "9323852",
                        "name": "Ming-Ching Chang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fc047613f7a58c4804b57f62596b121ca0062081",
                "externalIds": {
                    "DBLP": "journals/nca/TianS23",
                    "DOI": "10.1007/s00521-022-07607-5",
                    "CorpusId": 252031690
                },
                "corpusId": 252031690,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/fc047613f7a58c4804b57f62596b121ca0062081",
                "title": "A transfer-based few-shot classification approach via masked manifold mixup and fuzzy memory contrastive learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2130235796",
                        "name": "Runliang Tian"
                    },
                    {
                        "authorId": "2112515465",
                        "name": "Hongmei Shi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Typical self-supervised methods design pretext tasks to provide automated supervision, where both the inputs and labels are derived from an unlabeled dataset [29, 30, 31]."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "05fcd4fa04c40a4583bacae2ccd0241291a42e36",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-14888",
                    "ArXiv": "2208.14888",
                    "DOI": "10.48550/arXiv.2208.14888",
                    "CorpusId": 251953679,
                    "PubMed": "36841039"
                },
                "corpusId": 251953679,
                "publicationVenue": {
                    "id": "a13f3cb8-2492-4ccb-9329-73a5ddcaab9b",
                    "name": "Neural Networks",
                    "type": "journal",
                    "alternate_names": [
                        "Neural Netw"
                    ],
                    "issn": "0893-6080",
                    "url": "http://www.elsevier.com/locate/neunet",
                    "alternate_urls": [
                        "http://www.elsevier.com/wps/find/journaldescription.cws_home/841/description",
                        "http://www.sciencedirect.com/science/journal/08936080"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/05fcd4fa04c40a4583bacae2ccd0241291a42e36",
                "title": "Feature Alignment by Uncertainty and Self-Training for Source-Free Unsupervised Domain Adaptation",
                "abstract": "Most unsupervised domain adaptation (UDA) methods assume that labeled source images are available during model adaptation. However, this assumption is often infeasible owing to confidentiality issues or memory constraints on mobile devices. Some recently developed approaches do not require source images during adaptation, but they show limited performance on perturbed images. To address these problems, we propose a novel source-free UDA method that uses only a pre-trained source model and unlabeled target images. Our method captures the aleatoric uncertainty by incorporating data augmentation and trains the feature generator with two consistency objectives. The feature generator is encouraged to learn consistent visual features away from the decision boundaries of the head classifier. Thus, the adapted model becomes more robust to image perturbations. Inspired by self-supervised learning, our method promotes inter-space alignment between the prediction space and the feature space while incorporating intra-space consistency within the feature space to reduce the domain gap between the source and target domains. We also consider epistemic uncertainty to boost the model adaptation performance. Extensive experiments on popular UDA benchmark datasets demonstrate that the proposed source-free method is comparable or even superior to vanilla UDA methods. Moreover, the adapted models show more robust results when input images are perturbed.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2116659707",
                        "name": "Joonho Lee"
                    },
                    {
                        "authorId": "2143198",
                        "name": "Gyemin Lee"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9222f55cc355c593d858138ab2362cddac0b43bb",
                "externalIds": {
                    "DBLP": "conf/icpr/WuH22",
                    "DOI": "10.1109/ICPR56361.2022.9956065",
                    "CorpusId": 254099923
                },
                "corpusId": 254099923,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9222f55cc355c593d858138ab2362cddac0b43bb",
                "title": "Learning a Latent Space with Triplet Network for Few-Shot Image Classification",
                "abstract": "Few-shot image classification has attracted much attention due to its requirement of limited training data for target classes. Existing methods usually pretrain a network with images from the base set as feature extractor to obtain features of images from novel set. However, the pretrained feature extractor cannot extract accurate representation for categories have never seen, making images from novel set difficult to distinguish. To be specific, in the pretrained feature space, there exist a large number of overlapped areas between novel categories. To address this issue, it is crucial to acquire a space, where features from same class are gathering together and features from different classes are far away from each other. Since lots of experiments have proved that the triplet network is effective to achieve this goal, in this paper, we base our network on the Maximum a posteriori (MAP), learning a latent space with triplet network to project features from pretrained feature space into a more discriminative one. Experimental results on four few-shot benchmarks show that it significantly outperforms the baseline methods, improves around 1.09%\u223c13.09% than the best results in each dataset on both 1- and 5-shot tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1830420003",
                        "name": "Jiaying Wu"
                    },
                    {
                        "authorId": "37065012",
                        "name": "Jinglu Hu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "987869ad4ad2f0dd0c4d9b130a15b13627608fdd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2208-08135",
                    "ArXiv": "2208.08135",
                    "DOI": "10.48550/arXiv.2208.08135",
                    "CorpusId": 251622399
                },
                "corpusId": 251622399,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/987869ad4ad2f0dd0c4d9b130a15b13627608fdd",
                "title": "Gradient-Based Meta-Learning Using Uncertainty to Weigh Loss for Few-Shot Learning",
                "abstract": ". Model-Agnostic Meta-Learning (MAML) is one of the most successful meta-learning techniques for few-shot learning. It uses gradient descent to learn commonalities between various tasks, enabling the model to learn the meta-initialization of its own parameters to quickly adapt to new tasks using a small amount of labeled training data. A key challenge to few-shot learning is task uncertainty. Although a strong prior can be obtained from meta-learning with a large number of tasks, a precision model of the new task cannot be guaranteed because the vol-ume of the training dataset is normally too small. In this study, \ufb01rst, in the process of choosing initialization parameters, the new method is proposed for task-speci\ufb01c learner adaptively learn to select initialization parameters that minimize the loss of new tasks. Then, we propose two improved methods for the meta-loss part: Method 1 generates weights by comparing meta-loss di\ufb00erences to improve the accuracy when there are few classes, and Method 2 introduces the homoscedastic uncertainty of each task to weigh multiple losses based on the original gradient descent, as a way to enhance the generalization ability to novel classes while en-suring accuracy improvement. Compared with previous gradient-based meta-learning methods, our model achieves better performance in regression tasks and few-shot classi\ufb01cation and improves the robustness of the model to the learning rate and query sets in the meta-test set. Meta-loss.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2181814102",
                        "name": "Lin Ding"
                    },
                    {
                        "authorId": "145779142",
                        "name": "Peng Liu"
                    },
                    {
                        "authorId": "2149662002",
                        "name": "Wenfeng Shen"
                    },
                    {
                        "authorId": "1865353860",
                        "name": "Weijia Lu"
                    },
                    {
                        "authorId": "2145396599",
                        "name": "Shengbo Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fbf26b51ed835a868a2f4155142da9c2273b15d0",
                "externalIds": {
                    "ArXiv": "2208.08089",
                    "DBLP": "journals/corr/abs-2208-08089",
                    "DOI": "10.48550/arXiv.2208.08089",
                    "CorpusId": 251623114
                },
                "corpusId": 251623114,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/fbf26b51ed835a868a2f4155142da9c2273b15d0",
                "title": "Constrained Few-Shot Learning: Human-Like Low Sample Complexity Learning and Non-Episodic Text Classification",
                "abstract": "Few-shot learning (FSL) is an emergent paradigm of learning that attempts to learn with low sample complexity to mimic the way humans can learn, generalise and extrapolate based on only a few examples. While FSL attempts to mimic these human characteristics, fundamentally, the task of FSL as conventionally described and modelled using meta-learning with episodic-based training does not fully align with how humans acquire and reason with knowledge. FSL with episodic training, while only using K instances of each test class, still requires a large number of labelled instances from disjoint training classes. In this paper, we introduce the novel task of constrained few-shot learning (CFSL), a special case of FSL where the number of training instances of each class is constrained to be less than some value M thus applying a similar re-striction during training and test. We propose a method for CFSL leveraging Cat2Vec using a novel categorical contrastive loss inspired by cognitive theories such as fuzzy trace theory and prototype theory.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "50818569",
                        "name": "Jaron Mar"
                    },
                    {
                        "authorId": "2108326935",
                        "name": "Jiamou Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", the finetuning function) can be solved by a few gradient steps, the firstorder Taylor expansion, or other closed-form approximation [3]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "48dfdeedbad27ddcdb4770dfca220054d6bca94c",
                "externalIds": {
                    "DBLP": "conf/kdd/ChenZJ22",
                    "DOI": "10.1145/3534678.3539115",
                    "CorpusId": 251518355
                },
                "corpusId": 251518355,
                "publicationVenue": {
                    "id": "a0edb93b-1e95-4128-a295-6b1659149cef",
                    "name": "Knowledge Discovery and Data Mining",
                    "type": "conference",
                    "alternate_names": [
                        "KDD",
                        "Knowl Discov Data Min"
                    ],
                    "url": "http://www.acm.org/sigkdd/"
                },
                "url": "https://www.semanticscholar.org/paper/48dfdeedbad27ddcdb4770dfca220054d6bca94c",
                "title": "Physics-Guided Graph Meta Learning for Predicting Water Temperature and Streamflow in Stream Networks",
                "abstract": "This paper proposes a graph-based meta learning approach to separately predict water quantity and quality variables for river segments in stream networks. Given the heterogeneous water dynamic patterns in large-scale basins, we introduce an additional meta-learning condition based on physical characteristics of stream segments, which allows learning different sets of initial parameters for different stream segments. Specifically, we develop a representation learning method that leverages physical simulations to embed the physical characteristics of each segment. The obtained embeddings are then used to cluster river segments and add the condition for the meta-learning process. We have tested the performance of the proposed method for predicting daily water temperature and streamflow for the Delaware River Basin (DRB) over a 14 year period. The results confirm the effectiveness of our method in predicting target variables even using sparse training samples. We also show that our method can achieve robust performance with different numbers of clusterings.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2145396874",
                        "name": "Shengyu Chen"
                    },
                    {
                        "authorId": "40377193",
                        "name": "J. Zwart"
                    },
                    {
                        "authorId": "38139853",
                        "name": "X. Jia"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We compared the results against those of various networks for few-shot recognition, including ProtoNet [42], R2D2 [45], and BaseLine [46].",
                "Performance Comparison of Different FSL Networks\nTo validate the effectiveness of RelationNet, the four experimental validation results of ProtoNet, R2D2, BaseLine, and RelationNet were compared."
            ],
            "intents": [
                "result"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7d0c90f1c818fb3bfd9867eb2bc3a647ea413465",
                "externalIds": {
                    "DOI": "10.3390/math10152806",
                    "CorpusId": 251488464
                },
                "corpusId": 251488464,
                "publicationVenue": {
                    "id": "6175efe8-6f8e-4cbe-8cee-d154f4e78627",
                    "name": "Mathematics",
                    "issn": "2227-7390",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-283014",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-283014",
                        "https://www.mdpi.com/journal/mathematics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7d0c90f1c818fb3bfd9867eb2bc3a647ea413465",
                "title": "DL-Aided Underground Cavity Morphology Recognition Based on 3D GPR Data",
                "abstract": "Cavity under urban roads has increasingly become a huge threat to traffic safety. This paper aims to study cavity morphology characteristics and proposes a deep learning (DL)-based morphology classification method using the 3D ground-penetrating radar (GPR) data. Fine-tuning technology in DL can be used in some cases with relatively few samples, but in the case of only one or very few samples, there will still be overfitting problems. To address this issue, a simple and general framework, few-shot learning (FSL), is first employed for the cavity classification tasks, based on which a classifier learns to identify new classes given only very few examples. We adopt a relation network (RelationNet) as the FSL framework, which consists of an embedding module and a relation module. Furthermore, the proposed method is simpler and faster because it does not require pre-training or fine-tuning. The experimental results are validated using the 3D GPR road modeling data obtained from the gprMax3D system. The proposed method is compared with other FSL networks such as ProtoNet, R2D2, and BaseLine relative to different benchmarks. The experimental results demonstrate that this method outperforms other prior approaches, and its average accuracy reaches 97.328% in a four-way five-shot problem using few support samples.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "146714942",
                        "name": "Feifei Hou"
                    },
                    {
                        "authorId": "2144534059",
                        "name": "Xu Liu"
                    },
                    {
                        "authorId": "2148432314",
                        "name": "Xinyu Fan"
                    },
                    {
                        "authorId": "2153201990",
                        "name": "Ying Guo"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c4616265fea3b631b0fb50fd2fb6cfdb40a742db",
                "externalIds": {
                    "DBLP": "journals/pr/ChenZWWWT23",
                    "DOI": "10.1016/j.patcog.2022.108986",
                    "CorpusId": 251731275
                },
                "corpusId": 251731275,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c4616265fea3b631b0fb50fd2fb6cfdb40a742db",
                "title": "Few-shot learning with unsupervised part discovery and part-aligned similarity",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109090809",
                        "name": "Wentao Chen"
                    },
                    {
                        "authorId": "48805574",
                        "name": "Zhang Zhang"
                    },
                    {
                        "authorId": "145200778",
                        "name": "Wei Wang"
                    },
                    {
                        "authorId": "123865558",
                        "name": "Liang Wang"
                    },
                    {
                        "authorId": "3238613",
                        "name": "Zilei Wang"
                    },
                    {
                        "authorId": "143874948",
                        "name": "T. Tan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "scale to large datasets, the efficient gradient descent methods provide a promising solution to the complicated bi-level optimization problem and thus are widely adopted in many deep learning research work to optimize hyperparameters in the single-task formulation [Bertinetto et al. 2019; Y. Chen et al. 2019; Hu et al. 2019; H. Liu et al. 2019; Ma et al. 2020; Rendle 2012] or extract meta knowledge in the multi-task formulation [Andrychowicz et al.",
                "[Bertinetto et al. 2019] propose ridge regression as part of its internal model for closed-form solutions.",
                "\u2026optimization problem and thus are widely adopted in much deep learning research work to optimize hyperparameters in the single-task formulation (Bertinetto et al., 2019; Hu et al., 2019; Liu et al., 2019; Rendle, 2012; Chen et al., 2019; Ma et al., 2020; Zhang et al., 2023; Li et al., 2022) or\u2026",
                "Bertinetto et al. (2019) propose ridge regression as part of its internal model for closed-form solutions."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "16e57ac3e26f6b2ff083c86c3876077a2a2ec727",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-11719",
                    "ArXiv": "2207.11719",
                    "DOI": "10.48550/arXiv.2207.11719",
                    "CorpusId": 251040336
                },
                "corpusId": 251040336,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/16e57ac3e26f6b2ff083c86c3876077a2a2ec727",
                "title": "Gradient-based Bi-level Optimization for Deep Learning: A Survey",
                "abstract": "Bi-level optimization, especially the gradient-based category, has been widely used in the deep learning community including hyperparameter optimization and meta-knowledge extraction. Bi-level optimization embeds one problem within another and the gradient-based category solves the outer-level task by computing the hypergradient, which is much more efficient than classical methods such as the evolutionary algorithm. In this survey, we first give a formal definition of the gradient-based bi-level optimization. Next, we delineate criteria to determine if a research problem is apt for bi-level optimization and provide a practical guide on structuring such problems into a bi-level optimization framework, a feature particularly beneficial for those new to this domain. More specifically, there are two formulations: the single-task formulation to optimize hyperparameters such as regularization parameters and the distilled data, and the multi-task formulation to extract meta-knowledge such as the model initialization. With a bi-level formulation, we then discuss four bi-level optimization solvers to update the outer variable including explicit gradient update, proxy update, implicit function update, and closed-form update. Finally, we wrap up the survey by highlighting two prospective future directions: (1) Effective Data Optimization for Science examined through the lens of task formulation. (2) Accurate Explicit Proxy Update analyzed from an optimization standpoint.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109063223",
                        "name": "Can (Sam) Chen"
                    },
                    {
                        "authorId": "95487088",
                        "name": "Xiangshan Chen"
                    },
                    {
                        "authorId": "74142381",
                        "name": "Chen Ma"
                    },
                    {
                        "authorId": "1645199888",
                        "name": "Zixuan Liu"
                    },
                    {
                        "authorId": "2151058626",
                        "name": "Xue Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a4afbf2ee6c77845ef4a7e91a02f6deef2b84590",
                "externalIds": {
                    "DBLP": "conf/eccv/ZhangH22",
                    "ArXiv": "2207.11685",
                    "DOI": "10.48550/arXiv.2207.11685",
                    "CorpusId": 251040520
                },
                "corpusId": 251040520,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/a4afbf2ee6c77845ef4a7e91a02f6deef2b84590",
                "title": "Kernel Relative-prototype Spectral Filtering for Few-shot Learning",
                "abstract": "Few-shot learning performs classification tasks and regression tasks on scarce samples. As one of the most representative few-shot learning models, Prototypical Network represents each class as sample average, or a prototype, and measures the similarity of samples and prototypes by Euclidean distance. In this paper, we propose a framework of spectral filtering (shrinkage) for measuring the difference between query samples and prototypes, or namely the relative prototypes, in a reproducing kernel Hilbert space (RKHS). In this framework, we further propose a method utilizing Tikhonov regularization as the filter function for few-shot classification. We conduct several experiments to verify our method utilizing different kernels based on the miniImageNet dataset, tiered-ImageNet dataset and CIFAR-FS dataset. The experimental results show that the proposed model can perform the state-of-the-art. In addition, the experimental results show that the proposed shrinkage method can boost the performance. Source code is available at https://github.com/zhangtao2022/DSFN.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2146342045",
                        "name": "Tao Zhang"
                    },
                    {
                        "authorId": "9393382",
                        "name": "Wu Huang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The second is the optimized-based approach [24,6,44,30,43,2,31,68], which rapidly updates models through meta-learning the optimization procedures from a few samples."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8b479d33e3a03eec89e100493a377db466f2d6ae",
                "externalIds": {
                    "DBLP": "conf/eccv/FanPTT22",
                    "ArXiv": "2207.11549",
                    "DOI": "10.48550/arXiv.2207.11549",
                    "CorpusId": 251040260
                },
                "corpusId": 251040260,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/8b479d33e3a03eec89e100493a377db466f2d6ae",
                "title": "Self-Support Few-Shot Semantic Segmentation",
                "abstract": "Existing few-shot segmentation methods have achieved great progress based on the support-query matching framework. But they still heavily suffer from the limited coverage of intra-class variations from the few-shot supports provided. Motivated by the simple Gestalt principle that pixels belonging to the same object are more similar than those to different objects of same class, we propose a novel self-support matching strategy to alleviate this problem, which uses query prototypes to match query features, where the query prototypes are collected from high-confidence query predictions. This strategy can effectively capture the consistent underlying characteristics of the query objects, and thus fittingly match query features. We also propose an adaptive self-support background prototype generation module and self-support loss to further facilitate the self-support matching procedure. Our self-support network substantially improves the prototype quality, benefits more improvement from stronger backbones and more supports, and achieves SOTA on multiple datasets. Codes are at \\url{https://github.com/fanq15/SSP}.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2105557652",
                        "name": "Qi Fan"
                    },
                    {
                        "authorId": "1678473",
                        "name": "Wenjie Pei"
                    },
                    {
                        "authorId": "5068280",
                        "name": "Yu-Wing Tai"
                    },
                    {
                        "authorId": "2088295",
                        "name": "Chi-Keung Tang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "B.2 Details of Datasets\nWe evaluated our method on five benchmark datasets to demonstrate its robustness: miniImagenet[35], tieredImagenet[26], CIFAR-FS[2], FC100[22], and CUB[36].",
                "Existing research work [11, 34, 24, 2] has empirically shown that debiasing the model by input data or learned representation can significantly improve the action recognition performance.",
                "For example, 0.43% vs 0.98%, 0.71% vs 1.9% on CUB-200-2001 and 1.72% vs 2.40% on CIFAR-FS.",
                "For DeepEMD, we do more experiments on CIFAR-FS[2], FC100[22] and CUB[36].",
                "We evaluated our method on five benchmark datasets to demonstrate its robustness: miniImagenet[35], tieredImagenet[26], CIFAR-FS[2], FC100[22], and CUB[36].",
                "We report the accuracy and ECE on CIFAR-FS, FC100 and CUB-200-2011.",
                "Dataset derived from CIFAR100[15]: CIFAR-FS[2] contains 100 classes.",
                "Table 5: Few-shot classification accuracy and 95% confidence interval on CIFAR-FS, FC100 and CUB-200-2011 datasets.",
                "Algorithm Backbone CIFAR-FS,5-way FC100,5-way CUB-200-2011,5-way1-shot 5-shot 1-shot 5-shot 1-shot 5-shot Rethink-Distill[34] ResNet-12 73.90\u00b10.80 86.90\u00b10.50 44.6\u00b10.7 60.9\u00b10.6 \u2013 \u2013\nBML[44] ResNet-12 73.04\u00b10.47 88.04\u00b10.33 45.00\u00b10.41 63.03\u00b10.41 76.21\u00b10.63 90.45\u00b10.36 DeepEMD[42] ResNet-12 73.80\u00b10.29 86.76\u00b10.62 45.17\u00b10.26 60.91\u00b10.75 75.81\u00b10.29 88.35\u00b10.55 DeepEMD+BEL(ours) ResNet-12 73.96\u00b10.29 86.92\u00b10.62 45.10\u00b10.26 61.07\u00b10.74 75.75\u00b10.29 88.56\u00b10.54\nTable 6: Few-shot classification expected calibration error(ECE)%\u2193 on CIFAR-FS, FC100 and CUB-200-2011 datasets."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "02695b2c12ac95af9f30b8f208719d4a01de7815",
                "externalIds": {
                    "ArXiv": "2207.13137",
                    "DBLP": "journals/corr/abs-2207-13137",
                    "DOI": "10.48550/arXiv.2207.13137",
                    "CorpusId": 251105114
                },
                "corpusId": 251105114,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/02695b2c12ac95af9f30b8f208719d4a01de7815",
                "title": "Bayesian Evidential Learning for Few-Shot Classification",
                "abstract": "Few-Shot Classification(FSC) aims to generalize from base classes to novel classes given very limited labeled samples, which is an important step on the path toward human-like machine learning. State-of-the-art solutions involve learning to find a good metric and representation space to compute the distance between samples. Despite the promising accuracy performance, how to model uncertainty for metric-based FSC methods effectively is still a challenge. To model uncertainty, We place a distribution over class probability based on the theory of evidence. As a result, uncertainty modeling and metric learning can be decoupled. To reduce the uncertainty of classification, we propose a Bayesian evidence fusion theorem. Given observed samples, the network learns to get posterior distribution parameters given the prior parameters produced by the pre-trained network. Detailed gradient analysis shows that our method provides a smooth optimization target and can capture the uncertainty. The proposed method is agnostic to metric learning strategies and can be implemented as a plug-and-play module. We integrate our method into several newest FSC methods and demonstrate the improved accuracy and uncertainty quantification on standard FSC benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2170539011",
                        "name": "Xiongkun Linghu"
                    },
                    {
                        "authorId": "145079192",
                        "name": "Yan Bai"
                    },
                    {
                        "authorId": "9920529",
                        "name": "Yihang Lou"
                    },
                    {
                        "authorId": "2000181754",
                        "name": "Shengsen Wu"
                    },
                    {
                        "authorId": "2175139382",
                        "name": "Jinze Li"
                    },
                    {
                        "authorId": "2153099868",
                        "name": "Jianzhong He"
                    },
                    {
                        "authorId": "2174735019",
                        "name": "Tao Bai"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Ridge Regression Meta-Learner (Bertinetto et al., 2018) (RRML) develops the closed-form solution based on ridge regression to acquire the class vector.",
                "The combinations with PN and RRML, respectively, improve the performance of its original counterpart.",
                "We incorporate them into the RRML (Bertinetto et al., 2018) to build a more effective metalearning system.",
                "Notably, the method obtains better generalization ability in various meta-learning frameworks, and DS+RRML achieves the best performance in (Bao et al., 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "29141c265d47936fc0c97fb3c23b748e1324163f",
                "externalIds": {
                    "DBLP": "conf/ijcnn/WangL22",
                    "DOI": "10.1109/IJCNN55064.2022.9892387",
                    "CorpusId": 252625117
                },
                "corpusId": 252625117,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/29141c265d47936fc0c97fb3c23b748e1324163f",
                "title": "Joint Few-Shot Text Classification Aided by Label Semantic and Sentence-Aware Interaction",
                "abstract": "Meta-learning has achieved remarkable performance to address few-shot text classification. However, previous studies fail to attach importance to the label semantic completely and overlook the implicit interaction between lexical features of sentences. In this paper, we explore three enhancement components of the meta-learner aided by the label semantic and sentence-aware interaction, e.g., the label-augmented encoder, the interaction extractor, and the label semantic discriminator. Significantly, these modules are agnostic to the choice of few-shot text classification methods and can be easily incorporated into various existing meta-learning frameworks to improve the classification performance and adaptive ability of the model. We conduct extensive experiments on five benchmark datasets. The results demonstrate that meta-learning approaches upgraded by the above three enhancement components obtain considerable superiority over state-of-the-art models in all datasets. In particular, the average accuracy of 1-shot classification and 5-shot classification is increased by 3.60% and 2.28 %, respectively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2038466068",
                        "name": "Suhe Wang"
                    },
                    {
                        "authorId": "2156643091",
                        "name": "Bo Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fa3cf8f806a01b85f4f26291833efbbce7fd0130",
                "externalIds": {
                    "DBLP": "conf/icmcs/ZhuZ22",
                    "DOI": "10.1109/ICME52920.2022.9859903",
                    "CorpusId": 251847162
                },
                "corpusId": 251847162,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fa3cf8f806a01b85f4f26291833efbbce7fd0130",
                "title": "An Attention-Guided Two-Stream Convolutional Neural Network for Few-Shot Learning",
                "abstract": "Learning unlabeled samples from unseen categories given limited labeled data is a challenging problem. Existing few-shot learning methods fail to generate satisfactory feature representations due to tackling the informative and interference information without distinction. In this paper, we propose an attention-guided two-stream convolutional neural network (AGTSNet), which highlights the salient and discriminative features of the main object while alleviating the background interference to address this indiscriminate treatment. Comprehensive experiments are conducted on few-shot image classification with four standard benchmark datasets to demonstrate the effectiveness of our method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115717093",
                        "name": "Hui Zhu"
                    },
                    {
                        "authorId": "9272754",
                        "name": "Xiaofang Zhao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "21f97e6a7a612c91c87fbcf8f2339aaa232833d2",
                "externalIds": {
                    "ArXiv": "2207.06817",
                    "DBLP": "journals/corr/abs-2207-06817",
                    "DOI": "10.48550/arXiv.2207.06817",
                    "CorpusId": 250526736
                },
                "corpusId": 250526736,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/21f97e6a7a612c91c87fbcf8f2339aaa232833d2",
                "title": "Pseudo-Labeling Based Practical Semi-Supervised Meta-Training for Few-Shot Learning",
                "abstract": "Most existing few-shot learning (FSL) methods require a large amount of labeled data in meta-training, which is a major limit. To reduce the requirement of labels, a semi-supervised meta-training (SSMT) setting has been proposed for FSL, which includes only a few labeled samples and numbers of unlabeled samples in base classes. However, existing methods under this setting require class-aware sample selection from the unlabeled set, which violates the assumption of unlabeled set. In this paper, we propose a practical semi-supervised meta-training setting with truly unlabeled data to facilitate the applications of FSL in realistic scenarios. To better utilize both the labeled and truly unlabeled data, we propose a simple and effective meta-training framework, called pseudo-labeling based meta-learning (PLML). Firstly, we train a classifier via common semi-supervised learning (SSL) and use it to obtain the pseudo-labels of unlabeled data. Then we build few-shot tasks from labeled and pseudo-labeled data and design a novel finetuning method with feature smoothing and noise suppression to better learn the FSL model from noise labels. Surprisingly, through extensive experiments across two FSL datasets, we find that this simple meta-training framework effectively prevents the performance degradation of various FSL models under limited labeled data, and also significantly outperforms the state-of-the-art SSMT models. Besides, benefiting from meta-training, our method also improves two representative SSL algorithms as well.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2509726",
                        "name": "Xingping Dong"
                    },
                    {
                        "authorId": "144082425",
                        "name": "Ling Shao"
                    },
                    {
                        "authorId": "40397682",
                        "name": "Shengcai Liao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "They can be roughly categorized into two groups: (1) Optimization-based methods advocate learning a suitable initialization of model parameters from base classes and transferring these parameters to novel classes in a few gradient steps [33,48,3,10,29].",
                "The train/val/test classes are same to miniImageNet [3]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "519175bab6f5080da936689828576c6dcb7173fa",
                "externalIds": {
                    "DBLP": "conf/eccv/ZhangHLW22",
                    "ArXiv": "2207.06989",
                    "DOI": "10.48550/arXiv.2207.06989",
                    "CorpusId": 250526176
                },
                "corpusId": 250526176,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/519175bab6f5080da936689828576c6dcb7173fa",
                "title": "Tree Structure-Aware Few-Shot Image Classification via Hierarchical Aggregation",
                "abstract": ". In this paper, we mainly focus on the problem of how to learn additional feature representations for few-shot image classification through pretext tasks ( e.g. , rotation or color permutation and so on). This additional knowledge generated by pretext tasks can further improve the performance of few-shot learning (FSL) as it differs from human-annotated supervision ( i.e. , class labels of FSL tasks). To solve this problem, we present a plug-in Hierarchical Tree Structure-aware (HTS) method, which not only learns the relationship of FSL and pretext tasks, but more importantly, can adaptively select and aggregate feature representations generated by pretext tasks to maximize the performance of FSL tasks. A hierarchical tree constructing component and a gated selection aggregating component is introduced to construct the tree structure and find richer transferable knowledge that can rapidly adapt to novel classes with a few labeled images. Extensive experiments show that our HTS can significantly enhance multiple few-shot methods to achieve new state-of-the-art performance on four benchmark datasets. The code is available at: https://github.com/remiMZ/HTS-ECCV22 .",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "39767557",
                        "name": "M. Zhang"
                    },
                    {
                        "authorId": "122132048",
                        "name": "Siteng Huang"
                    },
                    {
                        "authorId": "35660603",
                        "name": "Wenbin Li"
                    },
                    {
                        "authorId": "2111224425",
                        "name": "Donglin Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As mentioned in (Bertinetto et al., 2019), the Woodbury formulation,\nW \u2217 = ZT (ZZT + \u03bbI)\u22121Y\nis used to alleviate the problem, leading to an O(d3) complexity, where d is the hidden size hyperparameter, fixed to some value (see Appendix H).",
                "This transforms the inner loop optimization problem into a simple ridge regression problem for the case of mean squared error loss, having a simple analytic solution to replace the otherwise complicated nonlinear optimization problem (Bertinetto et al., 2019).",
                "As mentioned in (Bertinetto et al., 2019), the Woodbury formulation, W \u2217 = Z (ZZ + \u03bbI)\u22121Y is used to alleviate the problem, leading to an O(d(3)) complexity, where d is the hidden size hyperparameter, fixed to some value (see Appendix H).",
                "We also specify an efficient instantiation of the meta-optimization procedure via a closed-form ridge regressor (Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "a9f1e05bb2f6f2eeaf92fe1fc5ca3f0eb498f673",
                "externalIds": {
                    "ArXiv": "2207.06046",
                    "DBLP": "conf/icml/WooLSKH23",
                    "CorpusId": 258832853
                },
                "corpusId": 258832853,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a9f1e05bb2f6f2eeaf92fe1fc5ca3f0eb498f673",
                "title": "Learning Deep Time-index Models for Time Series Forecasting",
                "abstract": "Deep learning has been actively applied to time series forecasting, leading to a deluge of new methods, belonging to the class of historical-value models. Yet, despite the attractive properties of time-index models, such as being able to model the continuous nature of underlying time series dynamics, little attention has been given to them. Indeed, while naive deep time-index models are far more expressive than the manually predefined function representations of classical time-index models, they are inadequate for forecasting, being unable to generalize to unseen time steps due to the lack of inductive bias. In this paper, we propose DeepTime, a meta-optimization framework to learn deep time-index models which overcome these limitations, yielding an efficient and accurate forecasting model. Extensive experiments on real world datasets in the long sequence time-series forecasting setting demonstrate that our approach achieves competitive results with state-of-the-art methods, and is highly efficient. Code is available at https://github.com/salesforce/DeepTime.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "151488390",
                        "name": "Gerald Woo"
                    },
                    {
                        "authorId": "2039481",
                        "name": "Chenghao Liu"
                    },
                    {
                        "authorId": "36187119",
                        "name": "Doyen Sahoo"
                    },
                    {
                        "authorId": "40305195",
                        "name": "Akshat Kumar"
                    },
                    {
                        "authorId": "1741126",
                        "name": "S. Hoi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Bilevel optimization has proven to be a major tool for solving machine learning problems that possess a nested structure such as hyper-parameter optimization [17], meta-learning [6], reinforcement learning [23, 33], or dictionary learning [38].",
                "[6] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "07fef0ff006c6ecaa340e05cdd068fd4d6da078e",
                "externalIds": {
                    "DBLP": "conf/nips/ArbelM22",
                    "ArXiv": "2207.04888",
                    "CorpusId": 250425910
                },
                "corpusId": 250425910,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/07fef0ff006c6ecaa340e05cdd068fd4d6da078e",
                "title": "Non-Convex Bilevel Games with Critical Point Selection Maps",
                "abstract": "Bilevel optimization problems involve two nested objectives, where an upper-level objective depends on a solution to a lower-level problem. When the latter is non-convex, multiple critical points may be present, leading to an ambiguous definition of the problem. In this paper, we introduce a key ingredient for resolving this ambiguity through the concept of a selection map which allows one to choose a particular solution to the lower-level problem. Using such maps, we define a class of hierarchical games between two agents that resolve the ambiguity in bilevel problems. This new class of games requires introducing new analytical tools in Morse theory to extend implicit differentiation, a technique used in bilevel optimization resulting from the implicit function theorem. In particular, we establish the validity of such a method even when the latter theorem is inapplicable due to degenerate critical points. Finally, we show that algorithms for solving bilevel problems based on unrolled optimization solve these games up to approximation errors due to finite computational power. A simple correction to these algorithms is then proposed for removing these errors.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1975860",
                        "name": "M. Arbel"
                    },
                    {
                        "authorId": "2599292",
                        "name": "J. Mairal"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f3a82ffc95fe00b4752ecd8d9fe3cc2b82e1e3c5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-03398",
                    "ArXiv": "2207.03398",
                    "DOI": "10.48550/arXiv.2207.03398",
                    "CorpusId": 250334577
                },
                "corpusId": 250334577,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f3a82ffc95fe00b4752ecd8d9fe3cc2b82e1e3c5",
                "title": "Diagnosing and Remedying Shot Sensitivity with Cosine Few-Shot Learners",
                "abstract": "Few-shot recognition involves training an image classifier to distinguish novel concepts at test time using few examples (shot). Existing approaches generally assume that the shot number at test time is known in advance. This is not realistic, and the performance of a popular and foundational method has been shown to suffer when train and test shots do not match. We conduct a systematic empirical study of this phenomenon. In line with prior work, we find that shot sensitivity is broadly present across metric-based few-shot learners, but in contrast to prior work, larger neural architectures provide a degree of built-in robustness to varying test shot. More importantly, a simple, previously known but greatly overlooked class of approaches based on cosine distance consistently and greatly improves robustness to shot variation, by removing sensitivity to sample noise. We derive cosine alternatives to popular and recent few-shot classifiers, broadening their applicability to realistic settings. These cosine models consistently improve shot-robustness, outperform prior shot-robust state of the art, and provide competitive accuracy on a range of benchmarks and architectures, including notable gains in the very-low-shot regime.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2171649534",
                        "name": "Davis Wertheimer"
                    },
                    {
                        "authorId": "34689393",
                        "name": "Luming Tang"
                    },
                    {
                        "authorId": "1790580",
                        "name": "Bharath Hariharan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[10] Luca Bertinetto, Joao F Henriques, Philip Torr, and Andrea Vedaldi.",
                "1 Introduction Bilevel optimization is rapidly evolving due to its wide array of applications in modern machine learning (ML) problems including meta-learning [25, 10], hyperparameter optimization [28, 24], neural network architecture search [56, 8], and reinforcement learning [45, 81]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8b106bd8ba95a2992598a5d96799d6b1c1b3811f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-02829",
                    "ArXiv": "2207.02829",
                    "DOI": "10.48550/arXiv.2207.02829",
                    "CorpusId": 250311130
                },
                "corpusId": 250311130,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8b106bd8ba95a2992598a5d96799d6b1c1b3811f",
                "title": "Online Bilevel Optimization: Regret Analysis of Online Alternating Gradient Methods",
                "abstract": "Online optimization is a well-established optimization paradigm that aims to make a sequence of correct decisions given knowledge of the correct answer to previous decision tasks. Bilevel programming involves a hierarchical optimization problem where the feasible region of the so-called outer problem is restricted by the graph of the solution set mapping of the inner problem. This paper brings these two ideas together and studies an online bilevel optimization setting in which a sequence of time-varying bilevel problems are revealed one after the other. We extend the known regret bounds for single-level online algorithms to the bilevel setting. Specifically, we introduce new notions of bilevel regret, develop an online alternating time-averaged gradient method that is capable of leveraging smoothness, and provide regret bounds in terms of the path-length of the inner and outer minimizer sequences.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3281605",
                        "name": "Davoud Ataee Tarzanagh"
                    },
                    {
                        "authorId": "1682385",
                        "name": "L. Balzano"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2022 R2D25 [3]: an efficient meta-learning model with closedform solvers based on ridge regression.",
                "a few labeled samples [2, 3, 12, 13], we employ episodic training to"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "370cbd1b8270f45e47b57e1e07871d36d3d1121c",
                "externalIds": {
                    "DBLP": "conf/sigir/WangWLD22",
                    "DOI": "10.1145/3477495.3531789",
                    "CorpusId": 250340445
                },
                "corpusId": 250340445,
                "publicationVenue": {
                    "id": "8dce23a9-44e0-4381-a39e-2acc1edff700",
                    "name": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
                    "type": "conference",
                    "alternate_names": [
                        "International ACM SIGIR Conference on Research and Development in Information Retrieval",
                        "Int ACM SIGIR Conf Res Dev Inf Retr",
                        "SIGIR",
                        "Annu Int ACM SIGIR Conf Res Dev Inf Retr"
                    ],
                    "url": "http://www.acm.org/sigir/"
                },
                "url": "https://www.semanticscholar.org/paper/370cbd1b8270f45e47b57e1e07871d36d3d1121c",
                "title": "Recognizing Medical Search Query Intent by Few-shot Learning",
                "abstract": "Online healthcare services can provide unlimited and in-time medical information to users, which promotes social goods and breaks the barriers of locations. However, understanding the user intents behind the medical related queries is a challenging problem. Medical search queries are usually short and noisy, lack strict syntactic structure, and also require professional background to understand the medical terms. The medical intents are fine-grained, making them hard to recognize. In addition, many intents only have a few labeled data. To handle these problems, we propose a few-shot learning method for medical search query intent recognition called MEDIC. We extract co-click queries from user search logs as weak supervision to compensate for the lack of labeled data. We also design a new query encoder which learns to represent queries as a combination of semantic knowledge recorded in an external medical knowledge graph, syntactic knowledge which marks the grammatical role of each word in the query, and generic knowledge which is captured by language models pretrained from large-scale text corpus. Experimental results on a real medical search query intent recognition dataset validate the effectiveness of MEDIC.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115793087",
                        "name": "Yaqing Wang"
                    },
                    {
                        "authorId": "2143256075",
                        "name": "Song Wang"
                    },
                    {
                        "authorId": "2135367150",
                        "name": "Yanyan Li"
                    },
                    {
                        "authorId": "1721158",
                        "name": "D. Dou"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d58d61859c9d9348e6f3ab719b6385cf41752ec4",
                "externalIds": {
                    "DOI": "10.1080/01431161.2022.2128926",
                    "CorpusId": 252840729
                },
                "corpusId": 252840729,
                "publicationVenue": {
                    "id": "e9883e67-315e-4b98-a80a-5136298bf7a4",
                    "name": "International Journal of Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Remote Sens"
                    ],
                    "issn": "0143-1161",
                    "url": "https://www.tandfonline.com/toc/tres20/current"
                },
                "url": "https://www.semanticscholar.org/paper/d58d61859c9d9348e6f3ab719b6385cf41752ec4",
                "title": "Few-Shot aerial image classification with deep economic network and teacher knowledge",
                "abstract": "ABSTRACT Deep learning has achieved excellent achievements and has become the mainstream in the field of aerial image classification. While obtaining remarkable success, deep learning-based approaches are notoriously dependent on large amounts of labelled data. Few-shot learning uses existing knowledge to learn from few samples and quickly generalizes to new tasks. In this work, we proposed the few-shot learning with deep economic network and teacher knowledge for aerial image classification. Firstly, we performed simplification twice to reduce large-scale parameters and computational effort in deep networks. In the first simplification, the redundancy in feature inputs\u2019 main components is reduced, and the implicit information in redundant components is extracted instead of directly discarding the redundant components. The channel and spatial redundancies in deeper layers\u2019 inputs are reduced in the second simplification. Secondly, the teacher knowledge guides the random sampling and uses limited samples to improve classification performance. We conducted extensive experiments on NWPU-RESISC45, RSD46-WHU, and UC Merced datasets. The experimental results reveal that the proposed method has better classification accuracy, fewer network parameters, and less computational effort. Experiments on miniImageNet, FC100, CUB, and cross-domain datasets show that our method also maintains advanced classification accuracy on few-shot image classification benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2186273993",
                        "name": "Kang Wang"
                    },
                    {
                        "authorId": "153316233",
                        "name": "Xuesong Wang"
                    },
                    {
                        "authorId": "33718755",
                        "name": "Yuhu Cheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "ridge regression and support vector machine, were successfully integrated into CNNs [55], [56] and have shown great potential in solving the challenging few-shot learning problem."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d03dd793513e1bf599ff1d6b595056caa9802801",
                "externalIds": {
                    "DBLP": "journals/tcsv/HaoHCT22",
                    "DOI": "10.1109/TCSVT.2021.3132912",
                    "CorpusId": 244932874
                },
                "corpusId": 244932874,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d03dd793513e1bf599ff1d6b595056caa9802801",
                "title": "Global-Local Interplay in Semantic Alignment for Few-Shot Learning",
                "abstract": "Few-shot learning aims to recognize novel classes from only a few labeled training examples. Aligning semantically relevant local regions has shown promise in effectively comparing a query image with support images. However, global information is usually overlooked in the existing approaches, resulting in a higher possibility of learning semantics unrelated to the global information. To address this issue, we propose a Global-Local Interplay Metric Learning (GLIML) framework to employ the interplay between global features and local features to guide semantic alignment. We first design a Global-Local Information Concurrent Learning (GLICL) module to extract both global features and local features and perform global-local interplay. We then design a Global-Local Information Cross-Covariance Estimator (GLICCE) to learn the similarity on the global-local interplay, in contrast to the current practice where only local features are considered. Visualizations show that the global-local interplay decreases (1) the weights placed on the semantics that are irrelevant to the global information and (2) the variability of the learned features within every class in the feature space. Quantitative experiments on three benchmark datasets demonstrate that GLIML achieves state-of-the-art performance while maintaining high efficiency.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "41022398",
                        "name": "Fusheng Hao"
                    },
                    {
                        "authorId": "51209425",
                        "name": "Fengxiang He"
                    },
                    {
                        "authorId": "2116819244",
                        "name": "Jun Cheng"
                    },
                    {
                        "authorId": "143719920",
                        "name": "D. Tao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "93b2d0804bfd0908cce5b04b1e3a763bf09311fe",
                "externalIds": {
                    "DBLP": "conf/ijcai/YuZJ22",
                    "DOI": "10.24963/ijcai.2022/513",
                    "CorpusId": 250635192
                },
                "corpusId": 250635192,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/93b2d0804bfd0908cce5b04b1e3a763bf09311fe",
                "title": "Masked Feature Generation Network for Few-Shot Learning",
                "abstract": "In this paper, we present a feature-augmentation approach called Masked Feature Generation Network (MFGN) for Few-Shot Learning (FSL), a challenging task that attempts to recognize the novel classes with a few visual instances for each class. Most of the feature-augmentation approaches tackle FSL tasks via modeling the intra-class distributions. We extend this idea further to explicitly capture the intra-class variations in a one-to-many manner. Specifically, MFGN consists of an encoder-decoder architecture, with an encoder that performs as a feature extractor and extracts the feature embeddings of the available visual instances (the unavailable instances are seen to be masked), along with a decoder that performs as a feature generator and reconstructs the feature embeddings of the unavailable visual instances from both the available feature embeddings and the masked tokens. Equipped with this generative architecture, MFGN produces nontrivial visual features for the novel classes with limited visual instances. In extensive experiments on four FSL benchmarks, MFGN performs competitively and outperforms the state-of-the-art competitors on most of the few-shot classification tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "50133856",
                        "name": "Yunlong Yu"
                    },
                    {
                        "authorId": "2141083701",
                        "name": "Dingyi Zhang"
                    },
                    {
                        "authorId": "143780023",
                        "name": "Zhong Ji"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The CIFAR-FS dataset (Bertinetto et al., 2019) and the FC100 dataset (Oreshkin et al., 2018) are generated from the CIFAR100 dataset based on different selection criteria.",
                "The CIFAR-FS dataset (Bertinetto et al., 2019) and the FC100 dataset (Oreshkin et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8f0481843f035ad80a4e16b4619aa986bed6fc96",
                "externalIds": {
                    "DOI": "10.24846/v31i2y202207",
                    "CorpusId": 250192598
                },
                "corpusId": 250192598,
                "publicationVenue": {
                    "id": "4080b3f6-c1d3-496f-ae83-6209a95ec6dd",
                    "name": "Studies in Informatics and Control",
                    "type": "journal",
                    "alternate_names": [
                        "Stud Informatics Control"
                    ],
                    "issn": "1220-1766",
                    "alternate_issns": [
                        "1841-429X"
                    ],
                    "url": "https://sic.ici.ro/"
                },
                "url": "https://www.semanticscholar.org/paper/8f0481843f035ad80a4e16b4619aa986bed6fc96",
                "title": "Enhancing the Generalization Performance of Few-Shot Image Classification with Self-Knowledge Distillation",
                "abstract": ": Though deep learning has succeeded in various fields, its performance on tasks without a large-scale dataset is always unsatisfactory. The meta-learning based few-shot learning has been used to address the limited data situation. Because of its fast adaptation to the new concepts, meta-learning fully utilizes the prior transferrable knowledge to recognize the unseen instances. The general belief is that meta-learning leverages a large quantity of few-shot tasks sampled from the base dataset to quickly adapt the learner to an unseen task. In this paper, the teacher model is distilled to transfer the features using the same architecture. Following the standard-setting in few-shot learning, the proposed model was trained from scratch and the distribution was transferred to a better generalization. Feature similarity matching was proposed to compensate for the inner feature similarities. Besides, the prediction from the teacher model was further corrected in the self-knowledge distillation period. The proposed approach was evaluated on several commonly used benchmarks in few-shot learning and performed best among all prior works.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2154884709",
                        "name": "Liang Li"
                    },
                    {
                        "authorId": "50680948",
                        "name": "Weidong Jin"
                    },
                    {
                        "authorId": "2118797693",
                        "name": "Yingkun Huang"
                    },
                    {
                        "authorId": "2049666629",
                        "name": "Junxiao Ren"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS includes 100 classes that are divided into 64 base, 16 validation, and 20 novel classes.",
                "For our proposed CAMtrast, we train 30 epochs (t = 30) for warmup on miniImageNet and CIFAR-FS, and 50 epochs (t = 50) on tieredImageNet.",
                "For the latter, the tieredImageNet and CIFAR-FS (Bertinetto et al. 2018) are used.",
                "Cross-domain few-shot recognition: To further evaluate the transfer performance in a more realistic scenario, we also conduct few-shot experiments with domain shifts between tieredImageNet and CIFAR-FS.",
                "The models are pretrained on either tieredImageNet\u2019s or CIFAR-FS\u2019s base classes and\nevaluated on the other\u2019s novel classes."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "48698cba618caa06d0ba353747b86a1529827440",
                "externalIds": {
                    "DBLP": "conf/aaai/Sun00W022",
                    "DOI": "10.1609/aaai.v36i2.20129",
                    "CorpusId": 250299545
                },
                "corpusId": 250299545,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/48698cba618caa06d0ba353747b86a1529827440",
                "title": "Boost Supervised Pretraining for Visual Transfer Learning: Implications of Self-Supervised Contrastive Representation Learning",
                "abstract": "Unsupervised pretraining based on contrastive learning has made significant progress recently and showed comparable or even superior transfer learning performance to traditional supervised pretraining on various tasks. In this work, we first empirically investigate when and why unsupervised pretraining surpasses supervised counterparts for image classification tasks with a series of control experiments. Besides the commonly used accuracy, we further analyze the results qualitatively with the class activation maps and assess the learned representations quantitatively with the representation entropy and uniformity. Our core finding is that it is the amount of information effectively perceived by the learning model that is crucial to transfer learning, instead of absolute size of the dataset. Based on this finding, we propose Classification Activation Map guided contrastive (CAMtrast) learning which better utilizes the label supervsion to strengthen supervised pretraining, by making the networks perceive more information from the training images. CAMtrast is evaluated with three fundamental visual learning tasks: image recognition, object detection, and semantic segmentation, on various public datasets. Experimental results show that our CAMtrast effectively improves the performance of supervised pretraining, and that its performance is superior to both unsupervised counterparts and a recent related work which similarly attempted improving supervised pretraining.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "6714154",
                        "name": "Jinghan Sun"
                    },
                    {
                        "authorId": "2092171024",
                        "name": "Dong Wei"
                    },
                    {
                        "authorId": "70665656",
                        "name": "Kai Ma"
                    },
                    {
                        "authorId": "2144698575",
                        "name": "Liansheng Wang"
                    },
                    {
                        "authorId": "2110381386",
                        "name": "Yefeng Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[5]) and K-Nearest Neighbor (KNN, K-Nearest Neighbor) to conduct our comparison experiments."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c64c11ea4423fc800d59a701be8a1179eb4cfd0c",
                "externalIds": {
                    "DBLP": "conf/ih/WenZYX22",
                    "DOI": "10.1145/3531536.3532949",
                    "CorpusId": 249960307
                },
                "corpusId": 249960307,
                "publicationVenue": {
                    "id": "a787c1d1-6429-4d3e-b5f5-56ac11fc9bca",
                    "name": "Information Hiding and Multimedia Security Workshop",
                    "type": "conference",
                    "alternate_names": [
                        "IH&MMSec",
                        "Inf Hiding Multimedia Secur Workshop"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1549"
                },
                "url": "https://www.semanticscholar.org/paper/c64c11ea4423fc800d59a701be8a1179eb4cfd0c",
                "title": "Few-shot Text Steganalysis Based on Attentional Meta-learner",
                "abstract": "Text steganalysis is a technique to distinguish between steganographic text and normal text via statistical features. Current state-of-the-art text steganalysis models have two limitations. First, they need sufficient amounts of labeled data for training. Second, they lack the generalization ability on different detection tasks. In this paper, we propose a meta-learning framework for text steganalysis in the few-shot scenario to ensure model fast-adaptation between tasks. A general feature extractor based on BERT is applied to extract universal features among tasks, and a meta-learner based on attentional Bi-LSTM is employed to learn task-specific representations. A classifier trained on the support set calculates the prediction loss on the query set with a few samples to update the meta-learner. Extensive experiments show that our model can adapt fast among different steganalysis tasks through extremely few-shot samples, significantly improving detection performance compared with the state-of-the-art steganalysis models and other meta-learning methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47808650",
                        "name": "Juan Wen"
                    },
                    {
                        "authorId": "2116462308",
                        "name": "Ziwei Zhang"
                    },
                    {
                        "authorId": "2116467972",
                        "name": "Y. Yang"
                    },
                    {
                        "authorId": "9095768",
                        "name": "Yiming Xue"
                    }
                ]
            }
        },
        {
            "contexts": [
                "It has been found to provide favorable solutions in a variety of problems, such as meta learning and hyperparameter optimization (Franceschi et al., 2018; Snell et al., 2017; Bertinetto et al., 2018), composition optimization (Wang and Liu, 2016b), two-player games (Von Stackelberg and Von, 1952), reinforcement learning and imitation learning (Arora et al.",
                ", 2020; Tu, 2021), and more recently in machine learning problems (Franceschi et al., 2018; Snell et al., 2017; Bertinetto et al., 2018; Wang and Liu, 2016b)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fc9360c57a03866e21909cccc267b5dded46eb59",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-10870",
                    "ArXiv": "2206.10870",
                    "DOI": "10.48550/arXiv.2206.10870",
                    "CorpusId": 249926964
                },
                "corpusId": 249926964,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/fc9360c57a03866e21909cccc267b5dded46eb59",
                "title": "Decentralized Gossip-Based Stochastic Bilevel Optimization over Communication Networks",
                "abstract": "Bilevel optimization have gained growing interests, with numerous applications found in meta learning, minimax games, reinforcement learning, and nested composition optimization. This paper studies the problem of distributed bilevel optimization over a network where agents can only communicate with neighbors, including examples from multi-task, multi-agent learning and federated learning. In this paper, we propose a gossip-based distributed bilevel learning algorithm that allows networked agents to solve both the inner and outer optimization problems in a single timescale and share information via network propagation. We show that our algorithm enjoys the $\\mathcal{O}(\\frac{1}{K \\epsilon^2})$ per-agent sample complexity for general nonconvex bilevel optimization and $\\mathcal{O}(\\frac{1}{K \\epsilon})$ for strongly convex objective, achieving a speedup that scales linearly with the network size. The sample complexities are optimal in both $\\epsilon$ and $K$. We test our algorithm on the examples of hyperparameter tuning and decentralized reinforcement learning. Simulated experiments confirmed that our algorithm achieves the state-of-the-art training efficiency and test accuracy.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "7388681",
                        "name": "Shuoguang Yang"
                    },
                    {
                        "authorId": "2108039040",
                        "name": "Xuezhou Zhang"
                    },
                    {
                        "authorId": "145731462",
                        "name": "Mengdi Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We exploit CaSE as building block of a hybrid training protocol called UpperCaSE which is based on the idea of adjusting the body of the network in a single forward pass over the context, and reserving the use of expensive fine-tuning routines for the linear head, similarly to methods like MetaOptNet (Lee et al., 2019), R2D2 (Bertinetto et al., 2018), and ANIL (Raghu et al., 2019).",
                "Another possible solution is the use of an alternating-optimization scheme, similar to the one proposed in a number of recent methods such as MetaOptNet (Lee et al., 2019), R2D2 (Bertinetto et al., 2018), and ANIL (Raghu et al., 2019).",
                ", 2019), R2D2 (Bertinetto et al., 2018), and ANIL (Raghu et al.",
                "\u2026is based on the idea of adjusting the body of the network in a single forward pass over the context, and reserving the use of expensive fine-tuning routines for the linear head, similarly to methods like MetaOptNet (Lee et al., 2019), R2D2 (Bertinetto et al., 2018), and ANIL (Raghu et al., 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "d32243eb4176f480d32adee969393a8069e9cee7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-09843",
                    "ArXiv": "2206.09843",
                    "DOI": "10.48550/arXiv.2206.09843",
                    "CorpusId": 249890038
                },
                "corpusId": 249890038,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/d32243eb4176f480d32adee969393a8069e9cee7",
                "title": "Contextual Squeeze-and-Excitation for Efficient Few-Shot Image Classification",
                "abstract": "Recent years have seen a growth in user-centric applications that require effective knowledge transfer across tasks in the low-data regime. An example is personalization, where a pretrained system is adapted by learning on small amounts of labeled data belonging to a specific user. This setting requires high accuracy under low computational complexity, therefore the Pareto frontier of accuracy vs. adaptation cost plays a crucial role. In this paper we push this Pareto frontier in the few-shot image classification setting with a key contribution: a new adaptive block called Contextual Squeeze-and-Excitation (CaSE) that adjusts a pretrained neural network on a new task to significantly improve performance with a single forward pass of the user data (context). We use meta-trained CaSE blocks to conditionally adapt the body of a network and a fine-tuning routine to adapt a linear head, defining a method called UpperCaSE. UpperCaSE achieves a new state-of-the-art accuracy relative to meta-learners on the 26 datasets of VTAB+MD and on a challenging real-world personalization benchmark (ORBIT), narrowing the gap with leading fine-tuning methods with the benefit of orders of magnitude lower adaptation cost.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3366919",
                        "name": "Massimiliano Patacchiola"
                    },
                    {
                        "authorId": "46242344",
                        "name": "J. Bronskill"
                    },
                    {
                        "authorId": "123830349",
                        "name": "Aliaksandra Shysheya"
                    },
                    {
                        "authorId": "1380228856",
                        "name": "Katja Hofmann"
                    },
                    {
                        "authorId": "2388416",
                        "name": "Sebastian Nowozin"
                    },
                    {
                        "authorId": "145369890",
                        "name": "Richard E. Turner"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The closed form inner optimization for meta-learning has been successfully used in various methods [3, 14, 37, 11, 12]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c76da11be0668b143695ca005656b50aa36d0077",
                "externalIds": {
                    "ArXiv": "2206.09543",
                    "DBLP": "journals/corr/abs-2206-09543",
                    "DOI": "10.48550/arXiv.2206.09543",
                    "CorpusId": 249888974
                },
                "corpusId": 249888974,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c76da11be0668b143695ca005656b50aa36d0077",
                "title": "Meta-learning for Out-of-Distribution Detection via Density Estimation in Latent Space",
                "abstract": "Many neural network-based out-of-distribution (OoD) detection methods have been proposed. How-ever, they require many training data for each target task. We propose a simple yet effective meta-learning method to detect OoD with small in-distribution data in a target task. With the proposed method, the OoD detection is performed by density estimation in a latent space. A neural network shared among all tasks is used to \ufb02exibly map instances in the original space to the latent space. The neural network is meta-learned such that the expected OoD detection performance is improved by using various tasks that are different from the target tasks. This meta-learning procedure enables us to obtain appropriate representations in the latent space for OoD detection. For density estimation, we use a Gaussian mixture model (GMM) with full covariance for each class. We can adapt the GMM parameters to in-distribution data in each task in a closed form by maximizing the likelihood. Since the closed form solution is differentiable, we can meta-learn the neural network ef\ufb01ciently with a stochastic gradient descent method by incorporating the solution into the meta-learning objective function. In experiments using six datasets, we demonstrate that the proposed method achieves better performance than existing meta-learning and OoD detection methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2664600",
                        "name": "Tomoharu Iwata"
                    },
                    {
                        "authorId": "3370561",
                        "name": "Atsutoshi Kumagai"
                    }
                ]
            }
        },
        {
            "contexts": [
                "MetaOptNet [14] and [28,3] reset the inner optimization by dividing the model into feature extractor and head classifier and apply on complex base learner like ResNet-12 without overfitting."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f6f150d7caa6c642580a8ccf01b180f766332924",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-09195",
                    "ArXiv": "2206.09195",
                    "DOI": "10.48550/arXiv.2206.09195",
                    "CorpusId": 249889901
                },
                "corpusId": 249889901,
                "publicationVenue": {
                    "id": "7068bf85-7588-4846-bb6e-07c641b910cf",
                    "name": "WISE",
                    "type": "conference",
                    "alternate_names": [
                        "World Conf Inf Secur Educ",
                        "ACM Workshop on Wireless Security",
                        "Int Conf Web Inf Syst Eng",
                        "Web Information Systems Engineering",
                        "WiSe",
                        "Web Inf Syst Eng",
                        "Workshop on Wireless Security",
                        "Workshop Wirel Secur",
                        "World Conference on Information Security Education",
                        "ACM Workshop Wirel Secur",
                        "International Conference on Web Information Systems Engineering"
                    ],
                    "issn": "2349-316X",
                    "url": "http://www.wisesociety.org/"
                },
                "url": "https://www.semanticscholar.org/paper/f6f150d7caa6c642580a8ccf01b180f766332924",
                "title": "EEML: Ensemble Embedded Meta-learning",
                "abstract": ". To accelerate learning process with few samples, meta-learning resorts to prior knowledge from previous tasks. However, the inconsis-tent task distribution and heterogeneity is hard to be handled through a global sharing model initialization. In this paper, based on gradient-based meta-learning, we propose an ensemble embedded meta-learning algorithm (EEML) that explicitly utilizes multi-model-ensemble to organize prior knowledge into diverse speci\ufb01c experts. We rely on a task embedding cluster mechanism to deliver diverse tasks to matching experts in training process and instruct how experts collaborate in test phase. As a result, the multi experts can focus on their own area of ex-pertise and cooperate in upcoming task to solve the task heterogeneity. The experimental results show that the proposed method outperforms recent state-of-the-arts easily in few-shot learning problem, which validates the importance of di\ufb00erentiation and cooperation.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108548674",
                        "name": "Geng Li"
                    },
                    {
                        "authorId": "2125147129",
                        "name": "Boyuan Ren"
                    },
                    {
                        "authorId": "2109570851",
                        "name": "Hongzhi Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Copyright 2023 by the author(s).\nof problems has attracted great attention due to their applications in hyper-parameter optimization (Franceschi et al., 2018; Shaban et al., 2019), meta-learning (Rajeswaran et al., 2019; Bertinetto et al., 2019), and reinforcement learning (Hong et al., 2020)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "23d4da6dd0331c8042afe6ebeb506d2badf6c119",
                "externalIds": {
                    "DBLP": "conf/aistats/JiangAMH23",
                    "ArXiv": "2206.08868",
                    "CorpusId": 253116910
                },
                "corpusId": 253116910,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/23d4da6dd0331c8042afe6ebeb506d2badf6c119",
                "title": "A Conditional Gradient-based Method for Simple Bilevel Optimization with Convex Lower-level Problem",
                "abstract": "In this paper, we study a class of bilevel optimization problems, also known as simple bilevel optimization, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue, in this paper, we introduce a novel bilevel optimization method that locally approximates the solution set of the lower-level problem via a cutting plane, and then runs a conditional gradient update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f,1/\\epsilon_g\\})$ iterations to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and $\\epsilon_g$-optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f^2,1/(\\epsilon_f\\epsilon_g)\\})$ iterations to find an $(\\epsilon_f,\\epsilon_g)$-optimal solution. We also prove stronger convergence guarantees under the H\\\"olderian error bound assumption on the lower-level problem. To the best of our knowledge, our method achieves the best-known iteration complexity for the considered class of bilevel problems.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2051263313",
                        "name": "Ruichen Jiang"
                    },
                    {
                        "authorId": "2171107359",
                        "name": "Nazanin Abolfazli"
                    },
                    {
                        "authorId": "2706423",
                        "name": "Aryan Mokhtari"
                    },
                    {
                        "authorId": "7783772",
                        "name": "E. Y. Hamedani"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fafc77d3a50840a5a387dac8d9a51c4bf4a5da86",
                "externalIds": {
                    "DOI": "10.1109/ITAIC54216.2022.9836774",
                    "CorpusId": 251325548
                },
                "corpusId": 251325548,
                "publicationVenue": {
                    "id": "e15ba297-92fa-47c7-b7d3-edafbd9b8e5b",
                    "name": "IEEE Joint International Information Technology and Artificial Intelligence Conference",
                    "type": "conference",
                    "alternate_names": [
                        "IITAIC",
                        "IEEE Jt Int Inf Technol Artif Intell Conf"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fafc77d3a50840a5a387dac8d9a51c4bf4a5da86",
                "title": "Image-to-Class Metric based on Category Traversal for Few-shot Learning",
                "abstract": "The purpose of few-shot learning is to learn a classification model with good generalization performance. When there is only one sample or several samples, the model can also be quickly generalized to new categories. In this paper, we use the method based on metric learning to complete the few-shot learning image classification task. In this method, we introduce a feature learning module to improve the representation ability of the feature extraction network. Through category traversal, the module extracts the intra-class common features and inter-class unique features of images. Finally, by comparing the similarity between the input image and the local descriptors of each category, the classification task is completed by the image-to-class measure. This metric is achieved by $k$-NN search in the local descriptors, in this way, we can make full use of all the local features of a category, thus expressing the distribution of this class more richly and effectively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "119548077",
                        "name": "Si-Cong Yuan"
                    },
                    {
                        "authorId": "2108107216",
                        "name": "Qishen Li"
                    },
                    {
                        "authorId": "2154489526",
                        "name": "Hua Huang"
                    },
                    {
                        "authorId": "2154487963",
                        "name": "Qiufeng Li"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b477b06032593f2d01d4ac278e340b5db174e7e2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-08150",
                    "ArXiv": "2206.08150",
                    "DOI": "10.48550/arXiv.2206.08150",
                    "CorpusId": 249712038
                },
                "corpusId": 249712038,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b477b06032593f2d01d4ac278e340b5db174e7e2",
                "title": "Self-Adaptive Label Augmentation for Semi-supervised Few-shot Classification",
                "abstract": "Few-shot classification aims to learn a model that can generalize well to new tasks when only a few labeled samples are available. To make use of unlabeled data that are more abundantly available in real applications, Ren et al. \\shortcite{ren2018meta} propose a semi-supervised few-shot classification method that assigns an appropriate label to each unlabeled sample by a manually defined metric. However, the manually defined metric fails to capture the intrinsic property in data. In this paper, we propose a \\textbf{S}elf-\\textbf{A}daptive \\textbf{L}abel \\textbf{A}ugmentation approach, called \\textbf{SALA}, for semi-supervised few-shot classification. A major novelty of SALA is the task-adaptive metric, which can learn the metric adaptively for different tasks in an end-to-end fashion. Another appealing feature of SALA is a progressive neighbor selection strategy, which selects unlabeled data with high confidence progressively through the training phase. Experiments demonstrate that SALA outperforms several state-of-the-art methods for semi-supervised few-shot classification on benchmark datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2191370578",
                        "name": "Xueliang Wang"
                    },
                    {
                        "authorId": "2115669924",
                        "name": "Jianyu Cai"
                    },
                    {
                        "authorId": "1743600",
                        "name": "Shuiwang Ji"
                    },
                    {
                        "authorId": "2144406784",
                        "name": "Houqiang Li"
                    },
                    {
                        "authorId": "144864333",
                        "name": "Feng Wu"
                    },
                    {
                        "authorId": "2146041754",
                        "name": "Jie Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Conventional benchmarks of FSL only consider category shift, i.e. the categories are disjoint for training and testing, such as miniImageNet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b60a8c7dcf300dc8cf3d656323887e66b24b8263",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-08126",
                    "ArXiv": "2206.08126",
                    "DOI": "10.48550/arXiv.2206.08126",
                    "CorpusId": 249712075
                },
                "corpusId": 249712075,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b60a8c7dcf300dc8cf3d656323887e66b24b8263",
                "title": "Channel Importance Matters in Few-Shot Image Classification",
                "abstract": "Few-Shot Learning (FSL) requires vision models to quickly adapt to brand-new classification tasks with a shift in task distribution. Understanding the difficulties posed by this task distribution shift is central to FSL. In this paper, we show that a simple channel-wise feature transformation may be the key to unraveling this secret from a channel perspective. When facing novel few-shot tasks in the test-time datasets, this transformation can greatly improve the generalization ability of learned image representations, while being agnostic to the choice of training algorithms and datasets. Through an in-depth analysis of this transformation, we find that the difficulty of representation transfer in FSL stems from the severe channel bias problem of image representations: channels may have different importance in different tasks, while convolutional neural networks are likely to be insensitive, or respond incorrectly to such a shift. This points out a core problem of the generalization ability of modern vision systems and needs further attention in the future. Our code is available at https://github.com/Frankluox/Channel_Importance_FSL.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115611493",
                        "name": "Xu Luo"
                    },
                    {
                        "authorId": "2155954441",
                        "name": "Jing Xu"
                    },
                    {
                        "authorId": "1683510",
                        "name": "Zenglin Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS.",
                "The CIFAR-FS dataset (Bertinetto et al., 2019) contains essentially the data from the CIFAR100 (Krizhevsky et al., 2009) dataset and splits the 100 categories of 600 images each into 64 training, 16 validation and 20 test classes.",
                "The CIFAR-FS dataset (Bertinetto et al., 2019) contains essentially the data from the CIFAR100 (Krizhevsky et al.",
                ", 2018), CIFAR-FS (Bertinetto et al., 2019) and FC100 (Oreshkin et al.",
                "Evaluations are conducted on all five popular FSL datasets: CUB-200-2011 (Wah et al., 2011), miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFAR-FS (Bertinetto et al., 2019) and FC100 (Oreshkin et al., 2018)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "5ed66b00b9096520911fb5052a02992e07403753",
                "externalIds": {
                    "DBLP": "conf/nips/HillerHD22",
                    "ArXiv": "2206.07260",
                    "DOI": "10.48550/arXiv.2206.07260",
                    "CorpusId": 249674409
                },
                "corpusId": 249674409,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/5ed66b00b9096520911fb5052a02992e07403753",
                "title": "On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot Adaptation",
                "abstract": "Inspired by the concept of preconditioning, we propose a novel method to increase adaptation speed for gradient-based meta-learning methods without incurring extra parameters. We demonstrate that recasting the optimization problem to a non-linear least-squares formulation provides a principled way to actively enforce a $\\textit{well-conditioned}$ parameter space for meta-learning models based on the concepts of the condition number and local curvature. Our comprehensive evaluations show that the proposed method significantly outperforms its unconstrained counterpart especially during initial adaptation steps, while achieving comparable or better overall results on several few-shot classification tasks -- creating the possibility of dynamically choosing the number of adaptation steps at inference time.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47467782",
                        "name": "M. Hiller"
                    },
                    {
                        "authorId": "23911916",
                        "name": "Mehrtash Harandi"
                    },
                    {
                        "authorId": "144418842",
                        "name": "T. Drummond"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Reported are the mean and 95% confidence interval on the unseen test sets of CIFAR-FS [4] and FC-100 [33], using the established evaluation protocols.",
                "We evaluate our method FewTURE using two different Transformer backbones and compare our results against the current state of the art in Table 1 for the miniImageNet and tieredImageNet, and in Table 2 for the CIFAR-FS and FC100 datasets.",
                "CIFAR-FS.",
                "The CIFAR-FS dataset [1] contains the 100 categories with 600 images per category from the CIFAR100 [8] dataset which are split into 64 training, 16 validation and 20 test classes.",
                "We train and evaluate our methods using four popular few-shot classification benchmarks, namely miniImageNet [48], tieredImageNet [37], CIFAR-FS [4] and FC-100 [34].",
                "We train and evaluate our methods using four popular few-shot classification benchmarks, namely miniImageNet [48], tieredImageNet [36], CIFAR-FS [4] and FC-100 [33]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "27bfbb21230e90bb373e5c02fa01ae205b3e3f10",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-07267",
                    "ArXiv": "2206.07267",
                    "DOI": "10.48550/arXiv.2206.07267",
                    "CorpusId": 249674585
                },
                "corpusId": 249674585,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/27bfbb21230e90bb373e5c02fa01ae205b3e3f10",
                "title": "Rethinking Generalization in Few-Shot Classification",
                "abstract": "Single image-level annotations only correctly describe an often small subset of an image's content, particularly when complex real-world scenes are depicted. While this might be acceptable in many classification scenarios, it poses a significant challenge for applications where the set of classes differs significantly between training and test time. In this paper, we take a closer look at the implications in the context of $\\textit{few-shot learning}$. Splitting the input samples into patches and encoding these via the help of Vision Transformers allows us to establish semantic correspondences between local regions across images and independent of their respective class. The most informative patch embeddings for the task at hand are then determined as a function of the support set via online optimization at inference time, additionally providing visual interpretability of `$\\textit{what matters most}$' in the image. We build on recent advances in unsupervised training of networks via masked image modelling to overcome the lack of fine-grained labels and learn the more general statistical structure of the data while avoiding negative image-level annotation influence, $\\textit{aka}$ supervision collapse. Experimental results show the competitiveness of our approach, achieving new state-of-the-art results on four popular few-shot classification benchmarks for $5$-shot and $1$-shot scenarios.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "47467782",
                        "name": "M. Hiller"
                    },
                    {
                        "authorId": "2146354647",
                        "name": "Rongkai Ma"
                    },
                    {
                        "authorId": "23911916",
                        "name": "Mehrtash Harandi"
                    },
                    {
                        "authorId": "144418842",
                        "name": "T. Drummond"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These include meta-learning (Franceschi et al., 2018; Bertinetto et al., 2019), hyperparameter optimisation (Feurer & Hutter, 2019; Shaban et al.",
                "These include meta-learning (Franceschi et al., 2018; Bertinetto et al., 2019), hyperparameter optimisation (Feurer & Hutter, 2019; Shaban et al., 2019), and reinforcement learning (Konda & Tsitsiklis, 2003; Khodadadian et al., 2021)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7881bfdb2b0b914364606cf961885796a101639b",
                "externalIds": {
                    "ArXiv": "2206.06995",
                    "CorpusId": 249642237
                },
                "corpusId": 249642237,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/7881bfdb2b0b914364606cf961885796a101639b",
                "title": "Two-Timescale Stochastic Approximation for Bilevel Optimisation Problems in Continuous-Time Models",
                "abstract": "We analyse the asymptotic properties of a continuous-time, two-timescale stochastic approximation algorithm designed for stochastic bilevel optimisation problems in continuous-time models. We obtain the weak convergence rate of this algorithm in the form of a central limit theorem. We also demonstrate how this algorithm can be applied to several continuous-time bilevel optimisation problems.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1846780885",
                        "name": "Louis Sharrock"
                    }
                ]
            }
        },
        {
            "contexts": [
                "1 Introduction Bilevel optimization provides a framework for solving problems arising from meta learning [33, 2, 29], hyperparameter optimization [26, 8], reinforcement learning[12], etc.",
                "[2] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi.",
                "It aims at minimizing an objective in the upper level under a constraint given by another optimization problem in the lower level, and has been studied intensively in recent years [8, 2, 9, 13, 12, 5].",
                "Due to its great success in solving problems in meta learning [33, 2, 29] and hyperparameter optimization [26, 8], there is a flurry of work proposing and analyzing bilevel optimization algorithms."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "62160b229328843495d02af348e07f80fb73a7a9",
                "externalIds": {
                    "ArXiv": "2206.05670",
                    "CorpusId": 249626492
                },
                "corpusId": 249626492,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/62160b229328843495d02af348e07f80fb73a7a9",
                "title": "Decentralized Bilevel Optimization",
                "abstract": "Bilevel optimization has been successfully applied to many important machine learning problems. Algorithms for solving bilevel optimization have been studied under various settings. In this paper, we study the nonconvex-strongly-convex bilevel optimization under a decentralized setting. We design decentralized algorithms for both deterministic and stochastic bilevel optimization problems. Moreover, we analyze the convergence rates of the proposed algorithms in difference scenarios including the case where data heterogeneity is observed across agents. Numerical experiments on both synthetic and real data demonstrate that the proposed methods are efficient.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2170123588",
                        "name": "Xuxing Chen"
                    },
                    {
                        "authorId": "14252014",
                        "name": "Minhui Huang"
                    },
                    {
                        "authorId": "152273546",
                        "name": "Shiqian Ma"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This case study demonstrates the capability of our tool in boosting performance on a natural image dataset, CIFAR-FS [53].",
                "CIFAR-FS has 12,000 images of 20 unseen classes.",
                "We evaluated the learner and shot selection algorithms with four widely used datasets: mini-ImageNet [50], tieredImageNet [51], MNIST [52], and CIFAR-FS [53].",
                "To demonstrate the generalization of our approach to new tasks, we used the MNIST and CIFAR-FS datasets because there are no base learners pre-trained on them.",
                "For MNIST and CIFAR-FS, we used all the unseen classes (10 and 20, respectively) in the tasks."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "b4da59eeba97310182e66f35a6cb72c4f7e5b8e8",
                "externalIds": {
                    "DBLP": "journals/tvcg/YangYZXXWZPL22",
                    "ArXiv": "2206.04372",
                    "DOI": "10.1109/TVCG.2022.3182488",
                    "CorpusId": 249538583,
                    "PubMed": "35696465"
                },
                "corpusId": 249538583,
                "publicationVenue": {
                    "id": "5e1f6444-5d03-48c7-b202-7f47d492aeae",
                    "name": "IEEE Transactions on Visualization and Computer Graphics",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Vis Comput Graph"
                    ],
                    "issn": "1077-2626",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=2945"
                },
                "url": "https://www.semanticscholar.org/paper/b4da59eeba97310182e66f35a6cb72c4f7e5b8e8",
                "title": "Diagnosing Ensemble Few-Shot Classifiers",
                "abstract": "The base learners and labeled samples (shots) in an ensemble few-shot classifier greatly affect the model performance. When the performance is not satisfactory, it is usually difficult to understand the underlying causes and make improvements. To tackle this issue, we propose a visual analysis method, FSLDiagnotor. Given a set of base learners and a collection of samples with a few shots, we consider two problems: 1) finding a subset of base learners that well predict the sample collections; and 2) replacing the low-quality shots with more representative ones to adequately represent the sample collections. We formulate both problems as sparse subset selection and develop two selection algorithms to recommend appropriate learners and shots, respectively. A matrix visualization and a scatterplot are combined to explain the recommended learners and shots in context and facilitate users in adjusting them. Based on the adjustment, the algorithm updates the recommendation results for another round of improvement. Two case studies are conducted to demonstrate that FSLDiagnotor helps build a few-shot classifier efficiently and increases the accuracy by 12% and 21%, respectively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1604645934",
                        "name": "Weikai Yang"
                    },
                    {
                        "authorId": "50183897",
                        "name": "Xi Ye"
                    },
                    {
                        "authorId": "37409910",
                        "name": "Xingxing Zhang"
                    },
                    {
                        "authorId": "2169956710",
                        "name": "Lanxi Xiao"
                    },
                    {
                        "authorId": "40579032",
                        "name": "Jiazhi Xia"
                    },
                    {
                        "authorId": "2135394423",
                        "name": "Zhongyuan Wang"
                    },
                    {
                        "authorId": "2155220672",
                        "name": "Jun Zhu"
                    },
                    {
                        "authorId": "143758236",
                        "name": "H. Pfister"
                    },
                    {
                        "authorId": "48641970",
                        "name": "Shixia Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2018), GNN (Garcia & Bruna, 2017), R2-D2 (Bertinetto et al., 2018), CC+rot (Gidaris et al.",
                "Regarding baselines, we use the MAML (Finn et al., 2017), Matching Nets (Vinyals et al., 2016), Meta-SGD (Li et al., 2017), MAML++ (Antoniou et al., 2019), Meta-Curvature (MC) (Park & Oliva, 2019), Meta Networks (Munkhdalai & Yu, 2017), Neural Statistician (Edwards & Storkey, 2017), and Memory Mod (Kaiser et al., 2017), Relation Network (Sung et al., 2018), GNN (Garcia & Bruna, 2017), R2-D2 (Bertinetto et al., 2018), CC+rot (Gidaris et al., 2019).",
                "\u2026Meta-Curvature (MC) (Park & Oliva, 2019), Meta Networks (Munkhdalai & Yu, 2017), Neural Statistician (Edwards & Storkey, 2017), and Memory Mod (Kaiser et al., 2017), Relation Network (Sung et al., 2018), GNN (Garcia & Bruna, 2017), R2-D2 (Bertinetto et al., 2018), CC+rot (Gidaris et al., 2019)."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0ed08d48117947da06725dc95dfb7c22d5d3d7e4",
                "externalIds": {
                    "DBLP": "conf/icml/AbbasXCCC22",
                    "ArXiv": "2206.03996",
                    "DOI": "10.48550/arXiv.2206.03996",
                    "CorpusId": 249461664
                },
                "corpusId": 249461664,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0ed08d48117947da06725dc95dfb7c22d5d3d7e4",
                "title": "Sharp-MAML: Sharpness-Aware Model-Agnostic Meta Learning",
                "abstract": "Model-agnostic meta learning (MAML) is currently one of the dominating approaches for few-shot meta-learning. Albeit its effectiveness, the optimization of MAML can be challenging due to the innate bilevel problem structure. Specifically, the loss landscape of MAML is much more complex with possibly more saddle points and local minimizers than its empirical risk minimization counterpart. To address this challenge, we leverage the recently invented sharpness-aware minimization and develop a sharpness-aware MAML approach that we term Sharp-MAML. We empirically demonstrate that Sharp-MAML and its computation-efficient variant can outperform the plain-vanilla MAML baseline (e.g., $+3\\%$ accuracy on Mini-Imagenet). We complement the empirical study with the convergence rate analysis and the generalization bound of Sharp-MAML. To the best of our knowledge, this is the first empirical and theoretical study on sharpness-aware minimization in the context of bilevel learning. The code is available at https://github.com/mominabbass/Sharp-MAML.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2168797364",
                        "name": "Momin Abbas"
                    },
                    {
                        "authorId": "41124384",
                        "name": "Quan-Wu Xiao"
                    },
                    {
                        "authorId": "46307667",
                        "name": "Lisha Chen"
                    },
                    {
                        "authorId": "2158177808",
                        "name": "Pin-Yu Chen"
                    },
                    {
                        "authorId": "2153166785",
                        "name": "Tianyi Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Many prior works have proposed different solutions for the aforementioned meta-overfitting problem, such as using dropout (Bertinetto et al., 2018; Lee et al., 2020), and modifying the loss function (Jamal & Qi, 2019) etc.",
                "(Bertinetto et al., 2018) find that regularization such as dropout can alleviate meta-overfitting and (Yin et al.",
                "(Bertinetto et al., 2018) find that regularization such as dropout can alleviate meta-overfitting and (Yin et al., 2019) propose metaregularization on weights; (Rajendran et al., 2020) introduce an information-theoretic framework of meta-augmentation to make meta-learner generalize to new tasks;\u2026",
                "The results of CIFAR-FS with new baseline ECM (Ravichandran et al., 2019) and PROTO Nets (Snell et al., 2017) are shown in Table 2.",
                "Many prior works have proposed different solutions for the aforementioned meta-overfitting problem (Zintgraf et al., 2019), such as using dropout (Bertinetto et al., 2018; Lee et al., 2020), and modifying the loss function (Jamal & Qi, 2019) etc.",
                "We verify the effectiveness of Eigen-Reptile alleviate overfitting sampling noise on two clean few-shot classification datasets Mini-Imagenet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2018)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "e1c62a1be63ffeab0963301331d00a6c77782bac",
                "externalIds": {
                    "ArXiv": "2206.01944",
                    "DBLP": "journals/corr/abs-2206-01944",
                    "DOI": "10.48550/arXiv.2206.01944",
                    "CorpusId": 249395196
                },
                "corpusId": 249395196,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/e1c62a1be63ffeab0963301331d00a6c77782bac",
                "title": "Robust Meta-learning with Sampling Noise and Label Noise via Eigen-Reptile",
                "abstract": "Recent years have seen a surge of interest in meta-learning techniques for tackling the few-shot learning (FSL) problem. However, the meta-learner is prone to overfitting since there are only a few available samples, which can be identified as sampling noise on a clean dataset. Moreover, when handling the data with noisy labels, the meta-learner could be extremely sensitive to label noise on a corrupted dataset. To address these two challenges, we present Eigen-Reptile (ER) that updates the meta-parameters with the main direction of historical task-specific parameters to alleviate sampling and label noise. Specifically, the main direction is computed in a fast way, where the scale of the calculated matrix is related to the number of gradient steps instead of the number of parameters. Furthermore, to obtain a more accurate main direction for Eigen-Reptile in the presence of many noisy labels, we further propose Introspective Self-paced Learning (ISPL). We have theoretically and experimentally demonstrated the soundness and effectiveness of the proposed Eigen-Reptile and ISPL. Particularly, our experiments on different tasks show that the proposed method is able to outperform or achieve highly competitive performance compared with other gradient-based methods with or without noisy labels. The code and data for the proposed method are provided for research purposes https://github.com/Anfeather/Eigen-Reptile.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2158193358",
                        "name": "Dong Chen"
                    },
                    {
                        "authorId": "3008832",
                        "name": "Lingfei Wu"
                    },
                    {
                        "authorId": "2118071462",
                        "name": "Siliang Tang"
                    },
                    {
                        "authorId": "2168060506",
                        "name": "Xiao Yun"
                    },
                    {
                        "authorId": "2052143728",
                        "name": "Bo Long"
                    },
                    {
                        "authorId": "2125211",
                        "name": "Yueting Zhuang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Similarly, for CIFAR-fs, more than 5\u00d7 reduction in FLOPs is achieved while improving the accuracy by more than 2%.",
                "The efficacy of our method is validated on CIFAR-fs [1] and mini-ImageNet [28] datasets, and we have observed that our approach can provide improvements in model accuracy of up to 2% on standard meta-learning benchmark, while reducing the model size by more than 75%.",
                "This translates to 15504 test tasks for both CIFAR-fs and mini-ImageNet (C = 20, N = 5).",
                "Learning task-specific compressed metamodels\nWe discuss here the results of task-specific pruning obtained using METADOCK on standard 4-Conv models with 64 and 128 channels for CIFAR-fs 5-way 1-shot and 5-way 5-shot settings.",
                "The former attains an average meta-test accuracy score of 70.15% on CIFARfs 5-way 1-shot (Table 3), while the latter scores 67.25%, thus increasing the performance by an absolute margin of 2.9%.",
                "We study the performance of METADOCK on standard 4-conv models trained on mini-ImageNet [28] and CIFARfs [1] datasets for several different choices of pruning budget.",
                "Figure 4 shows parameters vs. accuracy plot for CIFAR-fs and mini-ImageNet datasets on 5-way, 5-shot setting with 4-Conv-128 model.",
                "The results for continuous scheme as well as our approach on CIFAR-fs, 5-way, 5-shot are shown in Table 1.",
                "After a threshold parameter count, performance starts to drop for both CIFAR-fs and mini-ImageNet but the extent of compression achieved before that point is already significant.",
                "Similarly, Figure 5 shows FLOPs vs. accuracy plot for CIFAR-fs and mini-ImageNet dataset on 5-way, 5-shot setting with 4-Conv-128 model.",
                "Similar to CIFAR-fs, performance gains of up to 2% in accuracy are observed for this dataset as well."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "6c4d52b62b1117630477b8f03b26010740d3c6db",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-01690",
                    "ArXiv": "2206.01690",
                    "DOI": "10.1109/CVPR52688.2022.00962",
                    "CorpusId": 249375510
                },
                "corpusId": 249375510,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6c4d52b62b1117630477b8f03b26010740d3c6db",
                "title": "Dynamic Kernel Selection for Improved Generalization and Memory Efficiency in Meta-learning",
                "abstract": "Gradient based meta-learning methods are prone to overfit on the meta-training set, and this behaviour is more prominent with large and complex networks. Moreover, large networks restrict the application of meta-learning models on low-power edge devices. While choosing smaller networks avoid these issues to a certain extent, it affects the overall generalization leading to reduced performance. Clearly, there is an approximately optimal choice of network architecture that is best suited for every meta-learning problem, however, identifying it beforehand is not straight-forward. In this paper, we present Metadock, a task-specific dynamic kernel selection strategy for designing compressed CNN models that generalize well on unseen tasks in meta-learning. Our method is based on the hypothesis that for a given set of similar tasks, not all kernels of the network are needed by each individual task. Rather, each task uses only a fraction of the kernels, and the selection of the kernels per task can be learnt dynamically as a part of the inner update steps. Metadockcompresses the meta-model as well as the task-specific inner models, thus providing significant reduction in model size for each task, and through constraining the number of active kernels for every task, it implicitly mitigates the issue of meta-overfitting. We show that for the same inference budget, pruned versions of large CNN models obtained using our approach consistently outperform the conventional choices of CNN models. Metadock couples well with popular meta-learning approaches such as iMAML [22]. The efficacy of our method is validated on CIFAR-fs [1] and mini-ImageNet [28] datasets, and we have observed that our approach can provide improvements in model accuracy of up to 2% on standard meta-learning benchmark, while reducing the model size by more than 75%. Our code is available at https://github.com/transmuteAI/MetaDOCK.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1585915155",
                        "name": "Arnav Chavan"
                    },
                    {
                        "authorId": "2119293525",
                        "name": "Rishabh Tiwari"
                    },
                    {
                        "authorId": "1574190084",
                        "name": "Udbhav Bamba"
                    },
                    {
                        "authorId": "144775871",
                        "name": "D. Gupta"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Furthermore, our method also outperforms all previous works by at least 8.6% on PGD adversarial examples for 1-shot classification on CIFAR-FS with ResNet12.",
                "We present our experimental results on two standard benchmarks: miniImageNet [30] in Table 1 and CIFARFS [1] in Table 2.",
                "To fully evaluate the effectiveness of our methods, we conduct extensive experiments on two standard few-shot classification benchmarks: miniImageNet [30] and CIFARFS [1].",
                "The cross-domain transfer experiment is implemented between miniImageNet [30] and CIFAR-FS [1] bilaterally as shown as Table 5.",
                "CIFAR-FS [1] has the same dataset splitting of 64, 16, 20 classes for training, validation and testing respectively.",
                "To comprehensively evaluate our methods, we adopt the widely-used few-shot benchmark datasets miniImageNet [30] and CIFAR-FS [1]."
            ],
            "intents": [
                "methodology",
                "result"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "aaf8e22481339bff1db8461cf4eacb242ea5957d",
                "externalIds": {
                    "DBLP": "conf/cvpr/DongWLX22",
                    "DOI": "10.1109/CVPR52688.2022.00882",
                    "CorpusId": 250520614
                },
                "corpusId": 250520614,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/aaf8e22481339bff1db8461cf4eacb242ea5957d",
                "title": "Improving Adversarially Robust Few-shot Image Classification with Generalizable Representations",
                "abstract": "Few-Shot Image Classification (FSIC) aims to recognize novel image classes with limited data, which is significant in practice. In this paper, we consider the FSIC problem in the case of adversarial examples. This is an extremely challenging issue because current deep learning methods are still vulnerable when handling adversarial examples, even with massive labeled training samples. For this problem, existing works focus on training a network in the meta-learning fashion that depends on numerous sampled few-shot tasks. In comparison, we propose a simple but effective baseline through directly learning generalizable representations without tedious task sampling, which is robust to unforeseen adversarial FSIC tasks. Specifically, we introduce an adversarial-aware mechanism to establish auxiliary supervision via feature-level differences between legitimate and adversarial examples. Furthermore, we design a novel adversarial-reweighted training manner to alleviate the imbalance among adversarial examples. The feature purifier is also employed as post-processing for adversarial features. Moreover, our method can obtain generalizable representations to remain superior transferability, even facing cross-domain adversarial examples. Extensive experiments show that our method can significantly outperform state-of-the-art adversarially robust FSIC methods on two standard benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Junhao Dong"
                    },
                    {
                        "authorId": "2163691024",
                        "name": "Yuan Wang"
                    },
                    {
                        "authorId": "2151605931",
                        "name": "Jianhuang Lai"
                    },
                    {
                        "authorId": "46397019",
                        "name": "Xiaohua Xie"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "43f53345753218bc1c8265e3a568315c2afb647f",
                "externalIds": {
                    "ArXiv": "2206.00694",
                    "DBLP": "journals/corr/abs-2206-00694",
                    "DOI": "10.48550/arXiv.2206.00694",
                    "CorpusId": 249282374
                },
                "corpusId": 249282374,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/43f53345753218bc1c8265e3a568315c2afb647f",
                "title": "Meta-SysId: A Meta-Learning Approach for Simultaneous Identification and Prediction",
                "abstract": "In this paper, we propose Meta-SysId, a meta-learning approach to model sets of systems that have behavior governed by common but unknown laws and that differentiate themselves by their context. Inspired by classical modeling-and-identification approaches, Meta-SysId learns to represent the common law through shared parameters and relies on online optimization to compute system-specific context. Compared to optimization-based meta-learning methods, the separation between class parameters and context variables reduces the computational burden while allowing batch computations and a simple training scheme. We test Meta-SysId on polynomial regression, time-series prediction, model-based control, and real-world traffic prediction domains, empirically finding it outperforms or is competitive with meta-learning baselines.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1491104517",
                        "name": "Junyoung Park"
                    },
                    {
                        "authorId": "2133376851",
                        "name": "Federico Berto"
                    },
                    {
                        "authorId": "103218070",
                        "name": "Arec L. Jamgochian"
                    },
                    {
                        "authorId": "79262652",
                        "name": "Mykel J. Kochenderfer"
                    },
                    {
                        "authorId": "2085587",
                        "name": "Jinkyoo Park"
                    }
                ]
            }
        },
        {
            "contexts": [
                "regression [3,38] is used as a classifier and trained on the support set, and the regularized squared loss is minimized by Equation (12):"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c6907b7ca5626010ed28afe44485c5186487cb55",
                "externalIds": {
                    "DBLP": "journals/sensors/WangWCZ22",
                    "PubMedCentral": "9229404",
                    "DOI": "10.3390/s22124420",
                    "CorpusId": 249652223,
                    "PubMed": "35746202"
                },
                "corpusId": 249652223,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c6907b7ca5626010ed28afe44485c5186487cb55",
                "title": "Few-Shot Text Classification with Global\u2013Local Feature Information",
                "abstract": "Meta-learning frameworks have been proposed to generalize machine learning models for domain adaptation without sufficient label data in computer vision. However, text classification with meta-learning is less investigated. In this paper, we propose SumFS to find global top-ranked sentences by extractive summary and improve the local vocabulary category features. The SumFS consists of three modules: (1) an unsupervised text summarizer that removes redundant information; (2) a weighting generator that associates feature words with attention scores to weight the lexical representations of words; (3) a regular meta-learning framework that trains with limited labeled data using a ridge regression classifier. In addition, a marine news dataset was established with limited label data. The performance of the algorithm was tested on THUCnews, Fudan, and marine news datasets. Experiments show that the SumFS can maintain or even improve accuracy while reducing input features. Moreover, the training time of each epoch is reduced by more than 50%.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2118962551",
                        "name": "Depei Wang"
                    },
                    {
                        "authorId": "2108369912",
                        "name": "Zhuowei Wang"
                    },
                    {
                        "authorId": "39681786",
                        "name": "Lianglun Cheng"
                    },
                    {
                        "authorId": "2108478081",
                        "name": "Weiwen Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We construct a large-scale benchmark and collect 10 datasets with varying degree of similarity and difficulty, with default domain arrival order of Quickdraw [31], AIRCRAFT [45], CUB [77], Miniimagenet [70], Omniglot [35], Plantae [28], Electronic from Logo-2K+ [73], CIFARFS [10], Fungi [62], Necessities from Logo-2K+ [73]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "35653f7ffb9e28d18fa36562220baa91a9fb5e8d",
                "externalIds": {
                    "DBLP": "conf/cvpr/WangSDZFG22",
                    "DOI": "10.1109/CVPR52688.2022.00782",
                    "CorpusId": 250015700
                },
                "corpusId": 250015700,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/35653f7ffb9e28d18fa36562220baa91a9fb5e8d",
                "title": "Learning to Learn and Remember Super Long Multi-Domain Task Sequence",
                "abstract": "Catastrophic forgetting (CF) frequently occurs when learning with non-stationary data distribution. The CF issue remains nearly unexplored and is more challenging when meta-learning on a sequence of domains (datasets), called sequential domain meta-learning (SDML). In this work, we propose a simple yet effective learning to learn approach, i.e., meta optimizer, to mitigate the CF problem in SDML. We first apply the proposed meta optimizer to the simplified setting of SDML, domain-aware meta-learning, where the domain labels and boundaries are known during the learning process. We propose dynamically freezing the network and incorporating it with the proposed meta optimizer by considering the domain nature during meta training. In addition, we extend the meta optimizer to the more general setting of SDML, domain-agnostic meta-learning, where domain labels and boundaries are unknown during the learning process. We propose a domain shift detection technique to capture latent domain change and equip the meta optimizer with it to work in this setting. The proposed meta optimizer is versatile and can be easily integrated with several existing meta-learning algorithms. Finally, we construct a challenging and large-scale benchmark consisting of 10 heterogeneous domains with a super long task sequence consisting of 100K tasks. We perform extensive experiments on the proposed benchmark for both settings and demonstrate the effectiveness of our proposed method, outperforming current strong baselines by a large margin.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2920297",
                        "name": "Zhenyi Wang"
                    },
                    {
                        "authorId": "2172820082",
                        "name": "Li Shen"
                    },
                    {
                        "authorId": "3449409",
                        "name": "Tiehang Duan"
                    },
                    {
                        "authorId": "70100145",
                        "name": "Donglin Zhan"
                    },
                    {
                        "authorId": "2153679931",
                        "name": "Le Fang"
                    },
                    {
                        "authorId": "50987693",
                        "name": "Mingchen Gao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We use the following small-scale datasets for meta-learning with MLPs: Omniglot [26, 52], CIFARFS [7], VGG-Flower [37, 27] and Aircraft [33, 27]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f884682e5f4b5d41e6b7f97261075527bb8f9b25",
                "externalIds": {
                    "DBLP": "conf/nips/ChijiwaYKI22",
                    "ArXiv": "2205.15619",
                    "DOI": "10.48550/arXiv.2205.15619",
                    "CorpusId": 249209848
                },
                "corpusId": 249209848,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/f884682e5f4b5d41e6b7f97261075527bb8f9b25",
                "title": "Meta-ticket: Finding optimal subnetworks for few-shot learning within randomly initialized neural networks",
                "abstract": "Few-shot learning for neural networks (NNs) is an important problem that aims to train NNs with a few data. The main challenge is how to avoid overfitting since over-parameterized NNs can easily overfit to such small dataset. Previous work (e.g. MAML by Finn et al. 2017) tackles this challenge by meta-learning, which learns how to learn from a few data by using various tasks. On the other hand, one conventional approach to avoid overfitting is restricting hypothesis spaces by endowing sparse NN structures like convolution layers in computer vision. However, although such manually-designed sparse structures are sample-efficient for sufficiently large datasets, they are still insufficient for few-shot learning. Then the following questions naturally arise: (1) Can we find sparse structures effective for few-shot learning by meta-learning? (2) What benefits will it bring in terms of meta-generalization? In this work, we propose a novel meta-learning approach, called Meta-ticket, to find optimal sparse subnetworks for few-shot learning within randomly initialized NNs. We empirically validated that Meta-ticket successfully discover sparse subnetworks that can learn specialized features for each given task. Due to this task-wise adaptation ability, Meta-ticket achieves superior meta-generalization compared to MAML-based methods especially with large NNs. The code is available at: https://github.com/dchiji-ntt/meta-ticket",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2113252066",
                        "name": "Daiki Chijiwa"
                    },
                    {
                        "authorId": "36351779",
                        "name": "Shin'ya Yamaguchi"
                    },
                    {
                        "authorId": "3370561",
                        "name": "Atsutoshi Kumagai"
                    },
                    {
                        "authorId": "1719865",
                        "name": "Yasutoshi Ida"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7fbcc729f5ed2e3c36d56a3f207c3316d5e93e73",
                "externalIds": {
                    "ArXiv": "2205.15745",
                    "DBLP": "journals/corr/abs-2205-15745",
                    "DOI": "10.48550/arXiv.2205.15745",
                    "CorpusId": 249209580
                },
                "corpusId": 249209580,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7fbcc729f5ed2e3c36d56a3f207c3316d5e93e73",
                "title": "HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks",
                "abstract": "The aim of Few-Shot learning methods is to train models which can easily adapt to previously unseen tasks, based on small amounts of data. One of the most popular and elegant Few-Shot learning approaches is Model-Agnostic Meta-Learning (MAML). The main idea behind this method is to learn the general weights of the meta-model, which are further adapted to specific problems in a small number of gradient steps. However, the model's main limitation lies in the fact that the update procedure is realized by gradient-based optimisation. In consequence, MAML cannot always modify weights to the essential level in one or even a few gradient iterations. On the other hand, using many gradient steps results in a complex and time-consuming optimization procedure, which is hard to train in practice, and may lead to overfitting. In this paper, we propose HyperMAML, a novel generalization of MAML, where the training of the update procedure is also part of the model. Namely, in HyperMAML, instead of updating the weights with gradient descent, we use for this purpose a trainable Hypernetwork. Consequently, in this framework, the model can generate significant updates whose range is not limited to a fixed number of gradient steps. Experiments show that HyperMAML consistently outperforms MAML and performs comparably to other state-of-the-art techniques in a number of standard Few-Shot learning benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "147572870",
                        "name": "Marcin Przewiezlikowski"
                    },
                    {
                        "authorId": "2516192",
                        "name": "P. Przybysz"
                    },
                    {
                        "authorId": "145541197",
                        "name": "J. Tabor"
                    },
                    {
                        "authorId": "3027512",
                        "name": "Maciej Zi\u0229ba"
                    },
                    {
                        "authorId": "1790922",
                        "name": "P. Spurek"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Some works focused on the role of label122 and attribute semantics as additional information to facilitate few-shot learning [10, 60, 80].123\nAll the above discussed few-shot methods focused on the standard setting where the base classes124 and novel classes are from the same domain, and are evaluated on natural images using the current125 standard benchmarks for few-shot classification: Omniglot [36], CUB [75], miniImageNet [74],126 tieredImageNet [55] and CIFAR-FS [3].",
                "All the above discussed few-shot methods focused on the standard setting where the base classes and novel classes are from the same domain, and are evaluated on natural images using the current standard benchmarks for few-shot classification: Omniglot [40], CUB [79], miniImageNet [78], tieredImageNet [59] and CIFAR-FS [5]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "00a44bec8a36948d6f51365e6457eb2affd7a221",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-00092",
                    "ArXiv": "2206.00092",
                    "DOI": "10.48550/arXiv.2206.00092",
                    "CorpusId": 237235583
                },
                "corpusId": 237235583,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/00a44bec8a36948d6f51365e6457eb2affd7a221",
                "title": "FHIST: A Benchmark for Few-shot Classification of Histological Images",
                "abstract": "Few-shot learning has recently attracted wide interest in image classification, but almost all the current public benchmarks are focused on natural images. The few-shot paradigm is highly relevant in medical-imaging applications due to the scarcity of labeled data, as annotations are expensive and require specialized expertise. However, in medical imaging, few-shot learning research is sparse, limited to private data sets and is at its early stage. In particular, the few-shot setting is of high interest in histology due to the diversity and fine granularity of cancer related tissue classification tasks, and the variety of data-preparation techniques. This paper introduces a highly diversified public benchmark, gathered from various public datasets, for few-shot histology data classification. We build few-shot tasks and base-training data with various tissue types, different levels of domain shifts stemming from various cancer sites, and different class-granularity levels, thereby reflecting realistic scenarios. We evaluate the performances of state-of-the-art few-shot learning methods on our benchmark, and observe that simple fine-tuning and regularization methods achieve better results than the popular meta-learning and episodic-training paradigm. Furthermore, we introduce three scenarios based on the domain shifts between the source and target histology data: near-domain, middle-domain and out-domain. Our experiments display the potential of few-shot learning in histology classification, with state-of-art few shot learning methods approaching the supervised-learning baselines in the near-domain setting. In our out-domain setting, for 5-way 5-shot, the best performing method reaches 60% accuracy. We believe that our work could help in building realistic evaluations and fair comparisons of few-shot learning methods and will further encourage research in the few-shot paradigm.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2167317069",
                        "name": "Fereshteh Shakeri"
                    },
                    {
                        "authorId": "1583144397",
                        "name": "Malik Boudiaf"
                    },
                    {
                        "authorId": "119879914",
                        "name": "S. Mohammadi"
                    },
                    {
                        "authorId": "2086069040",
                        "name": "Ivaxi Sheth"
                    },
                    {
                        "authorId": "2203743",
                        "name": "Mohammad Havaei"
                    },
                    {
                        "authorId": "144019647",
                        "name": "Ismail Ben Ayed"
                    },
                    {
                        "authorId": "3127597",
                        "name": "S. Kahou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Bilevel optimization has attracted significant attention recently due to its popularity in a variety of machine learning applications including meta-learning [9, 1, 34, 17], hyperparameter optimization [9, 35, 5], reinforcement learning [22, 15], and signal processing [23, 7]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1d6da3878aeec164d56414c4a1a899342f139fe7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-14224",
                    "ArXiv": "2205.14224",
                    "DOI": "10.48550/arXiv.2205.14224",
                    "CorpusId": 249191673
                },
                "corpusId": 249191673,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/1d6da3878aeec164d56414c4a1a899342f139fe7",
                "title": "Will Bilevel Optimizers Benefit from Loops",
                "abstract": "Bilevel optimization has arisen as a powerful tool for solving a variety of machine learning problems. Two current popular bilevel optimizers AID-BiO and ITD-BiO naturally involve solving one or two sub-problems, and consequently, whether we solve these problems with loops (that take many iterations) or without loops (that take only a few iterations) can significantly affect the overall computational efficiency. Existing studies in the literature cover only some of those implementation choices, and the complexity bounds available are not refined enough to enable rigorous comparison among different implementations. In this paper, we first establish unified convergence analysis for both AID-BiO and ITD-BiO that are applicable to all implementation choices of loops. We then specialize our results to characterize the computational complexity for all implementations, which enable an explicit comparison among them. Our result indicates that for AID-BiO, the loop for estimating the optimal point of the inner function is beneficial for overall efficiency, although it causes higher complexity for each update step, and the loop for approximating the outer-level Hessian-inverse-vector product reduces the gradient complexity. For ITD-BiO, the two loops always coexist, and our convergence upper and lower bounds show that such loops are necessary to guarantee a vanishing convergence error, whereas the no-loop scheme suffers from an unavoidable non-vanishing convergence error. Our numerical experiments further corroborate our theoretical results.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "14697929",
                        "name": "Mingrui Liu"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    },
                    {
                        "authorId": "2167030792",
                        "name": "Lei Ying"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Four benchmark datasets are used to evaluate the model performance (miniImageNet [4], CUB-200-2011 [17], tieredImageNet [18] and CIFAR-FS [19])."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "cb86737b1a8de5bf680eb81f29f66a73e6fafa6b",
                "externalIds": {
                    "DBLP": "conf/icassp/ZhangHW22",
                    "DOI": "10.1109/icassp43922.2022.9747620",
                    "CorpusId": 249436528
                },
                "corpusId": 249436528,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/cb86737b1a8de5bf680eb81f29f66a73e6fafa6b",
                "title": "Domain Generalized Few-Shot Image Classification via Meta Regularization Network",
                "abstract": "In few-shot image classification scenarios, meta-learning methods aim to learn transferable feature representations extracted from seen domains (base classes) in the meta-training phase and quickly adapt to unseen domains (novel classes) in the meta-testing phase. However, when seen and unseen domains have a large discrepancy, existing approaches do not perform well due to the incapability of generalizing to unseen domains. In this paper, we investigate the challenging domain generalized few-shot image classification problem. We design an Meta Regularization Network (MRN) to learn a domain-invariant discriminative feature space, where a learning to learn update strategy is used to simulate domain shifts caused by seen and unseen domains. The simulation trains the model to learn to reorganize the feature knowledge acquired from seen domains to represent unseen domains. Extensive experiments and analysis show that our proposed MRN can significantly improve the generalization ability of various meta-learning methods to achieve state-of-the-art performance in domain generalized few-shot learning.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2157502742",
                        "name": "Min Zhang"
                    },
                    {
                        "authorId": "122132048",
                        "name": "Siteng Huang"
                    },
                    {
                        "authorId": "2111224425",
                        "name": "Donglin Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1a40acafcf3b46ea94fbcb461d0286163c955810",
                "externalIds": {
                    "DOI": "10.1109/ISCV54655.2022.9806100",
                    "CorpusId": 250119521
                },
                "corpusId": 250119521,
                "publicationVenue": {
                    "id": "1d8d1e5b-972b-4809-bf00-64e9da59fdb2",
                    "name": "International Symposium on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ISCV",
                        "Int Symp Comput Vis"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1a40acafcf3b46ea94fbcb461d0286163c955810",
                "title": "Intelligent Document Processing with Small and Relevant Training Dataset",
                "abstract": "Nowadays, companies deploy complex mechanisms to automate data collection, storage, and processing. Some of this data is unstructured and contained in pdf or scanned documents. Supervised object detection models exist to address the problem such as Faster-RCNN, but require retraining for each new use case. Annotation is a tedious and repetitive task done regularly when new document templates arrive. We present in this paper a method based on a Triplet-loss architecture to select a small and relevant subset of unstructured documents to annotate. To evaluate the method, we trained a model with many datasets. We compared the performance with different choices of document templates and dataset sizes. We show that a relevant and automated choice of document examples can avoid a huge annotation effort.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2120185721",
                        "name": "Lina Nicolaieff"
                    },
                    {
                        "authorId": "51040018",
                        "name": "Mohamed Mehdi Kandi"
                    },
                    {
                        "authorId": "2067340354",
                        "name": "Younes Zegaoui"
                    },
                    {
                        "authorId": "1806439",
                        "name": "C. Bortolaso"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2563ab592a4f82887e231426b52ecb66704c5867",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-08157",
                    "ArXiv": "2205.08157",
                    "DOI": "10.1109/ICME52920.2022.9859887",
                    "CorpusId": 248834448
                },
                "corpusId": 248834448,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2563ab592a4f82887e231426b52ecb66704c5867",
                "title": "Uncertainty-Based Network for Few-Shot Image Classification",
                "abstract": "The transductive inference is an effective technique in the few-shot learning task, where query sets update prototypes to improve themselves. However, these methods optimize the model by considering only the classification scores of the query instances as confidence while ignoring the uncertainty of these classification scores. In this paper, we propose a novel method called Uncertainty-Based Network, which models the uncertainty of classification results with the help of mutual information. Specifically, we first data augment and classify the query instance and calculate the mutual information of these classification scores. Then, mutual information is used as uncertainty to assign weights to classification scores, and the iterative update strategy based on classification scores and uncertainties assigns the optimal weights to query instances in prototype optimization. Extensive results on four benchmarks show that Uncertainty-Based Network achieves comparable performance in classification accuracy compared to state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1382297688",
                        "name": "Minglei Yuan"
                    },
                    {
                        "authorId": "2149106499",
                        "name": "Qian Xu"
                    },
                    {
                        "authorId": "2089156465",
                        "name": "Chunhao Cai"
                    },
                    {
                        "authorId": "1391155455",
                        "name": "Yin-Dong Zheng"
                    },
                    {
                        "authorId": "2156631133",
                        "name": "Tao Wang"
                    },
                    {
                        "authorId": "2113488744",
                        "name": "Tong Lu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Benchmarks The most simple few-shot classification benchmarks are built respectively on the basic image recognition dataset CIFAR100 [3] and Omniglot [14], which is a dataset of handwritten characters."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "17882de237840d56a5e3aef99890342e19412017",
                "externalIds": {
                    "DBLP": "conf/cvpr/BennequinTTH22",
                    "ArXiv": "2205.05155",
                    "DOI": "10.1109/CVPRW56347.2022.00523",
                    "CorpusId": 248693113
                },
                "corpusId": 248693113,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/17882de237840d56a5e3aef99890342e19412017",
                "title": "Few-Shot Image Classification Benchmarks are Too Far From Reality: Build Back Better with Semantic Task Sampling",
                "abstract": "Every day, a new method is published to tackle Few-Shot Image Classification, showing better and better performances on academic benchmarks. Nevertheless, we observe that these current benchmarks do not accurately represent the real industrial use cases that we encountered. In this work, through both qualitative and quantitative studies, we expose that the widely used benchmark tieredImageNet is strongly biased towards tasks composed of very semantically dissimilar classes e.g. bathtub, cabbage, pizza, schipperke, and cardoon. This makes tieredImageNet (and similar benchmarks) irrelevant to evaluate the ability of a model to solve real-life use cases usually involving more fine-grained classification. We mitigate this bias using semantic information about the classes of tieredImageNet and generate an improved, balanced benchmark. Going further, we also introduce a new benchmark for Few-Shot Image Classification using the Danish Fungi 2020 dataset. This benchmark proposes a wide variety of evaluation tasks with various fine-graininess. Moreover, this benchmark includes many-way tasks (e.g. composed of 100 classes), which is a challenging setting yet very common in industrial applications. Our experiments bring out the correlation between the difficulty of a task and the semantic similarity between its classes, as well as a heavy performance drop of state-of-the-art methods on many-way few-shot classification, raising questions about the scaling abilities of these methods. We hope that our work will encourage the community to further question the quality of standard evaluation processes and their relevance to real-life applications.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1388055677",
                        "name": "Etienne Bennequin"
                    },
                    {
                        "authorId": "30784787",
                        "name": "Myriam Tami"
                    },
                    {
                        "authorId": "3326099",
                        "name": "Antoine Toubhans"
                    },
                    {
                        "authorId": "1931593",
                        "name": "C. Hudelot"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026can be the weights of a neural network that acts as a feature extractor that will help a task-specific classifier or regressor parameterized by the base parameters to solve the task at hand (Raghu, Raghu, Bengio, & Vinyals, 2020; Lee, Maji, Ravichandran, & Soatto, 2019; Bertinetto et al., 2019).",
                "task-shared outer parameters can be the weights of a neural network that acts as a feature extractor that will help a task-specific classifier or regressor parameterized by the base parameters to solve the task at hand (Raghu, Raghu, Bengio, & Vinyals, 2020; Lee, Maji, Ravichandran, & Soatto, 2019; Bertinetto et al., 2019)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "04cf6ddc33322226fd0e28c522676b1acb0698d6",
                "externalIds": {
                    "ArXiv": "2205.03076",
                    "DBLP": "journals/neco/ZucchetS22",
                    "DOI": "10.1162/neco_a_01547",
                    "CorpusId": 252876691,
                    "PubMed": "36283053"
                },
                "corpusId": 252876691,
                "publicationVenue": {
                    "id": "69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                    "name": "Neural Computation",
                    "type": "journal",
                    "alternate_names": [
                        "Neural Comput"
                    ],
                    "issn": "0899-7667",
                    "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6720226",
                        "http://www.mitpressjournals.org/loi/neco",
                        "https://www.mitpressjournals.org/loi/neco"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/04cf6ddc33322226fd0e28c522676b1acb0698d6",
                "title": "Beyond Backpropagation: Bilevel Optimization Through Implicit Differentiation and Equilibrium Propagation",
                "abstract": "Abstract This review examines gradient-based techniques to solve bilevel optimization problems. Bilevel optimization extends the loss minimization framework underlying statistical learning to systems that are implicitly defined through a quantity they minimize. This characterization can be applied to neural networks, optimizers, algorithmic solvers, and even physical systems and allows for greater modeling flexibility compared to the usual explicit definition of such systems. We focus on solving learning problems of this kind through gradient descent, leveraging the toolbox of implicit differentiation and, for the first time applied to this setting, the equilibrium propagation theorem. We present the mathematical foundations behind such methods, introduce the gradient estimation algorithms in detail, and compare the competitive advantages of the different approaches.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1729494470",
                        "name": "Nicolas Zucchet"
                    },
                    {
                        "authorId": "3105061",
                        "name": "J. Sacramento"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Instead, many machine learning tasks \u2013 such as adversarial learning, meta learning (Franceschi et al., 2018; Bertinetto et al., 2018), hyperparameter optimization (Franceschi et al., 2018; Feurer & Hutter, 2019), reinforcement/imitation learning (Arora et al., 2020; Hong et al., 2020), and neural\u2026",
                "Instead, many machine learning tasks \u2013 such as adversarial learning, meta learning (Franceschi et al., 2018; Bertinetto et al., 2018), hyperparameter optimization (Franceschi et al."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "00a59eecd0efb93694f53b12302791f5f57af29b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-02215",
                    "ArXiv": "2205.02215",
                    "DOI": "10.48550/arXiv.2205.02215",
                    "CorpusId": 248512522
                },
                "corpusId": 248512522,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/00a59eecd0efb93694f53b12302791f5f57af29b",
                "title": "FEDNEST: Federated Bilevel, Minimax, and Compositional Optimization",
                "abstract": "Standard federated optimization methods successfully apply to stochastic problems with single-level structure. However, many contemporary ML problems -- including adversarial robustness, hyperparameter tuning, and actor-critic -- fall under nested bilevel programming that subsumes minimax and compositional optimization. In this work, we propose \\fedblo: A federated alternating stochastic gradient method to address general nested problems. We establish provable convergence rates for \\fedblo in the presence of heterogeneous data and introduce variations for bilevel, minimax, and compositional optimization. \\fedblo introduces multiple innovations including federated hypergradient computation and variance reduction to address inner-level heterogeneity. We complement our theory with experiments on hyperparameter \\&hyper-representation learning and minimax optimization that demonstrate the benefits of our method in practice. Code is available at https://github.com/ucr-optml/FedNest.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3281605",
                        "name": "Davoud Ataee Tarzanagh"
                    },
                    {
                        "authorId": "47629178",
                        "name": "Mingchen Li"
                    },
                    {
                        "authorId": "2751682",
                        "name": "Christos Thrampoulidis"
                    },
                    {
                        "authorId": "3103394",
                        "name": "Samet Oymak"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1c6cf95048d0f9840c16f4a24f0f98d2e92847a8",
                "externalIds": {
                    "DBLP": "journals/prl/WangLLL22",
                    "DOI": "10.1016/j.patrec.2022.05.013",
                    "CorpusId": 248806318
                },
                "corpusId": 248806318,
                "publicationVenue": {
                    "id": "f35e3e87-9df4-497b-aa0d-bb8584197290",
                    "name": "Pattern Recognition Letters",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit Lett"
                    ],
                    "issn": "0167-8655",
                    "url": "https://www.journals.elsevier.com/pattern-recognition-letters/",
                    "alternate_urls": [
                        "http://www.journals.elsevier.com/pattern-recognition-letters/",
                        "http://www.sciencedirect.com/science/journal/01678655"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1c6cf95048d0f9840c16f4a24f0f98d2e92847a8",
                "title": "A transductive learning method to leverage graph structure for few-shot learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108838032",
                        "name": "Yaning Wang"
                    },
                    {
                        "authorId": "2145254454",
                        "name": "Zijian Liu"
                    },
                    {
                        "authorId": "2112602110",
                        "name": "Yang Luo"
                    },
                    {
                        "authorId": "37603348",
                        "name": "Chunbo Luo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In this paper, we take inspiration from the in-context [11] few-shot learning technique instead of more involved few-shot learning approaches based on metric learning [24, 103, 112, 117] or meta-learning [6, 7, 27, 31, 91, 155]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3",
                "externalIds": {
                    "DBLP": "conf/nips/AlayracDLMBHLMM22",
                    "ArXiv": "2204.14198",
                    "CorpusId": 248476411
                },
                "corpusId": 248476411,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/26218bdcc3945c7edae7aa2adbfba4cd820a2df3",
                "title": "Flamingo: a Visual Language Model for Few-Shot Learning",
                "abstract": "Building models that can be rapidly adapted to novel tasks using only a handful of annotated examples is an open challenge for multimodal machine learning research. We introduce Flamingo, a family of Visual Language Models (VLM) with this ability. We propose key architectural innovations to: (i) bridge powerful pretrained vision-only and language-only models, (ii) handle sequences of arbitrarily interleaved visual and textual data, and (iii) seamlessly ingest images or videos as inputs. Thanks to their flexibility, Flamingo models can be trained on large-scale multimodal web corpora containing arbitrarily interleaved text and images, which is key to endow them with in-context few-shot learning capabilities. We perform a thorough evaluation of our models, exploring and measuring their ability to rapidly adapt to a variety of image and video tasks. These include open-ended tasks such as visual question-answering, where the model is prompted with a question which it has to answer; captioning tasks, which evaluate the ability to describe a scene or an event; and close-ended tasks such as multiple-choice visual question-answering. For tasks lying anywhere on this spectrum, a single Flamingo model can achieve a new state of the art with few-shot learning, simply by prompting the model with task-specific examples. On numerous benchmarks, Flamingo outperforms models fine-tuned on thousands of times more task-specific data.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2285263",
                        "name": "Jean-Baptiste Alayrac"
                    },
                    {
                        "authorId": "7408951",
                        "name": "Jeff Donahue"
                    },
                    {
                        "authorId": "152831141",
                        "name": "Pauline Luc"
                    },
                    {
                        "authorId": "19200186",
                        "name": "Antoine Miech"
                    },
                    {
                        "authorId": "2159207795",
                        "name": "Iain Barr"
                    },
                    {
                        "authorId": "66535271",
                        "name": "Yana Hasson"
                    },
                    {
                        "authorId": "3257286",
                        "name": "Karel Lenc"
                    },
                    {
                        "authorId": "1697879",
                        "name": "A. Mensch"
                    },
                    {
                        "authorId": "2143434227",
                        "name": "Katie Millican"
                    },
                    {
                        "authorId": "47447264",
                        "name": "Malcolm Reynolds"
                    },
                    {
                        "authorId": "81387328",
                        "name": "Roman Ring"
                    },
                    {
                        "authorId": "2143538252",
                        "name": "Eliza Rutherford"
                    },
                    {
                        "authorId": "12159303",
                        "name": "Serkan Cabi"
                    },
                    {
                        "authorId": "22237490",
                        "name": "Tengda Han"
                    },
                    {
                        "authorId": "48398849",
                        "name": "Zhitao Gong"
                    },
                    {
                        "authorId": "2412073",
                        "name": "Sina Samangooei"
                    },
                    {
                        "authorId": "49601928",
                        "name": "Marianne Monteiro"
                    },
                    {
                        "authorId": "10698483",
                        "name": "Jacob Menick"
                    },
                    {
                        "authorId": "148016269",
                        "name": "Sebastian Borgeaud"
                    },
                    {
                        "authorId": "2065040422",
                        "name": "Andy Brock"
                    },
                    {
                        "authorId": "3208081",
                        "name": "Aida Nematzadeh"
                    },
                    {
                        "authorId": "7782886",
                        "name": "Sahand Sharifzadeh"
                    },
                    {
                        "authorId": "9961753",
                        "name": "Mikolaj Binkowski"
                    },
                    {
                        "authorId": "2026369796",
                        "name": "Ricardo Barreira"
                    },
                    {
                        "authorId": "1689108",
                        "name": "Oriol Vinyals"
                    },
                    {
                        "authorId": "1688869",
                        "name": "Andrew Zisserman"
                    },
                    {
                        "authorId": "34838386",
                        "name": "K. Simonyan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We examined the 5-way (5 classes) 1-shot task of CIFAR-FS, which is a kind of standard task in one-shot classification.",
                "Also, for transfer learning, we used CIFAR-FS (Bertinetto et al. 2018) with Torchmeta (Deleu et al.",
                "Also, for transfer learning, we used CIFAR-FS (Bertinetto et al. 2018) with Torchmeta (Deleu et al. 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "50527d20047a35ced6ba35e1c0eedf147564dfdd",
                "externalIds": {
                    "ArXiv": "2204.13361",
                    "CorpusId": 253255500
                },
                "corpusId": 253255500,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/50527d20047a35ced6ba35e1c0eedf147564dfdd",
                "title": "It's DONE: Direct ONE-shot learning with quantile weight imprinting",
                "abstract": "Learning a new concept from one example is a superior function of the human brain and it is drawing attention in the field of machine learning as a one-shot learning task. In this paper, we propose one of the simplest methods for this task with a nonparametric weight imprinting, named Direct ONE-shot learning (DONE). DONE adds new classes to a pretrained deep neural network (DNN) classifier with neither training optimization nor pretrained-DNN modification. DONE is inspired by Hebbian theory and directly uses the neural activity input of the final dense layer obtained from data that belongs to the new additional class as the synaptic weight with a newly-provided-output neuron for the new class, transforming all statistical properties of the neural activity into those of synaptic weight by quantile normalization. DONE requires just one inference for learning a new concept and its procedure is simple, deterministic, not requiring parameter tuning and hyperparameters. DONE overcomes a severe problem of existing weight imprinting methods that DNN-dependently interfere with the classification of original-class images. The performance of DONE depends entirely on the pretrained DNN model used as a backbone model, and we confirmed that DONE with current well-trained backbone models perform at a decent accuracy.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2811391",
                        "name": "Kazufumi Hosoda"
                    },
                    {
                        "authorId": "2163741763",
                        "name": "Keigo Nishida"
                    },
                    {
                        "authorId": "35532030",
                        "name": "S. Seno"
                    },
                    {
                        "authorId": "1828039",
                        "name": "T. Mashita"
                    },
                    {
                        "authorId": "1799065",
                        "name": "H. Kashioka"
                    },
                    {
                        "authorId": "2821490",
                        "name": "I. Ohzawa"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We conduct few-shot classification experiments on four widely used few-shot image recognition benchmarks: miniImageNet [53], tieredImageNet [54], CIFAR-FS [37], and FC100 [24].",
                "For example, MAML-type algorithms assume \u03c6\u03c4 is one or a few gradient steps away from \u03b8 [5], [16]\u2013[18], while other meta-learning approaches assume that \u03c6\u03c4 and \u03b8 share the parameters in the feature extractor and only differ in the top layer [6], [37], [38].",
                "Meanwhile, R2-D2 [37] and MetaOptNet [38] reduce the dimensionality of trainable model parameters by freezing feature extraction layers during inner loop optimization.",
                "Note that the proposed method is fundamentally different from R2-D2 and MetaOptNet because our method requires neither episodic meta-learning nor bi-level optimization."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "db0aefaed7f4e7d5826b885275d931638b1bb6eb",
                "externalIds": {
                    "ArXiv": "2204.12466",
                    "DBLP": "conf/ijcnn/ChenL22",
                    "DOI": "10.1109/IJCNN55064.2022.9892722",
                    "CorpusId": 248496411
                },
                "corpusId": 248496411,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/db0aefaed7f4e7d5826b885275d931638b1bb6eb",
                "title": "Meta-free few-shot learning via representation learning with weight averaging",
                "abstract": "Recent studies on few-shot classification using transfer learning pose challenges to the effectiveness and efficiency of episodic meta-learning algorithms. Transfer learning approaches are a natural alternative, but they are restricted to few-shot classification. Moreover, little attention has been on the development of probabilistic models with well-calibrated uncertainty from few-shot samples, except for some Bayesian episodic learning algorithms. To tackle the aforementioned issues, we propose a new transfer learning method to obtain accurate and reliable models for few-shot regression and classification. The resulting method does not require episodic meta-learning and is called meta-free representation learning (MFRL). MFRL first finds low-rank representation generalizing well on meta-test tasks. Given the learned representation, probabilistic linear models are fine-tuned with few-shot samples to obtain models with well-calibrated uncertainty. The proposed method not only achieves the highest accuracy on a wide range of few-shot learning benchmark datasets but also correctly quantifies the prediction uncertainty. In addition, weight averaging and temperature scaling are effective in improving the accuracy and reliability of few-shot learning in existing meta-learning algorithms with a wide range of learning paradigms and model architectures.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3289893",
                        "name": "Kuilin Chen"
                    },
                    {
                        "authorId": "2143724945",
                        "name": "Chi-Guhn Lee"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "790c1c20dbe7198280c911c746933f076b9c2463",
                "externalIds": {
                    "DBLP": "journals/apin/ZhengFYLG23",
                    "DOI": "10.1007/s10489-022-03479-3",
                    "CorpusId": 248333291
                },
                "corpusId": 248333291,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/790c1c20dbe7198280c911c746933f076b9c2463",
                "title": "BDLA: Bi-directional local alignment for few-shot learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2148256380",
                        "name": "Zijun Zheng"
                    },
                    {
                        "authorId": "1964666",
                        "name": "Xiang Feng"
                    },
                    {
                        "authorId": "2118682546",
                        "name": "Huiqun Yu"
                    },
                    {
                        "authorId": "2116524482",
                        "name": "Xiuquan Li"
                    },
                    {
                        "authorId": "3425076",
                        "name": "Mengqi Gao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0b2b9cda21217e1b61112927f535b0700f91e48d",
                "externalIds": {
                    "DBLP": "journals/apin/TianS23",
                    "DOI": "10.1007/s10489-022-03506-3",
                    "CorpusId": 248332285
                },
                "corpusId": 248332285,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0b2b9cda21217e1b61112927f535b0700f91e48d",
                "title": "Momentum memory contrastive learning for transfer-based few-shot classification",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2130235796",
                        "name": "Runliang Tian"
                    },
                    {
                        "authorId": "2108502317",
                        "name": "Hongmei Shi"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "717df032a7672ca3d5ed0d5bb27b82e426ce82b8",
                "externalIds": {
                    "DBLP": "journals/apin/WangNL23",
                    "DOI": "10.1007/s10489-022-03399-2",
                    "CorpusId": 248255002
                },
                "corpusId": 248255002,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/717df032a7672ca3d5ed0d5bb27b82e426ce82b8",
                "title": "Object detection based on few-shot learning via instance-level feature correlation and aggregation",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2152326795",
                        "name": "Meng Wang"
                    },
                    {
                        "authorId": "2089574494",
                        "name": "Hongwei Ning"
                    },
                    {
                        "authorId": "2155522807",
                        "name": "Haipeng Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We first evaluate the impact of pre-training regime (including algorithm and dataset), as well as neural architecture on FSL benchmarks Meta-Dataset [61] (train on 8 datasets), miniImageNet [62], and CIFAR-FS [8].",
                "CIFAR-FS [8] is created by dividing the original CIFAR-100 into 64 training, 16 validation and 20 testing classes.",
                "For miniImageNet and CIFAR-FS, the convention is to evaluate 5-way-1-shot (5w1s) and 5-way-5-shot episodes, and the size of the query set for each episode is fixed to 15\u00d7 5.",
                "The results for single-domain miniImageNet and CIFAR-FS are summarized in Table 4,\nwhile the results for cross-domain datasets Meta-Dataset and Broader Study CDFSL are shown in Table 5 and 6 respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "69db61d66351673d26aec72229568ab8007c69b2",
                "externalIds": {
                    "DBLP": "conf/cvpr/Hu0SKH22",
                    "ArXiv": "2204.07305",
                    "DOI": "10.1109/CVPR52688.2022.00886",
                    "CorpusId": 248218774
                },
                "corpusId": 248218774,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/69db61d66351673d26aec72229568ab8007c69b2",
                "title": "Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference",
                "abstract": "Few-shot learning (FSL) is an important and topical problem in computer vision that has motivated extensive research into numerous methods spanning from sophisticated metalearning methods to simple transfer learning baselines. We seek to push the limits of a simple-but-effective pipeline for real-worldfew-shot image classification in practice. To this end, we explore few-shot learning from the perspective of neural architecture, as well as a three stage pipeline of pre-training on external data, meta-training with labelled few-shot tasks, and task-specific fine-tuning on unseen tasks. We investigate questions such as: \u2460 How pre-training on external data benefits FSL? \u2461 How state of the art transformer architectures can be exploited? and \u2462 How to best exploit finetuning? Ultimately, we show that a simple transformer-based pipeline yields surprisingly good performance on standard benchmarks such as Mini-ImageNet, CIFAR-FS, CDFSL and Meta-Dataset. Our code is available at https://hushell.github.io/pmf.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "145498976",
                        "name": "S. Hu"
                    },
                    {
                        "authorId": "2108338672",
                        "name": "Da Li"
                    },
                    {
                        "authorId": "2162737520",
                        "name": "Jan Stuhmer"
                    },
                    {
                        "authorId": "2918263",
                        "name": "Minyoung Kim"
                    },
                    {
                        "authorId": "1697755",
                        "name": "Timothy M. Hospedales"
                    }
                ]
            }
        },
        {
            "contexts": [
                "7.3.2 Meta-Ridge Regression (MRR) Our next baseline comes from the meta-learning work reviewed in Section 2.3 by Harrison et al. (2018b,a), Bertinetto et al. (2019), Lee et al. (2019), and O\u2019Connell et al. (2021), wherein ridge regression is used as a base-learner to meta-learn parametric features\u2026",
                "Boffi et al. (2020) discuss the case where V\u0304 is a Lyapunov function in the sense of Lyapunov\u2019s direct method (Lyapunov 1892) with x\u2217(t) \u2261 0.",
                "(2018b,a), Bertinetto et al. (2019), Lee et al. (2019), and O\u2019Connell et al. (2021), wherein ridge regression is used as a base-learner to meta-learn parametric features y(x;\u03c6). That is, for a given trajectory Tj , these works assume the last layer \u00c2 should be the best fit in a regression sense, as a function of the parametric features y(x;\u03c6), to some subset of points in Tj . The feature parameters \u03c6 are then trained to minimize this regression fit. This approach, which we term Meta-Ridge Regression (MRR), contrasts with our thesis that \u03c6 should be trained for the endmost purpose of improving control performance, rather than regression performance. We now specify how to implement MRR using the meta-learning language from Section 4. Our implementation is a generalization* of the approach taken by O\u2019Connell et al. (2021) to any nonlinear control-affine dynamical system (17), which can be slightly extended using (19) to include all fully-actuated Lagrangian systems.",
                "(2018b,a), Bertinetto et al. (2019), Lee et al. (2019), and O\u2019Connell et al. (2021), wherein ridge regression is used as a base-learner to meta-learn parametric features y(x;\u03c6).",
                "Bertinetto et al. (2019) and Lee et al. (2019) back-propagate through closed-form ridge regression solutions for few-shot learning, with a maximum likelihood meta-objective.",
                "Bertinetto et al. (2019) and Lee et al. (2019) instead study when the base-learner can be expressed as a convex program with a differentiable closedform solution.",
                "Bertinetto et al. (2019) and Lee et al. (2019) instead study when the base-learner can be expressed as a convex program with a differentiable closed-form solution."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "020d1e7d84d9fd7f5ca140881a086fc1207541a8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-06716",
                    "ArXiv": "2204.06716",
                    "DOI": "10.48550/arXiv.2204.06716",
                    "CorpusId": 247358702
                },
                "corpusId": 247358702,
                "publicationVenue": {
                    "id": "72433a21-03bd-4ab0-9780-8558a35c8dc5",
                    "name": "The international journal of robotics research",
                    "type": "journal",
                    "alternate_names": [
                        "The International Journal of Robotics Research",
                        "int j robot res",
                        "Int J Robot Res"
                    ],
                    "issn": "0278-3649",
                    "url": "http://www.sagepub.com/journals/Journal201324/title",
                    "alternate_urls": [
                        "http://ijr.sagepub.com/",
                        "https://journals.sagepub.com/home/ijr"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/020d1e7d84d9fd7f5ca140881a086fc1207541a8",
                "title": "Control-oriented meta-learning",
                "abstract": "Real-time adaptation is imperative to the control of robots operating in complex, dynamic environments. Adaptive control laws can endow even nonlinear systems with good trajectory tracking performance, provided that any uncertain dynamics terms are linearly parameterizable with known nonlinear features. However, it is often difficult to specify such features a priori, such as for aerodynamic disturbances on rotorcraft or interaction forces between a manipulator arm and various objects. In this paper, we turn to data-driven modeling with neural networks to learn, offline from past data, an adaptive controller with an internal parametric model of these nonlinear features. Our key insight is that we can better prepare the controller for deployment with control-oriented meta-learning of features in closed-loop simulation, rather than regression-oriented meta-learning of features to fit input-output data. Specifically, we meta-learn the adaptive controller with closed-loop tracking simulation as the base-learner and the average tracking error as the meta-objective. With both fully actuated and underactuated nonlinear planar rotorcraft subject to wind, we demonstrate that our adaptive controller outperforms other controllers trained with regression-oriented meta-learning when deployed in closed-loop for trajectory tracking control.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51219725",
                        "name": "Spencer M. Richards"
                    },
                    {
                        "authorId": "2082417",
                        "name": "Navid Azizan"
                    },
                    {
                        "authorId": "1740591",
                        "name": "J. Slotine"
                    },
                    {
                        "authorId": "1696085",
                        "name": "M. Pavone"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "250345d0a0a4066bddb324000f760c24a8ced642",
                "externalIds": {
                    "DBLP": "journals/remotesensing/ZhaoLCGZQW22",
                    "DOI": "10.3390/rs14081884",
                    "CorpusId": 248272725
                },
                "corpusId": 248272725,
                "publicationVenue": {
                    "id": "8e1bd4b5-d5b2-4e22-ba0a-01fe5568d472",
                    "name": "Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "Remote Sens"
                    ],
                    "issn": "2315-4675",
                    "alternate_issns": [
                        "2072-4292"
                    ],
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-169233",
                    "alternate_urls": [
                        "https://www.mdpi.com/journal/remotesensing",
                        "http://www.mdpi.com/journal/remotesensing",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-169233"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/250345d0a0a4066bddb324000f760c24a8ced642",
                "title": "Few-Shot SAR-ATR Based on Instance-Aware Transformer",
                "abstract": "Few-shot synthetic aperture radar automatic target recognition (SAR-ATR) aims to recognize the targets of the images (query images) based on a few annotated images (support images). Such a task requires modeling the relationship between the query and support images. In this paper, we propose the instance-aware transformer (IAT) model. The IAT exploits the power of all instances by constructing the attention map based on the similarities between the query feature and all support features. The query feature aggregates the support features based on the attention values. To align the features of the query and support images in IAT, the shared cross-transformer keep all the projections in the module shared across all features. Instance cosine distance is used in training to minimize the distance between the query feature and the support features. In testing, to fuse the support features of the same class into the class representation, Euclidean (Cosine) Loss is used to calculate the query-class distances. Experiments on the two proposed few-shot SAR-ATR test sets based on MSTAR demonstrate the superiority of the proposed method.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2145734317",
                        "name": "Xin Zhao"
                    },
                    {
                        "authorId": "50085385",
                        "name": "Xiaoling Lv"
                    },
                    {
                        "authorId": "6109371",
                        "name": "Jinlei Cai"
                    },
                    {
                        "authorId": "47093572",
                        "name": "Jiayi Guo"
                    },
                    {
                        "authorId": "2145912886",
                        "name": "Yueting Zhang"
                    },
                    {
                        "authorId": "3032924",
                        "name": "Xiaolan Qiu"
                    },
                    {
                        "authorId": "2115853360",
                        "name": "Yirong Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[8] and MetaOptNet [23] presented closed form solutions and differentiable solvers for task-dependent Ridge Regression, Logistic Regression (LR), and Support Vector Machines (SVMs)."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "52c327eba81faf42f4b4bc71613cd840f33d06e7",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiangRPH22",
                    "ArXiv": "2204.05494",
                    "DOI": "10.1109/CVPR52688.2022.00888",
                    "CorpusId": 248118989
                },
                "corpusId": 248118989,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/52c327eba81faf42f4b4bc71613cd840f33d06e7",
                "title": "Few-shot Learning with Noisy Labels",
                "abstract": "Few-shot learning (FSL) methods typically assume clean support sets with accurately labeled samples when training on novel classes. This assumption can often be unrealistic: support sets, no matter how small, can still include mislabeled samples. Robustness to label noise is therefore essential for FSL methods to be practical, but this problem surprisingly remains largely unexplored. To address mislabeled samples in FSL settings, we make several technical contributions. (1) We offer simple, yet effective, feature aggregation methods, improving the prototypes used by ProtoNet, a popular FSL technique. (2) We describe a novel Transformer model for Noisy Few-Shot Learning (TraNFS). TraNFS leverages a transformer's attention mechanism to weigh mislabeled versus correct samples. (3) Finally, we extensively test these methods on noisy versions of MinilmageNet and TieredImageNet. Our results show that TraNFS is on-par with leading FSL methods on clean support sets, yet outperforms them, by far, in the presence of label noise.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "144130492",
                        "name": "Kevin J Liang"
                    },
                    {
                        "authorId": "7509100",
                        "name": "Samrudhdhi B. Rangrej"
                    },
                    {
                        "authorId": "2162195471",
                        "name": "Vladan Petrovic"
                    },
                    {
                        "authorId": "1756099",
                        "name": "Tal Hassner"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2018), R2-D2 (Bertinetto et al., 2019), and BOIL (Oh et al.",
                "\u2026of IBP with other few-shot learners: As contending meta-learning algorithms, we choose the vanilla MAML along with notable meta-learners such as Meta-SGD (Li et al., 2017), Reptile (Nichol et al., 2018), LLAMA (Grant et al., 2018), R2-D2 (Bertinetto et al., 2019), and BOIL (Oh et al., 2021).",
                "Comparison of IBP with other few-shot learners: As contending meta-learning algorithms, we choose the vanilla MAML along with notable meta-learners such as Meta-SGD (Li et al., 2017), Reptile (Nichol et al., 2018), LLAMA (Grant et al., 2018), R2-D2 (Bertinetto et al., 2019), and BOIL (Oh et al., 2021)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2f11886fc2e720cb532c065dda159b0a7bb46179",
                "externalIds": {
                    "DBLP": "conf/icml/DattaMCD23",
                    "ArXiv": "2204.03511",
                    "CorpusId": 258479919
                },
                "corpusId": 258479919,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2f11886fc2e720cb532c065dda159b0a7bb46179",
                "title": "Interval Bound Interpolation for Few-shot Learning with Few Tasks",
                "abstract": "Few-shot learning aims to transfer the knowledge acquired from training on a diverse set of tasks to unseen tasks from the same task distribution with a limited amount of labeled data. The underlying requirement for effective few-shot generalization is to learn a good representation of the task manifold. This becomes more difficult when only a limited number of tasks are available for training. In such a few-task few-shot setting, it is beneficial to explicitly preserve the local neighborhoods from the task manifold and exploit this to generate artificial tasks for training. To this end, we introduce the notion of interval bounds from the provably robust training literature to few-shot learning. The interval bounds are used to characterize neighborhoods around the training tasks. These neighborhoods can then be preserved by minimizing the distance between a task and its respective bounds. We then use a novel strategy to artificially form new tasks for training by interpolating between the available tasks and their respective interval bounds. We apply our framework to both model-agnostic meta-learning as well as prototype-based metric-learning paradigms. The efficacy of our proposed approach is evident from the improved performance on several datasets from diverse domains compared to current methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2165464",
                        "name": "Shounak Datta"
                    },
                    {
                        "authorId": "70040213",
                        "name": "S. S. Mullick"
                    },
                    {
                        "authorId": "2131635170",
                        "name": "A. Chakrabarty"
                    },
                    {
                        "authorId": "71658519",
                        "name": "Swagatam Das"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For the experiments we have used the novel CIFARFS [8] dataset.",
                "In [8] it has been suggested to split 100 classes into train, validation and test sets.",
                "Accuracies and timings for our MAML implementation on CIFAR-FS are presented in Table 1.",
                "The testing results will be shown on a publicly available few-shot learning dataset CIFAR-FS [8].",
                "The exact classes that go into each split are important and are defined in [8].",
                "Instead, we consistently use meta-batch size of 4 as it leads to slightly better performance on CIFAR-FS [8] dataset during our experiments.",
                "We have taken the CIFAR-FS dataset for our experiments as it hasn\u2019t been analyzed by the MAML authors and is also faster to compute than miniImageNet."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2e19c2fb8a68b786618e63a96540c0ea5d47dbbc",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-05930",
                    "ArXiv": "2206.05930",
                    "DOI": "10.15588/1607-3274-2022-1-10",
                    "CorpusId": 248464169
                },
                "corpusId": 248464169,
                "publicationVenue": {
                    "id": "c395d217-d288-41c4-a32c-c0f5bf9c8d25",
                    "name": "Radio Electronics, Computer Science, Control",
                    "type": "journal",
                    "alternate_names": [
                        "Radio Electron Comput Sci Control"
                    ],
                    "issn": "2313-688X"
                },
                "url": "https://www.semanticscholar.org/paper/2e19c2fb8a68b786618e63a96540c0ea5d47dbbc",
                "title": "Faster Optimization-Based Meta-Learning Adaptation Phase",
                "abstract": "Context. Neural networks require a large amount of annotated data to learn. Meta-learning algorithms propose a way to decrease number of training samples to only a few. One of the most prominent optimization-based meta-learning algorithms is MAML. However, its adaptation to new tasks is quite slow. The object of study is the process of meta-learning and adaptation phase as defined by the MAML algorithm.Objective. The goal of this work is creation of an approach, which should make it possible to: 1) increase the execution speed of MAML adaptation phase; 2) improve MAML accuracy in certain cases. The testing results will be shown on a publicly available few-shot learning dataset CIFAR-FS.Method. In this work an improvement to MAML meta-learning algorithm is proposed. Meta-learning procedure is defined in terms of tasks. In case of image classification problem, each task is to try to learn to classify images of new classes given only a few training examples. MAML defines 2 stages for the learning procedure: 1) adaptation to the new task; 2) meta-weights update. The whole training procedure requires Hessian computation, which makes the method computationally expensive. After being trained, the network will typically be used for adaptation to new tasks and the subsequent prediction on them. Thus, improving adaptation time is an important problem, which we focus on in this work. We introduce lambda pattern by which we restrict which weight we update in the network during the adaptation phase. This approach allows us to skip certain gradient computations. The pattern is selected given an allowed quality degradation threshold parameter. Among the pattern that fit the criteria, the fastest pattern is then selected. However, as it is discussed later, quality improvement is also possible is certain cases by a careful pattern selection.Results. The MAML algorithm with lambda pattern adaptation has been implemented, trained and tested on the open CIFAR-FS dataset. This makes our results easily reproducible.Conclusions. The experiments conducted have shown that via lambda adaptation pattern selection, it is possible to significantly improve the MAML method in the following areas: adaptation time has been decreased by a factor of 3 with minimal accuracy loss. Interestingly, accuracy for one-step adaptation has been substantially improved by using lambda patterns as well. Prospects for further research are to investigate a way of a more robust automatic pattern selection scheme.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "103862117",
                        "name": "K. Khabarlak"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026with hallucinating more samples(Hariharan and Girshick 2017; Wang et al. 2018), optimization with ridge regression or support vector machine (Bertinetto et al. 2018; Lee et al. 2019), using graph neural networks (Garcia and Bruna 2017; Kim et al. 2019), self/semi-supervised learning (Ren et\u2026",
                "2018), optimization with ridge regression or support vector machine (Bertinetto et al. 2018; Lee et al. 2019), using graph neural networks (Garcia and Bruna 2017; Kim et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "151ddaa95cccb7f965be0490c097d9c41bf073a5",
                "externalIds": {
                    "DBLP": "conf/aaai/TaoZZS22",
                    "ArXiv": "2204.03749",
                    "DOI": "10.1609/aaai.v36i8.20823",
                    "CorpusId": 249375208
                },
                "corpusId": 249375208,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/151ddaa95cccb7f965be0490c097d9c41bf073a5",
                "title": "Powering Finetuning in Few-Shot Learning: Domain-Agnostic Bias Reduction with Selected Sampling",
                "abstract": "In recent works, utilizing a deep network trained on meta-training set serves as a strong baseline in few-shot learning. In this paper, we move forward to refine novel-class features by finetuning a trained deep network. Finetuning is designed to focus on reducing biases in novel-class feature distributions, which we define as two aspects: class-agnostic and class-specific biases. Class-agnostic bias is defined as the distribution shifting introduced by domain difference, which we propose Distribution Calibration Module(DCM) to reduce. DCM owes good property of eliminating domain difference and fast feature adaptation during optimization. Class-specific bias is defined as the biased estimation using a few samples in novel classes, which we propose Selected Sampling(SS) to reduce. Without inferring the actual class distribution, SS is designed by running sampling using proposal distributions around support-set samples. By powering finetuning with DCM and SS, we achieve state-of-the-art results on Meta-Dataset with consistent performance boosts over ten datasets from different domains. We believe our simple yet effective method demonstrates its possibility to be applied on practical few-shot applications.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "26151496",
                        "name": "R. Tao"
                    },
                    {
                        "authorId": "120811666",
                        "name": "Han Zhang"
                    },
                    {
                        "authorId": "3049981",
                        "name": "Yutong Zheng"
                    },
                    {
                        "authorId": "1794486",
                        "name": "M. Savvides"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fc606ec21f3d64bf5aebce080bba51c8a614d962",
                "externalIds": {
                    "DOI": "10.1109/i2ct54291.2022.9824942",
                    "CorpusId": 250661005
                },
                "corpusId": 250661005,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/fc606ec21f3d64bf5aebce080bba51c8a614d962",
                "title": "A Study On Meta Learning Optimization Techniques",
                "abstract": "In the last decade, the domain of Artificial Intelligence (AI) has undergone rapid advancement and has achieved ability to mimic near-human intelligence in multiple aspects. Deep Neural Networks (DNNs), when trained with large datasets and optimal computational resources can achieve great outcomes, but the learning process is exhaustively time consuming. Along with this there still exists several challenges with respect to computational resources constraints, scarcity of data related to specific task and so on. In various situations, where the data is scarce, the algorithms are incapable of learning tasks quickly and accurately similar to that human intelligence. Meanwhile, the problem has been addressed with advancements in deep meta-learning in multiple researches. Meta-Learning has wide range of applications where in the insights from meta-data of the either data, tasks or the previously trained models can be utilised to optimise the learning process. To get an in-depth overview of available meta-learning techniques for DNN model optimization, we have carried-out a survey of optimization-based meta-learning techniques, their advantages, drawbacks and open challenges.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2176957343",
                        "name": "Prasanna H Sulibhavi"
                    },
                    {
                        "authorId": "2176957220",
                        "name": "Raghavendra A Hallyal"
                    },
                    {
                        "authorId": "2021080117",
                        "name": "Rohini K Katti"
                    },
                    {
                        "authorId": "2176950982",
                        "name": "Amruta E Kabade"
                    },
                    {
                        "authorId": "2176957273",
                        "name": "Sujay S Thadal"
                    },
                    {
                        "authorId": "2148654167",
                        "name": "M. M"
                    },
                    {
                        "authorId": "2066226934",
                        "name": "Uday Kulkarni"
                    },
                    {
                        "authorId": "65766676",
                        "name": "Sunil V. Gurlahosur"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For MiniImagenet (Table 1) we report on both versions \u201cSOTp\u201d and \u201cSOTt\u201d over a range of backbone architectures, while for the smaller datasets CIFAR-FS and CUB (Table 2) we focus on the \u2018drop-in\u2019 version \u201cSOTp\u201d and only the strongest wrn-28-10 architecture.",
                "Table 2: Few-Shot Classification (FSC) accuracy on CIFAR-FS [1] and CUB [40].",
                "Our main experiment is a comprehensive evaluation on the standard few-shot classification benchmarks MiniImagenet [39], CIFAR-FS [1], and CUB [40], with detailed results in Tables 1 and 2.",
                "The CIFAR-FS [1] dataset includes 100 classes with 600 images of size 32 \u00d7 32 per-class."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2839543e820f5ce5005332d5d604acf1be21f49a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-03065",
                    "ArXiv": "2204.03065",
                    "DOI": "10.48550/arXiv.2204.03065",
                    "CorpusId": 248006519
                },
                "corpusId": 248006519,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2839543e820f5ce5005332d5d604acf1be21f49a",
                "title": "The Self-Optimal-Transport Feature Transform",
                "abstract": "The Self-Optimal-Transport (SOT) feature transform is designed to upgrade the set of features of a data instance to facilitate downstream matching or grouping related tasks. The transformed set encodes a rich representation of high order relations between the instance features. Distances between transformed features capture their direct original similarity and their third party agreement regarding similarity to other features in the set. A particular min-cost-max-flow fractional matching problem, whose entropy regularized version can be approximated by an optimal transport (OT) optimization, results in our transductive transform which is efficient, differentiable, equivariant, parameterless and probabilistically interpretable. Empirically, the transform is highly effective and flexible in its use, consistently improving networks it is inserted into, in a variety of tasks and training schemes. We demonstrate its merits through the problem of unsupervised clustering and its efficiency and wide applicability for few-shot-classification, with state-of-the-art results, and large-scale person re-identification.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2161661204",
                        "name": "Daniel Shalam"
                    },
                    {
                        "authorId": "28235967",
                        "name": "Simon Korman"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Results on the mini-ImageNet, tiered-ImageNet, CUB, and CIFAR-FS datasets are shown in Tables 1, 2, 3, and 4, respectively.",
                "\u2018Others\u2019 means some other backbones that are larger than ResNet12, such as ResNet18 [1], [23], [24], [59], [78], [79], ResNet34 [80], and ResNet50 [81].\nthe mini-ImageNet (in Table 1) and CIFAR-FS (in Table 4) datasets, our method improves upon the model-based method METAVRF [33] by 5:1% and 5%, using ConvNet as the backbone.",
                "Similarly, experimental results on the tiered-ImageNet (in Table 2), CUB (in Table 3), and CIFAR-FS (in Table 4) datasets further suggest our superiority.",
                "On the CIFAR-FS dataset, our method outperforms compared methods by more than 8% and 5% in the 1-shot and 5-shot tasks.",
                "We used the mini-ImageNet [59], tiered-ImageNet [64], CUB [65], and CIFAR-FS [66] datasets for few-shot classification.",
                "Thus, we choose m \u00bc 16 in the classification tasks for the miniImageNet, tiered-ImageNet, CUB, and CIFAR-FS dataset.",
                "Comparisons With the State-of-the-Art Few-Shot Classification Methods on the CIFAR-FS Dataset\nBackbone Method Category 1-shot 5-way 5-shot 5-way\nConvNet\nMETAVRF [33] Model 63:10 0:70 76:50 0:90 MAML [1] Optim 56:50 1:90 70:50 0:90\nFOMAML [1] Optim 55:60 1:88 69:52 0:91 Reptile [71] Optim 57:50 0:45 71:88 0:42 Lazy-Reptile [35] Optim 59:36 1:44 74:90 1:28 Ours Optim 65:43 0:90 81:50 1:08\nResNet12\nShot-Free [68] Metric 69.20 84.70 TEWAM [29] Metric 70.40 81.30 ProtoNet [23] Metric 72:20 0:70 83:50 0:50 MetaOptNet [75] Metric 72:60 0:70 84:30 0:50 RENet [26] Metric 74:51 0:46 86:60 0:32 DSN [30] Metric 75:60 0:90 86:20 0:60\nMCGN [85] Metric 76:45 0:99 88:42 0:23 RFS [86] Metric 73:90 0:80 86:90 0:50 Rizve et al. [87] Metric 77:87 0:85 89:74 0:57 MABAS [88] Aug 73:51 0:92 85:49 0:68\nOurs Optim 86:40 0:80 94:87 0:50\n\u2018Aug\u2019 means the data augmentation technique for few-shot learning.\nwhile our method uses a product manifold neural network, and learns a curvature generation scheme and a curvature updating scheme.",
                "CIFAR-FS is a dataset derived from CIFAR-100 [67]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "c8b48633947d4f679af579e01d9220a1908cf0d2",
                "externalIds": {
                    "DBLP": "journals/pami/GaoWHJ23",
                    "DOI": "10.1109/TPAMI.2022.3164894",
                    "CorpusId": 247978761,
                    "PubMed": "35380955"
                },
                "corpusId": 247978761,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c8b48633947d4f679af579e01d9220a1908cf0d2",
                "title": "Curvature-Adaptive Meta-Learning for Fast Adaptation to Manifold Data",
                "abstract": "Meta-learning methods are shown to be effective in quickly adapting a model to novel tasks. Most existing meta-learning methods represent data and carry out fast adaptation in euclidean space. In fact, data of real-world applications usually resides in complex and various Riemannian manifolds. In this paper, we propose a curvature-adaptive meta-learning method that achieves fast adaptation to manifold data by producing suitable curvature. Specifically, we represent data in the product manifold of multiple constant curvature spaces and build a product manifold neural network as the base-learner. In this way, our method is capable of encoding complex manifold data into discriminative and generic representations. Then, we introduce curvature generation and curvature updating schemes, through which suitable product manifolds for various forms of data manifolds are constructed via few optimization steps. The curvature generation scheme identifies task-specific curvature initialization, leading to a shorter optimization trajectory. The curvature updating scheme automatically produces appropriate learning rate and search direction for curvature, making a faster and more adaptive optimization paradigm compared to hand-designed optimization schemes. We evaluate our method on a broad set of problems including few-shot classification, few-shot regression, and reinforcement learning tasks. Experimental results show that our method achieves substantial improvements as compared to meta-learning methods ignoring the geometry of the underlying space.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2116492882",
                        "name": "Zhi Gao"
                    },
                    {
                        "authorId": "150352923",
                        "name": "Yuwei Wu"
                    },
                    {
                        "authorId": "1686714",
                        "name": "M. Harandi"
                    },
                    {
                        "authorId": "7415267",
                        "name": "Yunde Jia"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Our proposed method could likely be extended to Relation Networks [22], MetaOptNet [15], or R2D2 [3], with a decoder network to visualize embeddings.",
                "The CIFAR-FS dataset [3] is a recent few-shot image classification benchmark consisting of all 100 classes from CIFAR-100 [14]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "03d2c7a30554f34ef3613d743fd14af68d4782a9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-00929",
                    "ArXiv": "2204.00929",
                    "DOI": "10.48550/arXiv.2204.00929",
                    "CorpusId": 247625826
                },
                "corpusId": 247625826,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/03d2c7a30554f34ef3613d743fd14af68d4782a9",
                "title": "AutoProtoNet: Interpretability for Prototypical Networks",
                "abstract": "In meta-learning approaches, it is difficult for a practitioner to make sense of what kind of representations the model employs. Without this ability, it can be difficult to both understand what the model knows as well as to make meaningful corrections. To address these challenges, we introduce AutoProtoNet, which builds interpretability into Prototypical Networks by training an embedding space suitable for reconstructing inputs, while remaining convenient for few-shot learning. We demonstrate how points in this embedding space can be visualized and used to understand class representations. We also devise a prototype refinement method, which allows a human to debug inadequate classification parameters. We use this debugging technique on a custom classification task and find that it leads to accuracy improvements on a validation set consisting of in-the-wild images. We advocate for interpretability in meta-learning approaches and show that there are interactive ways for a human to enhance meta-learning algorithms.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "27369232",
                        "name": "Pedro Sandoval Segura"
                    },
                    {
                        "authorId": "39648491",
                        "name": "W. Lawson"
                    }
                ]
            }
        },
        {
            "contexts": [
                "From Figure 9, we can see that on the MiniImagenet dataset and the CIFAR-FS dataset, the classification accuracy of the WPGN is higher than that of the DPGN on the three tasks.",
                "The results of the ablation experiment on the CUB-200-2011 and CIFAR-FS datasets under 5-way-1 shot tasks are shown in Table 9.",
                "This data can be found here: CUB-200-2011: https://resolver.caltech.edu/CaltechAUTHORS:20111026-120541847, MiniImagenet: https://www.image-net.org/, CIFAR-FS: DOI: 10.1109/IROS45743.",
                "7 k 200 100/50/50 [33] 84 \u00d7 84 CIFAR-FS 60 k 100 64/16/20 [4] 32 \u00d7 32",
                "We selected three types of standard datasets in FSL: MiniImageNet [9], CUB-2002011 [32] and CIFAR-FS [4].",
                "Meta-learning with differentiable closed-form solvers [4] uses simpler differentiable regression methods that have closed-form solutions to replace the original learning algorithms (e.",
                "The accuracy of the CIFAR-FS dataset was lower than that of the MiniImagenet dataset because its background had a much smaller impact on the classification accuracy."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "f01428073133e417047aa522610d1df5d6a11466",
                "externalIds": {
                    "DBLP": "journals/sensors/ZhuWH22",
                    "PubMedCentral": "9002792",
                    "DOI": "10.3390/s22072648",
                    "CorpusId": 247896893,
                    "PubMed": "35408261"
                },
                "corpusId": 247896893,
                "publicationVenue": {
                    "id": "3dbf084c-ef47-4b74-9919-047b40704538",
                    "name": "Italian National Conference on Sensors",
                    "type": "conference",
                    "alternate_names": [
                        "SENSORS",
                        "IEEE Sens",
                        "Ital National Conf Sens",
                        "IEEE Sensors",
                        "Sensors"
                    ],
                    "issn": "1424-8220",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-142001",
                        "http://www.mdpi.com/journal/sensors",
                        "https://www.mdpi.com/journal/sensors"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f01428073133e417047aa522610d1df5d6a11466",
                "title": "Word Embedding Distribution Propagation Graph Network for Few-Shot Learning",
                "abstract": "Few-shot learning (FSL) is of great significance to the field of machine learning. The ability to learn and generalize using a small number of samples is an obvious distinction between artificial intelligence and humans. In the FSL domain, most graph neural networks (GNNs) focus on transferring labeled sample information to an unlabeled query sample, ignoring the important role of semantic information during the classification process. Our proposed method embeds semantic information of classes into a GNN, creating a word embedding distribution propagation graph network (WPGN) for FSL. We merge the attention mechanism with our backbone network, use the Mahalanobis distance to calculate the similarity of classes, select the Funnel ReLU (FReLU) function as the activation function of the Transform layer, and update the point graph and word embedding distribution graph. In extensive experiments on FSL benchmarks, compared with the baseline model, the accuracy of the WPGN on the 5-way-1/2/5 shot tasks increased by 9.03, 4.56, and 4.15%, respectively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2152682400",
                        "name": "Chaoran Zhu"
                    },
                    {
                        "authorId": "2151979821",
                        "name": "Ling Wang"
                    },
                    {
                        "authorId": "2161258192",
                        "name": "Cheng Han"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026and popular optimization framework that covers a variety of emerging machine learning applications, e.g., metalearning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyperparameter\noptimization (Franceschi et al., 2018; Shaban et al., 2019;\u2026"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "59902d4795f7f5eef15021cf0e74492dea4ebe29",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-16615",
                    "ArXiv": "2203.16615",
                    "DOI": "10.48550/arXiv.2203.16615",
                    "CorpusId": 247839136
                },
                "corpusId": 247839136,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/59902d4795f7f5eef15021cf0e74492dea4ebe29",
                "title": "A Fast and Convergent Proximal Algorithm for Regularized Nonconvex and Nonsmooth Bi-level Optimization",
                "abstract": "Many important machine learning applications involve regularized nonconvex bi-level optimization. However, the existing gradient-based bi-level optimization algorithms cannot handle nonconvex or nonsmooth regularizers, and they suffer from a high computation complexity in nonconvex bi-level optimization. In this work, we study a proximal gradient-type algorithm that adopts the approximate implicit differentiation (AID) scheme for nonconvex bi-level optimization with possibly nonconvex and nonsmooth regularizers. In particular, the algorithm applies the Nesterov's momentum to accelerate the computation of the implicit gradient involved in AID. We provide a comprehensive analysis of the global convergence properties of this algorithm through identifying its intrinsic potential function. In particular, we formally establish the convergence of the model parameters to a critical point of the bi-level problem, and obtain an improved computation complexity $\\mathcal{O}(\\kappa^{3.5}\\epsilon^{-2})$ over the state-of-the-art result. Moreover, we analyze the asymptotic convergence rates of this algorithm under a class of local nonconvex geometries characterized by a {\\L}ojasiewicz-type gradient inequality. Experiment on hyper-parameter optimization demonstrates the effectiveness of our algorithm.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2144251699",
                        "name": "Ziyi Chen"
                    },
                    {
                        "authorId": "1749353",
                        "name": "B. Kailkhura"
                    },
                    {
                        "authorId": "2118765295",
                        "name": "Yi Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Meta-learning is closely related to representation learning, although the assumption is not the same [Denevi et al., 2019; Finn et al., 2019; Khodak et al., 2019; Lee et al., 2019; Bertinetto et al., 2018]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "056831f0a6ae60ae96fe5525f9a0d5274d9f78ea",
                "externalIds": {
                    "ArXiv": "2203.15664",
                    "DBLP": "journals/corr/abs-2203-15664",
                    "DOI": "10.48550/arXiv.2203.15664",
                    "CorpusId": 247779071
                },
                "corpusId": 247779071,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/056831f0a6ae60ae96fe5525f9a0d5274d9f78ea",
                "title": "Nearly Minimax Algorithms for Linear Bandits with Shared Representation",
                "abstract": "We give novel algorithms for multi-task and lifelong linear bandits with shared representation. Specifically, we consider the setting where we play $M$ linear bandits with dimension $d$, each for $T$ rounds, and these $M$ bandit tasks share a common $k(\\ll d)$ dimensional linear representation. For both the multi-task setting where we play the tasks concurrently, and the lifelong setting where we play tasks sequentially, we come up with novel algorithms that achieve $\\widetilde{O}\\left(d\\sqrt{kMT} + kM\\sqrt{T}\\right)$ regret bounds, which matches the known minimax regret lower bound up to logarithmic factors and closes the gap in existing results [Yang et al., 2021]. Our main technique include a more efficient estimator for the low-rank linear feature extractor and an accompanied novel analysis for this estimator.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1423718086",
                        "name": "Jiaqi Yang"
                    },
                    {
                        "authorId": "144438755",
                        "name": "Qi Lei"
                    },
                    {
                        "authorId": "2108327687",
                        "name": "Jason D. Lee"
                    },
                    {
                        "authorId": "145697585",
                        "name": "S. Du"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Note that it is difficult to present a fair and direct comparison between the conventional FS-C and our few-shot classification task since FS-C is always evaluated on single-label classification benchmarks [2,32,57,74,76], whereas our task is evaluated on multi-label benchmarks [13,36], which are irreducible to a single-label one in general."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "734b900a97bdc51628dec39b12c615d0c7f5a228",
                "externalIds": {
                    "DBLP": "conf/cvpr/KangC22",
                    "ArXiv": "2203.15712",
                    "DOI": "10.1109/CVPR52688.2022.00974",
                    "CorpusId": 247779043
                },
                "corpusId": 247779043,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/734b900a97bdc51628dec39b12c615d0c7f5a228",
                "title": "Integrative Few-Shot Learning for Classification and Segmentation",
                "abstract": "We introduce the integrative task of few-shot classification and segmentation (FS-CS) that aims to both classify and segment target objects in a query image when the target classes are given with a few examples. This task combines two conventional few-shot learning problems, few-shot classification and segmentation. FS-CS generalizes them to more realistic episodes with arbitrary image pairs, where each target class may or may not be present in the query. To address the task, we propose the integrative few-shot learning (iFSL) framework for FS-CS, which trains a learner to construct class-wise foreground maps for multi-label classification and pixel-wise segmentation. We also develop an effective iFSL model, attentive squeeze network (ASNet), that leverages deep semantic correlation and global self-attention to produce reliable foreground maps. In experiments, the proposed method shows promising performance on the FS-CS task and also achieves the state of the art on standard few-shot segmentation benchmarks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2088167050",
                        "name": "Dahyun Kang"
                    },
                    {
                        "authorId": "72643925",
                        "name": "Minsu Cho"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following the split in [2], we used 64 classes to construct the base set, 16 and 20 for validation and novel set."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "86286541e91379b86944c0d2fd49cbbe3c82c10d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-14840",
                    "ArXiv": "2203.14840",
                    "DOI": "10.48550/arXiv.2203.14840",
                    "CorpusId": 247778770
                },
                "corpusId": 247778770,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/86286541e91379b86944c0d2fd49cbbe3c82c10d",
                "title": "A Framework of Meta Functional Learning for Regularising Knowledge Transfer",
                "abstract": "\u2014Machine learning classi\ufb01ers\u2019 capability is largely dependent on the scale of available training data and limited by the model over\ufb01tting in data-scarce learning tasks. To address this problem, this work proposes a novel framework of Meta Functional Learning (MFL) by meta-learning a generalisable functional model from data-rich tasks whilst simultaneously regularising knowledge transfer to data-scarce tasks. The MFL computes meta-knowledge on functional regularisation generalisable to different learning tasks by which functional training on limited labelled data promotes more discriminative functions to be learned. Based on this framework, we formulate three variants of MFL: MFL with Prototypes (MFL-P) which learns a functional by auxiliary prototypes, Composite MFL (ComMFL) that transfers knowledge from both functional space and representational space, and MFL with Iterative Updates (MFL-IU) which improves knowledge transfer regularisation from MFL by progressively learning the functional regularisation in knowledge transfer. Moreover, we generalise these variants for knowledge transfer regularisation from binary classi\ufb01ers to multi-class classi\ufb01ers. Extensive experiments on two few-shot learning scenarios, Few-Shot Learning (FSL) and Cross-Domain Few-Shot Learning (CD-FSL), show that meta functional learning for knowledge transfer regularisation can improve FSL classi\ufb01ers.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2125435016",
                        "name": "Pan Li"
                    },
                    {
                        "authorId": "35782003",
                        "name": "Yanwei Fu"
                    },
                    {
                        "authorId": "144784813",
                        "name": "S. Gong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For this purpose, we employ the miniImageNet [8, 36], tieredImageNet [38], CIFAR-FS [5], and CUB-2002011 [49] datasets.",
                "On the other hand, while our approach does not report the best result on CUB-200, we are on par with the best method FRN and produce the best performance on CIFAR-FS (\u2248 5%).",
                "For this purpose, we employ the miniImageNet [8, 36], tieredImageNet [38], CIFAR-FS [5], and CUB-2002011 [49] datasets.\nminiImageNet consists of a subset of 100 object classes from ImageNet [8] with 600 images per class."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b6aa719f295d8190e40a8d4ec46fbde7b424cbc5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-13465",
                    "ArXiv": "2203.13465",
                    "DOI": "10.1109/CVPR52688.2022.01415",
                    "CorpusId": 247749057
                },
                "corpusId": 247749057,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b6aa719f295d8190e40a8d4ec46fbde7b424cbc5",
                "title": "CAD: Co-Adapting Discriminative Features for Improved Few-Shot Classification",
                "abstract": "Few-shot classification is a challenging problem that aims to learn a model that can adapt to unseen classes given a few labeled samples. Recent approaches pre-train a feature extractor, and then fine-tune for episodic metalearning. Other methods leverage spatial features to learn pixel-level correspondence while jointly training a classifier. However, results using such approaches show marginal improvements. In this paper, inspired by the transformer style self-attention mechanism, we propose a strategy to cross-attend and re-weight discriminative features for fewshot classification. Given a base representation of support and query images after global pooling, we introduce a single shared module that projects features and cross-attends in two aspects: (i) query to support, and (ii) support to query. The module computes attention scores between features to produce an attention pooled representation of features in the same class that is later added to the original representation followed by a projection head. This effectively re-weights features in both aspects (i & ii) to produce features that better facilitate improved metric-based metalearning. Extensive experiments on public benchmarks show our approach outperforms state-of-the-art methods by 3%~5%.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51939462",
                        "name": "Philip Chikontwe"
                    },
                    {
                        "authorId": "1518605867",
                        "name": "Soopil Kim"
                    },
                    {
                        "authorId": "7882417",
                        "name": "Sang Hyun Park"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f8dd57ada1d4514c72fcee28e1e807644f56829a",
                "externalIds": {
                    "DBLP": "conf/cvpr/Pandey022",
                    "ArXiv": "2203.12768",
                    "DOI": "10.1109/CVPR52688.2022.01399",
                    "CorpusId": 247627751
                },
                "corpusId": 247627751,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f8dd57ada1d4514c72fcee28e1e807644f56829a",
                "title": "Multidimensional Belief Quantification for Label-Efficient Meta-Learning",
                "abstract": "Optimization-based meta-learning offers a promising direction for few-shot learning that is essential for many real-world computer vision applications. However, learning from few samples introduces uncertainty, and quantifying model confidence for few-shot predictions is essential for many critical domains. Furthermore, few-shot tasks used in meta training are usually sampled randomly from a task distribution for an iterative model update, leading to high labeling costs and computational overhead in meta-training. We propose a novel uncertainty-aware task selection model for label efficient meta-learning. The proposed model formulates a multidimensional belief measure, which can quantify the known uncertainty and lower bound the unknown uncertainty of any given task. Our theoretical result establishes an important relationship between the conflicting belief and the incorrect belief The theoretical result allows us to estimate the total uncertainty of a task, which provides a principled criterion for task selection. A novel multi-query task formulation is further developed to improve both the computational and labeling efficiency of meta-learning. Experiments conducted over multiple real-world few-shot image classification tasks demonstrate the effectiveness of the proposed model.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2054481507",
                        "name": "Deepshikha Pandey"
                    },
                    {
                        "authorId": "2087411179",
                        "name": "Qi Yu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "82a4f1f3c17842d6d086a405b9909f69c7c8a429",
                "externalIds": {
                    "DBLP": "conf/wacv/SenderaPKZTS23",
                    "ArXiv": "2203.11378",
                    "DOI": "10.1109/WACV56688.2023.00250",
                    "CorpusId": 247596876
                },
                "corpusId": 247596876,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/82a4f1f3c17842d6d086a405b9909f69c7c8a429",
                "title": "HyperShot: Few-Shot Learning by Kernel HyperNetworks",
                "abstract": "Few-shot models aim at making predictions using a minimal number of labeled examples from a given task. The main challenge in this area is the one-shot setting where only one element represents each class. We propose HyperShot - the fusion of kernels and hypernetwork paradigm. Compared to reference approaches that apply a gradientbased adjustment of the parameters, our model aims to switch the classification module parameters depending on the task\u2019s embedding. In practice, we utilize a hypernetwork, which takes the aggregated information from support data and returns the classifier\u2019s parameters handcrafted for the considered problem. Moreover, we introduce the kernel-based representation of the support examples delivered to hypernetwork to create the parameters of the classification module. Consequently, we rely on relations between embeddings of the support examples instead of direct feature values provided by the backbone models. Thanks to this approach, our model can adapt to highly different tasks.*",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "46220915",
                        "name": "Marcin Sendera"
                    },
                    {
                        "authorId": "147572870",
                        "name": "Marcin Przewiezlikowski"
                    },
                    {
                        "authorId": "2131182370",
                        "name": "Konrad Karanowski"
                    },
                    {
                        "authorId": "3027512",
                        "name": "Maciej Zi\u0229ba"
                    },
                    {
                        "authorId": "145541197",
                        "name": "J. Tabor"
                    },
                    {
                        "authorId": "1790922",
                        "name": "P. Spurek"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In this work, we leverage the tools of NTK from [26, 37] to analyze MAML in the few-shot learning setting, and our analysis can be easily generalized to other variants of MAML such as [9, 50, 51]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9bfa1d2e606944a3fd0899db9ed544b992fa4b0f",
                "externalIds": {
                    "DBLP": "conf/cvpr/WangW0022",
                    "ArXiv": "2203.09137",
                    "DOI": "10.1109/CVPR52688.2022.00957",
                    "CorpusId": 247518767
                },
                "corpusId": 247518767,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9bfa1d2e606944a3fd0899db9ed544b992fa4b0f",
                "title": "Global Convergence of MAML and Theory-Inspired Neural Architecture Search for Few-Shot Learning",
                "abstract": "Model-agnostic meta-learning (MAML) and its variants have become popular approaches for few-shot learning. However, due to the non-convexity of deep neural nets (DNNs) and the bi-level formulation of MAML, the theoretical properties of MAML with DNNs remain largely unknown. In this paper, we first prove that MAML with over-parameterized DNNs is guaranteed to converge to global optima at a linear rate. Our convergence analysis indicates that MAML with over-parameterized DNNs is equivalent to kernel regression with a novel class of kernels, which we name as Meta Neural Tangent Kernels (MetaNTK). Then, we propose MetaNTK-NAS, a new training-free neural architecture search (NAS) method for few-shot learning that uses MetaNTK to rank and select architectures. Empirically, we compare our MetaNTK-NAS with previous NAS methods on two popular few-shot learning benchmarks, miniImageNet, and tieredImageNet. We show that the performance of MetaNTK-NAS is comparable or better than the state-of-the-art NAS method designed for few-shot learning while enjoying more than 100x speedup. We believe the efficiency of MetaNTK-NAS makes itself more practical for many real-world tasks. Our code is released at github.com/YiteWang/MetaNTK-NAS.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2029142",
                        "name": "Haoxiang Wang"
                    },
                    {
                        "authorId": "2159213654",
                        "name": "Yite Wang"
                    },
                    {
                        "authorId": "153899948",
                        "name": "Ruoyu Sun"
                    },
                    {
                        "authorId": "71788673",
                        "name": "Bo Li"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "732e57698f9d50586a8006ff0e6467d07727ec6f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-09064",
                    "ArXiv": "2203.09064",
                    "DOI": "10.1109/CVPR52688.2022.00891",
                    "CorpusId": 247519123
                },
                "corpusId": 247519123,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/732e57698f9d50586a8006ff0e6467d07727ec6f",
                "title": "Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-shot Learning",
                "abstract": "This paper presents new hierarchically cascaded transformers that can improve data efficiency through attribute surrogates learning and spectral tokens pooling. Vision transformers have recently been thought of as a promising alternative to convolutional neural networks for visual recognition. But when there is no sufficient data, it gets stuck in overfitting and shows inferior performance. To improve data efficiency, we propose hierarchically cascaded transformers that exploit intrinsic image structures through spectral tokens pooling and optimize the learnable parameters through latent attribute surrogates. The intrinsic image structure is utilized to reduce the ambiguity between foreground content and background noise by spectral tokens pooling. And the attribute surrogate learning scheme is designed to benefit from the rich visual information in image-label pairs instead of simple visual concepts assigned by their labels. Our Hierarchically Cascaded Transformers, called HCTransformers, is built upon a self-supervised learning framework DINO and is tested on several popular few-shot learning benchmarks. In the inductive setting, HCTransformers surpass the DINO baseline by a large margin of 9.7% 5-way 1-shot accuracy and 9.17% 5-way 5-shot accuracy on miniImageNet, which demonstrates HCTransformers are efficient to extract discriminative features. Also, HCTransformers show clear advantages over SOTA few-shot classification methods in both 5-way 1-shot and 5-way 5-shot settings on four popular benchmark datasets, including miniImageNet, tieredImageNet, FC100, and CIFAR-FS. The trained weights and codes are available at https://github.com/StomachCold/HCTransformers.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "48479348",
                        "name": "Yang He"
                    },
                    {
                        "authorId": "2159200959",
                        "name": "Weihan Liang"
                    },
                    {
                        "authorId": "2003812225",
                        "name": "Dongyang Zhao"
                    },
                    {
                        "authorId": "2157473801",
                        "name": "Hong-Yu Zhou"
                    },
                    {
                        "authorId": "2390300",
                        "name": "Weifeng Ge"
                    },
                    {
                        "authorId": "1841911",
                        "name": "Yizhou Yu"
                    },
                    {
                        "authorId": "2159070511",
                        "name": "Wenqiang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                ",miniImageNet [50], tieredImageNet [39] and CIFAR-FS [3] whose details are deferred to the supplement.",
                "Here we compare SUN with state-of-the-arts (SoTAs), including CNN based methods and ViT based one, on miniImageNet [50], tieredImageNet [39] and CIFAR-FS [3].",
                "Without introducing extremely complex few-shot learning methods like [54,21], our SUN achieves comparable performance with SoTA on miniImageNet [50], and sets new SoTAs on tieredImageNet [39] and CIFAR-FS [3]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "71f2f7c29a13937dce35644481542a8f7b44368c",
                "externalIds": {
                    "DBLP": "conf/eccv/DongZYZ22",
                    "ArXiv": "2203.07057",
                    "DOI": "10.48550/arXiv.2203.07057",
                    "CorpusId": 247446637
                },
                "corpusId": 247446637,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/71f2f7c29a13937dce35644481542a8f7b44368c",
                "title": "Self-Promoted Supervision for Few-Shot Transformer",
                "abstract": "The few-shot learning ability of vision transformers (ViTs) is rarely investigated though heavily desired. In this work, we empirically find that with the same few-shot learning frameworks, \\eg~Meta-Baseline, replacing the widely used CNN feature extractor with a ViT model often severely impairs few-shot classification performance. Moreover, our empirical study shows that in the absence of inductive bias, ViTs often learn the low-qualified token dependencies under few-shot learning regime where only a few labeled training data are available, which largely contributes to the above performance degradation. To alleviate this issue, for the first time, we propose a simple yet effective few-shot training framework for ViTs, namely Self-promoted sUpervisioN (SUN). Specifically, besides the conventional global supervision for global semantic learning SUN further pretrains the ViT on the few-shot learning dataset and then uses it to generate individual location-specific supervision for guiding each patch token. This location-specific supervision tells the ViT which patch tokens are similar or dissimilar and thus accelerates token dependency learning. Moreover, it models the local semantics in each patch token to improve the object grounding and recognition capability which helps learn generalizable patterns. To improve the quality of location-specific supervision, we further propose two techniques:~1) background patch filtration to filtrate background patches out and assign them into an extra background class; and 2) spatial-consistent augmentation to introduce sufficient diversity for data augmentation while keeping the accuracy of the generated local supervisions. Experimental results show that SUN using ViTs significantly surpasses other few-shot learning frameworks with ViTs and is the first one that achieves higher performance than those CNN state-of-the-arts.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "50660465",
                        "name": "Bowen Dong"
                    },
                    {
                        "authorId": "2153245275",
                        "name": "Pan Zhou"
                    },
                    {
                        "authorId": "143653681",
                        "name": "Shuicheng Yan"
                    },
                    {
                        "authorId": "1724520",
                        "name": "W. Zuo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We evaluate the proposed method on three benchmark datasets, which are mini -ImageNet [33], CUB-200-2011 (CUB) [34] and CIFAR-FS [4].",
                "CIFAR-FS is produced by arbitrarily dividing CIFAR-100 [19] into 64 base, 16 validation and 20 novel classes.",
                "Another line of work [29,30,33,4,17] leverages the characteristics of different distance metrics to classify unknown samples by comparing with embeddings or their variants (e.",
                "We evaluate the proposed method on three benchmark datasets, which are mini -ImageNet [33], CUB-200-2011 (CUB) [34] and CIFAR-FS [4]. mini -ImageNet consists of 100 categories randomly selected from the ImageNet dataset [27] with each category containing 600 images sized 84\u00d784.",
                "%) worse on CIFAR-FS."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "62a7e1991c2f12f99cd30d6b544345a30f94b50e",
                "externalIds": {
                    "DBLP": "conf/eccv/FuCW22",
                    "ArXiv": "2203.06574",
                    "DOI": "10.48550/arXiv.2203.06574",
                    "CorpusId": 247447165
                },
                "corpusId": 247447165,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/62a7e1991c2f12f99cd30d6b544345a30f94b50e",
                "title": "Worst Case Matters for Few-Shot Recognition",
                "abstract": "Few-shot recognition learns a recognition model with very few (e.g., 1 or 5) images per category, and current few-shot learning methods focus on improving the average accuracy over many episodes. We argue that in real-world applications we may often only try one episode instead of many, and hence maximizing the worst-case accuracy is more important than maximizing the average accuracy. We empirically show that a high average accuracy not necessarily means a high worst-case accuracy. Since this objective is not accessible, we propose to reduce the standard deviation and increase the average accuracy simultaneously. In turn, we devise two strategies from the bias-variance tradeoff perspective to implicitly reach this goal: a simple yet effective stability regularization (SR) loss together with model ensemble to reduce variance during fine-tuning, and an adaptability calibration mechanism to reduce the bias. Extensive experiments on benchmark datasets demonstrate the effectiveness of the proposed strategies, which outperforms current state-of-the-art methods with a significant margin in terms of not only average, but also worst-case accuracy. Our code is available at https://github.com/heekhero/ACSR.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2158818865",
                        "name": "Minghao Fu"
                    },
                    {
                        "authorId": "6787938",
                        "name": "Yunhao Cao"
                    },
                    {
                        "authorId": "2155449887",
                        "name": "Jianxin Wu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3aef7e5770fe673fd0570c24acd44d49bc08ee0b",
                "externalIds": {
                    "DBLP": "journals/npl/XuXSLZL22",
                    "DOI": "10.1007/s11063-022-10770-4",
                    "CorpusId": 247373598
                },
                "corpusId": 247373598,
                "publicationVenue": {
                    "id": "03101d6e-e317-48fe-ab55-f82ed4f0727f",
                    "name": "Neural Processing Letters",
                    "type": "journal",
                    "alternate_names": [
                        "Neural Process Lett"
                    ],
                    "issn": "1370-4621",
                    "url": "https://link.springer.com/journal/11063"
                },
                "url": "https://www.semanticscholar.org/paper/3aef7e5770fe673fd0570c24acd44d49bc08ee0b",
                "title": "Co-Learning for Few-Shot Learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1606128526",
                        "name": "Rui Xu"
                    },
                    {
                        "authorId": "2053893677",
                        "name": "Lei Xing"
                    },
                    {
                        "authorId": "47975317",
                        "name": "Shuai Shao"
                    },
                    {
                        "authorId": "2155992419",
                        "name": "Baodi Liu"
                    },
                    {
                        "authorId": "2153279857",
                        "name": "Kai Zhang"
                    },
                    {
                        "authorId": "2109174226",
                        "name": "Weifeng Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR\u2010FS The full name of CIFAR-FS is CIFAR100 Few-Shots, which is the same as Fewshot-CIFAR100 from the CIFAR100 dataset and was first proposed by [51]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2da1d312b2d285f310e94ea22749c8d3b8020920",
                "externalIds": {
                    "PubMedCentral": "8897954",
                    "DOI": "10.1186/s13007-022-00866-2",
                    "CorpusId": 247238210,
                    "PubMed": "35248105"
                },
                "corpusId": 247238210,
                "publicationVenue": {
                    "id": "7218da31-236c-47af-8931-874dcec1be68",
                    "name": "Plant Methods",
                    "type": "journal",
                    "alternate_names": [
                        "Plant Method"
                    ],
                    "issn": "1746-4811",
                    "url": "http://www.plantmethods.com/"
                },
                "url": "https://www.semanticscholar.org/paper/2da1d312b2d285f310e94ea22749c8d3b8020920",
                "title": "A survey of few-shot learning in smart agriculture: developments, applications, and challenges",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109723412",
                        "name": "Jiachen Yang"
                    },
                    {
                        "authorId": "2157484428",
                        "name": "Xiaolan Guo"
                    },
                    {
                        "authorId": "2154900466",
                        "name": "Yang Li"
                    },
                    {
                        "authorId": "13726830",
                        "name": "F. Marinello"
                    },
                    {
                        "authorId": "5677716",
                        "name": "S. Erci\u015fli"
                    },
                    {
                        "authorId": "2157409233",
                        "name": "Zhuo Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following [5], we split the data set into 64 classes for training, 16 classes for validation, and 20 classes for test, respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "11f6953f04ec0d674a4f538ac872d56512d7555a",
                "externalIds": {
                    "ArXiv": "2203.01482",
                    "DBLP": "journals/corr/abs-2203-01482",
                    "DOI": "10.48550/arXiv.2203.01482",
                    "CorpusId": 247222951
                },
                "corpusId": 247222951,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/11f6953f04ec0d674a4f538ac872d56512d7555a",
                "title": "MetaDT: Meta Decision Tree for Interpretable Few-Shot Learning",
                "abstract": "Few-Shot Learning (FSL) is a challenging task, which aims to recognize novel classes with few examples. Recently, lots of methods have been proposed from the perspective of meta-learning and representation learning. However, few works focus on the interpretability of FSL decision process. In this paper, we take a step towards the interpretable FSL by proposing a novel meta-learning based decision tree framework, namely, MetaDT. In particular, the FSL interpretability is achieved from two aspects, i.e., a concept aspect and a visual aspect. On the concept aspect, we first introduce a tree-like concept hierarchy as FSL prior. Then, resorting to the prior, we split each few-shot task to a set of subtasks with different concept levels and then perform class prediction via a model of decision tree. The advantage of such design is that a sequence of high-level concept decisions that lead up to a final class prediction can be obtained, which clarifies the FSL decision process. On the visual aspect, a set of subtask-specific classifiers with visual attention mechanism is designed to perform decision at each node of the decision tree. As a result, a subtask-specific heatmap visualization can be obtained to achieve the decision interpretability of each tree node. At last, to alleviate the data scarcity issue of FSL, we regard the prior of concept hierarchy as an undirected graph, and then design a graph convolution-based decision tree inference network as our meta-learner to infer parameters of the decision tree. Extensive experiments on performance comparison and interpretability analysis show superiority of our MetaDT.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "121178411",
                        "name": "Baoquan Zhang"
                    },
                    {
                        "authorId": "2152631472",
                        "name": "Hao Jiang"
                    },
                    {
                        "authorId": "48569885",
                        "name": "Xutao Li"
                    },
                    {
                        "authorId": "2903685",
                        "name": "Shanshan Feng"
                    },
                    {
                        "authorId": "144782498",
                        "name": "Yunming Ye"
                    },
                    {
                        "authorId": "143932236",
                        "name": "Rui Ye"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This yields the exact meta-gradients in constant memory, without any assumption on the optimality of the inner optimization problem, which is necessary when using the normal equations (Bertinetto et al., 2018), or to apply implicit differentiation (Rajeswaran et al., 2019).",
                "This yields the exact meta-gradients in constant memory, without any assumption on the optimality of the inner optimization problem, which is necessary when using the normal equations (Bertinetto et al., 2018), or to apply implicit differentiation (Rajeswaran et al.",
                "With its shared embedding network across tasks, COMLN is also connected to metric-based meta-learning methods (Vinyals et al., 2016; Snell et al., 2017; Sung et al., 2018; Bertinetto et al., 2018; Lee et al., 2019)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2947873e49f3185cf39be950c4f8603a1fa901cd",
                "externalIds": {
                    "ArXiv": "2203.01443",
                    "DBLP": "journals/corr/abs-2203-01443",
                    "DOI": "10.48550/arXiv.2203.01443",
                    "CorpusId": 247222761
                },
                "corpusId": 247222761,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2947873e49f3185cf39be950c4f8603a1fa901cd",
                "title": "Continuous-Time Meta-Learning with Forward Mode Differentiation",
                "abstract": "Drawing inspiration from gradient-based meta-learning methods with infinitely small gradient steps, we introduce Continuous-Time Meta-Learning (COMLN), a meta-learning algorithm where adaptation follows the dynamics of a gradient vector field. Specifically, representations of the inputs are meta-learned such that a task-specific linear classifier is obtained as a solution of an ordinary differential equation (ODE). Treating the learning process as an ODE offers the notable advantage that the length of the trajectory is now continuous, as opposed to a fixed and discrete number of gradient steps. As a consequence, we can optimize the amount of adaptation necessary to solve a new task using stochastic gradient descent, in addition to learning the initial conditions as is standard practice in gradient-based meta-learning. Importantly, in order to compute the exact meta-gradients required for the outer-loop updates, we devise an efficient algorithm based on forward mode differentiation, whose memory requirements do not scale with the length of the learning trajectory, thus allowing longer adaptation in constant memory. We provide analytical guarantees for the stability of COMLN, we show empirically its efficiency in terms of runtime and memory usage, and we illustrate its effectiveness on a range of few-shot image classification problems.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "7636193",
                        "name": "T. Deleu"
                    },
                    {
                        "authorId": "83210513",
                        "name": "David Kanaa"
                    },
                    {
                        "authorId": "31787052",
                        "name": "Leo Feng"
                    },
                    {
                        "authorId": "51922896",
                        "name": "Giancarlo Kerg"
                    },
                    {
                        "authorId": "1865800402",
                        "name": "Y. Bengio"
                    },
                    {
                        "authorId": "49921594",
                        "name": "Guillaume Lajoie"
                    },
                    {
                        "authorId": "145180695",
                        "name": "Pierre-Luc Bacon"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al.",
                "Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al. (2018); Shaban et al.",
                "Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al. (2018); Shaban et al. (2019), actors and critics in reinforcement learning Konda & Tsitsiklis (2000); Hong et al. (2020), and model architectures and weights in neural architecture search Liu et al.",
                "Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al.",
                "Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al.\u2026",
                "Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al. (2018); Shaban et al. (2019), actors and critics in reinforcement learning Konda & Tsitsiklis (2000); Hong et al. (2020), and model architectures and weights in neural architecture search Liu et al. (2018). Mathematically, bilevel optimization captures intrinsic hierarchical structures in those machine learning models, and can be formulated into the following two-level problem:",
                "Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning Bertinetto et al. (2018); Rajeswaran et al. (2019), hyperparameters and model parameters training in automated hyperparameter tuning Franceschi et al. (2018); Shaban et al. (2019), actors and critics in reinforcement learning Konda & Tsitsiklis (2000); Hong et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0d1277bf6d79e436a9ce39c565024cc74ee1d020",
                "externalIds": {
                    "ArXiv": "2203.01123",
                    "CorpusId": 249494543
                },
                "corpusId": 249494543,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0d1277bf6d79e436a9ce39c565024cc74ee1d020",
                "title": "A Primal-Dual Approach to Bilevel Optimization with Multiple Inner Minima",
                "abstract": "Bilevel optimization has found extensive applications in modern machine learning problems such as hyperparameter optimization, neural architecture search, meta-learning, etc. While bilevel problems with a unique inner minimal point (e.g., where the inner function is strongly convex) are well understood, such a problem with multiple inner minimal points remains to be challenging and open. Existing algorithms designed for such a problem were applicable to restricted situations and do not come with a full guarantee of convergence. In this paper, we adopt a reformulation of bilevel optimization to constrained optimization, and solve the problem via a primal-dual bilevel optimization (PDBO) algorithm. PDBO not only addresses the multiple inner minima challenge, but also features fully first-order efficiency without involving second-order Hessian and Jacobian computations, as opposed to most existing gradient-based bilevel algorithms. We further characterize the convergence rate of PDBO, which serves as the first known non-asymptotic convergence guarantee for bilevel optimization with multiple inner minima. Our experiments demonstrate desired performance of the proposed approach.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "143827145",
                        "name": "Daouda Sow"
                    },
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "11701175",
                        "name": "Ziwei Guan"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0fd08c1237f80d96a6618d93cb1292b45b9f09fc",
                "externalIds": {
                    "DBLP": "conf/cvpr/AfhamDDDTR22",
                    "ArXiv": "2203.00680",
                    "DOI": "10.1109/CVPR52688.2022.00967",
                    "CorpusId": 247187696
                },
                "corpusId": 247187696,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0fd08c1237f80d96a6618d93cb1292b45b9f09fc",
                "title": "CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding",
                "abstract": "Manual annotation of large-scale point cloud dataset for varying tasks such as 3D object classification, segmentation and detection is often laborious owing to the irregular structure of point clouds. Self-supervised learning, which operates without any human labeling, is a promising approach to address this issue. We observe in the real world that humans are capable of mapping the visual concepts learnt from 2D images to understand the 3D world. Encouraged by this insight, we propose CrossPoint, a simple cross-modal contrastive learning approach to learn transferable 3D point cloud representations. It enables a 3D-2D correspondence of objects by maximizing agreement between point clouds and the corresponding rendered 2D image in the invariant space, while encouraging invariance to transformations in the point cloud modality. Our joint training objective combines the feature correspondences within and across modalities, thus ensembles a rich learning signal from both 3D point cloud and 2D image modalities in a self-supervised fashion. Experimental results show that our approach outperforms the previous unsupervised learning methods on a diverse range of downstream tasks including 3D object classification and segmentation. Further, the ablation studies validate the potency of our approach for a better point cloud understanding. Code and pretrained models are available at https://github.com/MohamedAfham/CrossPoint.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2084548724",
                        "name": "Mohamed Afham"
                    },
                    {
                        "authorId": "1825640352",
                        "name": "Isuru Dissanayake"
                    },
                    {
                        "authorId": "2156789747",
                        "name": "Dinithi Dissanayake"
                    },
                    {
                        "authorId": "2088382219",
                        "name": "A. Dharmasiri"
                    },
                    {
                        "authorId": "3153007",
                        "name": "Kanchana Thilakarathna"
                    },
                    {
                        "authorId": "144952844",
                        "name": "R. Rodrigo"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c04fc38ebaf3b02195fbbf140463888bf85ac692",
                "externalIds": {
                    "DBLP": "journals/ijon/LiangQSQYZ22",
                    "DOI": "10.1016/j.neucom.2022.03.029",
                    "CorpusId": 247458206
                },
                "corpusId": 247458206,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c04fc38ebaf3b02195fbbf140463888bf85ac692",
                "title": "Multi-modal interactive attention and dual progressive decoding network for RGB-D/T salient object detection",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "46992126",
                        "name": "Yanhua Liang"
                    },
                    {
                        "authorId": "1783055",
                        "name": "G. Qin"
                    },
                    {
                        "authorId": "2118254956",
                        "name": "Minghui Sun"
                    },
                    {
                        "authorId": "2154283239",
                        "name": "Jun Qin"
                    },
                    {
                        "authorId": "2112299355",
                        "name": "Jie Yan"
                    },
                    {
                        "authorId": "2155968391",
                        "name": "Zhonghan Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "17ce12cd734ccb49a507d8f8b4263123cf217b28",
                "externalIds": {
                    "DOI": "10.1109/ICNLP55136.2022.00041",
                    "CorpusId": 252396554
                },
                "corpusId": 252396554,
                "publicationVenue": {
                    "id": "8a6e871b-6c73-419c-98a8-27e437270a12",
                    "name": "ICON",
                    "type": "conference",
                    "alternate_names": [
                        "ICNLP",
                        "Int conf nat lang process",
                        "International conference natural language processing",
                        "Int Conf Nat Lang Process",
                        "TAL",
                        "IEEE International Conference on Networks",
                        "IEEE Int Conf Netw",
                        "International Conference on Natural Language Processing"
                    ],
                    "issn": "1361-8113",
                    "url": "http://www.icohtec.org/publications-icon.html",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conhome/1000494/all-proceedings",
                        "http://www.wikicfp.com/cfp/program?id=1360",
                        "http://www.jstor.org/journal/icon"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/17ce12cd734ccb49a507d8f8b4263123cf217b28",
                "title": "Few-Shot Image Classification Based on Asymmetric Convolution and Attention Mechanism",
                "abstract": "Deep learning has achieved great success in the field of image processing, but it is often difficult to achieve good results when the amount of annotation data is small, and it is prone to overfitting. Few-shot learning can effectively solve this problem. The existing few-shot image classification models usually lead to a large computational loss, and the design of the network structure is complicated and costly. In addition, they do not pay attention to the key features of the image. To solve the above problems, this paper proposes a few-shot image classification method based on asymmetric convolution and attention mechanism. Through replacing the standard $3\\times3$ convolution kernel with asymmetric convolution blocks, the feature extraction ability of the model is improved without increasing additional computational consumption. Secondly, the SENet (Squeeze-and-Excitation Networks) attention mechanism is introduced to explicitly construct the correlation between feature channels, so that the salient features of the image are highlighted and emphasized. Finally, the K-Nearest Neighbor (KNN) is used to calculate the similarity between the query image and the category. A large number of experimental results show that the proposed algorithm performs well in the task of few-shot image classification, which verifies the effectiveness and superiority of the algorithm.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1679704",
                        "name": "Y. Liu"
                    },
                    {
                        "authorId": "2153528246",
                        "name": "Hengchang Zhang"
                    },
                    {
                        "authorId": "2145436891",
                        "name": "Yixin Yang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "957306f7d8c9dd436575c77f3e98c0cdce33cfe6",
                "externalIds": {
                    "DOI": "10.3390/app12052351",
                    "CorpusId": 247112877
                },
                "corpusId": 247112877,
                "publicationVenue": {
                    "id": "136edf8d-0f88-4c2c-830f-461c6a9b842e",
                    "name": "Applied Sciences",
                    "type": "journal",
                    "alternate_names": [
                        "Appl Sci"
                    ],
                    "issn": "2076-3417",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-217814",
                    "alternate_urls": [
                        "http://www.mathem.pub.ro/apps/",
                        "https://www.mdpi.com/journal/applsci",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-217814"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/957306f7d8c9dd436575c77f3e98c0cdce33cfe6",
                "title": "Few-Shot Network Intrusion Detection Using Discriminative Representation Learning with Supervised Autoencoder",
                "abstract": "Recently, intrusion detection methods based on supervised deep learning techniques (DL) have seen widespread adoption by the research community, as a result of advantages, such as the ability to learn useful feature representations from input data without excessive manual intervention. However, these techniques require large amounts of data to generalize well. Collecting a large-scale malicious sample is non-trivial, especially in the modern day with its constantly evolving landscape of cyber-threats. On the other hand, collecting a few-shot of malicious samples is more realistic in practical settings, as in cases such as zero-day attacks, where security agents are only able to intercept a limited number of such samples. Hence, intrusion detection methods based on few-shot learning is emerging as an alternative to conventional supervised learning approaches to simulate more realistic settings. Therefore, in this paper, we propose a novel method that leverages discriminative representation learning with a supervised autoencoder to achieve few-shot intrusion detection. Our approach is implemented in two stages: we first train a feature extractor model with known classes of malicious samples using a discriminative autoencoder, and then in the few-shot detection stage, we use the trained feature extractor model to fit a classifier with a few-shot examples of the novel attack class. We are able to achieve detection rates of 99.5% and 99.8% for both the CIC-IDS2017 and NSL-KDD datasets, respectively, using only 10 examples of an unseen attack.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "117507012",
                        "name": "A. Iliyasu"
                    },
                    {
                        "authorId": "9322160",
                        "name": "Usman Alhaji Abdurrahman"
                    },
                    {
                        "authorId": "2149968853",
                        "name": "Lirong Zheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Because training models that can perform well in FSL tasks is difficult, meta-learning frameworks such as those of [2] were developed to transfer knowledge from the meta-training stage to the meta-testing stage.",
                "Authors in [2] developed a deep neural network augmented with conventional learning components.",
                "Unlike the metric-based approach, recent optimization-based modeling approaches estimate parameters using a parameterized predictor together with a feature-extractor [2, 11].",
                "Following in the footsteps of [2], the authors of \u201cMetaOptNetSVM\u201d [11] used a support-vector machine instead of ridge regression for meta-learning."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2a18be1960d4293de900933813050ef36426cba6",
                "externalIds": {
                    "DBLP": "conf/icmlc2/AlsadhanH22",
                    "DOI": "10.1145/3529836.3529914",
                    "CorpusId": 249891801
                },
                "corpusId": 249891801,
                "publicationVenue": {
                    "id": "d79c0d2a-37de-4287-87e7-1e57576dcae7",
                    "name": "International Conference on Machine Learning and Computing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Mach Learn Cybern",
                        "International Conference on Machine Learning and Cybernetics",
                        "International Conference Machine Learning and Computing",
                        "Int Conf Mach Learn Comput",
                        "ICMLC"
                    ],
                    "url": "http://www.icmlc.com/"
                },
                "url": "https://www.semanticscholar.org/paper/2a18be1960d4293de900933813050ef36426cba6",
                "title": "Few-Shot Learning in Object Classification using Meta-Learning with Between-Class Attribute Transfer",
                "abstract": "We present a novel framework for the problem of transfer learning between few-shot source and target domains, using synthetic attributes in addition to convolutional neural networks that are pre-trained on larger image corpora. In these corpora, no labeled instances of the target domains are present, though they may contain instances of their superclasses. Using probabilistic inference over predicted classes and inferred attributes, we developed a meta-learning ensemble method that builds upon that of [10]. This paper introduces the new framework BCAT (Between-Class Attribute Transfer), adapting inter-class attribute transfer designed for zero-shot learning (ZSL), combined with fusing transfer learning and probabilistic priors, and thereby extending and improving upon existing deep meta-learning models for FSL. We show how probabilistic learning architectures can be adapted to use state-of-the-field deep learning components in this framework. We applied our technique to four baseline convnet-based FSL ensembles and boosted accuracy by up to 6.24% for 1-shot learning and up to 4.11% for 5-shot learning on the mini-ImageNet dataset, the best result of which is competitive with the current state of the field; using the same technique, we improved accuracy by up to 7.83% for 1-shot learning and up to 3.67% for 5-shot learning on the tiered-ImageNet dataset.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Majed Alsadhan"
                    },
                    {
                        "authorId": "145591174",
                        "name": "W. Hsu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We train MetaOptNet-SVM (Lee et al., 2019) for benchmark datasets CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al., 2018) in 1-, 5-, and 10-shot settings.",
                "On the other hand, CIFAR-FS train and test tasks are more similar, as indicated by the high accuracy, and thus are harder to distinguish; the correlation is worse for all dataset distances.",
                "FC100 is a more challenging variant of CIFAR-FS that was created to reduce similarity between train and test tasks (Oreshkin et al., 2018).",
                "Both CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al., 2018) are few-shot learning benchmarks derived from the CIFAR-100 dataset (Krizhevsky et al., 2009).",
                "CIFAR-FS partitions the classes randomly, while FC100 utilizes the class similarity information (100 classes are grouped into 20 superclasses in CIFAR-100) to reduce the semantic overlap between train and\ntest classes.",
                ", 2019) for benchmark datasets CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "00c1c62577509298d6f6f75bc8d34725943a7418",
                "externalIds": {
                    "ArXiv": "2202.01671",
                    "DBLP": "conf/icml/ShnitzerYGS22",
                    "CorpusId": 246485499
                },
                "corpusId": 246485499,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/00c1c62577509298d6f6f75bc8d34725943a7418",
                "title": "Log-Euclidean Signatures for Intrinsic Distances Between Unaligned Datasets",
                "abstract": "The need for efficiently comparing and representing datasets with unknown alignment spans various fields, from model analysis and comparison in machine learning to trend discovery in collections of medical datasets. We use manifold learning to compare the intrinsic geometric structures of different datasets by comparing their diffusion operators, symmetric positive-definite (SPD) matrices that relate to approximations of the continuous Laplace-Beltrami operator from discrete samples. Existing methods typically assume known data alignment and compare such operators in a pointwise manner. Instead, we exploit the Riemannian geometry of SPD matrices to compare these operators and define a new theoretically-motivated distance based on a lower bound of the log-Euclidean metric. Our framework facilitates comparison of data manifolds expressed in datasets with different sizes, numbers of features, and measurement modalities. Our log-Euclidean signature (LES) distance recovers meaningful structural differences, outperforming competing methods in various application domains.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3393265",
                        "name": "Tal Shnitzer"
                    },
                    {
                        "authorId": "8202372",
                        "name": "Mikhail Yurochkin"
                    },
                    {
                        "authorId": "2403306",
                        "name": "Kristjan H. Greenewald"
                    },
                    {
                        "authorId": "1932072",
                        "name": "J. Solomon"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR FS [1] is a subset of CIFAR 100 [19] dataset which was generated in the same way as miniImageNet and contains 37800 images of 64 categories in the train set and 11400 images of 20 categories in the test set."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "83c98435c3bd08fb7e27fdd610e9a8061681b114",
                "externalIds": {
                    "ArXiv": "2202.01186",
                    "DBLP": "journals/corr/abs-2202-01186",
                    "CorpusId": 246473266
                },
                "corpusId": 246473266,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/83c98435c3bd08fb7e27fdd610e9a8061681b114",
                "title": "Smoothed Embeddings for Certified Few-Shot Learning",
                "abstract": "Randomized smoothing is considered to be the state-of-the-art provable defense against adversarial perturbations. However, it heavily exploits the fact that classifiers map input objects to class probabilities and do not focus on the ones that learn a metric space in which classification is performed by computing distances to embeddings of classes prototypes. In this work, we extend randomized smoothing to few-shot learning models that map inputs to normalized embeddings. We provide analysis of Lipschitz continuity of such models and derive robustness certificate against $\\ell_2$-bounded perturbations that may be useful in few-shot learning scenarios. Our theoretical results are confirmed by experiments on different datasets.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "134451470",
                        "name": "Mikhail Aleksandrovich Pautov"
                    },
                    {
                        "authorId": "2071750582",
                        "name": "Olesya Kuznetsova"
                    },
                    {
                        "authorId": "28082245",
                        "name": "Nurislam Tursynbek"
                    },
                    {
                        "authorId": "1380315305",
                        "name": "Aleksandr Petiushko"
                    },
                    {
                        "authorId": "1738205",
                        "name": "I. Oseledets"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods.",
                "MetaOptNet [Lee et al., 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model.",
                ", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods. 10. HyperTransformer [Zhmoginov et al., 2022] study amortized models based on transformers [Vaswani et al., 2017] and show applications to few-shot classification. 11. Metz et al. [2021] study and emphasize the difficulty of optimizing objectivebased loss with just gradient information due to natural chaotic-based failure models of the amortization model.",
                ", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use.",
                ", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods. 10. HyperTransformer [Zhmoginov et al., 2022] study amortized models based on transformers [Vaswani et al., 2017] and show applications to few-shot classification. 11. Metz et al. [2021] study and emphasize the difficulty of optimizing objectivebased loss with just gradient information due to natural chaotic-based failure models of the amortization model. They focus on iterated dynamical systems and study where chaotic losses arise in physics and meta-learning. They identify the spectrum of the Jacobian as one source of these issues and give suggestions for remedying these undesirable behaviors to have learning systems that are well-behaved and stable. 12. Metz et al. [2019b] learn optimizers for robust classification tasks. They find that optimizers can uncover ways of quickly finding robust parameterizations that generalize to settings beyond the corruptions used during training. 13. Metz et al. [2019a] study semi-amortized optimization of convolutional architectures and identify and focus on key issues of 1) biased gradients from truncated BPTT and 2) exploding gradient norms from unrolling for many timesteps. They overcome both of these issues by optimizing the smoothed loss in eq. (2.14) with a variant of the gradient estimator proposed in Parmas et al. [2018] for reinforcement learning.",
                ", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods. 10. HyperTransformer [Zhmoginov et al., 2022] study amortized models based on transformers [Vaswani et al., 2017] and show applications to few-shot classification. 11. Metz et al. [2021] study and emphasize the difficulty of optimizing objectivebased loss with just gradient information due to natural chaotic-based failure models of the amortization model. They focus on iterated dynamical systems and study where chaotic losses arise in physics and meta-learning. They identify the spectrum of the Jacobian as one source of these issues and give suggestions for remedying these undesirable behaviors to have learning systems that are well-behaved and stable. 12. Metz et al. [2019b] learn optimizers for robust classification tasks. They find that optimizers can uncover ways of quickly finding robust parameterizations that generalize to settings beyond the corruptions used during training. 13. Metz et al. [2019a] study semi-amortized optimization of convolutional architectures and identify and focus on key issues of 1) biased gradients from truncated BPTT and 2) exploding gradient norms from unrolling for many timesteps.",
                ", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model.",
                ", 2019b] and R2D2 [Bertinetto et al., 2019] consider semi-amortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model. 8. Almost No Inner Loop by Raghu et al. [2020] study what parameters should be adapted within the amortization model and demonstrate settings where adapting only the final layer performs well, indicating that the shared model between tasks works well because it is learning shared features for all the tasks to use. 9. Wang et al. [2021] further connect gradient-based meta learning methods to multi-task learning methods. 10. HyperTransformer [Zhmoginov et al., 2022] study amortized models based on transformers [Vaswani et al., 2017] and show applications to few-shot classification. 11. Metz et al. [2021] study and emphasize the difficulty of optimizing objectivebased loss with just gradient information due to natural chaotic-based failure models of the amortization model. They focus on iterated dynamical systems and study where chaotic losses arise in physics and meta-learning. They identify the spectrum of the Jacobian as one source of these issues and give suggestions for remedying these undesirable behaviors to have learning systems that are well-behaved and stable. 12. Metz et al. [2019b] learn optimizers for robust classification tasks."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2e4427778f0d2ed3f2b5bd9a52e882f6b7f0432a",
                "externalIds": {
                    "ArXiv": "2202.00665",
                    "DBLP": "journals/ftml/Amos23",
                    "DOI": "10.1561/9781638282099",
                    "CorpusId": 258298859
                },
                "corpusId": 258298859,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2e4427778f0d2ed3f2b5bd9a52e882f6b7f0432a",
                "title": "Tutorial on Amortized Optimization",
                "abstract": "Optimization is a ubiquitous modeling tool and is often deployed in settings which repeatedly solve similar instances of the same problem. Amortized optimization methods use learning to predict the solutions to problems in these settings, exploiting the shared structure between similar problem instances. These methods have been crucial in variational inference and reinforcement learning and are capable of solving optimization problems many orders of magnitudes times faster than traditional optimization methods that do not use amortization. This tutorial presents an introduction to the amortized optimization foundations behind these advancements and overviews their applications in variational inference, sparse coding, gradient-based meta-learning, control, reinforcement learning, convex optimization, optimal transport, and deep equilibrium networks. The source code for this tutorial is available at https://github.com/facebookresearch/amortized-optimization-tutorial.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1773498",
                        "name": "Brandon Amos"
                    }
                ]
            }
        },
        {
            "contexts": [
                "ANIL and related GBML methods (Lee et al., 2019; Bertinetto et al., 2019) restrict Eq."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a9d19372562fb6e5bd31feba5c12feb435acee99",
                "externalIds": {
                    "ArXiv": "2202.01889",
                    "DBLP": "journals/corr/abs-2202-01889",
                    "CorpusId": 246608231
                },
                "corpusId": 246608231,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a9d19372562fb6e5bd31feba5c12feb435acee99",
                "title": "Generalizing to New Physical Systems via Context-Informed Dynamics Model",
                "abstract": "Data-driven approaches to modeling physical systems fail to generalize to unseen systems that share the same general dynamics with the learning domain, but correspond to different physical contexts. We propose a new framework for this key problem, context-informed dynamics adaptation (CoDA), which takes into account the distributional shift across systems for fast and efficient adaptation to new dynamics. CoDA leverages multiple environments, each associated to a different dynamic, and learns to condition the dynamics model on contextual parameters, specific to each environment. The conditioning is performed via a hypernetwork, learned jointly with a context vector from observed data. The proposed formulation constrains the search hypothesis space to foster fast adaptation and better generalization across environments. We theoretically motivate our approach and show state-of-the-art generalization results on a set of nonlinear dynamics, representative of a variety of application domains. We also show, on these systems, that new system parameters can be inferred from context vectors with minimal supervision. Code is available at https://github.com/yuan-yin/CoDA .",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2583878",
                        "name": "Matthieu Kirchmeyer"
                    },
                    {
                        "authorId": "2109472874",
                        "name": "Yuan Yin"
                    },
                    {
                        "authorId": "1853488882",
                        "name": "J\u00e9r\u00e9mie Don\u00e0"
                    },
                    {
                        "authorId": "1800361",
                        "name": "Nicolas Baskiotis"
                    },
                    {
                        "authorId": "1792962",
                        "name": "A. Rakotomamonjy"
                    },
                    {
                        "authorId": "1741426",
                        "name": "P. Gallinari"
                    }
                ]
            }
        },
        {
            "contexts": [
                "3) We conduct extensive experiments on miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), and CIFAR-FS (Bertinetto et al., 2018) datasets where the unlabeled set has in-distribution and out-of-distribution (OOD) classes.",
                "We conduct experiments on three datasets: miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), and CIFAR-FS (Bertinetto et al., 2018).",
                "3, and CIFAR-FS in Tab.",
                ", 2018), and CIFAR-FS (Bertinetto et al., 2018) datasets where the unlabeled set has in-distribution and out-of-distribution (OOD) classes.",
                "CIFAR-FS contains 60,000 images of size 32\u00d732\u00d73 from 100 classes."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "8bb5ac0000bd54ac9caff3932fa50c628b988929",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2201-12928",
                    "ArXiv": "2201.12928",
                    "CorpusId": 246430442
                },
                "corpusId": 246430442,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/8bb5ac0000bd54ac9caff3932fa50c628b988929",
                "title": "PLATINUM: Semi-Supervised Model Agnostic Meta-Learning using Submodular Mutual Information",
                "abstract": "Few-shot classification (FSC) requires training models using a few (typically one to five) data points per class. Meta learning has proven to be able to learn a parametrized model for FSC by training on various other classification tasks. In this work, we propose PLATINUM (semi-suPervised modeL Agnostic meTa-learnIng usiNg sUbmodular Mutual information), a novel semi-supervised model agnostic meta-learning framework that uses the submodular mutual information (SMI) functions to boost the performance of FSC. PLATINUM leverages unlabeled data in the inner and outer loop using SMI functions during meta-training and obtains richer meta-learned parameterizations for meta-test. We study the performance of PLATINUM in two scenarios - 1) where the unlabeled data points belong to the same set of classes as the labeled set of a certain episode, and 2) where there exist out-of-distribution classes that do not belong to the labeled set. We evaluate our method on various settings on the miniImageNet, tieredImageNet and Fewshot-CIFAR100 datasets. Our experiments show that PLATINUM outperforms MAML and semi-supervised approaches like pseduo-labeling for semi-supervised FSC, especially for small ratio of labeled examples per class.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1944093317",
                        "name": "Changbin Li"
                    },
                    {
                        "authorId": "9745898",
                        "name": "S. Kothawade"
                    },
                    {
                        "authorId": "144180429",
                        "name": "F. Chen"
                    },
                    {
                        "authorId": "145074006",
                        "name": "Rishabh K. Iyer"
                    }
                ]
            }
        },
        {
            "contexts": [
                "3 Relation network[33] CVPR 18 InceptionV2 No / 50.",
                "11 Relation net (T)[33] CVPR18 Conv4 No 15 50."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a4be71680409643be941422b88bfeb9f26379638",
                "externalIds": {
                    "DBLP": "journals/ijautcomp/YangLY22",
                    "PubMedCentral": "8777173",
                    "DOI": "10.1007/s11633-022-1320-9",
                    "CorpusId": 246164977
                },
                "corpusId": 246164977,
                "publicationVenue": {
                    "id": "ec733e98-d402-49a3-8cf0-e35b1fecbd84",
                    "name": "International Journal of Automation and Computing",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Autom Comput"
                    ],
                    "issn": "1476-8186",
                    "url": "https://link.springer.com/journal/11633"
                },
                "url": "https://www.semanticscholar.org/paper/a4be71680409643be941422b88bfeb9f26379638",
                "title": "Weakly Correlated Knowledge Integration for Few-shot Image Classification",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2154925588",
                        "name": "Chun Yang"
                    },
                    {
                        "authorId": "2144904390",
                        "name": "Chang-Ping Liu"
                    },
                    {
                        "authorId": "1682664",
                        "name": "Xu-Cheng Yin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [130] is randomly sampled from CIFAR100 by using the same criteria with which miniImageNet has been generated.",
                "Image Datasets without Auxiliary Knowledge for zero-shot learning, as CIFAR-FS, FC100, or domain generalization, as Office-31, Office-Home, and VisDA2017.",
                "CIFAR-FS [10]: CIFAR-FS is randomly sampled from CIFAR-100 [75]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e0ade6a261e6dd079e509c875901b40b53ec0b5d",
                "externalIds": {
                    "ArXiv": "2201.11794",
                    "DBLP": "journals/corr/abs-2201-11794",
                    "DOI": "10.3233/sw-212959",
                    "CorpusId": 245972209
                },
                "corpusId": 245972209,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e0ade6a261e6dd079e509c875901b40b53ec0b5d",
                "title": "A Survey on Visual Transfer Learning using Knowledge Graphs",
                "abstract": "The information perceived via visual observations of real-world phenomena is unstructured and complex. Computer vision (CV) is the field of research that attempts to make use of that information. Recent approaches of CV utilize deep learning (DL) methods as they perform quite well if training and testing domains follow the same underlying data distribution. However, it has been shown that minor variations in the images that occur when these methods are used in the real world can lead to unpredictable and catastrophic errors. Transfer learning is the area of machine learning that tries to prevent these errors. Especially, approaches that augment image data using auxiliary knowledge encoded in language embeddings or knowledge graphs (KGs) have achieved promising results in recent years. This survey focuses on visual transfer learning approaches using KGs, as we believe that KGs are well suited to store and represent any kind of auxiliary knowledge. KGs can represent auxiliary knowledge either in an underlying graph-structured schema or in a vector-based knowledge graph embedding. Intending to enable the reader to solve visual transfer learning problems with the help of specific KG-DL configurations we start with a description of relevant modeling structures of a KG of various expressions, such as directed labeled graphs, hypergraphs, and hyper-relational graphs. We explain the notion of feature extractor, while specifically referring to visual and semantic features. We provide a broad overview of knowledge graph embedding methods and describe several joint training objectives suitable to combine them with high dimensional visual embeddings. The main section introduces four different categories on how a KG can be combined with a DL pipeline: 1) Knowledge Graph as a Reviewer; 2) Knowledge Graph as a Trainee; 3) Knowledge Graph as a Trainer; and 4) Knowledge Graph as a Peer. To help researchers find meaningful evaluation benchmarks, we provide an overview of generic KGs and a set of image processing datasets and benchmarks that include various types of auxiliary knowledge. Last, we summarize related surveys and give an outlook about challenges and open issues for future research.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2100108777",
                        "name": "Sebastian Monka"
                    },
                    {
                        "authorId": "2567075",
                        "name": "Lavdim Halilaj"
                    },
                    {
                        "authorId": "1748257",
                        "name": "Achim Rettinger"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We have many choices, such as logistic regression (Kleinbaum et al. 2002), kernel-based nonlinear model (Liu 2003) and differentiable closed-form solvers (Bertinetto et al. 2018).",
                "2002), kernel-based nonlinear model (Liu 2003) and differentiable closed-form solvers (Bertinetto et al. 2018).",
                "(Lee et al. 2019; Bertinetto et al. 2018) argue that (Bengio 2000; Baydin and Pearlmutter 2014) it is too costly and adopt algorithms with closed-form solutions in the lower-level optimization."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5363ca2113e74a294dbeaf2f309c4fd828a0babd",
                "externalIds": {
                    "ArXiv": "2201.04038",
                    "DBLP": "journals/corr/abs-2201-04038",
                    "DOI": "10.1609/aaai.v36i4.20327",
                    "CorpusId": 245853677
                },
                "corpusId": 245853677,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/5363ca2113e74a294dbeaf2f309c4fd828a0babd",
                "title": "DDG-DA: Data Distribution Generation for Predictable Concept Drift Adaptation",
                "abstract": "In many real-world scenarios, we often deal with streaming data that is sequentially collected over time. Due to the non-stationary nature of the environment, the streaming data distribution may change in unpredictable ways, which is known as the concept drift in the literature. To handle concept drift, previous methods first detect when/where the concept drift happens and then adapt models to fit the distribution of the latest data. However, there are still many cases that some underlying factors of environment evolution are predictable, making it possible to model the future concept drift trend of the streaming data, while such cases are not fully explored in previous work. In this paper, we propose a novel method DDG-DA, that can effectively forecast the evolution of data distribution and improve the performance of models. Specifically, we first train a predictor to estimate the future data distribution, then leverage it to generate training samples, and finally train models on the generated data. We conduct experiments on three real-world tasks (forecasting on stock price trend, electricity load and solar irradiance) and obtained significant improvement on multiple widely-used models.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108635193",
                        "name": "Wendi Li"
                    },
                    {
                        "authorId": "2112096484",
                        "name": "Xiao Yang"
                    },
                    {
                        "authorId": "1390517481",
                        "name": "Weiqing Liu"
                    },
                    {
                        "authorId": "2111056280",
                        "name": "Yingce Xia"
                    },
                    {
                        "authorId": "143901037",
                        "name": "J. Bian"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We evaluate the performance of the proposed method using standardized few-shot classification datasets: miniImageNet [1], CUB [19] and CIFAR-FS [20].",
                "The CIFAR-FS dataset is called the CIFAR100 Few-Shots dataset, which is derived from the CIFAR 100 dataset."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "97655f26767871138f59cc306ee160212e260007",
                "externalIds": {
                    "DBLP": "conf/icwcsn/ZhangCZ22",
                    "DOI": "10.1145/3514105.3514106",
                    "CorpusId": 247843700
                },
                "corpusId": 247843700,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/97655f26767871138f59cc306ee160212e260007",
                "title": "Few-shot Learning via Non-negative Representation",
                "abstract": "Due to the uncertainty caused by using a small number of labeled samples, few-shot classification is a challenging problem. In the past few years, many methods have been proposed to solve few-shot classification, among which the method based on transduction has been proved to be the best. According to this idea, in this paper, we propose a new transduction-based method, which is based on the nonnegative representation. In order to obtain the classification results, we minimize the objective function with two items: (1) The first item assigns representation coefficients for each class prototype to obtain the minimum reconstruction error; (2) The second item encourages similar query samples to have consistent label allocation. At the same time, we make non-negative constraints on the representation coefficient to make the representation sparse and discriminative. Using standardized visual benchmarks, we prove that the proposed method can achieve high accuracy in various data sets, inductive and transductive settings, and is robust to the situation that the number of unlabeled samples per class is unbalanced.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2161256018",
                        "name": "Shengxiang Zhang"
                    },
                    {
                        "authorId": "2160936187",
                        "name": "Nan Chen"
                    },
                    {
                        "authorId": "2160917356",
                        "name": "Nan Zhao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "On the basis of transfer learning and metalearning [1], Timothy Hospedales [24] proposed small sample learning [14] to apply to limited labeled data."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fc17499ccff643e0b262f84db0870def7f8c3ebc",
                "externalIds": {
                    "DOI": "10.1007/s11042-021-11472-0",
                    "CorpusId": 254873553
                },
                "corpusId": 254873553,
                "publicationVenue": {
                    "id": "477368e9-7a8e-475a-8c93-6d623797fd06",
                    "name": "Multimedia tools and applications",
                    "type": "journal",
                    "alternate_names": [
                        "Multimedia Tools and Applications",
                        "Multimedia Tool Appl",
                        "Multimedia tool appl"
                    ],
                    "issn": "1380-7501",
                    "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fc17499ccff643e0b262f84db0870def7f8c3ebc",
                "title": "Few-shot learning for skin lesion image classification",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "30268445",
                        "name": "Xu Liu"
                    },
                    {
                        "authorId": "2158259897",
                        "name": "Kai-li Li"
                    },
                    {
                        "authorId": "2163917536",
                        "name": "Hai-ying Luan"
                    },
                    {
                        "authorId": "49337276",
                        "name": "Wenzhe Wang"
                    },
                    {
                        "authorId": "2111605927",
                        "name": "Zhaoying Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e8612eddae0c17469728884053683ce83eed5493",
                "externalIds": {
                    "DOI": "10.1007/s11704-021-1188-9",
                    "CorpusId": 255386685
                },
                "corpusId": 255386685,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e8612eddae0c17469728884053683ce83eed5493",
                "title": "Improving meta-learning model via meta-contrastive loss",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "51305326",
                        "name": "Pinzhuo Tian"
                    },
                    {
                        "authorId": "2145974630",
                        "name": "Yang Gao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "407b1fadde1dc7838f0db4fcc8066006ef7c7ad0",
                "externalIds": {
                    "DBLP": "journals/npl/XuLLZL22",
                    "DOI": "10.1007/s11063-021-10684-7",
                    "CorpusId": 245653343
                },
                "corpusId": 245653343,
                "publicationVenue": {
                    "id": "03101d6e-e317-48fe-ab55-f82ed4f0727f",
                    "name": "Neural Processing Letters",
                    "type": "journal",
                    "alternate_names": [
                        "Neural Process Lett"
                    ],
                    "issn": "1370-4621",
                    "url": "https://link.springer.com/journal/11063"
                },
                "url": "https://www.semanticscholar.org/paper/407b1fadde1dc7838f0db4fcc8066006ef7c7ad0",
                "title": "DMH-FSL: Dual-Modal Hypergraph for Few-Shot Learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1606128526",
                        "name": "Rui Xu"
                    },
                    {
                        "authorId": "2155992419",
                        "name": "Baodi Liu"
                    },
                    {
                        "authorId": "2152840019",
                        "name": "Xiaoping Lu"
                    },
                    {
                        "authorId": "2153279857",
                        "name": "Kai Zhang"
                    },
                    {
                        "authorId": "2109174226",
                        "name": "Weifeng Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We consider four different datasets: (i) Mini-ImageNet (Vinyals et al., 2016); (ii) CIFAR-FS (Bertinetto et al., 2019); (iii) FC-100 (Oreshkin et al., 2018); and (iv) EMNIST (balanced) (Cohen et al., 2017).",
                "Throughout the experiments, we consider four different datasets: (i) MiniImageNet (Vinyals et al., 2016) and (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al., 2018) and EMNIST (balanced) (Cohen et al., 2017).",
                ", 2016) and (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al.",
                ", 2016); (ii) CIFAR-FS (Bertinetto et al., 2019); (iii) FC-100 (Oreshkin et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "8f0d609618838b20631469ffa7fc78928bba8ca0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-15121",
                    "ArXiv": "2112.15121",
                    "CorpusId": 245634209
                },
                "corpusId": 245634209,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/8f0d609618838b20631469ffa7fc78928bba8ca0",
                "title": "On the Role of Neural Collapse in Transfer Learning",
                "abstract": "We study the ability of foundation models to learn representations for classification that are transferable to new, unseen classes. Recent results in the literature show that representations learned by a single classifier over many classes are competitive on few-shot learning problems with representations learned by special-purpose algorithms designed for such problems. In this paper we provide an explanation for this behavior based on the recently observed phenomenon that the features learned by overparameterized classification networks show an interesting clustering property, called neural collapse. We demonstrate both theoretically and empirically that neural collapse generalizes to new samples from the training classes, and -- more importantly -- to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the few-shot setting.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "9923405",
                        "name": "Tomer Galanti"
                    },
                    {
                        "authorId": "2090601385",
                        "name": "Andr'as Gyorgy"
                    },
                    {
                        "authorId": "144154444",
                        "name": "Marcus Hutter"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d75ebdbdcbe67c9ae801b27ae65c8daf5da1a0d6",
                "externalIds": {
                    "ArXiv": "2112.13989",
                    "DBLP": "journals/corr/abs-2112-13989",
                    "CorpusId": 245537788
                },
                "corpusId": 245537788,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d75ebdbdcbe67c9ae801b27ae65c8daf5da1a0d6",
                "title": "Associative Adversarial Learning Based on Selective Attack",
                "abstract": "A human's attention can intuitively adapt to corrupted areas of an image by recalling a similar uncorrupted image they have previously seen. This observation motivates us to improve the attention of adversarial images by considering their clean counterparts. To accomplish this, we introduce Associative Adversarial Learning (AAL) into adversarial learning to guide a selective attack. We formulate the intrinsic relationship between attention and attack (perturbation) as a coupling optimization problem to improve their interaction. This leads to an attention backtracking algorithm that can effectively enhance the attention's adversarial robustness. Our method is generic and can be used to address a variety of tasks by simply choosing different kernels for the associative attention that select other regions for a specific attack. Experimental results show that the selective attack improves the model's performance. We show that our method improves the recognition accuracy of adversarial training on ImageNet by 8.32% compared with the baseline. It also increases object detection mAP on PascalVOC by 2.02% and recognition accuracy of few-shot learning on miniImageNet by 1.63%.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2041702379",
                        "name": "Runqi Wang"
                    },
                    {
                        "authorId": "2067781481",
                        "name": "Xiaoyue Duan"
                    },
                    {
                        "authorId": "1740430",
                        "name": "Baochang Zhang"
                    },
                    {
                        "authorId": "3324218",
                        "name": "Shenjun Xue"
                    },
                    {
                        "authorId": "50017718",
                        "name": "Wentao Zhu"
                    },
                    {
                        "authorId": "48471936",
                        "name": "D. Doermann"
                    },
                    {
                        "authorId": "1822413",
                        "name": "G. Guo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We report few-shot classification within domain by using Conv-4, WRN-28-10, ResNet-12 and ResNet-18 in Table 16.",
                "For the within-domain experiments, we use two backbones: Conv-4 and ResNet-12.",
                "The results using ResNet-12 are reported in Table 5, the results using Conv-4 are reported in the appendix B.5.",
                "We also provide results for few-shot within domain using a ResNet-12 backbone under data augmentation in the meta-training stage following (Zhang et al., 2021).",
                "Following the prior works, we configure the ResNet-12 backbone as 4 residual blocks.",
                "To gain better performance, ResNet-12 (Bertinetto et al., 2019; Gidaris & Komodakis, 2018; Yoon et al., 2018) is also widely reported for few-shot classification."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "a69cf91f0a4aa8ce4306f7b3bc59629631fa35f8",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-08181",
                    "ArXiv": "2112.08181",
                    "CorpusId": 245144606
                },
                "corpusId": 245144606,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a69cf91f0a4aa8ce4306f7b3bc59629631fa35f8",
                "title": "Hierarchical Variational Memory for Few-shot Learning Across Domains",
                "abstract": "Neural memory enables fast adaptation to new tasks with just a few training samples. Existing memory models store features only from the single last layer, which does not generalize well in presence of a domain shift between training and test distributions. Rather than relying on a flat memory, we propose a hierarchical alternative that stores features at different semantic levels. We introduce a hierarchical prototype model, where each level of the prototype fetches corresponding information from the hierarchical memory. The model is endowed with the ability to flexibly rely on features at different semantic levels if the domain shift circumstances so demand. We meta-learn the model by a newly derived hierarchical variational inference framework, where hierarchical memory and prototypes are jointly optimized. To explore and exploit the importance of different semantic levels, we further propose to learn the weights associated with the prototype at each level in a data-driven way, which enables the model to adaptively choose the most generalizable features. We conduct thorough ablation studies to demonstrate the effectiveness of each component in our model. The new state-of-the-art performance on cross-domain and competitive performance on traditional few-shot classification further substantiates the benefit of hierarchical variational memory.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "46941376",
                        "name": "Yingjun Du"
                    },
                    {
                        "authorId": "34798935",
                        "name": "Xiantong Zhen"
                    },
                    {
                        "authorId": "144082425",
                        "name": "Ling Shao"
                    },
                    {
                        "authorId": "145404204",
                        "name": "Cees G. M. Snoek"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "06ddbe4affb617135c3f9edd77e5a6d67a14f45a",
                "externalIds": {
                    "DBLP": "conf/bigdataconf/TuP21",
                    "DOI": "10.1109/BigData52589.2021.9671673",
                    "CorpusId": 245934659
                },
                "corpusId": 245934659,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/06ddbe4affb617135c3f9edd77e5a6d67a14f45a",
                "title": "A Dropout Style Model Augmentation for Cross Domain Few-Shot Learning",
                "abstract": "We focus on few-shot learning with cross-domain shift. While most existing few-shot learning assumed similar distributions between the source and target data, we aim to deal with the scenarios when we need to experience domain shift, the scenarios that fit to many real-world applications such as customization from lab-made toys to industrial products. More specifically, we consider the domain shift when we do not have much overlap between the source and the target domains, such as they do not have many overlapped classes or they do not have many common features. In fact, we experience significant improvement from existing work especially when we do not have much overlap between the source and the target domains. We propose a simple yet effective dropout-style method given a model that has been trained based on low-complexity concept from the source domain. The main idea is to sample several sub-networks by dropping neurons (or feature maps) to construct a bunch of models with diverse features for the target domain. Afterward, we choose the most suitable sub-networks to construct the ensemble for the target domain learning. The proposed method requires almost no external storage other than the original model for the source domain learning. As another advantage over other learning methods is the computation in the method is highly parallelizable for the purpose of efficiency. To evaluate the proposed method, we conduct experiments and show that the proposed method can be in cooperated with many metric-based few-shot learning base models, with consistent improvement under various settings.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2149929591",
                        "name": "Pei-Cheng Tu"
                    },
                    {
                        "authorId": "1771220",
                        "name": "H. Pao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, the typical metatesting stage just adapts the last classification head with the frozen backbone, which is commonly a fully connected (FC) layer [6]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "81dd4ae412a5f607bdad0a34815dd6f40f98d7a5",
                "externalIds": {
                    "ArXiv": "2112.06320",
                    "CorpusId": 253802180
                },
                "corpusId": 253802180,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/81dd4ae412a5f607bdad0a34815dd6f40f98d7a5",
                "title": "Anomaly Crossing: New Horizons for Video Anomaly Detection as Cross-domain Few-shot Learning",
                "abstract": "Video anomaly detection aims to identify abnormal events that occurred in videos. Since anomalous events are relatively rare, it is not feasible to collect a balanced dataset and train a binary classifier to solve the task. Thus, most previous approaches learn only from normal videos using unsupervised or semi-supervised methods. Obviously, they are limited in capturing and utilizing discriminative abnormal characteristics, which leads to compromised anomaly detection performance. In this paper, to address this issue, we propose a new learning paradigm by making full use of both normal and abnormal videos for video anomaly detection. In particular, we formulate a new learning task: cross-domain few-shot anomaly detection, which can transfer knowledge learned from numerous videos in the source domain to help solve few-shot abnormality detection in the target domain. Concretely, we leverage self-supervised training on the target normal videos to reduce the domain gap and devise a meta context perception module to explore the video context of the event in the few-shot setting. Our experiments show that our method significantly outperforms baseline methods on DoTA and UCF-Crime datasets, and the new task contributes to a more practical training paradigm for anomaly detection.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2113639896",
                        "name": "Guangyu Sun"
                    },
                    {
                        "authorId": "1508234044",
                        "name": "Zhangpu Liu"
                    },
                    {
                        "authorId": "2152129821",
                        "name": "Lianggong Wen"
                    },
                    {
                        "authorId": "2112852471",
                        "name": "Jing Shi"
                    },
                    {
                        "authorId": "2026123",
                        "name": "Chenliang Xu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "60226dc255948dd06a87e54601fe7b2193582bef",
                "externalIds": {
                    "ArXiv": "2112.03494",
                    "DBLP": "journals/corr/abs-2112-03494",
                    "DOI": "10.1007/978-3-031-20044-1_15",
                    "CorpusId": 244920863
                },
                "corpusId": 244920863,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/60226dc255948dd06a87e54601fe7b2193582bef",
                "title": "Learning Instance and Task-Aware Dynamic Kernels for Few Shot Learning",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2146354647",
                        "name": "Rongkai Ma"
                    },
                    {
                        "authorId": "49208246",
                        "name": "Pengfei Fang"
                    },
                    {
                        "authorId": "67080195",
                        "name": "Gilat Avraham"
                    },
                    {
                        "authorId": "2057617710",
                        "name": "Yan Zuo"
                    },
                    {
                        "authorId": "144418842",
                        "name": "T. Drummond"
                    },
                    {
                        "authorId": "1686714",
                        "name": "M. Harandi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In CIFAR-FS and FC100 5-shot, the average improvement are 0.8% and 3.2% respectively.",
                "2018), CIFAR-FS (Bertinetto et al. 2019), and FC100 (Oreshkin, L\u00f3pez, and Lacoste 2018).",
                "We evaluate our method on four widely used few-shot recognition benchmarks: miniImageNet (Vinyals et al. 2016), tieredImageNet (Ren et al. 2018), CIFAR-FS (Bertinetto et al. 2019), and FC100 (Oreshkin, Lo\u0301pez, and Lacoste 2018).",
                "On CIFAR-FS, the improvements over SKD-GEN1 (our implementation) for 1-shot and 5-shot are 0.7% and 0.9%, respectively.",
                "With the combination of distillation loss on the soft-labeled base dataset, our method (Soft LabelHalluc + finetuning) eliminates the overfitting problem yielding 5-shot gains of 5.57%, 3.8% and 5.3% on miniImageNet, CIFAR-FS, and FC100, respec-\ntively, over finetuning with the episode examples only.",
                "The use of soft labels over hard labels contributes 5-shot classification gains of 4.92% in miniImageNet, 4.2% in CIFAR-FS, and 4.8% in FC100.",
                "Though using the arcMax alone yieds an improvement of 1.18% over finetune in miniImageNet, we find that combining arcMax with centroid alignment leads to inferior results in our experimental setup based on ResNet-12 and SGD. AssoAlign with softMax and centroid alignment outperforms finetune by 3.44%, 1.9% and 2.7%, whereas our method outperforms AssoAlign by 2.13%, 1.9% and 3.6% in miniImageNet, CIFAR-FS and FC100 respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "8a1deed670e2361dbc74ee90dedcd5efb3b9264e",
                "externalIds": {
                    "ArXiv": "2112.03340",
                    "DBLP": "conf/aaai/JianT22",
                    "DOI": "10.1609/aaai.v36i6.20659",
                    "CorpusId": 244920807
                },
                "corpusId": 244920807,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/8a1deed670e2361dbc74ee90dedcd5efb3b9264e",
                "title": "Label Hallucination for Few-Shot Classification",
                "abstract": "Few-shot classification requires adapting knowledge learned from a large annotated base dataset to recognize novel unseen classes, each represented by few labeled examples. In such a scenario, pretraining a network with high capacity on the large dataset and then finetuning it on the few examples causes severe overfitting. At the same time, training a simple linear classifier on top of ``frozen'' features learned from the large labeled dataset fails to adapt the model to the properties of the novel classes, effectively inducing underfitting. In this paper we propose an alternative approach to both of these two popular strategies. First, our method pseudo-labels the entire large dataset using the linear classifier trained on the novel classes. This effectively ``hallucinates'' the novel classes in the large dataset, despite the novel categories not being present in the base database (novel and base classes are disjoint). Then, it finetunes the entire model with a distillation loss on the pseudo-labeled base examples, in addition to the standard cross-entropy loss on the novel dataset. This step effectively trains the network to recognize contextual and appearance cues that are useful for the novel-category recognition but using the entire large-scale base dataset and thus overcoming the inherent data-scarcity problem of few-shot learning. Despite the simplicity of the approach, we show that that our method outperforms the state-of-the-art on four well-established few-shot classification benchmarks. The code is available at https://github.com/yiren-jian/LabelHalluc.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "19258096",
                        "name": "Yiren Jian"
                    },
                    {
                        "authorId": "1732879",
                        "name": "L. Torresani"
                    }
                ]
            }
        },
        {
            "contexts": [
                "2011), CIFAR-FS (Bertinetto et al. 2018) and Fewshot-CIFAR100 (FC100) (Oreshkin, L\u00f3pez, and Lacoste 2018).",
                "\u2026evaluate our approach across five standard benchmarks, i.e., mini-ImageNet (Ravi and Larochelle 2016), tiered-ImageNet (Ren et al. 2018), Caltech-UCSD Birds-200-2011 (CUB) (Wah et al. 2011), CIFAR-FS (Bertinetto et al. 2018) and Fewshot-CIFAR100 (FC100) (Oreshkin, Lo\u0301pez, and Lacoste 2018).",
                "Both CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, L\u00f3pez, and Lacoste 2018) are modified from the CIFAR-100 dataset containing 100 classes, with 600 samples per class.",
                "Both CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, Lo\u0301pez, and Lacoste 2018) are modified from the CIFAR-100 dataset containing 100 classes, with 600 samples per class."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "8fcf2c89df04c9cf55d2a8d50567f7716b08e006",
                "externalIds": {
                    "ArXiv": "2112.01719",
                    "DBLP": "conf/aaai/MaFDH22",
                    "DOI": "10.1609/aaai.v36i2.20087",
                    "CorpusId": 244923783
                },
                "corpusId": 244923783,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/8fcf2c89df04c9cf55d2a8d50567f7716b08e006",
                "title": "Adaptive Poincar\u00e9 Point to Set Distance for Few-Shot Classification",
                "abstract": "Learning and generalizing from limited examples, i.e., few-shot learning, is of core importance to many real-world vision applications. A principal way of achieving few-shot learning is to realize an embedding where samples from different classes are distinctive. Recent studies suggest that embedding via hyperbolic geometry enjoys low distortion for hierarchical and structured data, making it suitable for few-shot learning. In this paper, we propose to learn a context-aware hyperbolic metric to characterize the distance between a point and a set associated with a learned set to set distance. To this end, we formulate the metric as a weighted sum on the tangent bundle of the hyperbolic space and develop a mechanism to obtain the weights adaptively, based on the constellation of the points. This not only makes the metric local but also dependent on the task in hand, meaning that the metric will adapt depending on the samples that it compares. We empirically show that such metric yields robustness in the presence of outliers and achieves a tangible improvement over baseline models. This includes the state-of-the-art results on five popular few-shot classification benchmarks, namely mini-ImageNet, tiered-ImageNet, Caltech-UCSD Birds-200-2011(CUB), CIFAR-FS, and FC100.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2146354647",
                        "name": "Rongkai Ma"
                    },
                    {
                        "authorId": "49208246",
                        "name": "Pengfei Fang"
                    },
                    {
                        "authorId": "144418842",
                        "name": "T. Drummond"
                    },
                    {
                        "authorId": "1686714",
                        "name": "M. Harandi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We carry out experiments on five benchmark datasets, including mini-ImageNet [56], tiered-ImageNet [54], CIFARFS [57], FC100 [25], and CUB [58].",
                "We carry out experiments on five benchmark datasets, including mini-ImageNet [56], tiered-ImageNet [54], CIFAR-\nFS [57], FC100 [25], and CUB [58].",
                "We follow the split introduced in [57] to divide CIFAR-FS into 64 classes as base set, 16 classes as validation set, 20 classes as novel set, and divide FC100 into 60 classes as base set, 20 classes as validation set, 20 classes as novel set."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c95a5d67ebb33dc5a47b5e0018032d19acf34c61",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-00690",
                    "ArXiv": "2112.00690",
                    "DOI": "10.1109/tcsvt.2021.3135023",
                    "CorpusId": 244773203
                },
                "corpusId": 244773203,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c95a5d67ebb33dc5a47b5e0018032d19acf34c61",
                "title": "MDFM: Multi-Decision Fusing Model for Few-Shot Learning",
                "abstract": "In recent years, researchers pay growing attention to the few-shot learning (FSL) task to address the data-scarce problem. A standard FSL framework is composed of two components: i) Pre-train. Employ the base data to generate a CNN-based feature extraction model (FEM). ii) Meta-test. Apply the trained FEM to the novel data (category is different from base data) to acquire the feature embeddings and recognize them. Although researchers have made remarkable breakthroughs in FSL, there still exists a fundamental problem. Since the trained FEM with base data usually cannot adapt to the novel class flawlessly, the novel data\u2019s feature may lead to the distribution shift problem. To address this challenge, we hypothesize that even if most of the decisions based on different FEMs are viewed as weak decisions, which are not available for all classes, they still perform decent in some specific categories. Inspired by this assumption, we propose a novel method Multi-Decision Fusing Model (MDFM), which comprehensively considers the decisions based on multiple FEMs to enhance the efficacy and robustness of the model. MDFM is a simple, flexible, non-parametric method that can directly apply to the existing FEMs. Besides, we extend the proposed MDFM to two FSL settings (e.g., supervised and semi-supervised settings). We evaluate the proposed method on five benchmark datasets and achieve significant improvements of 3.4%-7.3% compared with state-of-the-arts.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "47975317",
                        "name": "Shuai Shao"
                    },
                    {
                        "authorId": "144218954",
                        "name": "Lei Xing"
                    },
                    {
                        "authorId": "1606128526",
                        "name": "Rui Xu"
                    },
                    {
                        "authorId": "2109174226",
                        "name": "Weifeng Liu"
                    },
                    {
                        "authorId": "7707388",
                        "name": "Yanjiang Wang"
                    },
                    {
                        "authorId": "1678435",
                        "name": "Baodi Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d898241a82fb4b1ebb508ae015a320e2f46e01bb",
                "externalIds": {
                    "DOI": "10.1016/j.inffus.2021.11.019",
                    "CorpusId": 261303637
                },
                "corpusId": 261303637,
                "publicationVenue": {
                    "id": "06afdd0b-0d85-413f-af8a-c3045c12c561",
                    "name": "Information Fusion",
                    "type": "journal",
                    "alternate_names": [
                        "Inf Fusion"
                    ],
                    "issn": "1566-2535",
                    "url": "https://www.journals.elsevier.com/information-fusion",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/15662535"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d898241a82fb4b1ebb508ae015a320e2f46e01bb",
                "title": "A fusion spatial attention approach for few-shot learning",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "31272142",
                        "name": "Heda Song"
                    },
                    {
                        "authorId": "145281509",
                        "name": "Bowen Deng"
                    },
                    {
                        "authorId": "2144887849",
                        "name": "Michael Pound"
                    },
                    {
                        "authorId": "2166362934",
                        "name": "Ender \u00d6zcan"
                    },
                    {
                        "authorId": "1778602",
                        "name": "I. Triguero"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Indeed, many machine learning applications can be reduced to (1) including hyper-parameter optimization (Feurer and Hutter, 2019), meta-learning (Bertinetto et al., 2018), reinforcement learning (Hong et al.",
                "Indeed, many machine learning applications can be reduced to (1) including hyper-parameter optimization (Feurer and Hutter, 2019), meta-learning (Bertinetto et al., 2018), reinforcement learning (Hong et al., 2020b; Liu et al., 2021) or dictionary learning (Mairal et al., 2011; Lecouat et al.,\u2026"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dab2cd1db9f2182d77df4d6fa689f37e93b506a7",
                "externalIds": {
                    "DBLP": "conf/iclr/ArbelM22",
                    "ArXiv": "2111.14580",
                    "CorpusId": 244714983
                },
                "corpusId": 244714983,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/dab2cd1db9f2182d77df4d6fa689f37e93b506a7",
                "title": "Amortized Implicit Differentiation for Stochastic Bilevel Optimization",
                "abstract": "We study a class of algorithms for solving bilevel optimization problems in both stochastic and deterministic settings when the inner-level objective is strongly convex. Specifically, we consider algorithms based on inexact implicit differentiation and we exploit a warm-start strategy to amortize the estimation of the exact gradient. We then introduce a unified theoretical framework inspired by the study of singularly perturbed systems (Habets, 1974) to analyze such amortized algorithms. By using this framework, our analysis shows these algorithms to match the computational complexity of oracle methods that have access to an unbiased estimate of the gradient, thus outperforming many existing results for bilevel optimization. We illustrate these findings on synthetic experiments and demonstrate the efficiency of these algorithms on hyper-parameter optimization experiments involving several thousands of variables.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1975860",
                        "name": "M. Arbel"
                    },
                    {
                        "authorId": "2599292",
                        "name": "J. Mairal"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", miniImageNet [54], tieredImageNet [40], CIFAR-FS [3], and CUB [55].",
                "Results on CIFAR-FS are shown in Table 4, where our method also gets competitive results.",
                "We perform experiments on four widely used FSL benchmarks to verify the effectiveness of the proposed method, i.e., miniImageNet [54], tieredImageNet [40], CIFAR-FS [3], and CUB [55]. miniImageNet and tieredImageNet are both derivatives of ImageNet dataset [41], CIFAR-FS is derived from CIFAR-100 dataset [19,52].",
                "By comparing the performance of with semantic (the first row) and without semantic (the second row which is our baseline [11] under our framework), we can infer that the semantic knowledge can significantly improve performance (i.e., the performance improvement is 6%, 4% and 8% on miniImageNet, tieredImageNet, and CIFAR-FS respectively)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "3973e27b613e178017ef4637c7e4a8ed434e4c32",
                "externalIds": {
                    "DBLP": "conf/wacv/Yang0022",
                    "ArXiv": "2111.04316",
                    "DOI": "10.1109/WACV51458.2022.00165",
                    "CorpusId": 243847999
                },
                "corpusId": 243847999,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/3973e27b613e178017ef4637c7e4a8ed434e4c32",
                "title": "SEGA: Semantic Guided Attention on Visual Prototype for Few-Shot Learning",
                "abstract": "Teaching machines to recognize a new category based on few training samples especially only one remains challenging owing to the incomprehensive understanding of the novel category caused by the lack of data. However, human can learn new classes quickly even given few samples since human can tell what discriminative features should be focused on about each category based on both the visual and semantic prior knowledge. To better utilize those prior knowledge, we propose the SEmantic Guided Attention (SEGA) mechanism where the semantic knowledge is used to guide the visual perception in a top-down manner about what visual features should be paid attention to when distinguishing a category from the others. As a result, the embedding of the novel class even with few samples can be more discriminative. Concretely, a feature extractor is trained to embed few images of each novel class into a visual prototype with the help of transferring visual prior knowledge from base classes. Then we learn a network that maps semantic knowledge to category-specific attention vectors which will be used to perform feature selection to enhance the visual prototypes. Extensive experiments on miniImageNet, tieredImageNet, CIFAR-FS, and CUB indicate that our semantic guided attention realizes anticipated function and outperforms state-of-the-art results.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2156127601",
                        "name": "Fengyuan Yang"
                    },
                    {
                        "authorId": "2108681349",
                        "name": "Ruiping Wang"
                    },
                    {
                        "authorId": "46772547",
                        "name": "Xilin Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "371f8000c72c7cc8f77b562defbc04f59da0f254",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-04331",
                    "ArXiv": "2111.04331",
                    "DOI": "10.1109/icassp43922.2022.9747666",
                    "CorpusId": 243847483
                },
                "corpusId": 243847483,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/371f8000c72c7cc8f77b562defbc04f59da0f254",
                "title": "Enhancing Prototypical Few-Shot Learning By Leveraging The Local-Level Strategy",
                "abstract": "Aiming at recognizing the samples from novel categories with few reference samples, few-shot learning (FSL) is a challenging problem. We found that the existing works often build their few-shot model based on the image-level feature by mixing all local-level features, which leads to the discriminative location bias and information loss in local details. To tackle the problem, this paper returns the perspective to the local-level feature and proposes a series of local-level strategies. Specifically, we present (a) a local-agnostic training strategy to avoid the discriminative location bias between the base and novel categories, (b) a novel local-level similarity measure to capture the accurate comparison between local-level features, and (c) a local-level knowledge transfer that can synthesize different knowledge transfers from the base category according to different location features. Extensive experiments justify that our proposed local-level strategies can significantly boost the performance and achieve 2.8%\u20137.2% improvements over the baseline across different benchmark datasets, which also achieves the state-of-the-art accuracy.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2145754707",
                        "name": "Junying Huang"
                    },
                    {
                        "authorId": "2149503110",
                        "name": "Fan Chen"
                    },
                    {
                        "authorId": "2124615864",
                        "name": "Keze Wang"
                    },
                    {
                        "authorId": "2110902045",
                        "name": "Liang Lin"
                    },
                    {
                        "authorId": "2109566995",
                        "name": "Dongyu Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Aside from the original application in few-shot image classification [7], differentiable closed-form solvers have been used for other few-shot problems like visual tracking [47], video object segmentation [24], spoken intent recognition [27] and spatial regression [17], while we are not aware of any application in forecasting."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "31bfb15cfe0d91ad6bc8289bb454e9b46dc7cc7f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-03418",
                    "ArXiv": "2111.03418",
                    "CorpusId": 243832718
                },
                "corpusId": 243832718,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/31bfb15cfe0d91ad6bc8289bb454e9b46dc7cc7f",
                "title": "Meta-Forecasting by combining Global Deep Representations with Local Adaptation",
                "abstract": "While classical time series forecasting considers individual time series in isolation, recent advances based on deep learning showed that jointly learning from a large pool of related time series can boost the forecasting accuracy. However, the accuracy of these methods suffers greatly when modeling out-of-sample time series, significantly limiting their applicability compared to classical forecasting methods. To bridge this gap, we adopt a meta-learning view of the time series forecasting problem. We introduce a novel forecasting method, called Meta Global-Local Auto-Regression (Meta-GLAR), that adapts to each time series by learning in closed-form the mapping from the representations produced by a recurrent neural network (RNN) to one-step-ahead forecasts. Crucially, the parameters ofthe RNN are learned across multiple time series by backpropagating through the closed-form adaptation mechanism. In our extensive empirical evaluation we show that our method is competitive with the state-of-the-art in out-of-sample forecasting accuracy reported in earlier work.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51004518",
                        "name": "Riccardo Grazzi"
                    },
                    {
                        "authorId": "2067154581",
                        "name": "Valentin Flunkert"
                    },
                    {
                        "authorId": "144607961",
                        "name": "David Salinas"
                    },
                    {
                        "authorId": "2166235",
                        "name": "Tim Januschowski"
                    },
                    {
                        "authorId": "1680574",
                        "name": "M. Seeger"
                    },
                    {
                        "authorId": "2824663",
                        "name": "C. Archambeau"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Typical meta-learning methods usually parameterize a learnable function as the meta learner, which can generate the parameters or statistics [20, 18, 21] for base learners."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2698921f4df5b25e186dafb574271e825359b735",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2111-04239",
                    "ArXiv": "2111.04239",
                    "DOI": "10.1016/j.patcog.2021.108467",
                    "CorpusId": 243847380
                },
                "corpusId": 243847380,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2698921f4df5b25e186dafb574271e825359b735",
                "title": "Learning to Rectify for Robust Learning with Noisy Labels",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2776765",
                        "name": "Haoliang Sun"
                    },
                    {
                        "authorId": "2110226934",
                        "name": "Chenhui Guo"
                    },
                    {
                        "authorId": "2114826675",
                        "name": "Qi Wei"
                    },
                    {
                        "authorId": "1382646197",
                        "name": "Zhongyi Han"
                    },
                    {
                        "authorId": "102446355",
                        "name": "Yilong Yin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "990be11df3e31eff2875661cee62482921274ded",
                "externalIds": {
                    "DBLP": "journals/inffus/ZhengYGW22",
                    "DOI": "10.1016/j.inffus.2021.10.009",
                    "CorpusId": 244109635
                },
                "corpusId": 244109635,
                "publicationVenue": {
                    "id": "06afdd0b-0d85-413f-af8a-c3045c12c561",
                    "name": "Information Fusion",
                    "type": "journal",
                    "alternate_names": [
                        "Inf Fusion"
                    ],
                    "issn": "1566-2535",
                    "url": "https://www.journals.elsevier.com/information-fusion",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/15662535"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/990be11df3e31eff2875661cee62482921274ded",
                "title": "Meta-learning meets the Internet of Things: Graph prototypical models for sensor-based human activity recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "48499775",
                        "name": "Wenbo Zheng"
                    },
                    {
                        "authorId": "151486225",
                        "name": "Lan Yan"
                    },
                    {
                        "authorId": "1491637173",
                        "name": "Chao Gou"
                    },
                    {
                        "authorId": "47939505",
                        "name": "Fei-Yue Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The first class of methodologies include optimization-based meta-learners, like model-agnostic meta-learner [11], gradient unrolling [12], closed-form solvers [13], and convex learners [14]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "00b66bcebfedce47daf6cb4cac50bc192c804ac3",
                "externalIds": {
                    "DBLP": "conf/iccad/GengY0021",
                    "DOI": "10.1109/ICCAD51958.2021.9643518",
                    "CorpusId": 245215935
                },
                "corpusId": 245215935,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/00b66bcebfedce47daf6cb4cac50bc192c804ac3",
                "title": "When Wafer Failure Pattern Classification Meets Few-shot Learning and Self-Supervised Learning",
                "abstract": "Due to advances in semiconductor processing technologies, wafer failure pattern detection plays a key role in preventing yield loss excursion events for semiconductor manufacturing. In the recent semiconductor industry, visible surface defects are still mainly being inspected manually, which may result in inevitably erroneous classification. Many machine learning techniques-based pioneered arts in academia have been proposed to aid wafer failure pattern classification. However, few of these attach importance to unlabeled information and alleviate the data imbalanced issue. Based on these concerns, this paper designs an end-to-end wafer defect classifier that unites the few-shot learning and self-supervised learning algorithms. The aim of applying the few-shot learning paradigm is to learn representations that generalize well to the minority defect pattern classes where only a few wafer images are available, while the self-supervision information containing the intrinsic correlations of unlabeled wafer maps and their augmentations is expected to enhance the few-shot learner. The experimental results demonstrate the proposed framework has superior performance compared to cutting-edge wafer defect classification methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2015104214",
                        "name": "Hao Geng"
                    },
                    {
                        "authorId": "2151253068",
                        "name": "Fan Yang"
                    },
                    {
                        "authorId": "144912628",
                        "name": "Xuan Zeng"
                    },
                    {
                        "authorId": "48317300",
                        "name": "Bei Yu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0f676cf51c2924b8c191ec3927b4295a9c8d890e",
                "externalIds": {
                    "DBLP": "journals/jei/LuoZY21",
                    "DOI": "10.1117/1.JEI.30.6.063009",
                    "CorpusId": 244280433
                },
                "corpusId": 244280433,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0f676cf51c2924b8c191ec3927b4295a9c8d890e",
                "title": "Powerful embedding networks for few-shot image classification",
                "abstract": "Abstract. Few-shot image classification commits to recognizing new concepts from limited annotated samples. Our insight is to obtain a sufficiently powerful embedding network (PEN) to solve few-shot classification tasks. We propose a method to tackle the few-shot classification tasks, namely PENs for few-shot image classification. The key core of PEN is gaining a well-trained embedding network that is capable of extracting strong discriminating representations to represent an image by utilizing two strategies. One strategy is that the multi-scale feature maps are fused instead of only utilizing the final top-level feature maps. We consider that low-level features also play an important role instead of only utilizing top-level representations. Another significant strategy is knowledge distillation (KD). The characteristics of KD can help us get better performance of an embedding network to extract features. Finally, a distance function is employed to classify unlabeled samples. Comprehensive experiments are conducted on few-shot benchmarks. Our method achieves promising performances. The results demonstrate that KD and future fusion are beneficial to gain an expected embedding network for few-shot classification tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2114162583",
                        "name": "Laigan Luo"
                    },
                    {
                        "authorId": "2048017538",
                        "name": "Anan Zhou"
                    },
                    {
                        "authorId": "35136944",
                        "name": "B. Yi"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", nonparametric nearest neighbors [28, 29, 30, 31, 32]; (2) black-box methods that train feed-forward or recurrent neural networks (RNNs) to take the hyperparameters and task dataset as the input and predict the optimal model parameters or parameter updating rules [33, 34, 35, 36, 37, 38, 39, 40, 41]; and (3) optimization-based methods that conduct a bi-level optimization, where the inner level is to estimate the model parameters given the hyperparameters and the outer level is to optimize the hyperparameters via a meta-loss [42, 43, 44, 45, 46, 47, 48, 49]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "461e18aa026b71367d5a719fd06b29bab4de5a0b",
                "externalIds": {
                    "DBLP": "journals/jcphy/PenwardenZNK23",
                    "ArXiv": "2110.13361",
                    "DOI": "10.1016/j.jcp.2023.11191211912",
                    "CorpusId": 255644688
                },
                "corpusId": 255644688,
                "publicationVenue": {
                    "id": "58606051-2e63-4034-8496-9d4ed773bb49",
                    "name": "Journal of Computational Physics",
                    "type": "journal",
                    "alternate_names": [
                        "J Comput Phys"
                    ],
                    "issn": "0021-9991",
                    "url": "http://www.elsevier.com/locate/jcp",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/00219991",
                        "http://www.elsevier.com/wps/find/journaldescription.cws_home/622866/description#description",
                        "http://www.idealibrary.com/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/461e18aa026b71367d5a719fd06b29bab4de5a0b",
                "title": "A metalearning approach for Physics-Informed Neural Networks (PINNs): Application to parameterized PDEs",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2115147703",
                        "name": "Michael Penwarden"
                    },
                    {
                        "authorId": "2390798",
                        "name": "Shandian Zhe"
                    },
                    {
                        "authorId": "1689459",
                        "name": "A. Narayan"
                    },
                    {
                        "authorId": "152534535",
                        "name": "Robert M. Kirby"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In this section, we compare our proposed SDNN approach against contemporary methods on miniImageNet, CIFAR-FS and tieredImageNet.",
                "We perform all our main experiments on three standard datasets used for few shot learning: miniImageNet [40], tieredImageNet [27], and CIFAR-FS [2]. miniImageNet consists of 100 classes randomly picked from the ImageNet dataset [28] with 600 images of size 84\u00d784 pixels per class.",
                "\u2022 We demonstrate the effectiveness of SDNNs on the miniImageNet, tiered-ImageNet, CIFAR-FS, and ActEV Surprise Activities datasets.",
                "For two of the experiments in the original paper (the \u201cGaussian SDNN + BF3S\u201d experiment performed on the CIFAR-FS and tieredImageNet dataset in Table 1 of the original paper) our SDNN implementation only applied noise and auxiliary losses to the last two blocks of the network, as opposed to the three used in every other experiment.",
                "An unmodified version of our method also perform favorably against many prior methods, even achieving state-of-the-art performance on the \u201cCIFAR-FS\u201d dataset without modification.",
                "We perform all our main experiments on three standard datasets used for few shot learning: miniImageNet [40], tieredImageNet [27], and CIFAR-FS [2]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "55345706d97e75209bd4f5d4c4effc84e6280724",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-13386",
                    "ArXiv": "2110.13386",
                    "CorpusId": 239885714
                },
                "corpusId": 239885714,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/55345706d97e75209bd4f5d4c4effc84e6280724",
                "title": "Self-Denoising Neural Networks for Few Shot Learning",
                "abstract": "In this paper, we introduce a new architecture for few shot learning, the task of teaching a neural network from as few as one or five labeled examples. Inspired by the theoretical results of Alaine et al that Denoising Autoencoders refine features to lie closer to the true data manifold, we present a new training scheme that adds noise at multiple stages of an existing neural architecture while simultaneously learning to be robust to this added noise. This architecture, which we call a Self-Denoising Neural Network (SDNN), can be applied easily to most modern convolutional neural architectures, and can be used as a supplement to many existing few-shot learning techniques. We empirically show that SDNNs out-perform previous state-of-the-art methods for few shot image recognition using the Wide-ResNet architecture on the \\textit{mini}ImageNet, tiered-ImageNet, and CIFAR-FS few shot learning datasets. We also perform a series of ablation experiments to empirically justify the construction of the SDNN architecture. Finally, we show that SDNNs even improve few shot performance on the task of human action detection in video using experiments on the ActEV SDL Surprise Activities challenge.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "52023459",
                        "name": "S. Schwarcz"
                    },
                    {
                        "authorId": "3403576",
                        "name": "Sai Saketh Rambhatla"
                    },
                    {
                        "authorId": "69416958",
                        "name": "Ramalingam Chellappa"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In this section we study the performance range of meta-learners trained with a variety of algorithms: MAML [10], Meta-Curvature (MC) [32], Prototypical networks [38], R2D2 [4], and MetaOptNet with Ridge and SVM heads [21].",
                "We execute algorithm 1 to find the worst-case 5-way 10-shot support examples on CIFAR-FS and FC100 datasets for R2D2, ResNet-Ridge, and the ResNet-SVM algorithms.",
                "R2D2 [4] casts classification as a multi-target ridge-regression problem and utilizes the corresponding closed-form solution as a(\u03b8,A).",
                "D Improving support data robustness with adversarial training\nIn Table 6, we show the projected embeddings for the R2D2, MetaOptNet-Ridge, and the MetaOptNetSVM algorithms on the training and the test dataset, when trained in a standard manner vs when trained adversarially.",
                "We also see no differences between meta-learners adapting end-to-end, i.e. MAML and MC, and those adapting only the last linear classification layer, i.e. R2D2 and MetaOptNet.",
                "0 1 2 3 4 5 6 7 8 9 10 Iterations\n30\n40\n50\n60\n70\n80\n90\nAc cu\nra cy\nR2D2 ResNet-Ridge ResNet-SVM\n(a) Worst-case accuracy over 10 iterations of algorithm 1 for different algorithms and on the CIFAR-FS dataset.",
                "For ProtoNet and R2D2 experiments, we use the same architectures as are used in the original papers.",
                "The corresponding run times for a single iteration for R2D2 method on FC100 are approximately 1 minute for 1-shot setting, approximately 6 minutes for 5-shot setting, and approximately 20 minutes for 10-shot setting.",
                "0 1 2 3 4 5 6 7 8 9 10 Iterations\n10\n20\n30\n40\n50\n60\nAc cu\nra cy\nR2D2 ResNet-Ridge ResNet-SVM\n(b) Worst-case accuracy over 10 iterations of Algorithm 1 for different algorithms and on the FC100 dataset.",
                "CIFAR-FS [4] is a dataset of 60000 32\u00d732 RGB images from CIFAR-100 partitioned into 64, 16 and 20 classes for training, validation and testing, respectively.",
                "The R2D2 feature extractor is a combination of 4 convolutional layers with [96, 192, 384, 512] filters."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "b1e3a356e1e71e3db72490d9dd771e3856d34f7c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-13953",
                    "ArXiv": "2110.13953",
                    "CorpusId": 239998536
                },
                "corpusId": 239998536,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b1e3a356e1e71e3db72490d9dd771e3856d34f7c",
                "title": "On sensitivity of meta-learning to support data",
                "abstract": "Meta-learning algorithms are widely used for few-shot learning. For example, image recognition systems that readily adapt to unseen classes after seeing only a few labeled examples. Despite their success, we show that modern meta-learning algorithms are extremely sensitive to the data used for adaptation, i.e. support data. In particular, we demonstrate the existence of (unaltered, in-distribution, natural) images that, when used for adaptation, yield accuracy as low as 4\\% or as high as 95\\% on standard few-shot image classification benchmarks. We explain our empirical findings in terms of class margins, which in turn suggests that robust and safe meta-learning requires larger margins than supervised learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145625761",
                        "name": "Mayank Agarwal"
                    },
                    {
                        "authorId": "8202372",
                        "name": "Mikhail Yurochkin"
                    },
                    {
                        "authorId": "3340442",
                        "name": "Yuekai Sun"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The CIFAR-FS and FC100 datasets are derived from CIFAR-100 dataset having 100 classes with each class consisting of 600 images of size 32 \u00d7 32.",
                "We conducted experiments on four datasets \u2013 CIFAR-FS [8], FC100 [13], miniImageNet [6] and tieredImageNet [32].",
                "On CIFAR-FS, we have improved on original methods up to 2.0%, with the largest improvement by 2-way MAML MTM SPSA-Track.",
                "R2D2 [8] and MetaOptNet [2] improved accuracy by using Ridge Regression and SVM as classifiers.",
                "In the CIFAR-FS dataset classes are randomly divided into groups of 64, 16 and 20 for training, validation, and testing, respectively, while in the FC100 datasets 20 superclasses of CIFAR-100 are split into groups of 12, 4 and 4."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1193d08e0b1f14cd83a1d469c20985e7d831f9bd",
                "externalIds": {
                    "DBLP": "conf/iconip/BoiarovKY22",
                    "ArXiv": "2110.13188",
                    "DOI": "10.1007/978-981-99-1639-9_31",
                    "CorpusId": 252684037
                },
                "corpusId": 252684037,
                "publicationVenue": {
                    "id": "bc5a5118-8f5c-49c7-806e-fb8d44c10ae7",
                    "name": "International Conference on Neural Information Processing",
                    "type": "conference",
                    "alternate_names": [
                        "ICONIP",
                        "Int Conf Neural Inf Process"
                    ],
                    "url": "https://link.springer.com/conference/iconip"
                },
                "url": "https://www.semanticscholar.org/paper/1193d08e0b1f14cd83a1d469c20985e7d831f9bd",
                "title": "Simultaneous Perturbation Method for Multi-task Weight Optimization in One-Shot Meta-learning",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "27003403",
                        "name": "A. Boiarov"
                    },
                    {
                        "authorId": "103862117",
                        "name": "K. Khabarlak"
                    },
                    {
                        "authorId": "2135091095",
                        "name": "Igor Yastrebov"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2017) aim to learn transferable deep representations which can adapt to unseen classes without any additional fine-tuning; (c) Optimization based methods (Finn et al., 2017; Lee et al., 2019; Bertinetto et al., 2018) learn a good pre-training initialization for effective transfer to unseen tasks with only a few optimization steps.",
                "In addition, we use MetaOptNet (Lee et al., 2019) and R2D2 (Bertinetto et al., 2018) as representative algorithms from the optimization based meta-learning methods.",
                "\u2026representations which can adapt to unseen classes without any additional fine-tuning; (c) Optimization based methods (Finn et al., 2017; Lee et al., 2019; Bertinetto et al., 2018) learn a good pre-training initialization for effective transfer to unseen tasks with only a few optimization steps.",
                "The CIFAR-FS dataset (Bertinetto et al., 2018) is curated from CIFAR-100 and comprises of 100 classes in total with each class consisting of 600 images.",
                ", 2019), and R2D2 (Bertinetto et al., 2018) primarily focus on improving prediction performance on average across multiple episodes.",
                "Existing state-of-the-art meta-learners (Finn et al., 2017; Lee et al., 2019; Snell et al., 2017; Bertinetto et al., 2018) primarily focus on optimizing for the average loss across multiple training episodes or tasks.",
                "In this paper, we study this issue and investigate how existing state-of-the-art meta-learners (Snell et al., 2017; Bertinetto et al., 2018; Lee et al., 2019) perform on episodes of varying hardness.",
                "Existing meta-learners such as prototypical networks (Snell et al., 2017), MAML (Finn et al., 2017), MetaOptNet (Lee et al., 2019), and R2D2 (Bertinetto et al., 2018) primarily focus on improving prediction performance on average across multiple episodes.",
                "Different meta-learners have different types of fine-tuning procedures and we direct the readers to (Finn et al., 2017; Snell et al., 2017; Bertinetto et al., 2018)",
                "We use three standard few-shot classification datasets for our experiments : (i) CIFARFS (Bertinetto et al., 2018); (ii) mini-ImageNet (Vinyals et al.",
                "Different meta-learners have different types of fine-tuning procedures and we direct the readers to (Finn et al., 2017; Snell et al., 2017; Bertinetto et al., 2018)\nfor more information on the characteristics ofA.",
                "We use three standard few-shot classification datasets for our experiments : (i) CIFARFS (Bertinetto et al., 2018); (ii) mini-ImageNet (Vinyals et al., 2016) and (iii) tieredImageNet (Ren et al., 2018).",
                ", 2019) and R2D2 (Bertinetto et al., 2018) as representative algorithms from the optimization based meta-learning methods."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "9bfc760dbd12d1ad0d55387c985c6c388ebde804",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-11190",
                    "ArXiv": "2110.11190",
                    "CorpusId": 239050549
                },
                "corpusId": 239050549,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/9bfc760dbd12d1ad0d55387c985c6c388ebde804",
                "title": "On Hard Episodes in Meta-Learning",
                "abstract": "Existing meta-learners primarily focus on improving the average task accuracy across multiple episodes. Different episodes, however, may vary in hardness and quality leading to a wide gap in the meta-learner's performance across episodes. Understanding this issue is particularly critical in industrial few-shot settings, where there is limited control over test episodes as they are typically uploaded by end-users. In this paper, we empirically analyse the behaviour of meta-learners on episodes of varying hardness across three standard benchmark datasets: CIFAR-FS, mini-ImageNet, and tiered-ImageNet. Surprisingly, we observe a wide gap in accuracy of around 50% between the hardest and easiest episodes across all the standard benchmarks and meta-learners. We additionally investigate various properties of hard episodes and highlight their connection to catastrophic forgetting during meta-training. To address the issue of sub-par performance on hard episodes, we investigate and benchmark different meta-training strategies based on adversarial training and curriculum learning. We find that adversarial training strategies are much more powerful than curriculum learning in improving the prediction performance on hard episodes.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "152785197",
                        "name": "S. Basu"
                    },
                    {
                        "authorId": "143816740",
                        "name": "Amr Sharaf"
                    },
                    {
                        "authorId": "2723245",
                        "name": "Nicol\u00f3 Fusi"
                    },
                    {
                        "authorId": "34389431",
                        "name": "S. Feizi"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "db0244b9a8b39a912a8f7e1e12caf1975f492aa1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-10353",
                    "ArXiv": "2110.10353",
                    "DOI": "10.1109/WACV51458.2022.00356",
                    "CorpusId": 239049420
                },
                "corpusId": 239049420,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/db0244b9a8b39a912a8f7e1e12caf1975f492aa1",
                "title": "Contextual Gradient Scaling for Few-Shot Learning",
                "abstract": "Model-agnostic meta-learning (MAML) is a well-known optimization-based meta-learning algorithm that works well in various computer vision tasks, e.g., few-shot classification. MAML is to learn an initialization so that a model can adapt to a new task in a few steps. However, since the gradient norm of a classifier (head) is much bigger than those of backbone layers, the model focuses on learning the decision boundary of the classifier with similar representations. Furthermore, gradient norms of high-level layers are small than those of the other layers. So, the backbone of MAML usually learns task-generic features, which results in deteriorated adaptation performance in the inner-loop. To resolve or mitigate this problem, we propose contextual gradient scaling (CxGrad), which scales gradient norms of the backbone to facilitate learning task-specific knowledge in the inner-loop. Since the scaling factors are generated from task-conditioned parameters, gradient norms of the backbone can be scaled in a task-wise fashion. Experimental results show that CxGrad effectively encourages the backbone to learn task-specific knowledge in the inner-loop and improves the performance of MAML up to a significant margin in both same- and cross-domain few-shot classification.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2201761320",
                        "name": "Sang Hyuk Lee"
                    },
                    {
                        "authorId": "50111977",
                        "name": "Seunghyun Lee"
                    },
                    {
                        "authorId": "10774886",
                        "name": "B. Song"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Similar to [41, 17, 12], Figure 6: Accuracy results for training and validation on R2-D2 base-learner [8] with a DBT-regularized ResNet-12 backbone on the CIFAR-FS dataset.",
                "To start with, we used the R2-D2 base learner [8] and the CIFAR-FS database to evaluate the augmentation performance on support, query and task augmentations as shown in Table 1.",
                "We used the R2-D2 base leaner [8], the \u201dResNet12\u201d and \u201d64-64-64-64\u201d backbone for different few-shot learning modes used in our work."
            ],
            "intents": [
                "methodology",
                "result"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "669bcc4354bd7aa4447997dda1774c0a2cbad180",
                "externalIds": {
                    "ArXiv": "2110.09374",
                    "DBLP": "journals/corr/abs-2110-09374",
                    "DOI": "10.1109/WACV51458.2022.00210",
                    "CorpusId": 239016284
                },
                "corpusId": 239016284,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/669bcc4354bd7aa4447997dda1774c0a2cbad180",
                "title": "Ortho-Shot: Low Displacement Rank Regularization with Data Augmentation for Few-Shot Learning",
                "abstract": "In few-shot classification, the primary goal is to learn representations from a few samples that generalize well for novel classes. In this paper, we propose an efficient low displacement rank (LDR) regularization strategy termed Ortho-Shot; a technique that imposes orthogonal regularization on the convolutional layers of a few-shot classifier, which is based on the doubly-block toeplitz (DBT) matrix structure. The regularized convolutional layers of the few-shot classifier enhances model generalization and intra-class feature embeddings that are crucial for few-shot learning. Overfitting is a typical issue for few-shot models, the lack of data diversity inhibits proper model inference which weakens the classification accuracy of few-shot learners to novel classes. In this regard, we broke down the pipeline of the few-shot classifier and established that the support, query and task data augmentation collectively alleviates overfitting in networks. With compelling results, we demonstrated that combining a DBT-based low-rank orthogonal regularizer with data augmentation strategies, significantly boosts the performance of a few-shot classifier. We perform our experiments on the miniImagenet, CIFAR- FS and Stanford datasets with performance values of about 5% when compared to state-of-the-art.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "88489141",
                        "name": "Uche M. Osahor"
                    },
                    {
                        "authorId": "8147588",
                        "name": "N. Nasrabadi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In this branch, optimization based methods [3, 1, 2, 10, 11, 12] train a well-initialized optimizer so that it quickly adapts to unseen classes with a few epochs of training."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8b769cf8963cb662da5e2e7d0a784472feedfc0b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-09446",
                    "ArXiv": "2110.09446",
                    "DOI": "10.3390/a15050147",
                    "CorpusId": 239016701
                },
                "corpusId": 239016701,
                "publicationVenue": {
                    "id": "e95c8d18-09be-464f-a3cf-5b2637f0eff6",
                    "name": "Algorithms",
                    "type": "journal",
                    "issn": "1999-4893",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-150910",
                    "alternate_urls": [
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-150910",
                        "http://www.mdpi.com/journal/algorithms",
                        "http://www.mdpi.com/journal/algorithms/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8b769cf8963cb662da5e2e7d0a784472feedfc0b",
                "title": "Squeezing Backbone Feature Distributions to the Max for Efficient Few-Shot Learning",
                "abstract": "In many real-life problems, it is difficult to acquire or label large amounts of data, resulting in so-called few-shot learning problems. However, few-shot classification is a challenging problem due to the uncertainty caused by using few labeled samples. In the past few years, many methods have been proposed with the common aim of transferring knowledge acquired on a previously solved task, which is often achieved by using a pretrained feature extractor. As such, if the initial task contains many labeled samples, it is possible to circumvent the limitations of few-shot learning. A shortcoming of existing methods is that they often require priors about the data distribution, such as the balance between considered classes. In this paper, we propose a novel transfer-based method with a double aim: providing state-of-the-art performance, as reported on standardized datasets in the field of few-shot learning, while not requiring such restrictive priors. Our methodology is able to cope with both inductive cases, where prediction is performed on test samples independently from each other, and transductive cases, where a joint (batch) prediction is performed.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2143462361",
                        "name": "Yuqing Hu"
                    },
                    {
                        "authorId": "144916029",
                        "name": "Vincent Gripon"
                    },
                    {
                        "authorId": "2642628",
                        "name": "S. Pateux"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This section focuses on comparing and evaluating the proposed method with several state-of-the-art approaches on several benchmark few-shot learning datasets, such as mini-ImageNet[5], tiered-ImageNet[4], CIFAR-FS[12], and CUB[24].",
                "In the 5-way 1-shot setting, tiered-Imagenet and CIFAR-FS are improved by at least 1.59% and 1.5%, respectively.",
                "Table II and Table III show the accuracy of LDAnet in tiered-Imagenet and CIFAR-FS, respectively.",
                "In the 5- way 5-shot setting, tiered-Imagenet and CIFAR-FS increased by at least 0.99% and 1% respectively.",
                "CIFAR-FS is the subsets of the CIFAR-100 dataset and consists of 100 classes.",
                "We divide the 100 category into meta-training set, metavalidation set, and meta-test set according to [12], with categories of 64, 16, and 20, respectively.",
                "We divide the 200 category into base set, validation set, and novel set according to [12], with categories of 100, 50, and 50, respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "25e16606d42829610a0c35a89af5fda609519f5a",
                "externalIds": {
                    "DBLP": "conf/smc/ChenL21a",
                    "DOI": "10.1109/SMC52423.2021.9659021",
                    "CorpusId": 245803497
                },
                "corpusId": 245803497,
                "publicationVenue": {
                    "id": "e84bb5a1-8f79-42cc-8eb1-3a52f7c73d63",
                    "name": "IEEE International Conference on Systems, Man and Cybernetics",
                    "type": "conference",
                    "alternate_names": [
                        "Smoky Mountains Computational Sciences and Engineering Conference",
                        "Smoky Mt Comput Sci Eng Conf",
                        "IEEE Int Conf Syst Man Cybern",
                        "SMC",
                        "Syst Man Cybern",
                        "Systems, Man and Cybernetics"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/25e16606d42829610a0c35a89af5fda609519f5a",
                "title": "LDAnet:a discriminant subspace for metric-based few-shot learning",
                "abstract": "Deep neural networks have surpassed humans in some cases, such as image recognition and image classification, with numerous labeled training samples. However, multiple tasks cannot provide enough labeled samples, training a neural network with a limited number of labeled samples is challenging. Therefore, meta-learning emerges. It aims to summarize from few-shot tasks and can quickly adapt to new categories. However, it is challenging to ensure that the trained feature extractor in the meta-train can adapt to the novel class in the meta-test. In this paper, we propose a subspace learning module to deal with the feature-mismatch problem. Specifically, we embed the linear discriminant analysis (LDA) module into the few-shot learning framework. It guarantees the feature embeddings in each few-shot task are more discriminative via increasing the inter-class distance and reducing the intra-class variances. We conduct experiments on four benchmark few-shot learning datasets, namely mini-Imagenet, CIFAR-FS, tiered-ImageNet, and CUB, to demonstrate the effectiveness of the proposed module. Experimental results show that this method has better performance than the state-of-the-art approaches.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2113596253",
                        "name": "Da-Ren Chen"
                    },
                    {
                        "authorId": "1678435",
                        "name": "Baodi Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We comprehensively evaluate our proposed method on three challenging benchmark datasets, including miniImageNet, CIFAR-FS and FC100.",
                "CIFAR-FS and FC100 are both derived from the standard CIFAR-100 dataset [22].",
                "To further illustrate the effectiveness of our method, we also conducted extensive experiments on CIFAR derivatives (CIFAR-FS and FC100).",
                "CIFAR-FS contains a random split of 100 classes into 64 training classes, 16 validation classes and 20 testing classes, while FC100 splits classes based on the super-classes.",
                "Tables 1, 2 and 3 tabulate the few-shot classification performances of different methods on miniImageNet, CIFAR-FS and FC100 datasets respectively.",
                "Extensive experimental results on miniImageNet, CIFAR-FS and FC100 datasets demonstrate the effectiveness of our proposed approach, which can achieve consistent performance gains across different benchmark methods.",
                "On CIFAR-FS dataset, our method achieves accuracy of 76.68% and 87.49% in 1-shot and 5-shot scenarios, respectively.",
                "In this section, we conduct experiments on three widely used few-shot learning benchmarks: miniImageNet [42], CIFAR-FS [2], FC100 [32]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "9fcc42adc0ec0eca8de8af91748bc2c284b5e9c6",
                "externalIds": {
                    "DBLP": "conf/mm/ZhangHZ21",
                    "DOI": "10.1145/3474085.3475459",
                    "CorpusId": 239012126
                },
                "corpusId": 239012126,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9fcc42adc0ec0eca8de8af91748bc2c284b5e9c6",
                "title": "Generally Boosting Few-Shot Learning with HandCrafted Features",
                "abstract": "Existing Few-Shot Learning (FSL) methods predominantly focus on developing different types of sophisticated models to extract the transferable prior knowledge for recognizing novel classes, while they almost pay less attention to the feature learning part in FSL which often simply leverage some well-known CNN as the feature learner. However, feature is the core medium for encoding such transferable knowledge. Feature learning is easy to be trapped in the over-fitting particularly in the scarcity of the training data, and thereby degenerates the performances of FSL. The handcrafted features, such as Histogram of Oriented Gradient (HOG) and Local Binary Pattern (LBP), have no requirement on the amount of training data, and used to perform quite well in many small-scale data scenarios, since their extractions involve no learning process, and are mainly based on the empirically observed and summarized prior feature engineering knowledge. In this paper, we intend to develop a general and simple approach for generally boosting FSL via exploiting such prior knowledge in the feature learning phase. To this end, we introduce two novel handcrafted feature regression modules, namely HOG and LBP regression, to the feature learning parts of deep learning-based FSL models. These two modules are separately plugged into the different convolutional layers of backbone based on the characteristics of the corresponding handcrafted features to guide the backbone optimization from different feature granularity, and also ensure that the learned feature can encode the handcrafted feature knowledge which improves the generalization ability of feature and alleviate the over-fitting of the models. Three recent state-of-the-art FSL approaches are leveraged for examining the effectiveness of our method. Extensive experiments on miniImageNet, CIFAR-FS and FC100 datasets show that the performances of all these FSL approaches are well boosted via applying our method on all three datasets. Our codes and models have been released.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2153910406",
                        "name": "Yi Zhang"
                    },
                    {
                        "authorId": "2149206104",
                        "name": "Sheng Huang"
                    },
                    {
                        "authorId": "2153433523",
                        "name": "Fengtao Zhou"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2017), and (3) optimization-based methods that conduct a bi-level optimization, where the inner level is to estimate the model parameters given the hyperparameters (in each task) and the outer level is to optimize the hyperparameters via a meta-loss (Finn et al., 2017; Finn, 2018; Bertinetto et al., 2018; Lee et al., 2019; Zintgraf et al., 2019; Li et al., 2017; Finn et al., 2018; Zhou et al., 2018; Harrison et al., 2018).",
                "\u2026the model parameters given the hyperparameters (in each task) and the outer level is to optimize the hyperparameters via a meta-loss (Finn et al., 2017; Finn, 2018; Bertinetto et al., 2018; Zintgraf et al., 2019; Li et al., 2017;\nFinn et al., 2018; Zhou et al., 2018; Harrison et al., 2018)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2b63bd7b1b2587c4aec4d3e48688871424e8830d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-08432",
                    "ArXiv": "2110.08432",
                    "CorpusId": 239016029
                },
                "corpusId": 239016029,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2b63bd7b1b2587c4aec4d3e48688871424e8830d",
                "title": "Meta-Learning with Adjoint Methods",
                "abstract": "Model Agnostic Meta Learning (MAML) is widely used to find a good initialization for a family of tasks. Despite its success, a critical challenge in MAML is to calculate the gradient w.r.t. the initialization of a long training trajectory for the sampled tasks, because the computation graph can rapidly explode and the computational cost is very expensive. To address this problem, we propose Adjoint MAML (A-MAML). We view gradient descent in the inner optimization as the evolution of an Ordinary Differential Equation (ODE). To efficiently compute the gradient of the validation loss w.r.t. the initialization, we use the adjoint method to construct a companion, backward ODE. To obtain the gradient w.r.t. the initialization, we only need to run the standard ODE solver twice -- one is forward in time that evolves a long trajectory of gradient flow for the sampled task; the other is backward and solves the adjoint ODE. We need not create or expand any intermediate computational graphs, adopt aggressive approximations, or impose proximal regularizers in the training loss. Our approach is cheap, accurate, and adaptable to different trajectory lengths. We demonstrate the advantage of our approach in both synthetic and real-world meta-learning tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118056567",
                        "name": "Shibo Li"
                    },
                    {
                        "authorId": "40072305",
                        "name": "Zheng Wang"
                    },
                    {
                        "authorId": "1689459",
                        "name": "A. Narayan"
                    },
                    {
                        "authorId": "2062359813",
                        "name": "Robert Kirby"
                    },
                    {
                        "authorId": "2390798",
                        "name": "Shandian Zhe"
                    }
                ]
            }
        },
        {
            "contexts": [
                "They can also be extended to other applications such as regression and image classification by changing the architecture and training objective [9], [69], [70], [71]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e2df22fdffb0cba47e1ce65ae39316280b6f047b",
                "externalIds": {
                    "ArXiv": "2110.07510",
                    "DOI": "10.1109/TPAMI.2023.3319517",
                    "CorpusId": 254854391,
                    "PubMed": "37751343"
                },
                "corpusId": 254854391,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e2df22fdffb0cba47e1ce65ae39316280b6f047b",
                "title": "Omni-Training: Bridging Pre-Training and Meta-Training for Few-Shot Learning.",
                "abstract": "Few-shot learning aims to fast adapt a deep model from a few examples. While pre-training and meta-training can create deep models powerful for few-shot generalization, we find that pre-training and meta-training focus respectively on cross-domain transferability and cross-task transferability, which restricts their data efficiency in the entangled settings of domain shift and task shift. We thus propose the Omni-Training framework to seamlessly bridge pre-training and meta-training for data-efficient few-shot learning. Our first contribution is a tri-flow Omni-Net architecture. Besides the joint representation flow, Omni-Net introduces two parallel flows for pre-training and meta-training, responsible for improving domain transferability and task transferability respectively. Omni-Net further coordinates the parallel flows by routing their representations via the joint-flow, enabling knowledge transfer across flows. Our second contribution is the Omni-Loss, which introduces a self-distillation strategy separately on the pre-training and meta-training objectives for boosting knowledge transfer throughout different training stages. Omni-Training is a general framework to accommodate many existing algorithms. Evaluations justify that our single framework consistently and clearly outperforms the individual state-of-the-art methods on both cross-task and cross-domain settings in a variety of classification, regression and reinforcement learning problems.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2066476988",
                        "name": "Yang Shu"
                    },
                    {
                        "authorId": "3451430",
                        "name": "Zhangjie Cao"
                    },
                    {
                        "authorId": "2118390591",
                        "name": "Jing Gao"
                    },
                    {
                        "authorId": "2144499343",
                        "name": "Jianmin Wang"
                    },
                    {
                        "authorId": "144019071",
                        "name": "Philip S. Yu"
                    },
                    {
                        "authorId": "2054275000",
                        "name": "Mingsheng Long"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning [4, 12, 49, 24, 36], hyperparamater optimization [12, 51], neural architecture search [35, 58], signal processing [10], etc."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "97f2a3c678b6bb5c146eb7f14df51223d3324534",
                "externalIds": {
                    "ArXiv": "2110.07004",
                    "DBLP": "conf/nips/SowJL22",
                    "CorpusId": 249395170
                },
                "corpusId": 249395170,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/97f2a3c678b6bb5c146eb7f14df51223d3324534",
                "title": "On the Convergence Theory for Hessian-Free Bilevel Algorithms",
                "abstract": "Bilevel optimization has arisen as a powerful tool in modern machine learning. However, due to the nested structure of bilevel optimization, even gradient-based methods require second-order derivative approximations via Jacobian- or/and Hessian-vector computations, which can be costly and unscalable in practice. Recently, Hessian-free bilevel schemes have been proposed to resolve this issue, where the general idea is to use zeroth- or first-order methods to approximate the full hypergradient of the bilevel problem. However, we empirically observe that such approximation can lead to large variance and unstable training, but estimating only the response Jacobian matrix as a partial component of the hypergradient turns out to be extremely effective. To this end, we propose a new Hessian-free method, which adopts the zeroth-order-like method to approximate the response Jacobian matrix via taking difference between two optimization paths. Theoretically, we provide the convergence rate analysis for the proposed algorithms, where our key challenge is to characterize the approximation and smoothness properties of the trajectory-dependent estimator, which can be of independent interest. This is the first known convergence rate result for this type of Hessian-free bilevel algorithms. Experimentally, we demonstrate that the proposed algorithms outperform baseline bilevel optimizers on various bilevel problems. Particularly, in our experiment on few-shot meta-learning with ResNet-12 network over the miniImageNet dataset, we show that our algorithm outperforms baseline meta-learning algorithms, while other baseline bilevel optimizers do not solve such meta-learning problems within a comparable time frame.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "143827145",
                        "name": "Daouda Sow"
                    },
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS The CIFAR-FS dataset [34] is a recently proposed fewshot image classification benchmark, consisting of all 100 classes from CIFAR-100 [35].",
                "[34] Luca Bertinetto, Jo\u00e3o Henriques, Philip H."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "74416b63ce04a2cab74d23c687f7282495fd873c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-05076",
                    "ArXiv": "2110.05076",
                    "CorpusId": 238583708
                },
                "corpusId": 238583708,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/74416b63ce04a2cab74d23c687f7282495fd873c",
                "title": "A Closer Look at Prototype Classifier for Few-shot Image Classification",
                "abstract": "The prototypical network is a prototype classifier based on meta-learning and is widely used for few-shot learning because it classifies unseen examples by constructing class-specific prototypes without adjusting hyper-parameters during meta-testing. Interestingly, recent research has attracted a lot of attention, showing that training a new linear classifier, which does not use a meta-learning algorithm, performs comparably with the prototypical network. However, the training of a new linear classifier requires the retraining of the classifier every time a new class appears. In this paper, we analyze how a prototype classifier works equally well without training a new linear classifier or meta-learning. We experimentally find that directly using the feature vectors, which is extracted by using standard pre-trained models to construct a prototype classifier in meta-testing, does not perform as well as the prototypical network and training new linear classifiers on the feature vectors of pre-trained models. Thus, we derive a novel generalization bound for a prototypical classifier and show that the transformation of a feature vector can improve the performance of prototype classifiers. We experimentally investigate several normalization methods for minimizing the derived bound and find that the same performance can be obtained by using the L2 normalization and minimizing the ratio of the within-class variance to the between-class variance without training a new classifier or meta-learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2135375612",
                        "name": "Mingcheng Hou"
                    },
                    {
                        "authorId": "73355331",
                        "name": "Issei Sato"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1b3d401618610f77b5783aa0df8b91e8ef874082",
                "externalIds": {
                    "DBLP": "journals/ijon/LimLOL21",
                    "MAG": "3175695077",
                    "DOI": "10.1016/J.NEUCOM.2021.06.090",
                    "CorpusId": 237621042
                },
                "corpusId": 237621042,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1b3d401618610f77b5783aa0df8b91e8ef874082",
                "title": "Efficient-PrototypicalNet with self knowledge distillation for few-shot learning",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2148578902",
                        "name": "Jit Yan Lim"
                    },
                    {
                        "authorId": "30039300",
                        "name": "K. Lim"
                    },
                    {
                        "authorId": "1788756",
                        "name": "S. Ooi"
                    },
                    {
                        "authorId": "84161127",
                        "name": "C. Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For the cosine classifier experiments, we trained over 1.92, 1.92, and 3.36 million classifiers for mini-ImageNet, CIFAR-FS, and tiered-ImageNet datasets, respectively.",
                "CIFAR-FS is a random split of CIFAR-100 (Krizhevsky and Hinton, 2009) with images of size 32\u00d7 32 into 64, 16, and 20 classes for base, validation, and novel sets, respectively.",
                "E.1 ADDITIONAL LOGISTIC CLASSIFIER EXPERIMENTS\nThe experiments of Figure 2 were repeated to perform 16-way classification using a logistic classifier on tiered-ImageNet and CIFAR-FS in Figure A13.",
                "The improvement almost falls within (0.1%-0.5%), (0-0.1%), and (0-0.2%), for mini-ImageNet, CIFAR-FS, and tiered-ImageNet, respectively.",
                ", 2016), CIFAR-FS (Bertinetto et al., 2019), tiered-ImageNet (Ren et al.",
                "Datasets: We perform experiments on four widely-used and publicly available benchmarks: miniImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), tiered-ImageNet (Ren et al., 2018), and CUB (Wah et al., 2011).",
                "Before After Improvement Before After Improvement\n5-way 10-way\n1-shot 74.96 75.03 \u00b1 0.19 0.07 \u00b1 0.01 61.46 61.49 \u00b1 0.13 0.03 \u00b1 0.00 5-shot 87.43 87.48 \u00b1 0.13 0.06 \u00b1 0.00 77.73 77.83 \u00b1 0.10 0.10 \u00b1 0.00\n10-shot 89.83 89.88 \u00b1 0.11 0.05 \u00b1 0.00 81.52 81.64 \u00b1 0.09 0.11 \u00b1 0.00 15-way 20-way\n1-shot 53.45 53.47 \u00b1 0.10 0.02 \u00b1 0.00 47.78 47.79 \u00b1 0.07 0.01 \u00b1 0.00 5-shot 70.70 70.99 \u00b1 0.07 0.28 \u00b1 0.00 65.26 65.60 \u00b1 0.03 0.34 \u00b1 0.00\n10-shot 75.37 75.71 \u00b1 0.06 0.34 \u00b1 0.00 70.57 70.99 \u00b1 0.02 0.42 \u00b1 0.00\nTable A6: The Firth bias reduction improvements on the CIFAR-FS dataset shown in Figure 4 in the main paper.",
                "We trained Firth penalized and non-penalized cosine classifiers on the mini-ImageNet, tiered-ImageNet, and CIFAR-FS datasets."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1729f308d7874f7a51a19571d5c96c3cc1a53d4d",
                "externalIds": {
                    "DBLP": "conf/iclr/GhaffariSFW22",
                    "ArXiv": "2110.02529",
                    "CorpusId": 238408406
                },
                "corpusId": 238408406,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/1729f308d7874f7a51a19571d5c96c3cc1a53d4d",
                "title": "On the Importance of Firth Bias Reduction in Few-Shot Classification",
                "abstract": "Learning accurate classifiers for novel categories from very few examples, known as few-shot image classification, is a challenging task in statistical machine learning and computer vision. The performance in few-shot classification suffers from the bias in the estimation of classifier parameters; however, an effective underlying bias reduction technique that could alleviate this issue in training few-shot classifiers has been overlooked. In this work, we demonstrate the effectiveness of Firth bias reduction in few-shot classification. Theoretically, Firth bias reduction removes the $O(N^{-1})$ first order term from the small-sample bias of the Maximum Likelihood Estimator. Here we show that the general Firth bias reduction technique simplifies to encouraging uniform class assignment probabilities for multinomial logistic classification, and almost has the same effect in cosine classifiers. We derive an easy-to-implement optimization objective for Firth penalized multinomial logistic and cosine classifiers, which is equivalent to penalizing the cross-entropy loss with a KL-divergence between the uniform label distribution and the predictions. Then, we empirically evaluate that it is consistently effective across the board for few-shot image classification, regardless of (1) the feature representations from different backbones, (2) the number of samples per class, and (3) the number of classes. Finally, we show the robustness of Firth bias reduction, in the case of imbalanced data distribution. Our implementation is available at https://github.com/ehsansaleh/firth_bias_reduction",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51032350",
                        "name": "Saba Ghaffari"
                    },
                    {
                        "authorId": "2141211761",
                        "name": "Ehsan Saleh"
                    },
                    {
                        "authorId": "121068894",
                        "name": "David A. Forsyth"
                    },
                    {
                        "authorId": "2302062",
                        "name": "Yu-Xiong Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The CIFAR-FS dataset (Bertinetto et al., 2018) is derived from the original CIFAR-100 dataset (Krizhevsky et al.",
                "Next, we compare our proposed few-shot approach with other state-of-the-art methods on CIFAR-FS and FC-100 datasets.",
                "(13)\nA.2 EXPERIMENTS ON CIFAR-FS AND FC-100\nHere, we conduct the experiments on the CIFAR-FS and the FC-100 datasets.",
                "The pre-trained model, by itself, outperforms several meta-learning approaches in numerous FSL datasets (e.g., miniImageNet, tieredImageNet, CIFAR-FS, etc.).",
                "Experimental results on miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFARFS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al., 2018) datasets are provided demonstrating the efficacy of the proposed approach compared to other state-of-the-art few-shot learning\u2026",
                "In this section, we present our experimental results in various few-shot learning benchmarks, including miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFAR-FS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al., 2018) 3.",
                "Experimental results on miniImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFARFS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al., 2018) datasets are provided demonstrating the efficacy of the proposed approach compared to other state-of-the-art few-shot learning methods.",
                ", 2018), CIFAR-FS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al.",
                ", 2018), CIFARFS (Bertinetto et al., 2018), and FC-100 (Oreshkin et al.",
                "The CIFAR-FS dataset (Bertinetto et al., 2018) is derived from the original CIFAR-100 dataset (Krizhevsky et al., 2009) by splitting 100 classes into 64 training classes, 16 validation classes, and 20 testing classes.",
                "3Due to page limits, we discuss the experiments on CIFAR-FS and FC-100 in the appendix.\nencoder f\u03b8 of the Whole-Classification network, and use it to compute the TAS in the task affinity phase.",
                "Here, we fist present the proof of the Theorem 1, and then we provide more experimental results on CIFAR-FS and FC-100 datasets."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "87397e5d3eaede08709f5d1d8b83da9823e6c1f8",
                "externalIds": {
                    "DBLP": "conf/iclr/LeDST22",
                    "ArXiv": "2110.02399",
                    "CorpusId": 238408300
                },
                "corpusId": 238408300,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/87397e5d3eaede08709f5d1d8b83da9823e6c1f8",
                "title": "Task Affinity with Maximum Bipartite Matching in Few-Shot Learning",
                "abstract": "We propose an asymmetric affinity score for representing the complexity of utilizing the knowledge of one task for learning another one. Our method is based on the maximum bipartite matching algorithm and utilizes the Fisher Information matrix. We provide theoretical analyses demonstrating that the proposed score is mathematically well-defined, and subsequently use the affinity score to propose a novel algorithm for the few-shot learning problem. In particular, using this score, we find relevant training data labels to the test data and leverage the discovered relevant data for episodically fine-tuning a few-shot model. Results on various few-shot benchmark datasets demonstrate the efficacy of the proposed approach by improving the classification accuracy over the state-of-the-art methods even when using smaller models.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1387147326",
                        "name": "Cat P. Le"
                    },
                    {
                        "authorId": "27320445",
                        "name": "Juncheng Dong"
                    },
                    {
                        "authorId": "36050308",
                        "name": "Mohammadreza Soltani"
                    },
                    {
                        "authorId": "1780864",
                        "name": "V. Tarokh"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "554f49cb06eed4ea0cd6fdddb6eecac332cde344",
                "externalIds": {
                    "DBLP": "conf/iccvw/LiuW21",
                    "DOI": "10.1109/ICCVW54120.2021.00124",
                    "CorpusId": 237257803
                },
                "corpusId": 237257803,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/554f49cb06eed4ea0cd6fdddb6eecac332cde344",
                "title": "Few-shot Learning with Online Self-Distillation",
                "abstract": "Few-shot learning has been a long-standing problem in learning to learn. This problem typically involves training a model on an extremely small amount of data and testing the model on the out-of-distribution data. The focus of recent few-shot learning research has been on the development of good representation models that can quickly adapt to test tasks. To that end, we come up with a model that learns representation through online self-distillation. Our model combines supervised training with knowledge distillation via a continuously updated teacher. We also identify that data augmentation plays an important role in producing robust features. Our final model is trained with CutMix augmentation and online self-distillation. On the commonly used benchmark miniImageNet, our model achieves 67.07% and 83.03% under the 5-way 1-shot setting and the 5-way 5-shot setting, respectively. It outperforms counterparts of its kind by 2.25% and 0.89%.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1391191077",
                        "name": "Sihan Liu"
                    },
                    {
                        "authorId": "2118462083",
                        "name": "Yue Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Meanwhile, optimization-based approaches employ bi-level optimization to learn the learning procedures, such as initialization and weight updates, that will be used to adapt to new tasks with few examples [2, 4, 5, 10, 21, 26, 38].",
                "Several works attempted to overcome the difficulty either by attempting to find a better initialization [5, 13, 11, 15, 45, 49] or a better fast adaptation process (inner-loop update rule) [2, 7, 20, 21, 34].",
                "There has been recent studies on improving the overall performance either by enhancing the learning scheme of initialization [5, 15, 34, 43, 45] or improving gradient-based fine-tuning process [2, 4, 21, 38]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8427455565ca12bcb6572ff7f29eb58515f36f28",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-03909",
                    "ArXiv": "2110.03909",
                    "DOI": "10.1109/iccv48922.2021.00933",
                    "CorpusId": 238531408
                },
                "corpusId": 238531408,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/8427455565ca12bcb6572ff7f29eb58515f36f28",
                "title": "Meta-Learning with Task-Adaptive Loss Function for Few-Shot Learning",
                "abstract": "In few-shot learning scenarios, the challenge is to generalize and perform well on new unseen examples when only very few labeled examples are available for each task. Model-agnostic meta-learning (MAML) has gained the popularity as one of the representative few-shot learning methods for its flexibility and applicability to diverse problems. However, MAML and its variants often resort to a simple loss function without any auxiliary loss function or regularization terms that can help achieve better generalization. The problem lies in that each application and task may require different auxiliary loss function, especially when tasks are diverse and distinct. Instead of attempting to hand-design an auxiliary loss function for each application and task, we introduce a new meta-learning framework with a loss function that adapts to each task. Our proposed framework, named Meta-Learning with Task-Adaptive Loss Function (MeTAL), demonstrates the effectiveness and the flexibility across various domains, such as few-shot classification and few-shot regression.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "148009160",
                        "name": "Sungyong Baik"
                    },
                    {
                        "authorId": "2149219663",
                        "name": "Janghoon Choi"
                    },
                    {
                        "authorId": "48206011",
                        "name": "Heewon Kim"
                    },
                    {
                        "authorId": "2142378893",
                        "name": "Dohee Cho"
                    },
                    {
                        "authorId": "3221917",
                        "name": "Jaesik Min"
                    },
                    {
                        "authorId": "2110246953",
                        "name": "Kyoung Mu Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We compare our method with state-of-the-art FSL methods in the inductive and transductive settings on the miniImageNet, tiered-ImageNet, CUB, and CIFAR-FS datasets, where 1-shot/5-shot 5-way classification were implemented\nand query sets had 15 samples per class.",
                "We conducted experiments on four popular datasets: mini-ImageNet [50], tiered-ImageNet [40], CUB [51], and CIFAR-FS [4].",
                "We used BigResNet12 on tiered-ImageNet and CIFAR-FS, and ConvNet on the CUB dataset."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "37ce63358c3f8d98af3500cb988d5b109af9c480",
                "externalIds": {
                    "DBLP": "conf/iccv/GaoWJH21",
                    "DOI": "10.1109/ICCV48922.2021.00857",
                    "CorpusId": 244072370
                },
                "corpusId": 244072370,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/37ce63358c3f8d98af3500cb988d5b109af9c480",
                "title": "Curvature Generation in Curved Spaces for Few-Shot Learning",
                "abstract": "Few-shot learning describes the challenging problem of recognizing samples from unseen classes given very few labeled examples. In many cases, few-shot learning is cast as learning an embedding space that assigns test samples to their corresponding class prototypes. Previous methods assume that data of all few-shot learning tasks comply with a fixed geometrical structure, mostly a Euclidean structure. Questioning this assumption that is clearly difficult to hold in real-world scenarios and incurs distortions to data, we propose to learn a task-aware curved embedding space by making use of the hyperbolic geometry. As a result, task-specific embedding spaces where suitable curvatures are generated to match the characteristics of data are constructed, leading to more generic embedding spaces. We then leverage on intra-class and inter-class context information in the embedding space to generate class prototypes for discriminative classification. We conduct a comprehensive set of experiments on inductive and transductive few-shot learning, demonstrating the benefits of our proposed method over existing embedding methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2116492882",
                        "name": "Zhi Gao"
                    },
                    {
                        "authorId": "150352923",
                        "name": "Yuwei Wu"
                    },
                    {
                        "authorId": "7415267",
                        "name": "Yunde Jia"
                    },
                    {
                        "authorId": "1686714",
                        "name": "M. Harandi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The results on Omniglot and CIFAR-FS are reported in Table 3.",
                "Some recent studies along this line include Matching Networks [49], which employs the cosine similarity, Prototypical Networks [43], which uses the Euclidean distance to compute the similarity, Relation Network [44], which uses a relation module as the similarity function, ridge regression [6], and graph neural networks [39].",
                "We experiment with four datasets for few-shot learning: Omniglot [24], MiniImageNet [50], TieredImageNet [37], and CIFAR-FS [6]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b96024a659c8c4f48087d86d59492cda8e6ae898",
                "externalIds": {
                    "DBLP": "conf/iccv/JamalWG21",
                    "DOI": "10.1109/ICCV48922.2021.00651",
                    "CorpusId": 244102102
                },
                "corpusId": 244102102,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/b96024a659c8c4f48087d86d59492cda8e6ae898",
                "title": "A Lazy Approach to Long-Horizon Gradient-Based Meta-Learning",
                "abstract": "Gradient-based meta-learning first trains task-specific models by an inner loop and then backpropagates meta-gradients through the loop to update the meta-model. To avoid high-order gradients, existing methods either take a small number of inner steps or approximate the meta-updates for the situations that the meta-model and task models lie in the same space. To enable long inner horizons for more general meta-learning problems, we instead propose an intuitive teacher-student strategy. The key idea is to employ a student network to adequately explore the search space of task-specific models, followed by a teacher\u2019s \"leap\" toward the regions probed by the student. The teacher not only arrives at a high-quality model but also defines a lightweight computational graph for the meta-gradients. Our approach is generic; it performs well when applied to four meta-learning algorithms over three tasks: few-shot learning, long-tailed object recognition, and adversarial blackbox attack.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "34902211",
                        "name": "Muhammad Abdullah Jamal"
                    },
                    {
                        "authorId": "1390771606",
                        "name": "Liqiang Wang"
                    },
                    {
                        "authorId": "40206014",
                        "name": "Boqing Gong"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9fb9def34e3488e07f753ece49643eb3dfd3e1a6",
                "externalIds": {
                    "DBLP": "conf/iccv/WuZ0021",
                    "DOI": "10.1109/ICCV48922.2021.00832",
                    "CorpusId": 244407905
                },
                "corpusId": 244407905,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/9fb9def34e3488e07f753ece49643eb3dfd3e1a6",
                "title": "Task-aware Part Mining Network for Few-Shot Learning",
                "abstract": "Few-Shot Learning (FSL) aims at classifying samples into new unseen classes with only a handful of labeled samples available. However, most of the existing methods are based on the image-level pooled representation, yet ignore considerable local clues that are transferable across tasks. To address this issue, we propose an end-to-end Task-aware Part Mining Network (TPMN) by integrating an automatic part mining process into the metric-based model for FSL. The proposed TPMN model enjoys several merits. First, we design a meta filter learner to generate task-aware part filters based on the task embedding in a meta-learning way. The task-aware part filters can adapt to any individual task and automatically mine task-related local parts even for an unseen task. Second, an adaptive importance generator is proposed to identify key local parts and assign adaptive importance weights to different parts. To the best of our knowledge, this is the first work to automatically exploit the task-aware local parts in a meta-learning way for FSL. Extensive experimental results on four standard benchmarks demonstrate that the proposed model performs favorably against state-of-the-art FSL methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2110410048",
                        "name": "Jiamin Wu"
                    },
                    {
                        "authorId": "2146331327",
                        "name": "Tianzhu Zhang"
                    },
                    {
                        "authorId": "1699819",
                        "name": "Yongdong Zhang"
                    },
                    {
                        "authorId": "2116505227",
                        "name": "Feng Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Given that high-dimensional features have better modeling capacity but are computationally expensive to work with, each meta-learning task is then formulated as a convex optimization problem and solved in its low-dimensional dual space [9, 34]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7d92f5b00c2843037bafd49e30686560ffa1edb5",
                "externalIds": {
                    "DBLP": "conf/iccv/GuiBSHHW21",
                    "DOI": "10.1109/ICCV48922.2021.00858",
                    "CorpusId": 244426606
                },
                "corpusId": 244426606,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/7d92f5b00c2843037bafd49e30686560ffa1edb5",
                "title": "Learning to Hallucinate Examples from Extrinsic and Intrinsic Supervision",
                "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks. This work investigates two important yet overlooked natural supervision signals for guiding the hallucination process \u2013 (i) extrinsic: classifiers trained on hallucinated examples should be close to strong classifiers that would be learned from a large amount of real examples; and (ii) intrinsic: clusters of hallucinated and real examples belonging to the same class should be pulled together, while simultaneously pushing apart clusters of hallucinated and real examples from different classes. We achieve (i) by introducing an additional mentor model on data-abundant base classes for directing the hallucinator, and achieve (ii) by performing contrastive learning between hallucinated and real examples. As a general, model-agnostic framework, our dual mentor-and self-directed (DMAS) hallucinator significantly improves few-shot learning performance on widely-used benchmarks in various scenarios.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1970583",
                        "name": "Liangke Gui"
                    },
                    {
                        "authorId": "1453740540",
                        "name": "Adrien Bardes"
                    },
                    {
                        "authorId": "145124475",
                        "name": "R. Salakhutdinov"
                    },
                    {
                        "authorId": "7661726",
                        "name": "Alexander Hauptmann"
                    },
                    {
                        "authorId": "145670946",
                        "name": "M. Hebert"
                    },
                    {
                        "authorId": "2302062",
                        "name": "Yu-Xiong Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Another popular approach [2, 39, 34, 4, 6] is to develop a meta-learner to optimize key hyper-parameters (e.",
                "Baselines FPAIT [11] directly leverages MAML [13] to deal with few-shot VQA and IC tasks; Prototypical Net [42], Relation Net [44], R2D2 [6], and DN4 [28] focus on few-shot classification."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "19d6bf09027c7c7aedb032c5df33d417f5dd7f67",
                "externalIds": {
                    "DBLP": "conf/iccv/0001WCJX021",
                    "DOI": "10.1109/ICCV48922.2021.00218",
                    "CorpusId": 244868291
                },
                "corpusId": 244868291,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/19d6bf09027c7c7aedb032c5df33d417f5dd7f67",
                "title": "Hierarchical Graph Attention Network for Few-shot Visual-Semantic Learning",
                "abstract": "Deep learning has made tremendous success in computer vision, natural language processing and even visual-semantic learning, which requires a huge amount of labeled training data. Nevertheless, the goal of human-level intelligence is to enable a model to quickly obtain an in-depth understanding given a small number of samples, especially with heterogeneity in the multi-modal scenarios such as visual question answering and image captioning. In this paper, we study the few-shot visual-semantic learning and present the Hierarchical Graph ATtention network (HGAT). This two-stage network models the intra- and inter-modal relationships with limited image-text samples. The main contributions of HGAT can be summarized as follows: 1) it sheds light on tackling few-shot multi-modal learning problems, which focuses primarily, but not exclusively on visual and semantic modalities, through better exploitation of the intra-relationship of each modality and an attention-based co-learning framework between modalities using a hierarchical graph-based architecture; 2) it achieves superior performance on both visual question answering and image captioning in the few-shot setting; 3) it can be easily extended to the semi-supervised setting where image-text samples are partially unlabeled. We show via extensive experiments that HGAT delivers state-of-the-art performance on three widely-used benchmarks of two visual-semantic learning tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2706269",
                        "name": "Chengxiang Yin"
                    },
                    {
                        "authorId": "2112562410",
                        "name": "Kun Wu"
                    },
                    {
                        "authorId": "1939695",
                        "name": "Zhengping Che"
                    },
                    {
                        "authorId": "2114186861",
                        "name": "Bo Jiang"
                    },
                    {
                        "authorId": "48559420",
                        "name": "Zhiyuan Xu"
                    },
                    {
                        "authorId": "145357789",
                        "name": "Jian Tang"
                    },
                    {
                        "authorId": "2049098948",
                        "name": "Didi Chuxing"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "85b69831032668d12efee12d9acb8bcf8d6d21cf",
                "externalIds": {
                    "DBLP": "conf/iccv/HuangG0DX21",
                    "DOI": "10.1109/ICCV48922.2021.00855",
                    "CorpusId": 246527070
                },
                "corpusId": 246527070,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/85b69831032668d12efee12d9acb8bcf8d6d21cf",
                "title": "Pseudo-loss Confidence Metric for Semi-supervised Few-shot Learning",
                "abstract": "Semi-supervised few-shot learning is developed to train a classifier that can adapt to new tasks with limited labeled data and a fixed quantity of unlabeled data. Most semi-supervised few-shot learning methods select pseudo-labeled data of unlabeled set by task-specific confidence estimation. This work presents a task-unified confidence estimation approach for semi-supervised few-shot learning, named pseudo-loss confidence metric (PLCM). It measures the data credibility by the loss distribution of pseudo-labels, which is synthetical considered multi-tasks. Specifically, pseudo-labeled data of different tasks are mapped to a unified metric space by mean of the pseudo-loss model, making it possible to learn the prior pseudo-loss distribution. Then, confidence of pseudo-labeled data is estimated according to the distribution component confidence of its pseudo-loss. Thus highly reliable pseudo-labeled data are selected to strengthen the classifier. Moreover, to overcome the pseudo-loss distribution shift and improve the effectiveness of classifier, we advance the multi-step training strategy coordinated with the class balance measures of class-apart selection and class weight. Experimental results on four popular benchmark datasets demonstrate that the proposed approach can effectively select pseudo-labeled data and achieve the state-of-the-art performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2112768810",
                        "name": "Kai Huang"
                    },
                    {
                        "authorId": "1382076201",
                        "name": "Jie Geng"
                    },
                    {
                        "authorId": "2116484978",
                        "name": "Wen Jiang"
                    },
                    {
                        "authorId": "1928801",
                        "name": "Xinyang Deng"
                    },
                    {
                        "authorId": "2149237319",
                        "name": "Zhe Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", Euclidean distance) or directly learn the metric [49, 56, 3, 40, 16, 58]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a0ac072fb6b54fe5e8167a03de1b9fc78d4845fe",
                "externalIds": {
                    "DBLP": "conf/iccv/FeiG0X21",
                    "DOI": "10.1109/ICCV48922.2021.00021",
                    "CorpusId": 247191876
                },
                "corpusId": 247191876,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/a0ac072fb6b54fe5e8167a03de1b9fc78d4845fe",
                "title": "Z-Score Normalization, Hubness, and Few-Shot Learning",
                "abstract": "The goal of few-shot learning (FSL) is to recognize a set of novel classes with only few labeled samples by exploiting a large set of abundant base class samples. Adopting a meta-learning framework, most recent FSL methods meta-learn a deep feature embedding network, and during inference classify novel class samples using nearest neighbor in the learned high-dimensional embedding space. This means that these methods are prone to the hubness problem, that is, a certain class prototype becomes the nearest neighbor of many test instances regardless which classes they belong to. However, this problem is largely ignored in existing FSL studies. In this work, for the first time we show that many FSL methods indeed suffer from the hubness problem. To mitigate its negative effects, we further propose to employ z-score feature normalization, a simple yet effective trans-formation, during meta-training. A theoretical analysis is provided on why it helps. Extensive experiments are then conducted to show that with z-score normalization, the performance of many recent FSL methods can be boosted, resulting in new state-of-the-art on three benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "21313225",
                        "name": "Nanyi Fei"
                    },
                    {
                        "authorId": "1939358",
                        "name": "Yizhao Gao"
                    },
                    {
                        "authorId": "1776220",
                        "name": "Zhiwu Lu"
                    },
                    {
                        "authorId": "2120489266",
                        "name": "Tao Xiang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c465c07c7ce3eb8972b10bdf31a0e56b5e142798",
                "externalIds": {
                    "ArXiv": "2109.12932",
                    "DBLP": "journals/corr/abs-2109-12932",
                    "DOI": "10.1007/s11432-022-3700-8",
                    "CorpusId": 237940459
                },
                "corpusId": 237940459,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c465c07c7ce3eb8972b10bdf31a0e56b5e142798",
                "title": "Sparse Spatial Transformers for Few-Shot Learning",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2149050779",
                        "name": "Haoxing Chen"
                    },
                    {
                        "authorId": "1802772",
                        "name": "Huaxiong Li"
                    },
                    {
                        "authorId": "2140323921",
                        "name": "Yaohui Li"
                    },
                    {
                        "authorId": "2109521795",
                        "name": "Chunlin Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recent efforts on reducing the impact of DSP are generally based on designing a more robust and adaptive FEM to generate better features, such as introducing meta-learning strategy [10] [2]; self-supervised learning strategy [23] [30]; knowledge distillation strategy [38] [29].",
                "(2) Meta feature (Meta-Fea), the FEM introduces the meta-learning strategy to the network, just like [2].",
                "(3)Weevaluate the proposedmethod on four benchmark datasets (mini-ImageNet, tiered-ImageNet, CIFAR-FS, FC100) and achieve significant improvements of 2.1%-7.8% compared with other stateof-the-art methods.",
                "(2)Metric learning based methods, focusing on looking for ideal distance metrics to strengthen model\u2019s robustness, including ProtoNet [36], MetaOpt [2], TADAM [25] \ud835\udc52\ud835\udc61 \ud835\udc4e\ud835\udc59 .",
                "MHFC has significant improvements of at least 7.7%, 10.0%, 6.8% and 4.7% on miniImageNet, tiered-ImageNet, CIFAR-FS, FC100 datasets.",
                ",M \u03b8 , where h = [1, 2] denotes the hth head.",
                "Both CIFAR-FS and FC100 are the subsets of CIFAR-100 dataset [14], and consist of 100 classes.",
                "And on the 5-way 5-shot case, the MHFC also exceeds others at least 3.0%,\n2.8%, 4.8% and 6.9% on mini-ImageNet, tiered-ImageNet, CIFAR-FS, FC100 datasets.",
                "(2)Metric learning based methods, focusing on looking for ideal distance metrics to strengthen model\u2019s robustness, including ProtoNet [36], MetaOpt [2], TADAM [25] et al .",
                "MHFC is a simple non-parametric model that can directly fuse multi-head features extracted from the existing FEMs, such as ICI-Net [47], MetaOpt-Net [2].",
                "We follow the split introduced in [2] to divide CIFAR-FS into 64 classes as base set, 16 classes as validation set, 20 classes as novel set, and divide FC100 into 60 classes as base set, 20 classes as validation set, 20 classes as novel set.",
                "We carry out experiments on five benchmark datasets, including mini-ImageNet [43], tiered-ImageNet [28], CIFAR-FS [2], FC100 [25], and CUB [44]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1998b343e142579c1a6aaa78d8f83740d120d5d3",
                "externalIds": {
                    "DBLP": "conf/mm/0006XWXZWL21",
                    "ArXiv": "2109.07785",
                    "DOI": "10.1145/3474085.3475553",
                    "CorpusId": 237532122
                },
                "corpusId": 237532122,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1998b343e142579c1a6aaa78d8f83740d120d5d3",
                "title": "MHFC: Multi-Head Feature Collaboration for Few-Shot Learning",
                "abstract": "Few-shot learning (FSL) aims to address the data-scarce problem. A standard FSL framework is composed of two components: (1) Pre-train. Employ the base data to generate a CNN-based feature extraction model (FEM). (2) Meta-test. Apply the trained FEM to acquire the novel data's features and recognize them. FSL relies heavily on the design of the FEM. However, various FEMs have distinct emphases. For example, several may focus more attention on the contour information, whereas others may lay particular emphasis on the texture information. The single-head feature is only a one-sided representation of the sample. Besides the negative influence of cross-domain (e.g., the trained FEM can not adapt to the novel class flawlessly), the distribution of novel data may have a certain degree of deviation compared with the ground truth distribution, which is dubbed as distribution-shift-problem (DSP). To address the DSP, we propose Multi-Head Feature Collaboration (MHFC) algorithm, which attempts to project the multi-head features (e.g., multiple features extracted from a variety of FEMs) to a unified space and fuse them to capture more discriminative information. Typically, first, we introduce a subspace learning method to transform the multi-head features to aligned low-dimensional representations. It corrects the DSP via learning the feature with more powerful discrimination and overcomes the problem of inconsistent measurement scales from different head features. Then, we design an attention block to update combination weights for each head feature automatically. It comprehensively considers the contribution of various perspectives and further improves the discrimination of features. We evaluate the proposed method on five benchmark datasets (including cross-domain experiments) and achieve significant improvements of 2.1%-7.8% compared with state-of-the-arts.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "47975317",
                        "name": "Shuai Shao"
                    },
                    {
                        "authorId": "144218954",
                        "name": "Lei Xing"
                    },
                    {
                        "authorId": "2152547674",
                        "name": "Yan Wang"
                    },
                    {
                        "authorId": "1606128526",
                        "name": "Rui Xu"
                    },
                    {
                        "authorId": "2152873165",
                        "name": "Chunyan Zhao"
                    },
                    {
                        "authorId": "7707388",
                        "name": "Yanjiang Wang"
                    },
                    {
                        "authorId": "1678435",
                        "name": "Baodi Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "More recently, differentiable solvers have also been adopted for meta-learning [4, 25] as well."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a7ccfc060b4f9830f4570339eafbe9ff93b1a27c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2109-05535",
                    "ArXiv": "2109.05535",
                    "DOI": "10.1007/978-3-030-86520-7_45",
                    "CorpusId": 231993574
                },
                "corpusId": 231993574,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a7ccfc060b4f9830f4570339eafbe9ff93b1a27c",
                "title": "Adversarial Representation Learning with Closed-Form Solvers",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "9505785",
                        "name": "Bashir Sadeghi"
                    },
                    {
                        "authorId": "2108759651",
                        "name": "Lan Wang"
                    },
                    {
                        "authorId": "144223220",
                        "name": "Vishnu Naresh Boddeti"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c9943aec3dfb3c38b57aee430b9c000970327115",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2109-04898",
                    "ArXiv": "2109.04898",
                    "DOI": "10.1109/TPAMI.2023.3312125",
                    "CorpusId": 237485475,
                    "PubMed": "37669193"
                },
                "corpusId": 237485475,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/c9943aec3dfb3c38b57aee430b9c000970327115",
                "title": "LibFewShot: A Comprehensive Library for Few-shot Learning",
                "abstract": "Few-shot learning, especially few-shot image classification, has received increasing attention and witnessed significant advances in recent years. Some recent studies implicitly show that many generic techniques or \"tricks\", such as data augmentation, pre-training, knowledge distillation, and self-supervision, may greatly boost the performance of a few-shot learning method. Moreover, different works may employ different software platforms, backbone architectures and input image sizes, making fair comparisons difficult and practitioners struggle with reproducibility. To address these situations, we propose a comprehensive library for few-shot learning (LibFewShot) by re-implementing eighteen state-of-the-art few-shot learning methods in a unified framework with the same single codebase in PyTorch. Furthermore, based on LibFewShot, we provide comprehensive evaluations on multiple benchmarks with various backbone architectures to evaluate common pitfalls and effects of different training tricks. In addition, with respect to the recent doubts on the necessity of meta- or episodic-training mechanism, our evaluation results confirm that such a mechanism is still necessary especially when combined with pre-training. We hope our work can not only lower the barriers for beginners to enter the area of few-shot learning but also elucidate the effects of nontrivial tricks to facilitate intrinsic research on few-shot learning. The source code is available from https://github.com/RL-VIG/LibFewShot.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2108691450",
                        "name": "Wenbin Li"
                    },
                    {
                        "authorId": "28113294",
                        "name": "C. Dong"
                    },
                    {
                        "authorId": "51305326",
                        "name": "Pinzhuo Tian"
                    },
                    {
                        "authorId": "1379496298",
                        "name": "Tiexin Qin"
                    },
                    {
                        "authorId": "2145180721",
                        "name": "Xuesong Yang"
                    },
                    {
                        "authorId": "47196654",
                        "name": "Ziyi Wang"
                    },
                    {
                        "authorId": "2055851838",
                        "name": "Jing Huo"
                    },
                    {
                        "authorId": "2475959",
                        "name": "Yinghuan Shi"
                    },
                    {
                        "authorId": null,
                        "name": "Lei Wang"
                    },
                    {
                        "authorId": "145644819",
                        "name": "Yang Gao"
                    },
                    {
                        "authorId": "2116782926",
                        "name": "Jiebo Luo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Images Classes Split miniImageNet [39] 60,000 100 64/16/20 tieredImageNet [31] 779,165 608 351/97/160 CIFAR-FS [3] 60,000 100 60/16/20 CUB-200-2011 [40] 11,788 200 100/50/50",
                "We validate our BML on four commonly used benchmarks, including miniImageNet [39], tieredImageNet [31], CIFAR-FS [3] and CUB-200-2011 (CUB) [40].",
                "As for CIFAR-FS, we surpass all competitors and reach a new SoTA, including LR+ICI [41] which is based on the transductive strategy."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8bcb65121ee48ef643d506f4301d1b8c7b5d4017",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-12104",
                    "ArXiv": "2108.12104",
                    "DOI": "10.1109/ICCV48922.2021.00829",
                    "CorpusId": 237347136
                },
                "corpusId": 237347136,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/8bcb65121ee48ef643d506f4301d1b8c7b5d4017",
                "title": "Binocular Mutual Learning for Improving Few-shot Classification",
                "abstract": "Most of the few-shot learning methods learn to transfer knowledge from datasets with abundant labeled data (i.e., the base set). From the perspective of class space on base set, existing methods either focus on utilizing all classes under a global view by normal pretraining, or pay more attention to adopt an episodic manner to train meta-tasks within few classes in a local view. However, the interaction of the two views is rarely explored. As the two views capture complementary information, we naturally think of the compatibility of them for achieving further performance gains. Inspired by the mutual learning paradigm and binocular parallax, we propose a unified framework, namely Binocular Mutual Learning (BML), which achieves the compatibility of the global view and the local view through both intraview and cross-view modeling. Concretely, the global view learns in the whole class space to capture rich inter-class relationships. Meanwhile, the local view learns in the local class space within each episode, focusing on matching positive pairs correctly. In addition, cross-view mutual interaction further promotes the collaborative learning and the implicit exploration of useful knowledge from each other. During meta-test, binocular embeddings are aggregated together to support decision-making, which greatly improve the accuracy of classification. Extensive experiments conducted on multiple benchmarks including cross-domain validation confirm the effectiveness of our method1.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2112252436",
                        "name": "Ziqi Zhou"
                    },
                    {
                        "authorId": "2004204769",
                        "name": "Xi Qiu"
                    },
                    {
                        "authorId": "144418234",
                        "name": "Jiangtao Xie"
                    },
                    {
                        "authorId": "2110430704",
                        "name": "Jianan Wu"
                    },
                    {
                        "authorId": "2115811693",
                        "name": "Chi Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Some of model-based meta-algorithms avoid innertask training by learning a meta amortization network G parameterized by \u03c8 to generate task-specific parameters \u03c6Ti using the support set as inputs (Gordon et al., 2018b,a), i.e.,\n\u03c6Ti = G\u03c8 ( f\u03b8(DtrTi) ) .",
                "\u2026with closed-form solvers can be applied as the inner-task algorithm, such as nearest neighbor classification (Snell et al., 2017), ridge regression (Bertinetto et al., 2019), SVM (Lee et al., 2019) or gradient descent with a learned initialization (Finn et al., 2017), which significantly limits\u2026",
                "Several meta-algorithms adopt a simple algorithm with convex objective function as inner-task algorithm such that the taskspecific parameters \u03c6Ti have a closed-form solution (Bertinetto et al., 2019; Lee et al., 2019).",
                "(5)\nThen, the gradients of \u03b8 include a second-order gradient of \u03b8, because \u2207\u03b8\u03c6Ti = I \u2212 \u22072\u03b8 (\u2211 (xj ,yj)\u2208DtrTi l ( f\u03b8(xj), yj )) .",
                "For example, (Bertinetto et al., 2019) uses ridge regression as inner-task algorithm, and the closed-form solution is\n\u03c6Ti = (X\u03b8 TX\u03b8 + \u03bbI) \u22121X\u03b8 TY.",
                "Similarly, over the embedding space, meta-algorithms with closedform solutions apply simple inner-task algorithms with a closed-form solution such as ridge regression (Bertinetto et al., 2019) or SVM (Lee et al.",
                "Next, meta-update is performed by aggregating the predictions of all the predictors on the query set to obtain final predictions and then using the final predictions to update the shared meta-parameters \u03b8. Formally, the meta-training procedure of A2M is formulated as follows,\nInner-task adaptation: Fix \u03b8, for e \u2208 {1, 2, . . . , E}, \u03c6eTi = arg minx\u03c6e Ti L(DtrTi ; \u03b8, x\u03c6eTi ), Meta-update: Fix {\u03c6eTi} E e=1, \u03b8 = \u03b8 \u2212 l\u03b8\u2207\u03b8L(DtsTi ; \u03b8, {\u03c6 e Ti} E e=1).",
                ", 2017), ridge regression (Bertinetto et al., 2019), SVM (Lee et al.",
                "2, during inner-task adaptation, we train a bag of diverse algorithms {Ae}Ee=1 separately with the embedded support set and obtain E predictors, i.e., {Ae(DtrTi ; \u03b8)} E e=1.",
                "The iteration scheme is formulated as follows:\nInner-task adaptation: Fix \u03b8, \u03c6Ti = arg minx\u03c6Ti L(DtrTi ; \u03b8, x\u03c6Ti ), (9) Meta-update: Fix \u03c6Ti , \u03b8 = \u03b8 \u2212 l\u03b8\u2207\u03b8L(DtsTi ; \u03b8, \u03c6Ti), (10)\nwhere \u03b8 refers to the meta-parameters, i.e., the global parameters shared by all the tasks, and \u03c6Ti refers to the task-specific parameters, i.e., the local parameters which are different among the tasks.",
                "For example, (Bertinetto et al., 2019) uses ridge regression as inner-task algorithm, and the closed-form solution is",
                "For prototypical networks (Snell et al., 2017), the task-specific parameters are the mean vectors of same-class support samples, which can be computed as\n\u03c6Ti = { 1\nN \u2211 (xj ,yj)\u2208DtrTi ,yj=k f\u03b8(xj)}Kk=1.",
                "(8)\nFor brevity, X\u03b8 = {f\u03b8(xj)}mj=1 and Y = {yj}mj=1, where (xj , yj) \u2208 DtrTi (Bertinetto et al., 2019).",
                "During inner-task adaptation, the inner-task algorithm A runs through the support set DtrTi and outputs a predictor g\u03c6Ti parameterized by taskspecific parameters \u03c6Ti .",
                "For example, the taskspecific parameters of a typical gradient-based meta-algotithm, MAML (Finn et al., 2017) \u03c6Ti is\n\u03c6Ti = \u03b8 \u2212 l\u03c6Ti\u2207\u03b8L(D tr Ti ; \u03b8) = \u03b8 \u2212\u2207\u03b8 ( \u2211 (xj ,yj)\u2208DtrTi l ( f\u03b8(xj), yj )) .",
                "Hence, the inner-task algorithm A should be solved analytically, i.e., \u03c6Ti should be an analytical expression of \u03b8,\n\u03c6Ti = s(DtrTi , \u03b8).",
                "2, the three algorithms are trained over the embedded support set independently, i.e,:\nA1: \u03c61Ti ={ck} K k=1 = {\n1\nN \u2211 zj\u2208DtrTi ,yj=k f\u03b8\u2032(xj)}Kk=1,\nA2:\u03c62Ti =\u03c6\u2212 l\u03c6\u2207\u03c6[ 1\nm \u2211 zj\u2208DtrTi \u2212 log ( eg\u03c6(f\u03b8\u2032 (xj))[yj ]\u2211 k\u2032 e g\u03c6(f\u03b8\u2032 (xj))[k \u2032] ) ],\nA3: \u03c63Ti =\u03c6 3 Ti \u2212 l\u03c63Ti \u2207\u03c63Ti [\n1\nm \u2211 zj\u2208DtrTi \u2212 log  eg\u03c63Ti (f\u03b8\u2032 (xj))[yj ]\u2211 k\u2032 e g \u03c63 Ti (f\u03b8\u2032 (xj))[k \u2032] ], (13) where A1, A2 and A3 denote the mean-centroid classification algorithm, the initializationbased algorithm and the two-layer MLP, respectively.",
                "Similarly, over the embedding space, meta-algorithms with closedform solutions apply simple inner-task algorithms with a closed-form solution such as ridge regression (Bertinetto et al., 2019) or SVM (Lee et al., 2019).",
                "During meta-training, given a set of training tasks {Ti \u223c p(\u03c4)}ni=1, the meta-algorithm observes the meta-samples D = {DTi = (DtrTi ,D ts Ti )}ni=1, where DtrTi is the training (support) set of task Ti and D ts Ti\nis the test (query) set of Ti.",
                "For brevity, X\u03b8 = {f\u03b8(xj)}j=1 and Y = {yj}j=1, where (xj , yj) \u2208 Dtr Ti (Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0cbb395c5cf4b11f2f58a6bb072e4077ca3ab411",
                "externalIds": {
                    "ArXiv": "2108.10557",
                    "DBLP": "journals/corr/abs-2108-10557",
                    "CorpusId": 237279376
                },
                "corpusId": 237279376,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0cbb395c5cf4b11f2f58a6bb072e4077ca3ab411",
                "title": "Adaptation-Agnostic Meta-Training",
                "abstract": "Many meta-learning algorithms can be formulated into an interleaved process, in the sense that task-specific predictors are learned during inner-task adaptation and meta-parameters are updated during meta-update. The normal meta-training strategy needs to differentiate through the inner-task adaptation procedure to optimize the meta-parameters. This leads to a constraint that the inner-task algorithms should be solved analytically. Under this constraint, only simple algorithms with analytical solutions can be applied as the inner-task algorithms, limiting the model expressiveness. To lift the limitation, we propose an adaptation-agnostic meta-training strategy. Following our proposed strategy, we can apply stronger algorithms (e.g., an ensemble of different types of algorithms) as the inner-task algorithm to achieve superior performance comparing with popular baselines. The source code is available at https://github.com/jiaxinchen666/AdaptationAgnosticMetaLearning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2124957356",
                        "name": "Jiaxin Chen"
                    },
                    {
                        "authorId": "2061239456",
                        "name": "Li-Ming Zhan"
                    },
                    {
                        "authorId": "19195265",
                        "name": "Xiao-Ming Wu"
                    },
                    {
                        "authorId": "145288211",
                        "name": "K. F. Chung"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We randomly construct a training batch of size 128 for the ImageNet family [57, 75] and 64 for CUB [76] & CIFAR-FS [3] to compute Lanchor.",
                "The hyperparameter \u03bb is set to 0.25, 0.5, 1.5 for ImageNet derivatives, CIFAR-FS, CUB, respectively. \u03b3 is set to 2 for CUB and 5 otherwise.",
                "For evaluation, we use four standard benchmarks for few-shot classification: miniImageNet, tieredImageNet, CUB-200-2011, and CIFAR-FS. miniImageNet [75] is a subset of ImageNet [60] consisting of 60,000 images uniformly distributed over 100 object classes.",
                "Our model uses a smaller backbone than that of several methods [17, 41, 53, 61] yet sets a new state of the art in both 5-way 1- shot and 5-shot settings on miniImageNet, CUB-200-2011, and CIFAR-FS datasets while being comparable to DeepEMD [87] on tieredImageNet.",
                "Following the recent work of [3], we use the same train/validation/test splits consisting of 64/16/20 object classes, respectively.",
                "CIFAR-FS [3] is built upon CIFAR-100 [29] dataset."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "4aa87f481bbe7e46bbd698e96a26e8728ccb1e70",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-09666",
                    "ArXiv": "2108.09666",
                    "DOI": "10.1109/ICCV48922.2021.00870",
                    "CorpusId": 237266674
                },
                "corpusId": 237266674,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/4aa87f481bbe7e46bbd698e96a26e8728ccb1e70",
                "title": "Relational Embedding for Few-Shot Classification",
                "abstract": "We propose to address the problem of few-shot classification by meta-learning \"what to observe\" and \"where to attend\" in a relational perspective. Our method lever-ages relational patterns within and between images via self-correlational representation (SCR) and cross-correlational attention (CCA). Within each image, the SCR module transforms a base feature map into a self-correlation tensor and learns to extract structural patterns from the tensor. Between the images, the CCA module computes cross-correlation between two image representations and learns to produce co-attention between them. Our Relational Embedding Network (RENet) combines the two relational modules to learn relational embedding in an end-to-end manner. In experimental evaluation, it achieves consistent improvements over state-of-the-art methods on four widely used few-shot classification benchmarks of miniImageNet, tieredImageNet, CUB-200-2011, and CIFAR-FS.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2088167050",
                        "name": "Dahyun Kang"
                    },
                    {
                        "authorId": "30557120",
                        "name": "Heeseung Kwon"
                    },
                    {
                        "authorId": "2067799001",
                        "name": "Juhong Min"
                    },
                    {
                        "authorId": "72643925",
                        "name": "Minsu Cho"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5b40ebc9b015a121c096fe3696b7128a16c4eb0b",
                "externalIds": {
                    "DBLP": "conf/ccris/HuangHHL21",
                    "DOI": "10.1145/3483845.3483873",
                    "CorpusId": 239459649
                },
                "corpusId": 239459649,
                "publicationVenue": {
                    "id": "5315da6a-ca26-469b-b986-dae8a0241449",
                    "name": "International Conference on Control, Robotics and Intelligent System",
                    "type": "conference",
                    "alternate_names": [
                        "CCRIS",
                        "Int Conf Control Robot Intell Syst"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5b40ebc9b015a121c096fe3696b7128a16c4eb0b",
                "title": "Learning A Linear Classifier by Transforming Feature Vectors for Few-shot Image Classification",
                "abstract": "Deep neural networks have achieved remarkable results in large-scale data domain. However, they have not performed well on few-shot image classification tasks. Here we propose a new meta-learning approach composed of an embedding network and a linear classifier learner. During the training phase, our approach (called Transformation Network) learns to learn a classifier by transforming the feature vectors produced by the embedding module. Once trained, a Transformation Network is able to classify images of new classes by the learned classifier. The ability of learning a discriminatively trained classifier could make our architecture adapt fast to new examples from unseen classes. We further describe implementation details upon the architecture convolutional networks and linear transformation operations. We demonstrate that our approach achieves improved performance on few-shot image classification tasks on two benchmarks and a self-made dataset.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3441469",
                        "name": "Wanrong Huang"
                    },
                    {
                        "authorId": "2113665703",
                        "name": "Yaqing Hu"
                    },
                    {
                        "authorId": "5992746",
                        "name": "Shuofeng Hu"
                    },
                    {
                        "authorId": "2109088093",
                        "name": "Jingde Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "572b24d2b79d06cd03ad800404e4f60a6dfe9961",
                "externalIds": {
                    "DBLP": "journals/pami/ZhangLYF23",
                    "ArXiv": "2108.05010",
                    "DOI": "10.1109/TPAMI.2023.3277881",
                    "CorpusId": 236976250,
                    "PubMed": "37216260"
                },
                "corpusId": 236976250,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/572b24d2b79d06cd03ad800404e4f60a6dfe9961",
                "title": "Prototype Completion for Few-Shot Learning",
                "abstract": "Few-shot learning (FSL) aims to recognize novel classes with few examples. Pre-training based methods effectively tackle the problem by pre-training a feature extractor and then fine-tuning it through the nearest centroid based meta-learning. However, results show that the fine-tuning step makes marginal improvements. In this paper, 1) we figure out the reason, i.e., in the pre-trained feature space, the base classes already form compact clusters while novel classes spread as groups with large variances, which implies that fine-tuning feature extractor is less meaningful; 2) instead of fine-tuning feature extractor, we focus on estimating more representative prototypes. Consequently, we propose a novel prototype completion based meta-learning framework. This framework first introduces primitive knowledge (i.e., class-level part or attribute annotations) and extracts representative features for seen attributes as priors. Second, a part/attribute transfer network is designed to learn to infer the representative features for unseen attributes as supplementary priors. Finally, a prototype completion network is devised to learn to complete prototypes with these priors. Moreover, to avoid the prototype completion error, we further develop a Gaussian based prototype fusion strategy that fuses the mean-based and completed prototypes by exploiting the unlabeled samples. At last, we also develop an economic prototype completion version for FSL, which does not need to collect primitive knowledge, for a fair comparison with existing FSL methods without external knowledge. Extensive experiments show that our method: i) obtains more accurate prototypes; ii) achieves superior performance on both inductive and transductive FSL settings.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "121178411",
                        "name": "Baoquan Zhang"
                    },
                    {
                        "authorId": "48569885",
                        "name": "Xutao Li"
                    },
                    {
                        "authorId": "144782498",
                        "name": "Yunming Ye"
                    },
                    {
                        "authorId": "2903685",
                        "name": "Shanshan Feng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We focus on a broad class of methods that we call meta-representation learning [1, 6, 10, 15], which is remarkably effective in practice and closely related to feature pre-training.",
                "In [1], the ridge regression estimator is chosen as the base learner Alg(\u03b8,D) = w(\u03c8\u03b8(D))"
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3a01c704e03567d73ae11717c16f6f4aa06c3248",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-04055",
                    "ArXiv": "2108.04055",
                    "CorpusId": 236957389
                },
                "corpusId": 236957389,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/3a01c704e03567d73ae11717c16f6f4aa06c3248",
                "title": "The Role of Global Labels in Few-Shot Classification and How to Infer Them",
                "abstract": "Few-shot learning is a central problem in meta-learning, where learners must quickly adapt to new tasks given limited training data. Recently, feature pre-training has become a ubiquitous component in state-of-the-art meta-learning methods and is shown to provide significant performance improvement. However, there is limited theoretical understanding of the connection between pre-training and meta-learning. Further, pre-training requires global labels shared across tasks, which may be unavailable in practice. In this paper, we show why exploiting pre-training is theoretically advantageous for meta-learning, and in particular the critical role of global labels. This motivates us to propose Meta Label Learning (MeLa), a novel meta-learning framework that automatically infers global labels to obtains robust few-shot models. Empirically, we demonstrate that MeLa is competitive with existing methods and provide extensive ablation experiments to highlight its key properties.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3368222",
                        "name": "Ruohan Wang"
                    },
                    {
                        "authorId": "1704699",
                        "name": "M. Pontil"
                    },
                    {
                        "authorId": "7666146",
                        "name": "C. Ciliberto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "where X([1,2,3,4]) t is a simplified denotation of search features from different backbone layers (layer 1 to 4).",
                "In [27], the closed-form ridge regression [3] is introduced to solve the VOS problem, it online optimizes a parameter matrix that maps features to segmentation masks.",
                "The steepest descent method is applied to iteratively minimize the squared error instead of the direct closed-form solution [3], as the latter requires time-consuming matrix inversion operations which are harmful to the running speed."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "37c2e63feebae0b18b217b2405404ef62ffdb2e5",
                "externalIds": {
                    "ArXiv": "2108.03679",
                    "DBLP": "journals/corr/abs-2108-03679",
                    "DOI": "10.1109/ICCV48922.2021.00953",
                    "CorpusId": 236956586
                },
                "corpusId": 236956586,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/37c2e63feebae0b18b217b2405404ef62ffdb2e5",
                "title": "Joint Inductive and Transductive Learning for Video Object Segmentation",
                "abstract": "Semi-supervised video object segmentation is a task of segmenting the target object in a video sequence given only a mask annotation in the first frame. The limited information available makes it an extremely challenging task. Most previous best-performing methods adopt matching-based transductive reasoning or online inductive learning. Nevertheless, they are either less discriminative for similar instances or insufficient in the utilization of spatio-temporal information. In this work, we propose to integrate transductive and inductive learning into a unified framework to exploit the complementarity between them for accurate and robust video object segmentation. The proposed approach consists of two functional branches. The transduction branch adopts a lightweight transformer architecture to aggregate rich spatio-temporal cues while the induction branch performs online inductive learning to obtain discriminative target information. To bridge these two diverse branches, a two-head label encoder is introduced to learn the suitable target prior for each of them. The generated mask encodings are further forced to be disentangled to better retain their complementarity. Extensive experiments on several prevalent benchmarks show that, without the need of synthetic training data, the proposed approach sets a series of new state-of-the-art records. Code is available at https://github.com/maoyunyao/JOINT.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152119570",
                        "name": "Yunyao Mao"
                    },
                    {
                        "authorId": "2152169749",
                        "name": "Ning Wang"
                    },
                    {
                        "authorId": "38272296",
                        "name": "Wen-gang Zhou"
                    },
                    {
                        "authorId": "2108508109",
                        "name": "Houqiang Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Optimization-based methods [2, 6, 21] leverage a meta learner over the auxiliary dataset to learn a general initialization model."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fc61e79edf88e2fc01b09697e713fba60ffff6a1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2108-02953",
                    "ArXiv": "2108.02953",
                    "DOI": "10.1145/3474085.3475232",
                    "CorpusId": 236950664
                },
                "corpusId": 236950664,
                "publicationVenue": {
                    "id": "f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                    "name": "ACM Multimedia",
                    "type": "conference",
                    "alternate_names": [
                        "MM"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fc61e79edf88e2fc01b09697e713fba60ffff6a1",
                "title": "Few-shot Unsupervised Domain Adaptation with Image-to-Class Sparse Similarity Encoding",
                "abstract": "This paper investigates a valuable setting called few-shot unsupervised domain adaptation (FS-UDA), which has not been sufficiently studied in the literature. In this setting, the source domain data are labelled, but with few-shot per category, while the target domain data are unlabelled. To address the FS-UDA setting, we develop a general UDA model to solve the following two key issues: the few-shot labeled data per category and the domain adaptation between support and query sets. Our model is general in that once trained it will be able to be applied to various FS-UDA tasks from the same source and target domains. Inspired by the recent local descriptor based few-shot learning (FSL), our general UDA model is fully built upon local descriptors (LDs) for image classification and domain adaptation. By proposing a novel concept called similarity patterns (SPs), our model not only effectively considers the spatial relationship of LDs that was ignored in previous FSL methods, but also makes the learned image similarity better serve the required domain alignment. Specifically, we propose a novel IMage-to-class sparse Similarity Encoding (IMSE) method. It learns SPs to extract the local discriminative information for classification and meanwhile aligns the covariance matrix of the SPs for domain adaptation. Also, domain adversarial training and multi-scale local feature matching are performed upon LDs. Extensive experiments conducted on a multi-domain benchmark dataset DomainNet demonstrates the state-of-the-art performance of our IMSE for the novel setting of FS-UDA. In addition, for FSL, our IMSE can also show better performance than most of recent FSL methods on miniImageNet.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2149206104",
                        "name": "Sheng Huang"
                    },
                    {
                        "authorId": "3183928",
                        "name": "Wanqi Yang"
                    },
                    {
                        "authorId": "2152505258",
                        "name": "Lei Wang"
                    },
                    {
                        "authorId": "6578587",
                        "name": "Luping Zhou"
                    },
                    {
                        "authorId": "2150425915",
                        "name": "Ming Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We further assess our method on two relatively less acknowledged datasets that are derived from CIFAR [42], namely, FC100 (Fewshot-CIFAR100) [18] and CIFAR-FS (CIFAR100 few-shots) [43]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2256cc990bca4813f8406d536fef10922422104f",
                "externalIds": {
                    "DBLP": "journals/pami/BaikOHL22",
                    "DOI": "10.1109/TPAMI.2021.3102098",
                    "CorpusId": 236926923,
                    "PubMed": "34347593"
                },
                "corpusId": 236926923,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2256cc990bca4813f8406d536fef10922422104f",
                "title": "Learning to Forget for Meta-Learning via Task-and-Layer-Wise Attenuation",
                "abstract": "Few-shot learning is an emerging yet challenging problem in which the goal is to achieve generalization from only few examples. Meta-learning tackles few-shot learning via the learning of prior knowledge shared across tasks and using it to learn new tasks. One of the most representative meta-learning algorithms is the model-agnostic meta-learning (MAML), which formulates prior knowledge as a common initialization, a shared starting point from where a learner can quickly adapt to unseen tasks. However, forcibly sharing an initialization can lead to conflicts among tasks and the compromised (undesired by tasks) location on optimization landscape, thereby hindering task adaptation. Furthermore, the degree of conflict is observed to vary not only among the tasks but also among the layers of a neural network. Thus, we propose task-and-layer-wise attenuation on the compromised initialization to reduce its adverse influence on task adaptation. As attenuation dynamically controls (or selectively forgets) the influence of the compromised prior knowledge for a given task and each layer, we name our method Learn to Forget (L2F). Experimental results demonstrate that the proposed method greatly improves the performance of the state-of-the-art MAML-based frameworks across diverse domains: few-shot classification, cross-domain few-shot classification, regression, reinforcement learning, and visual tracking.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "148009160",
                        "name": "Sungyong Baik"
                    },
                    {
                        "authorId": "2150321733",
                        "name": "Junghoon Oh"
                    },
                    {
                        "authorId": "150297656",
                        "name": "Seokil Hong"
                    },
                    {
                        "authorId": "2110246953",
                        "name": "Kyoung Mu Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Metric-based methods learn a shared feature extractor which is used to compute the distance between samples in embedding space [53, 3, 44, 30]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "998e24e833ca8b52ba0d7006b837cd6489faadaa",
                "externalIds": {
                    "DBLP": "conf/nips/ArnoldDRS21",
                    "ArXiv": "2108.01662",
                    "CorpusId": 236881055
                },
                "corpusId": 236881055,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/998e24e833ca8b52ba0d7006b837cd6489faadaa",
                "title": "Uniform Sampling over Episode Difficulty",
                "abstract": "Episodic training is a core ingredient of few-shot learning to train models on tasks with limited labelled data. Despite its success, episodic training remains largely understudied, prompting us to ask the question: what is the best way to sample episodes? In this paper, we first propose a method to approximate episode sampling distributions based on their difficulty. Building on this method, we perform an extensive analysis and find that sampling uniformly over episode difficulty outperforms other sampling schemes, including curriculum and easy-/hard-mining. As the proposed sampling method is algorithm agnostic, we can leverage these insights to improve few-shot learning accuracies across many episodic training algorithms. We demonstrate the efficacy of our method across popular few-shot learning datasets, algorithms, network architectures, and protocols.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "16378659",
                        "name": "S\u00e9bastien M. R. Arnold"
                    },
                    {
                        "authorId": "16404879",
                        "name": "Guneet Singh Dhillon"
                    },
                    {
                        "authorId": "2529423",
                        "name": "Avinash Ravichandran"
                    },
                    {
                        "authorId": "1715959",
                        "name": "Stefano Soatto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Three standard few-shot classification datasets (CIFAR-FS [Bertinetto et al., 2019], CUB-200 [Wah et al., 2011], mini-ImageNet [Vinyals et al., 2016]) are selected to compare the performance of our approach with previous fewshot learning methods.",
                "Three standard few-shot classification datasets (CIFAR-FS [Bertinetto et al., 2019], CUB-200 [Wah et al."
            ],
            "intents": [
                "background",
                "result"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4097946a128faafcec78d8084e6ab23607483fa7",
                "externalIds": {
                    "DBLP": "conf/ijcai/AnXZZ21",
                    "DOI": "10.24963/ijcai.2021/295",
                    "CorpusId": 237101033
                },
                "corpusId": 237101033,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/4097946a128faafcec78d8084e6ab23607483fa7",
                "title": "Conditional Self-Supervised Learning for Few-Shot Classification",
                "abstract": "How to learn a transferable feature representation from limited examples is a key challenge for few-shot classification. Self-supervision as an auxiliary task to the main supervised few-shot task is considered to be a conceivable way to solve the problem since self-supervision can provide additional structural information easily ignored by the main task. However, learning a good representation by traditional self-supervised methods is usually dependent on large training samples. In few-shot scenarios, due to the lack of sufficient samples, these self-supervised methods might learn a biased representation, which more likely leads to the wrong guidance for the main tasks and finally causes the performance degradation. In this paper, we propose conditional self-supervised learning (CSS) to use auxiliary information to guide the representation learning of self-supervised tasks. Specifically, CSS leverages supervised information as prior knowledge to shape and improve the learning feature manifold of self-supervision without auxiliary unlabeled data, so as to reduce representation bias and mine more effective semantic information. Moreover, CSS exploits more meaningful information through supervised and the improved self-supervised learning respectively and integrates the information into a unified distribution, which can further enrich and broaden the original representation. Extensive experiments demonstrate that our proposed method without any fine-tuning can achieve a significant accuracy improvement on the few-shot classification scenarios compared to the state-of-the-art few-shot learning methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "7686972",
                        "name": "Yuexuan An"
                    },
                    {
                        "authorId": "143962062",
                        "name": "H. Xue"
                    },
                    {
                        "authorId": "47039400",
                        "name": "Xingyu Zhao"
                    },
                    {
                        "authorId": "2156147512",
                        "name": "Lu Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3f4557ae9f9611cda61f0a72795a11b02debb1c5",
                "externalIds": {
                    "DBLP": "conf/ijcai/LiuTLQMYZX21",
                    "DOI": "10.24963/ijcai.2021/123",
                    "CorpusId": 237101247
                },
                "corpusId": 237101247,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/3f4557ae9f9611cda61f0a72795a11b02debb1c5",
                "title": "Learn from Concepts: Towards the Purified Memory for Few-shot Learning",
                "abstract": "Human beings have a great generalization ability to recognize a novel category by only seeing a few number of samples. This is because humans possess the ability to learn from the concepts that already exist in our minds. However, many existing few-shot approaches fail in addressing such a fundamental problem, {\\it i.e.,} how to utilize the knowledge learned in the past to improve the prediction for the new task. In this paper, we present a novel purified memory mechanism that simulates the recognition process of human beings. This new memory updating scheme enables the model to purify the information from semantic labels and progressively learn consistent, stable, and expressive concepts when episodes are trained one by one. On its basis, a Graph Augmentation Module (GAM) is introduced to aggregate these concepts and knowledge learned from new tasks via a graph neural network, making the prediction more accurate. Generally, our approach is model-agnostic and computing efficient with negligible memory cost. Extensive experiments performed on several benchmarks demonstrate the proposed method can consistently outperform a vast number of state-of-the-art few-shot learning methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109381351",
                        "name": "Xuncheng Liu"
                    },
                    {
                        "authorId": "2090453071",
                        "name": "Xudong Tian"
                    },
                    {
                        "authorId": "3431378",
                        "name": "Shaohui Lin"
                    },
                    {
                        "authorId": "1696146",
                        "name": "Yanyun Qu"
                    },
                    {
                        "authorId": "8452947",
                        "name": "Lizhuang Ma"
                    },
                    {
                        "authorId": "2114109236",
                        "name": "Wang Yuan"
                    },
                    {
                        "authorId": "2108963095",
                        "name": "Zhizhong Zhang"
                    },
                    {
                        "authorId": "1390847046",
                        "name": "Yuan Xie"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Common approaches include back-propagation through the sequence of gradient updates for a set of parameters, as in MAML [9], or back-propagation through the fixed point of a convex optimization algorithm [4], [19], [27], [34]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "da3450b75d9aa25879fcc4b3d1a963ae4b7c416e",
                "externalIds": {
                    "ArXiv": "2107.13682",
                    "DBLP": "journals/corr/abs-2107-13682",
                    "DOI": "10.1109/TPAMI.2022.3201541",
                    "CorpusId": 236493311,
                    "PubMed": "36063507"
                },
                "corpusId": 236493311,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/da3450b75d9aa25879fcc4b3d1a963ae4b7c416e",
                "title": "Bayesian Embeddings for Few-Shot Open World Recognition",
                "abstract": "As autonomous decision-making agents move from narrow operating environments to unstructured worlds, learning systems must move from a closed-world formulation to an open-world and few-shot setting in which agents continuously learn new classes from small amounts of information. This stands in stark contrast to modern machine learning systems that are typically designed with a known set of classes and a large number of examples for each class. In this work we extend embedding-based few-shot learning algorithms to the open-world recognition setting. We combine Bayesian non-parametric class priors with an embedding-based pre-training scheme to yield a highly flexible framework which we refer to as few-shot learning for open world recognition (FLOWR). We benchmark our framework on open-world extensions of the common MiniImageNet and TieredImageNet few-shot learning datasets. Our results show, compared to prior methods, strong classification accuracy performance and up to a 12% improvement in H-measure (a measure of novel class detection) from our non-parametric open-world few-shot learning scheme.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "114401442",
                        "name": "John Willes"
                    },
                    {
                        "authorId": "2106702981",
                        "name": "James Harrison"
                    },
                    {
                        "authorId": "2006610",
                        "name": "Ali Harakeh"
                    },
                    {
                        "authorId": "46881670",
                        "name": "Chelsea Finn"
                    },
                    {
                        "authorId": "1696085",
                        "name": "M. Pavone"
                    },
                    {
                        "authorId": "145292735",
                        "name": "Steven L. Waslander"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [6] is created by dividing CIFAR-100 into 64 training, 16 validation and 20 testing classes; images are of size 32 \u00d7 32.",
                "A complete run of Conv-4-64 on CIFAR-FS and WRN-28-10 on MiniImageNet takes less than 2 hours and 5 hours respectively.",
                "For few-shot classification, experiments are performed on CIFAR-FS and MiniImageNet whereas for continual learning, experiments are performed on Omniglot, CIFAR-100 and MiniImageNet."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "46cb086cbc98b80ad4094f157ec3ad3774fcbda1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2107-14053",
                    "ArXiv": "2107.14053",
                    "DOI": "10.1109/ICCV48922.2021.00932",
                    "CorpusId": 236493398
                },
                "corpusId": 236493398,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/46cb086cbc98b80ad4094f157ec3ad3774fcbda1",
                "title": "Few-Shot and Continual Learning with Attentive Independent Mechanisms",
                "abstract": "Deep neural networks (DNNs) are known to perform well when deployed to test distributions that shares high similarity with the training distribution. Feeding DNNs with new data sequentially that were unseen in the training distribution has two major challenges \u2014 fast adaptation to new tasks and catastrophic forgetting of old tasks. Such difficulties paved way for the on-going research on few-shot learning and continual learning. To tackle these problems, we introduce Attentive Independent Mechanisms (AIM). We incorporate the idea of learning using fast and slow weights in conjunction with the decoupling of the feature extraction and higher-order conceptual learning of a DNN. AIM is designed for higher-order conceptual learning, modeled by a mixture of experts that compete to learn independent concepts to solve a new task. AIM is a modular component that can be inserted into existing deep learning frameworks. We demonstrate its capability for few-shot learning by adding it to SIB and trained on MiniImageNet and CIFAR-FS, showing significant improvement. AIM is also applied to ANML and OML trained on Omniglot, CIFAR-100 and MiniImageNet to demonstrate its capability in continual learning. Code made publicly available at https://github.com/huang50213/AIM-Fewshot-Continual.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "72817601",
                        "name": "Eugene Lee"
                    },
                    {
                        "authorId": "2150608198",
                        "name": "Cheng-Han Huang"
                    },
                    {
                        "authorId": "2115291993",
                        "name": "Chen-Yi Lee"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "72a12beb960afb1454ff201b94c63b8295ce1c4d",
                "externalIds": {
                    "MAG": "3185614262",
                    "DBLP": "journals/mlc/WangWZC22",
                    "DOI": "10.1007/S13042-021-01373-X",
                    "CorpusId": 237722248
                },
                "corpusId": 237722248,
                "publicationVenue": {
                    "id": "a0c45882-7c78-4f0c-8886-d3481ba02586",
                    "name": "International Journal of Machine Learning and Cybernetics",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Mach Learn Cybern"
                    ],
                    "issn": "1868-8071",
                    "url": "http://www.springer.com/engineering/mathematical/journal/13042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/13042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/72a12beb960afb1454ff201b94c63b8295ce1c4d",
                "title": "Few-shot learning with deep balanced network and acceleration strategy",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2117843725",
                        "name": "Kang Wang"
                    },
                    {
                        "authorId": "153316233",
                        "name": "Xuesong Wang"
                    },
                    {
                        "authorId": "2117882173",
                        "name": "Tong Zhang"
                    },
                    {
                        "authorId": "33718755",
                        "name": "Yuhu Cheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In order to explore the role of each module, ablation experiments were performed on miniImageNet, CIFARFS, and CUB to investigate the following three components: ResNet-12, simple linear operation, and local cross-channel interaction.",
                "In this section, experiments were performed on four traditional datasets including miniImageNet, CIFARFS, FC100, tieredImageNet, and CUB datasets to verify the effect of the acceleration strategy.",
                "Four image datasets including miniImageNet [13], CIFARFS [26], FC100 [27], and tieredImageNet [28] are used to validate the performance of BAL-Reptile on traditional image classification, where both CIFAR-FS and FC100 are derived from CIFAR-100."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "83342d53a55f06254130c71cbbc65c0800f02f04",
                "externalIds": {
                    "DOI": "10.1007/s13042-021-01373-x",
                    "CorpusId": 255993534
                },
                "corpusId": 255993534,
                "publicationVenue": {
                    "id": "a0c45882-7c78-4f0c-8886-d3481ba02586",
                    "name": "International Journal of Machine Learning and Cybernetics",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Mach Learn Cybern"
                    ],
                    "issn": "1868-8071",
                    "url": "http://www.springer.com/engineering/mathematical/journal/13042",
                    "alternate_urls": [
                        "https://link.springer.com/journal/13042"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/83342d53a55f06254130c71cbbc65c0800f02f04",
                "title": "Few-shot learning with deep balanced network and acceleration strategy",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2186273993",
                        "name": "Kang Wang"
                    },
                    {
                        "authorId": "153316233",
                        "name": "Xuesong Wang"
                    },
                    {
                        "authorId": "2117882173",
                        "name": "Tong Zhang"
                    },
                    {
                        "authorId": "33718755",
                        "name": "Yuhu Cheng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Because our method uses multi-task training, the batchsize is set to 2 for training ProNet, RelationNet, ANIL, R2D2, and MetaOpt.",
                "R2D2 [4] and MetaOpt [18] adopt ridge regression or support vector machine [7] as the task-specific learner for each learning task, respectively.",
                "As shown in Table 3, pre-training the feature encoder substantially improves the performance of ProNet and R2D2 on four unseen benchmarks.",
                "As for gradient-based method, ANIL, R2D2 [4], and MetaOptNet [18] are chosen.",
                "R2D2 [4] and MetaOpt [18] adopt ridge regression or support vector machine [7] as the task-specific learner for each learning task,\nrespectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "c6867d639b4020959ccaa66f3bae40c6a737e45b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2107-11056",
                    "ArXiv": "2107.11056",
                    "CorpusId": 236318485
                },
                "corpusId": 236318485,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c6867d639b4020959ccaa66f3bae40c6a737e45b",
                "title": "Improving the Generalization of Meta-learning on Unseen Domains via Adversarial Shift",
                "abstract": "Meta-learning provides a promising way for learning to efficiently learn and achieves great success in many applications. However, most meta-learning literature focuses on dealing with tasks from a same domain, making it brittle to generalize to tasks from the other unseen domains. In this work, we address this problem by simulating tasks from the other unseen domains to improve the generalization and robustness of meta-learning method. Specifically, we propose a model-agnostic shift layer to learn how to simulate the domain shift and generate pseudo tasks, and develop a new adversarial learning-to-learn mechanism to train it. Based on the pseudo tasks, the meta-learning model can learn cross-domain meta-knowledge, which can generalize well on unseen domains. We conduct extensive experiments under the domain generalization setting. Experimental results demonstrate that the proposed shift layer is applicable to various meta-learning frameworks. Moreover, our method also leads to state-of-the-art performance on different cross-domain few-shot classification benchmarks and produces good results on cross-domain few-shot regression.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51305326",
                        "name": "Pinzhuo Tian"
                    },
                    {
                        "authorId": "2154881143",
                        "name": "Yao Gao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "cec495c9338929c20f6991ae80a97d6300d1c242",
                "externalIds": {
                    "ArXiv": "2107.14035",
                    "DBLP": "journals/corr/abs-2107-14035",
                    "CorpusId": 236493494
                },
                "corpusId": 236493494,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/cec495c9338929c20f6991ae80a97d6300d1c242",
                "title": "ProtoTransformer: A Meta-Learning Approach to Providing Student Feedback",
                "abstract": "High-quality computer science education is limited by the difficulty of providing instructor feedback to students at scale. While this feedback could in principle be automated, supervised approaches to predicting the correct feedback are bottlenecked by the intractability of annotating large quantities of student code. In this paper, we instead frame the problem of providing feedback as few-shot classification, where a meta-learner adapts to give feedback to student code on a new programming question from just a few examples annotated by instructors. Because data for meta-training is limited, we propose a number of amendments to the typical few-shot learning framework, including task augmentation to create synthetic tasks, and additional side information to build stronger priors about each task. These additions are combined with a transformer architecture to embed discrete sequences (e.g. code) to a prototypical representation of a feedback class label. On a suite of few-shot natural language processing tasks, we match or outperform state-of-the-art performance. Then, on a collection of student solutions to exam questions from an introductory university course, we show that our approach reaches an average precision of 88% on unseen questions, surpassing the 82% precision of teaching assistants. Our approach was successfully deployed to deliver feedback to 16,000 student exam-solutions in a programming course offered by a tier 1 university. This is, to the best of our knowledge, the first successful deployment of a machine learning based feedback to open-ended student code.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1700653",
                        "name": "Mike Wu"
                    },
                    {
                        "authorId": "144002017",
                        "name": "Noah D. Goodman"
                    },
                    {
                        "authorId": "2012749",
                        "name": "C. Piech"
                    },
                    {
                        "authorId": "46881670",
                        "name": "Chelsea Finn"
                    }
                ]
            }
        },
        {
            "contexts": [
                "R2-D2 [22] and MetaOptNet [23] adopt linear models as the classifier due to their computational efficiency.",
                "Experimental results show that the proposed SEEN method achieves state-of-the-art few-shot classification performance on benchmark datasets, including mini-ImageNet, tiered-ImageNet, and CIFAR-FS.",
                "mini-ImageNet [8] 100 60, 000 84\u00d7 84 tiered-ImageNet [40] 608 779, 165 84\u00d7 84 CIFAR-FS [22] 100 60, 000 32\u00d7 32 CUB [41] 200 11, 788 224\u00d7 224",
                "The metric-based methods include MatchingNet [8], ProtoNet [6], RelationNet [7], TADAM [20], R2-D2 [22], Prototype Classifier, and MetaOptNet [23].",
                "Four benchmark datasets are used, including the mini-ImageNet and tiered-ImageNet from ILSVRC-2012 [44], CIFAR-FS from CIFAR-100, and CUB [41].",
                "CIFAR-FS [22] is a recent benchmark for few-shot classification."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "416f382163ccfa80e71f8935483582b6a4931bfd",
                "externalIds": {
                    "DBLP": "conf/ijcnn/JiangZK21",
                    "DOI": "10.1109/IJCNN52387.2021.9533845",
                    "CorpusId": 237598688
                },
                "corpusId": 237598688,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/416f382163ccfa80e71f8935483582b6a4931bfd",
                "title": "SEEN: Few-Shot Classification with SElf-ENsemble",
                "abstract": "Few-shot classification aims at learning new concepts with only a few labeled examples. In this paper, we focus on metric-based methods that have achieved state-of-the-art performance. However, they classify query examples based on embeddings extracted from only the last layer. These embeddings tend to be class-specific and may not generalize well to novel classes or domains. To alleviate this problem, we propose the SElf-ENsemble (SEEN) that leverages embeddings from multiple layers. Specifically, a base classifier is built for each of the last few layers, and the resultant base classifiers are then combined together. Experiments on various benchmark datasets demonstrate that the proposed SEEN method outperforms existing methods in both standard few-shot classification and cross-domain few-shot classification scenarios.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152123946",
                        "name": "Weisen Jiang"
                    },
                    {
                        "authorId": "2153638098",
                        "name": "Yu Zhang"
                    },
                    {
                        "authorId": "145193332",
                        "name": "J. Kwok"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[49] and R2D2 [2] by about 4% and 8%, respectively.",
                ", miniImagenet [43] and CIFAR-FS [2], which firmly validates the effectiveness of our method.",
                "Following [2, 39, 46], we respectively use ConvNet4 [43] and ResNet-12 [14] to implement the meta-learner.",
                "7 n/a n/a R2D2 [2] ICLR\u2019 19 ConvNet-4 51.",
                "miniImagenet [43] and CIFAR-FS [2] are the most commonly used FSL datasets."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2cdda10ca193d0d28df82d6e2c0478411d479601",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2107-05583",
                    "ArXiv": "2107.05583",
                    "CorpusId": 235794989
                },
                "corpusId": 235794989,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2cdda10ca193d0d28df82d6e2c0478411d479601",
                "title": "Few-shot Learning with Global Relatedness Decoupled-Distillation",
                "abstract": "Despite the success that metric learning based approaches have achieved in few-shot learning, recent works reveal the ineffectiveness of their episodic training mode. In this paper, we point out two potential reasons for this problem: 1) the random episodic labels can only provide limited supervision information, while the relatedness information between the query and support samples is not fully exploited; 2) the meta-learner is usually constrained by the limited contextual information of the local episode. To overcome these problems, we propose a new Global Relatedness Decoupled-Distillation (GRDD) method using the global category knowledge and the Relatedness Decoupled-Distillation (RDD) strategy. Our GRDD learns new visual concepts quickly by imitating the habit of humans, i.e. learning from the deep knowledge distilled from the teacher. More specifically, we first train a global learner on the entire base subset using category labels as supervision to leverage the global context information of the categories. Then, the well-trained global learner is used to simulate the query-support relatedness in global dependencies. Finally, the distilled global query-support relatedness is explicitly used to train the meta-learner using the RDD strategy, with the goal of making the meta-learner more discriminative. The RDD strategy aims to decouple the dense query-support relatedness into the groups of sparse decoupled relatedness. Moreover, only the relatedness of a single support sample with other query samples is considered in each group. By distilling the sparse decoupled relatedness group by group, sharper relatedness can be effectively distilled to the meta-learner, thereby facilitating the learning of a discriminative meta-learner. We conduct extensive experiments on the miniImagenet and CIFAR-FS datasets, which show the state-of-the-art performance of our GRDD method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1877859275",
                        "name": "Yuanen Zhou"
                    },
                    {
                        "authorId": "8280010",
                        "name": "Yanrong Guo"
                    },
                    {
                        "authorId": "6175623",
                        "name": "Shijie Hao"
                    },
                    {
                        "authorId": "48043335",
                        "name": "Richang Hong"
                    },
                    {
                        "authorId": "2118950337",
                        "name": "Zhen junzha"
                    },
                    {
                        "authorId": "2146058658",
                        "name": "Meng Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2017), ridge regression classifier (Bertinetto et al., 2019) and SVM classifier (Lee et al.",
                "2 Experiments on CIFAR derivatives The CIFAR-FS dataset (Bertinetto et al., 2019) is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3739738553ac8e3c02febb61b793f60fd68e5b64",
                "externalIds": {
                    "ArXiv": "2107.02378",
                    "CorpusId": 258686161
                },
                "corpusId": 258686161,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3739738553ac8e3c02febb61b793f60fd68e5b64",
                "title": "Learning an Explicit Hyperparameter Prediction Function Conditioned on Tasks",
                "abstract": "Meta learning has attracted much attention recently in machine learning community. Contrary to conventional machine learning aiming to learn inherent prediction rules to predict labels for new query data, meta learning aims to learn the learning methodology for machine learning from observed tasks, so as to generalize to new query tasks by leveraging the meta-learned learning methodology. In this study, we interpret such learning methodology as learning an explicit hyper-parameter prediction function shared by all training tasks. Specifically, this function is represented as a parameterized function called meta-learner, mapping from a training/test task to its suitable hyper-parameter setting, extracted from a pre-specified function set called meta learning machine. Such setting guarantees that the meta-learned learning methodology is able to flexibly fit diverse query tasks, instead of only obtaining fixed hyper-parameters by many current meta learning methods, with less adaptability to query task's variations. Such understanding of meta learning also makes it easily succeed from traditional learning theory for analyzing its generalization bounds with general losses/tasks/models. The theory naturally leads to some feasible controlling strategies for ameliorating the quality of the extracted meta-learner, verified to be able to finely ameliorate its generalization capability in some typical meta learning applications, including few-shot regression, few-shot classification and domain generalization.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "38741604",
                        "name": "Jun Shu"
                    },
                    {
                        "authorId": "1803714",
                        "name": "Deyu Meng"
                    },
                    {
                        "authorId": "98220533",
                        "name": "Zongben Xu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5d5936fb376c743a649d86f450f02e0d2944199b",
                "externalIds": {
                    "DBLP": "conf/icmcs/LiWGL21",
                    "MAG": "3173086070",
                    "DOI": "10.1109/ICME51207.2021.9428178",
                    "CorpusId": 236166305
                },
                "corpusId": 236166305,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5d5936fb376c743a649d86f450f02e0d2944199b",
                "title": "Semi-Supervised Few-Shot Learning with Pseudo Label Refinement",
                "abstract": "Few-shot classification aims at recognising novel categories with very limited labelled samples. Although substantial achievements have been obtained, few-shot classification remains challenging due to the scarcity of labelled examples. Recent studies resort to leveraging unlabelled data to expand the training set using pseudo labelling, but this strategy often yields significant label noise. In this work, we introduce a new baseline method for semi-supervised few-shot learning by iterative pseudo label refinement to reduce noise. Then, we investigate the label noise propagation problem and improve the baseline with a denoising network to learn distributions of clean and noisy pseudo-labelled examples via a mixture model. This helps to estimate confidence values of pseudo labelled examples and to select the reliable ones with less noise for iteratively refining a few-shot classifier. Extensive experiments on three widely used benchmarks, minilma- genet, tieredImagenet and CIFAR-FS, show the superiority of the proposed methods over the state-of-the-art methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2125435016",
                        "name": "Pan Li"
                    },
                    {
                        "authorId": "3401831",
                        "name": "Guile Wu"
                    },
                    {
                        "authorId": "144784813",
                        "name": "S. Gong"
                    },
                    {
                        "authorId": "143866730",
                        "name": "Xu Lan"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d422ae4d9ec1824651de58ee5e2a38242625880b",
                "externalIds": {
                    "DBLP": "conf/icmcs/WangZL21a",
                    "MAG": "3171562621",
                    "DOI": "10.1109/ICME51207.2021.9428122",
                    "CorpusId": 236233969
                },
                "corpusId": 236233969,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d422ae4d9ec1824651de58ee5e2a38242625880b",
                "title": "GSS: Graph-Based Subspace Learning with Shots Initialization for few-shot Recognition",
                "abstract": "Previous methods of few-shot Learning mostly solve different few-shot recognition tasks in an identical feature space. But identical features are hard to fit various tasks. Some works show that learning a unique subspace for each few-shot recognition task can improve the signal-noise ratio (SNR) of the features and boost the performance. However, there are still two problems remaining. First, in constructing the subspace for few-shot task, often some information (embeddings of queries or labels of shots) are discarded. Second, the eigendecomposition of covariance matrix is usually needed, which degrades the efficiency of the whole model. In this paper, we propose Graph-based Subspace learning with Shots initialization (GSS) for few-shot recognition to learn a better subspace efficiently. In GSS, the bases of the subspace are directly initialized with labels based on shots (given labeled samples) and iteratively updated for better discrimination based on a graph that connects bases and all samples. Extensive experiments on four few-shot benchmark datasets show that GSS reports better performance and higher efficient compared with previous subspace based methods and achieves state-of-the-art performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109050605",
                        "name": "Rui-Qi Wang"
                    },
                    {
                        "authorId": "2870877",
                        "name": "Xu-Yao Zhang"
                    },
                    {
                        "authorId": "1689269",
                        "name": "Cheng-Lin Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Experiments of few-shot learning are based on four popular benchmark datasets: miniImageNet [4], tiered-ImageNet [24], CIFAR-FS [25], and FC100 [10].",
                "Experimental results on ImageNet derivatives (mini-ImageNet and tiered-ImageNet) are reported in Table 1, and results on CIFAR derivatives (CIFAR-FS and FC100) are reported in Table 2."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "99b9640f1de59ba9d795955aece33b89b781912a",
                "externalIds": {
                    "MAG": "3167082046",
                    "DBLP": "conf/icmcs/WangZL21b",
                    "DOI": "10.1109/ICME51207.2021.9428186",
                    "CorpusId": 236273374
                },
                "corpusId": 236273374,
                "publicationVenue": {
                    "id": "975e1529-a14b-436f-ad7e-a09d8eabc50d",
                    "name": "IEEE International Conference on Multimedia and Expo",
                    "type": "conference",
                    "alternate_names": [
                        "ICME",
                        "Int Conf Multimedia Expo",
                        "IEEE Int Conf Multimedia Expo",
                        "International Conference on Multimedia and Expo"
                    ],
                    "issn": "1945-7871",
                    "alternate_issns": [
                        "2330-7927"
                    ],
                    "url": "http://csdl2.computer.org/persagen/ProceedingByFilter.jsp?filter=I",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/conferences.jsp",
                        "http://www.wikicfp.com/cfp/program?id=1418"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/99b9640f1de59ba9d795955aece33b89b781912a",
                "title": "Class Forge: Boosting Feature Encoder for Few-Shot Learning with Synthesized Classes",
                "abstract": "Few-shot Learning (FSL) aims to gain classification ability on novel classes with only a few labeled samples. Previous works explore meta-learning, metric learning, and graph based methods. Though data augmentation is important to enhance the generalizability of neural networks, it is not well exploited in the field of FSL. We investigate the augmentation in FSL and propose Class Forge to synthesize forged classes that help to learn an encoder with better generalization to novel classes. Specifically, Class Forge divides given base visual classes into parts and combines these parts to synthesize forged visual classes. Training with the additional forged classes forces the encoder to learn richer features that can embed different parts, so as to boost the generalization to novel classes. Intrinsically, Class Forge is a \"class augmentation\" method that provides a simple yet effective way to synthesize classes, other than synthesizing samples of given classes in previous works. Extensive experiments show that Class Forge yields consistent performance gain on different datasets for FSL. And the ablation studies validate that features learned with Class Forge demonstrate better generalization ability.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109050605",
                        "name": "Rui-Qi Wang"
                    },
                    {
                        "authorId": "2870877",
                        "name": "Xu-Yao Zhang"
                    },
                    {
                        "authorId": "1689269",
                        "name": "Cheng-Lin Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Although few methods adapt to support instances by solving convex optimization problems for fast and effective adaptation [3, 26], they consider classification tasks.",
                "These methods require higher-order derivatives and to retain all optimization path of the iterative adaptation to backpropagate through the path, which imposes considerable computational and memory burdens [3].",
                "In this framework, fast adaptation to support instances is essential since the result of the adaptation is required to train the model in each iteration of training [3, 34].",
                "Meta-learning methods have been recently attracting a lot of attention [8, 41, 9, 34, 3, 16]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "3027bd43c9a02d4db13e576d9681a3607336c4fd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2107-00801",
                    "ArXiv": "2107.00801",
                    "CorpusId": 235727257
                },
                "corpusId": 235727257,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/3027bd43c9a02d4db13e576d9681a3607336c4fd",
                "title": "Meta-Learning for Relative Density-Ratio Estimation",
                "abstract": "The ratio of two probability densities, called a density-ratio, is a vital quantity in machine learning. In particular, a relative density-ratio, which is a bounded extension of the density-ratio, has received much attention due to its stability and has been used in various applications such as outlier detection and dataset comparison. Existing methods for (relative) density-ratio estimation (DRE) require many instances from both densities. However, sufficient instances are often unavailable in practice. In this paper, we propose a meta-learning method for relative DRE, which estimates the relative density-ratio from a few instances by using knowledge in related datasets. Specifically, given two datasets that consist of a few instances, our model extracts the datasets' information by using neural networks and uses it to obtain instance embeddings appropriate for the relative DRE. We model the relative density-ratio by a linear model on the embedded space, whose global optimum solution can be obtained as a closed-form solution. The closed-form solution enables fast and effective adaptation to a few instances, and its differentiability enables us to train our model such that the expected test error for relative DRE can be explicitly minimized after adapting to a few instances. We empirically demonstrate the effectiveness of the proposed method by using three problems: relative DRE, dataset comparison, and outlier detection.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3370561",
                        "name": "Atsutoshi Kumagai"
                    },
                    {
                        "authorId": "2664600",
                        "name": "Tomoharu Iwata"
                    },
                    {
                        "authorId": "1491242041",
                        "name": "Y. Fujiwara"
                    }
                ]
            }
        },
        {
            "contexts": [
                "miniImageNet [10] 64 38,400 16 9,600 20 12,000 tieredImageNet [26] 351 448,695 97 124,261 160 206,209 CUB [29] 100 5,891 50 2,932 50 2,965 CIFAR-FS [27] 64 38,400 16 9,600 20 12,000 FC-100 [28] 60 36,000 20 12,000 20 12,000",
                "The classes in CIFAR-FS are randomly split into 64/16/20 for metatraining/validation/testing, while FC-100 takes the split of 60/20/20 classes following the super-classes.",
                "CIFAR-FS [27] and FC-100 [28] are two variants of the CIFAR-100 dataset [103] for fewshot learning but with different partitions.",
                "For CIFAR-FS and FC-100, we enlarge the images to 50 by 50.",
                "We validate LASTSHOT in combination with representative FSL methods [13], [23], [24], [25] on multiple benchmarks, including miniImageNet [10], tieredImageNet [26], CIFARFS [27], FC-100 [28], and CUB [29].",
                "Last but not the least, comparing to Model Regression [16] and RFS [34], in which the former only uses the target classifier to guide the few-shot learner in the last fullyconnected layer while the latter uses distillation to strengthen the pre-trained features, our LASTSHOT outperforms them on miniImageNet, CUB, and CIFAR-FS, and performs on par with them on other datasets.",
                "Way 5-Shot tasks on miniImageNet (Table 2), tieredImageNet (Table 3), CUB (Table 4), CIFAR-FS (Table 5), and FC-100 (Table 5).",
                "We evaluate our approach LASTSHOT using multiple benchmark datasets, including miniImageNet [10], tieredImageNet [26], CUB [29], CIFAR-FS [27], and FC100 [28]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1e778df383b9fd0c8c61a4462f9039b185a05852",
                "externalIds": {
                    "ArXiv": "2107.00197",
                    "DBLP": "journals/corr/abs-2107-00197",
                    "DOI": "10.1109/TPAMI.2022.3160362",
                    "CorpusId": 235694435,
                    "PubMed": "35298376"
                },
                "corpusId": 235694435,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1e778df383b9fd0c8c61a4462f9039b185a05852",
                "title": "Few-Shot Learning with a Strong Teacher",
                "abstract": "Few-shot learning (FSL) aims to generate a classifier using limited labeled examples. Many existing works take the meta-learning approach, constructing a few-shot learner (a meta-model) that can learn from few-shot examples to generate a classifier. The performance is measured by how well the resulting classifiers classify the test (\\ie, query) examples of those tasks. In this paper, we point out two potential weaknesses of this approach. First, the sampled query examples may not provide sufficient supervision for meta-training the few-shot learner. Second, the effectiveness of meta-learning diminishes sharply with the increasing number of shots. We propose a novel meta-training objective for the few-shot learner, which is to encourage the few-shot learner to generate classifiers that perform like strong classifiers. Concretely, we associate each sampled few-shot task with a strong classifier, which is trained with ample labeled examples. The strong classifiers can be seen as the target classifiers that we hope the few-shot learner to generate given few-shot examples, and we use the strong classifiers to supervise the few-shot learner. We validate our approach in combinations with many representative meta-learning methods. More importantly, with our approach, meta-learning based FSL methods can consistently outperform non-meta-learning based methods at different numbers of shots.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2151459740",
                        "name": "Han-Jia Ye"
                    },
                    {
                        "authorId": "2117262894",
                        "name": "Lu Ming"
                    },
                    {
                        "authorId": "1721819",
                        "name": "De-chuan Zhan"
                    },
                    {
                        "authorId": "2113951006",
                        "name": "Wei-Lun Chao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0999abf5e150a76120e54abfe89f48114095636c",
                "externalIds": {
                    "DBLP": "conf/iclr/YeC22",
                    "ArXiv": "2106.16245",
                    "CorpusId": 235683072
                },
                "corpusId": 235683072,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0999abf5e150a76120e54abfe89f48114095636c",
                "title": "How to Train Your MAML to Excel in Few-Shot Classification",
                "abstract": "Model-agnostic meta-learning (MAML) is arguably one of the most popular meta-learning algorithms nowadays. Nevertheless, its performance on few-shot classification is far behind many recent algorithms dedicated to the problem. In this paper, we point out several key facets of how to train MAML to excel in few-shot classification. First, we find that MAML needs a large number of gradient steps in its inner loop update, which contradicts its common usage in few-shot classification. Second, we find that MAML is sensitive to the class label assignments during meta-testing. Concretely, MAML meta-trains the initialization of an $N$-way classifier. These $N$ ways, during meta-testing, then have\"$N!$\"different permutations to be paired with a few-shot task of $N$ novel classes. We find that these permutations lead to a huge variance of accuracy, making MAML unstable in few-shot classification. Third, we investigate several approaches to make MAML permutation-invariant, among which meta-training a single vector to initialize all the $N$ weight vectors in the classification head performs the best. On benchmark datasets like MiniImageNet and TieredImageNet, our approach, which we name UNICORN-MAML, performs on a par with or even outperforms many recent few-shot classification algorithms, without sacrificing MAML's simplicity.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2151459740",
                        "name": "Han-Jia Ye"
                    },
                    {
                        "authorId": "2113951006",
                        "name": "Wei-Lun Chao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Furthermore, the EFIL assumption is empirically reasonable, since previous works (Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020) yield comparable performance while leaving the encoder untouched during the inner loop.",
                "Similar ideas of freezing feature extractors during the inner loop have also been explored (Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020), and have been held as an assumption in theoretical works (Du et al., 2021; Tripuraneni et al., 2020; Chua et al., 2021).",
                "Similar ideas of freezing feature extractors during the inner loop have also been explored (Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020), and have been held as an assumption in theoretical works (Du et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "73e1b848711c304dbf16ed6f390d0d765ca1c7e1",
                "externalIds": {
                    "DBLP": "conf/iclr/KaoCC22",
                    "ArXiv": "2106.15367",
                    "CorpusId": 247245054
                },
                "corpusId": 247245054,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/73e1b848711c304dbf16ed6f390d0d765ca1c7e1",
                "title": "MAML is a Noisy Contrastive Learner in Classification",
                "abstract": "Model-agnostic meta-learning (MAML) is one of the most popular and widely adopted meta-learning algorithms, achieving remarkable success in various learning problems. Yet, with the unique design of nested inner-loop and outer-loop updates, which govern the task-specific and meta-model-centric learning, respectively, the underlying learning objective of MAML remains implicit and thus impedes a more straightforward understanding of it. In this paper, we provide a new perspective of the working mechanism of MAML. We discover that MAML is analogous to a meta-learner using a supervised contrastive objective. The query features are pulled towards the support features of the same class and against those of different classes. Such contrastiveness is experimentally verified via an analysis based on the cosine similarity. Moreover, we reveal that vanilla MAML has an undesirable interference term originating from the random initialization and the cross-task interaction. We thus propose a simple but effective technique, zeroing trick, to alleviate the interference. Extensive experiments are conducted on both mini-ImageNet and Omniglot datasets to demonstrate the consistent improvement brought by our proposed method, validating its effectiveness.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2115997017",
                        "name": "Chia-Hsiang Kao"
                    },
                    {
                        "authorId": "37811787",
                        "name": "Wei-Chen Chiu"
                    },
                    {
                        "authorId": "153191489",
                        "name": "Pin-Yu Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The inner algorithm from Equation (4), that uses \u2016 \u00b7 \u2016F regularization, has been used in empirical work, for ` being the logistic and squared error losses in Bertinetto et al. (2019) and the margin loss in Lee et al. (2019); also used in theoretical work (Saunshi et al., 2020).",
                "Their proposed representation learning algorithm ANIL and other methods (Lee et al., 2019; Bertinetto et al., 2019) show that representation learning performs comparably to gradient-based methods on many benchmarks."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d0841488031dd422fc4b37ca6214e37b2d6bc8a7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-15615",
                    "ArXiv": "2106.15615",
                    "CorpusId": 235670053
                },
                "corpusId": 235670053,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/d0841488031dd422fc4b37ca6214e37b2d6bc8a7",
                "title": "A Representation Learning Perspective on the Importance of Train-Validation Splitting in Meta-Learning",
                "abstract": "An effective approach in meta-learning is to utilize multiple\"train tasks\"to learn a good initialization for model parameters that can help solve unseen\"test tasks\"with very few samples by fine-tuning from this initialization. Although successful in practice, theoretical understanding of such methods is limited. This work studies an important aspect of these methods: splitting the data from each task into train (support) and validation (query) sets during meta-training. Inspired by recent work (Raghu et al., 2020), we view such meta-learning methods through the lens of representation learning and argue that the train-validation split encourages the learned representation to be low-rank without compromising on expressivity, as opposed to the non-splitting variant that encourages high-rank representations. Since sample efficiency benefits from low-rankness, the splitting strategy will require very few samples to solve unseen test tasks. We present theoretical results that formalize this idea for linear representation learning on a subspace meta-learning instance, and experimentally verify this practical benefit of splitting in simulations and on standard meta-learning benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "10769461",
                        "name": "Nikunj Saunshi"
                    },
                    {
                        "authorId": "2110047443",
                        "name": "Arushi Gupta"
                    },
                    {
                        "authorId": "145066190",
                        "name": "Wei Hu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These two features, few\u2010shot learning and rapid adaptation, make meta\u2010 learning to be on the spot of recent works, surpassing the previous literature by a considerable margin [32, 36, 37]."
            ],
            "intents": [
                "result"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f44af11d0cb3aea2f7cdedda940eeec976e85eae",
                "externalIds": {
                    "DBLP": "journals/iet-bmt/Costa-PazoPJAV21",
                    "MAG": "3176088906",
                    "DOI": "10.1049/bme2.12049",
                    "CorpusId": 237760131
                },
                "corpusId": 237760131,
                "publicationVenue": {
                    "id": "3c759089-f366-48eb-ae4e-9e6c4d43c3ce",
                    "name": "IET Biometrics",
                    "type": "journal",
                    "alternate_names": [
                        "IET Biom"
                    ],
                    "issn": "2047-4938",
                    "url": "https://digital-library.theiet.org/content/journals/iet-bmt",
                    "alternate_urls": [
                        "http://digital-library.theiet.org/IET-BMT"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f44af11d0cb3aea2f7cdedda940eeec976e85eae",
                "title": "Face presentation attack detection. A comprehensive evaluation of the generalisation problem",
                "abstract": "European Regional Development Fund; Xunta de Galicia (Centro de investigaci\u00f3n de Galicia accreditation 2019\u20132022); Doctorados Industriales (Agencia Estatal de Investigaci\u00f3n) Abstract Face recognition technology is now mature enough to reach commercial products, such as smart phones or tablets. However, it still needs to increase robustness against imposter attacks. In this regard, face PresentationAttackDetection (face\u2010PAD) is a key component in providing trustable facial access to digital devices. Despite the success of several face\u2010PAD works in publicly available datasets, most of them fail to reach the market, revealing the lack of evaluation frameworks that represent realistic settings. Here, an extensive analysis of the generalisation problem in face\u2010PAD is provided, jointly with an evaluation strategy based on the aggregation of most publicly available datasets and a set of novel protocols to cover the most realistic settings, including a novel demographic bias analysis. Besides, a new fine\u2010 grained categorisation of presentation attacks and instruments is provided, enabling higher flexibility in assessing the generalisation of different algorithms under a common framework. As a result, GRAD\u2010GPAD v2, a comprehensive and modular framework is presented to evaluate the performance of face\u2010PAD approaches in realistic settings, enabling accountability and fair comparison of most face\u2010PAD approaches in the literature.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1405371609",
                        "name": "Artur Costa-Pazo"
                    },
                    {
                        "authorId": "1414113199",
                        "name": "Daniel P\u00e9rez-Cabo"
                    },
                    {
                        "authorId": "1414915707",
                        "name": "David Jim\u00e9nez-Cabello"
                    },
                    {
                        "authorId": "1403161368",
                        "name": "J. Alba-Castro"
                    },
                    {
                        "authorId": "1402318519",
                        "name": "Esteban V\u00e1zquez-Fern\u00e1ndez"
                    }
                ]
            }
        },
        {
            "contexts": [
                "DATASET METHODS PROTONET R2D2 METAOPTNETAccnat Accadv TIME Accnat Accadv TIME Accnat Accadv TIME\nCIFAR-FS\nAT (5WAY-1SHOT) 42.67 % (0.65",
                "DATASET METHODS PROTONET R2D2 METAOPTNETAccnat Accadv TIME Accnat Accadv TIME Accnat Accadv TIME\nCIFAR-FS\nAT (5WAY-1SHOT) 38.11 % (0.62",
                "10.3H\nWe follow the experimental setting of AQ in (Goldblum et al., 2020), training the state-of-the-art metalearning models including PROTONET (Snell et al., 2017a), R2D2 (Bertinetto et al., 2018a) , and MetaOptNet ( ResNet12 as backbone (He et al., 2016)).",
                "We adopt models including PROTONET (Snell et al., 2017b), R2D2 (Bertinetto et al., 2018b), and MetaOptNet (Lee et al., 2019) and dataset including MiniImageNet (Vinyals et al., 2016), TieredImageNet (Ren et al., 2018), CIFARFS (Bertinetto et al., 2018b), and FC100 (Oreshkin et al., 2018).",
                "Extended experiments results on R2D2 and MetaOptNet versus PGD attack at different attack steps",
                "3 (See Appendix A.4 for R2D2 and MetaOptNet ).",
                "DATASET METHODS PROTONET R2D2 METAOPTNET\nAccnat Accadv TIME Accnat Accadv TIME Accnat Accadv TIME\nTIEREDIMAGENET\nAT (5WAY-1SHOT) 30.88 % (0.52"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "8525fa0f88611939c7a5cca793856e233aec2cf9",
                "externalIds": {
                    "ArXiv": "2106.12900",
                    "DBLP": "journals/corr/abs-2106-12900",
                    "CorpusId": 235623886
                },
                "corpusId": 235623886,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8525fa0f88611939c7a5cca793856e233aec2cf9",
                "title": "Long-term Cross Adversarial Training: A Robust Meta-learning Method for Few-shot Classification Tasks",
                "abstract": "Meta-learning model can quickly adapt to new tasks using few-shot labeled data. However, despite achieving good generalization on few-shot classification tasks, it is still challenging to improve the adversarial robustness of the meta-learning model in few-shot learning. Although adversarial training (AT) methods such as Adversarial Query (AQ) can improve the adversarially robust performance of meta-learning models, AT is still computationally expensive training. On the other hand, meta-learning models trained with AT will drop significant accuracy on the original clean images. This paper proposed a meta-learning method on the adversarially robust neural network called Long-term Cross Adversarial Training (LCAT). LCAT will update meta-learning model parameters cross along the natural and adversarial sample distribution direction with long-term to improve both adversarial and clean few-shot classification accuracy. Due to cross-adversarial training, LCAT only needs half of the adversarial training epoch than AQ, resulting in a low adversarial training computation. Experiment results show that LCAT achieves superior performance both on the clean and adversarial few-shot classification accuracy than SOTA adversarial training methods for meta-learning models.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "70448703",
                        "name": "F. Liu"
                    },
                    {
                        "authorId": "2111308126",
                        "name": "Shuyu Zhao"
                    },
                    {
                        "authorId": "1380439474",
                        "name": "Xuelong Dai"
                    },
                    {
                        "authorId": "2054421528",
                        "name": "Bin Xiao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As CIFAR-FS is a small dataset, we follow [3,23] to consider 5way 1-shot and 5-way 5-shot.",
                "Besides, CIFAR-FS is a subset of CIFAR-100, containing images of 32\u00d7 32 [3]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "80d4a74fd7703dafe14402a61117aec263dbdc27",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-09398",
                    "ArXiv": "2106.09398",
                    "DOI": "10.1007/978-3-030-75768-7_1",
                    "CorpusId": 234366288
                },
                "corpusId": 234366288,
                "publicationVenue": {
                    "id": "1e517cb2-1ca1-45b8-964a-456366bdcdc1",
                    "name": "Pacific-Asia Conference on Knowledge Discovery and Data Mining",
                    "type": "conference",
                    "alternate_names": [
                        "PAKDD",
                        "Pacific-asia Conf Knowl Discov Data Min"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/80d4a74fd7703dafe14402a61117aec263dbdc27",
                "title": "Episode Adaptive Embedding Networks for Few-Shot Learning",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2146422849",
                        "name": "Fangbing Liu"
                    },
                    {
                        "authorId": "2117944850",
                        "name": "Qing Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We conduct experiments on a set of widely used benchmarks for few-shot image classification: mini-ImageNet, tieredImageNet, CIFAR-FS and FC100.",
                "\u2022 CIFAR-FS (Bertinetto et al., 2019): It contains 60,000 colored images of 32x32 pixels, with 100 classes (each with 600 images) split into 64 training classes, 16 validation classes and 20 test classes.",
                "Note that the two ImageNet derivatives (i.e., mini-ImageNet of 7.2 GB and tiered-ImageNet of 29 GB) are much bigger than that of the two CIFAR-100 derivatives (i.e., CIFAR-FS of 336 MB and FC100 of 336 MB).",
                "As a comparison, another line of GBML algorithms uses the explicit `2 regularization in the inner loop instead (Rajeswaran et al., 2019; Lee et al., 2019b; Bertinetto et al., 2019; Zhou et al., 2019b; Goldblum et al., 2020)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "c18c92a925c4b670b1702c0a674cb6879ebe5e25",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-09017",
                    "ArXiv": "2106.09017",
                    "CorpusId": 235446399
                },
                "corpusId": 235446399,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/c18c92a925c4b670b1702c0a674cb6879ebe5e25",
                "title": "Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation",
                "abstract": "Multi-task learning (MTL) aims to improve the generalization of several related tasks by learning them jointly. As a comparison, in addition to the joint training scheme, modern meta-learning allows unseen tasks with limited labels during the test phase, in the hope of fast adaptation over them. Despite the subtle difference between MTL and meta-learning in the problem formulation, both learning paradigms share the same insight that the shared structure between existing training tasks could lead to better generalization and adaptation. In this paper, we take one important step further to understand the close connection between these two learning paradigms, through both theoretical analysis and empirical investigation. Theoretically, we first demonstrate that MTL shares the same optimization formulation with a class of gradient-based meta-learning (GBML) algorithms. We then prove that for over-parameterized neural networks with sufficient depth, the learned predictive functions of MTL and GBML are close. In particular, this result implies that the predictions given by these two models are similar over the same unseen task. Empirically, we corroborate our theoretical findings by showing that, with proper implementation, MTL is competitive against state-of-the-art GBML algorithms on a set of few-shot image classification benchmarks. Since existing GBML algorithms often involve costly second-order bi-level optimization, our first-order MTL method is an order of magnitude faster on large-scale datasets such as mini-ImageNet. We believe this work could help bridge the gap between these two learning paradigms, and provide a computationally efficient alternative to GBML that also supports fast task adaptation.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2029142",
                        "name": "Haoxiang Wang"
                    },
                    {
                        "authorId": "1390716752",
                        "name": "Han Zhao"
                    },
                    {
                        "authorId": "71788673",
                        "name": "Bo Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[10] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "df28d08cdd977ddc66e7d1ffe97731b67f209bb4",
                "externalIds": {
                    "ArXiv": "2106.08053",
                    "DBLP": "journals/corr/abs-2106-08053",
                    "CorpusId": 235436204
                },
                "corpusId": 235436204,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/df28d08cdd977ddc66e7d1ffe97731b67f209bb4",
                "title": "On the Power of Multitask Representation Learning in Linear MDP",
                "abstract": "While multitask representation learning has become a popular approach in reinforcement learning (RL), theoretical understanding of why and when it works remains limited. This paper presents analyses for the statistical benefit of multitask representation learning in linear Markov Decision Process (MDP) under a generative model. In this paper, we consider an agent to learn a representation function $\\phi$ out of a function class $\\Phi$ from $T$ source tasks with $N$ data per task, and then use the learned $\\hat{\\phi}$ to reduce the required number of sample for a new task. We first discover a \\emph{Least-Activated-Feature-Abundance} (LAFA) criterion, denoted as $\\kappa$, with which we prove that a straightforward least-square algorithm learns a policy which is $\\tilde{O}(H^2\\sqrt{\\frac{\\mathcal{C}(\\Phi)^2 \\kappa d}{NT}+\\frac{\\kappa d}{n}})$ sub-optimal. Here $H$ is the planning horizon, $\\mathcal{C}(\\Phi)$ is $\\Phi$'s complexity measure, $d$ is the dimension of the representation (usually $d\\ll \\mathcal{C}(\\Phi)$) and $n$ is the number of samples for the new task. Thus the required $n$ is $O(\\kappa d H^4)$ for the sub-optimality to be close to zero, which is much smaller than $O(\\mathcal{C}(\\Phi)^2\\kappa d H^4)$ in the setting without multitask representation learning, whose sub-optimality gap is $\\tilde{O}(H^2\\sqrt{\\frac{\\kappa \\mathcal{C}(\\Phi)^2d}{n}})$. This theoretically explains the power of multitask representation learning in reducing sample complexity. Further, we note that to ensure high sample efficiency, the LAFA criterion $\\kappa$ should be small. In fact, $\\kappa$ varies widely in magnitude depending on the different sampling distribution for new task. This indicates adaptive sampling technique is important to make $\\kappa$ solely depend on $d$. Finally, we provide empirical results of a noisy grid-world environment to corroborate our theoretical findings.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2047521049",
                        "name": "Ruitianyi Lu"
                    },
                    {
                        "authorId": "2115218570",
                        "name": "Gao Huang"
                    },
                    {
                        "authorId": "145697585",
                        "name": "S. Du"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9cf9a6ccc935c601cb3df8d325fc01e6f0a3e1f8",
                "externalIds": {
                    "ArXiv": "2106.05517",
                    "DBLP": "conf/cvpr/LiuZXZ0022",
                    "DOI": "10.1109/CVPR52688.2022.01401",
                    "CorpusId": 235390473
                },
                "corpusId": 235390473,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9cf9a6ccc935c601cb3df8d325fc01e6f0a3e1f8",
                "title": "Learning to Affiliate: Mutual Centralized Learning for Few-shot Classification",
                "abstract": "Few-shot learning (FSL) aims to learn a classifier that can be easily adapted to accommodate new tasks, given only a few examples. To handle the limited-data in few-shot regimes, recent methods tend to collectively use a set of local features to densely represent an image instead of using a mixed global feature. They generally explore a unidirectional paradigm, e.g., finding the nearest support feature for every query feature and aggregating local matches for a joint classification. In this paper, we propose a novel Mutual Centralized Learning (MCL) to fully affiliate these two disjoint dense features sets in a bidirectional paradigm. We first associate each local feature with a particle that can bidirectionally random walk in discrete feature space. To estimate the class probability, we propose the dense features' accessibility that measures the expected number of visits to the dense features of that class in a Markov process. We relate our method to learning a centrality on an affiliation network and demonstrate its capability to be plugged in existing methods by highlighting centralized local features. Experiments show that our method achieves the new state-of-the-art.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1614039034",
                        "name": "Yang Liu"
                    },
                    {
                        "authorId": "2108011590",
                        "name": "Weifeng Zhang"
                    },
                    {
                        "authorId": "153117519",
                        "name": "Chao Xiang"
                    },
                    {
                        "authorId": "2053658211",
                        "name": "Tu Zheng"
                    },
                    {
                        "authorId": "1724421",
                        "name": "Deng Cai"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This includes updates in closed form [2], iterative updates according to the gradient descent [10, 74, 44] and learnable iterative updates, such as LSTM [50]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "cb48a9854e7a398b589ba5b10dc7fa2095611ad5",
                "externalIds": {
                    "DBLP": "conf/wacv/LazarouSA22",
                    "ArXiv": "2106.05321",
                    "DOI": "10.1109/WACV51458.2022.00211",
                    "CorpusId": 235390545
                },
                "corpusId": 235390545,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/cb48a9854e7a398b589ba5b10dc7fa2095611ad5",
                "title": "Tensor feature hallucination for few-shot learning",
                "abstract": "Few-shot learning addresses the challenge of learning how to address novel tasks given not just limited supervision but limited data as well. An attractive solution is synthetic data generation. However, most such methods are overly sophisticated, focusing on high-quality, realistic data in the input space. It is unclear whether adapting them to the few-shot regime and using them for the downstream task of classification is the right approach. Previous works on synthetic data generation for few-shot classification focus on exploiting complex models, e.g. a Wasserstein GAN with multiple regularizers or a network that transfers latent diversities from known to novel classes.We follow a different approach and investigate how a simple and straightforward synthetic data generation method can be used effectively. We make two contributions, namely we show that: (1) using a simple loss function is more than enough for training a feature generator in the few-shot setting; and (2) learning to generate tensor features instead of vector features is superior. Extensive experiments on miniImagenet, CUB and CIFAR-FS datasets show that our method sets a new state of the art, outperforming more sophisticated few-shot data augmentation methods. The source code can be found at https://github.com/MichalisLazarou/TFH_fewshot.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "46973863",
                        "name": "Michalis Lazarou"
                    },
                    {
                        "authorId": "1744904",
                        "name": "Yannis Avrithis"
                    },
                    {
                        "authorId": "1783374",
                        "name": "T. Stathaki"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", ANIL [38], MetaOptNet [30], and R2D2 [29], are chosen as the benchmark algorithms.",
                "Besides MAML, some gradient-based approaches aim to learn a cross-task representation as meta-knowledge, which can generalize to new classes [29], [30].",
                "MetaOptNet and R2D2: MetaOptNet [30] and R2D2 [29] use support vector machine [39] and ridge regression as the"
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ca63e1ecc306224d72ce710510a592c079cb9668",
                "externalIds": {
                    "DBLP": "journals/tnn/TianLG22",
                    "DOI": "10.1109/TNNLS.2021.3084733",
                    "CorpusId": 235395456,
                    "PubMed": "34106865"
                },
                "corpusId": 235395456,
                "publicationVenue": {
                    "id": "79c5a18d-0295-432c-aaa5-961d73de6d88",
                    "name": "IEEE Transactions on Neural Networks and Learning Systems",
                    "alternate_names": [
                        "IEEE Trans Neural Netw Learn Syst"
                    ],
                    "issn": "2162-237X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ca63e1ecc306224d72ce710510a592c079cb9668",
                "title": "Consistent Meta-Regularization for Better Meta-Knowledge in Few-Shot Learning",
                "abstract": "Recently, meta-learning provides a powerful paradigm to deal with the few-shot learning problem. However, existing meta-learning approaches ignore the prior fact that good meta-knowledge should alleviate the data inconsistency between training and test data, caused by the extremely limited data, in each few-shot learning task. Moreover, legitimately utilizing the prior understanding of meta-knowledge can lead us to design an efficient method to improve the meta-learning model. Under this circumstance, we consider the data inconsistency from the distribution perspective, making it convenient to bring in the prior fact, and propose a new consistent meta-regularization (Con-MetaReg) to help the meta-learning model learn how to reduce the data-distribution discrepancy between the training and test data. In this way, the ability of meta-knowledge on keeping the training and test data consistent is enhanced, and the performance of the meta-learning model can be further improved. The extensive analyses and experiments demonstrate that our method can indeed improve the performances of different meta-learning models in few-shot regression, classification, and fine-grained classification.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51305326",
                        "name": "Pinzhuo Tian"
                    },
                    {
                        "authorId": "2108691450",
                        "name": "Wenbin Li"
                    },
                    {
                        "authorId": "2145974630",
                        "name": "Yang Gao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In few-shot meta-learning [1], the inner function g(x, \u00b7) often takes a quadratic form together with a strongly-convex regularizer.",
                "Bilevel optimization has become a timely and important topic recently due to its great effectiveness in a wide range of applications including hyperparameter optimization [7, 5], meta-learning [33, 16, 1], reinforcement learning [14, 24]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9e1b61004edcb6a94ea3a64e9f6c052e7490ca61",
                "externalIds": {
                    "ArXiv": "2106.04692",
                    "DBLP": "conf/nips/YangJL21",
                    "CorpusId": 235377197
                },
                "corpusId": 235377197,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/9e1b61004edcb6a94ea3a64e9f6c052e7490ca61",
                "title": "Provably Faster Algorithms for Bilevel Optimization",
                "abstract": "Bilevel optimization has been widely applied in many important machine learning applications such as hyperparameter optimization and meta-learning. Recently, several momentum-based algorithms have been proposed to solve bilevel optimization problems faster. However, those momentum-based algorithms do not achieve provably better computational complexity than $\\mathcal{\\widetilde O}(\\epsilon^{-2})$ of the SGD-based algorithm. In this paper, we propose two new algorithms for bilevel optimization, where the first algorithm adopts momentum-based recursive iterations, and the second algorithm adopts recursive gradient estimations in nested loops to decrease the variance. We show that both algorithms achieve the complexity of $\\mathcal{\\widetilde O}(\\epsilon^{-1.5})$, which outperforms all existing algorithms by the order of magnitude. Our experiments validate our theoretical results and demonstrate the superior empirical performance of our algorithms in hyperparameter applications.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2110873724",
                        "name": "Junjie Yang"
                    },
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Each combination was evaluated in a 5-shot 5-way few-shot setting on the CIFAR-FS dataset [51]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "68f882d03b19186a70fb2485df721ec4d9583c8e",
                "externalIds": {
                    "ArXiv": "2106.02566",
                    "DBLP": "journals/pr/GomezLFM22",
                    "DOI": "10.1016/j.patcog.2022.108927",
                    "CorpusId": 246431270
                },
                "corpusId": 246431270,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/68f882d03b19186a70fb2485df721ec4d9583c8e",
                "title": "BR-NPA: A non-parametric high-resolution attention model to improve the interpretability of attention",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2070904522",
                        "name": "T. Gomez"
                    },
                    {
                        "authorId": "23993939",
                        "name": "Suiyi Ling"
                    },
                    {
                        "authorId": "2107033619",
                        "name": "Thomas Fr'eour"
                    },
                    {
                        "authorId": "1790706",
                        "name": "H. Mouch\u00e8re"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We train our model on miniImageNet, tieredImageNet, CIFAR-FS and CUB-200-2011 for 200K, 200K, 100K and 100K iterations respectively.",
                "\u2022 We conduct extensive experiments on four benchmarks\n(i.e., miniImageNet, tieredImageNet, CIFAR-FS and CUB-200-2011) for the transductive few-shot classification task, and the results show that the proposed method achieves the state-of-the-art performances.",
                "CIFAR-FS [1] is reorganized from the CIFAR-100 dataset for the few-shot classification task.",
                "We follow the popularly used train/val/test setting proposed in [35, 36, 1, 47, 29]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "3cee6368f8825138636232d0d00c4b03ef1ae42b",
                "externalIds": {
                    "ArXiv": "2106.08523",
                    "DBLP": "conf/cvpr/ChenYXHM21",
                    "DOI": "10.1109/CVPR46437.2021.00653",
                    "CorpusId": 235446778
                },
                "corpusId": 235446778,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3cee6368f8825138636232d0d00c4b03ef1ae42b",
                "title": "ECKPN: Explicit Class Knowledge Propagation Network for Transductive Few-shot Learning",
                "abstract": "Recently, the transductive graph-based methods have achieved great success in the few-shot classification task. However, most existing methods ignore exploring the class-level knowledge that can be easily learned by humans from just a handful of samples. In this paper, we propose an Explicit Class Knowledge Propagation Network (ECKPN), which is composed of the comparison, squeeze and calibration modules, to address this problem. Specifically, we first employ the comparison module to explore the pairwise sample relations to learn rich sample representations in the instance-level graph. Then, we squeeze the instance-level graph to generate the class-level graph, which can help obtain the class-level visual knowledge and facilitate modeling the relations of different classes. Next, the calibration module is adopted to characterize the relations of the classes explicitly to obtain the more discriminative class-level knowledge representations. Finally, we combine the class-level knowledge with the instance-level sample representations to guide the inference of the query samples. We conduct extensive experiments on four few-shot classification benchmarks, and the experimental results show that the proposed ECKPN significantly outperforms the state-of-the art methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "120896645",
                        "name": "Chaofan CHEN"
                    },
                    {
                        "authorId": "2059713",
                        "name": "Xiaoshan Yang"
                    },
                    {
                        "authorId": "145194969",
                        "name": "Changsheng Xu"
                    },
                    {
                        "authorId": "145004602",
                        "name": "Xuhui Huang"
                    },
                    {
                        "authorId": "2125040673",
                        "name": "Zhe Ma"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "16bf1b781bf6a40a46d6c2c25ec4b4b863318088",
                "externalIds": {
                    "DBLP": "journals/ivc/LiuZF21",
                    "MAG": "3139511534",
                    "DOI": "10.1016/J.IMAVIS.2021.104164",
                    "CorpusId": 233546203
                },
                "corpusId": 233546203,
                "publicationVenue": {
                    "id": "6cc36eeb-d056-42c4-a306-7bcb239cc442",
                    "name": "Image and Vision Computing",
                    "type": "journal",
                    "alternate_names": [
                        "Image Vis Comput"
                    ],
                    "issn": "0262-8856",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525443/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/02628856",
                        "https://www.journals.elsevier.com/image-and-vision-computing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/16bf1b781bf6a40a46d6c2c25ec4b4b863318088",
                "title": "PDA: Proxy-based domain adaptation for few-shot image recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109614965",
                        "name": "Ge Liu"
                    },
                    {
                        "authorId": "1657444300",
                        "name": "Linglan Zhao"
                    },
                    {
                        "authorId": "1706164",
                        "name": "Xiangzhong Fang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5c6106dd24c393eaf79e4dfd495b0e694bf2670e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-04413",
                    "ArXiv": "2106.04413",
                    "DOI": "10.1109/CVPR46437.2021.01083",
                    "CorpusId": 235367653
                },
                "corpusId": 235367653,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5c6106dd24c393eaf79e4dfd495b0e694bf2670e",
                "title": "Stochastic Whitening Batch Normalization",
                "abstract": "Batch Normalization (BN) is a popular technique for training Deep Neural Networks (DNNs). BN uses scaling and shifting to normalize activations of mini-batches to accelerate convergence and improve generalization. The recently proposed Iterative Normalization (IterNorm) method improves these properties by whitening the activations iteratively using Newton\u2019s method. However, since Newton\u2019s method initializes the whitening matrix independently at each training step, no information is shared between consecutive steps. In this work, instead of exact computation of whitening matrix at each time step, we estimate it gradually during training in an online fashion, using our proposed Stochastic Whitening Batch Normalization (SWBN) algorithm. We show that while SWBN improves the convergence rate and generalization of DNNs, its computational overhead is less than that of IterNorm. Due to the high efficiency of the proposed method, it can be easily employed in most DNN architectures with a large number of layers. We provide comprehensive experiments and comparisons between BN, IterNorm, and SWBN layers to demonstrate the effectiveness of the proposed technique in conventional (many-shot) image classification and few-shot classification tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "87917854",
                        "name": "Shengdong Zhang"
                    },
                    {
                        "authorId": "1721295",
                        "name": "E. Nezhadarya"
                    },
                    {
                        "authorId": "9337946",
                        "name": "H. Fashandi"
                    },
                    {
                        "authorId": "2108357649",
                        "name": "Jiayi Liu"
                    },
                    {
                        "authorId": "2107745141",
                        "name": "Darin Graham"
                    },
                    {
                        "authorId": "40225085",
                        "name": "Mohak Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Few-shot learning is a fundamental yet unsolved problem in machine learning and computer vision [1, 19, 13, 14, 11, 25, 12]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e3d096aa5a077e03d4eb52d2e93f0deeb83f9531",
                "externalIds": {
                    "DBLP": "conf/cvpr/LiL21a",
                    "DOI": "10.1109/CVPR46437.2021.00311",
                    "CorpusId": 235657622
                },
                "corpusId": 235657622,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e3d096aa5a077e03d4eb52d2e93f0deeb83f9531",
                "title": "Transformation Invariant Few-Shot Object Detection",
                "abstract": "Few-shot object detection (FSOD) aims to learn detectors that can be generalized to novel classes with only a few instances. Unlike previous attempts that exploit meta-learning techniques to facilitate FSOD, this work tackles the problem from the perspective of sample expansion. To this end, we propose a simple yet effective Transformation Invariant Principle (TIP) that can be flexibly applied to various meta-learning models for boosting the detection performance on novel class objects. Specifically, by introducing consistency regularization on predictions from various transformed images, we augment vanilla FSOD models with the generalization ability to objects perturbed by various transformation, such as occlusion and noise. Importantly, our approach can extend supervised FSOD models to naturally cope with unlabeled data, thus addressing a more practical and challenging semi-supervised FSOD problem. Extensive experiments on PASCAL VOC and MSCOCO datasets demonstrate the effectiveness of our TIP under both of the two FSOD settings.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "5683005",
                        "name": "Aoxue Li"
                    },
                    {
                        "authorId": "7718952",
                        "name": "Zhenguo Li"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "919cb84e6d19505625d2df763ae267c4a0cb6334",
                "externalIds": {
                    "DBLP": "conf/cvpr/WangLVNKN21",
                    "DOI": "10.1109/CVPRW53098.2021.00259",
                    "CorpusId": 235692972
                },
                "corpusId": 235692972,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/919cb84e6d19505625d2df763ae267c4a0cb6334",
                "title": "MTUNet: Few-shot Image Classification with Visual Explanations",
                "abstract": "Few-shot learning (FSL) approaches, mostly neural network-based, are assuming that the pre-trained knowledge can be obtained from base (seen) categories and transferred to novel (unseen) categories. However, the black-box nature of neural networks makes it difficult to understand what is actually transferred, which may hamper its application in some risk-sensitive areas. In this paper, we reveal a new way to perform explainable FSL for image classification, using discriminative patterns and pairwise matching. Experimental results prove that the proposed method can achieve satisfactory explainability on two mainstream datasets. Code is available*.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2153213890",
                        "name": "Bowen Wang"
                    },
                    {
                        "authorId": "47681301",
                        "name": "Liangzhi Li"
                    },
                    {
                        "authorId": "1840437995",
                        "name": "Manisha Verma"
                    },
                    {
                        "authorId": "1789677",
                        "name": "Yuta Nakashima"
                    },
                    {
                        "authorId": "1738501775",
                        "name": "R. Kawasaki"
                    },
                    {
                        "authorId": "144829054",
                        "name": "H. Nagahara"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In addition, it is difficult for the SOT modules in many of them to benefit from the end-to-end training of CNNs or to keep the objective of offline training consistent with that of online tracking, limiting the power of the SOT module.",
                "Different from the previous methods [11, 46] which employ the features extracted via the ImageNet pre-trained CNNs to train discriminative models, modern methods [34, 4, 47] integrate the solver of discriminative model into the offline training of CNNs to learn the optimal feature embeddings for the SOT task.",
                "3) can be integrated into the offline training of CNNs [2, 47], the SOT branch can be trained in an end-toend way following the above, learning the optimal feature embeddings for the ridge regression model based single object tracker which tracks the target object by distinguishing it from its surrounding similar ones."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4d4b2bf9ff48b35e7191094aab643943188c5c45",
                "externalIds": {
                    "DBLP": "conf/cvpr/Zheng0CZWL21",
                    "DOI": "10.1109/CVPR46437.2021.00248",
                    "CorpusId": 235702636
                },
                "corpusId": 235702636,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4d4b2bf9ff48b35e7191094aab643943188c5c45",
                "title": "Improving Multiple Object Tracking with Single Object Tracking",
                "abstract": "Despite considerable similarities between multiple object tracking (MOT) and single object tracking (SOT) tasks, modern MOT methods have not benefited from the development of SOT ones to achieve satisfactory performance. The major reason for this situation is that it is inappropriate and inefficient to apply multiple SOT models directly to the MOT task, although advanced SOT methods are of the strong discriminative power and can run at fast speeds.In this paper, we propose a novel and end-to-end trainable MOT architecture that extends CenterNet by adding an SOT branch for tracking objects in parallel with the existing branch for object detection, allowing the MOT task to benefit from the strong discriminative power of SOT methods in an effective and efficient way. Unlike most existing SOT methods which learn to distinguish the target object from its local backgrounds, the added SOT branch trains a separate SOT model per target online to distinguish the target from its surrounding targets, assigning SOT models the novel discrimination. Moreover, similar to the detection branch, the SOT branch treats objects as points, making its online learning efficient even if multiple targets are processed simultaneously. Without tricks, the proposed tracker achieves MOTAs of 0.710 and 0.686, IDF1s of 0.719 and 0.714, on MOT17 and MOT20 benchmarks, respectively, while running at 16 FPS on MOT17.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "48026369",
                        "name": "Linyu Zheng"
                    },
                    {
                        "authorId": "2113727378",
                        "name": "Ming Tang"
                    },
                    {
                        "authorId": "50580380",
                        "name": "Yingying Chen"
                    },
                    {
                        "authorId": "2894321",
                        "name": "Guibo Zhu"
                    },
                    {
                        "authorId": "49606029",
                        "name": "Jinqiao Wang"
                    },
                    {
                        "authorId": "1694235",
                        "name": "Hanqing Lu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "56bf0c8f29857fb10bf5c8418cad79b72a98dc7b",
                "externalIds": {
                    "DBLP": "conf/cvpr/TangC0LGO21",
                    "DOI": "10.1109/CVPR46437.2021.00236",
                    "CorpusId": 235719188
                },
                "corpusId": 235719188,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/56bf0c8f29857fb10bf5c8418cad79b72a98dc7b",
                "title": "Mutual CRF-GNN for Few-shot Learning",
                "abstract": "Graph-neural-networks (GNN) is a rising trend for fewshot learning. A critical component in GNN is the affinity. Typically, affinity in GNN is mainly computed in the feature space, e.g., pairwise features, and does not take fully advantage of semantic labels associated to these features. In this paper, we propose a novel Mutual CRF-GNN (MCGN). In this MCGN, the labels and features of support data are used by the CRF for inferring GNN affinities in a principled and probabilistic way. Specifically, we construct a Conditional Random Field (CRF) conditioned on labels and features of support data to infer a affinity in the label space. Such affinity is fed to the GNN as the node-wise affinity. GNN and CRF mutually contributes to each other in MCGN. For GNN, CRF provides valuable affinity information. For CRF, GNN provides better features for inferring affinity. Experimental results show that our approach outperforms stateof-the-arts on datasets miniImageNet, tieredImageNet, and CIFAR-FS on both 5-way 1-shot and 5-way 5-shot settings.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "9084688",
                        "name": "Shixiang Tang"
                    },
                    {
                        "authorId": "143982372",
                        "name": "Dapeng Chen"
                    },
                    {
                        "authorId": "50010487",
                        "name": "Lei Bai"
                    },
                    {
                        "authorId": "2599915",
                        "name": "Kaijian Liu"
                    },
                    {
                        "authorId": "152988335",
                        "name": "Yixiao Ge"
                    },
                    {
                        "authorId": "3001348",
                        "name": "Wanli Ouyang"
                    },
                    {
                        "authorId": "2054238429",
                        "name": "Hong Kong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "taught a deep network to use standard machine learning tools like ridge regression for quickly learning parameters [18]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2a46bbca11ce4abe317b81e44bedd2853623aed0",
                "externalIds": {
                    "DBLP": "journals/pami/WangCDL22",
                    "DOI": "10.1109/TPAMI.2021.3082632",
                    "CorpusId": 235075435,
                    "PubMed": "34018930"
                },
                "corpusId": 235075435,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2a46bbca11ce4abe317b81e44bedd2853623aed0",
                "title": "Learning Deep Sparse Regularizers With Applications to Multi-View Clustering and Semi-Supervised Classification",
                "abstract": "Sparsity-constrained optimization problems are common in machine learning, such as sparse coding, low-rank minimization and compressive sensing. However, most of previous studies focused on constructing various hand-crafted sparse regularizers, while little work was devoted to learning adaptive sparse regularizers from given input data for specific tasks. In this paper, we propose a deep sparse regularizer learning model that learns data-driven sparse regularizers adaptively. Via the proximal gradient algorithm, we find that the sparse regularizer learning is equivalent to learning a parameterized activation function. This encourages us to learn sparse regularizers in the deep learning framework. Therefore, we build a neural network composed of multiple blocks, each being differentiable and reusable. All blocks contain learnable piecewise linear activation functions which correspond to the sparse regularizer to be learned. Furthermore, the proposed model is trained with back propagation, and all parameters in this model are learned end-to-end. We apply our framework to multi-view clustering and semi-supervised classification tasks to learn a latent compact representation. Experimental results demonstrate the superiority of the proposed framework over state-of-the-art multi-view learning models.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "47672719",
                        "name": "Shiping Wang"
                    },
                    {
                        "authorId": "2111605856",
                        "name": "Zhaoliang Chen"
                    },
                    {
                        "authorId": "2100639893",
                        "name": "Shide Du"
                    },
                    {
                        "authorId": "33383055",
                        "name": "Zhouchen Lin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [24] contains 100 classes with 600 images per class, and it is split into 64 base, 16 validation, and 20 novel classes.",
                "\u2022 CIFAR-FS and FC100: two datasets derived from CIFAR-100 [23]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "19a0062095cb089ea37d2d5b2f95bf2a569489f2",
                "externalIds": {
                    "DBLP": "journals/pr/LiYMX23",
                    "ArXiv": "2105.08149",
                    "DOI": "10.1016/j.patcog.2023.109381",
                    "CorpusId": 250072756
                },
                "corpusId": 250072756,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/19a0062095cb089ea37d2d5b2f95bf2a569489f2",
                "title": "Deep metric learning for few-shot image classification: A Review of recent developments",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "145074587",
                        "name": "Xiaoxu Li"
                    },
                    {
                        "authorId": "50031404",
                        "name": "Xiaochen Yang"
                    },
                    {
                        "authorId": "1755773",
                        "name": "Zhanyu Ma"
                    },
                    {
                        "authorId": "1891766",
                        "name": "Jing-Hao Xue"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5ffee7480bdb997a0f8452829016eee71cb8bbce",
                "externalIds": {
                    "PubMedCentral": "8242586",
                    "DBLP": "journals/ijis/ZhengYGZZHW21",
                    "DOI": "10.1002/int.22449",
                    "CorpusId": 235689895
                },
                "corpusId": 235689895,
                "publicationVenue": {
                    "id": "05528bac-d212-46a6-9c84-314d4bd77368",
                    "name": "International Journal of Intelligent Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Intell Syst"
                    ],
                    "issn": "0884-8173",
                    "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/36062",
                    "alternate_urls": [
                        "https://onlinelibrary.wiley.com/journal/1098111X"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5ffee7480bdb997a0f8452829016eee71cb8bbce",
                "title": "Learning to learn by yourself: Unsupervised meta\u2010learning with self\u2010knowledge distillation for COVID\u201019 diagnosis from pneumonia cases",
                "abstract": "The goal of diagnosing the coronavirus disease 2019 (COVID\u201019) from suspected pneumonia cases, that is, recognizing COVID\u201019 from chest X\u2010ray or computed tomography (CT) images, is to improve diagnostic accuracy, leading to faster intervention. The most important and challenging problem here is to design an effective and robust diagnosis model. To this end, there are three challenges to overcome: (1) The lack of training samples limits the success of existing deep\u2010learning\u2010based methods. (2) Many public COVID\u201019 data sets contain only a few images without fine\u2010grained labels. (3) Due to the explosive growth of suspected cases, it is urgent and important to diagnose not only COVID\u201019 cases but also the cases of other types of pneumonia that are similar to the symptoms of COVID\u201019. To address these issues, we propose a novel framework called Unsupervised Meta\u2010Learning with Self\u2010Knowledge Distillation to address the problem of differentiating COVID\u201019 from pneumonia cases. During training, our model cannot use any true labels and aims to gain the ability of learning to learn by itself. In particular, we first present a deep diagnosis model based on a relation network to capture and memorize the relation among different images. Second, to enhance the performance of our model, we design a self\u2010knowledge distillation mechanism that distills knowledge within our model itself. Our network is divided into several parts, and the knowledge in the deeper parts is squeezed into the shallow ones. The final results are derived from our model by learning to compare the features of images. Experimental results demonstrate that our approach achieves significantly higher performance than other state\u2010of\u2010the\u2010art methods. Moreover, we construct a new COVID\u201019 pneumonia data set based on text mining, consisting of 2696 COVID\u201019 images (347 X\u2010ray\u2009+\u20092349 CT), 10,155 images (9661 X\u2010ray\u2009+\u2009494 CT) about other types of pneumonia, and the fine\u2010grained labels of all. Our data set considers not only a bacterial infection or viral infection which causes pneumonia but also a viral infection derived from the influenza virus or coronavirus.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "48499775",
                        "name": "Wenbo Zheng"
                    },
                    {
                        "authorId": "151486225",
                        "name": "Lan Yan"
                    },
                    {
                        "authorId": "1491637173",
                        "name": "Chao Gou"
                    },
                    {
                        "authorId": "2110148121",
                        "name": "Zhi-Cheng Zhang"
                    },
                    {
                        "authorId": "2155659664",
                        "name": "J. Zhang"
                    },
                    {
                        "authorId": "2145919872",
                        "name": "Ming Hu"
                    },
                    {
                        "authorId": "47939505",
                        "name": "Fei-Yue Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "49a7f2e14d920815aa7741b1ab4b26e6b38200bf",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2105-03781",
                    "ArXiv": "2105.03781",
                    "DOI": "10.1109/TPAMI.2022.3154930",
                    "CorpusId": 234337943,
                    "PubMed": "35226600"
                },
                "corpusId": 234337943,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/49a7f2e14d920815aa7741b1ab4b26e6b38200bf",
                "title": "MetaKernel: Learning Variational Random Features with Limited Labels",
                "abstract": "Few-shot learning deals with the fundamental and challenging problem of learning from a few annotated samples, while being able to generalize well on new tasks. The crux of few-shot learning is to extract prior knowledge from related tasks to enable fast adaptation to a new task with a limited amount of data. In this paper, we propose meta-learning kernels with random Fourier features for few-shot learning, we call MetaKernel. Specically, we propose learning variational random features in a data-driven manner to obtain task-specic kernels by leveraging the shared knowledge provided by related tasks in a meta-learning setting. We treat the random feature basis as the latent variable, which is estimated by variational inference. The shared knowledge from related tasks is incorporated into a context inference of the posterior, which we achieve via a long-short term memory module. To establish more expressive kernels, we deploy conditional normalizing ows based on coupling layers to achieve a richer posterior distribution over random Fourier bases. The resultant kernels are more informative and discriminative, which further improves the few-shot learning. We conduct experiments on both few-shot image classication and regression tasks. The results on fourteen datasets demonstrate MetaKernel consistently better performance than state-of-the-art alternatives.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "46941376",
                        "name": "Yingjun Du"
                    },
                    {
                        "authorId": "2118180878",
                        "name": "Haoliang Sun"
                    },
                    {
                        "authorId": "34798935",
                        "name": "Xiantong Zhen"
                    },
                    {
                        "authorId": "145971173",
                        "name": "Jun Xu"
                    },
                    {
                        "authorId": "102446355",
                        "name": "Yilong Yin"
                    },
                    {
                        "authorId": "144082425",
                        "name": "Ling Shao"
                    },
                    {
                        "authorId": "145404204",
                        "name": "Cees G. M. Snoek"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The minimax bound applies regardless of the target fine-tuning procedure in use, including those used in practice, e.g. iMAML, MetaOptNet (Lee et al., 2019), and R2D2 (Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d4d37dfff71691cda8b4ff2314884b172fb5671b",
                "externalIds": {
                    "DBLP": "conf/nips/ChuaLL21",
                    "ArXiv": "2105.02221",
                    "CorpusId": 233740029
                },
                "corpusId": 233740029,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/d4d37dfff71691cda8b4ff2314884b172fb5671b",
                "title": "How Fine-Tuning Allows for Effective Meta-Learning",
                "abstract": "Representation learning has been widely studied in the context of meta-learning, enabling rapid learning of new tasks through shared representations. Recent works such as MAML have explored using fine-tuning-based metrics, which measure the ease by which fine-tuning can achieve good performance, as proxies for obtaining representations. We present a theoretical framework for analyzing representations derived from a MAML-like algorithm, assuming the available tasks use approximately the same underlying representation. We then provide risk bounds on the best predictor found by fine-tuning via gradient descent, demonstrating that the algorithm can provably leverage the shared structure. The upper bound applies to general function classes, which we demonstrate by instantiating the guarantees of our framework in the logistic regression and neural network settings. In contrast, we establish the existence of settings where any algorithm, using a representation trained with no consideration for task-specific fine-tuning, performs as well as a learner with no access to source tasks in the worst case. This separation result underscores the benefit of fine-tuning-based methods, such as MAML, over methods with\"frozen representation\"objectives in few-shot learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "46224156",
                        "name": "Kurtland Chua"
                    },
                    {
                        "authorId": "144438755",
                        "name": "Qi Lei"
                    },
                    {
                        "authorId": "2108327687",
                        "name": "Jason D. Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Applications of optimization-based modeling include computer vision [36, 37], reinforcement learning [5, 14, 42], game theory [30], and inverse optimization [38], and metalearning [11, 29]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1695324c0f5233a5b62fa52f12ae2d2e8bf22fa8",
                "externalIds": {
                    "DBLP": "conf/icml/PaulusRMAM21",
                    "ArXiv": "2105.02343",
                    "CorpusId": 233864616
                },
                "corpusId": 233864616,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/1695324c0f5233a5b62fa52f12ae2d2e8bf22fa8",
                "title": "CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints",
                "abstract": "Bridging logical and algorithmic reasoning with modern machine learning techniques is a funda-mental challenge with potentially transformative impact. On the algorithmic side, many NP- HARD problems can be expressed as integer programs, in which the constraints play the role of their \u201ccom-binatorial specification.\u201d In this work, we aim to integrate integer programming solvers into neural network architectures as layers capable of learning both the cost terms and the constraints. The resulting end-to-end trainable architectures jointly extract features from raw data and solve a suitable (learned) combinatorial problem with state-of-the-art integer programming solvers. We demonstrate the potential of such layers with an extensive performance analysis on synthetic data and with a demonstration on a competitive computer vision keypoint matching benchmark.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1443432623",
                        "name": "Anselm Paulus"
                    },
                    {
                        "authorId": "2065785622",
                        "name": "Michal Rol'inek"
                    },
                    {
                        "authorId": "153431278",
                        "name": "V\u00edt Musil"
                    },
                    {
                        "authorId": "1773498",
                        "name": "Brandon Amos"
                    },
                    {
                        "authorId": "144247521",
                        "name": "G. Martius"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6bf306366811f4495e7d0ee85de235498da2f317",
                "externalIds": {
                    "DBLP": "journals/ijis/ZhengYGW21",
                    "DOI": "10.1002/int.22372",
                    "CorpusId": 232432836
                },
                "corpusId": 232432836,
                "publicationVenue": {
                    "id": "05528bac-d212-46a6-9c84-314d4bd77368",
                    "name": "International Journal of Intelligent Systems",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Intell Syst"
                    ],
                    "issn": "0884-8173",
                    "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/36062",
                    "alternate_urls": [
                        "https://onlinelibrary.wiley.com/journal/1098111X"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6bf306366811f4495e7d0ee85de235498da2f317",
                "title": "Fighting fire with fire: A spatial\u2013frequency ensemble relation network with generative adversarial learning for adversarial image classification",
                "abstract": "Adversarial images generated by generative adversarial networks are not close to any existing benign images, and contain nonrobust features that have been identified as critical to the robustness of a machine learning model. Since adversarial images have an underlying distribution that differs from normal images, these kinds of images can offer valuable features for training a robust model. To deal with these special features, we focus on a novel machine learning task of adversarial images classification, where adversarial images can be used to investigate the problem of classifying adversarial images themselves. In the setting of this novel task, adversarial images are the ONLY kind of data used in training and testing, rather than not just a set of testing images as usual. To this end, we propose a novel spatial\u2013frequency ensemble relation network with generative adversarial learning. First, we present a spatial\u2013frequency ensemble representation learning to extract the feature of training images. Second, we design a meta\u2010learning\u2010based relation model to gain the relationship between images. Third, to achieve a robust model, we utilize generative adversarial learning and transform the relationship into a Jacobian matrix. Finally, we design a discriminator model that determines whether an adversarial image is from the matching category or not. Experimental results demonstrate that our approach achieves significantly higher performance compared with other state\u2010of\u2010the\u2010arts.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "48499775",
                        "name": "Wenbo Zheng"
                    },
                    {
                        "authorId": "151486225",
                        "name": "Lan Yan"
                    },
                    {
                        "authorId": "1491637173",
                        "name": "Chao Gou"
                    },
                    {
                        "authorId": "47939505",
                        "name": "Fei-Yue Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This dataset [36] is obtained by randomly splitting 100 classes in CIFAR-100 [37] into 64 training classes, 16 validation",
                "* means results for miniImageNet and CUB-200-2011 datasets are from [39], and results for CIFAR-FS are from [36]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1630b0a4ec90bdfc52cb5f5f9031b2ae6805a9ba",
                "externalIds": {
                    "ArXiv": "2105.05348",
                    "DBLP": "conf/crv/ChenW21",
                    "DOI": "10.1109/CRV52889.2021.00011",
                    "CorpusId": 234469958
                },
                "corpusId": 234469958,
                "publicationVenue": {
                    "id": "3eaf5a5d-62f7-41b6-817e-92d78060c075",
                    "name": "Canadian Conference on Computer and Robot Vision",
                    "type": "conference",
                    "alternate_names": [
                        "CRV",
                        "Can Conf Comput Robot Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=583"
                },
                "url": "https://www.semanticscholar.org/paper/1630b0a4ec90bdfc52cb5f5f9031b2ae6805a9ba",
                "title": "Few-Shot Learning by Integrating Spatial and Frequency Representation",
                "abstract": "Human beings can recognize new objects with only a few labeled examples, however, few-shot learning remains a challenging problem for machine learning systems. Most previous algorithms in few-shot learning only utilize spatial information of the images. In this paper, we propose to integrate the frequency information into the learning model to boost the discrimination ability of the system. We employ Discrete Cosine Transformation (DCT) to generate the frequency representation, then, integrate the features from both the spatial domain and frequency domain for classification. The proposed strategy and its effectiveness are validated with different backbones, datasets, and algorithms. Extensive experiments demonstrate that the frequency information is complementary to the spatial representations in few-shot classification. The classification accuracy is boosted significantly by integrating features from both the spatial and frequency domains in different few-shot learning tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2143736330",
                        "name": "Xiangyu Chen"
                    },
                    {
                        "authorId": "2152581972",
                        "name": "Guanghui Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Optimization-based works learn task-agnostic knowledge on model parameters [35,4,65] for fast adaptation to new tasks on limited training data, using only a few gradient update steps."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c1a9bdb19a5ec2d23b10335e97bc1410b0cad671",
                "externalIds": {
                    "ArXiv": "2104.14805",
                    "DBLP": "conf/eccv/FanTT22",
                    "DOI": "10.1007/978-3-031-20044-1_5",
                    "CorpusId": 233476265
                },
                "corpusId": 233476265,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/c1a9bdb19a5ec2d23b10335e97bc1410b0cad671",
                "title": "Few-Shot Video Object Detection",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2105557652",
                        "name": "Qi Fan"
                    },
                    {
                        "authorId": "2088295",
                        "name": "Chi-Keung Tang"
                    },
                    {
                        "authorId": "5068280",
                        "name": "Yu-Wing Tai"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Existing few-shot learning methods based on data augmentation [12,6,5], metric learning [26,27,2], and initialization [10,25,23] ameliorate the models in terms of supervised empirical growth, hypothesis space reduction, and initial parameter setting, respectively, so as to enhance the generalization ability of the models under the premise of inadequate training data."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6a29ec16b44c95204df3b08ac3ab3efc83a891e0",
                "externalIds": {
                    "MAG": "3159249071",
                    "DBLP": "journals/corr/abs-2104-14696",
                    "ArXiv": "2104.14696",
                    "DOI": "10.1007/978-3-030-82136-4_45",
                    "CorpusId": 233476572
                },
                "corpusId": 233476572,
                "publicationVenue": {
                    "id": "3e22d1e0-9b11-40a4-ac7c-0ebe5825316e",
                    "name": "Knowledge Science, Engineering and Management",
                    "type": "conference",
                    "alternate_names": [
                        "KSEM",
                        "Knowl Sci Eng Manag"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1923"
                },
                "url": "https://www.semanticscholar.org/paper/6a29ec16b44c95204df3b08ac3ab3efc83a891e0",
                "title": "Spirit Distillation: A Model Compression Method with Multi-domain Knowledge Transfer",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2146254894",
                        "name": "Zhiyuan Wu"
                    },
                    {
                        "authorId": "2118492219",
                        "name": "Yu Jiang"
                    },
                    {
                        "authorId": "2152527913",
                        "name": "Minghao Zhao"
                    },
                    {
                        "authorId": "2003576699",
                        "name": "Chupeng Cui"
                    },
                    {
                        "authorId": "2109479351",
                        "name": "Zongmin Yang"
                    },
                    {
                        "authorId": "2003577494",
                        "name": "Xinhui Xue"
                    },
                    {
                        "authorId": "2072590105",
                        "name": "Hong Qi"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c95ee5782289dd84a841033db1772a4365548a75",
                "externalIds": {
                    "DBLP": "journals/tamd/ZhangLSWLSWL22",
                    "MAG": "3162390478",
                    "DOI": "10.1109/TCDS.2021.3075280",
                    "CorpusId": 236545781
                },
                "corpusId": 236545781,
                "publicationVenue": {
                    "id": "f35f148a-0a3c-45db-b610-3d89e09ddf21",
                    "name": "IEEE Transactions on Cognitive and Developmental Systems",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Cogn Dev Syst"
                    ],
                    "issn": "2379-8920",
                    "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7274989"
                },
                "url": "https://www.semanticscholar.org/paper/c95ee5782289dd84a841033db1772a4365548a75",
                "title": "Mixture Distribution Graph Network for Few Shot Learning",
                "abstract": "Few-shot learning aims at heuristically resolving new tasks with limited labeled data; most of the existing approaches are affected by knowledge learned from similar experiences. However, interclass barriers and new samples insufficiency limit the transfer of knowledge. In this article, we propose a novel mixture distribution graph network, in which the interclass relation is explicitly modeled and propagated via graph generation. Owing to the weighted distribution features based on the Gaussian mixture model, we take class diversity into consideration, thereby utilizing information precisely and efficiently. Equipped with minimal gated units, the \u201cmemory\u201d of similar tasks can be preserved and reused through episode training, which fills a gap in temporal characteristics and softens the impact of data insufficiency. Extensive trials are carried out based on the MiniImageNet and CIFAR-FS data sets. The results turn out that our method exceeds most state-of-the-art approaches, which shows the validity and universality of our method in few-shot learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118874391",
                        "name": "Baiyan Zhang"
                    },
                    {
                        "authorId": "144125487",
                        "name": "H. Ling"
                    },
                    {
                        "authorId": "2115732704",
                        "name": "Jialie Shen"
                    },
                    {
                        "authorId": null,
                        "name": "Qian Wang"
                    },
                    {
                        "authorId": "2052835090",
                        "name": "Jie Lei"
                    },
                    {
                        "authorId": "1753219181",
                        "name": "Yuxuan Shi"
                    },
                    {
                        "authorId": "50789878",
                        "name": "L. Wu"
                    },
                    {
                        "authorId": "144785138",
                        "name": "Ping Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "MAML uses a gradient descent method for fine-tuning, where the gradient of the gradient is needed for backpropagation through the gradient descent steps, which can be costly in terms of memory [5]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "101bbfb1686f806c94ab8cc49ee94945b0f05cf7",
                "externalIds": {
                    "ArXiv": "2104.09011",
                    "MAG": "3153057066",
                    "DBLP": "journals/corr/abs-2104-09011",
                    "CorpusId": 233296621
                },
                "corpusId": 233296621,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/101bbfb1686f806c94ab8cc49ee94945b0f05cf7",
                "title": "Few-shot Learning for Topic Modeling",
                "abstract": "Topic models have been successfully used for analyzing text documents. However, with existing topic models, many documents are required for training. In this paper, we propose a neural network-based few-shot learning method that can learn a topic model from just a few documents. The neural networks in our model take a small number of documents as inputs, and output topic model priors. The proposed method trains the neural networks such that the expected test likelihood is improved when topic model parameters are estimated by maximizing the posterior probability using the priors based on the EM algorithm. Since each step in the EM algorithm is differentiable, the proposed method can backpropagate the loss through the EM algorithm to train the neural networks. The expected test likelihood is maximized by a stochastic gradient descent method using a set of multiple text corpora with an episodic training framework. In our experiments, we demonstrate that the proposed method achieves better perplexity than existing methods using three real-world text document sets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2664600",
                        "name": "Tomoharu Iwata"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "01263f15e0724ed145f7ebd421702c883b0949b9",
                "externalIds": {
                    "DBLP": "conf/cvpr/ChenGZHW21",
                    "ArXiv": "2104.07841",
                    "DOI": "10.1109/CVPR46437.2021.01345",
                    "CorpusId": 233289906
                },
                "corpusId": 233289906,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/01263f15e0724ed145f7ebd421702c883b0949b9",
                "title": "Pareto Self-Supervised Training for Few-Shot Learning",
                "abstract": "While few-shot learning (FSL) aims for rapid generalization to new concepts with little supervision, self-supervised learning (SSL) constructs supervisory signals directly computed from unlabeled data. Exploiting the complementarity of these two manners, few-shot auxiliary learning has recently drawn much attention to deal with few labeled data. Previous works benefit from sharing inductive bias between the main task (FSL) and auxiliary tasks (SSL), where the shared parameters of tasks are optimized by minimizing a linear combination of task losses. However, it is challenging to select a proper weight to balance tasks and reduce task conflict. To handle the problem as a whole, we propose a novel approach named as Pareto self-supervised training (PSST) for FSL. PSST explicitly decomposes the few-shot auxiliary problem into multiple constrained multi-objective subproblems with different trade-off preferences, and here a preference region in which the main task achieves the best performance is identified. Then, an effective preferred Pareto exploration is proposed to find a set of optimal solutions in such a preference region. Extensive experiments on several public benchmark datasets validate the effectiveness of our approach by achieving state-of-the-art performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2117202703",
                        "name": "Zhengyu Chen"
                    },
                    {
                        "authorId": "2077594077",
                        "name": "Jixie Ge"
                    },
                    {
                        "authorId": "2077593788",
                        "name": "Heshen Zhan"
                    },
                    {
                        "authorId": "122132048",
                        "name": "Siteng Huang"
                    },
                    {
                        "authorId": "2111224425",
                        "name": "Donglin Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Typical examples include CIFAR-FS [7], mini-ImageNet [71, 52], TCGA [58], MultiMNIST [57, 62], CU Birds [75], FGVC Planes [36] and Fungi [64, 61], VGG Flowers [41], and Omniglot [29, 30].",
                "Some extensions to ProtoNet centered around learning and improving a specialized distance metric for a given task, typically by solving a convex optimization problem [7, 31, 83].",
                "[7, 71]) or leverage class semantic relationships (e.",
                "We denote by CNN4 the 4-layer CNN with 64 hidden described in [63], which we use for few-shot learning experiments on FC100, CIFAR-FS, EMNIST, and LFW10."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "5c9957636960a0bf09b7b4cb280d63e451f5fe1d",
                "externalIds": {
                    "ArXiv": "2104.07255",
                    "DBLP": "journals/corr/abs-2104-07255",
                    "CorpusId": 233241114
                },
                "corpusId": 233241114,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5c9957636960a0bf09b7b4cb280d63e451f5fe1d",
                "title": "Embedding Adaptation is Still Needed for Few-Shot Learning",
                "abstract": "Constructing new and more challenging tasksets is a fruitful methodology to analyse and understand few-shot classification methods. Unfortunately, existing approaches to building those tasksets are somewhat unsatisfactory: they either assume train and test task distributions to be identical -- which leads to overly optimistic evaluations -- or take a\"worst-case\"philosophy -- which typically requires additional human labor such as obtaining semantic class relationships. We propose ATG, a principled clustering method to defining train and test tasksets without additional human knowledge. ATG models train and test task distributions while requiring them to share a predefined amount of information. We empirically demonstrate the effectiveness of ATG in generating tasksets that are easier, in-between, or harder than existing benchmarks, including those that rely on semantic information. Finally, we leverage our generated tasksets to shed a new light on few-shot classification: gradient-based methods -- previously believed to underperform -- can outperform metric-based ones when transfer is most challenging.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "16378659",
                        "name": "S\u00e9bastien M. R. Arnold"
                    },
                    {
                        "authorId": "145757665",
                        "name": "Fei Sha"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026in tasks such as hyper-parameter optimization (Maity et al., 2019), architecture search (Souquet et al., 2020; Hou and Jin, 2020) and meta-learning (Bertinetto et al., 2019), where the problem is solved by constructing the explicit gradient\u2207\u03b8R (Grazzi et al., 2020; Finn et al., 2017; Okuno et al.,\u2026",
                ", 2020; Hou and Jin, 2020) and meta-learning (Bertinetto et al., 2019), where the problem is solved by constructing the explicit gradient\u2207\u03b8R (Grazzi et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5994e5f83ac1c045898012d5d2be39469f118025",
                "externalIds": {
                    "ArXiv": "2104.07541",
                    "DBLP": "journals/corr/abs-2104-07541",
                    "MAG": "3153818079",
                    "CorpusId": 233241021
                },
                "corpusId": 233241021,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5994e5f83ac1c045898012d5d2be39469f118025",
                "title": "Reward Optimization for Neural Machine Translation with Learned Metrics",
                "abstract": "Neural machine translation (NMT) models are conventionally trained with token-level negative log-likelihood (NLL), which does not guarantee that the generated translations will be optimized for a selected sequence-level evaluation metric. Multiple approaches are proposed to train NMT with BLEU as the reward, in order to directly improve the metric. However, it was reported that the gain in BLEU does not translate to real quality improvement, limiting the application in industry. Recently, it became clear to the community that BLEU has a low correlation with human judgment when dealing with state-of-the-art models. This leads to the emerging of model-based evaluation metrics. These new metrics are shown to have a much higher human correlation. In this paper, we investigate whether it is beneficial to optimize NMT models with the state-of-the-art model-based metric, BLEURT. We propose a contrastive-margin loss for fast and stable reward optimization suitable for large NMT models. In experiments, we perform automatic and human evaluations to compare models trained with smoothed BLEU and BLEURT to the baseline models. Results show that the reward optimization with BLEURT is able to increase the metric scores by a large margin, in contrast to limited gain when training with smoothed BLEU. The human evaluation shows that models trained with BLEURT improve adequacy and coverage of translations. Code is available via this https URL.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "7412686",
                        "name": "Raphael Shu"
                    },
                    {
                        "authorId": "31760501",
                        "name": "Kang Min Yoo"
                    },
                    {
                        "authorId": "2577039",
                        "name": "Jung-Woo Ha"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "18d10374dd0983816831e68bc05708c2c879e5ee",
                "externalIds": {
                    "DBLP": "journals/pami/YangWLX22",
                    "MAG": "3159759441",
                    "DOI": "10.1109/TPAMI.2021.3132021",
                    "CorpusId": 235499248,
                    "PubMed": "34860647"
                },
                "corpusId": 235499248,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/18d10374dd0983816831e68bc05708c2c879e5ee",
                "title": "Bridging the Gap Between Few-Shot and Many-Shot Learning via Distribution Calibration",
                "abstract": "A major gap between few-shot and many-shot learning is the data distribution empirically oserved by the model during training. In few-shot learning, the learned model can easily become over-fitted based on the biased distribution formed by only a few training examples, while the ground-truth data distribution is more accurately uncovered in many-shot learning to learn a well-generalized model. In this paper, we propose to calibrate the distribution of these few-sample classes to be more unbiased to alleviate such an over-fitting problem. The distribution calibration is achieved by transferring statistics from the classes with sufficient examples to those few-sample classes. After calibration, an adequate number of examples can be sampled from the calibrated distribution to expand the inputs to the classifier. Specifically, we assume every dimension in the feature representation from the same class follows a Gaussian distribution so that the mean and the variance of the distribution can borrow from that of similar classes whose statistics are better estimated with an adequate number of samples. Extensive experiments on three datasets, miniImageNet, tieredImageNet, and CUB, show that a simple linear classifier trained using the features sampled from our calibrated distribution can outperform the state-of-the-art accuracy by a large margin. Besides the favorable performance, the proposed method also exhibits high flexibility by showing consistent accuracy improvement when it is built on top of any off-the-shelf pretrained feature extractors and classification models without extra learnable parameters. The visualization of these generated features demonstrates that our calibrated distribution is an accurate estimation thus the generalization ability gain is convincing. We also establish a generalization error bound for the proposed distribution-calibration-based few-shot learning, which consists of the distribution assumption error, the distribution approximation error, and the estimation error. This generalization error bound theoretically justifies the effectiveness of the proposed method.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2131876172",
                        "name": "Shuo Yang"
                    },
                    {
                        "authorId": "4206933",
                        "name": "Songhua Wu"
                    },
                    {
                        "authorId": "121698214",
                        "name": "Tongliang Liu"
                    },
                    {
                        "authorId": "2041286121",
                        "name": "Min Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Few-shot learning aims to reduce these demands by training models to recognize completely novel objects from only a few examples [9, 49, 40, 2, 38, 11, 46].",
                "In optimization-based approaches, the model takes many [51, 46, 5] or few [9, 52, 2] gradient steps on the context examples, and the updated model then classifies the target examples."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "26e479f571d6634ae351dd941a6bd483646637e9",
                "externalIds": {
                    "ArXiv": "2104.03841",
                    "DBLP": "journals/corr/abs-2104-03841",
                    "DOI": "10.1109/ICCV48922.2021.01064",
                    "CorpusId": 233181930
                },
                "corpusId": 233181930,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/26e479f571d6634ae351dd941a6bd483646637e9",
                "title": "ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition",
                "abstract": "Object recognition has made great advances in the last decade, but predominately still relies on many high-quality training examples per object category. In contrast, learning new objects from only a few examples could enable many impactful applications from robotics to user personalization. Most few-shot learning research, however, has been driven by benchmark datasets that lack the high variation that these applications will face when deployed in the real-world. To close this gap, we present the ORBIT dataset and benchmark, grounded in the real-world application of teachable object recognizers for people who are blind/low-vision. The dataset contains 3,822 videos of 486 objects recorded by people who are blind/low-vision on their mobile phones. The benchmark reflects a realistic, highly challenging recognition problem, providing a rich playground to drive research in robustness to few-shot, high-variation conditions. We set the benchmark\u2019s first state-of-the-art and show there is massive scope for further innovation, holding the potential to impact a broad range of real-world vision applications including tools for the blind/low-vision community. We release the dataset at https://doi.org/10.25383/city.14294597 and benchmark code at https://github.com/microsoft/ORBIT-Dataset.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3469119",
                        "name": "Daniela Massiceti"
                    },
                    {
                        "authorId": "3378188",
                        "name": "L. Zintgraf"
                    },
                    {
                        "authorId": "46242344",
                        "name": "J. Bronskill"
                    },
                    {
                        "authorId": "3315024",
                        "name": "Lida Theodorou"
                    },
                    {
                        "authorId": "49609808",
                        "name": "Matthew Tobias Harris"
                    },
                    {
                        "authorId": "1722375",
                        "name": "Edward Cutrell"
                    },
                    {
                        "authorId": "121927341",
                        "name": "C. Morrison"
                    },
                    {
                        "authorId": "1380228856",
                        "name": "Katja Hofmann"
                    },
                    {
                        "authorId": "2066549427",
                        "name": "Simone Stumpf"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2016), CIFAR-FS (Bertinetto et al., 2019), FC100 (Oreshkin et al.",
                "Established episodic evaluation benchmarks range in scale and domain diversity from Omniglot (Lake et al., 2015) to mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), FC100 (Oreshkin et al., 2018), and tieredImageNet (Ren et al., 2018)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c6ec56ac2b44221ed2e19ae5259a028269c8624f",
                "externalIds": {
                    "ArXiv": "2104.02638",
                    "DBLP": "journals/corr/abs-2104-02638",
                    "CorpusId": 233033713
                },
                "corpusId": 233033713,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c6ec56ac2b44221ed2e19ae5259a028269c8624f",
                "title": "Comparing Transfer and Meta Learning Approaches on a Unified Few-Shot Classification Benchmark",
                "abstract": "Meta and transfer learning are two successful families of approaches to few-shot learning. Despite highly related goals, state-of-the-art advances in each family are measured largely in isolation of each other. As a result of diverging evaluation norms, a direct or thorough comparison of different approaches is challenging. To bridge this gap, we perform a cross-family study of the best transfer and meta learners on both a large-scale meta-learning benchmark (Meta-Dataset, MD), and a transfer learning benchmark (Visual Task Adaptation Benchmark, VTAB). We find that, on average, large-scale transfer methods (Big Transfer, BiT) outperform competing approaches on MD, even when trained only on ImageNet. In contrast, meta-learning approaches struggle to compete on VTAB when trained and validated on MD. However, BiT is not without limitations, and pushing for scale does not improve performance on highly out-of-distribution MD tasks. In performing this study, we reveal a number of discrepancies in evaluation norms and study some of these in light of the performance gap. We hope that this work facilitates sharing of insights from each community, and accelerates progress on few-shot learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3074927",
                        "name": "Vincent Dumoulin"
                    },
                    {
                        "authorId": "2815290",
                        "name": "N. Houlsby"
                    },
                    {
                        "authorId": "3399348",
                        "name": "Utku Evci"
                    },
                    {
                        "authorId": "2743563",
                        "name": "Xiaohua Zhai"
                    },
                    {
                        "authorId": "2558463",
                        "name": "Ross Goroshin"
                    },
                    {
                        "authorId": "1802148",
                        "name": "S. Gelly"
                    },
                    {
                        "authorId": "1777528",
                        "name": "H. Larochelle"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al.",
                "\u2026approach used both in multi-task learning Argyriou et al. (2008); Caruana (1997); Jacob et al. (2009) and meta-learning Balcan et al. (2019); Bertinetto et al. (2018); Bullins et al. (2019); Denevi et al. (2019b); Finn and Levine (2018); Finn et al. (2019); Maurer (2009); Pentina and\u2026",
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al.",
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al. (2020); Yao et al. (2019) and propose a so-called\u2026",
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al.",
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al.",
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al.",
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al.",
                "Bertinetto et al. (2018); Finn et al. (2017)) and develop more efficient versions of our method, using less expensive algorithms to update the positive matrices, such as the Frank-Wolfe algorithm used in Bullins et al.",
                "In particular it will be valuable to investigate how to predict non-linear conditioning functions (similarly to e.g. Bertinetto et al. (2018); Finn et al. (2017)) and develop more efficient versions of our method, using less expensive algorithms to update the positive matrices, such as the\u2026",
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al. (2020); Yao et al. (2019) and propose a so-called conditional meta-learning approach for meta-learning a representation.",
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al. (2020); Yao et al.",
                "To overcome this issue, in this work, we follow the recent literature on heterogeneous meta-learning Bertinetto et al. (2018); Cai et al. (2020); Denevi et al. (2020); Jerfel et al. (2019); Rusu et al. (2018); Vuorio et al. (2019); Wang et al. (2020); Yao et al. (2019) and propose a so-called conditional meta-learning approach for meta-learning a representation. Our algorithm learns a conditioning function mapping available tasks\u2019 side information into a linear representation that is tuned to that task at hand. Our approach borrows from Denevi et al. (2020), where the authors proposed a conditional meta-learning approach for fine tuning and biased regularization."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "be81223b4c5cb372616c80f727e0ea3ec49f55d9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-16277",
                    "ArXiv": "2103.16277",
                    "CorpusId": 232417411
                },
                "corpusId": 232417411,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/be81223b4c5cb372616c80f727e0ea3ec49f55d9",
                "title": "Conditional Meta-Learning of Linear Representations",
                "abstract": "Standard meta-learning for representation learning aims to find a common representation to be shared across multiple tasks. The effectiveness of these methods is often limited when the nuances of the tasks' distribution cannot be captured by a single representation. In this work we overcome this issue by inferring a conditioning function, mapping the tasks' side information (such as the tasks' training dataset itself) into a representation tailored to the task at hand. We study environments in which our conditional strategy outperforms standard meta-learning, such as those in which tasks can be organized in separate clusters according to the representation they share. We then propose a meta-algorithm capable of leveraging this advantage in practice. In the unconditional setting, our method yields a new estimator enjoying faster learning rates and requiring less hyper-parameters to tune than current state-of-the-art methods. Our results are supported by preliminary experiments.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "40894851",
                        "name": "Giulia Denevi"
                    },
                    {
                        "authorId": "1704699",
                        "name": "M. Pontil"
                    },
                    {
                        "authorId": "7666146",
                        "name": "C. Ciliberto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Existing few-shot learning methods based on data augmentation [11], [12], [13], metric learning [14], [15], [16], and initialization [17], [18], [19] ameliorate the models in terms of supervised empirical growth, hypothesis space reduction, and initial parameter setting, respectively, so as to enhance the generalization ability of the models under the premise of inadequate training data."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dd3a59227dbc55273edaed0a9f0de7105c5f8ef6",
                "externalIds": {
                    "ArXiv": "2103.13733",
                    "CorpusId": 233301394
                },
                "corpusId": 233301394,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/dd3a59227dbc55273edaed0a9f0de7105c5f8ef6",
                "title": "Spirit Distillation: Precise Real-time Semantic Segmentation of Road Scenes with Insufficient Data",
                "abstract": "Semantic segmentation of road scenes is one of the key technologies for realizing autonomous driving scene perception, and the effectiveness of deep Convolutional Neural Networks(CNNs) for this task has been demonstrated. State-of-art CNNs for semantic segmentation suffer from excessive computations as well as large-scale training data requirement. Inspired by the ideas of Fine-tuning-based Transfer Learning (FTT) and feature-based knowledge distillation, we propose a new knowledge distillation method for cross-domain knowledge transference and efficient data-insufficient network training, named Spirit Distillation(SD), which allow the student network to mimic the teacher network to extract general features, so that a compact and accurate student network can be trained for real-time semantic segmentation of road scenes. Then, in order to further alleviate the trouble of insufficient data and improve the robustness of the student, an Enhanced Spirit Distillation (ESD) method is proposed, which commits to exploit a more comprehensive general features extraction capability by considering images from both the target and the proximity domains as input. To our knowledge, this paper is a pioneering work on the application of knowledge distillation to few-shot learning. Persuasive experiments conducted on Cityscapes semantic segmentation with the prior knowledge transferred from COCO2017 and KITTI demonstrate that our methods can train a better student network (mIOU and high-precision accuracy boost by 1.4% and 8.2% respectively, with 78.2% segmentation variance) with only 41.8% FLOPs (see Fig. 1).",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2146254894",
                        "name": "Zhiyuan Wu"
                    },
                    {
                        "authorId": "2118492219",
                        "name": "Yu Jiang"
                    },
                    {
                        "authorId": "2003576699",
                        "name": "Chupeng Cui"
                    },
                    {
                        "authorId": "2109479351",
                        "name": "Zongmin Yang"
                    },
                    {
                        "authorId": "2003577494",
                        "name": "Xinhui Xue"
                    },
                    {
                        "authorId": "2072590105",
                        "name": "Hong Qi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Specifically, compared with global-level metriclearning based methods (i.e., Relation Networks [6], Prototypical Networks [5] and Fine-tuning [23]), MML is 20.3% and 3.5% better than the best one of them on CIFAR-FS and FC100 under 5-way 5-shot setting.",
                "Table 4 evaluates our method on two CIFAR derivatives, i.e., CIFAR-FS and FC100.",
                "CIFAR derivatives: Both CIFAR-FS [16] dataset and FC100 [17] dataset are subsets of CIFAR-100."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "42eb9ac4cfcd90e933f94cefe6fcfea2d6535a46",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-11383",
                    "ArXiv": "2103.11383",
                    "DOI": "10.1007/978-3-031-15919-0_21",
                    "CorpusId": 232307083
                },
                "corpusId": 232307083,
                "publicationVenue": {
                    "id": "3e64b1c1-745f-4edf-bd92-b8ef122bb49c",
                    "name": "International Conference on Artificial Neural Networks",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Artif Neural Netw",
                        "ICANN"
                    ],
                    "url": "http://www.e-nns.org/"
                },
                "url": "https://www.semanticscholar.org/paper/42eb9ac4cfcd90e933f94cefe6fcfea2d6535a46",
                "title": "Multi-level Metric Learning for Few-shot Image Recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2149050779",
                        "name": "Haoxing Chen"
                    },
                    {
                        "authorId": "1802772",
                        "name": "Huaxiong Li"
                    },
                    {
                        "authorId": "2110973765",
                        "name": "Yaohui Li"
                    },
                    {
                        "authorId": "2109521795",
                        "name": "Chunlin Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "RR-dual-cls [2] develops a closed-form solution of RR in dual space for a more discriminative classifier considering the stepwise optimization negates the chances of the model reaching its optimal.",
                "Following the state-of-the-art approaches in FSL, the optimization-based few-shot learners can be implemented as either as a stepwise gradient descender (GD) [15, 37] or a differentiable quadratic programming (QP) solver [24, 2], which can be further inserted into network as a layer enabling an end-to-end training with feature extractor."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2c7bd36a1247c2200f448a711ffea77c647149c4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-10130",
                    "ArXiv": "2103.10130",
                    "CorpusId": 232270027
                },
                "corpusId": 232270027,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2c7bd36a1247c2200f448a711ffea77c647149c4",
                "title": "Real-Time Visual Object Tracking via Few-Shot Learning",
                "abstract": "Visual Object Tracking (VOT) can be seen as an extended task of Few-Shot Learning (FSL). While the concept of FSL is not new in tracking and has been previously applied by prior works, most of them are tailored to fit specific types of FSL algorithms and may sacrifice running speed. In this work, we propose a generalized two-stage framework that is capable of employing a large variety of FSL algorithms while presenting faster adaptation speed. The first stage uses a Siamese Regional Proposal Network to efficiently propose the potential candidates and the second stage reformulates the task of classifying these candidates to a few-shot classification problem. Following such a coarse-to-fine pipeline, the first stage proposes informative sparse samples for the second stage, where a large variety of FSL algorithms can be conducted more conveniently and efficiently. As substantiation of the second stage, we systematically investigate several forms of optimization-based few-shot learners from previous works with different objective functions, optimization methods, or solution space. Beyond that, our framework also entails a direct application of the majority of other FSL algorithms to visual tracking, enabling mutual communication between researchers on these two topics. Extensive experiments on the major benchmarks, VOT2018, OTB2015, NFS, UAV123, TrackingNet, and GOT-10k are conducted, demonstrating a desirable performance gain and a real-time speed.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "49640591",
                        "name": "Jinghao Zhou"
                    },
                    {
                        "authorId": "71788673",
                        "name": "Bo Li"
                    },
                    {
                        "authorId": "2155300848",
                        "name": "Peng Wang"
                    },
                    {
                        "authorId": "35391826",
                        "name": "Peixia Li"
                    },
                    {
                        "authorId": "35893447",
                        "name": "Weihao Gan"
                    },
                    {
                        "authorId": "145717875",
                        "name": "Wei Wu"
                    },
                    {
                        "authorId": "1721677",
                        "name": "Junjie Yan"
                    },
                    {
                        "authorId": "3001348",
                        "name": "Wanli Ouyang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "06983a454b3ea2926db94bb98f5493c8a0c024d6",
                "externalIds": {
                    "DBLP": "conf/aaai/CiobaBWNBGSB22",
                    "ArXiv": "2103.08463",
                    "DOI": "10.1609/aaai.v36i6.20590",
                    "CorpusId": 232233157
                },
                "corpusId": 232233157,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/06983a454b3ea2926db94bb98f5493c8a0c024d6",
                "title": "How to distribute data across tasks for meta-learning?",
                "abstract": "Meta-learning models transfer the knowledge acquired from previous tasks to quickly learn new ones. They are trained on benchmarks with a fixed number of data points per task. This number is usually arbitrary and it is unknown how it affects performance at testing. Since labelling of data is expensive, finding the optimal allocation of labels across training tasks may reduce costs. Given a fixed budget of labels, should we use a small number of highly labelled tasks, or many tasks with few labels each? Should we allocate more labels to some tasks and less to others?\nWe show that: 1) If tasks are homogeneous, there is a uniform optimal allocation, whereby all tasks get the same amount of data; 2) At fixed budget, there is a trade-off between number of tasks and number of data points per task, with a unique solution for the optimum; 3) When trained separately, harder task should get more data, at the cost of a smaller number of tasks; 4) When training on a mixture of easy and hard tasks, more data should be allocated to easy tasks. Interestingly, Neuroscience experiments have shown that human visual skills also transfer better from easy tasks. We prove these results mathematically on mixed linear regression, and we show empirically that the same results hold for few-shot image classification on CIFAR-FS and mini-ImageNet. Our results provide guidance for allocating labels across tasks when collecting data for meta-learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "102297302",
                        "name": "Alexandru Cioba"
                    },
                    {
                        "authorId": "32789262",
                        "name": "Michael Bromberg"
                    },
                    {
                        "authorId": "2183687933",
                        "name": "Qian Wang"
                    },
                    {
                        "authorId": "32402493",
                        "name": "R. Niyogi"
                    },
                    {
                        "authorId": "2053819384",
                        "name": "Georgios Batzolis"
                    },
                    {
                        "authorId": "2027686",
                        "name": "D. Shiu"
                    },
                    {
                        "authorId": "1872208",
                        "name": "A. Bernacchia"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "51f5b13da6cccd4ab00231a03e2e82f29aff953f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-04490",
                    "ArXiv": "2103.04490",
                    "DOI": "10.15607/RSS.2021.XVII.056",
                    "CorpusId": 232147745
                },
                "corpusId": 232147745,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/51f5b13da6cccd4ab00231a03e2e82f29aff953f",
                "title": "Adaptive-Control-Oriented Meta-Learning for Nonlinear Systems",
                "abstract": "Real-time adaptation is imperative to the control of robots operating in complex, dynamic environments. Adaptive control laws can endow even nonlinear systems with good trajectory tracking performance, provided that any uncertain dynamics terms are linearly parameterizable with known nonlinear features. However, it is often difficult to specify such features a priori, such as for aerodynamic disturbances on rotorcraft or interaction forces between a manipulator arm and various objects. In this paper, we turn to data-driven modeling with neural networks to learn, offline from past data, an adaptive controller with an internal parametric model of these nonlinear features. Our key insight is that we can better prepare the controller for deployment with control-oriented meta-learning of features in closed-loop simulation, rather than regression-oriented meta-learning of features to fit input-output data. Specifically, we meta-learn the adaptive controller with closed-loop tracking simulation as the base-learner and the average tracking error as the meta-objective. With a nonlinear planar rotorcraft subject to wind, we demonstrate that our adaptive controller outperforms other controllers trained with regression-oriented meta-learning when deployed in closed-loop for trajectory tracking control.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "51219725",
                        "name": "Spencer M. Richards"
                    },
                    {
                        "authorId": "2082417",
                        "name": "Navid Azizan"
                    },
                    {
                        "authorId": "1740591",
                        "name": "J. Slotine"
                    },
                    {
                        "authorId": "1696085",
                        "name": "M. Pavone"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e602ce17a993d33d114381be4dc54e7c19d01bce",
                "externalIds": {
                    "ArXiv": "2103.03571",
                    "DBLP": "conf/nips/LiuWL21",
                    "CorpusId": 232135262
                },
                "corpusId": 232135262,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/e602ce17a993d33d114381be4dc54e7c19d01bce",
                "title": "Cycle Self-Training for Domain Adaptation",
                "abstract": "Mainstream approaches for unsupervised domain adaptation (UDA) learn domain-invariant representations to narrow the domain shift. Recently, self-training has been gaining momentum in UDA, which exploits unlabeled target data by training with target pseudo-labels. However, as corroborated in this work, under distributional shift in UDA, the pseudo-labels can be unreliable in terms of their large discrepancy from target ground truth. Thereby, we propose Cycle Self-Training (CST), a principled self-training algorithm that explicitly enforces pseudo-labels to generalize across domains. CST cycles between a forward step and a reverse step until convergence. In the forward step, CST generates target pseudo-labels with a source-trained classifier. In the reverse step, CST trains a target classifier using target pseudo-labels, and then updates the shared representations to make the target classifier perform well on the source data. We introduce the Tsallis entropy as a confidence-friendly regularization to improve the quality of target pseudo-labels. We analyze CST theoretically under realistic assumptions, and provide hard cases where CST recovers target ground truth, while both invariant feature learning and vanilla self-training fail. Empirical results indicate that CST significantly improves over the state-of-the-arts on visual recognition and sentiment analysis benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118903632",
                        "name": "Hong Liu"
                    },
                    {
                        "authorId": "2144499343",
                        "name": "Jianmin Wang"
                    },
                    {
                        "authorId": "35776445",
                        "name": "Mingsheng Long"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For CIFAR-FS, FC100, miniImageNet, tieredImageNet datasets we set the initial learning rate to 0.05 and use a weight decay of 5e \u2212 4.",
                "Two of these datasets are subset of the CIFAR100 dataset: CIFAR-FS [4] and FC100 [50].",
                "Implementation Details: Following [72, 46, 50, 40], we use a ResNet-12 network as our base learner to conduct experiments on CIFAR-FS, FC100, miniImageNet, tieredImageNet datasets.",
                "Effect of the number of Transformations: To investigate the effect of the total number of applied transformations, we perform an ablation study on the CIFAR-FS validation set by varying the number of transformations, M .",
                "However, unlike [15], which achieves the current best results on the CIFAR-FS 1-shot task, we do not perform any transductive fine-tuning.",
                "To be more specific, our method outperforms the current best results on CIFAR-FS dataset (Table 1) by 1.3% in the 1-\nshot task whereas for the 5-shot task it improves the score by 2.8%.",
                "To study the contribution of different components of our method we do a thorough ablation study on three bench-\nmark FSL datasets: miniImageNet, CIFAR-FS, and FC100 (Table 6)."
            ],
            "intents": [],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "04733e633493d5adc31f5f507ebf54a5e509fae4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-01315",
                    "ArXiv": "2103.01315",
                    "DOI": "10.1109/CVPR46437.2021.01069",
                    "CorpusId": 232092147
                },
                "corpusId": 232092147,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/04733e633493d5adc31f5f507ebf54a5e509fae4",
                "title": "Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning",
                "abstract": "In many real-world problems, collecting a large number of labeled samples is infeasible. Few-shot learning (FSL) is the dominant approach to address this issue, where the objective is to quickly adapt to novel categories in presence of a limited number of samples. FSL tasks have been predominantly solved by leveraging the ideas from gradient-based meta-learning and metric learning approaches. However, recent works have demonstrated the significance of powerful feature representations with a simple embedding network that can outperform existing sophisticated FSL algorithms. In this work, we build on this insight and propose a novel training mechanism that simultaneously enforces equivariance and invariance to a general set of geometric transformations. Equivariance or invariance has been employed standalone in the previous works; however, to the best of our knowledge, they have not been used jointly. Simultaneous optimization for both of these contrasting objectives allows the model to jointly learn features that are not only independent of the input transformation but also the features that encode the structure of geometric transformations. These complementary sets of features help generalize well to novel classes with only a few data samples. We achieve additional improvements by incorporating a novel self-supervised distillation objective. Our extensive experimentation shows that even without knowledge distillation our proposed method can outperform current state-of-the-art FSL methods on five popular benchmark datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "9247631",
                        "name": "Mamshad Nayeem Rizve"
                    },
                    {
                        "authorId": "152973423",
                        "name": "Salman Hameed Khan"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "145103012",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Ridge regression differentiable discriminator [9] and meta-learning with differentiable convex optimization [45] find a global optimum linear projection for quick adaptation in meta-learning, although they consider classification tasks, and solves a linear",
                "R2D2 was ridge regression differentiable discriminators [9].",
                "least square problem [9] or a convex optimization problem [45]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "324319f3abef56e84f7a7fad7a42edce509eb34a",
                "externalIds": {
                    "ArXiv": "2103.00684",
                    "DBLP": "journals/corr/abs-2103-00684",
                    "CorpusId": 232076433
                },
                "corpusId": 232076433,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/324319f3abef56e84f7a7fad7a42edce509eb34a",
                "title": "Meta-learning One-class Classifiers with Eigenvalue Solvers for Supervised Anomaly Detection",
                "abstract": "Neural network-based anomaly detection methods have shown to achieve high performance. However, they require a large amount of training data for each task. We propose a neural network-based meta-learning method for supervised anomaly detection. The proposed method improves the anomaly detection performance on unseen tasks, which contains a few labeled normal and anomalous instances, by meta-training with various datasets. With a meta-learning framework, quick adaptation to each task and its effective backpropagation are important since the model is trained by the adaptation for each epoch. Our model enables them by formulating adaptation as a generalized eigenvalue problem with one-class classification; its global optimum solution is obtained, and the solver is differentiable. We experimentally demonstrate that the proposed method achieves better performance than existing anomaly detection and few-shot learning methods on various datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2664600",
                        "name": "Tomoharu Iwata"
                    },
                    {
                        "authorId": "3370561",
                        "name": "Atsutoshi Kumagai"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The contrasted ones include MAML [16], Matching networks [60], IMP [1], Prototypical networks [54], TAML [26], SAML [19], GCR [34], KTN (Visual) [46], PARN [61], Dynamic few-shot [17], Relation networks [56], R2D2 [4], SNAIL [40] and AdaResNet [42]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "542b8dd71309cc001082b152598f40674ec32c01",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-12205",
                    "ArXiv": "2102.12205",
                    "CorpusId": 232035558
                },
                "corpusId": 232035558,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/542b8dd71309cc001082b152598f40674ec32c01",
                "title": "Enabling the Network to Surf the Internet",
                "abstract": "Few-shot learning is challenging due to the limited data and labels. Existing algorithms usually resolve this problem by pre-training the model with a considerable amount of annotated data which shares knowledge with the target domain. Nevertheless, large quantities of homogenous data samples are not always available. To tackle this issue, we develop a framework that enables the model to surf the Internet, which implies that the model can collect and annotate data without manual effort. Since the online data is virtually limitless and continues to be generated, the model can thus be empowered to constantly obtain up-to-date knowledge from the Internet. Additionally, we observe that the generalization ability of the learned representation is crucial for self-supervised learning. To present its importance, a naive yet efficient normalization strategy is proposed. Consequentially, this strategy boosts the accuracy of the model significantly (20.46% at most). We demonstrate the superiority of the proposed framework with experiments on miniImageNet, tieredImageNet and Omniglot. The results indicate that our method has surpassed previous unsupervised counterparts by a large margin (more than 10%) and obtained performance comparable with the supervised ones.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118390512",
                        "name": "Zhuoling Li"
                    },
                    {
                        "authorId": "49528192",
                        "name": "Haohan Wang"
                    },
                    {
                        "authorId": "2051501958",
                        "name": "Tymoteusz \u015awistek"
                    },
                    {
                        "authorId": "2108947078",
                        "name": "Weixin Chen"
                    },
                    {
                        "authorId": "2167749913",
                        "name": "Yuanzhen Li"
                    },
                    {
                        "authorId": "2143410777",
                        "name": "Haoqian Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In particular, for the cifar-M and FC-M datasets, the ValGen ranking of algorithm snapshots seems to be only weakly correlated with the true meta-test ranking for all the meta-learning methods.",
                "(miniImageNet, CIFAR-FS, FC-100), only 20 novel classes are used for meta-testing.",
                "Here the original 600 examples of each base class are still only used for meta-training. ii) CIFAR-FS-Mod (cifar-M) [30], FC-100-Mod (FC-M) [4], and tieredImageNet-Mod (tiered-M) [33]: As we don\u2019t have additional samples for base classes, we randomly partition each base class\u2019s current examples into an approximate 80/20 split where the training tasks are constructed using the former and the latter is reserved for ID evaluation.",
                "ii) CIFAR-FS-Mod (cifar-M) [30], FC-100-Mod (FC-M) [4], and tieredImageNet-Mod (tiered-M) [33]: As we don\u2019t have additional samples for base classes, we randomly partition each base class\u2019s current examples into an approximate 80/20 split where the training tasks are constructed using the former and the latter is reserved for ID evaluation.",
                "A plethora of few-shot image classification benchmarks (e.g., miniImageNet (mini in short) [42], CIFAR-FS [4]) have been developed for FSL evaluation.",
                ", miniImageNet (mini in short) [42], CIFAR-FS [4]) have been developed for FSL evaluation.",
                "We evaluate the ID performance of four popular meta-learning methods: Prototypical Networks (PN) [39], MetaOptNet-SVM (SVM) [25], MetaOptNet-Ridge Regression (RR) [25, 4] and FOMAML [15] on our identified ID FSL benchmarks (Table 1).",
                "Another issue that may cause some to view the current FSL benchmarks as performing ID evaluation is that in some of these benchmarks, the base, val, novel classes are random partitions of iid drawn classes from a class level distribution (specifically miniImageNet, CIFAR-FS; but not FC-100, tieredImageNet as the classes are not partitioned randomly).",
                "Based on these two trends, for more reliable comparisons of meta-learning methods\u2019 OOD performance we suggest using datasets like tieredImageNet and MetaDataset (both with much larger set of base and novel classes) in addition to the smaller benchmarks like miniImageNet, CIFAR-FS, and FC-100, which some recent works [e.g., 30, 4] still solely rely upon.",
                "In practice, because 1) we never specify exactly what and how big the underlying set of classes that we care about is, and 2) some of the recent meta-learning methods (SVM vs PN on cifar in Table 2 of [25], R2-D2 vs GNN on mini in Table 1 of [4], FIX-ML [38]) sometimes only improve over the prior works by < 1%, we believe researchers should be aware of the possibility of getting a performance conclusion that is inconsistent over a single randomly chosen and fixed set of 20 novel classes used by some of these benchmarks."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "64e0fdebd4a396ec2c46c56f9c58d11c6ad991ce",
                "externalIds": {
                    "ArXiv": "2102.11503",
                    "DBLP": "conf/nips/SetlurLS21",
                    "CorpusId": 235658024
                },
                "corpusId": 235658024,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/64e0fdebd4a396ec2c46c56f9c58d11c6ad991ce",
                "title": "Two Sides of Meta-Learning Evaluation: In vs. Out of Distribution",
                "abstract": "We categorize meta-learning evaluation into two settings: $\\textit{in-distribution}$ [ID], in which the train and test tasks are sampled $\\textit{iid}$ from the same underlying task distribution, and $\\textit{out-of-distribution}$ [OOD], in which they are not. While most meta-learning theory and some FSL applications follow the ID setting, we identify that most existing few-shot classification benchmarks instead reflect OOD evaluation, as they use disjoint sets of train (base) and test (novel) classes for task generation. This discrepancy is problematic because -- as we show on numerous benchmarks -- meta-learning methods that perform better on existing OOD datasets may perform significantly worse in the ID setting. In addition, in the OOD setting, even though current FSL benchmarks seem befitting, our study highlights concerns in 1) reliably performing model selection for a given meta-learning method, and 2) consistently comparing the performance of different methods. To address these concerns, we provide suggestions on how to construct FSL benchmarks to allow for ID evaluation as well as more reliable OOD evaluation. Our work aims to inform the meta-learning community about the importance and distinction of ID vs. OOD evaluation, as well as the subtleties of OOD evaluation with current benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "80366270",
                        "name": "Amrith Rajagopal Setlur"
                    },
                    {
                        "authorId": "33282601",
                        "name": "Oscar Li"
                    },
                    {
                        "authorId": "145260024",
                        "name": "Virginia Smith"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "87174a4df7567e52771d15f949d459791145379b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-11544",
                    "ArXiv": "2102.11544",
                    "CorpusId": 232013963
                },
                "corpusId": 232013963,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/87174a4df7567e52771d15f949d459791145379b",
                "title": "Identifying Physical Law of Hamiltonian Systems via Meta-Learning",
                "abstract": "Hamiltonian mechanics is an effective tool to represent many physical processes with concise yet well-generalized mathematical expressions. A well-modeled Hamiltonian makes it easy for researchers to analyze and forecast many related phenomena that are governed by the same physical law. However, in general, identifying a functional or shared expression of the Hamiltonian is very difficult. It requires carefully designed experiments and the researcher's insight that comes from years of experience. We propose that meta-learning algorithms can be potentially powerful data-driven tools for identifying the physical law governing Hamiltonian systems without any mathematical assumptions on the representation, but with observations from a set of systems governed by the same physical law. We show that a well meta-trained learner can identify the shared representation of the Hamiltonian by evaluating our method on several types of physical systems with various experimental settings.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2108154935",
                        "name": "Seungjun Lee"
                    },
                    {
                        "authorId": "11325568",
                        "name": "Haesang Yang"
                    },
                    {
                        "authorId": "2517631",
                        "name": "W. Seong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We also test our proposed methods on CIFAR-FS (Bertinetto et al., 2018), which is an image classification dataset containing 64 classes of training data and 20 classes of evaluation data.",
                "We also test our methods on CIFAR-FS (Bertinetto et al., 2018) and Omniglot (Lake et al., 2015), and provide the results in Table 5 and Figure S3, respectively (more details can be viewed in Appendix 6 and Appendix 7).",
                "Table S2: SA/RA performance of our proposed methods on CIFAR-FS (Bertinetto et al., 2018) (1-Shot 5-",
                "There are 1028 classes of training data and 423 classes of evaluation\nTable S3: SA/RA performance of our proposed methods on CIFAR-FS (Bertinetto et al., 2018) (5-Shot 5-",
                "We also test our methods on CIFAR-FS (Bertinetto et al., 2018) and Omniglot (Lake et al.",
                "Table 5: SA/RA performance of our proposed methods on CIFAR-FS (Bertinetto et al., 2018)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "118a605ad954c8f8e1ad65941429d0fd2c14c918",
                "externalIds": {
                    "DBLP": "conf/iclr/0008X0CWGW21",
                    "ArXiv": "2102.10454",
                    "CorpusId": 231985673
                },
                "corpusId": 231985673,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/118a605ad954c8f8e1ad65941429d0fd2c14c918",
                "title": "On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning",
                "abstract": "Model-agnostic meta-learning (MAML) has emerged as one of the most successful meta-learning techniques in few-shot learning. It enables us to learn a meta-initialization} of model parameters (that we call meta-model) to rapidly adapt to new tasks using a small amount of labeled training data. Despite the generalization power of the meta-model, it remains elusive that how adversarial robustness can be maintained by MAML in few-shot learning. In addition to generalization, robustness is also desired for a meta-model to defend adversarial examples (attacks). Toward promoting adversarial robustness in MAML, we first study WHEN a robustness-promoting regularization should be incorporated, given the fact that MAML adopts a bi-level (fine-tuning vs. meta-update) learning procedure. We show that robustifying the meta-update stage is sufficient to make robustness adapted to the task-specific fine-tuning stage even if the latter uses a standard training protocol. We also make additional justification on the acquired robustness adaptation by peering into the interpretability of neurons' activation maps. Furthermore, we investigate HOW robust regularization can efficiently be designed in MAML. We propose a general but easily-optimized robustness-regularized meta-learning framework, which allows the use of unlabeled data augmentation, fast adversarial attack generation, and computationally-light fine-tuning. In particular, we for the first time show that the auxiliary contrastive learning task can enhance the adversarial robustness of MAML. Finally, extensive experiments are conducted to demonstrate the effectiveness of our proposed methods in robust few-shot learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "153537425",
                        "name": "Ren Wang"
                    },
                    {
                        "authorId": "46321210",
                        "name": "Kaidi Xu"
                    },
                    {
                        "authorId": "143743061",
                        "name": "Sijia Liu"
                    },
                    {
                        "authorId": "153191489",
                        "name": "Pin-Yu Chen"
                    },
                    {
                        "authorId": "27836724",
                        "name": "Tsui-Wei Weng"
                    },
                    {
                        "authorId": "144158271",
                        "name": "Chuang Gan"
                    },
                    {
                        "authorId": "2146059787",
                        "name": "Meng Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(15) as the nonconformity measure for label y = j.\nDifferentiable ridge regression (Bertinetto et al., 2019).",
                "Our meta nonconformity measure consists of a few-shot, closed-form ridge regressor (Bertinetto et al., 2019) on top of a directed Message Passing Network molecular encoder (Yang et al., 2019).5",
                "\u2026a popular approach to transferring knowledge gained from auxiliary tasks\u2014e.g., via featurizations or statistics (Edwards & Storkey, 2017)\u2014 to a target task that is otherwise resource-limited (Vinyals et al., 2016; Finn et al., 2017; Snell et al., 2017; Bertinetto et al., 2019; Bao et al., 2020).",
                ", via featurizations or statistics (Edwards & Storkey, 2017)\u2014 to a target task that is otherwise resource-limited (Vinyals et al., 2016; Finn et al., 2017; Snell et al., 2017; Bertinetto et al., 2019; Bao et al., 2020).",
                "Our meta nonconformity measure consists of a few-shot, closed-form ridge regressor (Bertinetto et al., 2019) on top of a directed Message Passing Network molecular encoder (Yang et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "36a2c27ffa72c05c2a17dc90b7c54e492b88ba01",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-08898",
                    "ArXiv": "2102.08898",
                    "CorpusId": 231942682
                },
                "corpusId": 231942682,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/36a2c27ffa72c05c2a17dc90b7c54e492b88ba01",
                "title": "Few-shot Conformal Prediction with Auxiliary Tasks",
                "abstract": "We develop a novel approach to conformal prediction when the target task has limited data available for training. Conformal prediction identifies a small set of promising output candidates in place of a single prediction, with guarantees that the set contains the correct answer with high probability. When training data is limited, however, the predicted set can easily become unusably large. In this work, we obtain substantially tighter prediction sets while maintaining desirable marginal guarantees by casting conformal prediction as a meta-learning paradigm over exchangeable collections of auxiliary tasks. Our conformalization algorithm is simple, fast, and agnostic to the choice of underlying model, learning algorithm, or dataset. We demonstrate the effectiveness of this approach across a number of few-shot classification and regression tasks in natural language processing, computer vision, and computational chemistry for drug discovery.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2064150446",
                        "name": "Adam Fisch"
                    },
                    {
                        "authorId": "32303439",
                        "name": "Tal Schuster"
                    },
                    {
                        "authorId": "35132120",
                        "name": "T. Jaakkola"
                    },
                    {
                        "authorId": "1741283",
                        "name": "R. Barzilay"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The former learns a generative metric to compare andmatch few-examples [2, 25, 28]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "eb8dba325534da472170293b054596a17558c7f2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-07916",
                    "ArXiv": "2102.07916",
                    "DOI": "10.1145/3442381.3450112",
                    "CorpusId": 231933868
                },
                "corpusId": 231933868,
                "publicationVenue": {
                    "id": "e07422f9-c065-40c3-a37b-75e98dce79fe",
                    "name": "The Web Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Web Conf",
                        "WWW"
                    ],
                    "url": "http://www.iw3c2.org/"
                },
                "url": "https://www.semanticscholar.org/paper/eb8dba325534da472170293b054596a17558c7f2",
                "title": "Few-Shot Graph Learning for Molecular Property Prediction",
                "abstract": "The recent success of graph neural networks has significantly boosted molecular property prediction, advancing activities such as drug discovery. The existing deep neural network methods usually require large training dataset for each property, impairing their performance in cases (especially for new molecular properties) with a limited amount of experimental data, which are common in real situations. To this end, we propose Meta-MGNN, a novel model for few-shot molecular property prediction. Meta-MGNN applies molecular graph neural network to learn molecular representations and builds a meta-learning framework for model optimization. To exploit unlabeled molecular information and address task heterogeneity of different molecular properties, Meta-MGNN further incorporates molecular structures, attribute based self-supervised modules and self-attentive task weights into the former framework, strengthening the whole learning model. Extensive experiments on two public multi-property datasets demonstrate that Meta-MGNN outperforms a variety of state-of-the-art methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109411071",
                        "name": "Zhichun Guo"
                    },
                    {
                        "authorId": "2117879943",
                        "name": "Chuxu Zhang"
                    },
                    {
                        "authorId": "38767143",
                        "name": "W. Yu"
                    },
                    {
                        "authorId": "5995871",
                        "name": "John E. Herr"
                    },
                    {
                        "authorId": "3222580",
                        "name": "O. Wiest"
                    },
                    {
                        "authorId": "1470716407",
                        "name": "Meng Jiang"
                    },
                    {
                        "authorId": "144539424",
                        "name": "N. Chawla"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The performance of the stated methods was measured based on standardised few-shot classification datasets CIFAR-FS (Bertinetto et al. 2019) and CUB (Wah et al. 2011)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "20ff1d1029ad2fea91d30984f91f86604a2cef34",
                "externalIds": {
                    "ArXiv": "2102.05176",
                    "DBLP": "journals/corr/abs-2102-05176",
                    "CorpusId": 231861477
                },
                "corpusId": 231861477,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/20ff1d1029ad2fea91d30984f91f86604a2cef34",
                "title": "Transfer learning based few-shot classification using optimal transport mapping from preprocessed latent space of backbone neural network",
                "abstract": "MetaDL Challenge 2020 focused on image classification tasks in few-shot settings. This paper describes second best submission in the competition. Our meta learning approach modifies the distribution of classes in a latent space produced by a backbone network for each class in order to better follow the Gaussian distribution. After this operation which we call Latent Space Transform algorithm, centers of classes are further aligned in an iterative fashion of the Expectation Maximisation algorithm to utilize information in unlabeled data that are often provided on top of few labelled instances. For this task, we utilize optimal transport mapping using the Sinkhorn algorithm. Our experiments show that this approach outperforms previous works as well as other variants of the algorithm, using K-Nearest Neighbour algorithm, Gaussian Mixture Models, etc.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1588690660",
                        "name": "Tom\u00e1s Chobola"
                    },
                    {
                        "authorId": "103252878",
                        "name": "Daniel Vasata"
                    },
                    {
                        "authorId": "2509371",
                        "name": "P. Kord\u00edk"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Note that the above quadratic subclass also covers a large collection of applications such as few-shot meta-learning with shared embedding model (Bertinetto et al., 2018) and biased regularization in hyperparameter optimization (Grazzi et al.",
                "\u2026y) \u2261 H, \u2207x\u2207yg(x, y) \u2261 J, \u2200x \u2208 X , y \u2208 Rd. (4)\nThe condition of g(x, y) in Assumption 2 covers a large collection of applications such as few-shot metalearning (Bertinetto et al., 2018) and biased regularization in hyperparameter optimization (Grazzi et al., 2020), where the inner-level problem\u2026"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "51ac8296b14d2563b718561059afc1532c3c4657",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-03926",
                    "ArXiv": "2102.03926",
                    "CorpusId": 231846549
                },
                "corpusId": 231846549,
                "publicationVenue": {
                    "id": "c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                    "name": "Journal of machine learning research",
                    "type": "journal",
                    "alternate_names": [
                        "Journal of Machine Learning Research",
                        "J mach learn res",
                        "J Mach Learn Res"
                    ],
                    "issn": "1532-4435",
                    "alternate_issns": [
                        "1533-7928"
                    ],
                    "url": "http://www.ai.mit.edu/projects/jmlr/",
                    "alternate_urls": [
                        "http://jmlr.csail.mit.edu/",
                        "http://www.jmlr.org/",
                        "http://portal.acm.org/affiliated/jmlr"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/51ac8296b14d2563b718561059afc1532c3c4657",
                "title": "Lower Bounds and Accelerated Algorithms for Bilevel Optimization",
                "abstract": "Bilevel optimization has recently attracted growing interests due to its wide applications in modern machine learning problems. Although recent studies have characterized the convergence rate for several such popular algorithms, it is still unclear how much further these convergence rates can be improved. In this paper, we address this fundamental question from two perspectives. First, we provide the first-known lower complexity bounds of $\\widetilde{\\Omega}(\\frac{1}{\\sqrt{\\mu_x}\\mu_y})$ and $\\widetilde \\Omega\\big(\\frac{1}{\\sqrt{\\epsilon}}\\min\\{\\frac{1}{\\mu_y},\\frac{1}{\\sqrt{\\epsilon^{3}}}\\}\\big)$ respectively for strongly-convex-strongly-convex and convex-strongly-convex bilevel optimizations. Second, we propose an accelerated bilevel optimizer named AccBiO, for which we provide the first-known complexity bounds without the gradient boundedness assumption (which was made in existing analyses) under the two aforementioned geometries. We also provide significantly tighter upper bounds than the existing complexity when the bounded gradient assumption does hold. We show that AccBiO achieves the optimal results (i.e., the upper and lower bounds match up to logarithmic factors) when the inner-level problem takes a quadratic form with a constant-level condition number. Interestingly, our lower bounds under both geometries are larger than the corresponding optimal complexities of minimax optimization, establishing that bilevel optimization is provably more challenging than minimax optimization.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ae031dcdb489ba292de48100f17f91a36b2e92dd",
                "externalIds": {
                    "DBLP": "journals/chinaf/PangZWXG21",
                    "DOI": "10.1007/s11432-020-3055-1",
                    "CorpusId": 231878429
                },
                "corpusId": 231878429,
                "publicationVenue": {
                    "id": "0534c8a0-1226-4f5b-bcf6-a13a8dd1825e",
                    "name": "Science China Information Sciences",
                    "alternate_names": [
                        "Sci China Inf Sci"
                    ],
                    "issn": "1869-1919",
                    "url": "http://info.scichina.com/"
                },
                "url": "https://www.semanticscholar.org/paper/ae031dcdb489ba292de48100f17f91a36b2e92dd",
                "title": "Few-shot text classification by leveraging bi-directional attention and cross-class knowledge",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "144296095",
                        "name": "Ning Pang"
                    },
                    {
                        "authorId": "2116711715",
                        "name": "Xiang Zhao"
                    },
                    {
                        "authorId": null,
                        "name": "Wei WANG"
                    },
                    {
                        "authorId": "153215984",
                        "name": "W. Xiao"
                    },
                    {
                        "authorId": "144233921",
                        "name": "Deke Guo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We also evaluate the effectiveness of illumination feature augmentation on standardized one/few-shot image classification datasets: miniImageNet [18], CUB [19] and CIFAR-FS [20].\nminiImageNet [18] is introduced by Vinyals et al. in [18] for small sample learning research for the first time.",
                "4) Generalized one/few-shot image classification on miniImageNet, CUB and CIFAR-FS\nSince our method requires template images for the separation of features, the model can not be directly trained on natural image datasets without regular templates such as ImageNet.",
                "CIFAR-FS [20] is randomly sampled from CIFAR-100 [21] by using the same criteria with which miniImageNet has been generated.",
                "We also evaluate the effectiveness of illumination feature augmentation on standardized one/few-shot image classification datasets: miniImageNet [18], CUB [19] and CIFAR-FS [20].",
                "To stress the genericity of the illumination repository, we perform experiments on standardized few-shot classification datasets: miniImageNet [18], CUB [19] and CIFAR-FS [20].",
                "3) We evaluate Sill-Net on several object classification benchmarks, i.e., two traffic datasets (GTSRB and TT100K), three logo datasets (Belgalogos, FlickrLogos32, and TopLogo-10) and three generalized one/few-shot benchmarks (miniImageNet, CUB, CIFAR-FS)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "4ca03e8a4dceec1a198f2ae5fd9cffe7fa26f4c4",
                "externalIds": {
                    "ArXiv": "2102.03539",
                    "DBLP": "journals/corr/abs-2102-03539",
                    "CorpusId": 231846995
                },
                "corpusId": 231846995,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4ca03e8a4dceec1a198f2ae5fd9cffe7fa26f4c4",
                "title": "Sill-Net: Feature Augmentation with Separated Illumination Representation",
                "abstract": "\u2014For visual object recognition tasks, the illumination variations can cause distinct changes in object appearance and thus confuse the deep neural network-based recognition models. Especially for some rare illumination conditions, collecting suf\ufb01cient training samples could be time-consuming and expensive. To solve this problem, in this paper we propose a novel neural network architecture called S eparating- Ill umination Net work (Sill-Net). Sill-Net learns to separate illumination features from images, and then we augment training samples with these separated illumination features in the feature space. The model is further trained on the augmented samples to be robust to illumination variations. We provide a fresh perspective to focus on removing the semantic part of images and storing the illumination to the repository for augmentations instead of augmenting the semantic part of features. Extensive experimental results demonstrate that our approach outperforms current state-of-the-art methods on common object classi\ufb01cation benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "5462268",
                        "name": "Hanwang Zhang"
                    },
                    {
                        "authorId": "2113998746",
                        "name": "Zhong Cao"
                    },
                    {
                        "authorId": "3451543",
                        "name": "Ziang Yan"
                    },
                    {
                        "authorId": "14966740",
                        "name": "Changshui Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Our theory applies to regression problems, and assumes a limited number of tasks where data is independently drawn in each task, while some applications use a large number of tasks with correlated draws (for example, images may be shared across tasks in few-shot image classification, see Bertinetto et al. (2019)).",
                "\u2026to regression problems, and assumes a limited number of tasks where data is independently drawn in each task, while some applications use a large number of tasks with correlated draws (for example, images may be shared across tasks in few-shot image classification, see Bertinetto et al. (2019)).",
                "In this context, metalearning received increased attention in the past few years, several new benchmarks have been introduced, and a large number of algorithms and models have been proposed to solve them (Vinyals et al. (2017), Bertinetto et al. (2019), Triantafillou et al. (2020))."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4454a763c891afb3fb8fa6567a367d05b1938e97",
                "externalIds": {
                    "ArXiv": "2102.00940",
                    "DBLP": "journals/corr/abs-2102-00940",
                    "CorpusId": 231740484
                },
                "corpusId": 231740484,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/4454a763c891afb3fb8fa6567a367d05b1938e97",
                "title": "Meta-learning with negative learning rates",
                "abstract": "Deep learning models require a large amount of data to perform well. When data is scarce for a target task, we can transfer the knowledge gained by training on similar tasks to quickly learn the target. A successful approach is meta-learning, or learning to learn a distribution of tasks, where learning is represented by an outer loop, and to learn by an inner loop of gradient descent. However, a number of recent empirical studies argue that the inner loop is unnecessary and more simple models work equally well or even better. We study the performance of MAML as a function of the learning rate of the inner loop, where zero learning rate implies that there is no inner loop. Using random matrix theory and exact solutions of linear models, we calculate an algebraic expression for the test loss of MAML applied to mixed linear regression and nonlinear regression with overparameterized models. Surprisingly, while the optimal learning rate for adaptation is positive, we find that the optimal learning rate for training is always negative, a setting that has never been considered before. Therefore, not only does the performance increase by decreasing the learning rate to zero, as suggested by recent work, but it can be increased even further by decreasing the learning rate to negative values. These results help clarify under what circumstances meta-learning performs best.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1872208",
                        "name": "A. Bernacchia"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Then we evaluate our model and make comparisons to related work on four few-shot classification benchmark datasets: miniImageNet [36], tieredImageNet [29], CIFAR-FS [1], Fewshot-CIFAR100 (FC100) [25].",
                "The CIFAR-FS dataset is a recently proposed few-shot image classification benchmark derived from CIFAR.",
                "We observe that the relative improvement rate on the CIFAR-FS dataset is larger compared to the FC100 dataset which is similar to generalization pattern on the Im-\nageNet derivatives.",
                "Our model achieves comparable performance on all tasks in both CIFAR-FS and FC100 benchmark.",
                "In addition, we also analyze the result of the number of items in the component dictionary D, map dictionary S.\nTable 3 shows the result of our ablation studies on miniImageNet, tieredImageNet, CIFAR-FS and FC100.",
                "Table 2 summarizes the performance on the 5- way CIFAR-FS and FC100."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0f10d0f5355a3f7ce371008e26419172d258bf77",
                "externalIds": {
                    "DBLP": "conf/wacv/HeKY23",
                    "ArXiv": "2101.11878",
                    "DOI": "10.1109/WACV56688.2023.00388",
                    "CorpusId": 254823669
                },
                "corpusId": 254823669,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/0f10d0f5355a3f7ce371008e26419172d258bf77",
                "title": "CORL: Compositional Representation Learning for Few-Shot Classification",
                "abstract": "Few-shot image classification consists of two consecutive learning processes: 1) In the meta-learning stage, the model acquires a knowledge base from a set of training classes. 2) During meta-testing, the acquired knowledge is used to recognize unseen classes from very few examples. Inspired by the compositional representation of objects in humans, we train a neural network architecture that explicitly represents objects as a dictionary of shared components and their spatial composition. In particular, during meta-learning, we train a knowledge base that consists of a dictionary of component representations and a dictionary of component activation maps that encode common spatial activation patterns of components. The elements of both dictionaries are shared among the training classes. During meta-testing, the representation of unseen classes is learned using the component representations and the component activation maps from the knowledge base. Finally, an attention mechanism is used to strengthen those components that are most important for each category. We demonstrate the value of our interpretable compositional learning framework for a few-shot classification using miniImageNet, tieredImageNet, CIFAR-FS, and FC100, where we achieve comparable performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "153146760",
                        "name": "Ju He"
                    },
                    {
                        "authorId": "2780587",
                        "name": "Adam Kortylewski"
                    },
                    {
                        "authorId": "145081362",
                        "name": "A. Yuille"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9d81282187337a4770b3cd2e842dadba329dfdfd",
                "externalIds": {
                    "DBLP": "journals/pami/LiuGZML22",
                    "ArXiv": "2101.11517",
                    "DOI": "10.1109/TPAMI.2021.3132674",
                    "CorpusId": 231718655,
                    "PubMed": "34871167"
                },
                "corpusId": 231718655,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9d81282187337a4770b3cd2e842dadba329dfdfd",
                "title": "Investigating Bi-Level Optimization for Learning and Vision From a Unified Perspective: A Survey and Beyond",
                "abstract": "Bi-Level Optimization (BLO) is originated from the area of economic game theory and then introduced into the optimization community. BLO is able to handle problems with a hierarchical structure, involving two levels of optimization tasks, where one task is nested inside the other. In machine learning and computer vision fields, despite the different motivations and mechanisms, a lot of complex problems, such as hyper-parameter optimization, multi-task and meta learning, neural architecture search, adversarial learning and deep reinforcement learning, actually all contain a series of closely related subproblms. In this paper, we first uniformly express these complex learning and vision problems from the perspective of BLO. Then we construct a best-response-based single-level reformulation and establish a unified algorithmic framework to understand and formulate mainstream gradient-based BLO methodologies, covering aspects ranging from fundamental automatic differentiation schemes to various accelerations, simplifications, extensions and their convergence and complexity properties. Last but not least, we discuss the potentials of our unified BLO framework for designing new algorithms and point out some promising directions for future research. A list of important papers discussed in this survey, corresponding codes, and additional resources on BLOs are publicly available at: https://github.com/vis-opt-group/BLO.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "34469457",
                        "name": "Risheng Liu"
                    },
                    {
                        "authorId": "1400207288",
                        "name": "Jiaxin Gao"
                    },
                    {
                        "authorId": "2108930792",
                        "name": "Jin Zhang"
                    },
                    {
                        "authorId": "1803714",
                        "name": "Deyu Meng"
                    },
                    {
                        "authorId": "33383055",
                        "name": "Zhouchen Lin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Optimization based methods [4, 14, 27] learn representations that lead to generalizable models measured using pre-defined classification model, objective, or a training procedure."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "25e571a8923107bcf764445ac42d3646194841fe",
                "externalIds": {
                    "ArXiv": "2101.11058",
                    "CorpusId": 235593418
                },
                "corpusId": 235593418,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/25e571a8923107bcf764445ac42d3646194841fe",
                "title": "Supervised Momentum Contrastive Learning for Few-Shot Classification",
                "abstract": "Few-shot learning aims to transfer information from one task to enable generalization on novel tasks given a few examples. This information is present both in the domain and the class labels. In this work we investigate the complementary roles of these two sources of information by combining instance-discriminative contrastive learning and supervised learning in a single framework called Supervised Momentum Contrastive learning (SUPMOCO). Our approach avoids a problem observed in supervised learning where information in images not relevant to the task is discarded, which hampers their generalization to novel tasks. We show that (self-supervised) contrastive learning and supervised learning are mutually beneficial, leading to a new state-of-the-art on the META-DATASET - a recently introduced benchmark for few-shot learning. Our method is based on a simple modification of MOCO and scales better than prior work on combining supervised and self-supervised learning. This allows us to easily combine data from multiple domains leading to further improvements.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "134549850",
                        "name": "Orchid Majumder"
                    },
                    {
                        "authorId": "2529423",
                        "name": "Avinash Ravichandran"
                    },
                    {
                        "authorId": "35208858",
                        "name": "Subhransu Maji"
                    },
                    {
                        "authorId": "16163297",
                        "name": "A. Achille"
                    },
                    {
                        "authorId": "32235780",
                        "name": "M. Polito"
                    },
                    {
                        "authorId": "1715959",
                        "name": "Stefano Soatto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Meanwhile, partial experimental results on the CIFAR-FS dataset dropped slightly, the reason of which might lie in the categories in the CIFAR-FS dataset are highly distinguishable.",
                "To evaluate our module, we select two GNN-based few-shot models: EGNN and DPGN, and four standard few-shot learning benchmarks: mini-ImageNet [28], tiered-ImageNet [30], CUB-200-2011 [31] and CIFAR-FS [32].",
                "We conducted extensive experiments on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB-200-2011, and CIFAR-FS.",
                "Experimental results demonstrate that it improves the performance of recently proposed GNNbased methods on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB-200-2011, and CIFAR-FS."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "6659d6b3d72fcd55a3d2a903785af424ba181cbb",
                "externalIds": {
                    "DBLP": "conf/vcip/GuoMLD21",
                    "ArXiv": "2101.09840",
                    "DOI": "10.1109/VCIP53242.2021.9675452",
                    "CorpusId": 237396058
                },
                "corpusId": 237396058,
                "publicationVenue": {
                    "id": "455f9323-a999-47fd-8b0d-5b06b6f519b7",
                    "name": "Visual Communications and Image Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Vis Commun Image Process",
                        "VCIP"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6659d6b3d72fcd55a3d2a903785af424ba181cbb",
                "title": "TLRM: Task-level Relation Module for GNN-based Few-Shot Learning",
                "abstract": "Recently, graph neural networks (GNNs) have shown powerful ability to handle few-shot classification problem, which aims at classifying unseen samples when trained with limited labeled samples per class. GNN-based few-shot learning architectures mostly replace traditional metric with a learnable GNN. In the GNN, the nodes are set as the samples' embedding, and the relationship between two connected nodes can be obtained by a network, the input of which is the difference of their embedding features. We consider this method of measuring relation of samples only models the sample-to-sample relation, while neglects the specificity of different tasks. That is, this method of measuring relation does not take the task-level information into account. To this end, we propose a new relation measure method, namely the task-level relation module (TLRM), to explicitly model the task-level relation of one sample to all the others. The proposed module captures the relation representations between nodes by considering the sample-to-task instead of sample-to-sample embedding features. We conducted extensive experiments on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB-200-2011, and CIFAR-FS. Experimental results demonstrate that the proposed module is effective for GNN-based few-shot learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2124916479",
                        "name": "Yurong Guo"
                    },
                    {
                        "authorId": "1755773",
                        "name": "Zhanyu Ma"
                    },
                    {
                        "authorId": "145074587",
                        "name": "Xiaoxu Li"
                    },
                    {
                        "authorId": "2115460273",
                        "name": "Yuan Dong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Our results on CIFAR-FS (Table 1) and miniImageNet (Table 2) show that, on its own, the rotation prediction pretext task limits the generality of the learned representations, significantly lagging behind in few-shot accuracy.",
                "Initial experimental results showed that BYOL on its own could only achieve 47.09\u00b10.96% accuracy on CIFAR-FS, which is significantly lower than the results reported in Table 1.",
                "On both CIFAR-FS (Table 1) and miniImageNet (Table 2), we find that stronger data augmentation improves the supervised baseline.",
                "As noted in \u00a74.1, we changed the learning schedule for CIFAR-FS but did not do so for miniImageNet.",
                "In this section, we evaluate our proposed multi-task framework on two widely used few-shot image recognition benchmarks: miniImageNet (Vinyals et al., 2016) and CIFAR-FS (Bertinetto et al., 2018).",
                "On CIFAR-FS, we report an accuracy of 82.19\u00b1 0.83% for this run, compared to 82.51\u00b1 0.82% when using \u03c4 = 0.99 on the same seed.",
                "Note that the performance gap between BYOL and the supervised baseline on miniImageNet is bigger than the one observed on CIFAR-FS.",
                "All models are trained for 90 epochs on CIFAR-FS with a decay step at epochs 45, 60 and 75, except when BYOL is used (alone or in combination with other tasks).",
                "On CIFAR-FS, our multi-task framework outperforms previous works by at least 1.5%.",
                "On CIFAR-FS, we explore different combinations of tasks for our multi-task framework of Figure 1.",
                "The CIFAR-FS dataset (Bertinetto et al., 2018) is derived from the original CIFAR-100 dataset by randomly splitting 100 classes into 64 classes for training, 16 for validation and 20 for testing.",
                "Based on our detailed experiments on CIFAR-FS and miniImageNet, we show that leveraging self-supervision improves transfer learning performance on novel classes."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "6d9abc4f1b629189731d9206e7d4214968ea1843",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-09825",
                    "ArXiv": "2101.09825",
                    "CorpusId": 231699172
                },
                "corpusId": 231699172,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6d9abc4f1b629189731d9206e7d4214968ea1843",
                "title": "Improving Few-Shot Learning with Auxiliary Self-Supervised Pretext Tasks",
                "abstract": "Recent work on few-shot learning \\cite{tian2020rethinking} showed that quality of learned representations plays an important role in few-shot classification performance. On the other hand, the goal of self-supervised learning is to recover useful semantic information of the data without the use of class labels. In this work, we exploit the complementarity of both paradigms via a multi-task framework where we leverage recent self-supervised methods as auxiliary tasks. We found that combining multiple tasks is often beneficial, and that solving them simultaneously can be done efficiently. Our results suggest that self-supervised auxiliary tasks are effective data-dependent regularizers for representation learning. Our code is available at: \\url{https://github.com/nathanielsimard/improving-fs-ssl}.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "71630873",
                        "name": "N. Simard"
                    },
                    {
                        "authorId": "32721165",
                        "name": "Guillaume Lagrange"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", CNN-based relation modules [51, 59], ridge regression [4], and graph neural networks [43, 17, 61])."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4b3709a718bf6d92e57d93723aff40c0266074c5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-09499",
                    "ArXiv": "2101.09499",
                    "CorpusId": 231699122
                },
                "corpusId": 231699122,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/4b3709a718bf6d92e57d93723aff40c0266074c5",
                "title": "Contrastive Prototype Learning with Augmented Embeddings for Few-Shot Learning",
                "abstract": "Most recent few-shot learning (FSL) methods are based on meta-learning with episodic training. In each meta-training episode, a discriminative feature embedding and/or classifier are first constructed from a support set in an inner loop, and then evaluated in an outer loop using a query set for model updating. This query set sample centered learning objective is however intrinsically limited in addressing the lack of training data problem in the support set. In this paper, a novel contrastive prototype learning with augmented embeddings (CPLAE) model is proposed to overcome this limitation. First, data augmentations are introduced to both the support and query sets with each sample now being represented as an augmented embedding (AE) composed of concatenated embeddings of both the original and augmented versions. Second, a novel support set class prototype centered contrastive loss is proposed for contrastive prototype learning (CPL). With a class prototype as an anchor, CPL aims to pull the query samples of the same class closer and those of different classes further away. This support set sample centered loss is highly complementary to the existing query centered loss, fully exploiting the limited training data in each episode. Extensive experiments on several benchmarks demonstrate that our proposed CPLAE achieves new state-of-the-art.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1939358",
                        "name": "Yizhao Gao"
                    },
                    {
                        "authorId": "21313225",
                        "name": "Nanyi Fei"
                    },
                    {
                        "authorId": "151472765",
                        "name": "Guangzhen Liu"
                    },
                    {
                        "authorId": "1776220",
                        "name": "Zhiwu Lu"
                    },
                    {
                        "authorId": "145406421",
                        "name": "T. Xiang"
                    },
                    {
                        "authorId": "2410938",
                        "name": "Songfang Huang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Grad-CAM is formed by weighted summation of feature maps, which can show the importance of each area to its classification.",
                "In order to further evaluate the effectiveness of our method, we apply Grad-CAM [27] to visualize the images of the CUB200-2011 dataset.",
                "In order to further evaluate the effectiveness of our method, we apply Grad-CAM [33] to visualize the images of the CUB-200-2011 dataset."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "fcd3abb24f07b45525044efd8107eb3e530ff092",
                "externalIds": {
                    "DBLP": "conf/vcip/ZhangCMG21",
                    "ArXiv": "2101.08527",
                    "DOI": "10.1109/VCIP53242.2021.9675376",
                    "CorpusId": 231662468
                },
                "corpusId": 231662468,
                "publicationVenue": {
                    "id": "455f9323-a999-47fd-8b0d-5b06b6f519b7",
                    "name": "Visual Communications and Image Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Vis Commun Image Process",
                        "VCIP"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fcd3abb24f07b45525044efd8107eb3e530ff092",
                "title": "Progressive Co-Attention Network for Fine-Grained Visual Classification",
                "abstract": "Fine-grained visual classification aims to recognize images belonging to multiple sub-categories within a same category. It is a challenging task due to the inherently subtle variations among highly-confused categories. Most existing methods only take an individual image as input, which may limit the ability of models to recognize contrastive clues from different images. In this paper, we propose an effective method called progressive co-attention network (PCA-Net) to tackle this problem. Specifically, we calculate the channel-wise similarity by encouraging interaction between the feature channels within same-category image pairs to capture the common discriminative features. Considering that complementary information is also crucial for recognition, we erase the prominent areas enhanced by the channel interaction to force the network to focus on other discriminative regions. The proposed model has achieved competitive results on three fine-grained visual classification benchmark datasets: CUB-200-2011, Stanford Cars, and FGVC Aircraft.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2146333460",
                        "name": "Tian Zhang"
                    },
                    {
                        "authorId": "67146777",
                        "name": "Dongliang Chang"
                    },
                    {
                        "authorId": "1755773",
                        "name": "Zhanyu Ma"
                    },
                    {
                        "authorId": "2117222700",
                        "name": "Jun Guo"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9ae589d287e28d3442d3b583f8fd5db35c36303a",
                "externalIds": {
                    "DBLP": "journals/chinaf/ChengLLH21",
                    "DOI": "10.1007/s11432-020-3156-7",
                    "CorpusId": 231690629
                },
                "corpusId": 231690629,
                "publicationVenue": {
                    "id": "0534c8a0-1226-4f5b-bcf6-a13a8dd1825e",
                    "name": "Science China Information Sciences",
                    "alternate_names": [
                        "Sci China Inf Sci"
                    ],
                    "issn": "1869-1919",
                    "url": "http://info.scichina.com/"
                },
                "url": "https://www.semanticscholar.org/paper/9ae589d287e28d3442d3b583f8fd5db35c36303a",
                "title": "Task-wise attention guided part complementary learning for few-shot image classification",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152127024",
                        "name": "Gong Cheng"
                    },
                    {
                        "authorId": "2150924371",
                        "name": "Ruimin Li"
                    },
                    {
                        "authorId": "50666142",
                        "name": "Chunbo Lang"
                    },
                    {
                        "authorId": "7181955",
                        "name": "Junwei Han"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "67deabbf7e0273d3fa1b45fb008b32d9077295fc",
                "externalIds": {
                    "DOI": "10.1007/s11432-020-3156-7",
                    "CorpusId": 255190109
                },
                "corpusId": 255190109,
                "publicationVenue": {
                    "id": "0534c8a0-1226-4f5b-bcf6-a13a8dd1825e",
                    "name": "Science China Information Sciences",
                    "alternate_names": [
                        "Sci China Inf Sci"
                    ],
                    "issn": "1869-1919",
                    "url": "http://info.scichina.com/"
                },
                "url": "https://www.semanticscholar.org/paper/67deabbf7e0273d3fa1b45fb008b32d9077295fc",
                "title": "Task-wise attention guided part complementary learning for few-shot image classification",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "144592996",
                        "name": "Gong Cheng"
                    },
                    {
                        "authorId": "2150926571",
                        "name": "Ruimin Li"
                    },
                    {
                        "authorId": "50666142",
                        "name": "Chunbo Lang"
                    },
                    {
                        "authorId": "2156545584",
                        "name": "Junwei Han"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d91ce56b1905e22bde9fccfed8abdeb751537b38",
                "externalIds": {
                    "ArXiv": "2101.05018",
                    "DBLP": "journals/chinaf/ChenWLGL21",
                    "DOI": "10.1007/s11432-020-2973-7",
                    "CorpusId": 231592481
                },
                "corpusId": 231592481,
                "publicationVenue": {
                    "id": "0534c8a0-1226-4f5b-bcf6-a13a8dd1825e",
                    "name": "Science China Information Sciences",
                    "alternate_names": [
                        "Sci China Inf Sci"
                    ],
                    "issn": "1869-1919",
                    "url": "http://info.scichina.com/"
                },
                "url": "https://www.semanticscholar.org/paper/d91ce56b1905e22bde9fccfed8abdeb751537b38",
                "title": "Learning to focus: cascaded feature matching network for few-shot image recognition",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2108610458",
                        "name": "Mengting Chen"
                    },
                    {
                        "authorId": "2443233",
                        "name": "Xinggang Wang"
                    },
                    {
                        "authorId": "2110415972",
                        "name": "Heng Luo"
                    },
                    {
                        "authorId": "2067505413",
                        "name": "Yifeng Geng"
                    },
                    {
                        "authorId": "2109194747",
                        "name": "Wenyu Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We perform our experiments on four benchmark datasets: MiniImageNet [10] denoted MINet, CUB [11], CIFAR-FS [12] and TieredImageNet [13] denoted TINet."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "18efd91dac97f61b67a0ff8f851ea65ba118e267",
                "externalIds": {
                    "DBLP": "conf/icip/HamidoucheLHDPG21",
                    "ArXiv": "2101.04789",
                    "MAG": "3195359770",
                    "DOI": "10.1109/ICIP42928.2021.9506042",
                    "CorpusId": 231704298
                },
                "corpusId": 231704298,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/18efd91dac97f61b67a0ff8f851ea65ba118e267",
                "title": "Improving Classification Accuracy With Graph Filtering",
                "abstract": "In machine learning, classifiers are typically susceptible to noise in the training data. In this work, we aim at reducing intra-class noise with the help of graph filtering to improve the classification performance. Considered graphs are obtained by connecting samples of the training set that belong to a same class depending on the similarity of their representation in a latent space. We show that the proposed graph filtering methodology has the effect of asymptotically reducing intra-class variance, while maintaining the mean. While our approach applies to all classification problems in general, it is particularly useful in few-shot settings, where intra-class noise can have a huge impact due to the small sample selection. Using standardized benchmarks in the field of vision, we empirically demonstrate the ability of the proposed method to slightly improve state-of-the-art results in both cases of few-shot and standard classification.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "35477938",
                        "name": "Mounia Hamidouche"
                    },
                    {
                        "authorId": "3373720",
                        "name": "C. Lassance"
                    },
                    {
                        "authorId": "2143462361",
                        "name": "Yuqing Hu"
                    },
                    {
                        "authorId": "3407508",
                        "name": "Lucas Drumetz"
                    },
                    {
                        "authorId": "3334569",
                        "name": "Bastien Pasdeloup"
                    },
                    {
                        "authorId": "144916029",
                        "name": "Vincent Gripon"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We perform our experiments on 3 standardized few-shot classification datasets: miniImageNet [11], CUB [32] and CIFAR-FS [16].",
                "CIFAR-FS: This dataset has 100 classes, each class contains 600 images of size 32 \u00d7 32 pixels.",
                "In [15] and [16], the authors create a classweight generator by training the model with a linear classifier (e."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d55443f27bb2c58c2f48d9df197d6cac7c1f26b4",
                "externalIds": {
                    "DBLP": "conf/icpr/HuGP20",
                    "DOI": "10.1109/ICPR48806.2021.9412076",
                    "CorpusId": 233877432
                },
                "corpusId": 233877432,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d55443f27bb2c58c2f48d9df197d6cac7c1f26b4",
                "title": "Graph-based Interpolation of Feature Vectors for Accurate Few-Shot Classification",
                "abstract": "In few-shot classification, the aim is to learn models able to discriminate classes using only a small number of labeled examples. In this context, works have proposed to introduce Graph Neural Networks (GNNs) aiming at exploiting the information contained in other samples treated concurrently, what is commonly referred to as the transductive setting in the literature. These GNNs are trained all together with a backbone feature extractor. In this paper, we propose a new method that relies on graphs only to interpolate feature vectors instead, resulting in a transductive learning setting with no additional parameters to train. Our proposed method thus exploits two levels of information: a) transfer features obtained on generic datasets, b) transductive information obtained from other samples to be classified. Using standard few-shot vision classification datasets, we demonstrate its ability to bring significant gains compared to other works.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2143462361",
                        "name": "Yuqing Hu"
                    },
                    {
                        "authorId": "144916029",
                        "name": "Vincent Gripon"
                    },
                    {
                        "authorId": "2642628",
                        "name": "S. Pateux"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "74b03899db6122bb96ef3b7a79541d1a4e29c65d",
                "externalIds": {
                    "DBLP": "conf/icpr/MatsumiY20",
                    "DOI": "10.1109/ICPR48806.2021.9411993",
                    "CorpusId": 233877997
                },
                "corpusId": 233877997,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/74b03899db6122bb96ef3b7a79541d1a4e29c65d",
                "title": "Few-Shot Learning Based on Metric Learning Using Class Augmentation",
                "abstract": "Few-shot learning is a machine learning problem in which new categories are learned from only a few samples. One approach for few-shot learning is metric learning, which learns an embedding space in which learning is efficient for few-shot samples. In this paper, we focus on metric learning and demonstrate that the number of classes in the training data used for metric learning has a greater impact on the accuracy of few-shot learning than the number of samples per class. We propose a few-shot learning approach based on metric learning in which the number of classes in the training data for performing metric learning is increased. The number of classes is augmented by synthesizing samples of imaginary classes at a feature level from the original training data. The proposed method is evaluated on the miniImageNet dataset using the nearest neighbor method or a support vector machine as the classifier, and the effectiveness of the approach is demonstrated.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2088934092",
                        "name": "Susumu Matsumi"
                    },
                    {
                        "authorId": "51499036",
                        "name": "K. Yamada"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [3] was created by randomly sampling from CIFAR-100 [27] by using the same criteria as miniImageNet (100 classes with 600 images per class, split into folds of 64/16/20 for meta-train/val/test).",
                "Results Table 1-3 summarize the results onminiImageNet, tieredImageNet and CIFAR-FS.",
                "For example, many have relied on episodic training schemes [52, 59], where few-shot learning problems are simulated at each iteration of training; differentiable optimisers [3, 30], or new neural network modules [55, 15]"
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ba6a3dbc04caa1ee17b82a79b66452a4ac619b55",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-02833",
                    "ArXiv": "2101.02833",
                    "DOI": "10.1109/ICCV48922.2021.00069",
                    "CorpusId": 231419172
                },
                "corpusId": 231419172,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/ba6a3dbc04caa1ee17b82a79b66452a4ac619b55",
                "title": "Shallow Bayesian Meta Learning for Real-World Few-Shot Recognition",
                "abstract": "Many state-of-the-art few-shot learners focus on developing effective training procedures for feature representations, before using simple (e.g., nearest centroid) classifiers. We take an approach that is agnostic to the features used, and focus exclusively on meta-learning the final classifier layer. Specifically, we introduce MetaQDA, a Bayesian meta-learning generalisation of the classic quadratic discriminant analysis. This approach has several benefits of interest to practitioners: meta-learning is fast and memory efficient, without the need to fine-tune features. It is agnostic to the off-the-shelf features chosen, and thus will continue to benefit from future advances in feature representations. Empirically, it leads to excellent performance in cross-domain few-shot learning, class-incremental few-shot learning, and crucially for real-world applications, the Bayesian formulation leads to state-of-the-art uncertainty calibration in predictions.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2108058854",
                        "name": "Xueting Zhang"
                    },
                    {
                        "authorId": "79402595",
                        "name": "Debin Meng"
                    },
                    {
                        "authorId": "2319565",
                        "name": "H. Gouk"
                    },
                    {
                        "authorId": "1697755",
                        "name": "Timothy M. Hospedales"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There exist approaches for directly back-propagation through the solution z\u2217 for convex problems such as (2b) using the implicit function theorem [18, 33] or closed-from expressions [5]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "af235029ee66a4f83048b7278bf4114974277b4b",
                "externalIds": {
                    "DBLP": "conf/iccv/ZhaoBDGT21",
                    "ArXiv": "2101.02196",
                    "DOI": "10.1109/ICCV48922.2021.01330",
                    "CorpusId": 230770344
                },
                "corpusId": 230770344,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/af235029ee66a4f83048b7278bf4114974277b4b",
                "title": "Generating Masks from Boxes by Mining Spatio-Temporal Consistencies in Videos",
                "abstract": "Segmenting objects in videos is a fundamental computer vision task. The current deep learning based paradigm offers a powerful, but data-hungry solution. However, current datasets are limited by the cost and human effort of annotating object masks in videos. This effectively limits the performance and generalization capabilities of existing video segmentation methods. To address this issue, we explore weaker form of bounding box annotations.We introduce a method for generating segmentation masks from per-frame bounding box annotations in videos. To this end, we propose a spatio-temporal aggregation module that effectively mines consistencies in the object and background appearance across multiple frames. We use our predicted accurate masks to train video object segmentation (VOS) networks for the tracking domain, where only manual bounding box annotations are available. The additional data provides substantially better generalization performance, leading to state-of-the-art results on standard tracking benchmarks. The code and models are available at https://github.com/visionml/pytracking.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2112632528",
                        "name": "Bin Zhao"
                    },
                    {
                        "authorId": "49922196",
                        "name": "Goutam Bhat"
                    },
                    {
                        "authorId": "2488938",
                        "name": "Martin Danelljan"
                    },
                    {
                        "authorId": "1681236",
                        "name": "L. Gool"
                    },
                    {
                        "authorId": "1732855",
                        "name": "R. Timofte"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3b65b8ed14ccb6ed102e0290adc57d00e27218c9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-01710",
                    "ArXiv": "2101.01710",
                    "DOI": "10.1109/CVPR46437.2021.00566",
                    "CorpusId": 230524089
                },
                "corpusId": 230524089,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3b65b8ed14ccb6ed102e0290adc57d00e27218c9",
                "title": "Learning Accurate Dense Correspondences and When to Trust Them",
                "abstract": "Establishing dense correspondences between a pair of images is an important and general problem. However, dense flow estimation is often inaccurate in the case of large displacements or homogeneous regions. For most applications and down-stream tasks, such as pose estimation, image manipulation, or 3D reconstruction, it is crucial to know when and where to trust the estimated matches.In this work, we aim to estimate a dense flow field relating two images, coupled with a robust pixel-wise confidence map indicating the reliability and accuracy of the prediction. We develop a flexible probabilistic approach that jointly learns the flow prediction and its uncertainty. In particular, we parametrize the predictive distribution as a constrained mixture model, ensuring better modelling of both accurate flow predictions and outliers. Moreover, we develop an architecture and training strategy tailored for robust and generalizable uncertainty prediction in the context of self-supervised training. Our approach obtains state- of-the-art results on multiple challenging geometric matching and optical flow datasets. We further validate the usefulness of our probabilistic confidence estimation for the task of pose estimation. Code and models are available at https://github.com/PruneTruong/PDCNet.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "153399953",
                        "name": "Prune Truong"
                    },
                    {
                        "authorId": "2488938",
                        "name": "Martin Danelljan"
                    },
                    {
                        "authorId": "1681236",
                        "name": "L. Gool"
                    },
                    {
                        "authorId": "1732855",
                        "name": "R. Timofte"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Model/Experiment 2 way accuracy 1-shot 5-shot MAML[23] 82.",
                "Model/Experiment 5 way accuracy 1-shot 5-shot MAML[23] 58."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d32d3a8ee55a984d05ae1bf27bc96f48b0160c42",
                "externalIds": {
                    "ArXiv": "2101.00203",
                    "DBLP": "journals/corr/abs-2101-00203",
                    "DOI": "10.1109/ICASSP39728.2021.9414437",
                    "CorpusId": 230437891
                },
                "corpusId": 230437891,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/d32d3a8ee55a984d05ae1bf27bc96f48b0160c42",
                "title": "B-Small: A Bayesian Neural Network Approach to Sparse Model-Agnostic Meta-Learning",
                "abstract": "There is a growing interest in the learning-to-learn paradigm, also known as meta-learning, where models infer on new tasks using a few training examples. Recently, meta-learning based methods have been widely used in few-shot classification, regression, reinforcement learning, and domain adaptation. The model-agnostic meta-learning (MAML) algorithm is a well-known algorithm that obtains model parameter initialization at meta-training phase. In the meta-test phase, this initialization is rapidly adapted to new tasks by using gradient descent. However, meta-learning models are prone to over-fitting since there are insufficient training tasks resulting in over-parameterized models with poor generalization performance for unseen tasks. In this paper, we propose a Bayesian neural network based MAML algorithm, which we refer to as the B-SMALLalgorithm. The proposed framework incorporates a sparse variational loss term alongside the loss function of MAML, which uses a sparsifying approximated KL divergence as a regularizer. We demonstrate the performance of B-MAMLusing classification and regression tasks, and high-light that training a sparsifying BNN using MAML indeed improves the parameter footprint of the model while performing at par or even outperforming the MAML approach. We also illustrate applicability of our approach in distributed sensor networks, where sparsity and meta-learning can be beneficial.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1703003796",
                        "name": "Anish Madan"
                    },
                    {
                        "authorId": "144990181",
                        "name": "Ranjitha Prasad"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Table I shows the results of 5-way classifcation tasks at CIFAR-FS [1] and FC100 [8].",
                "\u2020 denotes CIFAR-FS results taken from [1] and FC100 results taken from [8]."
            ],
            "intents": [
                "methodology",
                "result"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0b5e29d41fb374dd11193d598c9b18b9c99f5bac",
                "externalIds": {
                    "DBLP": "conf/bigcomp/LeePKLH21",
                    "DOI": "10.1109/BigComp51126.2021.00072",
                    "CorpusId": 232235120
                },
                "corpusId": 232235120,
                "publicationVenue": {
                    "id": "88cc76ce-f486-46c4-bfa1-a31809d402d7",
                    "name": "International Conference on Big Data and Smart Computing",
                    "type": "conference",
                    "alternate_names": [
                        "BIGCOMP",
                        "BigComp",
                        "Int Conf Big Data Smart Comput"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0b5e29d41fb374dd11193d598c9b18b9c99f5bac",
                "title": "Regularization with Multiple Feature Combination for Few-Shot Learning",
                "abstract": "Few-shot learning solves problems with a limited amount of labeled examples. Our analysis shows the existing metric-based methods concentrate on highly discriminative features while not fully utilizing whole capacity. In this work, we propose a novel regularization technique that constrains the model to exploit whole capacity by distinguishing data with multiple feature combinations. Our approach achieves state-of the-art performance in several public benchmarks compared to the existing metric-based methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2208876790",
                        "name": "Su Been Lee"
                    },
                    {
                        "authorId": "2115992256",
                        "name": "J. Park"
                    },
                    {
                        "authorId": "2127155507",
                        "name": "Ji Young Kim"
                    },
                    {
                        "authorId": "2207830048",
                        "name": "Seung Yeol Lee"
                    },
                    {
                        "authorId": "7212202",
                        "name": "Jae-Pil Heo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For CIFAR-CS, the classes are divided into 64, 16 and 20 classes for meta-training, metavalidation, and meta-testing respectively.",
                "\u2026base our implementation on the publicly available code of (Tian et al., 2020b) and conduct experiments on four popular few-shot classification benchmarks: mini-ImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFAR-CS (Bertinetto et al., 2019) and FC100 (Oreshkin et al., 2018).",
                "For the experimental section, we base our implementation on the publicly available code of [43] and conduct experiments on ImageNet derivatives: mini -ImageNet [47] and tiered -ImageNet [33], and CIFAR-100 derivatives: CIFAR-CS [2] and FC100 [28].",
                "For the experimental section, we base our implementation on the publicly available code of (Tian et al., 2020b) and conduct experiments on four popular few-shot classification benchmarks: mini-ImageNet (Vinyals et al., 2016), tieredImageNet (Ren et al., 2018), CIFAR-CS (Bertinetto et al., 2019) and FC100 (Oreshkin et al., 2018).",
                "CIFAR-CS (Bertinetto et al., 2019)\nand FC100 (Oreshkin et al., 2018) are both CIFAR-100 (Krizhevsky et al., 2010) derivatives, containing 100 classes and images of size 32\u00d732."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1d4fe5b45a6450554fe1beea8e7daf5a6fc7ca05",
                "externalIds": {
                    "ArXiv": "2012.13831",
                    "DBLP": "journals/corr/abs-2012-13831",
                    "DOI": "10.1007/978-3-030-86486-6_41",
                    "CorpusId": 229677873
                },
                "corpusId": 229677873,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1d4fe5b45a6450554fe1beea8e7daf5a6fc7ca05",
                "title": "Spatial Contrastive Learning for Few-Shot Classification",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "67035902",
                        "name": "Yassine Ouali"
                    },
                    {
                        "authorId": "1931593",
                        "name": "C. Hudelot"
                    },
                    {
                        "authorId": "30784787",
                        "name": "Myriam Tami"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e2cfab43c8fa4643e34e40531eeb8a725b872260",
                "externalIds": {
                    "ArXiv": "2012.13751",
                    "DBLP": "journals/corr/abs-2012-13751",
                    "CorpusId": 229678494
                },
                "corpusId": 229678494,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e2cfab43c8fa4643e34e40531eeb8a725b872260",
                "title": "Few Shot Learning With No Labels",
                "abstract": "Few-shot learners aim to recognize new categories given only a small number of training samples. The core challenge is to avoid overfitting to the limited data while ensuring good generalization to novel classes. Existing literature makes use of vast amounts of annotated data by simply shifting the label requirement from novel classes to base classes. Since data annotation is time-consuming and costly, reducing the label requirement even further is an important goal. To that end, our paper presents a more challenging few-shot setting where no label access is allowed during training or testing. By leveraging self-supervision for learning image representations and image similarity for classification at test time, we achieve competitive baselines while using \\textbf{zero} labels, which is at least fewer labels than state-of-the-art. We hope that this work is a step towards developing few-shot learning methods which do not depend on annotated data at all. Our code will be publicly released.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2064645504",
                        "name": "Aditya Bharti"
                    },
                    {
                        "authorId": "1699429",
                        "name": "V. Balasubramanian"
                    },
                    {
                        "authorId": "1694502",
                        "name": "C. V. Jawahar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [2] contains 100 classes with the class split for (64,16,20).",
                "We further conduct FSOR experiments on two fewshot benchmark datasets: CIFAR-FS [2], FC100 [29]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3072920e2a60c4d4ebcb58212d88de1515b43b54",
                "externalIds": {
                    "DBLP": "conf/cvpr/HuangMHC22",
                    "ArXiv": "2012.13073",
                    "DOI": "10.1109/CVPR52688.2022.00703",
                    "CorpusId": 250273577
                },
                "corpusId": 250273577,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/3072920e2a60c4d4ebcb58212d88de1515b43b54",
                "title": "Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition",
                "abstract": "We study the problem of few-shot open-set recognition (FSOR), which learns a recognition system capable of both fast adaptation to new classes with limited labeled exam-ples and rejection of unknown negative samples. Traditional large-scale open-set methods have been shown in-effective for FSOR problem due to data limitation. Current FSOR methods typically calibrate few-shot closed-set clas-sifiers to be sensitive to negative samples so that they can be rejected via thresholding. However, threshold tuning is a challenging process as different FSOR tasks may require different rejection powers. In this paper, we instead propose task-adaptive negative class envision for FSOR to integrate threshold tuning into the learning process. Specifically, we augment the few-shot closed-set classifier with additional negative prototypes generated from few-shot examples. By incorporating few-shot class correlations in the negative generation process, we are able to learn dynamic rejection boundaries for FSOR tasks. Besides, we extend our method to generalized few-shot open-set recognition (GF-SOR), which requires classification on both many-shot and few-shot classes as well as rejection of negative samples. Extensive experiments on public benchmarks validate our methods on both problems.11Code available at https://github.com/shiyuanh/TANE",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2110443113",
                        "name": "Shiyuan Huang"
                    },
                    {
                        "authorId": "152320135",
                        "name": "Jiawei Ma"
                    },
                    {
                        "authorId": "2067641876",
                        "name": "G. Han"
                    },
                    {
                        "authorId": "2122374530",
                        "name": "Shih-Fu Chang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We benchmark our models on miniImageNet, CIFAR-FS, and tieredImageNet, and show that NCA fairs surprisingly well against methods that use meta-learning and also against recent highperforming baselines which pre-train with the cross-entropy loss.",
                "Results for CIFAR-FS can be found in Fig.",
                "Without bells and whistles, our implementation of the NCA loss achieves an accuracy that is competitive with the state-of-the-art on multiple FSL benchmarks: miniImageNet, CIFAR-FS and tieredImageNet.",
                "We conduct our experiments on miniImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019) and tieredImageNet (Ren et al., 2018), using the ResNet12 variant first adopted by Lee et al. (2019) as embedding function f\u03b8.",
                "3.4 on miniImageNet and CIFAR-FS.",
                ", 2016), CIFAR-FS (Bertinetto et al., 2019) and tieredImageNet (Ren et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "17e742d2d48f0103664a9468454807076b41bd44",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2012-09831",
                    "ArXiv": "2012.09831",
                    "MAG": "3110874594",
                    "CorpusId": 229165454
                },
                "corpusId": 229165454,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/17e742d2d48f0103664a9468454807076b41bd44",
                "title": "On Episodes, Prototypical Networks, and Few-shot Learning",
                "abstract": "Episodic learning is a popular practice among researchers and practitioners interested in few-shot learning. It consists of organising training in a series of learning problems, each relying on small \"support\" and \"query\" sets to mimic the few-shot circumstances encountered during evaluation. In this paper, we investigate the usefulness of episodic learning in Prototypical Networks and Matching Networks, two of the most popular algorithms making use of this practice. Surprisingly, in our experiments we found that, for Prototypical and Matching Networks, it is detrimental to use the episodic learning strategy of separating training samples between support and query set, as it is a data-inefficient way to exploit training batches. These \"non-episodic\" variants, which are closely related to the classic Neighbourhood Component Analysis, reliably improve over their episodic counterparts in multiple datasets, achieving an accuracy that (in the case of Prototypical Networks) is competitive with the state-of-the-art, despite being extremely simple.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2008166763",
                        "name": "Steinar Laenen"
                    },
                    {
                        "authorId": "2271057",
                        "name": "Luca Bertinetto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Optimization-based methods attempt to learn model parameters that are able to adapt fast in novel tasks [12, 47, 68, 48, 40, 30, 6]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b5bc34dbb82ec8abffb360583c5d9c4f3674ea2d",
                "externalIds": {
                    "MAG": "3111381272",
                    "ArXiv": "2012.07962",
                    "DBLP": "conf/iccv/LazarouSA21",
                    "DOI": "10.1109/iccv48922.2021.00863",
                    "CorpusId": 229181323
                },
                "corpusId": 229181323,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/b5bc34dbb82ec8abffb360583c5d9c4f3674ea2d",
                "title": "Iterative label cleaning for transductive and semi-supervised few-shot learning",
                "abstract": "Few-shot learning amounts to learning representations and acquiring knowledge such that novel tasks may be solved with both supervision and data being limited. Improved performance is possible by transductive inference, where the entire test set is available concurrently, and semi-supervised learning, where more unlabeled data is available.Focusing on these two settings, we introduce a new algorithm that leverages the manifold structure of the labeled and unlabeled data distribution to predict pseudo-labels, while balancing over classes and using the loss value distribution of a limited-capacity classifier to select the cleanest labels, iteratively improving the quality of pseudo-labels. Our solution surpasses or matches the state of the art results on four benchmark datasets, namely miniImageNet, tieredImageNet, CUB and CIFAR-FS, while being robust over feature space pre-processing and the quantity of available data. The publicly available source code can be found in https://github.com/MichalisLazarou/iLPC",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "46973863",
                        "name": "Michalis Lazarou"
                    },
                    {
                        "authorId": "1744904",
                        "name": "Yannis Avrithis"
                    },
                    {
                        "authorId": "1783374",
                        "name": "T. Stathaki"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2017), and optimization-based meta-learners that embed an optimization procedure into the meta-learner (Finn et al., 2017; Li et al., 2017b; Rusu et al., 2018; Zintgraf et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Lee et al., 2019; Yoon et al., 2018; Finn et al., 2018).",
                "\u2026et al., 2017), and optimization-based meta-learners that embed an optimization procedure into the meta-learner (Finn et al., 2017; Li et al., 2017b; Rusu et al., 2018; Zintgraf et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Lee et al., 2019; Yoon et al., 2018; Finn et al., 2018)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c28dd422d4ba331fa2519df446a036b7d302aef3",
                "externalIds": {
                    "ArXiv": "2012.07769",
                    "DBLP": "journals/corr/abs-2012-07769",
                    "MAG": "3112308976",
                    "CorpusId": 229155975
                },
                "corpusId": 229155975,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c28dd422d4ba331fa2519df446a036b7d302aef3",
                "title": "Variable-Shot Adaptation for Online Meta-Learning",
                "abstract": "Few-shot meta-learning methods consider the problem of learning new tasks from a small, fixed number of examples, by meta-learning across static data from a set of previous tasks. However, in many real world settings, it is more natural to view the problem as one of minimizing the total amount of supervision --- both the number of examples needed to learn a new task and the amount of data needed for meta-learning. Such a formulation can be studied in a sequential learning setting, where tasks are presented in sequence. When studying meta-learning in this online setting, a critical question arises: can meta-learning improve over the sample complexity and regret of standard empirical risk minimization methods, when considering both meta-training and adaptation together? The answer is particularly non-obvious for meta-learning algorithms with complex bi-level optimizations that may demand large amounts of meta-training data. To answer this question, we extend previous meta-learning algorithms to handle the variable-shot settings that naturally arise in sequential learning: from many-shot learning at the start, to zero-shot learning towards the end. On sequential learning problems, we find that meta-learning solves the full task set with fewer overall labels and achieves greater cumulative performance, compared to standard supervised methods. These results suggest that meta-learning is an important ingredient for building learning systems that continuously learn and improve over a sequence of problems.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "10909315",
                        "name": "Tianhe Yu"
                    },
                    {
                        "authorId": "3468192",
                        "name": "Xinyang Geng"
                    },
                    {
                        "authorId": "46881670",
                        "name": "Chelsea Finn"
                    },
                    {
                        "authorId": "1736651",
                        "name": "S. Levine"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1085908abbb8ea6b04984315a506309f364ae563",
                "externalIds": {
                    "MAG": "3107123124",
                    "CorpusId": 227240556
                },
                "corpusId": 227240556,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1085908abbb8ea6b04984315a506309f364ae563",
                "title": "Weakly-supervised Object Localization for Few-shot Learning and Fine-grained Few-shot Learning.",
                "abstract": "Few-shot learning (FSL) aims to learn novel visual categories from very few samples, which is a challenging problem in real-world applications. Many methods of few-shot classification work well on general images to learn global representation. However, they can not deal with fine-grained categories well at the same time due to a lack of subtle and local information. We argue that localization is an efficient approach because it directly provides the discriminative regions, which is critical for both general classification and fine-grained classification in a low data regime. In this paper, we propose a Self-Attention Based Complementary Module (SAC Module) to fulfill the weakly-supervised object localization, and more importantly produce the activated masks for selecting discriminative deep descriptors for few-shot classification. Based on each selected deep descriptor, Semantic Alignment Module (SAM) calculates the semantic alignment distance between the query and support images to boost classification performance. Extensive experiments show our method outperforms the state-of-the-art methods on benchmark datasets under various settings, especially on the fine-grained few-shot tasks. Besides, our method achieves superior performance over previous methods when training the model on miniImageNet and evaluating it on the different datasets, demonstrating its superior generalization capacity. Extra visualization shows the proposed method can localize the key objects more interval.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1476816520",
                        "name": "Xiaojian He"
                    },
                    {
                        "authorId": "1476769857",
                        "name": "Jinfu Lin"
                    },
                    {
                        "authorId": "1471385352",
                        "name": "Junming Shen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dc57bf274a8b017d8b2d30fadb23e98d04d99088",
                "externalIds": {
                    "MAG": "3111980109",
                    "DBLP": "journals/corr/abs-2012-07176",
                    "CorpusId": 229152338
                },
                "corpusId": 229152338,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/dc57bf274a8b017d8b2d30fadb23e98d04d99088",
                "title": "Pseudo Shots: Few-Shot Learning with Auxiliary Data",
                "abstract": "In many practical few-shot learning problems, even though labeled examples are scarce, there are abundant auxiliary data sets that potentially contain useful information. We propose a framework to address the challenges of efficiently selecting and effectively using auxiliary data in image classification. Given an auxiliary dataset and a notion of semantic similarity among classes, we automatically select pseudo shots, which are labeled examples from other classes related to the target task. We show that naively assuming that these additional examples come from the same distribution as the target task examples does not significantly improve accuracy. Instead, we propose a masking module that adjusts the features of auxiliary data to be more similar to those of the target classes. We show that this masking module can improve accuracy by up to 18 accuracy points, particularly when the auxiliary data is semantically distant from the target task. We also show that incorporating pseudo shots improves over the current state-of-the-art few-shot image classification scores by an average of 4.81 percentage points of accuracy on 1-shot tasks and an average of 0.31 percentage points on 5-shot tasks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "36059869",
                        "name": "Reza Esfandiarpoor"
                    },
                    {
                        "authorId": "7659375",
                        "name": "M. Hajabdollahi"
                    },
                    {
                        "authorId": "2870504",
                        "name": "Stephen H. Bach"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Besides, many strategies such as Convolutional Neural Networks (CNN) [6], Ridge Regression, and Logistic Regression [7] and k-NearestNeighbors (k-NN) [8] are proposed for metric learning."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e1fa5ec18ed84729ccbc327da206f1fa0614b260",
                "externalIds": {
                    "DOI": "10.1109/ICCC51575.2020.9345220",
                    "CorpusId": 231920963
                },
                "corpusId": 231920963,
                "publicationVenue": {
                    "id": "5758d639-a450-4152-901d-7a78c8715aa7",
                    "name": "International Conference on Innovative Computing and Cloud Computing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Control Commun  Comput India",
                        "IEEE Int Conf Cogn Comput",
                        "IEEE International Conference Computer and Communications",
                        "Int Carpathian Control Conf",
                        "Int Conf Cogn Comput [services Soc",
                        "Int Conf Comput Cybern",
                        "IEEE International Conference on Cognitive Computing",
                        "IEEE Int Conf Comput Commun",
                        "International Conference on Computer Communication",
                        "Int Conf Innov Comput Cloud Comput",
                        "International Carpathian Control Conference",
                        "International Conference on Computational Creativity",
                        "Int Conf Comput Commun",
                        "International Conference on Control Communication & Computing India",
                        "ICCC",
                        "International Conference on Computational Cybernetics",
                        "Int Conf Comput Creativity",
                        "International Conference on Cognitive Computing [Services Society]",
                        "IEEE Int Conf Commun China",
                        "IEEE International Conference on Communications in China"
                    ],
                    "url": "http://computationalcreativity.net/",
                    "alternate_urls": [
                        "http://www.icccgovernors.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/e1fa5ec18ed84729ccbc327da206f1fa0614b260",
                "title": "Few-Shot Classification via Feature Redistribution",
                "abstract": "Deep learning in image classification tasks needs extensive data to get representative features. It becomes an emerging problem when facing a few labeled samples to classify novel categories. To this end, previous works focus on meta-learning (ML) and metric learning to leverage large resemble tasks to adapt to new tasks with few labeled examples. In this letter, we introduce a few-shot-learning (FSL) method based on feature redistribution. Our proposed method trained a more generalized embedding model which can provide great representative features with few labeled data. Then we transformed feature data layout through box-cox transformation into Gaussian distribution or Gaussian-like distribution. To measure the similarity between the class center and unlabeled samples, we proposed a metric method using Sinkhorn mapping initialized with the correlation coefficient. Our approach shows great performance on the CUB dataset, CIFAR dataset, and MiniImageNet dataset for 5 shot tasks by extensive comparisons to related baseline methods.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2118467661",
                        "name": "Lulu Liu"
                    },
                    {
                        "authorId": "2152721763",
                        "name": "Li Wang"
                    },
                    {
                        "authorId": "98132341",
                        "name": "Zhong Ma"
                    },
                    {
                        "authorId": "18170765",
                        "name": "Zhanzhuang He"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "648ad8757436e0d954a5319138d85fb64edea26e",
                "externalIds": {
                    "MAG": "3110057998",
                    "DBLP": "journals/corr/abs-2012-01641",
                    "ArXiv": "2012.01641",
                    "DOI": "10.1109/TCSVT.2022.3173687",
                    "CorpusId": 227254246
                },
                "corpusId": 227254246,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/648ad8757436e0d954a5319138d85fb64edea26e",
                "title": "Meta-Generating Deep Attentive Metric for Few-Shot Classification",
                "abstract": "Learning to generate a task-aware base learner proves a promising direction to deal with few-shot learning (FSL) problem. Existing methods mainly focus on generating an embedding model utilized with a fixed metric (e.g., cosine distance) for nearest neighbour classification or directly generating a linear classifier. However, due to the limited discriminative capacity of such a simple metric or classifier, these methods fail to generalize to challenging cases appropriately. To mitigate this problem, we present a novel deep metric meta-generation method that turns to an orthogonal direction, i.e., learning to adaptively generate a specific metric for a new FSL task based on the task description (e.g., a few labelled samples). In this study, we structure the metric using a three-layers deep attentive network that is flexible enough to produce a discriminative metric for each task. Moreover, different from existing methods that utilize an uni-modal weight distribution conditioned on labelled samples for network generation, the proposed meta-learner establishes a multi-modal weight distribution conditioned on cross-class sample pairs using a tailored variational autoencoder, which can separately capture the specific inter-class discrepancy statistics for each class and jointly embed the statistics for all classes into metric generation. By doing this, the generated metric can be appropriately adapted to a new FSL task with pleasing generalization performance. To demonstrate this, we test the proposed method on three benchmark FSL datasets and gain competitive results with state-of-the-art competitors.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1452981772",
                        "name": "Lei Zhang"
                    },
                    {
                        "authorId": "2106043218",
                        "name": "Fei Zhou"
                    },
                    {
                        "authorId": "145673165",
                        "name": "Wei Wei"
                    },
                    {
                        "authorId": "2047640322",
                        "name": "Yanning Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This formulation is owed to the Woodbury Identity [24] as applied in [4]:"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f105afbb27ebb78a2ee8c420b712a528c38994d2",
                "externalIds": {
                    "ArXiv": "2012.01506",
                    "DBLP": "conf/cvpr/WertheimerTH21",
                    "MAG": "3108436250",
                    "DOI": "10.1109/CVPR46437.2021.00792",
                    "CorpusId": 227254236
                },
                "corpusId": 227254236,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f105afbb27ebb78a2ee8c420b712a528c38994d2",
                "title": "Few-Shot Classification with Feature Map Reconstruction Networks",
                "abstract": "In this paper we reformulate few-shot classification as a reconstruction problem in latent space. The ability of the network to reconstruct a query feature map from support features of a given class predicts membership of the query in that class. We introduce a novel mechanism for few-shot classification by regressing directly from support features to query features in closed form, without introducing any new modules or large-scale learnable parameters. The resulting Feature Map Reconstruction Networks are both more performant and computationally efficient than previous approaches. We demonstrate consistent and substantial accuracy gains on four fine-grained benchmarks with varying neural architectures. Our model is also competitive on the non-fine-grained mini-ImageNet and tiered-ImageNet benchmarks with minimal bells and whistles.1",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "102270513",
                        "name": "Davis Wertheimer"
                    },
                    {
                        "authorId": "34689393",
                        "name": "Luming Tang"
                    },
                    {
                        "authorId": "73710317",
                        "name": "B. Hariharan"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2018) or apply faster adaptation (Bertinetto et al., 2018; Zintgraf et al., 2019; Rajeswaran et al., 2019) through meta-training.",
                "Another direction is to learn how to better initialize parameters for new classes (Finn et al., 2017; Finn et al., 2018) or apply faster adaptation (Bertinetto et al., 2018; Zintgraf et al., 2019; Rajeswaran et al., 2019) through meta-training."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "51d5322e6f2b93f5a7737956aa88015cae78f379",
                "externalIds": {
                    "MAG": "3114459349",
                    "DBLP": "conf/coling/DongYXGHLLLS20",
                    "ACL": "2020.coling-main.140",
                    "DOI": "10.18653/V1/2020.COLING-MAIN.140",
                    "CorpusId": 227230422
                },
                "corpusId": 227230422,
                "publicationVenue": {
                    "id": "f51ff783-cdff-4e22-94fb-28e6336d17b3",
                    "name": "International Conference on Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Comput Linguistics",
                        "COLING"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/coling/"
                },
                "url": "https://www.semanticscholar.org/paper/51d5322e6f2b93f5a7737956aa88015cae78f379",
                "title": "Meta-Information Guided Meta-Learning for Few-Shot Relation Classification",
                "abstract": "Few-shot classification requires classifiers to adapt to new classes with only a few training instances. State-of-the-art meta-learning approaches such as MAML learn how to initialize and fast adapt parameters from limited instances, which have shown promising results in few-shot classification. However, existing meta-learning models solely rely on implicit instance-based statistics, and thus suffer from instance unreliability and weak interpretability. To solve this problem, we propose a novel meta-information guided meta-learning (MIML) framework, where semantic concepts of classes provide strong guidance for meta-learning in both initialization and adaptation. In effect, our model can establish connections between instance-based information and semantic-based information, which enables more effective initialization and faster adaptation. Comprehensive experimental results on few-shot relation classification demonstrate the effectiveness of the proposed framework. Notably, MIML achieves comparable or superior performance to humans with only one shot on FewRel evaluation.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "50660465",
                        "name": "Bowen Dong"
                    },
                    {
                        "authorId": "1390925224",
                        "name": "Yuan Yao"
                    },
                    {
                        "authorId": "3360722",
                        "name": "Ruobing Xie"
                    },
                    {
                        "authorId": "4800645",
                        "name": "Tianyu Gao"
                    },
                    {
                        "authorId": "145760425",
                        "name": "Xu Han"
                    },
                    {
                        "authorId": "49293587",
                        "name": "Zhiyuan Liu"
                    },
                    {
                        "authorId": "1924873901",
                        "name": "Fen Lin"
                    },
                    {
                        "authorId": "4950224",
                        "name": "Leyu Lin"
                    },
                    {
                        "authorId": "1753344",
                        "name": "Maosong Sun"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b087a56922e7637a2adcc91413fd41d55e71a2c3",
                "externalIds": {
                    "MAG": "3076007039",
                    "DBLP": "journals/ivc/MazumderSN20",
                    "DOI": "10.1016/j.imavis.2020.104006",
                    "CorpusId": 224950187
                },
                "corpusId": 224950187,
                "publicationVenue": {
                    "id": "6cc36eeb-d056-42c4-a306-7bcb239cc442",
                    "name": "Image and Vision Computing",
                    "type": "journal",
                    "alternate_names": [
                        "Image Vis Comput"
                    ],
                    "issn": "0262-8856",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525443/description#description",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/02628856",
                        "https://www.journals.elsevier.com/image-and-vision-computing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b087a56922e7637a2adcc91413fd41d55e71a2c3",
                "title": "GIFSL - grafting based improved few-shot learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "31222412",
                        "name": "Pratik Mazumder"
                    },
                    {
                        "authorId": "144377059",
                        "name": "Pravendra Singh"
                    },
                    {
                        "authorId": "145460361",
                        "name": "Vinay P. Namboodiri"
                    },
                    {
                        "authorId": "145460361",
                        "name": "Vinay P. Namboodiri"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "274ad4074f33ecaaa4d879be6f6095466cea9acf",
                "externalIds": {
                    "ArXiv": "2012.00150",
                    "DBLP": "journals/corr/abs-2012-00150",
                    "MAG": "3110236288",
                    "DOI": "10.1109/WACV48630.2021.00263",
                    "CorpusId": 227238955
                },
                "corpusId": 227238955,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/274ad4074f33ecaaa4d879be6f6095466cea9acf",
                "title": "MUSCLE: Strengthening Semi-Supervised Learning Via Concurrent Unsupervised Learning Using Mutual Information Maximization",
                "abstract": "Deep neural networks are powerful, massively parameterized machine learning models that have been shown to perform well in supervised learning tasks. However, very large amounts of labeled data are usually needed to train deep neural networks. Several semi-supervised learning approaches have been proposed to train neural networks using smaller amounts of labeled data with a large amount of unlabeled data. The performance of these semisupervised methods significantly degrades as the size of labeled data decreases. We introduce Mutual-information-based Unsupervised & Semi-supervised Concurrent LEarning (MUSCLE), a hybrid learning approach that uses mutual information to combine both unsupervised and semisupervised learning. MUSCLE can be used as a standalone training scheme for neural networks, and can also be incorporated into other learning approaches. We show that the proposed hybrid model outperforms state of the art on several standard benchmarks, including CIFAR-10, CIFAR-100, and Mini-Imagenet. Furthermore, the performance gain consistently increases with the reduction in the amount of labeled data, as well as in the presence of bias. We also show that MUSCLE has the potential to boost the classification performance when used in the fine-tuning phase for a model pre-trained only on unlabeled data.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2029877863",
                        "name": "Hanchen Xie"
                    },
                    {
                        "authorId": "1572148863",
                        "name": "Mohamed E. Hussein"
                    },
                    {
                        "authorId": "143728483",
                        "name": "A. Galstyan"
                    },
                    {
                        "authorId": "1404588675",
                        "name": "W. Abd-Almageed"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Meta-learning methods: We focus our initial experiments on protoypical-networks (PN) [25] which uses a non-parametric last layer solver, as Protonets is a highly competitive ML approach, and also has the benefit of training faster and with less memory than competitors such as SVM [17], Ridge Regression (RR) [3].",
                "validation and 20 test, and (ii) CIFAR-FS (cifar) [3] with an identical split but with 32\u00d7 32 images.",
                "Recently, last-layer meta-learning methods [3, 17, 21, 25] have gained popularity."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7faefdcbe864f82f70aa987ba4336e4bd9db273b",
                "externalIds": {
                    "ArXiv": "2011.14048",
                    "DBLP": "journals/corr/abs-2011-14048",
                    "MAG": "3107257231",
                    "CorpusId": 227228028
                },
                "corpusId": 227228028,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7faefdcbe864f82f70aa987ba4336e4bd9db273b",
                "title": "Is Support Set Diversity Necessary for Meta-Learning?",
                "abstract": "Meta-learning is a popular framework for learning with limited data in which an algorithm is produced by training over multiple few-shot learning tasks. For classification problems, these tasks are typically constructed by sampling a small number of support and query examples from a subset of the classes. While conventional wisdom is that task diversity should improve the performance of meta-learning, in this work we find evidence to the contrary: we propose a modification to traditional meta-learning approaches in which we keep the support sets fixed across tasks, thus reducing task diversity. Surprisingly, we find that not only does this modification not result in adverse effects, it almost always improves the performance for a variety of datasets and meta-learning methods. We also provide several initial analyses to understand this phenomenon. Our work serves to: (i) more closely investigate the effect of support set construction for the problem of meta-learning, and (ii) suggest a simple, general, and competitive baseline for few-shot learning.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "80366270",
                        "name": "Amrith Rajagopal Setlur"
                    },
                    {
                        "authorId": "33282601",
                        "name": "Oscar Li"
                    },
                    {
                        "authorId": "145260024",
                        "name": "Virginia Smith"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8b1a09189acaa09e3a3da8507800ce5ed44a61f6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2011-12527",
                    "ArXiv": "2011.12527",
                    "MAG": "3108049163",
                    "DOI": "10.1007/s10489-022-04072-4",
                    "CorpusId": 227162430
                },
                "corpusId": 227162430,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/8b1a09189acaa09e3a3da8507800ce5ed44a61f6",
                "title": "Match them up: visually explainable few-shot image classification",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2153213890",
                        "name": "Bowen Wang"
                    },
                    {
                        "authorId": "47681301",
                        "name": "Liangzhi Li"
                    },
                    {
                        "authorId": "1840437995",
                        "name": "Manisha Verma"
                    },
                    {
                        "authorId": "1789677",
                        "name": "Yuta Nakashima"
                    },
                    {
                        "authorId": "1738501775",
                        "name": "R. Kawasaki"
                    },
                    {
                        "authorId": "144829054",
                        "name": "H. Nagahara"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Here, distancebased approaches [3, 21, 34, 39, 40, 49, 64, 67, 70, 73, 80, 84, 87] aim at transferring the reduced intra-class variation from base to novel classes, while initialization-based approaches [18, 19, 35] are designed to carry the best starting model configuration for novel class training."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c38af920ef584336a9b3b454165f6b4116459fbf",
                "externalIds": {
                    "DBLP": "conf/iccv/AfrasiyabiLG21",
                    "ArXiv": "2011.11872",
                    "DOI": "10.1109/ICCV48922.2021.00891",
                    "CorpusId": 237154257
                },
                "corpusId": 237154257,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/c38af920ef584336a9b3b454165f6b4116459fbf",
                "title": "Mixture-based Feature Space Learning for Few-shot Image Classification",
                "abstract": "We introduce Mixture-based Feature Space Learning (MixtFSL) for obtaining a rich and robust feature representation in the context of few-shot image classification. Previous works have proposed to model each base class either with a single point or with a mixture model by relying on offline clustering algorithms. In contrast, we propose to model base classes with mixture models by simultaneously training the feature extractor and learning the mixture model parameters in an online manner. This results in a richer and more discriminative feature space which can be employed to classify novel examples from very few samples. Two main stages are proposed to train the MixtFSL model. First, the multimodal mixtures for each base class and the feature extractor parameters are learned using a combination of two loss functions. Second, the resulting network and mixture models are progressively refined through a leader-follower learning procedure, which uses the current estimate as a \"target\" network. This target network is used to make a consistent assignment of instances to mixture components, which increases performance and stabilizes training. The effectiveness of our end-to-end feature space learning approach is demonstrated with extensive experiments on four standard datasets and four backbones. Notably, we demon-strate that when we combine our robust representation with recent alignment-based approaches, we achieve new state-of-the-art results in the inductive setting, with an absolute accuracy for 5-shot classification of 82.45% on miniImageNet, 88.20% with tieredImageNet, and 60.70% in FC100 using the ResNet-12 backbone.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "9050817",
                        "name": "Arman Afrasiyabi"
                    },
                    {
                        "authorId": "144430305",
                        "name": "Jean-Fran\u00e7ois Lalonde"
                    },
                    {
                        "authorId": "11146706",
                        "name": "Christian Gagn'e"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Here, distance-based approaches [3, 17, 28, 32, 33, 43, 57, 59, 62, 65, 72, 75, 78] aim at transferring the reduced intra-class variation from base to novel classes, while initialization-based approaches [14, 15, 29] are designed to carry the best starting model configuration for novel class training."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6f4ab58e523eb3360cf2695467c009d484e1e2f6",
                "externalIds": {
                    "MAG": "3107141709",
                    "DBLP": "journals/corr/abs-2011-11872",
                    "CorpusId": 227151795
                },
                "corpusId": 227151795,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6f4ab58e523eb3360cf2695467c009d484e1e2f6",
                "title": "Persistent Mixture Model Networks for Few-Shot Image Classification",
                "abstract": "We introduce Persistent Mixture Model (PMM) networks for representation learning in the few-shot image classification context. While previous methods represent classes with a single centroid or rely on post hoc clustering methods, our method learns a mixture model for each base class jointly with the data representation in an end-to-end manner. The PMM training algorithm is organized into two main stages: 1) initial training and 2) progressive following. First, the initial estimate for multi-component mixtures is learned for each class in the base domain using a combination of two loss functions (competitive and collaborative). The resulting network is then progressively refined through a leader-follower learning procedure, which uses the current estimate of the learner as a fixed \"target\" network. This target network is used to make a consistent assignment of instances to mixture components, in order to increase performance while stabilizing the training. The effectiveness of our joint representation/mixture learning approach is demonstrated with extensive experiments on four standard datasets and four backbones. In particular, we demonstrate that when we combine our robust representation with recent alignment- and margin-based approaches, we achieve new state-of-the-art results in the inductive setting, with an absolute accuracy for 5-shot classification of 82.45% on miniImageNet, 88.20% with tieredImageNet, and 60.70% in FC100, all using the ResNet-12 backbone.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "9050817",
                        "name": "Arman Afrasiyabi"
                    },
                    {
                        "authorId": "144430305",
                        "name": "Jean-Fran\u00e7ois Lalonde"
                    },
                    {
                        "authorId": "11146706",
                        "name": "Christian Gagn'e"
                    }
                ]
            }
        },
        {
            "contexts": [
                "4) FC 100 [3] is also derived from CIFAR100 [26].",
                "3) CIFAR FS [3] is a few-shot learning dataset that contains all 100 classes from CIFAR100 [26]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b73b130084c20349d84f9fca5588a33688658d36",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2011-10082",
                    "ArXiv": "2011.10082",
                    "MAG": "3110241708",
                    "DOI": "10.1109/CVPRW56347.2022.00308",
                    "CorpusId": 227119006
                },
                "corpusId": 227119006,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b73b130084c20349d84f9fca5588a33688658d36",
                "title": "Hybrid Consistency Training with Prototype Adaptation for Few-Shot Learning",
                "abstract": "Few-Shot Learning (FSL) aims to improve a model\u2019s generalization capability in low data regimes. Recent FSL works have made steady progress via metric learning, meta learning, representation learning, etc. However, FSL remains challenging due to the following longstanding difficulties. 1) The seen and unseen classes are disjoint, resulting in a distribution shift between training and testing. 2) During testing, labeled data of previously unseen classes is sparse, making it difficult to reliably extrapolate from labeled support examples to unlabeled query examples. To tackle the first challenge, we introduce Hybrid Consistency Training to jointly leverage two types of consistency: 1) interpolation consistency, which interpolates hidden features to imposes linear behavior locally, and 2) data augmentation consistency, which learns robust embeddings against sample variations. As for the second challenge, we use unlabeled examples to iteratively normalize features and adapt prototypes, as opposed to commonly used one-time update, for more reliable prototype-based transductive inference. We show that our method generates a 2% to 5% improvement over the state-of-the-art methods with similar backbones on five FSL datasets and, more notably, a 7% to 8% improvement for more challenging cross-domain FSL.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2054892429",
                        "name": "Meng Ye"
                    },
                    {
                        "authorId": "2117690187",
                        "name": "Xiaoyu Lin"
                    },
                    {
                        "authorId": "69919463",
                        "name": "Giedrius Burachas"
                    },
                    {
                        "authorId": "47977519",
                        "name": "Ajay Divakaran"
                    },
                    {
                        "authorId": "1400198856",
                        "name": "Yi Yao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b349e66296c735f8aef3d42a9663d5933cf03c01",
                "externalIds": {
                    "DBLP": "journals/ml/AkrourAP21",
                    "ArXiv": "2011.07016",
                    "MAG": "3106033135",
                    "DOI": "10.1007/s10994-021-06037-z",
                    "CorpusId": 226955804
                },
                "corpusId": 226955804,
                "publicationVenue": {
                    "id": "22c9862f-a25e-40cd-9d31-d09e68a293e6",
                    "name": "Machine-mediated learning",
                    "type": "journal",
                    "alternate_names": [
                        "Mach learn",
                        "Machine Learning",
                        "Mach Learn"
                    ],
                    "issn": "0732-6718",
                    "alternate_issns": [
                        "0885-6125"
                    ],
                    "url": "http://www.springer.com/computer/artificial/journal/10994",
                    "alternate_urls": [
                        "https://link.springer.com/journal/10994",
                        "http://www.springer.com/west/home/computer/artificial?SGWID=4-147-70-35726603-0"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b349e66296c735f8aef3d42a9663d5933cf03c01",
                "title": "Convex optimization with an interpolation-based projection and its application to deep learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1688702",
                        "name": "R. Akrour"
                    },
                    {
                        "authorId": "3197790",
                        "name": "Asma Atamna"
                    },
                    {
                        "authorId": "145197867",
                        "name": "Jan Peters"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In metatest stage, these models are evaluated in the same way their authors originally did [4,2,13,14].",
                "In the experiment, we build our method on the top of several state-of-the-art meta-learning methods, including Prototypical Network, Matching Network, Prototypical Matching Network and Ridge Regression Differentiable Discriminator [4,2,13,14].",
                "state-of-the-art meta-learning algorithms as our base meta-learning methods in our experiments: Prototypical Network (PN) [2], Matching Network (MN) [4], Prototype Matching Network (PMN) [13] and Ridge Regression Differentiable Discriminator (R2D2) [14].",
                "The same setting is also mentioned in other mainstream few-shot methods [14].",
                "We evaluate the models using query sets and support sets constructed in the same way as their authors originally did [4,2,13,14]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "9203ed7fee251daee748567756a79189c620bbe8",
                "externalIds": {
                    "ArXiv": "2011.03154",
                    "DBLP": "journals/corr/abs-2011-03154",
                    "MAG": "3103007561",
                    "DOI": "10.1007/978-3-030-67661-2_42",
                    "CorpusId": 226278346
                },
                "corpusId": 226278346,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/9203ed7fee251daee748567756a79189c620bbe8",
                "title": "Confusable Learning for Large-class Few-Shot Classification",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "38953293",
                        "name": "B. Li"
                    },
                    {
                        "authorId": "2087238859",
                        "name": "Bo Han"
                    },
                    {
                        "authorId": "1734347",
                        "name": "Zhuowei Wang"
                    },
                    {
                        "authorId": "1746594",
                        "name": "Jing Jiang"
                    },
                    {
                        "authorId": "2062835",
                        "name": "Guodong Long"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "40fa7d87dff59a8461e47bfd10b333ca9f19e554",
                "externalIds": {
                    "DOI": "10.1109/ICIBA50161.2020.9276759",
                    "CorpusId": 229310107
                },
                "corpusId": 229310107,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/40fa7d87dff59a8461e47bfd10b333ca9f19e554",
                "title": "A Matching Network Focusing on the Relation between Samples",
                "abstract": "Deep learning plays an important role in the field of artificial intelligence, but in most situation, deep learning requires a larger number of training samples to complete high-precision learning. Few-shot learning, which only uses a small dataset to learn different tasks, has been extensively researched. It can be summarized into three methods: metric learning, optimization-based and model-based. In this paper, we develop a novel method based on Matching Networks: focusing on the relation between samples. We have proposed a simple method based on the idea that we can aggregate intra-class samples and separate inter-class samples. Our experiments on the Omniglot dataset and miniImageNet dataset show that our method outperforms the baseline networks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "7818635",
                        "name": "Jieqiong Zhao"
                    },
                    {
                        "authorId": "1419534171",
                        "name": "Fei Gao"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", [37, 5]) is that we only have a single source task and a single target task.",
                "[5] speeds up the implementation of MAML [10] with closed-form solution of the inner loop, which is a technique that we also use."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "50c4cd99d0a1c8d8ab6f78254d90acf4cef84b74",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2011-01418",
                    "ArXiv": "2011.01418",
                    "MAG": "3095523169",
                    "CorpusId": 226237562
                },
                "corpusId": 226237562,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/50c4cd99d0a1c8d8ab6f78254d90acf4cef84b74",
                "title": "Meta-learning Transferable Representations with a Single Target Domain",
                "abstract": "Recent works found that fine-tuning and joint training---two popular approaches for transfer learning---do not always improve accuracy on downstream tasks. First, we aim to understand more about when and why fine-tuning and joint training can be suboptimal or even harmful for transfer learning. We design semi-synthetic datasets where the source task can be solved by either source-specific features or transferable features. We observe that (1) pre-training may not have incentive to learn transferable features and (2) joint training may simultaneously learn source-specific features and overfit to the target. Second, to improve over fine-tuning and joint training, we propose Meta Representation Learning (MeRLin) to learn transferable features. MeRLin meta-learns representations by ensuring that a head fit on top of the representations with target training data also performs well on target validation data. We also prove that MeRLin recovers the target ground-truth model with a quadratic neural net parameterization and a source distribution that contains both transferable and source-specific features. On the same distribution, pre-training and joint training provably fail to learn transferable features. MeRLin empirically outperforms previous state-of-the-art transfer learning algorithms on various real-world vision and NLP transfer learning benchmarks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2118903632",
                        "name": "Hong Liu"
                    },
                    {
                        "authorId": "134168070",
                        "name": "Jeff Z. HaoChen"
                    },
                    {
                        "authorId": "3460405",
                        "name": "Colin Wei"
                    },
                    {
                        "authorId": "1901958",
                        "name": "Tengyu Ma"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Such popularity led to a surge of MAML-based variants [2, 3, 9, 10, 11, 13, 14, 25, 26, 27, 30, 37, 39, 41, 42, 44], where they try to resolve the known issues of MAML, such as (meta-level) overfitting.",
                "[3]) on miniImageNet and tieredImageNet, along with comparisons to the other state-of-the-art metalearning algorithms for few-shot learning.",
                "Following this trend, many recent studies [3, 9, 11, 30, 39, 41] focused on learning a better initialization.",
                "46% MAML + L2F [3] 4-CONV 52.",
                "This makes learning tasks from new different domains difficult, as suggested in [3]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "5484768e507217f5959a03041ee81547353fb5e5",
                "externalIds": {
                    "MAG": "3097892290",
                    "DBLP": "conf/nips/BaikCCKL20",
                    "ArXiv": "2011.00209",
                    "CorpusId": 226227266
                },
                "corpusId": 226227266,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/5484768e507217f5959a03041ee81547353fb5e5",
                "title": "Meta-Learning with Adaptive Hyperparameters",
                "abstract": "Despite its popularity, several recent works question the effectiveness of MAML when test tasks are different from training tasks, thus suggesting various task-conditioned methodology to improve the initialization. Instead of searching for better task-aware initialization, we focus on a complementary factor in MAML framework, inner-loop optimization (or fast adaptation). Consequently, we propose a new weight update rule that greatly enhances the fast adaptation process. Specifically, we introduce a small meta-network that can adaptively generate per-step hyperparameters: learning rate and weight decay coefficients. The experimental results validate that the Adaptive Learning of hyperparameters for Fast Adaptation (ALFA) is the equally important ingredient that was often neglected in the recent few-shot learning approaches. Surprisingly, fast adaptation from random initialization with ALFA can already outperform MAML.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "148009160",
                        "name": "Sungyong Baik"
                    },
                    {
                        "authorId": "83500873",
                        "name": "Myungsub Choi"
                    },
                    {
                        "authorId": "9535762",
                        "name": "Janghoon Choi"
                    },
                    {
                        "authorId": "48206011",
                        "name": "Heewon Kim"
                    },
                    {
                        "authorId": "2135837",
                        "name": "Kyoung Mu Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Differentiable convex optimization: Recent works have considered the meta-learning setup of differentiating through a convex solver in the setting of few-shot learning Bertinetto et al. (2018); Lee et al. (2019b)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8212605d274d5e68bcedf990728f4f5c26f88168",
                "externalIds": {
                    "MAG": "3097629404",
                    "DBLP": "journals/corr/abs-2011-00050",
                    "ArXiv": "2011.00050",
                    "CorpusId": 226226438
                },
                "corpusId": 226226438,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/8212605d274d5e68bcedf990728f4f5c26f88168",
                "title": "Dataset Meta-Learning from Kernel Ridge-Regression",
                "abstract": "One of the most fundamental aspects of any machine learning algorithm is the training data used by the algorithm. We introduce the novel concept of $\\epsilon$-approximation of datasets, obtaining datasets which are much smaller than or are significant corruptions of the original training data while maintaining similar model performance. We introduce a meta-learning algorithm called Kernel Inducing Points (KIP) for obtaining such remarkable datasets, inspired by the recent developments in the correspondence between infinitely-wide neural networks and kernel ridge-regression (KRR). For KRR tasks, we demonstrate that KIP can compress datasets by one or two orders of magnitude, significantly improving previous dataset distillation and subset selection methods while obtaining state of the art results for MNIST and CIFAR-10 classification. Furthermore, our KIP-learned datasets are transferable to the training of finite-width neural networks even beyond the lazy-training regime, which leads to state of the art results for neural network dataset distillation with potential applications to privacy-preservation.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2116176847",
                        "name": "Timothy Nguyen"
                    },
                    {
                        "authorId": "2007548157",
                        "name": "Zhourung Chen"
                    },
                    {
                        "authorId": "49685832",
                        "name": "Jaehoon Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Other related work has attempted to devise loss functions to learn more transferable embeddings for few-shot learning [62, 65, 7, 15, 49], but embeddings of models trained with softmax cross-entropy often perform on par with these more sophisticated techniques [68]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "62bc27534e9915307acced33c1601b525af5281c",
                "externalIds": {
                    "DBLP": "conf/nips/KornblithCLN21",
                    "ArXiv": "2010.16402",
                    "CorpusId": 243755567
                },
                "corpusId": 243755567,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/62bc27534e9915307acced33c1601b525af5281c",
                "title": "Why Do Better Loss Functions Lead to Less Transferable Features?",
                "abstract": "Previous work has proposed many new loss functions and regularizers that improve test accuracy on image classification tasks. However, it is not clear whether these loss functions learn better representations for downstream tasks. This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. We show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks, and the choice of loss has little effect when networks are fully fine-tuned on the new tasks. Using centered kernel alignment to measure similarity between hidden representations of networks, we find that differences among loss functions are apparent only in the last few layers of the network. We delve deeper into representations of the penultimate layer, finding that different objectives and hyperparameter combinations lead to dramatically different levels of class separation. Representations with higher class separation obtain higher accuracy on the original task, but their features are less useful for downstream tasks. Our results suggest there exists a trade-off between learning invariant features for the original task and features relevant for transfer tasks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "40464924",
                        "name": "Simon Kornblith"
                    },
                    {
                        "authorId": "145358498",
                        "name": "Ting Chen"
                    },
                    {
                        "authorId": "2118338545",
                        "name": "Honglak Lee"
                    },
                    {
                        "authorId": "144739074",
                        "name": "Mohammad Norouzi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We specifically run each experiment setting with the three popular representation learning protocols - ProtoNet [21], Ridge [24] and MetaOptNet (SVM) [23].",
                "We consider three popular approaches from the robust-representation view of the meta-learning paradigm, termed ProtoNet [21], Ridge [24] and MetaOptNet [23].",
                "Task classifier could be a nearest neighbour (ProtoNet [21]), linear regression (Ridge [24]) or linear SVM (MetaOptNet [23]).",
                "Generally, max-margin classifiers such as SVM tend to outperform nearest neighbor distance based approaches, we find\n(a) Fluent Speech Commands (b) Google Commands\nFigure 3: The confusion matrix is mean computed for 5-shot classification task over 1000 test episodes.\nthat the performance of ProtoNet is often superior to SVM. Similarly, a closed-form solution of Ridge may be more sensitive to noise than ProtoNet leading to lower performance.",
                "Google Commands Fluent Speech Commands 5-Shot 1-Shot 5-Shot 1-ShotModel\nSPO No-SPO SPO No-SPO SPO No-SPO SPO No-SPO Val 85.45 \u00b1 0.32 83.48 \u00b1 0.35 71.07 \u00b1 0.52 70.61 \u00b1 0.53 83.55 \u00b1 0.38 68.57 \u00b1 0.45 70.42 \u00b1 0.55 56.14 \u00b1 0.56ProtoNet [21] Test 89.63 \u00b1 0.27 78.86 \u00b1 0.40 74.35 \u00b1 0.50 69.30 \u00b1 0.54 78.86 \u00b1 0.40 78.00 \u00b1 0.39 65.61 \u00b1 0.52 64.24 \u00b1 0.52 Val 82.38 \u00b1 0.34 81.33 \u00b1 0.35 68.49 \u00b1 0.51 68.03 \u00b1 0.51 81.47 \u00b1 0.39 67.75 \u00b1 0.42 70.56 \u00b1 0.51 56.69 \u00b1 0.55Ridge [24] Test 89.11 \u00b1 0.29 86.17 \u00b1 0.31 75.05 \u00b1 0.48 76.34 \u00b1 0.49 75.75 \u00b1 0.40 78.51 \u00b1 0.39 61.64 \u00b1 0.53 60.84 \u00b1 0.51 Val 76.31 \u00b1 0.39 83.48 \u00b1 0.35 62.90 \u00b1 0.51 60.50 \u00b1 0.51 78.52 \u00b1 0.43 65.90 \u00b1 0.46 67.68 \u00b1 0.53 52.77 \u00b1 0.53MetaOptNet [23] Test 84.37 \u00b1 0.32 88.64 \u00b1 0.29 66.61 \u00b1 0.53 70.82 \u00b1 0.50 70.16 \u00b1 0.43 69.84 \u00b1 0.44 58.71 \u00b1 0.50 59.44 \u00b1 0.51\nis trained with all the available training data in an end-to-end fashion.",
                "Task independent learning, or learning to learn is a popular paradigm of machine learning termed meta-learning [22, 18, 23, 24, 21, 25]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0fce84981cfff147ed2c022001be51779d99808f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-15238",
                    "MAG": "3096277532",
                    "ArXiv": "2106.15238",
                    "DOI": "10.21437/Interspeech.2020-3208",
                    "CorpusId": 226202230
                },
                "corpusId": 226202230,
                "publicationVenue": {
                    "id": "af90489e-312f-4514-bea2-bcb399cb8ece",
                    "name": "Interspeech",
                    "type": "conference",
                    "alternate_names": [
                        "Conf Int Speech Commun Assoc",
                        "INTERSPEECH",
                        "Conference of the International Speech Communication Association"
                    ],
                    "issn": "2308-457X",
                    "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech",
                    "alternate_urls": [
                        "http://www.isca-speech.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0fce84981cfff147ed2c022001be51779d99808f",
                "title": "Representation Based Meta-Learning for Few-Shot Spoken Intent Recognition",
                "abstract": "Spoken intent detection has become a popular approach to interface with various smart devices with ease. However, such systems are limited to the preset list of intents-terms or commands, which restricts the quick customization of personal devices to new intents. This paper presents a few-shot spoken intent classification approach with task-agnostic representations via meta-learning paradigm. Specifically, we leverage the popular representation-based meta-learning learning to build a task-agnostic representation of utterances, that then use a linear classifier for prediction. We evaluate three such approaches on our novel experimental protocol developed on two popular spoken intent classification datasets: Google Commands and the Fluent Speech Commands dataset. For a 5-shot (1-shot) classification of novel classes, the proposed framework provides an average classification accuracy of 88.6% (76.3%) on the Google Commands dataset, and 78.5% (64.2%) on the Fluent Speech Commands dataset. The performance is comparable to traditionally supervised classification models with abundant training samples.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "3441349",
                        "name": "Ashish R. Mittal"
                    },
                    {
                        "authorId": "34173298",
                        "name": "Samarth Bharadwaj"
                    },
                    {
                        "authorId": "3064586",
                        "name": "Shreya Khare"
                    },
                    {
                        "authorId": "27604943",
                        "name": "Saneem A. Chemmengath"
                    },
                    {
                        "authorId": "145590185",
                        "name": "K. Sankaranarayanan"
                    },
                    {
                        "authorId": "144707379",
                        "name": "Brian Kingsbury"
                    }
                ]
            }
        },
        {
            "contexts": [
                "42% on the 5-way 1-shot setting, surpassing the second best R2D2 [4] by 1.",
                "Datasets and settings We evaluate our model on four standard few-shot classification tasks: miniImageNet [71], tieredImageNet [53], CIFAR-FS [4] and Omniglot [33].",
                "The third group explicitly learns a base-learner that incorporates knowledge acquired by the meta-learner and effectively solves individual tasks [20, 4, 81].",
                "On CIFAR-FS, our model delivers 63.42% on the 5-way 1-shot setting, surpassing the second best R2D2 [4] by 1.12%."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "4695c4c84dc9cda08b7fce804fbd71bc00263f97",
                "externalIds": {
                    "MAG": "3102374825",
                    "DBLP": "conf/nips/ZhenDXQS020",
                    "ArXiv": "2010.10341",
                    "CorpusId": 224803849
                },
                "corpusId": 224803849,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/4695c4c84dc9cda08b7fce804fbd71bc00263f97",
                "title": "Learning to Learn Variational Semantic Memory",
                "abstract": "In this paper, we introduce variational semantic memory into meta-learning to acquire long-term knowledge for few-shot learning. The variational semantic memory accrues and stores semantic information for the probabilistic inference of class prototypes in a hierarchical Bayesian framework. The semantic memory is grown from scratch and gradually consolidated by absorbing information from tasks it experiences. By doing so, it is able to accumulate long-term, general knowledge that enables it to learn new concepts of objects. We formulate memory recall as the variational inference of a latent memory variable from addressed contents, which offers a principled way to adapt the knowledge to individual tasks. Our variational semantic memory, as a new long-term memory module, confers principled recall and update mechanisms that enable semantic information to be efficiently accrued and adapted for few-shot learning. Experiments demonstrate that the probabilistic modelling of prototypes achieves a more informative representation of object classes compared to deterministic vectors. The consistent new state-of-the-art performance on four benchmarks shows the benefit of variational semantic memory in boosting few-shot recognition.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "34798935",
                        "name": "Xiantong Zhen"
                    },
                    {
                        "authorId": "46941376",
                        "name": "Yingjun Du"
                    },
                    {
                        "authorId": "2054473409",
                        "name": "Huan Xiong"
                    },
                    {
                        "authorId": "2077648",
                        "name": "Qiang Qiu"
                    },
                    {
                        "authorId": "145404204",
                        "name": "Cees G. M. Snoek"
                    },
                    {
                        "authorId": "144082425",
                        "name": "Ling Shao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(b) CIFAR-FS [19] has 100 object classes, split into 64, 16, and 20 for training, validation and test sets, respectively.",
                "Overall, our approach achieves faster convergence and performs better classification datasets, including miniImageNet, tieredImageNet, and CIFAR-FS.",
                "Similarly, on the CIFAR-FS dataset, our method achieves state-of-the-art performance compared to the family of MAML algorithms.",
                "Table 2 Few-shot learning results on CIFAR-FS [19] and tieredImageNet [20] datasets.",
                "Methods miniImageNet, 5-way CIFAR-FS, 5-way tieredImageNet, 5-way1-shot 5-shot 1-shot 5-shot 1-shot 5-shot\nMAML [5] 48.70 \u00b1 1.84 63.11 \u00b1 0.92 58.9 \u00b1 1.9 71.5 \u00b1 1.9 51.67 \u00b1 1.87 70.30 \u00b1 1.75 MAML++ [2] 52.15 \u00b1 0.26 68.32 \u00b1 0.44 - - FOMAML [5] 48.07 \u00b1 1.75 63.15 \u00b1 0.91 55.6 \u00b1 0.9 70.2 \u00b1 0.7 47.37 \u00b1 0.80 66.12 \u00b1 0.79 Reptile [14] 49.97 \u00b1 0.32 65.99 \u00b1 0.58 - - Meta-LSTM [17] 43.44 \u00b1 0.77 60.60 \u00b1 0.71 43.4 \u00b1 0.8 60.6 \u00b1 0.7 - - Meta-SGD [13] 50.47 \u00b1 1.87 64.03 \u00b1 0.94 56.9 \u00b1 0.9 70.1 \u00b1 0.7 50.92 \u00b1 0.93 69.28 \u00b1 0.80 iMAML-HF [16] 49.30 \u00b1 1.88 - - - MT-Net [12] 51.70 \u00b1 1.84 - - - R2D2 [3] 49.50 \u00b1 0.20 65.40 \u00b1 0.20 62.3 \u00b1 0.2 77.4 \u00b1 0.2 - - L-MAML [4] 49.40 \u00b1 1.83 - - - HSML [22] 50.38 \u00b1 1.85 - - -\nPAMELA 53.50 \u00b1 0.89 70.51 \u00b1 0.67 63.5 \u00b1 0.9 79.1 \u00b1 0.7 54.81 \u00b1 0.88 74.39 \u00b1 0.71\nFigure 3: Few-shot learning results on miniImageNet [17], CIFAR-FS [3] and tieredImageNet [18] datasets.",
                "For experiments on miniImageNet, CIFAR-FS and tieredImageNet, we use a four-layer convolutional neural network, each with 64 filters."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "d1ce1416b77c637c247771d4b704213725271d4f",
                "externalIds": {
                    "ArXiv": "2010.09291",
                    "DBLP": "conf/bmvc/Rajasegaran0HKS21a",
                    "MAG": "3093147807",
                    "CorpusId": 224705408
                },
                "corpusId": 224705408,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/d1ce1416b77c637c247771d4b704213725271d4f",
                "title": "Meta-learning the Learning Trends Shared Across Tasks",
                "abstract": "Meta-learning stands for 'learning to learn' such that generalization to new tasks is achieved. Among these methods, Gradient-based meta-learning algorithms are a specific sub-class that excel at quick adaptation to new tasks with limited data. This demonstrates their ability to acquire transferable knowledge, a capability that is central to human learning. However, the existing meta-learning approaches only depend on the current task information during the adaptation, and do not share the meta-knowledge of how a similar task has been adapted before. To address this gap, we propose a 'Path-aware' model-agnostic meta-learning approach. Specifically, our approach not only learns a good initialization for adaptation, it also learns an optimal way to adapt these parameters to a set of task-specific parameters, with learnable update directions, learning rates and, most importantly, the way updates evolve over different time-steps. Compared to the existing meta-learning methods, our approach offers: (a) The ability to learn gradient-preconditioning at different time-steps of the inner-loop, thereby modeling the dynamic learning behavior shared across tasks, and (b) The capability of aggregating the learning context through the provision of direct gradient-skip connections from the old time-steps, thus avoiding overfitting and improving generalization. In essence, our approach not only learns a transferable initialization, but also models the optimal update directions, learning rates, and task-specific learning trends. Specifically, in terms of learning trends, our approach determines the way update directions shape up as the task-specific learning progresses and how the previous update history helps in the current update. Our approach is simple to implement and demonstrates faster convergence. We report significant performance improvements on a number of FSL datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "32548363",
                        "name": "Jathushan Rajasegaran"
                    },
                    {
                        "authorId": "152973423",
                        "name": "Salman Hameed Khan"
                    },
                    {
                        "authorId": "145684318",
                        "name": "Munawar Hayat"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "145103012",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We combined training data generating networks with two meta learning approaches (R2D2 (Bertinetto et al., 2019) and MetaOptNet (Lee et al.",
                "However, as we discussed above, differentiable optimization methods (Bertinetto et al., 2019; Lee et al., 2019) are generally better than hypernetworks.",
                "(2)\nThis process is done by a base learner (machine learning algorithm) in some meta learning methods (Bertinetto et al., 2019; Lee et al., 2019).",
                "The formulation of few-shot learning we use here is similar to Lee et al. (2019); Bertinetto et al. (2019), but also other formulations of few shot learning exist, e.g., MAML (Finn et al., 2017).",
                "Recent meta learning approaches use differentiable learners, e.g., R2D2 (Bertinetto et al., 2019) uses Ridge Regression and MetaOptNet (Lee et al., 2019) uses Support Vector Machines (SVM).",
                "Different than the learner in R2D2 and MetaOptNet, we use kernelized algorithms.",
                "R2D2 (Bertinetto et al., 2019) showed that using a light-weight and differentiable base learner (e.",
                ", R2D2 (Bertinetto et al., 2019) uses Ridge Regression and MetaOptNet (Lee et al.",
                "We combined training data generating networks with two meta learning approaches (R2D2 (Bertinetto et al., 2019) and MetaOptNet (Lee et al., 2019)) in our framework.",
                "R2D2 (Bertinetto et al., 2019) showed that using a light-weight and differentiable base learner (e.g. ridge regression) leads to better results.",
                "(2) This process is done by a base learner (machine learning algorithm) in some meta learning methods (Bertinetto et al., 2019; Lee et al., 2019)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "97933bf50776a35e087078a00c21132ed3854690",
                "externalIds": {
                    "ArXiv": "2010.08276",
                    "DBLP": "conf/iclr/ZhangW22",
                    "CorpusId": 248476477
                },
                "corpusId": 248476477,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/97933bf50776a35e087078a00c21132ed3854690",
                "title": "Training Data Generating Networks: Shape Reconstruction via Bi-level Optimization",
                "abstract": "We propose a novel 3d shape representation for 3d shape reconstruction from a single image. Rather than predicting a shape directly, we train a network to generate a training set which will be fed into another learning algorithm to define the shape. The nested optimization problem can be modeled by bi-level optimization. Specifically, the algorithms for bi-level optimization are also being used in meta learning approaches for few-shot learning. Our framework establishes a link between 3D shape analysis and few-shot learning. We combine training data generating networks with bi-level optimization algorithms to obtain a complete framework for which all components can be jointly trained. We improve upon recent work on standard benchmarks for 3d shape reconstruction.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2129438190",
                        "name": "Biao Zhang"
                    },
                    {
                        "authorId": "1798011",
                        "name": "Peter Wonka"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Bertinetto et al. (2019) showed that using a light-weight and differentiable base learner (e.",
                "Bertinetto et al. (2019) showed that using a light-weight and differentiable base learner (e.g. ridge regression) leads to better results.",
                "Bertinetto et al. (2019) showed that using a light-weight and differentiable base learner (e.g. ridge regression) leads to better results. To further developing the idea, Lee et al. (2019) used multi-class support vector machine (Crammer & Singer (2001)) as base learner and incorporated differentiable optimization (Amos & Kolter (2017); Gould et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "b3db7f2f0e2455d336a0c13076389fc79c0149be",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2010-08276",
                    "MAG": "3093041308",
                    "CorpusId": 223953700
                },
                "corpusId": 223953700,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b3db7f2f0e2455d336a0c13076389fc79c0149be",
                "title": "Training Data Generating Networks: Linking 3D Shapes and Few-Shot Classification",
                "abstract": "We propose a novel 3d shape representation for 3d shape reconstruction from a single image. Rather than predicting a shape directly, we train a network to generate a training set which will be feed into another learning algorithm to define the shape. Training data generating networks establish a link between few-shot learning and 3d shape analysis. We propose a novel meta-learning framework to jointly train the data generating network and other components. We improve upon recent work on standard benchmarks for 3d shape reconstruction, but our novel shape representation has many applications.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2129438190",
                        "name": "Biao Zhang"
                    },
                    {
                        "authorId": "1798011",
                        "name": "Peter Wonka"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026to the parameters of the last linear layer of a neural network and \u03c6 are the parameters of the remaining layers (e.g., 4 convolutional layers in Bertinetto et al. 2018; Ji et al. 2020a), and hence the lowerlevel function is strongly-convex w.r.t. w\u0303 and the upper-level function LD(\u03c6, w\u0303\u2217(\u03c6))\u2026",
                "\u2026attention recently and become an influential framework in various machine learning applications including metalearning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyperparameter\n1Department of Electrical and Computer Engineering, The Ohio\u2026",
                "Bilevel optimization has received significant attention recently and become an influential framework in various machine learning applications including metalearning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyperparameter"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "51501cfe17a784fcb3610f235e97b0ee1738988c",
                "externalIds": {
                    "DBLP": "conf/icml/JiYL21",
                    "ArXiv": "2010.07962",
                    "CorpusId": 235825903
                },
                "corpusId": 235825903,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/51501cfe17a784fcb3610f235e97b0ee1738988c",
                "title": "Bilevel Optimization: Convergence Analysis and Enhanced Design",
                "abstract": "Bilevel optimization has arisen as a powerful tool for many machine learning problems such as meta-learning, hyperparameter optimization, and reinforcement learning. In this paper, we investigate the nonconvex-strongly-convex bilevel optimization problem. For deterministic bilevel optimization, we provide a comprehensive convergence rate analysis for two popular algorithms respectively based on approximate implicit differentiation (AID) and iterative differentiation (ITD). For the AID-based method, we orderwisely improve the previous convergence rate analysis due to a more practical parameter selection as well as a warm start strategy, and for the ITD-based method we establish the first theoretical convergence rate. Our analysis also provides a quantitative comparison between ITD and AID based approaches. For stochastic bilevel optimization, we propose a novel algorithm named stocBiO, which features a sample-efficient hypergradient estimator using efficient Jacobian- and Hessian-vector product computations. We provide the convergence rate guarantee for stocBiO, and show that stocBiO outperforms the best known computational complexities orderwisely with respect to the condition number $\\kappa$ and the target accuracy $\\epsilon$. We further validate our theoretical results and demonstrate the efficiency of bilevel optimization algorithms by the experiments on meta-learning and hyperparameter optimization.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "2110873724",
                        "name": "Junjie Yang"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026to the parameters of the last linear layer of a neural network and \u03c6 are the parameters of the remaining layers (e.g., 4 convolutional layers in Bertinetto et al. (2018); Ji et al. (2020a)), and hence the lower-level function is strongly-convex w.r.t. w\u0303 and the upper-level function LD(\u03c6,\u2026",
                "1 Introduction Bilevel optimization has received significant attention recently and become an influential framework in various machine learning applications including meta-learning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyper-parameter optimization (Franceschi et al.",
                "\u2026attention recently and become an influential framework in various machine learning applications including meta-learning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyper-parameter optimization (Franceschi et al., 2018; Shaban et al., 2019;\u2026"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "98b45649986a66d5ae5c4f34092879bfb442dc68",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2010-07962",
                    "MAG": "3092809425",
                    "CorpusId": 223953522
                },
                "corpusId": 223953522,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/98b45649986a66d5ae5c4f34092879bfb442dc68",
                "title": "Provably Faster Algorithms for Bilevel Optimization and Applications to Meta-Learning",
                "abstract": "Bilevel optimization has arisen as a powerful tool for many machine learning problems such as meta-learning, hyper-parameter optimization, reinforcement learning, etc. In this paper, we investigate the nonconvex-strongly-convex bilevel optimization problem, and propose two novel algorithms named deterBiO and stocBiO respectively for the deterministic and stochastic settings. At the core design of deterBiO is the construction of a low-cost and easy-to-implement hyper-gradient estimator via a simple back-propagation. In addition, stocBiO updates with the mini-batch data sampling rather than the existing single-sample schemes, where a sample-efficient Hessian inverse estimator is proposed. We provide the finite-time convergence guarantee for both algorithms, and show that they outperform the best known computational complexities orderwisely with respect to the condition number $\\kappa$ and/or the target accuracy $\\epsilon$. We further demonstrate the superior efficiency of the proposed algorithms by the experiments on meta-learning and hyper-parameter optimization.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "2110873724",
                        "name": "Junjie Yang"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "1 Introduction Bilevel optimization has received significant attention recently and become an influential framework in various machine learning applications including meta-learning (Franceschi et al., 2018; Bertinetto et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a), hyperparameter optimization (Franceschi et al.",
                ", 4 convolutional layers in Bertinetto et al. (2018); Ji et al."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1122c610287db5600ea862c4dbdc8d8e0ae2d678",
                "externalIds": {
                    "MAG": "3112047150",
                    "CorpusId": 227311261
                },
                "corpusId": 227311261,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1122c610287db5600ea862c4dbdc8d8e0ae2d678",
                "title": "Bilevel Optimization: Nonasymptotic Analysis and Faster Algorithms.",
                "abstract": "Bilevel optimization has arisen as a powerful tool for many machine learning problems such as meta-learning, hyperparameter optimization, and reinforcement learning. In this paper, we investigate the nonconvex-strongly-convex bilevel optimization problem. For deterministic bilevel optimization, we provide a comprehensive finite-time convergence analysis for two popular algorithms respectively based on approximate implicit differentiation (AID) and iterative differentiation (ITD). For the AID-based method, we orderwisely improve the previous finite-time convergence analysis due to a more practical parameter selection as well as a warm start strategy, and for the ITD-based method we establish the first theoretical convergence rate. Our analysis also provides a quantitative comparison between ITD and AID based approaches. For stochastic bilevel optimization, we propose a novel algorithm named stocBiO, which features a sample-efficient hypergradient estimator using efficient Jacobian- and Hessian-vector product computations. We provide the finite-time convergence guarantee for stocBiO, and show that stocBiO outperforms the best known computational complexities orderwisely with respect to the condition number $\\kappa$ and the target accuracy $\\epsilon$. We further validate our theoretical results and demonstrate the efficiency of bilevel optimization algorithms by the experiments on meta-learning and hyperparameter optimization. Our code for stocBiO and its comparison to other algorithms is available online$^1$.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "2110873724",
                        "name": "Junjie Yang"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We perform our experiments on the mini-ImageNet and CIFAR-FS datasets [2, 22].",
                "R2-D2 and MetaOptNet instead use differentiable solvers with a ridge regression and SVM head, respectively.",
                "As we increase m and include a large number of augmentations in the pool, we observe performance boosts as high as 4% over the baseline, which uses horizontal flip, random crop, and color jitter data augmentations from the original work corresponding to the R2-D2 meta-learner used [2].",
                "We empirically evaluate the performance of all four different augmentation modes identified in Section 3.1 on the CIFAR-FS dataset using an R2-D2 base-learner paired with both a 4-layer CNN backbone (as used in the original work) and a ResNet-12 backbone.",
                "To this end, we plot the training and validation accuracy over time for R2-D2 metalearners with ResNet-12 backbones using baseline augmentations, query Self-Mix, and Meta-MaxUp with a medium sized pool and m = 4.",
                "\u201cCNN-4\u201d denotes a 4-layer convolutional network with 96, 192, 384, and 512 filters in each layer [2].",
                "Existing frameworks for few-shot image classification use only horizontal flips, random crops, and color jitter to augment images in a way that parallels augmentation for conventional training [2, 14].",
                "We conduct experiments on four meta-learning algorithms: ProtoNet [21], R2-D2 [2], MetaOptNet [14], and MCT [13].",
                "In this section, we improve the performance of four different popular meta-learning methods including ProtoNet [21], R2-D2 [2], MetaOptNet [14], and MCT [13]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "03542a713c3b92bc09b3a9ccda20c84846910544",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2010-07092",
                    "MAG": "3092742756",
                    "ArXiv": "2010.07092",
                    "CorpusId": 222341683
                },
                "corpusId": 222341683,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/03542a713c3b92bc09b3a9ccda20c84846910544",
                "title": "Data Augmentation for Meta-Learning",
                "abstract": "Conventional image classifiers are trained by randomly sampling mini-batches of images. To achieve state-of-the-art performance, sophisticated data augmentation schemes are used to expand the amount of training data available for sampling. In contrast, meta-learning algorithms sample not only images, but classes as well. We investigate how data augmentation can be used not only to expand the number of images available per class, but also to generate entirely new classes. We systematically dissect the meta-learning pipeline and investigate the distinct ways in which data augmentation can be integrated at both the image and class levels. Our proposed meta-specific data augmentation significantly improves the performance of meta-learners on few-shot classification benchmarks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "3434279",
                        "name": "Renkun Ni"
                    },
                    {
                        "authorId": "121592562",
                        "name": "Micah Goldblum"
                    },
                    {
                        "authorId": "143816740",
                        "name": "Amr Sharaf"
                    },
                    {
                        "authorId": "80253287",
                        "name": "Kezhi Kong"
                    },
                    {
                        "authorId": "1962083",
                        "name": "T. Goldstein"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There is a line of works that analyzed the theoretical properties of meta-learning (Denevi et al., 2019; Finn et al., 2019; Khodak et al., 2019; Lee et al., 2019; Bertinetto et al., 2018)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "187a38944e3d9aa026136ef089f7d0ca5a69df2c",
                "externalIds": {
                    "ArXiv": "2010.06531",
                    "DBLP": "conf/iclr/YangHLD21",
                    "CorpusId": 233740346
                },
                "corpusId": 233740346,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/187a38944e3d9aa026136ef089f7d0ca5a69df2c",
                "title": "Impact of Representation Learning in Linear Bandits",
                "abstract": "We study how representation learning can improve the efficiency of bandit problems. We study the setting where we play $T$ linear bandits with dimension $d$ concurrently, and these $T$ bandit tasks share a common $k (\\ll d)$ dimensional linear representation. For the finite-action setting, we present a new algorithm which achieves $\\widetilde{O}(T\\sqrt{kN} + \\sqrt{dkNT})$ regret, where $N$ is the number of rounds we play for each bandit. When $T$ is sufficiently large, our algorithm significantly outperforms the naive algorithm (playing $T$ bandits independently) that achieves $\\widetilde{O}(T\\sqrt{d N})$ regret. We also provide an $\\Omega(T\\sqrt{kN} + \\sqrt{dkNT})$ regret lower bound, showing that our algorithm is minimax-optimal up to poly-logarithmic factors. Furthermore, we extend our algorithm to the infinite-action setting and obtain a corresponding regret bound which demonstrates the benefit of representation learning in certain regimes. We also present experiments on synthetic and real-world data to illustrate our theoretical findings and demonstrate the effectiveness of our proposed algorithms.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2144518437",
                        "name": "Jiaqi Yang"
                    },
                    {
                        "authorId": "1471043558",
                        "name": "Wei Hu"
                    },
                    {
                        "authorId": "2108327687",
                        "name": "Jason D. Lee"
                    },
                    {
                        "authorId": "145697585",
                        "name": "S. Du"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Moreover we report the results of ADKL (Tossou et al., 2019), R2-D2 (Bertinetto et al., 2019), and ALPaCA (Harrison et al., 2018) obtained on a similar task (as defined in Yoon et al., 2018).",
                ", 2019), R2-D2 (Bertinetto et al., 2019), and ALPaCA (Harrison et al.",
                "Method in-range out-of-range Periodic functions ADKL (Tossou et al., 2019)\u2217 0.14 \u2013 R2-D2 (Bertinetto et al., 2019)\u2217 0.46 \u2013 ALPaCA (Harrison et al., 2018) 0.14 \u00b1 0.09 5.92 \u00b1 0.11 Feature Transfer/1 2.94 \u00b1 0.16 6.13 \u00b1 0.76 Feature Transfer/100 2.67 \u00b1 0.15 6.94 \u00b1 0.97 MAML (1 step) 2.76 \u00b1 0.06 8.45 \u00b1 0.25 DKBaseline + RBF 2.85 \u00b1 1.14 3.65 \u00b1 1.63 DKBaseline + Spectral 2.08 \u00b1 2.31 4.11 \u00b1 1.92 DKT + RBF (ours) 1.38 \u00b1 0.03 2.61 \u00b1 0.16 DKT + Spectral (ours) 0.08 \u00b1 0.06 0.10 \u00b1 0.06 Head pose trajectory Feature Transfer/1 0.25 \u00b1 0.04 0.20 \u00b1 0.01 Feature Transfer/100 0.22 \u00b1 0.03 0.18 \u00b1 0.01 MAML (1 step) 0.21 \u00b1 0.01 0.18 \u00b1 0.02 DKT + RBF (ours) 0.12 \u00b1 0.04 0.14 \u00b1 0.03 DKT + Spectral (ours) 0.10 \u00b1 0.01 0.11 \u00b1 0.02\nWe consider two tasks: amplitude prediction for unknown periodic functions, and head pose trajectory estimation from images.",
                "Method in-range out-of-range Periodic functions ADKL (Tossou et al., 2019)\u2217 0.14 \u2013 R2-D2 (Bertinetto et al., 2019)\u2217 0.46 \u2013 ALPaCA (Harrison et al., 2018) 0.14 \u00b1 0.09 5.92 \u00b1 0.11 Feature Transfer/1 2.94 \u00b1 0.16 6.13 \u00b1 0.76 Feature Transfer/100 2.67 \u00b1 0.15 6.94 \u00b1 0.97 MAML (1 step) 2.76 \u00b1 0.06 8.45 \u00b1\u2026",
                "ADKL, R2-D2, and ALPaCA (0.14, 0.46, 0.14) are better than DKT with an RBF kernel (1.38), but worse than DKT with a Spectral kernel (0.08)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1ae1c18632d6d4d61b70c918354d633ce24c0bcd",
                "externalIds": {
                    "MAG": "3105036711",
                    "DBLP": "conf/nips/PatacchiolaTCOS20",
                    "CorpusId": 222317967
                },
                "corpusId": 222317967,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/1ae1c18632d6d4d61b70c918354d633ce24c0bcd",
                "title": "Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels",
                "abstract": "Recently, different machine learning methods have been introduced to tackle the challenging few-shot learning scenario that is, learning from a small labeled dataset related to a specific task. Common approaches have taken the form of meta-learning: learning to learn on the new problem given the old. Following the recognition that meta-learning is implementing learning in a multi-level model, we present a Bayesian treatment for the meta-learning inner loop through the use of deep kernels. As a result we can learn a kernel that transfers to new tasks; we call this Deep Kernel Transfer (DKT). This approach has many advantages: is straightforward to implement as a single optimizer, provides uncertainty quantification, and does not require estimation of task-specific parameters. We empirically demonstrate that DKT outperforms several state-of-the-art algorithms in few-shot classification, and is the state of the art for cross-domain adaptation and regression. We conclude that complex meta-learning routines can be replaced by a simpler Bayesian model without loss of accuracy.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "3366919",
                        "name": "Massimiliano Patacchiola"
                    },
                    {
                        "authorId": "31463533",
                        "name": "Jack Turner"
                    },
                    {
                        "authorId": "37120806",
                        "name": "Elliot J. Crowley"
                    },
                    {
                        "authorId": "1401533251",
                        "name": "M. O\u2019Boyle"
                    },
                    {
                        "authorId": "1728216",
                        "name": "A. Storkey"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There is a line of works analyzed the theoretical properties of meta-learning [Denevi et al., 2019; Finn et al., 2019; Khodak et al., 2019; Lee et al., 2019; Bertinetto et al., 2018]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2a538c79fa647e2b89b0376231c665711c212b7e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2010-06531",
                    "MAG": "3092940299",
                    "CorpusId": 222310112
                },
                "corpusId": 222310112,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2a538c79fa647e2b89b0376231c665711c212b7e",
                "title": "Provable Benefits of Representation Learning in Linear Bandits",
                "abstract": "We study how representation learning can improve the efficiency of bandit problems. We study the setting where we play $T$ linear bandits with dimension $d$ concurrently, and these $T$ bandit tasks share a common $k (\\ll d)$ dimensional linear representation. For the finite-action setting, we present a new algorithm which achieves $\\widetilde{O}(T\\sqrt{kN} + \\sqrt{dkNT})$ regret, where $N$ is the number of rounds we play for each bandit. When $T$ is sufficiently large, our algorithm significantly outperforms the naive algorithm (playing $T$ bandits independently) that achieves $\\widetilde{O}(T\\sqrt{d N})$ regret. We also provide an $\\Omega(T\\sqrt{kN} + \\sqrt{dkNT})$ regret lower bound, showing that our algorithm is minimax-optimal up to poly-logarithmic factors. Furthermore, we extend our algorithm to the infinite-action setting and obtain a corresponding regret bound which demonstrates the benefit of representation learning in certain regimes. We also present experiments on synthetic and real-world data to illustrate our theoretical findings and demonstrate the effectiveness of our proposed algorithms.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2144518437",
                        "name": "Jiaqi Yang"
                    },
                    {
                        "authorId": "1471043558",
                        "name": "Wei Hu"
                    },
                    {
                        "authorId": "2421201",
                        "name": "J. Lee"
                    },
                    {
                        "authorId": "145697585",
                        "name": "S. Du"
                    }
                ]
            }
        },
        {
            "contexts": [
                "2018), CIFAR-FS (Bertinetto et al. 2018), and FC100 (Oreshkin, L\u00f3pez, and Lacoste 2018) (See our Supplementary for more detailed introduction).",
                "For few-shot image classification, we conduct experiments on four public benchmark datasets: miniImageNet [Vinyals et al., 2016], tiered-ImageNet [Ren et al., 2018], CIFAR-FS [Bertinetto et al., 2018], and FC100 [Oreshkin et al., 2018].",
                "Compared to Meta-Base [Chen et al., 2020], our Meta-UAFS achieves significant improvement of 1.12%, 1.41%, 1.72%, and 1.76% in 1-shot accuracy on mini-ImageNet, tiered-ImageNet, CIFAR-FS, and FC00, respectively for 1-shot classification."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2f4b931f7e913d0e46c0860c6962fa6ac06bc6b7",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2010-04525",
                    "MAG": "3092196051",
                    "ArXiv": "2010.04525",
                    "DOI": "10.24963/ijcai.2021/471",
                    "CorpusId": 222272104
                },
                "corpusId": 222272104,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/2f4b931f7e913d0e46c0860c6962fa6ac06bc6b7",
                "title": "Uncertainty-Aware Few-Shot Image Classification",
                "abstract": "Few-shot image classification learns to recognize new categories from limited labelled data. Metric learning based approaches have been widely investigated, where a query sample is classified by finding the nearest prototype from the support set based on their feature similarities. A neural network has different uncertainties on its calculated similarities of different pairs. Understanding and modeling the uncertainty on the similarity could promote the exploitation of limited samples in few-shot optimization. In this work, we propose Uncertainty-Aware Few-Shot framework for image classification by modeling uncertainty of the similarities of query-support pairs and performing uncertainty-aware optimization. Particularly, we exploit such uncertainty by converting observed similarities to probabilistic representations and incorporate them to the loss for more effective optimization. In order to jointly consider the similarities between a query and the prototypes in a support set, a graph-based model is utilized to estimate the uncertainty of the pairs. Extensive experiments show our proposed method brings significant improvements on top of a strong baseline and achieves the state-of-the-art performance.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1486397342",
                        "name": "Zhizheng Zhang"
                    },
                    {
                        "authorId": "40093162",
                        "name": "Cuiling Lan"
                    },
                    {
                        "authorId": "1634494276",
                        "name": "Wenjun Zeng"
                    },
                    {
                        "authorId": "31482866",
                        "name": "Zhibo Chen"
                    },
                    {
                        "authorId": "9546964",
                        "name": "Shih-Fu Chang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Ridge regression differentiable discriminator (R2-D2) [5] is a neural network-based meta-learning method, where the last layer is adapted by solving a"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "846c6338d1c9604b531fdef3dfd0bd7bd7acff73",
                "externalIds": {
                    "ArXiv": "2010.04360",
                    "DBLP": "journals/ml/IwataT22",
                    "MAG": "3092016148",
                    "DOI": "10.1007/s10994-021-06118-z",
                    "CorpusId": 244088487
                },
                "corpusId": 244088487,
                "publicationVenue": {
                    "id": "22c9862f-a25e-40cd-9d31-d09e68a293e6",
                    "name": "Machine-mediated learning",
                    "type": "journal",
                    "alternate_names": [
                        "Mach learn",
                        "Machine Learning",
                        "Mach Learn"
                    ],
                    "issn": "0732-6718",
                    "alternate_issns": [
                        "0885-6125"
                    ],
                    "url": "http://www.springer.com/computer/artificial/journal/10994",
                    "alternate_urls": [
                        "https://link.springer.com/journal/10994",
                        "http://www.springer.com/west/home/computer/artificial?SGWID=4-147-70-35726603-0"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/846c6338d1c9604b531fdef3dfd0bd7bd7acff73",
                "title": "Few-shot learning for spatial regression via neural embedding-based Gaussian processes",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2664600",
                        "name": "Tomoharu Iwata"
                    },
                    {
                        "authorId": "143668549",
                        "name": "Yusuke Tanaka"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Lastly, R2-D2, LRD2 (Bertinetto et al., 2019), and Lee et al.",
                "CIFAR-FS (Bertinetto et al., 2019) and FC-100 (Oreshkin et al.",
                "The technique can also be applied to iterative solvers when the optimization steps are differentiable (Bertinetto et al., 2019).",
                "R2-D2/LR-D2 (Bertinetto et al. 2019) MetaOptNet (Lee et al.",
                "Many variants of the CIFAR data sets can be sampled, giving rise to e.g. CIFAR-FS (Bertinetto et\u00a0al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "332c44793b70776b9b966128c52e694222b1ab73",
                "externalIds": {
                    "ArXiv": "2010.03522",
                    "DBLP": "journals/corr/abs-2010-03522",
                    "MAG": "3092053846",
                    "DOI": "10.1007/s10462-021-10004-4",
                    "CorpusId": 222177134
                },
                "corpusId": 222177134,
                "publicationVenue": {
                    "id": "ea8553fe-2467-4367-afee-c4deb3754820",
                    "name": "Artificial Intelligence Review",
                    "type": "journal",
                    "alternate_names": [
                        "Artif Intell Rev"
                    ],
                    "issn": "0269-2821",
                    "url": "https://link.springer.com/journal/10462"
                },
                "url": "https://www.semanticscholar.org/paper/332c44793b70776b9b966128c52e694222b1ab73",
                "title": "A survey of deep meta-learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1990802181",
                        "name": "M. Huisman"
                    },
                    {
                        "authorId": "1405456902",
                        "name": "Jan N. van Rijn"
                    },
                    {
                        "authorId": "2562595",
                        "name": "A. Plaat"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Our method also achieves competitive few-shot classification performances on non fine-grained datasets such as CIFAR-FS[3] and mini-ImageNet[47, 35]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f976f4622a817e9d3460e7afaa15344f554812d1",
                "externalIds": {
                    "ArXiv": "2010.03255",
                    "DBLP": "conf/iccv/XuLHAS21",
                    "DOI": "10.1109/ICCV48922.2021.00869",
                    "CorpusId": 237295180
                },
                "corpusId": 237295180,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/f976f4622a817e9d3460e7afaa15344f554812d1",
                "title": "Variational Feature Disentangling for Fine-Grained Few-Shot Classification",
                "abstract": "Data augmentation is an intuitive step towards solving the problem of few-shot classification. However, ensuring both discriminability and diversity in the augmented samples is challenging. To address this, we propose a feature disentanglement framework that allows us to augment features with randomly sampled intra-class variations while preserving their class-discriminative features. Specifically, we disentangle a feature representation into two components: one represents the intra-class variance and the other encodes the class-discriminative information. We assume that the intra-class variance induced by variations in poses, backgrounds, or illumination conditions is shared across all classes and can be modelled via a common distribution. Then we sample features repeatedly from the learned intra-class variability distribution and add them to the class-discriminative features to get the augmented features. Such a data augmentation scheme ensures that the augmented features inherit crucial class-discriminative features while exhibiting large intra-class variance. Our method significantly outperforms the state-of-the-art methods on multiple challenging fine-grained few-shot image classification benchmarks. Code is available at: https://github.com/cvlab-stonybrook/vfd-iccv21",
                "year": 2020,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Jingyi Xu"
                    },
                    {
                        "authorId": "143631873",
                        "name": "Hieu M. Le"
                    },
                    {
                        "authorId": "1931660936",
                        "name": "Mingzhen Huang"
                    },
                    {
                        "authorId": "50989827",
                        "name": "ShahRukh Athar"
                    },
                    {
                        "authorId": "145654220",
                        "name": "D. Samaras"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b9ab72aaa08b39fc1592c7a6c8c9302299818bb9",
                "externalIds": {
                    "ArXiv": "2010.01992",
                    "DBLP": "conf/eccv/BouniotRALH22",
                    "DOI": "10.1007/978-3-031-20044-1_25",
                    "CorpusId": 251253441
                },
                "corpusId": 251253441,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/b9ab72aaa08b39fc1592c7a6c8c9302299818bb9",
                "title": "Improving Few-Shot Learning Through Multi-task Representation Learning Theory",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1845899848",
                        "name": "Quentin Bouniot"
                    },
                    {
                        "authorId": "145898069",
                        "name": "I. Redko"
                    },
                    {
                        "authorId": "2641858",
                        "name": "Romaric Audigier"
                    },
                    {
                        "authorId": "37995240",
                        "name": "Ang\u00e9lique Loesch"
                    },
                    {
                        "authorId": "1749327",
                        "name": "Amaury Habrard"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For a linear base network b\u03b8, this leads to a linear least squares ridge regression problem, as previously considered in a metalearning context [1].",
                "Recent works have explored closed form solutions [1] and implicit differentiation of the optimality conditions [15].",
                "Moreover, compared to MetaOptNetSVM [15] and R2D2 [1], our framework can utilize a wider class of objective functions, allowing us to integrate the nonconvex transductive objective (14) and also to meta-learn important parameters of the objective and the base learner itself.",
                "In few-shot classification, two types of approaches have been particularly successful, namely metric learning [30, 27, 28] and optimization-based [6, 23, 22, 15, 1].",
                "While the CIFAR-100 dataset is split based on the subclasses to derive the CIFAR-FS dataset; FC100, similar to tieredImageNet, splits CIFAR-100 based on superclasses to minimize semantic similarity.",
                "[1] utilize a closed-form solution of the base learner, formulated as a ridge regression problem.",
                "While achieving promising performance, both these works [15, 1] are restricted to specific types of task-specific models.",
                "Note that this configuration implies a linear ridge regression objective, similar to [1].",
                "Moreover, compared to MetaOptNetSVM [9] and R2D2 [10], our framework can utilize a wider class of objective functions, allowing us to integrate the non-convex transductive objective (5) and also to meta-learn important parameters of the objective and the base learner itself.",
                "Among the compared methods, R2D2 [1] and MetaOptNet-SVM [15] employ an optimization-based base learner that predicts the parameters of a linear classification head.",
                "CIFAR-100 Derivatives: Both, the CIFAR-FS [10] and the FC100 [26] benchmarks encompass the full CIFAR100 dataset [27].",
                "CIFAR-100 Derivatives: Both, the CIFAR-FS [1] and the FC100 [20] benchmarks encompass the full CIFAR-100 dataset [12].",
                "Among the compared methods, R2D2 [10] and MetaOptNet-SVM [9] employ an optimization-based base learner that predicts the parameters of a linear classification head.",
                "Our meta-learning approach follows the paradigm in [15, 1] by having two components: the base learner and a metalearner."
            ],
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "7ae1e2d6b06ddbeaf17f599296d60ce70b1201c1",
                "externalIds": {
                    "ArXiv": "2010.00511",
                    "DBLP": "journals/corr/abs-2010-00511",
                    "MAG": "3091291418",
                    "DOI": "10.1109/ICRA48506.2021.9561269",
                    "CorpusId": 222090384
                },
                "corpusId": 222090384,
                "publicationVenue": {
                    "id": "3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                    "name": "IEEE International Conference on Robotics and Automation",
                    "type": "conference",
                    "alternate_names": [
                        "International Conference on Robotics and Automation",
                        "Int Conf Robot Autom",
                        "ICRA",
                        "IEEE Int Conf Robot Autom"
                    ],
                    "issn": "2152-4092",
                    "alternate_issns": [
                        "2379-9544"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639",
                    "alternate_urls": [
                        "http://www.ncsu.edu/IEEE-RAS/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7ae1e2d6b06ddbeaf17f599296d60ce70b1201c1",
                "title": "Fast Few-Shot Classification by Few-Iteration Meta-Learning",
                "abstract": "Autonomous agents interacting with the real world need to learn new concepts efficiently and reliably. This requires learning in a low-data regime, which is a highly challenging problem. We address this task by introducing a fast optimization-based meta-learning method for few-shot classification. It consists of an embedding network, providing a general representation of the image, and a base learner module. The latter learns a linear classifier during the inference through an unrolled optimization procedure. We design an inner learning objective composed of (i) a robust classification loss on the support set and (ii) an entropy loss, allowing transductive learning from unlabeled query samples. By employing an efficient initialization module and a Steepest Descent based optimization algorithm, our base learner predicts a powerful classifier within only a few iterations. Further, our strategy enables important aspects of the base learner objective to be learned during meta-training. To the best of our knowledge, this work is the first to integrate both induction and transduction into the base learner in an optimization-based meta-learning framework. We perform a comprehensive experimental analysis, demonstrating the speed and effectiveness of our approach on four few-shot classification datasets. The Code is available at https://github.com/4rdhendu/FIML.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "3322337",
                        "name": "A. S. Tripathi"
                    },
                    {
                        "authorId": "2488938",
                        "name": "Martin Danelljan"
                    },
                    {
                        "authorId": "1681236",
                        "name": "L. Gool"
                    },
                    {
                        "authorId": "1732855",
                        "name": "R. Timofte"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "434d8baa964856bcf4bbe9d1bf49dc70ac2128ab",
                "externalIds": {
                    "DBLP": "conf/icip/PuriZP20",
                    "MAG": "3091617927",
                    "DOI": "10.1109/ICIP40778.2020.9190819",
                    "CorpusId": 211267004
                },
                "corpusId": 211267004,
                "publicationVenue": {
                    "id": "b6369c33-5d70-463c-8e82-95a54efa3cc8",
                    "name": "International Conference on Information Photonics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Image Process",
                        "ICIP",
                        "Int Conf Inf Photonics",
                        "International Conference on Image Processing"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/434d8baa964856bcf4bbe9d1bf49dc70ac2128ab",
                "title": "Few Shot Learning For Point Cloud Data Using Model Agnostic Meta Learning",
                "abstract": "The ability of deep neural networks to extract complex statistics and learn high level features from vast datasets is proven. Yet current deep learning approaches suffer from poor sample efficiency in stark contrast to human perception. Few shot learning algorithms such as matching networks or Model Agnostic Meta Learning (MAML) mitigate this problem, enabling fast learning with few examples. In this paper, we extend the MAML algorithm to point cloud data using a PointNet Architecture. We construct N$\\times$K-shot classification tasks from the ModelNet40 point cloud dataset to show that this method performs classification as well as supervised deep learning methods with the added benefit of being able to adapt after a single gradient step on a single N$\\times$K task. We empirically search for optimal values of N and K for few shot classification and show our method to achieve 90% meta test accuracy compared to traditional PointNet with 89.2%. We also adapt a meta-trained PointNet to a support set of 9, N=3, K=3, never before seen point clouds which are drawn from an entirely different dataset, ShapeNet. Once adapted the model achieves 7.1/9 classification accuracy on average across 100 query sets of the same classes with new, unique instances. This result far exceeds the supervised Stochastic Gradient Descent (SGD) training result of 3.1/9 accuracy on the query sets which is equivalent to a random baseline.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "144830538",
                        "name": "R. Puri"
                    },
                    {
                        "authorId": "1806989",
                        "name": "A. Zakhor"
                    },
                    {
                        "authorId": "41158993",
                        "name": "Raul Puri"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Meta-learning [2, 14, 24, 27, 30], within the context of image classification, addresses the problems of data scarcity and generalization, trying to mimic the learning process of humans in two aspects: 1) using few samples to learn a new task (i."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "707979120790684d9d80edb46cf5a50a8dd7e5ee",
                "externalIds": {
                    "DBLP": "conf/icb/Perez-CaboJCL20",
                    "DOI": "10.1109/IJCB48548.2020.9304920",
                    "CorpusId": 230997628
                },
                "corpusId": 230997628,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/707979120790684d9d80edb46cf5a50a8dd7e5ee",
                "title": "Learning to Learn Face-PAD: a lifelong learning approach",
                "abstract": "A face presentation attack detection (face-PAD) system is in charge of determining whether a face corresponds to a presentation attack or not. The vast majority of proposed solutions consider a static scenario, where models are trained and evaluated in datasets where all types of attacks and conditions are known beforehand. However, in a real-world scenario, the situation is very different. There, for instance, the types of attacks change over time, with new impersonation situations appearing for which little training data is available. In this paper we propose to tackle these problems presenting for the first time a con-tinuallearning framework for PAD. We introduce a continual meta-learning PAD solution that can be trained on new attack scenarios, following the continual few-shot learning paradigm, where the model uses only a small number of training samples. We also provide a thorough experimental evaluation using the GRAD-GPAD benchmark. Our results confirm the benefits of applying a continual meta-learning model to the real-world PAD scenario. Interestingly, the accuracy of our solution, which is continuously trained, where data from new attacks arrive sequentially, is capable of recovering the accuracy achieved by a traditional solution that has all the data from all possible attacks from the beginning. In addition, our experiments show that when these traditional PAD solutions are trained on new attacks, using a standard fine-tuning process, they suffer from catastrophic forgetting while our model does not.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1414113199",
                        "name": "Daniel P\u00e9rez-Cabo"
                    },
                    {
                        "authorId": "1414915707",
                        "name": "David Jim\u00e9nez-Cabello"
                    },
                    {
                        "authorId": "1405371609",
                        "name": "Artur Costa-Pazo"
                    },
                    {
                        "authorId": "1402973336",
                        "name": "R. L\u00f3pez-Sastre"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Unlike for instance, in few-shot classification [30, 4, 63] and tracking [5, 57], our learner constitutes an internal network module of a larger architecture.",
                "Optimization-based meta-learning: Our approach is related to optimization-based meta-learning [30, 4, 63, 5, 57]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "159b4ea469abb9ce06f9614bc359ae39734a6f83",
                "externalIds": {
                    "MAG": "3086189723",
                    "DBLP": "conf/nips/TruongDGT20",
                    "ArXiv": "2009.07823",
                    "CorpusId": 221738910
                },
                "corpusId": 221738910,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/159b4ea469abb9ce06f9614bc359ae39734a6f83",
                "title": "GOCor: Bringing Globally Optimized Correspondence Volumes into Your Neural Network",
                "abstract": "The feature correlation layer serves as a key neural network module in numerous computer vision problems that involve dense correspondences between image pairs. It predicts a correspondence volume by evaluating dense scalar products between feature vectors extracted from pairs of locations in two images. However, this point-to-point feature comparison is insufficient when disambiguating multiple similar regions in an image, severely affecting the performance of the end task. We propose GOCor, a fully differentiable dense matching module, acting as a direct replacement to the feature correlation layer. The correspondence volume generated by our module is the result of an internal optimization procedure that explicitly accounts for similar regions in the scene. Moreover, our approach is capable of effectively learning spatial matching priors to resolve further matching ambiguities. We analyze our GOCor module in extensive ablative experiments. When integrated into state-of-the-art networks, our approach significantly outperforms the feature correlation layer for the tasks of geometric matching, optical flow, and dense semantic matching. The code and trained models will be made available at this http URL.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "153399953",
                        "name": "Prune Truong"
                    },
                    {
                        "authorId": "2488938",
                        "name": "Martin Danelljan"
                    },
                    {
                        "authorId": "1681236",
                        "name": "L. Gool"
                    },
                    {
                        "authorId": "1732855",
                        "name": "R. Timofte"
                    }
                ]
            }
        },
        {
            "contexts": [
                "PASCAL5i (Shaban et al. 2017) is derived from PASCAL VOC 2012 (Everingham et al. 2010) and SBD (Hariharan et al. 2011)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6dc4e259d7d2fe0489dc6d200d78c69e4aec9f82",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2009-06680",
                    "ArXiv": "2009.06680",
                    "MAG": "3085401358",
                    "DOI": "10.1016/J.PATREC.2021.03.036",
                    "CorpusId": 221702971
                },
                "corpusId": 221702971,
                "publicationVenue": {
                    "id": "f35e3e87-9df4-497b-aa0d-bb8584197290",
                    "name": "Pattern Recognition Letters",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit Lett"
                    ],
                    "issn": "0167-8655",
                    "url": "https://www.journals.elsevier.com/pattern-recognition-letters/",
                    "alternate_urls": [
                        "http://www.journals.elsevier.com/pattern-recognition-letters/",
                        "http://www.sciencedirect.com/science/journal/01678655"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6dc4e259d7d2fe0489dc6d200d78c69e4aec9f82",
                "title": "SML: Semantic Meta-learning for Few-shot Semantic Segmentation",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "119040053",
                        "name": "Ayyappa Kumar Pambala"
                    },
                    {
                        "authorId": "30895384",
                        "name": "Titir Dutta"
                    },
                    {
                        "authorId": "2150472814",
                        "name": "S. Biswas"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e6fa5de538b53aeec78c3a39507f811195536e07",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2009-05786",
                    "ArXiv": "2009.05786",
                    "MAG": "3086526823",
                    "CorpusId": 221655479
                },
                "corpusId": 221655479,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e6fa5de538b53aeec78c3a39507f811195536e07",
                "title": "Few-shot Learning with LSSVM Base Learner and Transductive Modules",
                "abstract": "The performance of meta-learning approaches for few-shot learning generally depends on three aspects: features suitable for comparison, the classifier ( base learner ) suitable for low-data scenarios, and valuable information from the samples to classify. In this work, we make improvements for the last two aspects: 1) although there are many effective base learners, there is a trade-off between generalization performance and computational overhead, so we introduce multi-class least squares support vector machine as our base learner which obtains better generation than existing ones with less computational overhead; 2) further, in order to utilize the information from the query samples, we propose two simple and effective transductive modules which modify the support set using the query samples, i.e., adjusting the support samples basing on the attention mechanism and adding the prototypes of the query set with pseudo labels to the support set as the pseudo support samples. These two modules significantly improve the few-shot classification accuracy, especially for the difficult 1-shot setting. Our model, denoted as FSLSTM (Few-Shot learning with LSsvm base learner and Transductive Modules), achieves state-of-the-art performance on miniImageNet and CIFAR-FS few-shot learning benchmarks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2109293550",
                        "name": "Haoqing Wang"
                    },
                    {
                        "authorId": "123580511",
                        "name": "Zhihong Deng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "One of the motivations of introducing CIFAR-FS was that there was a gap in the challenge between training models in Omniglot and miniImageNet and that successfully training models in the latter took hours [3].",
                "This dataset consists of 20 images of each of its 1623 handwritten characters, which are usually augmented with four multiples of 90\u25e6 to obtain 1623\u00d7 4 = 6492 classes [34, 3, 32, 9].",
                "We use the increased number of episodes to compute 95% confidence intervals like previous work for few-shot multiclass classification [3, 20].",
                "The first modification is the replacement of CIFAR-10 by the CIFAR-FS dataset [3], a new split of CIFAR-100 for few-shot classification in which there is no class overlap between the training, validation and test sets.",
                "[34] by resizing the images to 28\u00d7 28 pixels, and using 4800 classes for training and 1692 for testing, which is nowadays standard in few-shot classification work [9, 32, 3]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1e5fcdd15f98463f9927764269ca1eff4bf18a49",
                "externalIds": {
                    "ArXiv": "2009.05353",
                    "MAG": "3086833091",
                    "DBLP": "journals/corr/abs-2009-05353",
                    "DOI": "10.3390/AI2020012",
                    "CorpusId": 221640639
                },
                "corpusId": 221640639,
                "publicationVenue": {
                    "id": "b76366f5-0af9-45f3-8fe3-78fdb0114f67",
                    "name": "Applied Informatics",
                    "type": "conference",
                    "alternate_names": [
                        "Appl Informatics",
                        "Advances Argumentation Artificial Intelligence",
                        "AI",
                        "Can Conf Artif Intell",
                        "Adv Argum Artif Intell",
                        "Canadian Conference on Artificial Intelligence"
                    ],
                    "issn": "2196-0089",
                    "alternate_issns": [
                        "2673-2688"
                    ],
                    "url": "http://cscsi.org/",
                    "alternate_urls": [
                        "https://link.springer.com/journal/40535",
                        "http://www.applied-informatics-j.com/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1e5fcdd15f98463f9927764269ca1eff4bf18a49",
                "title": "Meta Learning for Few-Shot One-class Classification",
                "abstract": "We propose a method that can perform one-class classification given only a small number of examples from the target class and none from the others. We formulate the learning of meaningful features for one-class classification as a meta-learning problem in which the meta-training stage repeatedly simulates one-class classification, using the classification loss of the chosen algorithm to learn a feature representation. To learn these representations, we require only multiclass data from similar tasks. We show how the Support Vector Data Description method can be used with our method, and also propose a simpler variant based on Prototypical Networks that obtains comparable performance, indicating that learning feature representations directly from data may be more important than which one-class algorithm we choose. We validate our approach by adapting few-shot classification datasets to the few-shot one-class classification scenario, obtaining similar results to the state-of-the-art of traditional one-class classification, and that improves upon that of one-class classification baselines employed in the few-shot setting.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "35590430",
                        "name": "Gabriel Dahia"
                    },
                    {
                        "authorId": "51954343",
                        "name": "Maur\u00edcio Pamplona Segundo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS (Bertinetto et al. 2019) is randomly sampled from CIFAR-100 (Krizhevsky, Hinton, and others 2009) by applying the same criteria in (Bertinetto et al. 2019) as same as MiniImageNet, which means we split the 100 classes to 64 classes for meta-training, 16 for meta-validation and 20 for\u2026",
                "CIFAR-FS (Bertinetto et al. 2019) is randomly sampled from CIFAR-100 (Krizhevsky, Hinton, and others 2009) by applying the same criteria in (Bertinetto et al. 2019) as same as MiniImageNet, which means we split the 100 classes to 64 classes for meta-training, 16 for meta-validation and 20 for meta-testing.",
                "2019) is randomly sampled from CIFAR-100 (Krizhevsky, Hinton, and others 2009) by applying the same criteria in (Bertinetto et al. 2019) as same as MiniImageNet, which means we split the 100 classes to 64 classes for meta-training, 16 for meta-validation and 20 for meta-testing.",
                "We will show the results of ablation experiments of other two datasets(CIFAR-FS and Stanford Dogs) in the supplementary materials.",
                "CIFAR-FS (Bertinetto et al. 2019) is randomly sampled from CIFAR-100 (Krizhevsky, Hinton, and others 2009) by applying the same criteria in (Bertinetto et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1e9fd84a073a3a391464ac788dfdb812f83644c2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2009-03558",
                    "ArXiv": "2009.03558",
                    "MAG": "3083866628",
                    "CorpusId": 221534255
                },
                "corpusId": 221534255,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/1e9fd84a073a3a391464ac788dfdb812f83644c2",
                "title": "Region Comparison Network for Interpretable Few-shot Image Classification",
                "abstract": "While deep learning has been successfully applied to many real-world computer vision tasks, training robust classifiers usually requires a large amount of well-labeled data. However, the annotation is often expensive and time-consuming. Few-shot image classification has thus been proposed to effectively use only a limited number of labeled examples to train models for new classes. Recent works based on transferable metric learning methods have achieved promising classification performance through learning the similarity between the features of samples from the query and support sets. However, rare of them explicitly considers the model interpretability, which can actually be revealed during the training phase. \nFor that, in this work, we propose a metric learning based method named Region Comparison Network (RCN), which is able to reveal how few-shot learning works as in a neural network as well as to find out specific regions that are related to each other in images coming from the query and support sets. Moreover, we also present a visualization strategy named Region Activation Mapping (RAM) to intuitively explain what our method has learned by visualizing intermediate variables in our network. We also present a new way to generalize the interpretability from the level of tasks to categories, which can also be viewed as a method to find the prototypical parts for supporting the final decision of our RCN. Extensive experiments on four benchmark datasets clearly show the effectiveness of our method over existing baselines.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1726787",
                        "name": "Z. Xue"
                    },
                    {
                        "authorId": "2055900",
                        "name": "Lixin Duan"
                    },
                    {
                        "authorId": "98280253",
                        "name": "Wen Li"
                    },
                    {
                        "authorId": "2118536691",
                        "name": "Lin Chen"
                    },
                    {
                        "authorId": "33642939",
                        "name": "Jiebo Luo"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "541431601e19546b1ed02bf1559b12644e2ed305",
                "externalIds": {
                    "DBLP": "journals/pr/LuGYZZ23",
                    "ArXiv": "2009.02653",
                    "DOI": "10.1016/j.patcog.2023.109480",
                    "CorpusId": 257219880
                },
                "corpusId": 257219880,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/541431601e19546b1ed02bf1559b12644e2ed305",
                "title": "A survey on machine learning from few samples",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1443782509",
                        "name": "Jiang Lu"
                    },
                    {
                        "authorId": "2925921",
                        "name": "Pinghua Gong"
                    },
                    {
                        "authorId": "144030870",
                        "name": "Jieping Ye"
                    },
                    {
                        "authorId": "2108092056",
                        "name": "Jianwei Zhang"
                    },
                    {
                        "authorId": "2115693994",
                        "name": "Changshu Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [159] 60,000 64/26/20 common objects",
                "They might parameterize the task-specific predictor in base learner [152], [153], [154], [157], [158], [159], [160], or the intermediate feature extraction layers in base learner [56], [150], [155], even or the whole base learner [151], [156].",
                "R2-D2 [159] ridge regression layer predictor weights",
                "Comparably, R2-D2 [159] adopted a differentiable ridge regression layer to parameterize the task-specific predictor, while MeteOptNet [160] advocated a differentiable convex optimization on SVM for generating final predictor weights."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "adc87d3235a05520f678caacce5557b91d8b8c3e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2009-02653",
                    "MAG": "3083228912",
                    "CorpusId": 221516873
                },
                "corpusId": 221516873,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/adc87d3235a05520f678caacce5557b91d8b8c3e",
                "title": "Learning from Very Few Samples: A Survey",
                "abstract": "Few sample learning (FSL) is significant and challenging in the field of machine learning. The capability of learning and generalizing from very few samples successfully is a noticeable demarcation separating artificial intelligence and human intelligence since humans can readily establish their cognition to novelty from just a single or a handful of examples whereas machine learning algorithms typically entail hundreds or thousands of supervised samples to guarantee generalization ability. Despite the long history dated back to the early 2000s and the widespread attention in recent years with booming deep learning technologies, little surveys or reviews for FSL are available until now. In this context, we extensively review 300+ papers of FSL spanning from the 2000s to 2019 and provide a timely and comprehensive survey for FSL. In this survey, we review the evolution history as well as the current progress on FSL, categorize FSL approaches into the generative model based and discriminative model based kinds in principle, and emphasize particularly on the meta learning based FSL approaches. We also summarize several recently emerging extensional topics of FSL and review the latest advances on these topics. Furthermore, we highlight the important FSL applications covering many research hotspots in computer vision, natural language processing, audio and speech, reinforcement learning and robotic, data analysis, etc. Finally, we conclude the survey with a discussion on promising trends in the hope of providing guidance and insights to follow-up researches.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1443782509",
                        "name": "Jiang Lu"
                    },
                    {
                        "authorId": "2925921",
                        "name": "Pinghua Gong"
                    },
                    {
                        "authorId": "2778556",
                        "name": "Jieping Ye"
                    },
                    {
                        "authorId": "14966740",
                        "name": "Changshui Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Then, they compare whether two images embeddings belong to the same class, based on different metrics, such as similarity functions [17], [20], [21], SVM classifiers [22] and ridge regression model [23]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "65fcffdc4cd6003b6dbfce55b4eb538e77563fd8",
                "externalIds": {
                    "DBLP": "conf/sdm/XuLLLT21",
                    "MAG": "3081534675",
                    "ArXiv": "2009.01672",
                    "DOI": "10.1137/1.9781611976700.61",
                    "CorpusId": 221664574
                },
                "corpusId": 221664574,
                "publicationVenue": {
                    "id": "316506ad-c672-4283-9b3e-3f126d973e85",
                    "name": "SDM",
                    "type": "conference",
                    "alternate_names": [
                        "SIAM Int Conf Data Min",
                        "Secur Data Manag (VLDB Workshop",
                        "SIAM nternational Conf Data Min",
                        "Secure Data Management (VLDB Workshop)",
                        "SIAM International Conference on Data Mining",
                        "SIAM nternational Conference on Data Mining"
                    ],
                    "issn": "0049-0016",
                    "url": "https://archive.siam.org/meetings/archives.php"
                },
                "url": "https://www.semanticscholar.org/paper/65fcffdc4cd6003b6dbfce55b4eb538e77563fd8",
                "title": "Yet Meta Learning Can Adapt Fast, It Can Also Break Easily",
                "abstract": "Meta learning algorithms have been widely applied in many tasks for efficient learning, such as few-shot image classification and fast reinforcement learning. During meta training, the meta learner develops a common learning strategy, or experience, from a variety of learning tasks. Therefore, during meta test, the meta learner can use the learned strategy to quickly adapt to new tasks even with a few training samples. However, there is still a dark side about meta learning in terms of reliability and robustness. In particular, is meta learning vulnerable to adversarial attacks? In other words, would a well-trained meta learner utilize its learned experience to build wrong or likely useless knowledge, if an adversary unnoticeably manipulates the given training set? Without the understanding of this problem, it is extremely risky to apply meta learning in safety-critical applications. Thus, in this paper, we perform the initial study about adversarial attacks on meta learning under the few-shot classification problem. In particular, we formally define key elements of adversarial attacks unique to meta learning and propose the first attacking algorithm against meta learning under various settings. We evaluate the effectiveness of the proposed attacking strategy as well as the robustness of several representative meta learning algorithms. Experimental results demonstrate that the proposed attacking strategy can easily break the meta learner and meta learning is vulnerable to adversarial attacks. The implementation of the proposed framework will be released upon the acceptance of this paper.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2018756699",
                        "name": "Han Xu"
                    },
                    {
                        "authorId": "2146673352",
                        "name": "Hui Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "2016) datasets with new results on CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, Rodr\u00edguez L\u00f3pez, and Lacoste 2018).",
                "For example, we could easily complement ANIL\u2019s (Raghu et al. 2019) original results on the Omniglot (Lake, Salakhutdinov, and Tenenbaum 2015) and mini-Imagenet (Vinyals et al. 2016) datasets with new results on CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, Rodr\u00edguez L\u00f3pez, and Lacoste 2018).",
                "\u2026example, we could easily complement ANIL\u2019s (Raghu et al. 2019) original results on the Omniglot (Lake, Salakhutdinov, and Tenenbaum 2015) and mini-Imagenet (Vinyals et al. 2016) datasets with new results on CIFAR-FS (Bertinetto et al. 2018) and FC100 (Oreshkin, Rodr\u00edguez L\u00f3pez, and Lacoste 2018)."
            ],
            "intents": [
                "methodology",
                "result"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c55cc603b74b8ba0cc58dbaa1d8df1af94ab934b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2008-12284",
                    "ArXiv": "2008.12284",
                    "MAG": "3080894165",
                    "CorpusId": 221341010
                },
                "corpusId": 221341010,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c55cc603b74b8ba0cc58dbaa1d8df1af94ab934b",
                "title": "learn2learn: A Library for Meta-Learning Research",
                "abstract": "Meta-learning researchers face two fundamental issues in their empirical work: prototyping and reproducibility. Researchers are prone to make mistakes when prototyping new algorithms and tasks because modern meta-learning methods rely on unconventional functionalities of machine learning frameworks. In turn, reproducing existing results becomes a tedious endeavour -- a situation exacerbated by the lack of standardized implementations and benchmarks. As a result, researchers spend inordinate amounts of time on implementing software rather than understanding and developing new ideas. \nThis manuscript introduces learn2learn, a library for meta-learning research focused on solving those prototyping and reproducibility issues. learn2learn provides low-level routines common across a wide-range of meta-learning techniques (e.g. meta-descent, meta-reinforcement learning, few-shot learning), and builds standardized interfaces to algorithms and benchmarks on top of them. In releasing learn2learn under a free and open source license, we hope to foster a community around standardized software for meta-learning research.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "16378659",
                        "name": "S\u00e9bastien M. R. Arnold"
                    },
                    {
                        "authorId": "48505466",
                        "name": "Praateek Mahajan"
                    },
                    {
                        "authorId": "2852125",
                        "name": "Debajyoti Datta"
                    },
                    {
                        "authorId": "1910466063",
                        "name": "Ian Bunner"
                    },
                    {
                        "authorId": "115451708",
                        "name": "Konstantinos Saitas Zarkias"
                    }
                ]
            }
        },
        {
            "contexts": [
                "5 Related Work MAML [5] is one of the most famous algorithms in gradient-based meta-learning, achieving a competitive performance on few-shot learning benchmark data sets [34, 26, 1, 23]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0f03582169599043a23e738a37a3aaa6c77dce43",
                "externalIds": {
                    "ArXiv": "2008.08882",
                    "DBLP": "journals/corr/abs-2008-08882",
                    "MAG": "3052486331",
                    "CorpusId": 221187086
                },
                "corpusId": 221187086,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/0f03582169599043a23e738a37a3aaa6c77dce43",
                "title": "Does MAML really want feature reuse only?",
                "abstract": "Meta-learning, the effort to solve new tasks with only a few samples, has attracted great attention in recent years. Model Agnostic Meta-Learning (MAML) is one of the most representative gradient-based meta-learning algorithms. MAML learns new tasks with a few data samples with inner updates from a meta-initialization point and learns the meta-initialization parameters with outer updates. Recently, it has been hypothesized that feature reuse, which makes little change in efficient representations, is the dominant factor in the performance of meta-initialized model through MAML rather than rapid learning, which makes a big change in representations. In this work, we propose a novel meta-learning algorithm, coined as BOIL (Body Only update in Inner Loop), that updates only the body (extractor) of the model and freezes the head (classifier) of the model during inner loop updates. The BOIL algorithm thus heavily relies on rapid learning. Note that BOIL is the opposite direction to the hypothesis that feature reuse is more efficient than rapid learning. We validate the BOIL algorithm on various data sets and show significant performance improvement over MAML. The results imply that rapid learning in gradient-based meta-learning approaches is necessary.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "46299565",
                        "name": "Jaehoon Oh"
                    },
                    {
                        "authorId": "2068859444",
                        "name": "Hyungjun Yoo"
                    },
                    {
                        "authorId": "2110273264",
                        "name": "ChangHwan Kim"
                    },
                    {
                        "authorId": "145317736",
                        "name": "Seyoung Yun"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We observe that ARCADe-H outperforms ARCADe-M on Omniglot, while ARCADe-M achieves higher retained accuracy on MiniImageNet and CIFAR-FS.",
                "The features meta-learned on the meta-training set of Omniglot, which includes by far more classes than the ones of MiniImageNet and CIFAR-FS, require less adaptation to perform well on the meta-testing set.",
                "For meta-testing task-sequence lengths between 1 and 100 are used for Omniglot and between 1 and 5 for the more challenging MiniImageNet and CIFAR-FS.",
                "CIFAR-FS was derived from CIFAR-100 by dividing its classes into 64\n1Our code is made public under: https://github.com/AhmedFrikha/ ARCADe-A-Rapid-Continual-Anomaly-Detector\nclasses for meta-training, 16 for meta-validation and 20 for meta-testing to make it suitable for meta-learning problems.",
                "We evaluate ARCADe on three meta-learning benchmark datasets: Omniglot [48], MiniImageNet [49] and CIFAR-FS [50].",
                "Our explanation for this is that since MiniImageNet and CIFAR-FS have a higher variance in the input space, adapting the parameters of the feature extractor to the normal classes of the test tasks is beneficial.",
                "We use task-sequences composed of 10 tasks for meta-training on Omniglot and 5 tasks for meta-training on MiniImageNet and CIFAR-FS.",
                "The performance of the two ARCADe variants and the baselines is shown in Figure 1 on Omniglot and in Figure 2 on MiniImageNet and CIFAR-FS."
            ],
            "intents": [],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "360af9318cc2cc92e11715d3bed781d06032c8c5",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2008-04042",
                    "ArXiv": "2008.04042",
                    "MAG": "3047632590",
                    "DOI": "10.1109/ICPR48806.2021.9412627",
                    "CorpusId": 221090209
                },
                "corpusId": 221090209,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/360af9318cc2cc92e11715d3bed781d06032c8c5",
                "title": "ARCADe: A Rapid Continual Anomaly Detector",
                "abstract": "Although continual learning and anomaly detection have separately been well-studied in previous works, their intersection remains rather unexplored. The present work addresses a learning scenario where a model has to incrementally learn a sequence of anomaly detection tasks, i.e. tasks from which only examples from the normal (majority) class are available for training. We define this novel learning problem of continual anomaly detection (CAD) and formulate it as a meta-learning problem. Moreover, we propose A Rapid Continual Anomaly Detector (ARCADe), an approach to train neural networks to be robust against the major challenges of this new learning problem, namely catastrophic forgetting and overfitting to the majority class. The results of our experiments on three datasets show that, in the CAD problem setting, ARCADe substantially outperforms baselines from the continual learning and anomaly detection literature. Finally, we provide deeper insights into the learning strategy yielded by the proposed meta-learning algorithm.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2560012",
                        "name": "A. Frikha"
                    },
                    {
                        "authorId": "2614774",
                        "name": "Denis Krompass"
                    },
                    {
                        "authorId": "1742501819",
                        "name": "Volker Tresp"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Some works have learned alternative training curricula [3] or modified the task specialisation [2,8].",
                "Prior works on meta-learning have not sought to exploit context, even when readily available [1,2,3,4,5,6,7,8,9,10,11,12,13].",
                "Few-shot Learning: Existing few-shot methods belong to one of three categories: generative approaches [17,18], embedding-based meta-learners [9,10,11] and adaptation-based meta-learners [1,2,3,4,5,6,7,8,12,13]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2eb62be675751ed2253434ffd01fca02af35e32e",
                "externalIds": {
                    "MAG": "3045669268",
                    "DBLP": "conf/accv/PerrettMBMD20",
                    "ArXiv": "2007.14658",
                    "DOI": "10.1007/978-3-030-69538-5_5",
                    "CorpusId": 220845958
                },
                "corpusId": 220845958,
                "publicationVenue": {
                    "id": "a8f26d13-e373-4e48-b57b-ef89bf48f4db",
                    "name": "Asian Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Asian Conf Comput Vis",
                        "ACCV"
                    ],
                    "url": "http://www.cvl.iis.u-tokyo.ac.jp/afcv/"
                },
                "url": "https://www.semanticscholar.org/paper/2eb62be675751ed2253434ffd01fca02af35e32e",
                "title": "Meta-Learning with Context-Agnostic Initialisations",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2682004",
                        "name": "Toby Perrett"
                    },
                    {
                        "authorId": "46185180",
                        "name": "A. Masullo"
                    },
                    {
                        "authorId": "1717278",
                        "name": "T. Burghardt"
                    },
                    {
                        "authorId": "1728108",
                        "name": "M. Mirmehdi"
                    },
                    {
                        "authorId": "145089978",
                        "name": "D. Damen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The meta-learner either learns to produce new parameters directly from the new data [9, 33, 56, 62, 64, 72, 73], or learns to produce an update rule to iteratively optimize the base learner to fit the new data [2, 6, 8, 38, 63, 97]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0fee1138854bd786697dcdb1f052b079d077b9e9",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2007-11498",
                    "MAG": "3044220283",
                    "ArXiv": "2007.11498",
                    "CorpusId": 220686825
                },
                "corpusId": 220686825,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0fee1138854bd786697dcdb1f052b079d077b9e9",
                "title": "CrossTransformers: spatially-aware few-shot transfer",
                "abstract": "Given new tasks with very little data$-$such as new classes in a classification problem or a domain shift in the input$-$performance of modern vision systems degrades remarkably quickly. In this work, we illustrate how the neural network representations which underpin modern vision systems are subject to supervision collapse, whereby they lose any information that is not necessary for performing the training task, including information that may be necessary for transfer to new tasks or domains. We then propose two methods to mitigate this problem. First, we employ self-supervised learning to encourage general-purpose features that transfer better. Second, we propose a novel Transformer based neural network architecture called CrossTransformers, which can take a small number of labeled images and an unlabeled query, find coarse spatial correspondence between the query and the labeled images, and then infer class membership by computing distances between spatially-corresponding features. The result is a classifier that is more robust to task and domain shift, which we demonstrate via state-of-the-art performance on Meta-Dataset, a recent dataset for evaluating transfer from ImageNet to many other vision datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2786693",
                        "name": "Carl Doersch"
                    },
                    {
                        "authorId": "2110759501",
                        "name": "Ankush Gupta"
                    },
                    {
                        "authorId": "1688869",
                        "name": "Andrew Zisserman"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Intuitively, it outperforms those with ResNet-12, especially on CIFAR-FS and miniImageNet.",
                "As detailed in TABLE I, in 1-shot and 5-shot test, our method achieves 10.04% and 4.67% improvement over Finetuning [32] on CIFAR-FS dataset.",
                "Our results demonstrate that MCRNet achieves state-of-the-art performance in classification tasks on three few-shot learning datasets including CIFAR-FS [21], FC100 [22], and miniImageNet [14], [23].",
                "FC100 is another dataset derived from CIFAR-100 and similar to CIFAR-FS.",
                "\u03c6 is a proportional optimizable parameter which has shown good performance in few-shot learning [21], [22] under conditions of SVM and RR as base-learners.",
                "CIFAR-FS is a new standard benchmark for few-shot learning tasks, consisting of 100 classes from CIFAR-100 [37]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "a77c2c0e58f8117ea59ec28d785b24be1485bc77",
                "externalIds": {
                    "MAG": "3044396630",
                    "DBLP": "journals/corr/abs-2007-10778",
                    "ArXiv": "2007.10778",
                    "DOI": "10.1109/ICPR48806.2021.9412416",
                    "CorpusId": 220665514
                },
                "corpusId": 220665514,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/a77c2c0e58f8117ea59ec28d785b24be1485bc77",
                "title": "Complementing Representation Deficiency in Few-shot Image Classification: A Meta-Learning Approach",
                "abstract": "Few-shot learning is a challenging problem that has attracted more and more attention recently since abundant training samples are difficult to obtain in practical applications. Meta-learning has been proposed to address this issue, which focuses on quickly adapting a predictor as a base-learner to new tasks, given limited labeled samples. However, a critical challenge for meta-learning is the representation deficiency since it is hard to discover common information from a small number of training samples or even one, as is the representation of key features from such little information. As a result, a meta-learner cannot be trained well in a high-dimensional parameter space to generalize to new tasks. Existing methods mostly resort to extracting less expressive features so as to avoid the representation deficiency. Aiming at learning better representations, we propose a meta-learning approach with complemented representations network (MCRNet) for few-shot image classification. In particular, we embed a latent space, where latent codes are reconstructed with extra representation information to complement the representation deficiency. Furthermore, the latent space is established with variational inference, collaborating well with different base-learners, and can be extended to other models. Finally, our end-to-end framework achieves the state-of-the-art performance in image classification on three standard few-shot learning datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "46812609",
                        "name": "X. Zhong"
                    },
                    {
                        "authorId": "2053399518",
                        "name": "Cheng Gu"
                    },
                    {
                        "authorId": "1500393994",
                        "name": "Wenxin Huang"
                    },
                    {
                        "authorId": "2109136926",
                        "name": "Lin Li"
                    },
                    {
                        "authorId": "2107926343",
                        "name": "Shuqin Chen"
                    },
                    {
                        "authorId": "46246806",
                        "name": "Chia-Wen Lin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f5215b22b12a90bcd9383b80b842385dad1e0d88",
                "externalIds": {
                    "DBLP": "journals/neco/HuLMPZ20",
                    "MAG": "3044221819",
                    "DOI": "10.1162/neco_a_01302",
                    "CorpusId": 220650635,
                    "PubMed": "32687772"
                },
                "corpusId": 220650635,
                "publicationVenue": {
                    "id": "69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                    "name": "Neural Computation",
                    "type": "journal",
                    "alternate_names": [
                        "Neural Comput"
                    ],
                    "issn": "0899-7667",
                    "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6720226",
                        "http://www.mitpressjournals.org/loi/neco",
                        "https://www.mitpressjournals.org/loi/neco"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f5215b22b12a90bcd9383b80b842385dad1e0d88",
                "title": "Fine-Grained 3D-Attention Prototypes for Few-Shot Learning",
                "abstract": "In the real world, a limited number of labeled finely grained images per class can hardly represent the class distribution effectively. Due to the more subtle visual differences in fine-grained images than simple images with obvious objects, that is, there exist smaller interclass and larger intraclass variations. To solve these issues, we propose an end-to-end attention-based model for fine-grained few-shot image classification (AFG) with the recent episode training strategy. It is composed mainly of a feature learning module, an image reconstruction module, and a label distribution module. The feature learning module mainly devises a 3D-Attention mechanism, which considers both the spatial positions and different channel attentions of the image features, in order to learn more discriminative local features to better represent the class distribution. The image reconstruction module calculates the mappings between local features and the original images. It is constrained by a designed loss function as auxiliary supervised information, so that the learning of each local feature does not need extra annotations. The label distribution module is used to predict the label distribution of a given unlabeled sample, and we use the local features to represent the image features for classification. By conducting comprehensive experiments on Mini-ImageNet and three fine-grained data sets, we demonstrate that the proposed model achieves superior performance over the competitors.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2110048361",
                        "name": "Xin Hu"
                    },
                    {
                        "authorId": "2155648333",
                        "name": "Jun Liu"
                    },
                    {
                        "authorId": "49304622",
                        "name": "Jie Ma"
                    },
                    {
                        "authorId": "1452348450",
                        "name": "Yudai Pan"
                    },
                    {
                        "authorId": "2145417611",
                        "name": "Lingling Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We adopt PN on the CIFAR-FS dataset and report the average training time for each epoch, which includes task sampling, forward and backward propagation phases.",
                "We show 16 classes of CIFAR-FS, where the green and red colors denote the classes sampled by random sampling and gcp-sampling, respectively.",
                "For example, PN with gcp-sampling outperforms the PN with ResNet-12 by around 1.84 and 1.2 percentage points in miniImageNet and 1.89 and 1.0 percentage points in CIFAR-FS.",
                "(3) We study the impact of the adaptive task sampling method by integrating it with various meta-learning approaches and performing comprehensive experiments on the miniImageNet and CIFAR-FS few-shot datasets, which quantitatively demonstrates the superior performance of our method.",
                "Secondly, CIFAR-FS is another recent few-shot image classification benchmark [6] constructed by randomly sampling from the CIFAR-100 dataset [25] using the same criteria as the miniImageNet, and has the same number of classes and samples.",
                "We demonstrate the evolution of class-pair potentials about 16 classes of CIFAR-FS dataset.",
                "We also use the 64 / 16 / 20 divisions for consistency with previous studies [6,28].",
                "Tables 1 and 2 present the 5-way 1-shot and 5- way 5-shot results on miniImageNet and CIFAR-FS datasets, respectively.",
                "In this section, we evaluate the proposed adaptive task sampling method on two fewshot classification benchmarks: miniImageNet [55] and CIFAR-FS [6]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "7177443fefc24c22c139a6ca22d3195e314dad57",
                "externalIds": {
                    "ArXiv": "2007.08735",
                    "DBLP": "conf/eccv/LiuWSFZH20",
                    "MAG": "3042330800",
                    "DOI": "10.1007/978-3-030-58523-5_44",
                    "CorpusId": 220633423
                },
                "corpusId": 220633423,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/7177443fefc24c22c139a6ca22d3195e314dad57",
                "title": "Adaptive Task Sampling for Meta-Learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2039481",
                        "name": "Chenghao Liu"
                    },
                    {
                        "authorId": "2128102841",
                        "name": "Zhihao Wang"
                    },
                    {
                        "authorId": "36187119",
                        "name": "Doyen Sahoo"
                    },
                    {
                        "authorId": "143844731",
                        "name": "Yuan Fang"
                    },
                    {
                        "authorId": "2119017233",
                        "name": "Kun Zhang"
                    },
                    {
                        "authorId": "1741126",
                        "name": "S. Hoi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Extensive experiments show that our simple approach achieves appealing performance on four widely used fewshot visual recognition benchmark datasets including miniImageNet, tieredImageNet, CIFAR-FS, and CUB.",
                "5), the norm of somewrongly-predicted instances (see the lowest\nTABLE 2 The Averaged Accuracies With 95 percent Confidence Intervals Over 2000 Episodes on Several Datasets\nSetting Model miniImageNet tieredImageNet CIFAR-FS CUB\n1shot 5shot 1shot 5shot 1shot 5shot 1shot 5shot\nIn. Baseline [20] 51.75 0:80 74.27 0:63 - - - - 65.51 0:87 82.85 0:55 Baseline++ [20] 51.87 0:77 75.68 0:63 - - - - 67.02 0:90 83.58 0:54 MatchingNet [10] 52:911 0:88 68:881 0:69 - - - - 72:361 0:90 83:641 0:60 ProtoNet [8] 54:161 0:82 73:681 0:65 - - 72:203 83:503 71:881 0:91 87:421 0:48 MAML [7] 49:611 0:92 65:721 0:77 - - - - 69:961 1:01 82:701 0:65 RelationNet [9] 52:481 0:86 69:831 0:68 - - - - 67:591 1:02 82:751 0:58 adaResNet [86] 56.88 71.94 - - - - - -\nTapNet [87] 61.65 76.36 63.08 80.26 - - - - CTMy [88] 64.12 80.51 68.41 84.28 - - - - MetaOptNet [82] 64.09 80.00 65.81 81.75 72.60 84.30 - -\nTran.",
                "(iv) Extensive experiments under two few-shot settings show the effectiveness of our approach on four widely used few-shot learning benchmark datasets including miniImageNet, tieredImageNet, CIFAR-FS, and CUB.",
                "Extensive experiments under two few-shot settings show the effectiveness of our approach on four widely used few-shot visual recognition benchmark datasets includingminiImageNet, tieredImageNet, CIFAR-FS, and CUB.",
                "Our experiments are conducted on four widely used few-shot learning benchmark datasets including miniImageNet [73], tieredImageNet [23], CIFAR-FS [74] and CUB [75]. miniImageNet2 consists of 100 classes with 600 labeled instances per category.",
                "Our experiments are conducted on four widely used few-shot learning benchmark datasets including miniImageNet [73], tieredImageNet [23], CIFAR-FS [74] and CUB [75].",
                "We follow the common split given by [74], using 64 classes to construct the base set, 16 for validation, and 20 as the novel set.",
                "CIFAR-FS5 is a dataset derived from CIFAR100 [78] with lower-resolution images."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "6acd9fae37a0337c7b9ce03e0568041d62eb68b1",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2007-08461",
                    "MAG": "3043160218",
                    "ArXiv": "2007.08461",
                    "DOI": "10.1109/TPAMI.2021.3086140",
                    "CorpusId": 220546017,
                    "PubMed": "34081579"
                },
                "corpusId": 220546017,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/6acd9fae37a0337c7b9ce03e0568041d62eb68b1",
                "title": "How to Trust Unlabeled Data? Instance Credibility Inference for Few-Shot Learning",
                "abstract": "Deep learning based models have excelled in many computer vision tasks and appear to surpass humans\u2019 performance. However, these models require an avalanche of expensive human labeled training data and many iterations to train their large number of parameters. This severely limits their scalability to the real-world long-tail distributed categories, some of which are with a large number of instances, but with only a few manually annotated. Learning from such extremely limited labeled examples is known as Few-Shot Learning (FSL). Different to prior arts that leverage meta-learning or data augmentation strategies to alleviate this extremely data-scarce problem, this paper presents a statistical approach, dubbed Instance Credibility Inference (ICI) to exploit the support of unlabeled instances for few-shot visual recognition. Typically, we repurpose the self-taught learning paradigm to predict pseudo-labels of unlabeled instances with an initial classifier trained from the few shot and then select the most confident ones to augment the training set to re-train the classifier. This is achieved by constructing a (Generalized) Linear Model (LM/GLM) with incidental parameters to model the mapping from (un-)labeled features to their (pseudo-)labels, in which the sparsity of the incidental parameters indicates the credibility of the corresponding pseudo-labeled instance. We rank the credibility of pseudo-labeled instances along the regularization path of their corresponding incidental parameters, and the most trustworthy pseudo-labeled examples are preserved as the augmented labeled instances. This process is repeated until all the unlabeled samples are included in the expanded training set. Theoretically, under the conditions of restricted eigenvalue, irrepresentability, and large error, our approach is guaranteed to collect all the correctly-predicted pseudo-labeled instances from the noisy pseudo-labeled set. Extensive experiments under two few-shot settings show the effectiveness of our approach on four widely used few-shot visual recognition benchmark datasets including miniImageNet, tieredImageNet, CIFAR-FS, and CUB. Code and models are released at https://github.com/Yikai-Wang/ICI-FSL.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2108853258",
                        "name": "Yikai Wang"
                    },
                    {
                        "authorId": "48459110",
                        "name": "Li Zhang"
                    },
                    {
                        "authorId": "1390925430",
                        "name": "Yuan Yao"
                    },
                    {
                        "authorId": "35782003",
                        "name": "Yanwei Fu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Different from existing methods [11], [40], where feature embedding is reshaped into one dimensional vector as the input of classifiers, we keep the spatial information in the feature map by leveraging the 3D feature map."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "31b863743536d6e648e220214345d35579582030",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2007-07614",
                    "ArXiv": "2007.07614",
                    "MAG": "3043745450",
                    "DOI": "10.1109/ICPR48806.2021.9412926",
                    "CorpusId": 220525513
                },
                "corpusId": 220525513,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/31b863743536d6e648e220214345d35579582030",
                "title": "Augmented Bi-path Network for Few-shot Learning",
                "abstract": "Few-shot Learning (FSL) which aims to learn from few labeled training data is becoming a popular research topic, due to the expensive labeling cost in many real-world applications. One kind of successful FSL method learns to compare the testing (query) image and training (support) image by simply concatenating the features of two images and feeding it into the neural network. However, with few labeled data in each class, the neural network has difficulty in learning or comparing the local features of two images. Such simple image-level comparison may cause serious mis-classification. To solve this problem, we propose Augmented Bi-path Network (ABNet) for learning to compare both global and local features on multi-scales. Specifically, the salient patches are extracted and embedded as the local features for every image. Then, the model learns to augment the features for better robustness. Finally, the model learns to compare global and local features separately, i.e., in two paths, before merging the similarities. Extensive experiments show that the proposed ABNet outperforms the state-of-the-art methods. Both quantitative and visual ablation studies are provided to verify that the proposed modules lead to more precise comparison results.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "50736086",
                        "name": "Baoming Yan"
                    },
                    {
                        "authorId": "2111169338",
                        "name": "Chenchao Zhou"
                    },
                    {
                        "authorId": "2116551935",
                        "name": "Bo Zhao"
                    },
                    {
                        "authorId": "2061501367",
                        "name": "Kan Guo"
                    },
                    {
                        "authorId": "2109761014",
                        "name": "Jiang Yang"
                    },
                    {
                        "authorId": "2109349122",
                        "name": "Xiaobo Li"
                    },
                    {
                        "authorId": "2118542045",
                        "name": "M. Zhang"
                    },
                    {
                        "authorId": "2116758319",
                        "name": "Yizhou Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To adapt to the regime of (very) small training datasets, optimization-based meta-learning techniques replace the vanilla SGD approach by a trainable update mechanism (Bertinetto et al., 2019; Finn et al., 2017; Ravi & Larochelle, 2017), e.",
                "\u2026of (very) small training datasets, optimization-based meta-learning techniques replace the vanilla SGD approach by a trainable update mechanism (Bertinetto et al., 2019; Finn et al., 2017; Ravi & Larochelle, 2017), e.g., by learning a parameter initialization, such that a small number of SGD\u2026"
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "efb50224dad4fb2df6b279c5c689510a33fb73ad",
                "externalIds": {
                    "MAG": "3034261620",
                    "DBLP": "conf/icml/IakovlevaVA20",
                    "ArXiv": "2008.12037",
                    "CorpusId": 221082336
                },
                "corpusId": 221082336,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/efb50224dad4fb2df6b279c5c689510a33fb73ad",
                "title": "Meta-Learning with Shared Amortized Variational Inference",
                "abstract": "We propose a novel amortized variational inference scheme for an empirical Bayes meta-learning model, where model parameters are treated as latent variables. We learn the prior distribution over model parameters conditioned on limited training data using a variational autoencoder approach. Our framework proposes sharing the same amortized inference network between the conditional prior and variational posterior distributions over the model parameters. While the posterior leverages both the labeled support and query data, the conditional prior is based only on the labeled support data. We show that in earlier work, relying on Monte-Carlo approximation, the conditional prior collapses to a Dirac delta function. In contrast, our variational approach prevents this collapse and preserves uncertainty over the model parameters. We evaluate our approach on the miniImageNet, CIFAR-FS and FC100 datasets, and present results demonstrating its advantages over previous work.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2082891969",
                        "name": "E. Iakovleva"
                    },
                    {
                        "authorId": "1721683",
                        "name": "J. Verbeek"
                    },
                    {
                        "authorId": "72492981",
                        "name": "Alahari Karteek"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026task by performing gradient descent on a very small number of labeled samples, and (ii) amortized-inference (Snell et al., 2017; Lee et al., 2019; Bertinetto et al., 2018) based approaches that directly infer the optimal parameters of a new task without performing any gradient based optimization.",
                "To the best of our knowledge none of the existing meta-learning algorithms like Bertinetto et al. (2018); Rajeswaran et al. (2019); Ravi & Beatson (2018); Finn et al. (2018) explicitly utilize the information present in the covariates to improve the estimate of the adapted parameters.",
                ", 2017) approaches that metalearn parameters of optimization algorithms (like initialization and learning rate) in a way that the meta-learner (optimizer) is amenable to quickly adapt on a new task by performing gradient descent on a very small number of labeled samples, and (ii) amortized-inference (Snell et al., 2017; Lee et al., 2019; Bertinetto et al., 2018) based approaches that directly infer the optimal parameters of a new task without performing any gradient based optimization."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "53386e474901ea8db5e2017ca97ebed7151617d6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2007-02523",
                    "ArXiv": "2007.02523",
                    "MAG": "3038568053",
                    "CorpusId": 220363812
                },
                "corpusId": 220363812,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/53386e474901ea8db5e2017ca97ebed7151617d6",
                "title": "Covariate Distribution Aware Meta-learning",
                "abstract": "Meta-learning has proven to be successful at few-shot learning across the regression, classification and reinforcement learning paradigms. Recent approaches have adopted Bayesian interpretations to improve gradient based meta-learners by quantifying the uncertainty of the post-adaptation estimates. Most of these works almost completely ignore the latent relationship between the covariate distribution (p(x)) of a task and the corresponding conditional distribution p(y|x). In this paper, we identify the need to explicitly model the meta-distribution over the task covariates in a hierarchical Bayesian framework. We begin by introducing a graphical model that explicitly leverages very few samples drawn from p(x) to better infer the posterior over the optimal parameters of the conditional distribution (p(y|x)) for each task. Based on this model we provide an inference strategy and a corresponding meta-algorithm that explicitly accounts for the meta-distribution over task covariates. Finally, we demonstrate the significant gains of our proposed algorithm on a synthetic regression dataset.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "80366270",
                        "name": "Amrith Rajagopal Setlur"
                    },
                    {
                        "authorId": "68972710",
                        "name": "Saket Dingliwal"
                    },
                    {
                        "authorId": "1719347",
                        "name": "B. P\u00f3czos"
                    }
                ]
            }
        },
        {
            "contexts": [
                "However, existing Transformer-based models are mainly used for tasks in natural language processing [4], and only a few studies investigate the use of Transformer in healthcare domain [20, 34]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "feedf27a69dc2dea851593eec20d4a3101cbc2ef",
                "externalIds": {
                    "DBLP": "conf/kdd/LuoYXM20",
                    "MAG": "3080098168",
                    "DOI": "10.1145/3394486.3403107",
                    "CorpusId": 221191314
                },
                "corpusId": 221191314,
                "publicationVenue": {
                    "id": "a0edb93b-1e95-4128-a295-6b1659149cef",
                    "name": "Knowledge Discovery and Data Mining",
                    "type": "conference",
                    "alternate_names": [
                        "KDD",
                        "Knowl Discov Data Min"
                    ],
                    "url": "http://www.acm.org/sigkdd/"
                },
                "url": "https://www.semanticscholar.org/paper/feedf27a69dc2dea851593eec20d4a3101cbc2ef",
                "title": "HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction on Electronic Health Records",
                "abstract": "Deep learning methods especially recurrent neural network based models have demonstrated early success in disease risk prediction on longitudinal patient data. Existing works follow a strong assumption to implicitly assume the stationary disease progression during each time period, and thus, take a homogeneous way to decay the information from previous time steps for all patients. However,in reality, disease progression is non-stationary. Besides, the key time steps for a target disease vary among patients. To leverage time information for risk prediction in a more reasonable way, we propose a new hierarchical time-aware attention network, named HiTANet, which imitates the decision making process of doctors inrisk prediction. Particularly, HiTANet models time information in local and global stages. The local evaluation stage has a time aware Transformer that embeds time information into visit-level embed-ding and generates local attention weight for each visit. The global synthesis stage further adopts a time-aware key-query attention mechanism to assign global weights to different time steps. Finally, the two types of attention weights are dynamically combined to generate the patient representations for further risk prediction. We evaluate HiTANet on three real-world datasets. Compared with the best results among twelve competing baselines, HiTANet achieves over 7% in terms of F1 score on all datasets, which demonstrates the effectiveness of the proposed model and the necessity of modeling time information in risk prediction task.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "48300263",
                        "name": "Junyu Luo"
                    },
                    {
                        "authorId": "1898157310",
                        "name": "Muchao Ye"
                    },
                    {
                        "authorId": "145781464",
                        "name": "Cao Xiao"
                    },
                    {
                        "authorId": "2988239",
                        "name": "Fenglong Ma"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "374913281fcb7b1a4bd74685cfca97c45d1eb9cf",
                "externalIds": {
                    "MAG": "3034360553",
                    "DBLP": "conf/ijcai/TianQDSG20",
                    "DOI": "10.24963/ijcai.2020/377",
                    "CorpusId": 220483100
                },
                "corpusId": 220483100,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/374913281fcb7b1a4bd74685cfca97c45d1eb9cf",
                "title": "Consistent MetaReg: Alleviating Intra-task Discrepancy for Better Meta-knowledge",
                "abstract": "In the few-shot learning scenario, the data-distribution discrepancy between training data and test data in a task usually exists due to the limited data. However, most existing meta-learning approaches seldom consider this intra-task discrepancy in the meta-training phase which might deteriorate the performance. To overcome this limitation, we develop a new consistent meta-regularization method to reduce the intra-task data-distribution discrepancy. Moreover, the proposed meta-regularization method could be readily inserted into existing optimization-based meta-learning models to learn better meta-knowledge. Particularly, we provide the theoretical analysis to prove that using the proposed meta-regularization, the conventional gradient-based meta-learning method can reach the lower regret bound. The extensive experiments also demonstrate the effectiveness of our method, which indeed improves the performances of the state-of-the-art gradient-based meta-learning models in the few-shot classification task.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "51305326",
                        "name": "Pinzhuo Tian"
                    },
                    {
                        "authorId": "1785352346",
                        "name": "Lei Qi"
                    },
                    {
                        "authorId": "23218185",
                        "name": "Shaokang Dong"
                    },
                    {
                        "authorId": "2475959",
                        "name": "Yinghuan Shi"
                    },
                    {
                        "authorId": "49658113",
                        "name": "Yang Gao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4cd9a3821b0ba23bc1d742f364a80800f2788681",
                "externalIds": {
                    "DBLP": "conf/ijcnn/ZhangQSYH20",
                    "MAG": "3090167728",
                    "DOI": "10.1109/IJCNN48605.2020.9206909",
                    "CorpusId": 221596575
                },
                "corpusId": 221596575,
                "publicationVenue": {
                    "id": "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                    "name": "IEEE International Joint Conference on Neural Network",
                    "type": "conference",
                    "alternate_names": [
                        "IJCNN",
                        "IEEE Int Jt Conf Neural Netw",
                        "Int Jt Conf Neural Netw",
                        "International Joint Conference on Neural Network"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=1573"
                },
                "url": "https://www.semanticscholar.org/paper/4cd9a3821b0ba23bc1d742f364a80800f2788681",
                "title": "RelationNet2: Deep Comparison Network for Few-Shot Learning",
                "abstract": "Few-shot deep learning is a topical challenge area for scaling visual recognition to open ended growth of unseen new classes with limited labeled examples. A promising approach is based on metric learning, which trains a deep embedding to support image similarity matching. Our insight is that effective general purpose matching requires non-linear comparison of features at multiple abstraction levels. We thus propose a new deep comparison network comprised of embedding and relation modules that learn multiple non-linear distance metrics based on different levels of features simultaneously. Furthermore, to reduce over-fitting and enable the use of deeper embeddings, we represent images as distributions rather than vectors via learning parameterized Gaussian noise regularization. The resulting network achieves excellent performance on both miniImageNet and tieredImageNet.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2108058854",
                        "name": "Xueting Zhang"
                    },
                    {
                        "authorId": "3387134",
                        "name": "Yuting Qiang"
                    },
                    {
                        "authorId": "40497013",
                        "name": "Flood Sung"
                    },
                    {
                        "authorId": "2653152",
                        "name": "Yongxin Yang"
                    },
                    {
                        "authorId": "1697755",
                        "name": "Timothy M. Hospedales"
                    }
                ]
            }
        },
        {
            "contexts": [
                "R2D2 [1] makes use of fast convergent methods like ridge regression for few-shot learning.",
                "Few-shot classification performance on the CIFAR-FS dataset are shown in Table 3.",
                "CIFAR-FS consists of 64 train, 16 validation, and 20 test classes with images of size 32\u00d7 32 pixels.",
                "We perform few-shot classification experiments on 4 benchmark datasets: mini-ImageNet [42], tiered-ImageNet [31], CIFAR-FS [1] and FC-100 [27].\nmini-ImageNet [42] consists of 100 classes, each of which has around 600 images of size 84 \u00d7 84 pixels.",
                "CIFAR-FS and Few-shot-CIFAR100 (FC-100) are both derived from CIFAR-100 [17] dataset.",
                "20% R2-D2 [1] (ICLR\u201919) Conv-4-512 51.",
                "20% R2-D2 [1] (ICLR\u201919) Conv-4-512 65.",
                "We perform few-shot classification experiments on 4 benchmark datasets: mini-ImageNet [42], tiered-ImageNet [31], CIFAR-FS [1] and FC-100 [27].",
                "We perform ablations to validate our transformation choices by using various combinations of transformations as the auxiliary task used along with RFS on the CIFAR-FS dataset with ResNet12 architecture."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1a1ba50403a2cc0006679515b1f5d7a06708ce7e",
                "externalIds": {
                    "DBLP": "conf/wacv/MazumderSN21",
                    "MAG": "3037051051",
                    "ArXiv": "2006.15919",
                    "DOI": "10.1109/WACV48630.2021.00270",
                    "CorpusId": 220250552
                },
                "corpusId": 220250552,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/1a1ba50403a2cc0006679515b1f5d7a06708ce7e",
                "title": "Improving Few-Shot Learning using Composite Rotation based Auxiliary Task",
                "abstract": "In this paper, we propose an approach to improve few-shot classification performance using a composite rotation based auxiliary task. Few-shot classification methods aim to produce neural networks that perform well for classes with a large number of training samples and classes with less number of training samples. They employ techniques to enable the network to produce highly discriminative features that are also very generic. Generally, the better the quality and generic-nature of the features produced by the network, the better is the performance of the network on few-shot learning. Our approach aims to train networks to produce such features by using a self-supervised auxiliary task. Our proposed composite rotation based auxiliary task performs rotation at two levels, i.e., rotation of patches inside the image (inner rotation) and rotation of the whole image (outer rotation) and assigns one out of 16 rotation classes to the modified image. We then simultaneously train for the composite rotation prediction task along with the original classification task, which forces the network to learn high-quality generic features that help improve the few-shot classification performance. We experimentally show that our approach performs better than existing few-shot learning methods on multiple benchmark datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "31222412",
                        "name": "Pratik Mazumder"
                    },
                    {
                        "authorId": "144377059",
                        "name": "Pravendra Singh"
                    },
                    {
                        "authorId": "145460361",
                        "name": "Vinay P. Namboodiri"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The last setting, reminiscent of (Franceschi et al., 2018; Bertinetto et al., 2019), concerns learning a (common) linear transformation of the data and is formulated as\nf(H) = 1\n2 \u2016X \u2032Hw(H)\u2212 y\u2032\u20162\nw(H) = argmin w\u2208Rd\n1 2 \u2016XHw \u2212 y\u20162 + \u03b2 2 \u2016w\u20162\nwhere H \u2208 Rp\u00d7d and \u03b2 \u2208 R++.\nLR and KRR are high\u2026",
                "The last setting, reminiscent of (Franceschi et al., 2018; Bertinetto et al., 2019), concerns learning a (common) linear transformation of the data and is formulated as"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bb140fe86d621ade83217cd6281e7bc075ed646a",
                "externalIds": {
                    "MAG": "3037674050",
                    "DBLP": "conf/icml/GrazziFPS20",
                    "ArXiv": "2006.16218",
                    "CorpusId": 220250381
                },
                "corpusId": 220250381,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/bb140fe86d621ade83217cd6281e7bc075ed646a",
                "title": "On the Iteration Complexity of Hypergradient Computation",
                "abstract": "We study a general class of bilevel problems, consisting in the minimization of an upper-level objective which depends on the solution to a parametric fixed-point equation. Important instances arising in machine learning include hyperparameter optimization, meta-learning, and certain graph and recurrent neural networks. Typically the gradient of the upper-level objective (hypergradient) is hard or even impossible to compute exactly, which has raised the interest in approximation methods. We investigate some popular approaches to compute the hypergradient, based on reverse mode iterative differentiation and approximate implicit differentiation. Under the hypothesis that the fixed point equation is defined by a contraction mapping, we present a unified analysis which allows for the first time to quantitatively compare these methods, providing explicit bounds for their iteration complexity. This analysis suggests a hierarchy in terms of computational efficiency among the above methods, with approximate implicit differentiation based on conjugate gradient performing best. We present an extensive experimental comparison among the methods which confirm the theoretical findings.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "51004518",
                        "name": "Riccardo Grazzi"
                    },
                    {
                        "authorId": "39883180",
                        "name": "Luca Franceschi"
                    },
                    {
                        "authorId": "1704699",
                        "name": "M. Pontil"
                    },
                    {
                        "authorId": "2212342",
                        "name": "Saverio Salzo"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Then, the circular correlation X ?WCF is equal to AWCF, and the filter WCF has the following closed-form solution [34], [56], [57]:"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4c249df6bf700dee4651e1f31194a432fb0805d1",
                "externalIds": {
                    "DBLP": "journals/tcsv/WangZTL21",
                    "ArXiv": "2006.10336",
                    "MAG": "3038946636",
                    "DOI": "10.1109/TCSVT.2020.3006110",
                    "CorpusId": 219792862
                },
                "corpusId": 219792862,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/4c249df6bf700dee4651e1f31194a432fb0805d1",
                "title": "Cascaded Regression Tracking: Towards Online Hard Distractor Discrimination",
                "abstract": "Visual can be easily disturbed by similar surrounding objects. Such objects as hard distractors, even though being the minority among negative samples, increase the risk of target drift and model corruption, which deserve additional attention in online tracking and model update. To enhance the tracking robustness, in this paper, we propose a cascaded regression tracker with two sequential stages. In the first stage, we filter out abundant easily-identified negative candidates via an efficient convolutional regression. In the second stage, a discrete sampling based ridge regression is designed to double-check the remaining ambiguous hard samples, which serves as an alternative of fully-connected layers and benefits from the closed-form solver for efficient learning. During the model update, we utilize the hard negative mining technique and an adaptive ridge regression scheme to improve the discrimination capability of the second-stage regressor. Extensive experiments are conducted on 11 challenging tracking benchmarks including OTB-2013, OTB-2015, VOT2018, VOT2019, UAV123, Temple-Color, NfS, TrackingNet, LaSOT, UAV20L, and OxUvA. The proposed method achieves state-of-the-art performance on prevalent benchmarks, while running in a real-time speed.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "144041170",
                        "name": "Ning Wang"
                    },
                    {
                        "authorId": "38272296",
                        "name": "Wen-gang Zhou"
                    },
                    {
                        "authorId": "144876831",
                        "name": "Q. Tian"
                    },
                    {
                        "authorId": "2108508109",
                        "name": "Houqiang Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We use a simple logistic regression classifier [2, 39] to map the labels from support set to query set.",
                "Existing works mainly approach FSL using meta-learning [2, 12, 18, 22, 23, 33, 35] to adapt the base learner for the new tasks, or by enforcing margin maximizing constraints",
                "Our results shown in Table 1 (miniImageNet [41] & tieredImageNet [34] datasets ) and Table 2 (CIFAR-FS [2] & FC100 [28] datasets) suggest that the proposed SKD consistently outperforms the existing methods across all datasets.",
                ", CIFAR-FS [2] and FC100 [28], and a very large-scale Meta-dataset [40] (composed of multiple datasets of diverse nature).",
                "We comprehensively compare our method on five benchmark few-shot learning datasets that include miniImageNet [41], tieredImageNet [34], CIFAR-FS [2], FC100 [28] and Metadataset [40].",
                "Figure 3: Performance of SKD on CIFARFS [2] dataset for different self-supervision tasks.",
                "CIFAR-FS [2] has a random split of 100 classes into 64, 16 and 20 for training, validation, and testing, while FC100 [28] uses splits similar to tieredImageNet, making them more diverse.",
                "Table 2: FSL results on CIFAR-FS [2] and FC100 [28] datasets, with mean accuracy and 95% confidence interval.",
                "Table 3: FSL results on CIFAR-FS [2] and FC100 [28], with different combinations of loss functions for Gen-0 and Gen-1."
            ],
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "414faca3c45df06090ad2ae3a78418c36cf5047a",
                "externalIds": {
                    "MAG": "3036411233",
                    "ArXiv": "2006.09785",
                    "DBLP": "journals/corr/abs-2006-09785",
                    "CorpusId": 219720852
                },
                "corpusId": 219720852,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/414faca3c45df06090ad2ae3a78418c36cf5047a",
                "title": "Self-supervised Knowledge Distillation for Few-shot Learning",
                "abstract": "Real-world contains an overwhelmingly large number of object classes, learning all of which at once is infeasible. Few shot learning is a promising learning paradigm due to its ability to learn out of order distributions quickly with only a few samples. Recent works [7, 41] show that simply learning a good feature embedding can outperform more sophisticated meta-learning and metric learning algorithms for few-shot learning. In this paper, we propose a simple approach to improve the representation capacity of deep neural networks for few-shot learning tasks. We follow a two-stage learning process: First, we train a neural network to maximize the entropy of the feature embedding, thus creating an optimal output manifold using a self-supervised auxiliary loss. In the second stage, we minimize the entropy on feature embedding by bringing self-supervised twins together, while constraining the manifold with student-teacher distillation. Our experiments show that, even in the first stage, self-supervision can outperform current state-of-the-art methods, with further gains achieved by our second stage distillation process. Our codes are available at: this https URL.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "32548363",
                        "name": "Jathushan Rajasegaran"
                    },
                    {
                        "authorId": "152973423",
                        "name": "Salman Hameed Khan"
                    },
                    {
                        "authorId": "145684318",
                        "name": "Munawar Hayat"
                    },
                    {
                        "authorId": "2358803",
                        "name": "F. Khan"
                    },
                    {
                        "authorId": "145103012",
                        "name": "M. Shah"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Building on the embedded features, task-specific parameters are then searched as a minimizer of the inner-loop loss function [3, 18].",
                "The strongly-convex case occurs often when w corresponds to parameters of the last linear layer of a neural network, so that the loss function of such a w is naturally chosen to be a quadratic function or a logistic loss with a strongly convex regularizer [3, 18].",
                "As in [3, 18], the inner-loop loss function adopts L(2) regularization on w with a hyper-parameter \u03bb > 0, and hence is strongly convex.",
                "Apart from MAML-type meta-initialization algorithms, another well-established framework in few-shot meta learning [3, 18, 26, 28, 32] aims to learn good parameters as a common embedding model for all tasks."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "15a33303f1a132f04dad5aa80bdae4aba714c69f",
                "externalIds": {
                    "MAG": "3035840208",
                    "DBLP": "journals/corr/abs-2006-09486",
                    "ArXiv": "2006.09486",
                    "CorpusId": 219721135
                },
                "corpusId": 219721135,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/15a33303f1a132f04dad5aa80bdae4aba714c69f",
                "title": "Convergence of Meta-Learning with Task-Specific Adaptation over Partial Parameters",
                "abstract": "Although model-agnostic meta-learning (MAML) is a very successful algorithm in meta-learning practice, it can have high computational cost because it updates all model parameters over both the inner loop of task-specific adaptation and the outer-loop of meta initialization training. A more efficient algorithm ANIL (which refers to almost no inner loop) was proposed recently by Raghu et al. 2019, which adapts only a small subset of parameters in the inner loop and thus has substantially less computational cost than MAML as demonstrated by extensive experiments. However, the theoretical convergence of ANIL has not been studied yet. In this paper, we characterize the convergence rate and the computational complexity for ANIL under two representative inner-loop loss geometries, i.e., strongly-convexity and nonconvexity. Our results show that such a geometric property can significantly affect the overall convergence performance of ANIL. For example, ANIL achieves a faster convergence rate for a strongly-convex inner-loop loss as the number $N$ of inner-loop gradient descent steps increases, but a slower convergence rate for a nonconvex inner-loop loss as $N$ increases. Moreover, our complexity analysis provides a theoretical quantification on the improved efficiency of ANIL over MAML. The experiments on standard few-shot meta-learning benchmarks validate our theoretical findings.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "2421201",
                        "name": "J. Lee"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    },
                    {
                        "authorId": "145967056",
                        "name": "H. Poor"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Ridge regression layers have previously been used for few-shot learning [5] within minibatch.",
                "We are inspired by recent approaches in few-shot learning [5, 18] that avoid this issue through use of convex optimisation layers.",
                "While ridge regression (RR) is obviously oriented at regression problems, it has been shown [5] to work well for classification when regressing label vectors."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6b67b1f55ebad02eaa73328c3989d64c1dc23dff",
                "externalIds": {
                    "MAG": "3035559424",
                    "ArXiv": "2006.08572",
                    "DBLP": "journals/corr/abs-2006-08572",
                    "CorpusId": 219686980
                },
                "corpusId": 219686980,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6b67b1f55ebad02eaa73328c3989d64c1dc23dff",
                "title": "Flexible Dataset Distillation: Learn Labels Instead of Images",
                "abstract": "We study the problem of dataset distillation - creating a small set of synthetic examples capable of training a good model. In particular, we study the problem of label distillation - creating synthetic labels for a small set of real images, and show it to be more effective than the prior image-based approach to dataset distillation. Interestingly, label distillation can be applied across datasets, for example enabling learning Japanese character recognition by training only on synthetically labeled English letters. Methodologically, we introduce a more robust and flexible meta-learning algorithm for distillation, as well as an effective first-order strategy based on convex optimization layers. Distilling labels with our new algorithm leads to improved results over prior image-based distillation. More importantly, it leads to clear improvements in flexibility of the distilled dataset in terms of compatibility with off-the-shelf optimizers and diverse neural architectures.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1749549997",
                        "name": "Ondrej Bohdal"
                    },
                    {
                        "authorId": "2653152",
                        "name": "Yongxin Yang"
                    },
                    {
                        "authorId": "1697755",
                        "name": "Timothy M. Hospedales"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Other uses of such differentiable optimization have been found in learning attention models [26], meta-learning to differentiate through the base learning algorithm [21, 22], or to train the generator in a generative adversarial model by optimizing out the discriminator [20], or for end-to-end planning and control [23].",
                "For example, [66\u201368] used simple metric-based nearest neighbor, [69, 70] optimized standard learning algorithms iteratively, and [21, 22] leveraged closed-form solutions for base learners."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b4abc7a988caa0a965098335e3f6c6d25ac265dd",
                "externalIds": {
                    "ArXiv": "2006.07822",
                    "DBLP": "conf/nips/LiMZ20",
                    "MAG": "3100660618",
                    "CorpusId": 219687601
                },
                "corpusId": 219687601,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/b4abc7a988caa0a965098335e3f6c6d25ac265dd",
                "title": "Proximal Mapping for Deep Regularization",
                "abstract": "Underpinning the success of deep learning is effective regularizations that allow a variety of priors in data to be modeled. For example, robustness to adversarial perturbations, and correlations between multiple modalities. However, most regularizers are specified in terms of hidden layer outputs, which are not themselves optimization variables. In contrast to prevalent methods that optimize them indirectly through model weights, we propose inserting proximal mapping as a new layer to the deep network, which directly and explicitly produces well regularized hidden layer outputs. The resulting technique is shown well connected to kernel warping and dropout, and novel algorithms were developed for robust temporal learning and multiview modeling, both outperforming state-of-the-art methods.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2118481327",
                        "name": "Mao Li"
                    },
                    {
                        "authorId": "121720851",
                        "name": "Yingyi Ma"
                    },
                    {
                        "authorId": "2108029096",
                        "name": "Xinhua Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(1) Learnet [15] improves upon convolutional siamese net [61] by incorporating the specialty\nof Dtrain of each task T toZ.",
                "R2-D2 [14] adaptive CNN the same as f yes combined",
                "Instead of directly predicting for x test as in matching nets [127], the memory is used to refine the f (x (i)), and to parameterize a CNN as in Learnet [14].",
                "The recent work [14] replaces the classification layer of Learnet by a ridge regression model whose parameter can be found by cheap closed-form solution."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "368a8fbf6304a192a67f614d032510e5a4100552",
                "externalIds": {
                    "MAG": "3034942609",
                    "DBLP": "journals/csur/WangYKN20",
                    "DOI": "10.1145/3386252",
                    "CorpusId": 152282330
                },
                "corpusId": 152282330,
                "publicationVenue": {
                    "id": "7b2adce0-d53f-49d6-8784-b0645604fe62",
                    "name": "ACM Computing Surveys",
                    "type": "journal",
                    "alternate_names": [
                        "ACM Comput Surv"
                    ],
                    "issn": "0360-0300",
                    "url": "http://www.acm.org/pubs/surveys/",
                    "alternate_urls": [
                        "http://portal.acm.org/csur",
                        "https://csur.acm.org/",
                        "http://csur.acm.org/"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/368a8fbf6304a192a67f614d032510e5a4100552",
                "title": "Generalizing from a Few Examples",
                "abstract": "Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications, and theories, are also proposed to provide insights for future research.1",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "49416601",
                        "name": "Yaqing Wang"
                    },
                    {
                        "authorId": "3259992",
                        "name": "Quanming Yao"
                    },
                    {
                        "authorId": "145193332",
                        "name": "J. Kwok"
                    },
                    {
                        "authorId": "1726587",
                        "name": "L. Ni"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In some applications like classification, other categories of meta learning algorithms, namely black-box [1] and parametric methods [23] also achieve state of the art results."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3e527db9e1f4821661487f3f67d9b42bedb2f73e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2006-07438",
                    "ArXiv": "2006.07438",
                    "MAG": "3035713288",
                    "CorpusId": 219687624
                },
                "corpusId": 219687624,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3e527db9e1f4821661487f3f67d9b42bedb2f73e",
                "title": "Attentive Feature Reuse for Multi Task Meta learning",
                "abstract": "We develop new algorithms for simultaneous learning of multiple tasks (e.g., image classification, depth estimation), and for adapting to unseen task/domain distributions within those high-level tasks (e.g., different environments). First, we learn common representations underlying all tasks. We then propose an attention mechanism to dynamically specialize the network, at runtime, for each task. Our approach is based on weighting each feature map of the backbone network, based on its relevance to a particular task. To achieve this, we enable the attention module to learn task representations during training, which are used to obtain attention weights. Our method improves performance on new, previously unseen environments, and is 1.5x faster than standard existing meta learning methods using similar architectures. We highlight performance improvements for Multi-Task Meta Learning of 4 tasks (image classification, depth, vanishing point, and surface normal estimation), each over 10 to 25 test domains/environments, a result that could not be achieved with standard meta learning techniques like MAML.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "9315693",
                        "name": "Kiran Lekkala"
                    },
                    {
                        "authorId": "7326223",
                        "name": "L. Itti"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For fair comparison, we also cite the original results of R2-D2 (Bertinetto et al., 2019) using 64 channels.",
                "We cite the original results of R2-D2 (Bertinetto et al., 2019) using 64 channels for fair comparison.",
                "\u00b1 \u00b1 (Snell et al., 2017) 47.4 \u00b1 0.6 65.4 0.5 55.5 0.7 72.0 0.6 R ELATION NET (Sung et al., 2018) 50.4 0.8 \u00b1 \u00b1 \u00b1 65.3 0.7 55.0 1.0 69.3 0.8 \u00b1 \u00b1 \u00b1 \u00b1 SNAIL (32C) by (Bertinetto et al., 2019) 45.1 55.2 \u2014 \u2014 GNN (Garcia & Bruna, 2018) 50.3 66.4 61.9 75.3 PLATIPUS (Finn et al., 2018) 50.1 1.9 \u2014 \u2014 \u2014 \u00b1 VERSA (Gordon et al., 2019) 53.3 1.8 67.3 0.9 62.5 1.7 75.1 0.9 \u00b1 R2-D2 ( 64 C) (Bertinetto et al., 2019) 49.5 0.2 \u00b1 65.4 0.2 \u00b1 \u00b1 62.3 0.2 77.4 0.2 \u00b1 \u00b1 \u00b1 R2-D2 (Devos et al., 2019) 51.7 1.8 63.3 0.9 60.2 1.8 \u00b1 70.9 0.9 CAVIA (Zintgraf et al., 2019) 51 The key hyperparameter for the number of bases D in (7) is set to D = 780 for MetaVRF in all experiments, while we use RFFs with D = 2048 as this produces the best performance.",
                "Generally speaking, existing meta-learning algorithms (Ravi & Larochelle, 2017; Bertinetto et al., 2019) design the meta-learner to extract meta-knowledge that improves the performance of the baselearner on individual tasks."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "ca84ead69bac092ddc911b956b198ce4a8542946",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2006-06707",
                    "ArXiv": "2006.06707",
                    "MAG": "3034987668",
                    "CorpusId": 213755428
                },
                "corpusId": 213755428,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/ca84ead69bac092ddc911b956b198ce4a8542946",
                "title": "Learning to Learn Kernels with Variational Random Features",
                "abstract": "In this work, we introduce kernels with random Fourier features in the meta-learning framework to leverage their strong few-shot learning ability. We propose meta variational random features (MetaVRF) to learn adaptive kernels for the base-learner, which is developed in a latent variable model by treating the random feature basis as the latent variable. We formulate the optimization of MetaVRF as a variational inference problem by deriving an evidence lower bound under the meta-learning framework. To incorporate shared knowledge from related tasks, we propose a context inference of the posterior, which is established by an LSTM architecture. The LSTM-based inference network can effectively integrate the context information of previous tasks with task-specific information, generating informative and adaptive features. The learned MetaVRF can produce kernels of high representational power with a relatively low spectral sampling rate and also enables fast adaptation to new tasks. Experimental results on a variety of few-shot regression and classification tasks demonstrate that MetaVRF delivers much better, or at least competitive, performance compared to existing meta-learning alternatives.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "34798935",
                        "name": "Xiantong Zhen"
                    },
                    {
                        "authorId": "2776765",
                        "name": "Haoliang Sun"
                    },
                    {
                        "authorId": "46941376",
                        "name": "Yingjun Du"
                    },
                    {
                        "authorId": "145971173",
                        "name": "Jun Xu"
                    },
                    {
                        "authorId": "102446355",
                        "name": "Yilong Yin"
                    },
                    {
                        "authorId": "144082425",
                        "name": "Ling Shao"
                    },
                    {
                        "authorId": "145404204",
                        "name": "Cees G. M. Snoek"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For tieredImageNet and CIFAR-FS, the best accuracy are obtained on validation classes when \u03b2 = 0.5, \u03bb = 10, \u03b1 = 0.3 for s = 1; \u03b2 = 0.5, \u03bb = 10, \u03b1 = 0.2 for s = 5.",
                "We evaluate the performance of the proposed method using standardized few-shot classification datasets: miniImageNet [32], tieredImageNet [20], CUB [33] and CIFAR-FS [1].",
                "The CIFAR-FS dataset has 100 classes, each class contains 600 images of size 32\u00d7 32 pixels."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "3ee19426b9d5acd3b975708845e518277627ec59",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2006-03806",
                    "MAG": "3033606067",
                    "ArXiv": "2006.03806",
                    "DOI": "10.1007/978-3-030-86340-1_39",
                    "CorpusId": 219531491
                },
                "corpusId": 219531491,
                "publicationVenue": {
                    "id": "3e64b1c1-745f-4edf-bd92-b8ef122bb49c",
                    "name": "International Conference on Artificial Neural Networks",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Artif Neural Netw",
                        "ICANN"
                    ],
                    "url": "http://www.e-nns.org/"
                },
                "url": "https://www.semanticscholar.org/paper/3ee19426b9d5acd3b975708845e518277627ec59",
                "title": "Leveraging the Feature Distribution in Transfer-based Few-Shot Learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2143462361",
                        "name": "Yuqing Hu"
                    },
                    {
                        "authorId": "144916029",
                        "name": "Vincent Gripon"
                    },
                    {
                        "authorId": "2642628",
                        "name": "S. Pateux"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[5] and [21] used the closed-form solutions directly."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f5003f197aea0bfae680559da9462aa396b07a1d",
                "externalIds": {
                    "MAG": "2990216037",
                    "DBLP": "conf/cvpr/GuoC20",
                    "DOI": "10.1109/CVPR42600.2020.01351",
                    "CorpusId": 213594272
                },
                "corpusId": 213594272,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f5003f197aea0bfae680559da9462aa396b07a1d",
                "title": "Attentive Weights Generation for Few Shot Learning via Information Maximization",
                "abstract": "Few shot image classification aims at learning a classifier from limited labeled data. Generating the classification weights has been applied in many meta-learning methods for few shot image classification due to its simplicity and effectiveness. In this work, we present Attentive Weights Generation for few shot learning via Information Maximization (AWGIM), which introduces two novel contributions: i) Mutual information maximization between generated weights and data within the task; this enables the generated weights to retain information of the task and the specific query sample. ii) Self-attention and cross-attention paths to encode the context of the task and individual queries. Both two contributions are shown to be very effective in extensive experiments. Overall, AWGIM is competitive with state-of-the-art. Code is available at https://github.com/Yiluan/AWGIM.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Yiluan Guo"
                    },
                    {
                        "authorId": "143770929",
                        "name": "Ngai-Man Cheung"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The CIFAR-FS dataset [49] is a few-shot learning benchmark containing all 100 classes from CIFAR-100 [43]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "307272c796743bd6d78d4ff3ea762aa2a4c238a2",
                "externalIds": {
                    "DBLP": "conf/cvpr/SimonKNH20",
                    "MAG": "3035143213",
                    "DOI": "10.1109/cvpr42600.2020.00419",
                    "CorpusId": 219699986
                },
                "corpusId": 219699986,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/307272c796743bd6d78d4ff3ea762aa2a4c238a2",
                "title": "Adaptive Subspaces for Few-Shot Learning",
                "abstract": "Object recognition requires a generalization capability to avoid overfitting, especially when the samples are extremely few. Generalization from limited samples, usually studied under the umbrella of meta-learning, equips learning techniques with the ability to adapt quickly in dynamical environments and proves to be an essential aspect of life long learning. In this paper, we provide a framework for few-shot learning by introducing dynamic classifiers that are constructed from few samples. A subspace method is exploited as the central block of a dynamic classifier. We will empirically show that such modelling leads to robustness against perturbations (e.g., outliers) and yields competitive results on the task of supervised and semi-supervised few-shot classification. We also develop a discriminative form which can boost the accuracy even further. Our code is available at https://github.com/chrysts/dsn_fewshot",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "144616396",
                        "name": "Christian Simon"
                    },
                    {
                        "authorId": "2155775",
                        "name": "Piotr Koniusz"
                    },
                    {
                        "authorId": "1718786",
                        "name": "R. Nock"
                    },
                    {
                        "authorId": "1686714",
                        "name": "M. Harandi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Comparisons: We present the results of different methods on the MiniImageNet and CIFAR-FS datasets in Tables 1 and 2).",
                "However, although our method performs much better than GNN [17] on MiniImageNet, their results on CIFAR-FS are just comparable, possibly due to the dataset difference.",
                "CIFAR-FS [2] is randomly sampled from CIFAR-100 [10] by applying the same criteria as miniImagenet."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e9d0cd1aac5135edccd42e66ca6dac9b5b89faef",
                "externalIds": {
                    "DBLP": "conf/cvpr/XueXXD20",
                    "MAG": "3036587561",
                    "DOI": "10.1109/CVPRW50498.2020.00474",
                    "CorpusId": 220889539
                },
                "corpusId": 220889539,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e9d0cd1aac5135edccd42e66ca6dac9b5b89faef",
                "title": "Relative Position and Map Networks in Few-shot Learning for Image Classification",
                "abstract": "Few-shot learning is an important research topic in image classification, which aims to train robust classifiers to categorize images coming from new classes where only a few labeled samples are available. Recently, metric learning based methods have achieved promising performance, and in those methods a distance metric is learned to directly compare query images against training samples. In this work, we consider finer information from image feature maps and propose a new approach. Specifically, we newly develop Relative Position Network (RPN) based on the attention mechanism to compare different pairs of activation cells from each query and training images, which captures their intrinsic correspondences. Moreover, we introduce Relative Map Network (RMN) to learn a distance metric based on the attention maps obtained from RPN, which better measures the similarity between query and training images. Extensive experiments demonstrate the effectiveness of our proposed method. Our codes will be released at https://github.com/chrisyxue/RMN-RPN-for-FSL.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1726787",
                        "name": "Z. Xue"
                    },
                    {
                        "authorId": "67221823",
                        "name": "Zhenshan Xie"
                    },
                    {
                        "authorId": "2099118281",
                        "name": "Zheng Xing"
                    },
                    {
                        "authorId": "2055900",
                        "name": "Lixin Duan"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8172ca86b80e66c1b4ad9db8bbc34afe8c72d3fa",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2005-13826",
                    "MAG": "3030411842",
                    "ArXiv": "2005.13826",
                    "DOI": "10.1109/CVPR42600.2020.01259",
                    "CorpusId": 218971576
                },
                "corpusId": 218971576,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8172ca86b80e66c1b4ad9db8bbc34afe8c72d3fa",
                "title": "Boosting Few-Shot Learning With Adaptive Margin Loss",
                "abstract": "Few-shot learning (FSL) has attracted increasing attention in recent years but remains challenging, due to the intrinsic difficulty in learning to generalize from a few examples. This paper proposes an adaptive margin principle to improve the generalization ability of metric-based meta-learning approaches for few-shot learning problems. Specifically, we first develop a class-relevant additive margin loss, where semantic similarity between each pair of classes is considered to separate samples in the feature embedding space from similar classes. Further, we incorporate the semantic context among all classes in a sampled training task and develop a task-relevant additive margin loss to better distinguish samples from different classes. Our adaptive margin method can be easily extended to a more realistic generalized FSL setting. Extensive experiments demonstrate that the proposed method can boost the performance of current metric-based meta-learning approaches, under both the standard FSL and generalized FSL settings.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "5683005",
                        "name": "Aoxue Li"
                    },
                    {
                        "authorId": "8007867",
                        "name": "Weiran Huang"
                    },
                    {
                        "authorId": "143866730",
                        "name": "Xu Lan"
                    },
                    {
                        "authorId": "33221685",
                        "name": "Jiashi Feng"
                    },
                    {
                        "authorId": "7718952",
                        "name": "Zhenguo Li"
                    },
                    {
                        "authorId": "39060743",
                        "name": "Liwei Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c2e1d2efc2cbf2cec0aaa4c52e06c69987aeefe7",
                "externalIds": {
                    "MAG": "3083953109",
                    "CorpusId": 225834502
                },
                "corpusId": 225834502,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c2e1d2efc2cbf2cec0aaa4c52e06c69987aeefe7",
                "title": "Multiphysics Transport in Heterogeneous Media: from Pore-Scale Modeling to Deep Learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "14860759",
                        "name": "Haiyi Wu"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2011), CIFAR-FS (Bertinetto et al., 2019) and miniImageNet (Vinyals et al.",
                "Sequential MAML gives a noticeable drop in the performance of Omniglot and miniQuickDraw when meta-training on CIFAR-FS.",
                "There is a small trade-off in the performance of CIFAR-FS as BOMLA and BOMVI avoid catastrophically forgetting Omniglot and miniQuickDraw.",
                "Some popular examples of the few-shot classification datasets are Omniglot (Lake et al., 2011), CIFAR-FS (Bertinetto et al., 2019) and miniImageNet (Vinyals et al., 2016).",
                "The distributional shift from Omniglot to miniQuickDraw is less drastic, compared to the shift from miniQuickDraw to CIFAR-FS.",
                "The current practice to few-shot classify the novel classes from different datasets is to meta-learn a model for each dataset separately (Snell et al., 2017; Vinyals et al., 2016; Bertinetto et al., 2019)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "361850e0ec285528990c61235fc6c1e15cfd5ab6",
                "externalIds": {
                    "DBLP": "conf/icml/YapRB21",
                    "ArXiv": "2005.00146",
                    "CorpusId": 235490181
                },
                "corpusId": 235490181,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/361850e0ec285528990c61235fc6c1e15cfd5ab6",
                "title": "Addressing Catastrophic Forgetting in Few-Shot Problems",
                "abstract": "Neural networks are known to suffer from catastrophic forgetting when trained on sequential datasets. While there have been numerous attempts to solve this problem in large-scale supervised classification, little has been done to overcome catastrophic forgetting in few-shot classification problems. We demonstrate that the popular gradient-based model-agnostic meta-learning algorithm (MAML) indeed suffers from catastrophic forgetting and introduce a Bayesian online meta-learning framework that tackles this problem. Our framework utilises Bayesian online learning and meta-learning along with Laplace approximation and variational inference to overcome catastrophic forgetting in few-shot classification problems. The experimental evaluations demonstrate that our framework can effectively achieve this goal in comparison with various baselines. As an additional utility, we also demonstrate empirically that our framework is capable of meta-learning on sequentially arriving few-shot tasks from a stationary task distribution.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2028309427",
                        "name": "Pauching Yap"
                    },
                    {
                        "authorId": "47579842",
                        "name": "H. Ritter"
                    },
                    {
                        "authorId": "2056214994",
                        "name": "David Barber"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The CIFAR-FS dataset [11] is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100 [32]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "02ae998667e48ccd0b110dfe86f7ec7c3187356d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2004-14539",
                    "MAG": "3023596032",
                    "ArXiv": "2004.14539",
                    "DOI": "10.1609/aaai.v35i10.17081",
                    "CorpusId": 216868551,
                    "PubMed": "34484857"
                },
                "corpusId": 216868551,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/02ae998667e48ccd0b110dfe86f7ec7c3187356d",
                "title": "Physarum Powered Differentiable Linear Programming Layers and Applications",
                "abstract": "Consider a learning algorithm, which involves an internal call to an optimization routine such as a generalized eigenvalue problem, a cone programming problem or even sorting. Integrating such a method as a layer(s) within a trainable deep neural network (DNN) in an efficient and numerically stable way is not straightforward - for instance, only recently, strategies have emerged for eigendecomposition and differentiable sorting. We propose an efficient and differentiable solver for general linear programming problems which can be used in a plug and play manner within DNNs as a layer. Our development is inspired by a fascinating but not widely used link between dynamics of slime mold (physarum) and optimization schemes such as steepest descent. We describe our development and show the use of our solver in a video segmentation task and meta-learning for few-shot learning. We review the existing results and provide a technical analysis describing its applicability for our use cases. Our solver performs comparably with a customized projected gradient descent method on the first task and outperforms the differentiable CVXPY-SCS solver on the second task. Experiments show that our solver converges quickly without the need for a feasible initial point. Our proposal is easy to implement and can easily serve as layers whenever a learning procedure needs a fast approximate solution to a LP, within a larger network.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "8745352",
                        "name": "Zihang Meng"
                    },
                    {
                        "authorId": "3023295",
                        "name": "S. Ravi"
                    },
                    {
                        "authorId": "144711711",
                        "name": "Vikas Singh"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "52a73074a8d9a55af98424f9645203c708ba31f2",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2005-00146",
                    "MAG": "3022641269",
                    "CorpusId": 218470159
                },
                "corpusId": 218470159,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/52a73074a8d9a55af98424f9645203c708ba31f2",
                "title": "Bayesian Online Meta-Learning with Laplace Approximation",
                "abstract": "Neural networks are known to suffer from catastrophic forgetting when trained on sequential datasets. While there have been numerous attempts to solve this problem for large-scale supervised classification, little has been done to overcome catastrophic forgetting for few-shot classification problems. We demonstrate that the popular gradient-based few-shot meta-learning algorithm Model-Agnostic Meta-Learning (MAML) indeed suffers from catastrophic forgetting and introduce a Bayesian online meta-learning framework that tackles this problem. Our framework incorporates MAML into a Bayesian online learning algorithm with Laplace approximation. This framework enables few-shot classification on a range of sequentially arriving datasets with a single meta-learned model. The experimental evaluations demonstrate that our framework can effectively prevent forgetting in various few-shot classification settings compared to applying MAML sequentially.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2028309427",
                        "name": "Pauching Yap"
                    },
                    {
                        "authorId": "47579842",
                        "name": "H. Ritter"
                    },
                    {
                        "authorId": "145617808",
                        "name": "D. Barber"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The current practice to few-shot classify the novel classes from different datasets is to metalearn a model for each dataset separately (Snell et al., 2017; Vinyals et al., 2016; Sung et al., 2018; Bertinetto et al., 2019).",
                "CIFAR-FS: The CIFAR-FS dataset (Bertinetto et al., 2019) is a variation on CIFAR100 (Krizhevsky, 2009) for the few-shot classification purpose, with 100 classes of objects and each class comprises 600 images of size 32\u00d7 32.",
                ", 2011), CIFAR-FS (Bertinetto et al., 2019) and miniImageNet (Vinyals et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7a3d8d9acf50e44057db23c704b9c438cb4375c7",
                "externalIds": {
                    "MAG": "3107420016",
                    "CorpusId": 227143073
                },
                "corpusId": 227143073,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/7a3d8d9acf50e44057db23c704b9c438cb4375c7",
                "title": "Bayesian Online Meta-Learning",
                "abstract": "Neural networks are known to suffer from catastrophic forgetting when trained on sequential datasets. While there have been numerous attempts to solve this problem for large-scale supervised classification, little has been done to overcome catastrophic forgetting for few-shot classification problems. We demonstrate that the popular gradient-based few-shot meta-learning algorithm Model-Agnostic Meta-Learning (MAML) indeed suffers from catastrophic forgetting and introduce a Bayesian online meta-learning framework that tackles this problem. Our framework incorporates MAML into a Bayesian online learning algorithm with Laplace approximation. This framework enables few-shot classification on a range of sequentially arriving datasets with a single meta-learned model. The experimental evaluations demonstrate that our framework can effectively prevent forgetting in various few-shot classification settings compared to applying MAML sequentially.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2028309427",
                        "name": "Pauching Yap"
                    },
                    {
                        "authorId": "47579842",
                        "name": "H. Ritter"
                    },
                    {
                        "authorId": "145617808",
                        "name": "D. Barber"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS is proposed by Bertinetto et al. (2018), which is created by dividing the original CIFAR-100 into 64 training classes, 16 validation classes and 20 testing classes; each image is of size 32\u00d732.",
                "64 49.4 0.8% 68.2 0.7% 55.5 0.7% 72.0 0.6% Relation Net (Sung et al., 2018) Conv-4-64 50.4 0.8% 65.3 0.7% 55.0 1.0% 69.3 0.8% GNN (Satorras &amp; Bruna, 2017) Conv-4-64 50.3% 66.4% 61.9% 75.3% R2-D2 (Bertinetto et al., 2018) Conv-4-64 49.5 0.2% 65.4 0.2% 62.3 0.2% 77.4 0.2% TPN (Liu et al., 2018) Conv-4-64 55.5% 69.9% \u2013 \u2013 Gidaris et al. (2019) Conv-4-64 54.8 0.4% 71.9 0.3% 63.5 0.3% 79.8 0.2% SIB K=0 (Pre-trained feature",
                "Net is proposed by Vinyals et al. (2016), which contains 100 classes, split into 64 training classes, 16 validation classes and 20 testing classes; each image is of size 84 84. CIFAR-FSis proposed by Bertinetto et al. (2018), which is created by dividing the original CIFAR-100 into 64 training classes, 16 validation classes and 20 testing classes; each image is of size 32 32. Evaluation metrics In few-shot classi\ufb01cation,"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "96b279f5e8ef539a7ef01fd1fdfa6bc10f36a07c",
                "externalIds": {
                    "ArXiv": "2004.12696",
                    "DBLP": "conf/iclr/HuMXSOLD20",
                    "MAG": "3020429927",
                    "CorpusId": 214222435
                },
                "corpusId": 214222435,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/96b279f5e8ef539a7ef01fd1fdfa6bc10f36a07c",
                "title": "Empirical Bayes Transductive Meta-Learning with Synthetic Gradients",
                "abstract": "We propose a meta-learning approach that learns from multiple tasks in a transductive setting, by leveraging unlabeled information in the query set to learn a more powerful meta-model. To develop our framework we revisit the empirical Bayes formulation for multi-task learning. The evidence lower bound of the marginal log-likelihood of empirical Bayes decomposes as a sum of local KL divergences between the variational posterior and the true posterior of each task. We derive a novel amortized variational inference that couples all the variational posteriors into a meta-model, which consists of a synthetic gradient network and an initialization network. The combination of local KL divergences and synthetic gradient network allows for backpropagating information from unlabeled data, thereby enabling transduction. Our results on the Mini-ImageNet and CIFAR-FS benchmarks for episodic few-shot classification significantly outperform previous state-of-the-art methods.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "145498976",
                        "name": "S. Hu"
                    },
                    {
                        "authorId": "144840899",
                        "name": "Pablo G. Moreno"
                    },
                    {
                        "authorId": "2116642640",
                        "name": "Yanghua Xiao"
                    },
                    {
                        "authorId": "2111113336",
                        "name": "Xin Shen"
                    },
                    {
                        "authorId": "2533906",
                        "name": "G. Obozinski"
                    },
                    {
                        "authorId": "145306271",
                        "name": "Neil D. Lawrence"
                    },
                    {
                        "authorId": "3106771",
                        "name": "Andreas C. Damianou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "MetaOptNet [73] is developed under base learner and meta-learner double-layer framework [77], where base learner is formulated as a regularized linear classifier.",
                "[77] specifies base learner as an efficient and differentiable learner preferably with an explicit solution.",
                "In R2D2 (Ridge Regression Differentiable Discriminator) [77], ridge regression is specified to be base learner.",
                "[77] lays out base learner and meta-learner double-layer framework, in which base learner concentrates upon model fitting and meta-learner focuses upon model adaptation.",
                "In LR-D2 (Logistic Regression Differentiable Discriminator), iteratively reweighted least squares (IRLS) derived from logistic regression is applied as base learner.",
                "MetaOptNet is an extension of [77] in the sense that it explores more options of base learner specification under similar framework as in [77].",
                "This idea of base learner specification is similar to that in [77], where an efficient and differentiable statistical base learner is preferred.",
                "CIAFR-FS [77] is randomly sampled from CIFAR-100 for few-shot learning in the same mechanism as miniImageNet."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "d0eb13325d77e50a60102139e84484a9beaf62ff",
                "externalIds": {
                    "MAG": "3020638616",
                    "DBLP": "journals/corr/abs-2004-11149",
                    "ArXiv": "2004.11149",
                    "CorpusId": 216080675
                },
                "corpusId": 216080675,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/d0eb13325d77e50a60102139e84484a9beaf62ff",
                "title": "A Comprehensive Overview and Survey of Recent Advances in Meta-Learning",
                "abstract": "This article reviews meta-learning also known as learning-to-learn which seeks rapid and accurate model adaptation to unseen tasks with applications in strong AI, few-shot learning, natural language processing and robotics. Unlike deep learning, meta-learning can be applied to few-shot high-dimensional datasets and considers further improving model generalization to unseen tasks. Deep learning is focused upon in-sample prediction and meta-learning concerns model adaptation for out-of-sample prediction. Meta-learning can continually perform self-improvement to achieve highly autonomous AI. Meta-learning may serve as an additional generalization block complementary for original deep learning model. Meta-learning seeks adaptation of machine learning models to unseen tasks which are vastly different from trained tasks. Meta-learning with coevolution between agent and environment provides solutions for complex tasks unsolvable by training from scratch. Meta-learning methodology covers a wide range of great minds and thoughts. We briefly summarize meta-learning methodologies into the following categories: black-box meta-learning, metric-based meta-learning, layered meta-learning and Bayesian meta-learning framework. Recent applications concentrate upon the integration of meta-learning with other machine learning framework to provide feasible integrated problem solutions. We briefly present recent meta-learning advances and discuss potential future research directions.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1491241005",
                        "name": "Huimin Peng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026cosine similarity (Vinyals et al. 2016), euclidean distance to class prototypes (Snell, Swersky, and Zemel 2017; Ren et al. 2018), ridge regression (Bertinetto et al. 2019), relation network (Sung et al. 2018), task attention (Yan, Zhang, and He 2019), category traversal (Li et al. 2019a), and\u2026",
                "2018), ridge regression (Bertinetto et al. 2019), relation network (Sung et al."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3c0af65ddd73017ed4ac7f33bef8c9160e322717",
                "externalIds": {
                    "DBLP": "conf/aaai/LuoHZWBY20",
                    "MAG": "2998528009",
                    "DOI": "10.1609/AAAI.V34I04.5942",
                    "CorpusId": 213711313
                },
                "corpusId": 213711313,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/3c0af65ddd73017ed4ac7f33bef8c9160e322717",
                "title": "Learning from the Past: Continual Meta-Learning with Bayesian Graph Neural Networks",
                "abstract": "Meta-learning for few-shot learning allows a machine to leverage previously acquired knowledge as a prior, thus improving the performance on novel tasks with only small amounts of data. However, most mainstream models suffer from catastrophic forgetting and insufficient robustness issues, thereby failing to fully retain or exploit long-term knowledge while being prone to cause severe error accumulation. In this paper, we propose a novel Continual Meta-Learning approach with Bayesian Graph Neural Networks (CML-BGNN) that mathematically formulates meta-learning as continual learning of a sequence of tasks. With each task forming as a graph, the intra- and inter-task correlations can be well preserved via message-passing and history transition. To remedy topological uncertainty from graph initialization, we utilize Bayes by Backprop strategy that approximates the posterior distribution of task-specific parameters with amortized inference networks, which are seamlessly integrated into the end-to-end edge learning. Extensive experiments conducted on the miniImageNet and tieredImageNet datasets demonstrate the effectiveness and efficiency of the proposed method, improving the performance by 42.8% compared with state-of-the-art on the miniImageNet 5-way 1-shot classification task.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "150350159",
                        "name": "Yadan Luo"
                    },
                    {
                        "authorId": "145622169",
                        "name": "Zi Huang"
                    },
                    {
                        "authorId": "2148905838",
                        "name": "Zheng Zhang"
                    },
                    {
                        "authorId": "47196880",
                        "name": "Ziwei Wang"
                    },
                    {
                        "authorId": "51278862",
                        "name": "Mahsa Baktashmotlagh"
                    },
                    {
                        "authorId": "2152916796",
                        "name": "Yang Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [1] consists of 100 classes randomly selected from CIFAR-100 [14] and each class has 600 images, each of size 32 \u00d7 32."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ac2d8263981eca1026a7eb8c7c8806f669097f9d",
                "externalIds": {
                    "MAG": "3015113763",
                    "DBLP": "journals/corr/abs-2004-00251",
                    "ArXiv": "2004.00251",
                    "DOI": "10.1016/j.neunet.2021.02.007",
                    "CorpusId": 214743539,
                    "PubMed": "33652370"
                },
                "corpusId": 214743539,
                "publicationVenue": {
                    "id": "a13f3cb8-2492-4ccb-9329-73a5ddcaab9b",
                    "name": "Neural Networks",
                    "type": "journal",
                    "alternate_names": [
                        "Neural Netw"
                    ],
                    "issn": "0893-6080",
                    "url": "http://www.elsevier.com/locate/neunet",
                    "alternate_urls": [
                        "http://www.elsevier.com/wps/find/journaldescription.cws_home/841/description",
                        "http://www.sciencedirect.com/science/journal/08936080"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/ac2d8263981eca1026a7eb8c7c8806f669097f9d",
                "title": "Self-Augmentation: Generalizing Deep Networks to Unseen Classes for Few-Shot Learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "115026943",
                        "name": "Jinhwan Seo"
                    },
                    {
                        "authorId": "2109313062",
                        "name": "Hong G Jung"
                    },
                    {
                        "authorId": "50112753",
                        "name": "Seong-Whan Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2019] [Bertinetto et al., 2018], our proposed base learner is generated under the supervision of the presented masks of input support images.",
                "Different from the existing base learner used in [Lee et al., 2019] [Bertinetto et al., 2018], our proposed base learner is generated under the supervision of the presented masks of input support images.",
                ", 2019] and [Bertinetto et al., 2018] introduce machine learning methods such as SVM and ridge regression into the inner loop of the base learner, and [Rusu et al.",
                "In the latest study, [Lee et al., 2019] and [Bertinetto et al., 2018] introduce machine learning methods such as SVM and ridge regression into the inner loop of the base learner, and [Rusu et al., 2018] directly replaces the inner loop with an encoded-decode network."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "4538f4d631c7d273bd5b126b4d87b38f37e5817e",
                "externalIds": {
                    "DBLP": "conf/ijcai/ZhuZ020",
                    "ArXiv": "2004.05538",
                    "MAG": "3034954526",
                    "DOI": "10.24963/ijcai.2020/142",
                    "CorpusId": 215744862
                },
                "corpusId": 215744862,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/4538f4d631c7d273bd5b126b4d87b38f37e5817e",
                "title": "Self-Supervised Tuning for Few-Shot Segmentation",
                "abstract": "Few-shot segmentation aims at assigning a category label to each image pixel with few annotated samples. It is a challenging task since the dense prediction can only be achieved under the guidance of latent features defined by sparse annotations. Existing meta-learning based method tends to fail in generating category-specifically discriminative descriptor when the visual features extracted from support images are marginalized in embedding space. To address this issue, this paper presents an adaptive tuning framework, in which the distribution of latent features across different episodes is dynamically adjusted based on a self-segmentation scheme, augmenting category-specific descriptors for label prediction. Specifically, a novel self-supervised inner-loop is firstly devised as the base learner to extract the underlying semantic features from the support image. Then, gradient maps are calculated by back-propagating self-supervised loss through the obtained features, and leveraged as guidance for augmenting the corresponding elements in the embedding space. Finally, with the ability to continuously learn from different episodes, an optimization-based meta-learner is adopted as outer loop of our proposed framework to gradually refine the segmentation results. Extensive experiments on benchmark PASCAL-5i and COCO-20i datasets demonstrate the superiority of our proposed method over state-of-the-art.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2113842210",
                        "name": "Kai Zhu"
                    },
                    {
                        "authorId": "2000495780",
                        "name": "Wei Zhai"
                    },
                    {
                        "authorId": "143962510",
                        "name": "Zhengjun Zha"
                    },
                    {
                        "authorId": "145871531",
                        "name": "Yang Cao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Evaluation Protocols We evaluate DPGN in 5way1shot/5shot settings on standard few-shot learning datasets,\nminiImageNet, tieredImageNet, CUB-200-2011 and CIFAR-FS.",
                "As shown in Table 1, we list details for images number, classes number, images resolution and train/val/test splits following the criteria of previous works [41, 31, 4, 3].",
                "The total number of generations is an important ingredient for DPGN, so we perform experiments to obtain the trend of test accuracy with different generation numbers in DPGN on miniImageNet, tieredImageNet, CUB-200-2011, and CIFAR-FS.",
                "Additionally, to visualize the procedure of cyclic update, we choose a test scenario where the ground truth classes of five query images are [1, 2, 3, 4, 5] and visualize instance-level similarities which is used for predictions of five query samples as shown in Figure 8.",
                "CUB-200-2011 is initially designed for fine-grained classification and CIFAR-FS is a subset of CIFAR-100 for fewshot classification.",
                "For fair comparisons, we employ DPGN on miniImageNet, tieredImageNet, CIFAR-FS and CUB-200-2011 datasets, which is compared with other methods in the same backbones.",
                "We evaluate DPGN on four standard few-shot learning benchmarks: miniImageNet [41], tieredImageNet [31], CUB-200-2011 [42] and CIFAR-FS [3]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1c7a71d415710599c0c94161e6de846346d3ab5e",
                "externalIds": {
                    "DBLP": "conf/cvpr/YangLZZZL20",
                    "MAG": "3034637015",
                    "ArXiv": "2003.14247",
                    "DOI": "10.1109/cvpr42600.2020.01340",
                    "CorpusId": 214728305
                },
                "corpusId": 214728305,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1c7a71d415710599c0c94161e6de846346d3ab5e",
                "title": "DPGN: Distribution Propagation Graph Network for Few-Shot Learning",
                "abstract": "Most graph-network-based meta-learning approaches model instance-level relation of examples. We extend this idea further to explicitly model the distribution-level relation of one example to all other examples in a 1-vs-N manner. We propose a novel approach named distribution propagation graph network (DPGN) for few-shot learning. It conveys both the distribution-level relations and instance-level relations in each few-shot learning task. To combine the distribution-level relations and instance-level relations for all examples, we construct a dual complete graph network which consists of a point graph and a distribution graph with each node standing for an example. Equipped with dual graph architecture, DPGN propagates label information from labeled examples to unlabeled examples within several update generations. In extensive experiments on few-shot learning benchmarks, DPGN outperforms state-of-the-art results by a large margin in 5%\u223c12% under supervised setting and 7%\u223c13% under semi-supervised setting. Code will be released.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2155557947",
                        "name": "Ling Yang"
                    },
                    {
                        "authorId": "2154884770",
                        "name": "Liang Li"
                    },
                    {
                        "authorId": "2144370447",
                        "name": "Zilun Zhang"
                    },
                    {
                        "authorId": "2148927556",
                        "name": "Xinyu Zhou"
                    },
                    {
                        "authorId": "1848243",
                        "name": "Erjin Zhou"
                    },
                    {
                        "authorId": "2146401647",
                        "name": "Yu Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "52 R2D2 [1] 51.",
                "Recently, [19,1] alleviate the optimization problem by closed-form model like SVM, and achieve better performance on few-shot classification benchmark of large dataset."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2ad5f836e1d9876fa3fc53cb2c0a704b45988f0f",
                "externalIds": {
                    "ArXiv": "2003.12060",
                    "MAG": "3096805028",
                    "DBLP": "journals/corr/abs-2003-12060",
                    "DOI": "10.1007/978-3-030-58548-8_26",
                    "CorpusId": 214667377
                },
                "corpusId": 214667377,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/2ad5f836e1d9876fa3fc53cb2c0a704b45988f0f",
                "title": "Negative Margin Matters: Understanding Margin in Few-shot Classification",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "145117688",
                        "name": "Bin Liu"
                    },
                    {
                        "authorId": "2112823372",
                        "name": "Yue Cao"
                    },
                    {
                        "authorId": "51091819",
                        "name": "Yutong Lin"
                    },
                    {
                        "authorId": "2118913010",
                        "name": "Qi Li"
                    },
                    {
                        "authorId": "2148904543",
                        "name": "Zheng Zhang"
                    },
                    {
                        "authorId": "35776445",
                        "name": "Mingsheng Long"
                    },
                    {
                        "authorId": "1823518756",
                        "name": "Han Hu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We follow the split given by [5], using 64 classes to construct the base set, 16 for validation and 20 as the novel set.",
                "Our experiments are conducted on several widely few-shot learning benchmark datasets for general object recognition and fine-grained classification, including miniImageNet [36], tieredImageNet [37], CIFAR-FS [5] and CUB [54]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9b3f2536c2dbd5012227cca8eb32d4957b0d93dd",
                "externalIds": {
                    "MAG": "3013430732",
                    "DBLP": "conf/cvpr/WangXLZF20",
                    "ArXiv": "2003.11853",
                    "DOI": "10.1109/cvpr42600.2020.01285",
                    "CorpusId": 214667381
                },
                "corpusId": 214667381,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/9b3f2536c2dbd5012227cca8eb32d4957b0d93dd",
                "title": "Instance Credibility Inference for Few-Shot Learning",
                "abstract": "Few-shot learning (FSL) aims to recognize new objects with extremely limited training data for each category. Previous efforts are made by either leveraging meta-learning paradigm or novel principles in data augmentation to alleviate this extremely data-scarce problem. In contrast, this paper presents a simple statistical approach, dubbed Instance Credibility Inference (ICI) to exploit the distribution support of unlabeled instances for few-shot learning. Specifically, we first train a linear classifier with the labeled few-shot examples and use it to infer the pseudo-labels for the unlabeled data. To measure the credibility of each pseudo-labeled instance, we then propose to solve another linear regression hypothesis by increasing the sparsity of the incidental parameters and rank the pseudo-labeled instances with their sparsity degree. We select the most trustworthy pseudo-labeled instances alongside the labeled examples to re-train the linear classifier. This process is iterated until all the unlabeled samples are included in the expanded training set, i.e. the pseudo-label is converged for unlabeled data pool. Extensive experiments under two few-shot settings show that our simple approach can establish new state-of-the-arts on four widely used few-shot learning benchmark datasets including miniImageNet, tieredImageNet, CIFAR-FS, and CUB. Our code is available at: https://github.com/Yikai-Wang/ICI-FSL",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2108853258",
                        "name": "Yikai Wang"
                    },
                    {
                        "authorId": "2708397",
                        "name": "C. Xu"
                    },
                    {
                        "authorId": "2108118336",
                        "name": "Chen Liu"
                    },
                    {
                        "authorId": "48571183",
                        "name": "Li Zhang"
                    },
                    {
                        "authorId": "35782003",
                        "name": "Yanwei Fu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We train 100 epochs for miniImageNet, 60 epochs for tieredImageNet, and 90\nepochs for both CIFAR-FS and FC100.",
                "Table 2 summarizes the results, which shows that our simple baseline is comparable to Prototypical Networks [46] and MetaOptNet [26] on CIFAR-FS dataset, and outperforms both of them on FC100 dataset.",
                "Table 4 shows the results of our ablation studies on miniImageNet, tieredImageNet, CIFAR-FS, and FC100.",
                "For 4-layer convnet, we also the same training setup as ResNet-12 on tieredImageNet, CIFAR-FS, and FC100, For miniImageNet, we train for 240 epochs with learning rate decayed at epochs 150, 180, and 210 with a factor of 0.1.",
                "In Table 1, Table 2, and Table 4, we evalute the model of the second generation on miniImageNet, CIFAR-FS and\nFC100 datasets; we use the first generation on tieredImageNet.",
                "The CIFAR-FS dataset [3] is a derivative of the original CIFAR-100 dataset by randomly splitting 100 classes into 64, 16 and 20 classes for training, validation, and testing, respectively.",
                "We conduct experiments on four widely used few-shot image recognition benchmarks: miniImageNet [54], tieredImageNet [42], CIFAR-FS [3], and FC100 [34].",
                "The plots of 1-shot and 5-shot results on miniImageNet and CIFAR-FS are shown in Figure 4."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "80455126562cfe6a483e02b3446a3f30b8e9f229",
                "externalIds": {
                    "MAG": "3013644914",
                    "DBLP": "conf/eccv/TianWKTI20",
                    "ArXiv": "2003.11539",
                    "DOI": "10.1007/978-3-030-58568-6_16",
                    "CorpusId": 214641252
                },
                "corpusId": 214641252,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/80455126562cfe6a483e02b3446a3f30b8e9f229",
                "title": "Rethinking Few-Shot Image Classification: a Good Embedding Is All You Need?",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2476765",
                        "name": "Yonglong Tian"
                    },
                    {
                        "authorId": "2118462083",
                        "name": "Yue Wang"
                    },
                    {
                        "authorId": "1707347",
                        "name": "Dilip Krishnan"
                    },
                    {
                        "authorId": "1763295",
                        "name": "J. Tenenbaum"
                    },
                    {
                        "authorId": "2094770",
                        "name": "Phillip Isola"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In [19], the final layer of a segmentation network is predicted by closed-form ridge regression [3], using the reference example pair.",
                "Meta-learning for VOS: Since the VOS task itself includes a few-shot learning problem, it can be addressed with techniques developed for meta-learning [10,3,16]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "79304c6c8f8689ff2e8fd37383d0691c991f7181",
                "externalIds": {
                    "MAG": "3106773277",
                    "DBLP": "conf/eccv/BhatLDRFGT20",
                    "ArXiv": "2003.11540",
                    "DOI": "10.1007/978-3-030-58536-5_46",
                    "CorpusId": 214640989
                },
                "corpusId": 214640989,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/79304c6c8f8689ff2e8fd37383d0691c991f7181",
                "title": "Learning What to Learn for Video Object Segmentation",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "49922196",
                        "name": "Goutam Bhat"
                    },
                    {
                        "authorId": "3451384",
                        "name": "Felix J\u00e4remo Lawin"
                    },
                    {
                        "authorId": "2488938",
                        "name": "Martin Danelljan"
                    },
                    {
                        "authorId": "48325722",
                        "name": "Andreas Robinson"
                    },
                    {
                        "authorId": "2228323",
                        "name": "M. Felsberg"
                    },
                    {
                        "authorId": "1681236",
                        "name": "L. Gool"
                    },
                    {
                        "authorId": "1732855",
                        "name": "R. Timofte"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Most of the current few-shot classification benchmarks [1,22,36,51] include a single visual domain, i."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "074ce9a6b07211e4682046cd6f50678ff008a813",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2003-09338",
                    "MAG": "3012473455",
                    "ArXiv": "2003.09338",
                    "CorpusId": 214605591
                },
                "corpusId": 214605591,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/074ce9a6b07211e4682046cd6f50678ff008a813",
                "title": "Selecting Relevant Features from a Universal Representation for Few-shot Classification",
                "abstract": "Popular approaches for few-shot classification consist of first learning a generic data representation based on a large annotated dataset, before adapting the representation to new classes given only a few labeled samples. In this work, we propose a new strategy based on feature selection, which is both simpler and more effective than previous feature adaptation approaches. First, we obtain a multi-domain representation by training a set of semantically different feature extractors. Then, given a few-shot learning task, we use our multi-domain feature bank to automatically select the most relevant representations. We show that a simple non-parametric classifier built on top of such features produces high accuracy and generalizes to domains never seen during training, which leads to state-of-the-art results on MetaDataset and improved accuracy on mini-ImageNet.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "24015161",
                        "name": "Nikita Dvornik"
                    },
                    {
                        "authorId": "2462253",
                        "name": "C. Schmid"
                    },
                    {
                        "authorId": "2599292",
                        "name": "J. Mairal"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b1f73ed3e27b9d219c3b469bb579e70cdfd591f9",
                "externalIds": {
                    "DBLP": "conf/eccv/DvornikSM20",
                    "MAG": "3043470355",
                    "DOI": "10.1007/978-3-030-58607-2_45",
                    "CorpusId": 221493032
                },
                "corpusId": 221493032,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/b1f73ed3e27b9d219c3b469bb579e70cdfd591f9",
                "title": "Selecting Relevant Features from a Multi-domain Representation for Few-Shot Classification",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "24015161",
                        "name": "Nikita Dvornik"
                    },
                    {
                        "authorId": "2462253",
                        "name": "C. Schmid"
                    },
                    {
                        "authorId": "2599292",
                        "name": "J. Mairal"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We conduct few-shot classification experiments on five popular benchmark datasets, namely, miniImageNet [1], tieredImageNet [61], Fewshot-CIFAR100 (FC100) [4], Caltech-UCSD Birds-200-2011 (CUB) [110], and CIFAR-FewShot (CIFAR-FS) [111].\nminiImageNet. miniImageNetwas first proposed in [1] and becomes the most popular benchmark in the few-shot classification literature.",
                "We observe that on the FC100 and CIFAR-FS datasets, DeepEMD-FCN outperforms DeepEMD-Grid and DeepEMD-Sampling, which is different from the observations on other datasets.",
                "Experiments on five popular few-shot classification benchmark datasets\u2014miniImagenet, tieredImagenet, FC100, CUB, and CIFAR-FS show that our algorithm on both 1-shot and 5-shot classification tasks significantly outperforms the baselinemethods and achieves new state-of-the-art performance.",
                "We conduct few-shot classification experiments on five popular benchmark datasets, namely, miniImageNet [1], tieredImageNet [61], Fewshot-CIFAR100 (FC100) [4], Caltech-UCSD Birds-200-2011 (CUB) [110], and CIFAR-FewShot (CIFAR-FS) [111].",
                "CIFAR-FS [111] is also a few-shot classification dataset built on CIFAR100 [113].",
                "We report 1-shot 5-way and 5-shot 5-way performance on 5 popular benchmarks:miniImageNet, tieredImageNet, FC100, CUB and CIFAR-FS.",
                "Our extensive experiments validate the effectiveness of our algorithm which outperforms state-of-the-art methods by a significant margin on five widely used few-shot classification benchmarks, namely, miniImageNet, tieredImageNet, Fewshot-CIFAR100 (FC100), Caltech-UCSD Birds-200-2011 (CUB), and CIFAR-FewShot (CIFAR-FS)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "7eddaa5da37658a8c3bfe80e770079b38d6c96ca",
                "externalIds": {
                    "DBLP": "journals/pami/ZhangCLS23",
                    "MAG": "3022615309",
                    "ArXiv": "2003.06777",
                    "DOI": "10.1109/TPAMI.2022.3217373",
                    "CorpusId": 218571015,
                    "PubMed": "36288227"
                },
                "corpusId": 218571015,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7eddaa5da37658a8c3bfe80e770079b38d6c96ca",
                "title": "DeepEMD: Differentiable Earth Mover's Distance for Few-Shot Learning",
                "abstract": "In this work, we develop methods for few-shot image classification from a new perspective of optimal matching between image regions. We employ the Earth Mover's Distance (EMD) as a metric to compute a structural distance between dense image representations to determine image relevance. The EMD generates the optimal matching flows between structural elements that have the minimum matching cost, which is used to calculate the image distance for classification. To generate the important weights of elements in the EMD formulation, we design a cross-reference mechanism, which can effectively alleviate the adverse impact caused by the cluttered background and large intra-class appearance variations. To implement <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"lin-ieq1-3217373.gif\"/></alternatives></inline-formula>-shot classification, we propose to learn a structured fully connected layer that can directly classify dense image representations with the EMD. Based on the implicit function theorem, the EMD can be inserted as a layer into the network for end-to-end training. Our extensive experiments validate the effectiveness of our algorithm which outperforms state-of-the-art methods by a significant margin on five widely used few-shot classification benchmarks, namely, miniImageNet, tieredImageNet, Fewshot-CIFAR100 (FC100), Caltech-UCSD Birds-200-2011 (CUB), and CIFAR-FewShot (CIFAR-FS). We also demonstrate the effectiveness of our method on the image retrieval task in our experiments.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "144876211",
                        "name": "Chi Zhang"
                    },
                    {
                        "authorId": "1928716951",
                        "name": "Yujun Cai"
                    },
                    {
                        "authorId": "2604251",
                        "name": "Guosheng Lin"
                    },
                    {
                        "authorId": "12459603",
                        "name": "Chunhua Shen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3e71a292d79a2d9033e25453197512aa5621fed6",
                "externalIds": {
                    "MAG": "3086806925",
                    "DBLP": "conf/aaai/KarlinskySALHSD21",
                    "DOI": "10.1609/aaai.v35i2.16268",
                    "CorpusId": 221771196
                },
                "corpusId": 221771196,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/3e71a292d79a2d9033e25453197512aa5621fed6",
                "title": "StarNet: towards Weakly Supervised Few-Shot Object Detection",
                "abstract": "Few-shot detection and classification have advanced significantly in recent years. Yet, detection approaches require strong annotation (bounding boxes) both for pre-training and for adaptation to novel classes, and classification approaches rarely provide localization of objects in the scene. In this paper, we introduce StarNet - a few-shot model featuring an end-to-end differentiable non-parametric star-model detection and classification head. Through this head, the backbone is meta-trained using only image-level labels to produce good features for jointly localizing and classifying previously unseen categories of few-shot test tasks using a star-model that geometrically matches between the query and support images (to find corresponding object instances). Being a few-shot detector, StarNet does not require any bounding box annotations, neither during pre-training nor for novel classes adaptation. It can thus be applied to the previously unexplored and challenging task of Weakly Supervised Few-Shot Object Detection (WS-FSOD), where it attains significant improvements over the baselines. In addition, StarNet shows significant gains on few-shot classification benchmarks that are less cropped around the objects (where object localization is key).",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2428823",
                        "name": "Leonid Karlinsky"
                    },
                    {
                        "authorId": "2636229",
                        "name": "J. Shtok"
                    },
                    {
                        "authorId": "73769093",
                        "name": "Amit Alfassy"
                    },
                    {
                        "authorId": "87230465",
                        "name": "M. Lichtenstein"
                    },
                    {
                        "authorId": "1879259",
                        "name": "Sivan Harary"
                    },
                    {
                        "authorId": "1455047952",
                        "name": "Eli Schwartz"
                    },
                    {
                        "authorId": "93556973",
                        "name": "Sivan Doveh"
                    },
                    {
                        "authorId": "1706272",
                        "name": "P. Sattigeri"
                    },
                    {
                        "authorId": "1723233",
                        "name": "R. Feris"
                    },
                    {
                        "authorId": "49791556",
                        "name": "A. Bronstein"
                    },
                    {
                        "authorId": "2711839",
                        "name": "R. Giryes"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In addition, we show that StarNet few-shot learner is effective at few-shot classification, significantly improving the state-of-the-art (SOTA) baselines on the CUB [50] and ImageNetLOC-FS [15] few-shot benchmarks, and comparing favorably to the SOTA methods on: miniImageNet [49], CIFAR-FS [2] and FC100 [30].",
                "Thus, for benchmarks with 84 \u00d7 84 input image resolution, the block strides were [2, 2, 2, 1] resulting in 10\u00d710 feature grids, and for 32\u00d7 32 input resolution, we used [2, 2, 1, 1] strides resulting in 8\u00d7 8 feature grids.",
                "The CIFAR-FS dataset [2], consists of all 100 classes from CIFAR-100 [17]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3cee676e56c7cacf33e706767b79f2f8dcb25db9",
                "externalIds": {
                    "ArXiv": "2003.06798",
                    "DBLP": "journals/corr/abs-2003-06798",
                    "MAG": "3012375608",
                    "CorpusId": 212725799
                },
                "corpusId": 212725799,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3cee676e56c7cacf33e706767b79f2f8dcb25db9",
                "title": "StarNet: towards weakly supervised few-shot detection and explainable few-shot classification",
                "abstract": "Few-shot learning for classification has advanced significantly in recent years. Yet, these approaches rarely provide interpretability related to their decisions or localization of objects in the scene. In this paper, we introduce StarNet, featuring an end-to-end differentiable non-parametric star-model classification head. Through this head, the backbone is meta-trained using only image-level labels to produce good features for classifying previously unseen categories of few-shot test tasks using a star-model that geometrically matches between the query and support images. This also results in localization of corresponding object instances (on the query and best matching support images), providing plausible explanations for StarNet's class predictions. We evaluate StarNet on multiple few-shot classification benchmarks attaining significant gains on CUB and ImageNetLOC-FS. In addition, we test the proposed approach on the previously unexplored and challenging task of Weakly Supervised Few-Shot Object Detection (WS-FSOD), obtaining significant improvements over the baselines.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2428823",
                        "name": "Leonid Karlinsky"
                    },
                    {
                        "authorId": "2636229",
                        "name": "J. Shtok"
                    },
                    {
                        "authorId": "73769093",
                        "name": "Amit Alfassy"
                    },
                    {
                        "authorId": "87230465",
                        "name": "M. Lichtenstein"
                    },
                    {
                        "authorId": "1879259",
                        "name": "Sivan Harary"
                    },
                    {
                        "authorId": "50053043",
                        "name": "Eli Schwartz"
                    },
                    {
                        "authorId": "93556973",
                        "name": "Sivan Doveh"
                    },
                    {
                        "authorId": "1706272",
                        "name": "P. Sattigeri"
                    },
                    {
                        "authorId": "1723233",
                        "name": "R. Feris"
                    },
                    {
                        "authorId": "49791556",
                        "name": "A. Bronstein"
                    },
                    {
                        "authorId": "2711839",
                        "name": "R. Giryes"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The main-stream approaches of meta-learning can be broadly categorized into three groups: optimization-based [22][10][11][25], metric-based [34][28][23][2][31] and memory-based [26]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2f41bef726b6c53dcb209ff04505526b47b52117",
                "externalIds": {
                    "ArXiv": "2003.03711",
                    "DBLP": "journals/corr/abs-2003-03711",
                    "MAG": "3009996512",
                    "CorpusId": 212633644
                },
                "corpusId": 212633644,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2f41bef726b6c53dcb209ff04505526b47b52117",
                "title": "Meta3D: Single-View 3D Object Reconstruction from Shape Priors in Memory",
                "abstract": "3D shape reconstruction from a single-view RGB image is an ill-posed problem due to the invisible parts of the object to be reconstructed. Most of the existing methods rely on large-scale data to obtain shape priors through tuning parameters of reconstruction models. These methods might not be able to deal with the cases with heavy object occlusions and noisy background since prior information can not be retained completely or applied efficiently. In this paper, we are the first to develop a memory-based meta-learning framework for single-view 3D reconstruction. A write controller is designed to extract shape-discriminative features from images and store image features and their corresponding volumes into external memory. A read controller is proposed to sequentially encode shape priors related to the input image and predict a shape-specific refiner. Experimental results demonstrate that our Meta3D outperforms state-of-the-art methods with a large margin through retaining shape priors explicitly, especially for the extremely difficult cases.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2131876172",
                        "name": "Shuo Yang"
                    },
                    {
                        "authorId": "2041286121",
                        "name": "Min Xu"
                    },
                    {
                        "authorId": "1720100",
                        "name": "H. Yao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Secondly, few-shot learning is an application to use meta learning [15],[16]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "107e59074cab6d4fcce885115b436924557d916c",
                "externalIds": {
                    "ArXiv": "2003.02038",
                    "MAG": "3009634095",
                    "DBLP": "journals/corr/abs-2003-02038",
                    "CorpusId": 211989918
                },
                "corpusId": 211989918,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/107e59074cab6d4fcce885115b436924557d916c",
                "title": "On Hyper-parameter Tuning for Stochastic Optimization Algorithms",
                "abstract": "This paper proposes the first-ever algorithmic framework for tuning hyper-parameters of stochastic optimization algorithm based on reinforcement learning. Hyper-parameters impose significant influences on the performance of stochastic optimization algorithms, such as evolutionary algorithms (EAs) and meta-heuristics. Yet, it is very time-consuming to determine optimal hyper-parameters due to the stochastic nature of these algorithms. We propose to model the tuning procedure as a Markov decision process, and resort the policy gradient algorithm to tune the hyper-parameters. Experiments on tuning stochastic algorithms with different kinds of hyper-parameters (continuous and discrete) for different optimization problems (continuous and discrete) show that the proposed hyper-parameter tuning algorithms do not require much less running times of the stochastic algorithms than bayesian optimization method. The proposed framework can be used as a standard tool for hyper-parameter tuning in stochastic algorithms.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "13390587",
                        "name": "Haotian Zhang"
                    },
                    {
                        "authorId": "1706546",
                        "name": "Jianyong Sun"
                    },
                    {
                        "authorId": "98220533",
                        "name": "Zongben Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "76% improvement over R2D2 [Bertinetto et al., 2019], CovaMNet, and DN4.",
                "We also obtain very competitive accuracy on 5-way 1-shot task with Conv embedding module, gaining 3.8%, 2.11%, 1.76% improvement over R2D2 [Bertinetto et al., 2019], CovaMNet, and DN4."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "a858990c05ada9adf800a91d44b1090abad760f2",
                "externalIds": {
                    "ArXiv": "2003.00874",
                    "DBLP": "journals/corr/abs-2003-00874",
                    "MAG": "3007429212",
                    "CorpusId": 211677677
                },
                "corpusId": 211677677,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a858990c05ada9adf800a91d44b1090abad760f2",
                "title": "Few-shot Learning with Weakly-supervised Object Localization",
                "abstract": "Few-shot learning (FSL) aims to learn novel visual categories from very few samples, which is a challenging problem in real-world applications. Many data generation methods have improved the performance of FSL models, but require lots of annotated images to train a specialized network (e.g., GAN) dedicated to hallucinate new samples. We argue that localization is a more efficient approach because it provides the most discriminative regions without using extra samples. In this paper, we propose a novel method to address the FSL task by achieving weakly-supervised object localization within performing few-shot classification. To this end, we design (i) a triplet-input module to obtain the initial object seeds and (ii) an Image-To-Class-Distance (ITCD) based localizer to activate the deep descriptors of the key objects, thus obtaining the more discriminative representations used to perform few-shot classification. Extensive experiments show our method outperforms the state-of-the-art methods on benchmark datasets under various settings. Besides, our method achieves superior performance over previous methods when training the model on miniImageNet and evaluating it on the different datasets (e.g., Stanford Dogs), demonstrating its superior generalization capacity. Extra visualization shows the proposed method can localize the key objects accurately.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1476769857",
                        "name": "Jinfu Lin"
                    },
                    {
                        "authorId": "1476816520",
                        "name": "Xiaojian He"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "48f57077826f88d078f5b18fadd9ea8523c69429",
                "externalIds": {
                    "MAG": "3007550519",
                    "ArXiv": "2003.00210",
                    "DBLP": "journals/tip/CaoZ22",
                    "DOI": "10.1109/TIP.2022.3142530",
                    "CorpusId": 211678309,
                    "PubMed": "35044916"
                },
                "corpusId": 211678309,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/48f57077826f88d078f5b18fadd9ea8523c69429",
                "title": "Learning to Compare Relation: Semantic Alignment for Few-Shot Learning",
                "abstract": "Few-shot learning is a fundamental and challenging problem since it requires recognizing novel categories from only a few examples. The objects for recognition have multiple variants and can locate anywhere in images. Directly comparing query images with example images can not handle content misalignment. The representation and metric for comparison are critical but challenging to learn due to the scarcity and wide variation of the samples in few-shot learning. In this paper, we present a novel semantic alignment model to compare relations, which is robust to content misalignment. We propose to add two key ingredients to existing few-shot learning frameworks for better feature and metric learning ability. First, we introduce a semantic alignment loss to align the relation statistics of the features from samples that belong to the same category. And second, local and global mutual information maximization is introduced, allowing for representations that contain locally-consistent and intra-class shared information across structural locations in an image. Furthermore, we introduce a principled approach to weigh multiple loss functions by considering the homoscedastic uncertainty of each stream. We conduct extensive experiments on several few-shot learning datasets. Experimental results show that the proposed method is capable of comparing relations with semantic alignment strategies, and achieves state-of-the-art performance.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "3201156",
                        "name": "Congqi Cao"
                    },
                    {
                        "authorId": "2047640322",
                        "name": "Yanning Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The following FSL baselines are selected: (1) State-of-theart GCN-based FSL methods [33, 12, 8]; (2) Representative/latest FSL methods (w/o GCN) [39, 6, 40, 30, 2, 1, 3, 16].",
                "(2) The improvements achieved by our method over the stateof-the-art FSL baselines [30, 2, 1, 3, 16] range from 1% to 6%, showing that AdarGCN has a great potential for FSL even with sufficient and clean training samples, due to its Branch d"
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c5a5a2c5a4c5bdc490c8d69f1005b7ba88e9be20",
                "externalIds": {
                    "DBLP": "conf/wacv/ZhangZLX21",
                    "ArXiv": "2002.12641",
                    "MAG": "3007721491",
                    "DOI": "10.1109/WACV48630.2021.00352",
                    "CorpusId": 211572877
                },
                "corpusId": 211572877,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/c5a5a2c5a4c5bdc490c8d69f1005b7ba88e9be20",
                "title": "AdarGCN: Adaptive Aggregation GCN for Few-Shot Learning",
                "abstract": "Existing few-shot learning (FSL) methods assume that there exist sufficient training samples from source classes for knowledge transfer to target classes with few training samples. However, this assumption is often invalid, especially when it comes to fine-grained recognition. In this work, we define a new FSL setting termed scarce-source few-shot learning (SSFSL), under which both the source and target classes have limited training samples. To overcome the source class data scarcity problem, a natural option is to crawl images from the web with class names as search keywords. However, the crawled images are inevitably corrupted by large amount of noise (irrelevant images) and thus may harm the performance. To address this problem, we propose a graph convolutional network (GCN)-based label denoising (LDN) method to remove the irrelevant images. Further, with the cleaned web images as well as the original clean training images, we propose a GCN-based FSL method. For both the LDN and FSL tasks, a novel adaptive aggregation GCN (AdarGCN) model is proposed, which differs from existing GCN models in that adaptive aggregation is performed based on a multi-head multi-level aggregation module. With AdarGCN, how much and how far information carried by each graph node is propagated in the graph structure can be determined automatically, therefore alleviating the effects of both noisy and outlying training samples. Extensive experiments demonstrate the superior performance of our AdarGCN under both the new SSFSL and the conventional FSL settings.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2108239433",
                        "name": "Jianhong Zhang"
                    },
                    {
                        "authorId": "151483168",
                        "name": "Manli Zhang"
                    },
                    {
                        "authorId": "1776220",
                        "name": "Zhiwu Lu"
                    },
                    {
                        "authorId": "145406421",
                        "name": "T. Xiang"
                    },
                    {
                        "authorId": "153693432",
                        "name": "Ji-rong Wen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This dataset (Bertinetto et al., 2019) is a variant of CIFAR-100 dataset used for few-shot classification, which contains 100 classes that describe general object categories."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "9325eba95f9ae67ac069fc29240f10ad237537b3",
                "externalIds": {
                    "ArXiv": "2002.12017",
                    "DBLP": "journals/corr/abs-2002-12017",
                    "MAG": "3007881937",
                    "CorpusId": 211532271
                },
                "corpusId": 211532271,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/9325eba95f9ae67ac069fc29240f10ad237537b3",
                "title": "Transductive Few-shot Learning with Meta-Learned Confidence",
                "abstract": "We propose a novel transductive inference framework for metric-based meta-learning models, which updates the prototype of each class with the confidence-weighted average of all the support and query samples. However, a caveat here is that the model confidence may be unreliable, which could lead to incorrect prediction in the transductive setting. To tackle this issue, we further propose to meta-learn to assign correct confidence scores to unlabeled queries. Specifically, we meta-learn the parameters of the distance-metric, such that the model can improve its transductive inference performance on unseen tasks with the generated confidence scores. We also consider various types of uncertainties to further enhance the reliability of the meta-learned confidence. We combine our transductive meta-learning scheme, Meta-Confidence Transduction (MCT) with a novel dense classifier, Dense Feature Matching Network (DFMN), which performs both instance-level and feature-level classification without global average pooling and validate it on four benchmark datasets. Our model achieves state-of-the-art results on all datasets, outperforming existing state-of-the-art models by 11.11% and 7.68% on miniImageNet and tieredImageNet dataset respectively. Further qualitative analysis confirms that this impressive performance gain is indeed due to its ability to assign high confidence to instances with the correct labels.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1509424106",
                        "name": "Seong Min Kye"
                    },
                    {
                        "authorId": "2110308284",
                        "name": "Haebeom Lee"
                    },
                    {
                        "authorId": "33250489",
                        "name": "Hoirin Kim"
                    },
                    {
                        "authorId": "35788904",
                        "name": "Sung Ju Hwang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "036da0dc917fc9f02a081d24ad7d4babe8ce06fb",
                "externalIds": {
                    "MAG": "3037023107",
                    "CorpusId": 220042845
                },
                "corpusId": 220042845,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/036da0dc917fc9f02a081d24ad7d4babe8ce06fb",
                "title": "Meta-Learned Confidence for Few-shot Learning",
                "abstract": "Transductive inference is an effective means of tackling the data deficiency problem in few-shot learning settings. A popular transductive inference technique for few-shot metric-based approaches, is to update the prototype of each class with the mean of the most confident query examples, or confidence-weighted average of all the query samples. However, a caveat here is that the model confidence may be unreliable, which may lead to incorrect predictions. To tackle this issue, we propose to meta-learn the confidence for each query sample, to assign optimal weights to unlabeled queries such that they improve the model's transductive inference performance on unseen tasks. We achieve this by meta-learning an input-adaptive distance metric over a task distribution under various model and data perturbations, which will enforce consistency on the model predictions under diverse uncertainties for unseen tasks. Moreover, we additionally suggest a regularization which explicitly enforces the consistency on the predictions across the different dimensions of a high-dimensional embedding vector. We validate our few-shot learning model with meta-learned confidence on four benchmark datasets, on which it largely outperforms strong recent baselines and obtains new state-of-the-art results. Further application on semi-supervised few-shot learning tasks also yields significant performance improvements over the baselines. The source code of our algorithm is available at this https URL.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1509424106",
                        "name": "Seong Min Kye"
                    },
                    {
                        "authorId": "2110308284",
                        "name": "Haebeom Lee"
                    },
                    {
                        "authorId": "33250489",
                        "name": "Hoirin Kim"
                    },
                    {
                        "authorId": "35788904",
                        "name": "Sung Ju Hwang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "More recent approaches leverage the fact that, in certain settings, the initial estimate can instead be updated using a convex optimization algorithm (Bertinetto et al., 2018; Lee et al., 2019)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1e2dec02197db68c7552f6a56e533009eb76600e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2002-11275",
                    "ArXiv": "2002.11275",
                    "MAG": "3007361404",
                    "CorpusId": 211505986
                },
                "corpusId": 211505986,
                "publicationVenue": {
                    "id": "c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                    "name": "Journal of machine learning research",
                    "type": "journal",
                    "alternate_names": [
                        "Journal of Machine Learning Research",
                        "J mach learn res",
                        "J Mach Learn Res"
                    ],
                    "issn": "1532-4435",
                    "alternate_issns": [
                        "1533-7928"
                    ],
                    "url": "http://www.ai.mit.edu/projects/jmlr/",
                    "alternate_urls": [
                        "http://jmlr.csail.mit.edu/",
                        "http://www.jmlr.org/",
                        "http://portal.acm.org/affiliated/jmlr"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1e2dec02197db68c7552f6a56e533009eb76600e",
                "title": "Adversarial Monte Carlo Meta-Learning of Optimal Prediction Procedures",
                "abstract": "We frame the meta-learning of prediction procedures as a search for an optimal strategy in a two-player game. In this game, Nature selects a prior over distributions that generate labeled data consisting of features and an associated outcome, and the Predictor observes data sampled from a distribution drawn from this prior. The Predictor's objective is to learn a function that maps from a new feature to an estimate of the associated outcome. We establish that, under reasonable conditions, the Predictor has an optimal strategy that is equivariant to shifts and rescalings of the outcome and is invariant to permutations of the observations and to shifts, rescalings, and permutations of the features. We introduce a neural network architecture that satisfies these properties. The proposed strategy performs favorably compared to standard practice in both parametric and nonparametric experiments.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "3422181",
                        "name": "Alexander Luedtke"
                    },
                    {
                        "authorId": "1507484715",
                        "name": "Incheoul Chung"
                    },
                    {
                        "authorId": "49726480",
                        "name": "Oleg Sofrygin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In fact, the scheme we analyze in this paper is closely related to Lee et al. (2019), Bertinetto et al. (2018)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "02841af780570666389643f2815460a10d9ae286",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2002-09434",
                    "ArXiv": "2002.09434",
                    "MAG": "3007684729",
                    "CorpusId": 211252411
                },
                "corpusId": 211252411,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/02841af780570666389643f2815460a10d9ae286",
                "title": "Few-Shot Learning via Learning the Representation, Provably",
                "abstract": "This paper studies few-shot learning via representation learning, where one uses $T$ source tasks with $n_1$ data per task to learn a representation in order to reduce the sample complexity of a target task for which there is only $n_2 (\\ll n_1)$ data. Specifically, we focus on the setting where there exists a good \\emph{common representation} between source and target, and our goal is to understand how much of a sample size reduction is possible. First, we study the setting where this common representation is low-dimensional and provide a fast rate of $O\\left(\\frac{\\mathcal{C}\\left(\\Phi\\right)}{n_1T} + \\frac{k}{n_2}\\right)$; here, $\\Phi$ is the representation function class, $\\mathcal{C}\\left(\\Phi\\right)$ is its complexity measure, and $k$ is the dimension of the representation. When specialized to linear representation functions, this rate becomes $O\\left(\\frac{dk}{n_1T} + \\frac{k}{n_2}\\right)$ where $d (\\gg k)$ is the ambient input dimension, which is a substantial improvement over the rate without using representation learning, i.e. over the rate of $O\\left(\\frac{d}{n_2}\\right)$. Second, we consider the setting where the common representation may be high-dimensional but is capacity-constrained (say in norm); here, we again demonstrate the advantage of representation learning in both high-dimensional linear regression and neural network learning. Our results demonstrate representation learning can fully utilize all $n_1T$ samples from source tasks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "145697585",
                        "name": "S. Du"
                    },
                    {
                        "authorId": "1471043558",
                        "name": "Wei Hu"
                    },
                    {
                        "authorId": "144695232",
                        "name": "S. Kakade"
                    },
                    {
                        "authorId": "2421201",
                        "name": "J. Lee"
                    },
                    {
                        "authorId": "144438755",
                        "name": "Qi Lei"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "cb4423652b23f12bf19dcbf7828128e0b9364904",
                "externalIds": {
                    "MAG": "3015474227",
                    "ArXiv": "2002.09143",
                    "DBLP": "conf/icassp/ShiSPKMW20",
                    "DOI": "10.1109/ICASSP40776.2020.9053336",
                    "CorpusId": 211252736
                },
                "corpusId": 211252736,
                "publicationVenue": {
                    "id": "0d6f7fba-7092-46b3-8039-93458dba736b",
                    "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Acoust Speech Signal Process",
                        "IEEE Int Conf Acoust Speech Signal Process",
                        "ICASSP",
                        "International Conference on Acoustics, Speech, and Signal Processing"
                    ],
                    "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
                },
                "url": "https://www.semanticscholar.org/paper/cb4423652b23f12bf19dcbf7828128e0b9364904",
                "title": "Few-Shot Acoustic Event Detection Via Meta Learning",
                "abstract": "We study few-shot acoustic event detection (AED) in this paper. Few-shot learning enables detection of new events with very limited labeled data. Compared to other research areas like computer vision, few-shot learning for audio recognition has been under-studied. We formulate few-shot AED problem and explore different ways of utilizing traditional supervised methods for this setting as well as a variety of meta-learning approaches, which are conventionally used to solve few-shot classification problem. Compared to supervised baselines, meta-learning models achieve superior performance, thus showing its effectiveness on generalization to new audio events. Our analysis including impact of initialization and domain discrepancy further validate the advantage of meta-learning approaches in few-shot AED.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1633532182",
                        "name": "Bowen Shi"
                    },
                    {
                        "authorId": "145739665",
                        "name": "Ming Sun"
                    },
                    {
                        "authorId": "2255622151",
                        "name": "Krishna C. Puvvada"
                    },
                    {
                        "authorId": "1804844",
                        "name": "Chieh-Chi Kao"
                    },
                    {
                        "authorId": "145819149",
                        "name": "Spyros Matsoukas"
                    },
                    {
                        "authorId": "72462439",
                        "name": "Chao Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Table 2 also offers a comparison between LS Meta-Learning and Bertinetto et al. (2019). As discussed in Sec. 4.2 the two methods use same inner algorithm (empirical risk minimization with respect to the least-square loss) but different task loss functions (least squares for ours and cross-entropy for Bertinetto et al. (2019)).",
                "Bertinetto et al. (2019) proposed Alg(\u03b8,D) to perform empirical risk minimization of fW over D = (xi, yi) m i=1 with respect to the least-squares loss `(y, y\u2032) = \u2016y \u2212 y\u2032\u2016(2).",
                "Similar to Bertinetto et al. (2019), we chose the least-squares empirical risk minimizer as our inner algorithm.",
                "We introduce a practical and efficient algorithm for TASML, along with several algorithmic modifications aimed at improving model efficiency and performance, including: representation pre-training, optimization as a layer Amos & Kolter (2017); Bertinetto et al. (2019), and least-squares relaxation of classification loss.",
                "(2018), Bertinetto et al. (2019); Qiao et al. (2018), CAVIA Zintgraf et al. (2019), LEO Rusu et al. (2019) and META-SGD Li et al. (2017) with LEO\u2019s feature maps \u03c6 as input (from Rusu et al.",
                "Several MAML variants have focused on mitigating such issues Bertinetto et al. (2019); Rajeswaran et al.",
                "Several MAML variants have focused on mitigating such issues Bertinetto et al. (2019); Rajeswaran et al. (2019).",
                "We note that TASML is at least twice as fast as LEO since the model is both simpler and admits efficient meta-gradient computation with 2We tested our method with a cross entropy meta loss and achieved results similar to Bertinetto et al. (2019).",
                "Table 2 also offers a comparison between LS Meta-Learning and Bertinetto et al. (2019). As discussed in Sec.",
                "Similar to Bertinetto et al. (2019), we chose the least-squares empirical risk minimizer as our inner algorithm. However, we note that Bertinetto et al. (2019) uses the cross-entropy ` to induce L."
            ],
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2bfff2c10732a54918b38d5abea12b38af605ba2",
                "externalIds": {
                    "ArXiv": "2002.08799",
                    "DBLP": "journals/corr/abs-2002-08799",
                    "MAG": "3008227517",
                    "CorpusId": 211205120
                },
                "corpusId": 211205120,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2bfff2c10732a54918b38d5abea12b38af605ba2",
                "title": "A Structured Prediction Approach for Conditional Meta-Learning",
                "abstract": "Optimization-based meta-learning algorithms are a powerful class of methods for learning-to-learn applications such as few-shot learning. They tackle the limited availability of training data by leveraging the experience gained from previously observed tasks. However, when the complexity of the tasks distribution cannot be captured by a single set of shared meta-parameters, existing methods may fail to fully adapt to a target task. We address this issue with a novel perspective on conditional meta-learning based on structured prediction. We propose task-adaptive structured meta-learning (TASML), a principled estimator that weighs meta-training data conditioned on the target task to design tailored meta-learning objectives. In addition, we introduce algorithmic improvements to tackle key computational limitations of existing methods. Experimentally, we show that TASML outperforms state-of-the-art methods on benchmark datasets both in terms of accuracy and efficiency. An ablation study quantifies the individual contribution of model components and suggests useful practices for meta-learning.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "3368222",
                        "name": "Ruohan Wang"
                    },
                    {
                        "authorId": "1699337",
                        "name": "Y. Demiris"
                    },
                    {
                        "authorId": "7666146",
                        "name": "C. Ciliberto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "There are two perspectives on approaching meta-learning: optimization based (Li et al., 2017; Bertinetto et al., 2019; Zhou et al., 2018; Zintgraf et al., 2019; Rajeswaran et al., 2019), and probabilistic (Grant et al.",
                "There are two perspectives on approaching meta-learning: optimization based (Li et al., 2017; Bertinetto et al., 2019; Zhou et al., 2018; Zintgraf et al., 2019; Rajeswaran et al., 2019), and probabilistic (Grant et al., 2018; Finn et al., 2018; Kim et al., 2018; Harrison et al., 2018)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "69a575abf40636c967be86a0bde9fda65ca3375a",
                "externalIds": {
                    "MAG": "3034402086",
                    "ArXiv": "2002.08936",
                    "DBLP": "journals/corr/abs-2002-08936",
                    "CorpusId": 211204795
                },
                "corpusId": 211204795,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/69a575abf40636c967be86a0bde9fda65ca3375a",
                "title": "Meta-learning for mixed linear regression",
                "abstract": "In modern supervised learning, there are a large number of tasks, but many of them are associated with only a small amount of labeled data. These include data from medical image processing and robotic interaction. Even though each individual task cannot be meaningfully trained in isolation, one seeks to meta-learn across the tasks from past experiences by exploiting some similarities. We study a fundamental question of interest: When can abundant tasks with small data compensate for lack of tasks with big data? We focus on a canonical scenario where each task is drawn from a mixture of $k$ linear regressions, and identify sufficient conditions for such a graceful exchange to hold; The total number of examples necessary with only small data tasks scales similarly as when big data tasks are available. To this end, we introduce a novel spectral approach and show that we can efficiently utilize small data tasks with the help of $\\tilde\\Omega(k^{3/2})$ medium data tasks each with $\\tilde\\Omega(k^{1/2})$ examples.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2001138",
                        "name": "Weihao Kong"
                    },
                    {
                        "authorId": "51910830",
                        "name": "Raghav Somani"
                    },
                    {
                        "authorId": "2087073519",
                        "name": "Zhao Song"
                    },
                    {
                        "authorId": "144695232",
                        "name": "S. Kakade"
                    },
                    {
                        "authorId": "47342457",
                        "name": "Sewoong Oh"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "45dd2123ae90b0e8ff35d14f9ec3f4c75d3c81a2",
                "externalIds": {
                    "DBLP": "conf/nips/WangDC20",
                    "MAG": "3102329536",
                    "CorpusId": 224815691
                },
                "corpusId": 224815691,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/45dd2123ae90b0e8ff35d14f9ec3f4c75d3c81a2",
                "title": "Structured Prediction for Conditional Meta-Learning",
                "abstract": "The goal of optimization-based meta-learning is to find a single initialization shared across a distribution of tasks to speed up the process of learning new tasks. Conditional meta-learning seeks task-specific initialization to better capture complex task distributions and improve performance. However, many existing conditional methods are difficult to generalize and lack theoretical guarantees. In this work, we propose a new perspective on conditional meta-learning via structured prediction. We derive task-adaptive structured meta-learning (TASML), a principled framework that yields task-specific objective functions by weighing meta-training data on target tasks. Our non-parametric approach is model-agnostic and can be combined with existing meta-learning methods to achieve conditioning. Empirically, we show that TASML improves the performance of existing meta-learning models, and outperforms the state-of-the-art on benchmark datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "3368222",
                        "name": "Ruohan Wang"
                    },
                    {
                        "authorId": "1699337",
                        "name": "Y. Demiris"
                    },
                    {
                        "authorId": "7666146",
                        "name": "C. Ciliberto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This problem is often motivated by the ability of humans to learn new tasks from few examples [18, 19], which has given rise to meta-learning [37, 27, 31, 2, 10], or learning to learn."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7415be1325a8c0efd2d0660a876303f85bdd84c8",
                "externalIds": {
                    "MAG": "3006469715",
                    "DBLP": "journals/corr/abs-2002-07522",
                    "ArXiv": "2002.07522",
                    "DOI": "10.1109/ICPR48806.2021.9412902",
                    "CorpusId": 209486564
                },
                "corpusId": 209486564,
                "publicationVenue": {
                    "id": "48782cc2-a3b4-44f3-95a4-2c4cb0f7245b",
                    "name": "International Conference on Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "Pattern Recognit (ICPR Proc Int Conf",
                        "Int Conf Pattern Recognit",
                        "ICPR",
                        "International conference on pattern recognition",
                        "Int conf pattern recognit",
                        "Pattern Recognition (ICPR), Proceedings of the International Conference on"
                    ],
                    "issn": "1041-3278",
                    "alternate_issns": [
                        "1051-4651"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=4740202"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7415be1325a8c0efd2d0660a876303f85bdd84c8",
                "title": "Few-Shot Few-Shot Learning and the role of Spatial Attention",
                "abstract": "Few-shot learning is often motivated by the ability of humans to learn new tasks from few examples. However, standard few-shot classification benchmarks assume that the representation is learned on a limited amount of base class data, ignoring the amount of prior knowledge that a human may have accumulated before learning new tasks. At the same time, even if a powerful representation is available, it may happen in some domain that base class data are limited or non-existent. This motivates us to study a problem where the representation is obtained from a classifier pre-trained on a large-scale dataset of a different domain, assuming no access to its training process, while the base class data are limited to few examples per class and their role is to adapt the representation to the domain at hand rather than learn from scratch. We adapt the representation in two stages, namely on the few base class data if available and on the even fewer data of new tasks. In doing so, we obtain from the pre-trained classifier a spatial attention map that allows focusing on objects and suppressing background clutter. This is important in the new problem, because when base class data are few, the network cannot learn where to focus implicitly. We also show that a pre-trained network may be easily adapted to novel classes, without meta-learning.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "84595722",
                        "name": "Yann Lifchitz"
                    },
                    {
                        "authorId": "1744904",
                        "name": "Yannis Avrithis"
                    },
                    {
                        "authorId": "29376389",
                        "name": "Sylvaine Picard"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2019) and R2-D2 (Bertinetto et al., 2018), we find that meta-learning tends to cluster object classes more tightly in feature space.",
                "Such methods include R2-D2 and MetaOptNet (Bertinetto et al., 2018; Lee et al., 2019).",
                "\u2026strategies that fix the feature extractor and only update the last (classification) layer of a network during the inner-loop, such as MetaOptNet (Lee et al., 2019) and R2-D2 (Bertinetto et al., 2018), we find that meta-learning tends to cluster object classes more tightly in feature space.",
                "We train the R2-D2 and MetaOptNet backbones in this fashion on the mini-ImageNet and CIFAR-FS datasets, and we test these networks on both 1-shot and 5-shot tasks.",
                "The CIFAR-FS dataset samples images from CIFAR-100 (Bertinetto et al., 2018).",
                "R2-D2 and MetaOptNet achieve stronger performance than MAML and are able to harness larger architectures without overfitting.",
                "Using both R2-D2 and MetaOptNet backbones on both mini-ImageNet and CIFAR-FS datasets, networks trained with RFC exhibit higher similarity scores to meta-learned networks than networks trained classically but without RFC ."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "baba60a1c57833ee88ff7585f68a0f02d0efa29f",
                "externalIds": {
                    "DBLP": "conf/icml/GoldblumRFNCG20",
                    "ArXiv": "2002.06753",
                    "MAG": "3006505669",
                    "CorpusId": 211132835
                },
                "corpusId": 211132835,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/baba60a1c57833ee88ff7585f68a0f02d0efa29f",
                "title": "Unraveling Meta-Learning: Understanding Feature Representations for Few-Shot Tasks",
                "abstract": "Meta-learning algorithms produce feature extractors which achieve state-of-the-art performance on few-shot classification. While the literature is rich with meta-learning methods, little is known about why the resulting feature extractors perform so well. We develop a better understanding of the underlying mechanics of meta-learning and the difference between models trained using meta-learning and models which are trained classically. In doing so, we introduce and verify several hypotheses for why meta-learned models perform better. Furthermore, we develop a regularizer which boosts the performance of standard training routines for few-shot classification. In many cases, our routine outperforms meta-learning while simultaneously running an order of magnitude faster.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "121592562",
                        "name": "Micah Goldblum"
                    },
                    {
                        "authorId": "145653742",
                        "name": "Steven Reich"
                    },
                    {
                        "authorId": "120165773",
                        "name": "Liam H. Fowl"
                    },
                    {
                        "authorId": "3434279",
                        "name": "Renkun Ni"
                    },
                    {
                        "authorId": "1471176143",
                        "name": "Valeriia Cherepanova"
                    },
                    {
                        "authorId": "1962083",
                        "name": "T. Goldstein"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Among a variety of meta-learning formulations, MAML [12] has become especially popular due to its efficiency and flexibility, inspiring many follow-up works [1, 22, 26, 5, 21]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4aebc6a6c1390c62e37a6bf0c4ddd390d7bf3983",
                "externalIds": {
                    "MAG": "3101367184",
                    "DBLP": "conf/nips/CollinsMS20",
                    "CorpusId": 219956342
                },
                "corpusId": 219956342,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/4aebc6a6c1390c62e37a6bf0c4ddd390d7bf3983",
                "title": "Task-Robust Model-Agnostic Meta-Learning",
                "abstract": "Meta-learning methods have shown an impressive ability to train models that rapidly learn new tasks. However, these methods only aim to perform well in expectation over tasks coming from some particular distribution that is typically equivalent across meta-training and meta-testing, rather than considering worst-case task performance. In this work we introduce the notion of \"task-robustness\" by reformulating the popular Model-Agnostic Meta-Learning (MAML) objective [Finn et al. 2017] such that the goal is to minimize the maximum loss over the observed meta-training tasks. The solution to this novel formulation is task-robust in the sense that it places equal importance on even the most difficult and/or rare tasks. This also means that it performs well over all distributions of the observed tasks, making it robust to shifts in the task distribution between meta-training and meta-testing. We present an algorithm to solve the proposed min-max problem, and show that it converges to an $\\epsilon$-accurate point at the optimal rate of $\\mathcal{O}(1/\\epsilon^2)$ in the convex setting and to an $(\\epsilon, \\delta)$-stationary point at the rate of $\\mathcal{O}(\\max\\{1/\\epsilon^5, 1/\\delta^5\\})$ in nonconvex settings. We also provide an upper bound on the new task generalization error that captures the advantage of minimizing the worst-case task loss, and demonstrate this advantage in sinusoid regression and image classification experiments.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2057634000",
                        "name": "Liam Collins"
                    },
                    {
                        "authorId": "2706423",
                        "name": "Aryan Mokhtari"
                    },
                    {
                        "authorId": "1688634",
                        "name": "S. Shakkottai"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For R2-D2, we set the same training shot as for M-SVM, and used a learnable scale and bias following [3].",
                "the new images are associated to the novel classes with the method proposed in [3] on CIFAR-FS, FC100, miniImageNet few-shot learning tasks, and showed the second case got better results.",
                "In the evaluation of Task Aug for ProtoNets and M-SVM, we set pmax to the value getting the best results for R2-D2.",
                "The CIFAR-FS [3] containing all 100 classes from CIFAR100 [12] is proposed as few-shot classification benchmark recently.",
                "Therefore, in the experiment, the methods applied in the \u201cinner loop\u201d are able to classify data, and they are K-nearest neighbor (KNN), Support Vector Machine (SVM) and ridge regression, respectively [27, 15, 3].",
                "We proved that Task Aug was valid for CIFAR-FS, FC100, and miniImageNet,\nand exceeded the result of the previous works.",
                "It was different from [3] we used a fixed regularization parameter of ridge regression which was set to 50 because [3] has confirmed that making it learnable might not be helpful.",
                "For M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.1; and a learnable scale was used following [15].",
                "Previous studies have introduced many popular regularization techniques to few-shot learning from deep learning, such as weight decay, dropout, label smooth [3], and data augmentation.",
                "C V\n] 8\nthe new images are associated to the novel classes with the method proposed in [3] on CIFAR-FS, FC100, miniImageNet few-shot learning tasks, and showed the second case got better results.",
                "Same as CIFAR-FS, there are 600 nature color images of size 32\u00d7 32 in each class.",
                "In the experiments of comparing Task Aug and Image Aug by rotating, R2-D2 was applied, and we set T to 80000.",
                "We used ProtoNets [27], MetaOptNet-SVM [15] (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) [3] as basic methods to verify the effective of Task Aug.",
                "Then the proposed method is evaluated by experiments with the state of art meta-learning methods [27, 15, 3] on CIFAR-FS, FC100, miniImageNet fewshot learning tasks, and compare with the results without the data augmentation by rotating."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "94f24b06a8d6d92b20cba206079b37c3e3466a28",
                "externalIds": {
                    "MAG": "3006782633",
                    "DBLP": "journals/corr/abs-2003-00804",
                    "ArXiv": "2003.00804",
                    "CorpusId": 211677443
                },
                "corpusId": 211677443,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/94f24b06a8d6d92b20cba206079b37c3e3466a28",
                "title": "Task Augmentation by Rotating for Meta-Learning",
                "abstract": "Data augmentation is one of the most effective approaches for improving the accuracy of modern machine learning models, and it is also indispensable to train a deep model for meta-learning. In this paper, we introduce a task augmentation method by rotating, which increases the number of classes by rotating the original images 90, 180 and 270 degrees, different from traditional augmentation methods which increase the number of images. With a larger amount of classes, we can sample more diverse task instances during training. Therefore, task augmentation by rotating allows us to train a deep network by meta-learning methods with little over-fitting. Experimental results show that our approach is better than the rotation for increasing the number of images and achieves state-of-the-art performance on miniImageNet, CIFAR-FS, and FC100 few-shot learning benchmarks. The code is available on \\url{this http URL}.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2108415378",
                        "name": "Jialin Liu"
                    },
                    {
                        "authorId": "2864709",
                        "name": "F. Chao"
                    },
                    {
                        "authorId": "2146147406",
                        "name": "Chih-Min Lin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bbe741e6634adc40ea936798e94ae83b703b74fb",
                "externalIds": {
                    "MAG": "3010396240",
                    "DOI": "10.1017/9781139061773.015",
                    "CorpusId": 215888850
                },
                "corpusId": 215888850,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/bbe741e6634adc40ea936798e94ae83b703b74fb",
                "title": "Few-Shot Learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1777528",
                        "name": "H. Larochelle"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In [16] and [1], the authors create a class-weight generator by training the model with a linear classifier (e.",
                "We perform our experiments on 3 standardized few-shot classification datasets: miniImageNet [34], CUB [35] and CIFAR-FS [1].",
                "CIFAR-FS: This dataset has 100 classes, each class contains 600 images of size 32\u00d7 32 pixels."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e72273f31b31d3ba369ed3e23a46a2b28949f5b2",
                "externalIds": {
                    "ArXiv": "2001.09849",
                    "MAG": "3002474619",
                    "DBLP": "journals/corr/abs-2001-09849",
                    "CorpusId": 210920592
                },
                "corpusId": 210920592,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/e72273f31b31d3ba369ed3e23a46a2b28949f5b2",
                "title": "Exploiting Unsupervised Inputs for Accurate Few-Shot Classification",
                "abstract": "In few-shot classification, the aim is to learn models able to discriminate classes with only a small number of labelled examples. Most of the literature considers the problem of labelling a single unknown input at a time. Instead, it can be beneficial to consider a setting where a batch of unlabelled inputs are treated conjointly and non-independently. In this paper, we propose a method able to exploit three levels of information: a) feature extractors pretrained on generic datasets, b) few labelled examples of classes to discriminate and c) other available unlabelled inputs. If for a), we use state-of-the-art approaches, we introduce the use of simplified graph convolutions to perform b) and c) together. Our proposed model reaches state-of-the-art accuracy with a $6-11\\%$ increase compared to available alternatives on standard few-shot vision classification datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2143462361",
                        "name": "Yuqing Hu"
                    },
                    {
                        "authorId": "144916029",
                        "name": "Vincent Gripon"
                    },
                    {
                        "authorId": "2642628",
                        "name": "S. Pateux"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d93caee6be54387d7ae0b3ff0e18b8bd8fd10098",
                "externalIds": {
                    "DBLP": "conf/eccv/GuoCKCSSRF20",
                    "MAG": "3110608229",
                    "DOI": "10.1007/978-3-030-58583-9_8",
                    "CorpusId": 220128212
                },
                "corpusId": 220128212,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/d93caee6be54387d7ae0b3ff0e18b8bd8fd10098",
                "title": "A Broader Study of Cross-Domain Few-Shot Learning",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2329625",
                        "name": "Yunhui Guo"
                    },
                    {
                        "authorId": "40589056",
                        "name": "N. Codella"
                    },
                    {
                        "authorId": "2428823",
                        "name": "Leonid Karlinsky"
                    },
                    {
                        "authorId": "11465603",
                        "name": "James Codella"
                    },
                    {
                        "authorId": "2118965263",
                        "name": "John R. Smith"
                    },
                    {
                        "authorId": "2903226",
                        "name": "Kate Saenko"
                    },
                    {
                        "authorId": "1728828",
                        "name": "T. Rosing"
                    },
                    {
                        "authorId": "1723233",
                        "name": "R. Feris"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The common benchmarks for eval-\nuation are miniImageNet [33], CUB [34], Omniglot [18], CIFAR-FS [3] and tieredImageNet [27].",
                "uation are miniImageNet [33], CUB [34], Omniglot [18], CIFAR-FS [3] and tieredImageNet [27]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f2837994aed67daaebfff12689f4dbf9f9ab45cd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1912-07200",
                    "ArXiv": "1912.07200",
                    "MAG": "2994814245",
                    "CorpusId": 209376656
                },
                "corpusId": 209376656,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f2837994aed67daaebfff12689f4dbf9f9ab45cd",
                "title": "A New Benchmark for Evaluation of Cross-Domain Few-Shot Learning",
                "abstract": "Recent progress on few-shot learning has largely re-lied on annotated data for meta-learning, sampled from the same domain as the novel classes. However, in many applications, collecting data for meta-learning is infeasible or impossible. This leads to the cross-domain few-shot learn-ing problem, where a large domain shift exists between base and novel classes. Although some preliminary investigation of the few-shot methods under domain shift exists, a standard benchmark for cross-domain few-shot learning is not yet established. In this paper, we propose the cross-domain few-shot learning (CD-FSL) benchmark, consist-ing of images from diverse domains with varying similarity to ImageNet, ranging from crop disease images, satellite images, and medical images. Extensive experiments on the proposed benchmark are performed to compare an array of state-of-art meta-learning and transfer learning approaches, including various forms of single model fine-tuning and ensemble learning. The results demonstrate that current meta-learning methods underperform in relation to simple fine-tuning by 12.8% average accuracy. Accuracy of all methods tend to correlate with dataset similarity toImageNet. In addition, the relative performance gain with increasing number of shots is greater with transfer methods compared to meta-learning. Finally, we demonstrate that transferring from multiple pretrained models achieves best performance, with accuracy improvements of 14.9% and 1.9% versus the best of meta-learning and single model fine-tuning approaches, respectively. In summary, the proposed benchmark serves as a challenging platform to guide future research on cross-domain few-shot learning due to its spectrum of diversity and coverage",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2329625",
                        "name": "Yunhui Guo"
                    },
                    {
                        "authorId": "40589056",
                        "name": "N. Codella"
                    },
                    {
                        "authorId": "2428823",
                        "name": "Leonid Karlinsky"
                    },
                    {
                        "authorId": "2118965263",
                        "name": "John R. Smith"
                    },
                    {
                        "authorId": "3560620",
                        "name": "T. Simunic"
                    },
                    {
                        "authorId": "1723233",
                        "name": "R. Feris"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Metric-based approaches [2,12,21,25,27,33,42,44,45,47,53,57] learn a metric with the intent of reducing the intra-class variations while training on base categories."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "483b016c731d4917f3e077ffec1079ecd2241081",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1912-05094",
                    "ArXiv": "1912.05094",
                    "MAG": "2996255323",
                    "DOI": "10.1007/978-3-030-58558-7_2",
                    "CorpusId": 209202755
                },
                "corpusId": 209202755,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/483b016c731d4917f3e077ffec1079ecd2241081",
                "title": "Associative Alignment for Few-shot Image Classification",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "9050817",
                        "name": "Arman Afrasiyabi"
                    },
                    {
                        "authorId": "144430305",
                        "name": "Jean-Fran\u00e7ois Lalonde"
                    },
                    {
                        "authorId": "11146706",
                        "name": "Christian Gagn'e"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4d37014842f4fbc059506ebfdf63498fffaf68ae",
                "externalIds": {
                    "ArXiv": "1912.04973",
                    "DBLP": "journals/tip/DasL20",
                    "MAG": "3100653623",
                    "DOI": "10.1109/TIP.2019.2959254",
                    "CorpusId": 209202120,
                    "PubMed": "31869792"
                },
                "corpusId": 209202120,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4d37014842f4fbc059506ebfdf63498fffaf68ae",
                "title": "A Two-Stage Approach to Few-Shot Learning for Image Recognition",
                "abstract": "This paper proposes a multi-layer neural network structure for few-shot image recognition of novel categories. The proposed multi-layer neural network architecture encodes transferable knowledge extracted from a large annotated dataset of base categories. This architecture is then applied to novel categories containing only a few samples. The transfer of knowledge is carried out at the feature-extraction and the classification levels distributed across the two training stages. In the first-training stage, we introduce the relative feature to capture the structure of the data as well as obtain a low-dimensional discriminative space. Secondly, we account for the variable variance of different categories by using a network to predict the variance of each class. Classification is then performed by computing the Mahalanobis distance to the mean-class representation in contrast to previous approaches that used the Euclidean distance. In the second-training stage, a category-agnostic mapping is learned from the mean-sample representation to its corresponding class-prototype representation. This is because the mean-sample representation may not accurately represent the novel category prototype. Finally, we evaluate the proposed network structure on four standard few-shot image recognition datasets, where our proposed few-shot learning system produces competitive performance compared to previous work. We also extensively studied and analyzed the contribution of each component of our proposed framework.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "49950690",
                        "name": "Debasmit Das"
                    },
                    {
                        "authorId": "2194559714",
                        "name": "C. S. Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently proposed approaches to few-shot learning problem can be roughly divided into meta-learning based [16, 3, 4, 17, 18, 19] and weight-generation based approaches [20, 12, 5, 13, 21]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8e9f5f71c8efa68956c0d3dd64d267e293415031",
                "externalIds": {
                    "ArXiv": "1911.12476",
                    "DBLP": "journals/pr/LiangHPGL22",
                    "DOI": "10.1016/j.patcog.2022.108662",
                    "CorpusId": 233738940
                },
                "corpusId": 233738940,
                "publicationVenue": {
                    "id": "266f640f-003e-453b-ab76-57e4053252f8",
                    "name": "Pattern Recognition",
                    "type": "journal",
                    "alternate_names": [
                        "Pattern Recognit"
                    ],
                    "issn": "0031-3203",
                    "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description",
                    "alternate_urls": [
                        "https://www.journals.elsevier.com/pattern-recognition",
                        "http://www.sciencedirect.com/science/journal/00313203"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8e9f5f71c8efa68956c0d3dd64d267e293415031",
                "title": "Learning multi-level weight-centric features for few-shot learning",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2966244",
                        "name": "Min-Siong Liang"
                    },
                    {
                        "authorId": "2518836",
                        "name": "Shaoli Huang"
                    },
                    {
                        "authorId": "2585415",
                        "name": "Shirui Pan"
                    },
                    {
                        "authorId": "29393235",
                        "name": "Mingming Gong"
                    },
                    {
                        "authorId": "1654091065",
                        "name": "Wei Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The paper [17] shows that on top of the common feature extractor one may simply use a classifier with a closed-form solution for each few-shot task."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "08f780c4685da482f27b2d86c78d16e4573599b5",
                "externalIds": {
                    "MAG": "2981858346",
                    "DBLP": "phd/hal/Dvornik19",
                    "CorpusId": 214442469
                },
                "corpusId": 214442469,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/08f780c4685da482f27b2d86c78d16e4573599b5",
                "title": "Learning with Limited Annotated Data for Visual Understanding. (Apprentissage avec des donn\u00e9es annot\u00e9es limit\u00e9es pour une compr\u00e9hension visuelle)",
                "abstract": "Recuperation d'image a grande echelle avec les reseaux de neurones profonds. Le principal objectif de substituer les descripteurs traditionnels pour les images qui sont basees sur les caracteristiques artisanales avec celles extraites des reseaux de neurones convolutionnels profonds pour obtenir de meilleurs resultats dans la recuperation et avoir des representations des images qui sont plus robustes aux transformations d'image.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "1584402645",
                        "name": "Mikita Dvornik"
                    }
                ]
            }
        },
        {
            "contexts": [
                "-shot 5-shot 1-shot 5-shot MAML [6] ConvNet-32 58.9\u00b11.9 71.5\u00b11.0 - - Prototypical Networks [31] ConvNet-64 55.5\u00b10.7 72.0\u00b10.6 35.3\u00b10.6 48.6\u00b10.6 Relation Net [32] ConvNet-256 55.0\u00b11.0 69.3\u00b10.8 - - R2D2 [3] ConvNet-512 65.3\u00b10.2 79.4\u00b10.1 - - TADAM [23] ResNet-12 - - 40.1\u00b10.4 56.1\u00b10.4 MetaOptNet-SVM [14] ResNet-12 72.0\u00b10.7 84.2\u00b10.5 41.1\u00b10.6 55.5\u00b10.6 CSPN (ours) WRN-28-10 63.68\u00b10.85 80.00\u00b10.68 37.67\u00b10.67 5",
                "-level categories. These categories are split into 20/6/8 categories for training/validation/test. The splits include 351, 97, 160 lowlevel classes respectivelywith images of size 84 \u00d7 84. TheCIFAR-FS[3]isrecentlyproposedwhichisderived fromCIFAR-100[12] containingall 100classes ofCIFAR100. The 100 classes are randomly split into 64, 16, 20 classes for training, validation and test, by using the same "
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "633c5630ca60cdab63b50d836d5f7939a5fdd8ad",
                "externalIds": {
                    "DBLP": "conf/eccv/LiuSQ20",
                    "ArXiv": "1911.10713",
                    "MAG": "2991512408",
                    "DOI": "10.1007/978-3-030-58452-8_43",
                    "CorpusId": 208267646
                },
                "corpusId": 208267646,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/633c5630ca60cdab63b50d836d5f7939a5fdd8ad",
                "title": "Prototype Rectification for Few-Shot Learning",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "48210731",
                        "name": "Jinlu Liu"
                    },
                    {
                        "authorId": "143875337",
                        "name": "Liang Song"
                    },
                    {
                        "authorId": "2112437065",
                        "name": "Yongqiang Qin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The CIFAR-FS includes 100 classes which is derived from CIFAR-100 dataset [1] and each class has 600 images of size 32 \u00d7 32."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a01f0127795aff97199507242e313ce220906e61",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1911-10807",
                    "MAG": "2991528214",
                    "ArXiv": "1911.10807",
                    "CorpusId": 208268547
                },
                "corpusId": 208268547,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/a01f0127795aff97199507242e313ce220906e61",
                "title": "Fast and Generalized Adaptation for Few-Shot Learning",
                "abstract": "The ability of fast generalizing to novel tasks from a few examples is critical in dealing with few-shot learning problems. However, deep learning models severely suffer from overfitting in extreme low data regime. In this paper, we propose Adaptable Cosine Classifier (ACC) and Amphibian to achieve fast and generalized adaptation for few-shot learning. The ACC realizes the flexible retraining of a deep network on small data without overfitting. The Amphibian learns a good weight initialization in the parameter space where optimal solutions for the tasks of the same class cluster tightly. It enables rapid adaptation to novel tasks with few gradient updates. We conduct comprehensive experiments on four few-shot datasets and achieve state-of-the-art performance in all cases. Notably, we achieve the accuracy of 87.75% on 5-shot miniImageNet which approximately outperforms existing methods by 10%. We also conduct experiment on cross-domain few-shot tasks and provide the best results.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "143875337",
                        "name": "Liang Song"
                    },
                    {
                        "authorId": "48210731",
                        "name": "Jinlu Liu"
                    },
                    {
                        "authorId": "2112437065",
                        "name": "Yongqiang Qin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c3d90a4192a3a4253a922d04e8da97a60a5fee76",
                "externalIds": {
                    "MAG": "3009261266",
                    "CorpusId": 215924489
                },
                "corpusId": 215924489,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c3d90a4192a3a4253a922d04e8da97a60a5fee76",
                "title": "Generalized Adaptation for Few-Shot Learning",
                "abstract": "Many Few-Shot Learning research works have two stages: pre-training base model and adapting to novel model. In this paper, we propose to use closed-form base learner, which constrains the adapting stage with pre-trained base model to get better generalized novel model. Following theoretical analysis proves its rationality as well as indication of how to train a well-generalized base model. We then conduct experiments on four benchmarks and achieve state-of-the-art performance in all cases. Notably, we achieve the accuracy of 87.75% on 5-shot miniImageNet which approximately outperforms existing methods by 10%.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "143875337",
                        "name": "Liang Song"
                    },
                    {
                        "authorId": "48210731",
                        "name": "Jinlu Liu"
                    },
                    {
                        "authorId": "2112437065",
                        "name": "Yongqiang Qin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In fact, the ridge regression was originally designed for the regression task, we also adjust the prediction of base linear \u039b by Equation (5), as in (Bertinetto et al. 2019).",
                "In order to optimize the \u03c6 in Equation (2) by backpropagation and stochastic gradient descent (SGD), \u039b is preferred to be a simple and efficient model (e.g., nearest neighbor methods or linear models) (Bertinetto et al. 2019).",
                ", nearest neighbor methods or linear models) (Bertinetto et al. 2019).",
                "In fact, the ridge regression was originally designed for the regression task, we also adjust the prediction of base linear \u039b by Equation (5), as in (Bertinetto et al. 2019).\ny\u0302 = \u03b1X\u2032w + \u03b2, (5)\nwhere X\u2032 \u2208 Rn\u00d7c is the feature matrix of the test image."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "9658ec529cb2171e05dad830eb1ec53481cbec9c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1911-10371",
                    "ArXiv": "1911.10371",
                    "MAG": "2997884746",
                    "DOI": "10.1609/AAAI.V34I07.6887",
                    "CorpusId": 208268004
                },
                "corpusId": 208268004,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/9658ec529cb2171e05dad830eb1ec53481cbec9c",
                "title": "Differentiable Meta-learning Model for Few-shot Semantic Segmentation",
                "abstract": "To address the annotation scarcity issue in some cases of semantic segmentation, there have been a few attempts to develop the segmentation model in the few-shot learning paradigm. However, most existing methods only focus on the traditional 1-way segmentation setting (i.e., one image only contains a single object). This is far away from practical semantic segmentation tasks where the K-way setting (K > 1) is usually required by performing the accurate multi-object segmentation. To deal with this issue, we formulate the few-shot semantic segmentation task as a learning-based pixel classification problem, and propose a novel framework called MetaSegNet based on meta-learning. In MetaSegNet, an architecture of embedding module consisting of the global and local feature branches is developed to extract the appropriate meta-knowledge for the few-shot segmentation. Moreover, we incorporate a linear model into MetaSegNet as a base learner to directly predict the label of each pixel for the multi-object segmentation. Furthermore, our MetaSegNet can be trained by the episodic training mechanism in an end-to-end manner from scratch. Experiments on two popular semantic segmentation datasets, i.e., PASCAL VOC and COCO, reveal the effectiveness of the proposed MetaSegNet in the K-way few-shot semantic segmentation task.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "51305326",
                        "name": "Pinzhuo Tian"
                    },
                    {
                        "authorId": "1429833643",
                        "name": "Zhangkai Wu"
                    },
                    {
                        "authorId": "1785352346",
                        "name": "Lei Qi"
                    },
                    {
                        "authorId": null,
                        "name": "Lei Wang"
                    },
                    {
                        "authorId": "2475959",
                        "name": "Yinghuan Shi"
                    },
                    {
                        "authorId": "145644819",
                        "name": "Yang Gao"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4a58fb969ef0db81d837d12d65ed0acb019876de",
                "externalIds": {
                    "MAG": "2984260139",
                    "DBLP": "journals/nca/WangCHWF20",
                    "DOI": "10.1007/s00521-019-04605-y",
                    "CorpusId": 208060471
                },
                "corpusId": 208060471,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/4a58fb969ef0db81d837d12d65ed0acb019876de",
                "title": "Embedded adaptive cross-modulation neural network for few-shot learning",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2108818662",
                        "name": "Peng Wang"
                    },
                    {
                        "authorId": "2112570628",
                        "name": "Jun Cheng"
                    },
                    {
                        "authorId": "41022398",
                        "name": "Fusheng Hao"
                    },
                    {
                        "authorId": "2152509578",
                        "name": "Lei Wang"
                    },
                    {
                        "authorId": "2114324566",
                        "name": "Wei Feng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Catastrophic forgetting (Kemker et al. 2018) has been a long-standing issue in machine learning community due to the stability-plasticity dilemma (Ditzler et al. 2015)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "611d5d3e9081e6e15db4edba678f56016e024674",
                "externalIds": {
                    "ArXiv": "1911.04695",
                    "DBLP": "journals/corr/abs-1911-04695",
                    "MAG": "2984724235",
                    "CorpusId": 207863540
                },
                "corpusId": 207863540,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/611d5d3e9081e6e15db4edba678f56016e024674",
                "title": "Learning from the Past: Continual Meta-Learning via Bayesian Graph Modeling",
                "abstract": "Meta-learning for few-shot learning allows a machine to leverage previously acquired knowledge as a prior, thus improving the performance on novel tasks with only small amounts of data. However, most mainstream models suffer from catastrophic forgetting and insufficient robustness issues, thereby failing to fully retain or exploit long-term knowledge while being prone to cause severe error accumulation. In this paper, we propose a novel Continual Meta-Learning approach with Bayesian Graph Neural Networks (CML-BGNN) that mathematically formulates meta-learning as continual learning of a sequence of tasks. With each task forming as a graph, the intra- and inter-task correlations can be well preserved via message-passing and history transition. To remedy topological uncertainty from graph initialization, we utilize Bayes by Backprop strategy that approximates the posterior distribution of task-specific parameters with amortized inference networks, which are seamlessly integrated into the end-to-end edge learning. Extensive experiments conducted on the miniImageNet and tieredImageNet datasets demonstrate the effectiveness and efficiency of the proposed method, improving the performance by 42.8% compared with state-of-the-art on the miniImageNet 5-way 1-shot classification task.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "150350159",
                        "name": "Yadan Luo"
                    },
                    {
                        "authorId": "2109595617",
                        "name": "Zi Huang"
                    },
                    {
                        "authorId": "143644345",
                        "name": "Zheng Zhang"
                    },
                    {
                        "authorId": "47196880",
                        "name": "Ziwei Wang"
                    },
                    {
                        "authorId": "3019028",
                        "name": "Mahsa Baktash"
                    },
                    {
                        "authorId": "2152916796",
                        "name": "Yang Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2015), CIFAR-FS (Bertinetto et al., 2019), and mini-ImageNet (Vinyals et al.",
                "Datasets and settings In the following study, we use the standard 5-ways and 5-shots setting on the Omniglot (Lake et al., 2015), CIFAR-FS (Bertinetto et al., 2019), and mini-ImageNet (Vinyals et al., 2016) datasets.",
                "At CNN(6), there are degradations in performance by the original MAML on Omniglot and CIFAR-FS such that LinNet does not improve further.",
                "All methods improve the original MAML while meta-kfo improves the most on Omniglot and CIFAR-FS."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "870c56bae1b89e6a2fddb97d688a118323f762cf",
                "externalIds": {
                    "DBLP": "conf/aistats/ArnoldIS21",
                    "MAG": "3035021992",
                    "CorpusId": 219708686
                },
                "corpusId": 219708686,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/870c56bae1b89e6a2fddb97d688a118323f762cf",
                "title": "When MAML Can Adapt Fast and How to Assist When It Cannot",
                "abstract": "Model-Agnostic Meta-Learning (MAML) and its variants have achieved success in meta-learning tasks on many datasets and settings. On the other hand, we have just started to understand and analyze how they are able to adapt fast to new tasks. For example, one popular hypothesis is that the algorithms learn good representations for transfer, as in multi-task learning. In this work, we contribute by providing a series of empirical and theoretical studies, and discover several interesting yet previously unknown properties of the algorithm. We find MAML adapts better with a deep architecture even if the tasks need only a shallow one (and thus, no representation learning is needed). While echoing previous findings by others that the bottom layers in deep architectures enable representation learning, we also find that upper layers enable fast adaptation by being meta-learned to perform adaptive gradient update when generalizing to new tasks. Motivated by these findings, we study several meta-optimization approaches and propose a new one for learning to optimize adaptively. Those approaches attain stronger performance in meta-learning both shallower and deeper architectures than MAML.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "16378659",
                        "name": "S\u00e9bastien M. R. Arnold"
                    },
                    {
                        "authorId": "2899335",
                        "name": "Shariq Iqbal"
                    },
                    {
                        "authorId": "145757665",
                        "name": "Fei Sha"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al.",
                "As reported in Table 6, ours improves consistently 5-way 1/5-shot classification accuracy on mini-ImageNet, CIFAR-FS, and FC100.",
                "We evaluate our method on various classification datasets: CIFAR10/100 (Krizhevsky et al., 2009), Caltech-UCSD Birds or CUB200 (Wah et al.,\n2011), Indoor Scene Recognition or MIT67 (Quattoni & Torralba, 2009), Stanford Dogs (Khosla et al., 2011), and tiny-ImageNet3 for standard or imbalanced image classification; mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al., 2018) for few-shot classification.",
                "\u2026Scene Recognition or MIT67 (Quattoni & Torralba, 2009), Stanford Dogs (Khosla et al., 2011), and tiny-ImageNet3 for standard or imbalanced image classification; mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al., 2018) for few-shot classification.",
                "%) with 95% confidence intervals of 1000 5-way few-shot tasks on mini-ImageNet, CIFAR-FS, and FC100.",
                "The best accuracy is indicated as bold.\nmini-ImageNet CIFAR-FS FC100\nMethod 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot\nMAML\u2020 (Finn et al., 2017) 48.70\u00b11.84 63.11\u00b10.92 58.9\u00b11.9 71.5\u00b11.0 - - R2D2\u2020 (Bertinetto et al., 2019) - - 65.3\u00b10.2 79.4\u00b10.1 - -\nRelationNet\u2020 (Sung et al., 2018) 50.44\u00b10.82 65.32\u00b10.70 55.0\u00b11.0 69.3\u00b10.8 - - SNAIL (Mishra et al., 2018) 55.71\u00b10.99 68.88\u00b10.92 - - - - TADAM (Oreshkin et al., 2018) 58.50\u00b10.30 76.70\u00b10.30 - - 40.1\u00b10.4 56.1\u00b10.4 LEO\u2021 (Rusu et al., 2019) 61.76\u00b10.08 77.59\u00b10.12 - - - - MetaOptNet-SVM (Lee et al., 2019) 62.64\u00b10.61 78.63\u00b10.46 72.0\u00b10.7 84.2\u00b10.5 41.1\u00b10.6 55.5\u00b10.6\nProtoNet (Snell et al., 2017) 59.25\u00b10.64 75.60\u00b10.48 72.2\u00b10.7 83.5\u00b10.5 37.5\u00b10.6 52.5\u00b10.6 ProtoNet + SLA+AG (ours) 62.22\u00b10.69 77.78\u00b10.51 74.6\u00b10.7 86.8\u00b10.5 40.0\u00b10.6 55.7\u00b10.6\nMetaOptNet-RR (Lee et al., 2019) 61.41\u00b10.61 77.88\u00b10.46 72.6\u00b10.7 84.3\u00b10.5 40.5\u00b10.6 55.3\u00b10.6 MetaOptNet-RR + SLA+AG (ours) 62.93\u00b10.63 79.63\u00b10.47 73.5\u00b10.7 86.7\u00b10.5 42.2\u00b10.6 59.2\u00b10.5\n(DeVries & Taylor, 2017), CutMix (Yun et al., 2019), AutoAugment (Cubuk et al., 2019), and FastAutoAugment (Lim et al., 2019) into recent architectures (Zagoruyko & Komodakis, 2016b; Han et al., 2017).",
                "\u2026CIFAR-FS FC100\nMethod 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot\nMAML\u2020 (Finn et al., 2017) 48.70\u00b11.84 63.11\u00b10.92 58.9\u00b11.9 71.5\u00b11.0 - - R2D2\u2020 (Bertinetto et al., 2019) - - 65.3\u00b10.2 79.4\u00b10.1 - -\nRelationNet\u2020 (Sung et al., 2018) 50.44\u00b10.82 65.32\u00b10.70 55.0\u00b11.0 69.3\u00b10.8 - - SNAIL (Mishra\u2026"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "6bfa8f8b09ec21fe06d4eee28c3fb6cce879be1d",
                "externalIds": {
                    "MAG": "3037584823",
                    "DBLP": "conf/icml/LeeHS20",
                    "CorpusId": 220249782
                },
                "corpusId": 220249782,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/6bfa8f8b09ec21fe06d4eee28c3fb6cce879be1d",
                "title": "Self-supervised Label Augmentation via Input Transformations",
                "abstract": "Self-supervised learning, which learns by constructing artificial labels given only the input signals, has recently gained considerable attention for learning representations with unlabeled datasets, i.e., learning without any human-annotated supervision. In this paper, we show that such a technique can be used to significantly improve the model accuracy even under fully-labeled datasets. Our scheme trains the model to learn both original and self-supervised tasks, but is different from conventional multi-task learning frameworks that optimize the summation of their corresponding losses. Our main idea is to learn a single unified task with respect to the joint distribution of the original and self-supervised labels, i.e., we augment original labels via self-supervision of input transformation. This simple, yet effective approach allows to train models easier by relaxing a certain invariant constraint during learning the original and self-supervised tasks simultaneously. It also enables an aggregated inference which combines the predictions from different augmentations to improve the prediction accuracy. Furthermore, we propose a novel knowledge transfer technique, which we refer to as self-distillation, that has the effect of the aggregated inference in a single (faster) inference. We demonstrate the large accuracy improvement and wide applicability of our framework on various fully-supervised settings, e.g., the few-shot and imbalanced classification scenarios.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "51122345",
                        "name": "Hankook Lee"
                    },
                    {
                        "authorId": "35788904",
                        "name": "Sung Ju Hwang"
                    },
                    {
                        "authorId": "143720148",
                        "name": "Jinwoo Shin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "cc23659e081440b23749579dd6c488d147a45534",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1910-05199",
                    "MAG": "2980037473",
                    "ArXiv": "1910.05199",
                    "CorpusId": 204401913
                },
                "corpusId": 204401913,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/cc23659e081440b23749579dd6c488d147a45534",
                "title": "Deep Kernel Transfer in Gaussian Processes for Few-shot Learning",
                "abstract": "Humans tackle new problems by making inferences that go far beyond the information available, reusing what they have previously learned, and weighing different alternatives in the face of uncertainty. Incorporating these abilities in an artificial system is a major objective in machine learning. Towards this goal, we adapt Gaussian Processes (GPs) to tackle the problem of few-shot learning. We propose a simple, yet effective variant of deep kernel learning in which the kernel is transferred across tasks, which we call deep kernel transfer. This approach is straightforward to implement, provides uncertainty quantification, and does not require estimation of task-specific parameters. We empirically demonstrate that the proposed method outperforms several state-of-the-art algorithms in few-shot regression, classification, and cross-domain adaptation.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "3366919",
                        "name": "Massimiliano Patacchiola"
                    },
                    {
                        "authorId": "31463533",
                        "name": "Jack Turner"
                    },
                    {
                        "authorId": "37120806",
                        "name": "Elliot J. Crowley"
                    },
                    {
                        "authorId": "1728216",
                        "name": "A. Storkey"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These include optimization-based meta-learners, such as model-agnostic meta-learner (MAML) [16], gradient unrolling [49], closed-form solvers [4], and convex learners [35]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0c1513b21d703e7e0d5a1d99a2ad5f6614a2706d",
                "externalIds": {
                    "DBLP": "conf/eccv/SuMH20",
                    "ArXiv": "1910.03560",
                    "MAG": "2980086073",
                    "DOI": "10.1007/978-3-030-58571-6_38",
                    "CorpusId": 203902614
                },
                "corpusId": 203902614,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/0c1513b21d703e7e0d5a1d99a2ad5f6614a2706d",
                "title": "When Does Self-supervision Improve Few-shot Learning?",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2148766061",
                        "name": "Jong-Chyi Su"
                    },
                    {
                        "authorId": "35208858",
                        "name": "Subhransu Maji"
                    },
                    {
                        "authorId": "73710317",
                        "name": "B. Hariharan"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0beceb58bf35073bf4abe1e0d9116c8525530179",
                "externalIds": {
                    "DBLP": "journals/pami/SunLCCS22",
                    "MAG": "2979747407",
                    "ArXiv": "1910.03648",
                    "DOI": "10.1109/TPAMI.2020.3018506",
                    "CorpusId": 203952963,
                    "PubMed": "32822293"
                },
                "corpusId": 203952963,
                "publicationVenue": {
                    "id": "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                    "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Pattern Anal Mach Intell"
                    ],
                    "issn": "0162-8828",
                    "url": "http://www.computer.org/tpami/",
                    "alternate_urls": [
                        "http://www.computer.org/portal/web/tpami",
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=34"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0beceb58bf35073bf4abe1e0d9116c8525530179",
                "title": "Meta-Transfer Learning Through Hard Tasks",
                "abstract": "Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, typical meta-learning models use shallow neural networks, thus limiting its effectiveness. In order to achieve top performance, some recent works tried to use the DNNs pre-trained on large-scale datasets but mostly in straight-forward manners, e.g., (1) taking their weights as a warm start of meta-training, and (2) freezing their convolutional layers as the feature extractor of base-learners. In this paper, we propose a novel approach called meta-transfer learning (MTL), which learns to transfer the weights of a deep NN for few-shot learning tasks. Specifically, meta refers to training multiple tasks, and transfer is achieved by learning scaling and shifting functions of DNN weights (and biases) for each task. To further boost the learning efficiency of MTL, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum of few-shot classification tasks. We conduct experiments for five-class few-shot classification tasks on three challenging benchmarks, miniImageNet, tieredImageNet, and Fewshot-CIFAR100 (FC100), in both supervised and semi-supervised settings. Extensive comparisons to related works validate that our MTL approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "32222907",
                        "name": "Qianru Sun"
                    },
                    {
                        "authorId": "3035233",
                        "name": "Yaoyao Liu"
                    },
                    {
                        "authorId": "150356012",
                        "name": "Zhaozheng Chen"
                    },
                    {
                        "authorId": "144078686",
                        "name": "Tat-Seng Chua"
                    },
                    {
                        "authorId": "48920094",
                        "name": "B. Schiele"
                    }
                ]
            }
        },
        {
            "contexts": [
                "2019b) or directly use a meta-optimizer to learn the optimization process (Ravi and Larochelle 2016); (2) metricbased few-shot learning methods, which propose to learn a generalized metric and matching functions from training tasks (Snell, Swersky, and Zemel 2017; Vinyals et al. 2016; Yang et al. 2018; Bertinetto et al. 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ca1b417cf0f7906b52851e650ee0c7b9f85a5089",
                "externalIds": {
                    "DBLP": "conf/aaai/YaoZWJWHCL20",
                    "MAG": "2997198750",
                    "ArXiv": "1910.03053",
                    "DOI": "10.1609/AAAI.V34I04.6142",
                    "CorpusId": 203902492
                },
                "corpusId": 203902492,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/ca1b417cf0f7906b52851e650ee0c7b9f85a5089",
                "title": "Graph Few-shot Learning via Knowledge Transfer",
                "abstract": "Towards the challenging problem of semi-supervised node classification, there have been extensive studies. As a frontier, Graph Neural Networks (GNNs) have aroused great interest recently, which update the representation of each node by aggregating information of its neighbors. However, most GNNs have shallow layers with a limited receptive field and may not achieve satisfactory performance especially when the number of labeled nodes is quite small. To address this challenge, we innovatively propose a graph few-shot learning (GFL) algorithm that incorporates prior knowledge learned from auxiliary graphs to improve classification accuracy on the target graph. Specifically, a transferable metric space characterized by a node embedding and a graph-specific prototype embedding function is shared between auxiliary graphs and the target, facilitating the transfer of structural knowledge. Extensive experiments and ablation studies on four real-world graph datasets demonstrate the effectiveness of our proposed model and the contribution of each component.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "18307037",
                        "name": "Huaxiu Yao"
                    },
                    {
                        "authorId": "3407809",
                        "name": "Chuxu Zhang"
                    },
                    {
                        "authorId": "2112556840",
                        "name": "Ying Wei"
                    },
                    {
                        "authorId": "1470716407",
                        "name": "Meng Jiang"
                    },
                    {
                        "authorId": "2893721",
                        "name": "Suhang Wang"
                    },
                    {
                        "authorId": "1768190",
                        "name": "Junzhou Huang"
                    },
                    {
                        "authorId": "144539424",
                        "name": "N. Chawla"
                    },
                    {
                        "authorId": "2109640666",
                        "name": "Z. Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We focus on four meta-learning algorithms: MAML, R2-D2, MetaOptNet, and ProtoNet [8, 3, 18, 29].",
                "In this work, we report performance on Omniglot, Mini-ImageNet, and CIFAR-FS [16, 31, 3].",
                "Table 1: R2-D2 [3], adversarially trained transfer learning, ADML [33], and our adversarially queried (AQ) R2-D2 model on 5-shot Mini-ImageNet."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1563e56e22d40769bdda91bffe481cfa3b9dac6c",
                "externalIds": {
                    "MAG": "2990520147",
                    "DBLP": "conf/nips/GoldblumFG20",
                    "CorpusId": 208176023
                },
                "corpusId": 208176023,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/1563e56e22d40769bdda91bffe481cfa3b9dac6c",
                "title": "Adversarially Robust Few-Shot Learning: A Meta-Learning Approach",
                "abstract": "Previous work on adversarially robust neural networks for image classification requires large training sets and computationally expensive training procedures. On the other hand, few-shot learning methods are highly vulnerable to adversarial examples. The goal of our work is to produce networks which both perform well at few-shot classification tasks and are simultaneously robust to adversarial examples. We develop an algorithm for producing adversarially robust meta-learners, and we thoroughly investigate factors which contribute to adversarial vulnerability. Moreover, our method achieves far superior robust performance on few-shot image classification tasks, such as Mini-ImageNet and CIFAR-FS, than robust transfer learning.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "121592562",
                        "name": "Micah Goldblum"
                    },
                    {
                        "authorId": "120165773",
                        "name": "Liam H. Fowl"
                    },
                    {
                        "authorId": "1962083",
                        "name": "T. Goldstein"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "70ee3fc509bd4a971f5e1b4e410d732ee3924515",
                "externalIds": {
                    "MAG": "2981707695",
                    "DBLP": "conf/iccv/ZhangZNXY19",
                    "DOI": "10.1109/ICCV.2019.00177",
                    "CorpusId": 204961178
                },
                "corpusId": 204961178,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/70ee3fc509bd4a971f5e1b4e410d732ee3924515",
                "title": "Variational Few-Shot Learning",
                "abstract": "We propose a variational Bayesian framework for enhancing few-shot learning performance. This idea is motivated by the fact that single point based metric learning approaches are inherently noise-vulnerable and easy-to-be-biased. In a nutshell, stochastic variational inference is invoked to approximate bias-eliminated class specific sample distributions. In the meantime, a classifier-free prediction is attained by leveraging the distribution statistics on novel samples. Extensive experimental results on several benchmarks well demonstrate the effectiveness of our distribution-driven few-shot learning framework over previous point estimates based methods, in terms of superior classification accuracy and robustness.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2151809495",
                        "name": "Jian Zhang"
                    },
                    {
                        "authorId": "50015607",
                        "name": "Chenglong Zhao"
                    },
                    {
                        "authorId": "5796401",
                        "name": "Bingbing Ni"
                    },
                    {
                        "authorId": "2153554889",
                        "name": "Minghao Xu"
                    },
                    {
                        "authorId": "1795291",
                        "name": "Xiaokang Yang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This amplitude is similar to the reported difference in accuracy between algorithms and higher than the confidence intervals usually reported when evaluating meta-learning algorithms [34] [8] [9] [11] [7] [36]."
            ],
            "intents": [
                "result"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bd23c7894239c9b2e84f46de489b4c221da5c683",
                "externalIds": {
                    "MAG": "2976736557",
                    "DBLP": "journals/corr/abs-1909-13579",
                    "ArXiv": "1909.13579",
                    "CorpusId": 203594041
                },
                "corpusId": 203594041,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/bd23c7894239c9b2e84f46de489b4c221da5c683",
                "title": "Meta-learning algorithms for Few-Shot Computer Vision",
                "abstract": "Few-Shot Learning is the challenge of training a model with only a small amount of data. Many solutions to this problem use meta-learning algorithms, i.e. algorithms that learn to learn. By sampling few-shot tasks from a larger dataset, we can teach these algorithms to solve new, unseen tasks. This document reports my work on meta-learning algorithms for Few-Shot Computer Vision. This work was done during my internship at Sicara, a French company building image recognition solutions for businesses. It contains: 1. an extensive review of the state-of-the-art in few-shot computer vision; 2. a benchmark of meta-learning algorithms for few-shot image classification; 3. the introduction to a novel meta-learning algorithm for few-shot object detection, which is still in development.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "1388055677",
                        "name": "Etienne Bennequin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "388ab8ff4f2ccb53064297da438fecded2f61a26",
                "externalIds": {
                    "MAG": "2975849227",
                    "DBLP": "journals/corr/abs-1909-13046",
                    "ArXiv": "1909.13046",
                    "DOI": "10.1109/IROS45743.2020.9341282",
                    "CorpusId": 203593815
                },
                "corpusId": 203593815,
                "publicationVenue": {
                    "id": "37275deb-3fcf-4d16-ae77-95db9899b1f3",
                    "name": "IEEE/RJS International Conference on Intelligent RObots and Systems",
                    "type": "conference",
                    "alternate_names": [
                        "IROS",
                        "Intelligent Robots and Systems",
                        "Intell Robot Syst",
                        "IEEE/RJS Int Conf Intell Robot Syst"
                    ],
                    "url": "http://www.iros.org/"
                },
                "url": "https://www.semanticscholar.org/paper/388ab8ff4f2ccb53064297da438fecded2f61a26",
                "title": "Meta Learning with Differentiable Closed-form Solver for Fast Video Object Segmentation",
                "abstract": "Video object segmentation plays a vital role to many robotic tasks, beyond the satisfied accuracy, quickly adapt to the new scenario with very limited annotations and conduct a quick inference are also important. In this paper, we are specifically concerned with the task of fast segmenting all pixels of a target object in all frames, given the annotation mask in the first frame. Even when such annotation is available, this remains a challenging problem because of the changing appearance and shape of the object over time. In this paper, we tackle this task by formulating it as a meta-learning problem, where the base learner grasping the semantic scene understanding for a general type of objects, and the meta learner quickly adapting the appearance of the target object with a few examples. Our proposed meta-learning method uses a closed form optimizer, the so-called \"ridge regression\", which has been shown to be conducive for fast and better training convergence. Moreover, we propose a mechanism, named \"block splitting\", to further speed up the training process as well as to reduce the number of learning parameters. In comparison with the state-of-the art methods, our proposed framework achieves significant boost up in processing speed, while having highly comparable performance compared to the best performing methods on the widely used datasets. Video demo can be found here 1.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2146400239",
                        "name": "Yu Liu"
                    },
                    {
                        "authorId": "2161037",
                        "name": "Lingqiao Liu"
                    },
                    {
                        "authorId": "9726614",
                        "name": "Haokui Zhang"
                    },
                    {
                        "authorId": "73768948",
                        "name": "S. H. Rezatofighi"
                    },
                    {
                        "authorId": "145950884",
                        "name": "I. Reid"
                    }
                ]
            }
        },
        {
            "contexts": [
                "From the image domain we use 4 few-shot learning benchmarks, namely MiniImageNet [37], Omniglot [25], CIFAR-FS [5] and FC100 [33] and 1 OCC benchmark dataset, the Multi-Task MNIST (MT-MNIST) dataset.",
                "Table 4 shows that applying the proposed sampling technique to MetaOptNet and Meta-SGD results in a significant accuracy increase in FS-OCC on the MiniImageNet, CIFAR-FS and FC100 datasets."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f42f87e4015f1aad3ed464b47c8644214b41748c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2007-04146",
                    "ArXiv": "2007.04146",
                    "MAG": "3002105122",
                    "DOI": "10.1609/aaai.v35i8.16913",
                    "CorpusId": 213591705
                },
                "corpusId": 213591705,
                "publicationVenue": {
                    "id": "bdc2e585-4e48-4e36-8af1-6d859763d405",
                    "name": "AAAI Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "National Conference on Artificial Intelligence",
                        "National Conf Artif Intell",
                        "AAAI Conf Artif Intell",
                        "AAAI"
                    ],
                    "url": "http://www.aaai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/f42f87e4015f1aad3ed464b47c8644214b41748c",
                "title": "Few-Shot One-Class Classification via Meta-Learning",
                "abstract": "Although few-shot learning and one-class classification (OCC), i.e., learning a binary classifier with data from only one class, have been separately well studied, their intersection remains rather unexplored. Our work addresses the few-shot OCC problem and presents a method to modify the episodic data sampling strategy of the model-agnostic meta-learning (MAML) algorithm to learn a model initialization particularly suited for learning few-shot OCC tasks. This is done by explicitly optimizing for an initialization which only requires few gradient steps with one-class minibatches to yield a performance increase on class-balanced test data. We provide a theoretical analysis that explains why our approach works in the few-shot OCC scenario, while other meta-learning algorithms fail, including the unmodified MAML. Our experiments on eight datasets from the image and time-series domains show that our method leads to better results than classical OCC and few-shot classification approaches, and demonstrate the ability to learn unseen tasks from only few normal class samples. Moreover, we successfully train anomaly detectors for a real-world application on sensor readings recorded during industrial manufacturing of workpieces with a CNC milling machine, by using few normal examples. Finally, we empirically demonstrate that the proposed data sampling technique increases the performance of more recent meta-learning algorithms in few-shot OCC and yields state-of-the-art results in this problem setting.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2560012",
                        "name": "A. Frikha"
                    },
                    {
                        "authorId": "2614774",
                        "name": "Denis Krompass"
                    },
                    {
                        "authorId": "2064641269",
                        "name": "Hans-Georg Koepken"
                    },
                    {
                        "authorId": "1700754",
                        "name": "Volker Tresp"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To this end, we apply the proposed approach of learning meta-optimizers to the example synthetic dataset, as well as popular benchmark datasets: Omniglot (Lake et al., 2015), mini-ImageNet (Ravi & Larochelle, 2017), and CIFAR-FS (Bertinetto et al., 2019).",
                "To examine this claim, we meta-train a model consisting of four convolutional layers (C1 - C4) and a final fully-connected layer (FC) on Omniglot (Lake et al., 2015) and CIFAR-FS (Bertinetto et al., 2019).",
                ", 2015), mini-ImageNet (Ravi & Larochelle, 2017), and CIFAR-FS (Bertinetto et al., 2019).",
                "\u2026datasets: the Omniglot where the setting is 10-way classification with 5-shots and 4 adaptation steps, using the original 4-layer convolutional network (CNN) of Finn et al. (2017), and the CIFAR-FS dataset (Bertinetto et al., 2019), doing 10- way classification with 3-shots and 2 adaptation steps.",
                "Table A1: Accuracies and standar deviation of Meta-Learning of Non-Linear Models\nOmniglot CIFAR-FS\nNum.",
                "We focus on two datasets: the Omniglot where the setting is 10-way classification with 5-shots and 4 adaptation steps, using the original 4-layer convolutional network (CNN) of Finn et al. (2017), and the CIFAR-FS dataset (Bertinetto et al., 2019), doing 10- way classification with 3-shots and 2 adaptation steps.",
                "(2017), and the CIFAR-FS dataset (Bertinetto et al., 2019), doing 10way classification with 3-shots and 2 adaptation steps.",
                "As opposed to Bertinetto et al. (2019), our model closely resembles the one of our Omniglot experiments.",
                "The KFC architecture consists of 4 layers, such that the meta-optimizers contains a total of 134,171 parameters for the 2-layer CNN model and 267,451 parameters for the 4-layer CNN.\nCIFAR-FS We obtained the splits created by Bertinetto et al. (2019) and exactly reproduced their preprocessing setting for our experiments on CIFAR-FS.",
                "\u2026layers, such that the meta-optimizers contains a total of 134,171 parameters for the 2-layer CNN model and 267,451 parameters for the 4-layer CNN.\nCIFAR-FS We obtained the splits created by Bertinetto et al. (2019) and exactly reproduced their preprocessing setting for our experiments on CIFAR-FS."
            ],
            "intents": [
                "methodology",
                "result"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "caedd5bf470c3fbe9b330cb5b0649f02a128e2ff",
                "externalIds": {
                    "ArXiv": "1910.13603",
                    "DBLP": "journals/corr/abs-1910-13603",
                    "MAG": "2982641032",
                    "CorpusId": 204961482
                },
                "corpusId": 204961482,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/caedd5bf470c3fbe9b330cb5b0649f02a128e2ff",
                "title": "Decoupling Adaptation from Modeling with Meta-Optimizers for Meta Learning",
                "abstract": "Meta-learning methods, most notably Model-Agnostic Meta-Learning or MAML, have achieved great success in adapting to new tasks quickly, after having been trained on similar tasks. The mechanism behind their success, however, is poorly understood. We begin this work with an experimental analysis of MAML, finding that deep models are crucial for its success, even given sets of simple tasks where a linear model would suffice on any individual task. Furthermore, on image-recognition tasks, we find that the early layers of MAML-trained models learn task-invariant features, while later layers are used for adaptation, providing further evidence that these models require greater capacity than is strictly necessary for their individual tasks. Following our findings, we propose a method which enables better use of model capacity at inference time by separating the adaptation aspect of meta-learning into parameters that are only used for adaptation but are not part of the forward model. We find that our approach enables more effective meta-learning in smaller models, which are suitably sized for the individual tasks.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "16378659",
                        "name": "S\u00e9bastien M. R. Arnold"
                    },
                    {
                        "authorId": "2899335",
                        "name": "Shariq Iqbal"
                    },
                    {
                        "authorId": "145757665",
                        "name": "Fei Sha"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Table 2 contains 5-shot natural and robust accuracy on the Mini-ImageNet and CIFAR-FS datasets (Vinyals et al., 2016; Bertinetto et al., 2018).",
                "(Finn et al., 2017; Bertinetto et al., 2018; Lee et al., 2019; Snell et al., 2017).",
                "We found the expressiveness of the generator architecture used in the original DefenseGAN setup to be insufficient for even CIFAR-FS, so we substitute a stronger ProGAN generator to model the CIFAR-100 classes (Karras et al., 2017).",
                "We test this method on the MAML, ProtoNet, R2-D2, and MetaOptNet algorithms on the Mini-ImageNet and CIFAR-FS datasets (see Table 4).",
                "In this work, we report performance on OmniGlot, Mini-ImageNet, and CIFAR-FS (Lake et al., 2015; Vinyals et al., 2016; Bertinetto et al., 2018).",
                "All R2-D2 models are fine-tuned with a ridge regression head as in (Bertinetto et al., 2018), and we re-implement ADML from (Yin et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "aa9607327d7c3c0fa463510c46a9ed9a108df183",
                "externalIds": {
                    "ArXiv": "1910.00982",
                    "MAG": "2978775473",
                    "DBLP": "journals/corr/abs-1910-00982",
                    "CorpusId": 203626819
                },
                "corpusId": 203626819,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/aa9607327d7c3c0fa463510c46a9ed9a108df183",
                "title": "Robust Few-Shot Learning with Adversarially Queried Meta-Learners",
                "abstract": "Previous work on adversarially robust neural networks requires large training sets and computationally expensive training procedures. On the other hand, few-shot learning methods are highly vulnerable to adversarial examples. The goal of our work is to produce networks which both perform well at few-shot tasks and are simultaneously robust to adversarial examples. We adapt adversarial training for meta-learning, we adapt robust architectural features to small networks for meta-learning, we test pre-processing defenses as an alternative to adversarial training for meta-learning, and we investigate the advantages of robust meta-learning over robust transfer-learning for few-shot tasks. This work provides a thorough analysis of adversarially robust methods in the context of meta-learning, and we lay the foundation for future work on defenses for few-shot tasks.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "121592562",
                        "name": "Micah Goldblum"
                    },
                    {
                        "authorId": "120165773",
                        "name": "Liam H. Fowl"
                    },
                    {
                        "authorId": "1962083",
                        "name": "T. Goldstein"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We evaluate our method on various classification datasets: CIFAR10/100 (Krizhevsky et al., 2009), Caltech-UCSD Birds or CUB200 (Wah et al., 2011), Indoor Scene Recognition or MIT67 (Quattoni & Torralba, 2009), Stanford Dogs (Khosla et al., 2011), and tinyImageNet2 for standard or imbalanced image classification; mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al., 2018) for few-shot classification.",
                ", 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al.",
                "\u2026Scene Recognition or MIT67 (Quattoni & Torralba, 2009), Stanford Dogs (Khosla et al., 2011), and tinyImageNet2 for standard or imbalanced image classification; mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), and FC100 (Oreshkin et al., 2018) for few-shot classification.",
                "As reported in Table 5, ours improves consistently 5-way 1/5-shot classification accuracy on mini-ImageNet, CIFAR-FS, and FC100."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "88d08a5bd00a301455e0f6a454642550775fb427",
                "externalIds": {
                    "MAG": "2979927723",
                    "DBLP": "journals/corr/abs-1910-05872",
                    "ArXiv": "1910.05872",
                    "CorpusId": 204509054
                },
                "corpusId": 204509054,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/88d08a5bd00a301455e0f6a454642550775fb427",
                "title": "Rethinking Data Augmentation: Self-Supervision and Self-Distillation",
                "abstract": "Data augmentation techniques, e.g., flipping or cropping, which systematically enlarge the training dataset by explicitly generating more training samples, are effective in improving the generalization performance of deep neural networks. In the supervised setting, a common practice for data augmentation is to assign the same label to all augmented samples of the same source. However, if the augmentation results in large distributional discrepancy among them (e.g., rotations), forcing their label invariance may be too difficult to solve and often hurts the performance. To tackle this challenge, we suggest a simple yet effective idea of learning the joint distribution of the original and self-supervised labels of augmented samples. The joint learning framework is easier to train, and enables an aggregated inference combining the predictions from different augmented samples for improving the performance. Further, to speed up the aggregation process, we also propose a knowledge transfer technique, self-distillation, which transfers the knowledge of augmentation into the model itself. We demonstrate the effectiveness of our data augmentation framework on various fully-supervised settings including the few-shot and imbalanced classification scenarios.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "51122345",
                        "name": "Hankook Lee"
                    },
                    {
                        "authorId": "35788904",
                        "name": "Sung Ju Hwang"
                    },
                    {
                        "authorId": "143720148",
                        "name": "Jinwoo Shin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Other optimization-based algorithms have also since been developed, for example [18, 10, 4, 17, 38], which learn functions to embed the support set and test examples of a few-shot learning task, and then learn the weights of a task-specific classifier (using the support set) to perform few-shot classification on the embedded test examples."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "abf5478c24664a1380b7e213a3ab1c4af54775d0",
                "externalIds": {
                    "ArXiv": "1909.09157",
                    "DBLP": "conf/iclr/RaghuRBV20",
                    "MAG": "2995049146",
                    "CorpusId": 202712906
                },
                "corpusId": 202712906,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/abf5478c24664a1380b7e213a3ab1c4af54775d0",
                "title": "Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML",
                "abstract": "An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning. An especially successful algorithm has been Model Agnostic Meta-Learning (MAML), a method that consists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks. Despite MAML's popularity, a fundamental open question remains -- is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changes in the representations) or due to feature reuse, with the meta initialization already containing high quality features? We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor. This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we remove the inner loop for all but the (task-specific) head of a MAML-trained network. ANIL matches MAML's performance on benchmark few-shot image classification and RL and offers computational improvements over MAML. We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network (the NIL algorithm). We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "31411877",
                        "name": "Aniruddh Raghu"
                    },
                    {
                        "authorId": "40297238",
                        "name": "M. Raghu"
                    },
                    {
                        "authorId": "1751569",
                        "name": "Samy Bengio"
                    },
                    {
                        "authorId": "1689108",
                        "name": "Oriol Vinyals"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "43d726a2fb4941dbaf0508251cb8c0b84ee19758",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1909-09140",
                    "MAG": "2974734674",
                    "ArXiv": "1909.09140",
                    "CorpusId": 209997272
                },
                "corpusId": 209997272,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/43d726a2fb4941dbaf0508251cb8c0b84ee19758",
                "title": "Meta-Neighborhoods",
                "abstract": "Traditional methods for training neural networks use training data just once, as it is discarded after training. Instead, in this work we also leverage the training data during testing to adjust the network and gain more expressivity. Our approach, named Meta-Neighborhoods, is developed under a multi-task learning framework and is a generalization of k-nearest neighbors methods. It can flexibly adapt network parameters w.r.t. different query data using their respective local neighborhood information. Local information is learned and stored in a dictionary of learnable neighbors rather than directly retrieved from the training set for greater flexibility and performance. The network parameters and the dictionary are optimized end-to-end via meta-learning. Extensive experiments demonstrate that Meta-Neighborhoods consistently improved classification and regression performance across various network architectures and datasets. We also observed superior improvements than other state-of-the-art meta-learning methods designed to improve supervised learning.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "7774416",
                        "name": "Siyuan Shan"
                    },
                    {
                        "authorId": "50024187",
                        "name": "Yang Li"
                    },
                    {
                        "authorId": "143930995",
                        "name": "Junier B. Oliva"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2018), CIFAR-FS (Bertinetto et al., 2018), and Fewshot-CIFAR100 (Oreshkin et al.",
                "The library currently contains 5 few-shot classification problems: Omniglot (Lake et al., 2015, 2019), Mini-ImageNet (Vinyals et al., 2016; Ravi and Larochelle, 2017), Tiered-ImageNet (Ren et al., 2018), CIFAR-FS (Bertinetto et al., 2018), and Fewshot-CIFAR100 (Oreshkin et al., 2018)."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6c72c4ef7c76b4d64fa4c244ec38d70de053d97e",
                "externalIds": {
                    "ArXiv": "1909.06576",
                    "DBLP": "journals/corr/abs-1909-06576",
                    "MAG": "2972518327",
                    "CorpusId": 202578024
                },
                "corpusId": 202578024,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6c72c4ef7c76b4d64fa4c244ec38d70de053d97e",
                "title": "Torchmeta: A Meta-Learning library for PyTorch",
                "abstract": "The constant introduction of standardized benchmarks in the literature has helped accelerating the recent advances in meta-learning research. They offer a way to get a fair comparison between different algorithms, and the wide range of datasets available allows full control over the complexity of this evaluation. However, for a large majority of code available online, the data pipeline is often specific to one dataset, and testing on another dataset requires significant rework. We introduce Torchmeta, a library built on top of PyTorch that enables seamless and consistent evaluation of meta-learning algorithms on multiple datasets, by providing data-loaders for most of the standard benchmarks in few-shot classification and regression, with a new meta-dataset abstraction. It also features some extensions for PyTorch to simplify the development of models compatible with meta-learning algorithms. The code is available here: this https URL",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "7636193",
                        "name": "T. Deleu"
                    },
                    {
                        "authorId": "3478353",
                        "name": "Tobias W\u00fcrfl"
                    },
                    {
                        "authorId": "1379976263",
                        "name": "Mandana Samiei"
                    },
                    {
                        "authorId": "40061310",
                        "name": "Joseph Paul Cohen"
                    },
                    {
                        "authorId": "1751762",
                        "name": "Yoshua Bengio"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[14, 15], and (iii) \u201chyper-parameter optimisation\u201d which has been characterised as meta-learning for a single task [16]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e181e9c2cf01a91914a3c5c257437e133562c667",
                "externalIds": {
                    "MAG": "2991023628",
                    "DBLP": "conf/nips/0001TC19",
                    "CorpusId": 208029411
                },
                "corpusId": 208029411,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/e181e9c2cf01a91914a3c5c257437e133562c667",
                "title": "Fixing Implicit Derivatives: Trust-Region Based Learning of Continuous Energy Functions",
                "abstract": "We present a new technique for the learning of continuous energy functions that we refer to as Wibergian Learning. One common approach to inverse problems is to cast them as an energy minimisation problem, where the minimum cost solution found is used as an estimator of hidden parameters. Our new approach formally characterises the dependency between weights that control the shape of the energy function, and the location of minima, by describing minima as fixed points of optimisation methods. This allows for the use of gradient-based end-to- end training to integrate deep-learning and the classical inverse problem methods. We show how our approach can be applied to obtain state-of-the-art results in the diverse applications of tracker fusion and multiview 3D reconstruction.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "145485799",
                        "name": "Chris Russell"
                    },
                    {
                        "authorId": "51209920",
                        "name": "M. Toso"
                    },
                    {
                        "authorId": "2036351",
                        "name": "N. Campbell"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Prior work has considered a number of inner loops, ranging from a very general setting where all parameters are adapted using gradient descent [15], to more structured and specialized settings, such as ridge regression [8], Bayesian linear regression [23], and simulated annealing [2].",
                "and produce weight updates [25, 5, 33, 48] or predictions for new inputs [50, 12, 58, 40, 38], and optimization-based approaches that use bi-level optimization to embed learning procedures, such as gradient descent, into the meta-optimization problem [15, 13, 8, 60, 34, 17, 59, 23]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a2933c8d0e152264d1cd25ca8248b25d4b49038b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1909-04630",
                    "MAG": "2970697704",
                    "ArXiv": "1909.04630",
                    "CorpusId": 202542766
                },
                "corpusId": 202542766,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a2933c8d0e152264d1cd25ca8248b25d4b49038b",
                "title": "Meta-Learning with Implicit Gradients",
                "abstract": "A core capability of intelligent systems is the ability to quickly learn new tasks by drawing on prior experience. Gradient (or optimization) based meta-learning has recently emerged as an effective approach for few-shot learning. In this formulation, meta-parameters are learned in the outer loop, while task-specific models are learned in the inner-loop, by using only a small amount of data from the current task. A key challenge in scaling these approaches is the need to differentiate through the inner loop learning process, which can impose considerable computational and memory burdens. By drawing upon implicit differentiation, we develop the implicit MAML algorithm, which depends only on the solution to the inner level optimization and not the path taken by the inner loop optimizer. This effectively decouples the meta-gradient computation from the choice of inner loop optimizer. As a result, our approach is agnostic to the choice of inner loop optimizer and can gracefully handle many gradient steps without vanishing gradients or memory constraints. Theoretically, we prove that implicit MAML can compute accurate meta-gradients with a memory footprint that is, up to small constant factors, no more than that which is required to compute a single inner loop gradient and at no overall increase in the total computational cost. Experimentally, we show that these benefits of implicit MAML translate into empirical gains on few-shot image recognition benchmarks.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "19275599",
                        "name": "A. Rajeswaran"
                    },
                    {
                        "authorId": "46881670",
                        "name": "Chelsea Finn"
                    },
                    {
                        "authorId": "144695232",
                        "name": "S. Kakade"
                    },
                    {
                        "authorId": "1736651",
                        "name": "S. Levine"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This indicates that CIFAR-FS, FC-100 and Mini-ImageNet may be good benchmarks for applications with few classes.",
                "The first is the CIFAR-FS dataset [10] which splits classes randomly into 64 training, 16 validation and 20 test with 600 images in each.",
                "Our base28 line outperforms the state-of-the-art on a variety of benchmark datasets such as Mini-ImageNet [1], 29 Tiered-ImageNet [4], CIFAR-FS [5] and FC-100 [3], all with the same hyper-parameters.",
                "Our baseline outperforms the state-of-the-art on a variety of benchmark datasets such as Mini-ImageNet [1], Tiered-ImageNet [9], CIFAR-FS [10] and FC-100 [5], all with the same hyper-parameters.",
                "This section shows results of transductive fine-tuning on benchmark datasets in few-shot learning, 71 namely Mini-ImageNet [1], Tiered-ImageNet [4], CIFAR-FS [5] and FC-100 [3].",
                "For the Mini-ImageNet, CIFAR-FS and FC-100 datasets using additional data from the validation set to pre-train the backbone results in 2-8% improvements on the few-shot episodes; the improvement is smaller for Tiered-ImageNet.",
                "3 also shows that due to fewer test classes, CIFAR-FS, FC-100 and Mini-ImageNet have less diversity in the hardness of episodes while Tiered-ImageNet and Imagenet-21k allow sampling of both very hard and very easy diverse episodes.",
                "This section shows results of transductive fine-tuning on benchmark datasets in few-shot learning, namely Mini-ImageNet [1], Tiered-ImageNet [9], CIFAR-FS [10] and FC-100 [5].",
                "All hyper-parameters are kept constant for experiments on benchmark datasets, namely Mini-ImageNet, Tiered-ImageNet, CIFAR-FS and FC-100."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "c4b6162ae0e0aa99b910998a8f0e12450d7d22b7",
                "externalIds": {
                    "MAG": "2995589713",
                    "DBLP": "conf/iclr/DhillonCRS20",
                    "ArXiv": "1909.02729",
                    "CorpusId": 202230734
                },
                "corpusId": 202230734,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/c4b6162ae0e0aa99b910998a8f0e12450d7d22b7",
                "title": "A Baseline for Few-Shot Image Classification",
                "abstract": "Fine-tuning a deep network trained with the standard cross-entropy loss is a strong baseline for few-shot learning. When fine-tuned transductively, this outperforms the current state-of-the-art on standard datasets such as Mini-ImageNet, Tiered-ImageNet, CIFAR-FS and FC-100 with the same hyper-parameters. The simplicity of this approach enables us to demonstrate the first few-shot learning results on the ImageNet-21k dataset. We find that using a large number of meta-training classes results in high few-shot accuracies even for a large number of few-shot classes. We do not advocate our approach as the solution for few-shot learning, but simply use the results to highlight limitations of current benchmarks and few-shot protocols. We perform extensive studies on benchmark datasets to propose a metric that quantifies the \"hardness\" of a few-shot episode. This metric can be used to report the performance of few-shot algorithms in a more systematic way.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "16404879",
                        "name": "Guneet Singh Dhillon"
                    },
                    {
                        "authorId": "143976382",
                        "name": "P. Chaudhari"
                    },
                    {
                        "authorId": "2529423",
                        "name": "Avinash Ravichandran"
                    },
                    {
                        "authorId": "1715959",
                        "name": "Stefano Soatto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Learning algorithms In addition to the ridge regressor (RR) (Bertinetto et al., 2019), we evaluate two standard supervised learning algorithms and two meta-learning algorithms.",
                "We adopt ridge regression (Bertinetto et al., 2019) to fit the labeled support set for the following reasons: 1) ridge regression admits a closed-form solution that enables end-to-end differentiation through the model, and 2) with proper regularization, ridge regression reduces over-fitting on the small support set.",
                "Although we optimized for a regression objective in Eq equation 5, the learned transformation has been shown to work well in few-shot classification after a calibration step (Bertinetto et al., 2019), as \u0176Q = a\u03a6QW + b (7) where a \u2208 R and b \u2208 R are meta-parameters learned through meta-training.",
                "Current approaches transfer knowledge from the source to the target by either fine-tuning a pre-trained encoder (Howard & Ruder, 2018; Peters et al., 2018; Radford et al., 2018; Bertinetto et al., 2019), or multi-task learning with a shared encoder (Collobert & Weston, 2008; Liu et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2579c9c2f74a01f382082fc2b1fbc04ba4834718",
                "externalIds": {
                    "ArXiv": "1908.06039",
                    "MAG": "2995322030",
                    "DBLP": "journals/corr/abs-1908-06039",
                    "CorpusId": 201058594
                },
                "corpusId": 201058594,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2579c9c2f74a01f382082fc2b1fbc04ba4834718",
                "title": "Few-shot Text Classification with Distributional Signatures",
                "abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "26565554",
                        "name": "Yujia Bao"
                    },
                    {
                        "authorId": "1661559699",
                        "name": "Menghua Wu"
                    },
                    {
                        "authorId": "3307026",
                        "name": "Shiyu Chang"
                    },
                    {
                        "authorId": "1741283",
                        "name": "R. Barzilay"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To learn an effective comparison model, these methods make their prediction conditioned on distances to few labeled instances during the training process [1, 34, 13, 2]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5052154bf1e8f9cf06dbcdb22ac52f02500f0c3a",
                "externalIds": {
                    "ArXiv": "1908.05257",
                    "MAG": "2966993394",
                    "DBLP": "conf/iccv/LiLX0019",
                    "DOI": "10.1109/ICCV.2019.00981",
                    "CorpusId": 199577364
                },
                "corpusId": 199577364,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/5052154bf1e8f9cf06dbcdb22ac52f02500f0c3a",
                "title": "Few-Shot Learning With Global Class Representations",
                "abstract": "In this paper, we propose to tackle the challenging few-shot learning (FSL) problem by learning global class representations using both base and novel class training samples. In each training episode, an episodic class mean computed from a support set is registered with the global representation via a registration module. This produces a registered global class representation for computing the classification loss using a query set. Though following a similar episodic training pipeline as existing meta learning based approaches, our method differs significantly in that novel class training samples are involved in the training from the beginning. To compensate for the lack of novel class training samples, an effective sample synthesis strategy is developed to avoid overfitting. Importantly, by joint base-novel class training, our approach can be easily extended to a more practical yet challenging FSL setting, i.e., generalized FSL, where the label space of test data is extended to both base and novel classes. Extensive experiments show that our approach is effective for both of the two FSL settings.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "51441378",
                        "name": "Tiange Luo"
                    },
                    {
                        "authorId": "5683005",
                        "name": "Aoxue Li"
                    },
                    {
                        "authorId": "145406421",
                        "name": "T. Xiang"
                    },
                    {
                        "authorId": "8007867",
                        "name": "Weiran Huang"
                    },
                    {
                        "authorId": "24952249",
                        "name": "Liwei Wang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The proposed methodology\n(S2M2) outperforms the state-of-the-art methods by 3-8% over the CIFAR-FS, CUB, mini-ImageNet and tiered-ImageNet datasets.",
                "We show that our proposed method S2M2 beats the current state-of-the-art accuracy on standard fewshot learning datasets like CIFAR-FS, CUB, mini-ImageNet and tiered-ImageNet by 3 \u2212 8%.",
                "Datasets: We perform experiments on four standard datasets for few-shot image classification benchmark, miniImageNet [63], tiered-ImageNet [52], CUB [64] and CIFAR-FS [4]. mini-ImageNet consists of 100 classes from the ImageNet [53] which are split randomly into 64 base, 16 validation and 20 novel classes.",
                "For training ResNet-18 and ResNet-34 architectures, we use Adam [33] optimizer for mini-ImageNet and CUB whereas SGD optimizer for CIFAR-FS.",
                "CIFAR-FS is created by randomly splitting 100 classes of CIFAR-100 [34] into 64 base, 16 validation and 20 novel classes.",
                "We find that using only rotation prediction as an auxiliary task during backbone training also outperforms the existing state-of-the-art methods on all datasets except CIFAR-FS.",
                "Datasets: We perform experiments on four standard datasets for few-shot image classification benchmark, miniImageNet [63], tiered-ImageNet [52], CUB [64] and CIFAR-FS [4]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "ccbe37b5c4d8a5687153df6fedbb44d6f1c46d7d",
                "externalIds": {
                    "MAG": "2965535361",
                    "DBLP": "conf/wacv/Mangla0SKBK20",
                    "ArXiv": "1907.12087",
                    "DOI": "10.1109/WACV45572.2020.9093338",
                    "CorpusId": 198968328
                },
                "corpusId": 198968328,
                "publicationVenue": {
                    "id": "acd15a6d-3248-41fb-8439-9a40aabe5608",
                    "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "Workshop on Applications of Computer Vision",
                        "WACV",
                        "IEEE Work Conf Appl Comput Vis",
                        "Workshop Appl Comput Vis"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=2993"
                },
                "url": "https://www.semanticscholar.org/paper/ccbe37b5c4d8a5687153df6fedbb44d6f1c46d7d",
                "title": "Charting the Right Manifold: Manifold Mixup for Few-shot Learning",
                "abstract": "Few-shot learning algorithms aim to learn model parameters capable of adapting to unseen classes with the help of only a few labeled examples. A recent regularization technique - Manifold Mixup focuses on learning a general-purpose representation, robust to small changes in the data distribution. Since the goal of few-shot learning is closely linked to robust representation learning, we study Manifold Mixup in this problem setting. Self-supervised learning is another technique that learns semantically meaningful features, using only the inherent structure of the data. This work investigates the role of learning relevant feature manifold for few-shot tasks using self-supervision and regularization techniques. We observe that regularizing the feature manifold, enriched via self-supervised techniques, with Manifold Mixup significantly improves few-shot learning performance. We show that our proposed method S2M2 beats the current state-of-the-art accuracy on standard few-shot learning datasets like CIFAR-FS, CUB, mini-ImageNet and tiered-ImageNet by 3 \u2212 8%. Through extensive experimentation, we show that the features learned using our approach generalize to complex few-shot evaluation tasks, cross-domain scenarios and are robust against slight changes to data distribution.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "69453609",
                        "name": "Puneet Mangla"
                    },
                    {
                        "authorId": "1400331254",
                        "name": "M. Singh"
                    },
                    {
                        "authorId": "144318274",
                        "name": "Abhishek Sinha"
                    },
                    {
                        "authorId": "46373847",
                        "name": "Nupur Kumari"
                    },
                    {
                        "authorId": "1699429",
                        "name": "V. Balasubramanian"
                    },
                    {
                        "authorId": "145846953",
                        "name": "Balaji Krishnamurthy"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1aa6a044c576d8bf084b1fe819d0541a892d4ab1",
                "externalIds": {
                    "MAG": "2953574880",
                    "DBLP": "journals/ijon/LiYFFH20",
                    "ArXiv": "1907.03123",
                    "DOI": "10.1016/j.neucom.2020.04.040",
                    "CorpusId": 195833540
                },
                "corpusId": 195833540,
                "publicationVenue": {
                    "id": "df12d289-f447-47d3-8846-75e39de3ab57",
                    "name": "Neurocomputing",
                    "type": "journal",
                    "issn": "0925-2312",
                    "url": "http://www.elsevier.com/locate/neucom",
                    "alternate_urls": [
                        "http://www.sciencedirect.com/science/journal/09252312"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1aa6a044c576d8bf084b1fe819d0541a892d4ab1",
                "title": "Revisiting Metric Learning for Few-Shot Image Classification",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "48569488",
                        "name": "Xiaomeng Li"
                    },
                    {
                        "authorId": "2342535",
                        "name": "Lequan Yu"
                    },
                    {
                        "authorId": "144856288",
                        "name": "Chi-Wing Fu"
                    },
                    {
                        "authorId": "2055723368",
                        "name": "Meng Fang"
                    },
                    {
                        "authorId": "1714602",
                        "name": "P. Heng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[1] proposed both closed-form and iterative solvers, based on ridge regression and logistic regression components, to teach a CNN to use standard machine learning tools as part of its internal model, enabling it to adapt to novel data quickly."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "125e5f736263918908b1ecb36df3ed45f8e89280",
                "externalIds": {
                    "MAG": "3108637696",
                    "DBLP": "conf/eccv/ZhengTCWL20",
                    "DOI": "10.1007/978-3-030-58555-6_45",
                    "CorpusId": 221516679
                },
                "corpusId": 221516679,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/125e5f736263918908b1ecb36df3ed45f8e89280",
                "title": "Learning Feature Embeddings for Discriminant Model Based Tracking",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "48026369",
                        "name": "Linyu Zheng"
                    },
                    {
                        "authorId": "2113727378",
                        "name": "Ming Tang"
                    },
                    {
                        "authorId": "50580380",
                        "name": "Yingying Chen"
                    },
                    {
                        "authorId": "49606029",
                        "name": "Jinqiao Wang"
                    },
                    {
                        "authorId": "1694235",
                        "name": "Hanqing Lu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c2e71c797c8ebc03d06e30c40397780438783720",
                "externalIds": {
                    "MAG": "2954090070",
                    "ArXiv": "1906.10414",
                    "DBLP": "journals/corr/abs-1906-10414",
                    "CorpusId": 195584360
                },
                "corpusId": 195584360,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c2e71c797c8ebc03d06e30c40397780438783720",
                "title": "Learning Features with Differentiable Closed-Form Solver for Tracking",
                "abstract": "We present a novel and easy-to-implement training framework for visual tracking. Our approach mainly focuses on learning feature embeddings in an end-to-end way, which can generalize well to the trackers based on online discriminatively trained ridge regression model. This goal is efficiently achieved by taking advantage of the following two important theories. 1) Ridge regression problem has closed-form solution and is implicit differentiation under the optimality condition. Therefore, its solver can be embedded as a layer with efficient forward and backward processes in training deep convolutional neural networks. 2) Woodbury identity can be utilized to ensure efficient solution of ridge regression problem when the high-dimensional feature embeddings are employed. Moreover, in order to address the extreme foreground-background class imbalance during training, we modify the origin shrinkage loss and then employ it as the loss function for efficient and effective training. It is worth mentioning that the above core parts of our proposed training framework are easy to be implemented with several lines of code under the current popular deep learning frameworks, thus our approach is easy to be followed. Extensive experiments on six public benchmarks, OTB2015, NFS, TrackingNet, GOT10k, VOT2018, and VOT2019, show that the proposed tracker achieves state-of-the-art performance, while running at over 30 FPS. Code will be made available.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "48026369",
                        "name": "Linyu Zheng"
                    },
                    {
                        "authorId": "2113727378",
                        "name": "Ming Tang"
                    },
                    {
                        "authorId": "49606029",
                        "name": "Jinqiao Wang"
                    },
                    {
                        "authorId": "1694235",
                        "name": "Hanqing Lu"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", MAML[9], gradient unrolling [35], closed form solvers [2], convex learners [23], etc."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c3e612b40fa547ce6a36bb7fbbbabfa9b9306281",
                "externalIds": {
                    "MAG": "2951094958",
                    "DBLP": "journals/corr/abs-1906-07079",
                    "ArXiv": "1906.07079",
                    "CorpusId": 189927945
                },
                "corpusId": 189927945,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c3e612b40fa547ce6a36bb7fbbbabfa9b9306281",
                "title": "Boosting Supervision with Self-Supervision for Few-shot Learning",
                "abstract": "We present a technique to improve the transferability of deep representations learned on small labeled datasets by introducing self-supervised tasks as auxiliary loss functions. While recent approaches for self-supervised learning have shown the benefits of training on large unlabeled datasets, we find improvements in generalization even on small datasets and when combined with strong supervision. Learning representations with self-supervised losses reduces the relative error rate of a state-of-the-art meta-learner by 5-25% on several few-shot learning benchmarks, as well as off-the-shelf deep networks on standard classification tasks when training from scratch. We find the benefits of self-supervision increase with the difficulty of the task. Our approach utilizes the images within the dataset to construct self-supervised losses and hence is an effective way of learning transferable representations without relying on any external training data.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2148766061",
                        "name": "Jong-Chyi Su"
                    },
                    {
                        "authorId": "35208858",
                        "name": "Subhransu Maji"
                    },
                    {
                        "authorId": "73710317",
                        "name": "B. Hariharan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For more experiments on other datasets, such as FC100 [17], CIFAR-FS [3], and Meta-Dataset [31], please see the supplementary materials."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4241d67f0c37c4efa3f35c740a73174b1c83f61e",
                "externalIds": {
                    "MAG": "2952425013",
                    "ArXiv": "1906.05895",
                    "DBLP": "conf/cvpr/BaikHL20",
                    "DOI": "10.1109/cvpr42600.2020.00245",
                    "CorpusId": 189897731
                },
                "corpusId": 189897731,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4241d67f0c37c4efa3f35c740a73174b1c83f61e",
                "title": "Learning to Forget for Meta-Learning",
                "abstract": "Few-shot learning is a challenging problem where the goal is to achieve generalization from only few examples. Model-agnostic meta-learning (MAML) tackles the problem by formulating prior knowledge as a common initialization across tasks, which is then used to quickly adapt to unseen tasks. However, forcibly sharing an initialization can lead to conflicts among tasks and the compromised (undesired by tasks) location on optimization landscape, thereby hindering the task adaptation. Further, we observe that the degree of conflict differs among not only tasks but also layers of a neural network. Thus, we propose task-and-layer-wise attenuation on the compromised initialization to reduce its influence. As the attenuation dynamically controls (or selectively forgets) the influence of prior knowledge for a given task and each layer, we name our method as L2F (Learn to Forget). The experimental results demonstrate that the proposed method provides faster adaptation and greatly improves the performance. Furthermore, L2F can be easily applied and improve other state-of-the-art MAML-based frameworks, illustrating its simplicity and generalizability.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "148009160",
                        "name": "Sungyong Baik"
                    },
                    {
                        "authorId": "150297656",
                        "name": "Seokil Hong"
                    },
                    {
                        "authorId": "2135837",
                        "name": "Kyoung Mu Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We perform this study using the MiniImageNet and CIFAR-FS datasets and report results in Tables 1 and 2 respectively.",
                "In Tables 5, 6, and 7, we compare our approach with prior few-shot methods on the MiniImageNet, CIFAR-FS, and tiered-MiniImageNet datasets respectively.",
                "CIFAR-FS is a few-shot dataset created by dividing the 100 classes of CIFAR-100 into 64 base classes, 16 validation classes, and 20 novel test classes.",
                "Our detailed experiments on MiniImagenet, CIFAR-FS, tiered-MiniImagenet, and ImageNet-FS few-shot datasets reveal that indeed adding self-supervision leads to significant improvements on the few-shot classification performance, which makes the employed few-shot models achieve stateof-the-art results.",
                "Also, we consider only the MiniImageNet dataset and not CIFAR-FS since the latter contains thumbnail images of size 32 \u00d7 32 from which it does not make sense to extract patches: their size would have to be less than 8\u00d7 8 pixels, which is too small for the evaluated architectures.",
                "(2) We study the impact of the added self-supervised loss by performing exhaustive quantitative experiments on MiniImagenet, CIFAR-FS, tiered-MiniImagenet, and ImageNetFS few-shot datasets.",
                "We perform experiments on four few-shot datasets, MiniImageNet [55], tiered-MiniImageNet [46], CIFAR-FS [2], and ImageNet-FS [20]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "8286d8b9b5e72f0bbf8c7084fd875bdc8e6f06c3",
                "externalIds": {
                    "DBLP": "journals/corr/abs-1906-05186",
                    "ArXiv": "1906.05186",
                    "MAG": "2994633389",
                    "DOI": "10.1109/ICCV.2019.00815",
                    "CorpusId": 186206588
                },
                "corpusId": 186206588,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/8286d8b9b5e72f0bbf8c7084fd875bdc8e6f06c3",
                "title": "Boosting Few-Shot Visual Learning With Self-Supervision",
                "abstract": "Few-shot learning and self-supervised learning address different facets of the same problem: how to train a model with little or no labeled data. Few-shot learning aims for optimization methods and models that can learn efficiently to recognize patterns in the low data regime. Self-supervised learning focuses instead on unlabeled data and looks into it for the supervisory signal to feed high capacity deep neural networks. In this work we exploit the complementarity of these two domains and propose an approach for improving few-shot learning through self-supervision. We use self-supervision as an auxiliary task in a few-shot learning pipeline, enabling feature extractors to learn richer and more transferable visual representations while still using few annotated samples. Through self-supervision, our approach can be naturally extended towards using diverse unlabeled data from other datasets in the few-shot setting. We report consistent improvements across an array of architectures, datasets and self-supervision techniques. We provide the implementation code at: https://github.com/valeoai/BF3S",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2475428",
                        "name": "Spyros Gidaris"
                    },
                    {
                        "authorId": "3056236",
                        "name": "Andrei Bursuc"
                    },
                    {
                        "authorId": "2505902",
                        "name": "N. Komodakis"
                    },
                    {
                        "authorId": "144565371",
                        "name": "P. P\u00e9rez"
                    },
                    {
                        "authorId": "51021910",
                        "name": "M. Cord"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Following the setting of most recent methods [45, 52, 70], we use ResNet variants [5, 22] to implement the embedding backbone \u03c6.",
                "works chooses to learn the common optimization strategy [5, 47] across few-shot tasks, e."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2e1d7c2d8ededa981674439dd47c0ad1eb6ffec0",
                "externalIds": {
                    "DBLP": "journals/ijcv/YeHZ21",
                    "MAG": "3155876088",
                    "ArXiv": "1906.02944",
                    "DOI": "10.1007/s11263-020-01381-4",
                    "CorpusId": 213306864
                },
                "corpusId": 213306864,
                "publicationVenue": {
                    "id": "939ee07c-6009-43f8-b884-69238b40659e",
                    "name": "International Journal of Computer Vision",
                    "type": "journal",
                    "alternate_names": [
                        "Int J Comput Vis"
                    ],
                    "issn": "0920-5691",
                    "url": "https://www.springer.com/computer/image+processing/journal/11263",
                    "alternate_urls": [
                        "https://link.springer.com/journal/11263",
                        "http://link.springer.com/journal/11263"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2e1d7c2d8ededa981674439dd47c0ad1eb6ffec0",
                "title": "Learning Adaptive Classifiers Synthesis for Generalized Few-Shot Learning",
                "abstract": null,
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2151459740",
                        "name": "Han-Jia Ye"
                    },
                    {
                        "authorId": "2804000",
                        "name": "Hexiang Hu"
                    },
                    {
                        "authorId": "1721819",
                        "name": "De-chuan Zhan"
                    },
                    {
                        "authorId": "145757665",
                        "name": "Fei Sha"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps. Our subspace networks method can also be seen as a form of meta-learning, in the sense that it dynamically produces a simple classifier from incoming test episodes, yet the parametrized embedding function f\u03c6 remains fixed after training. Oreshkin et al. [2018] show that, following Hinton et al. [2015], by adding a learnable temperature \u03b1 in the softmax (p\u03c6,\u03b1(y = n|x) = softmax(\u2212\u03b1d(ei,Pnei))), they enable the model to learn the best regime for each similarity metric. By using such a learnable temperature, the performance difference between matching networks and prototypical networks vanishes. However, the performance of prototypical networks improves only slightly. Also, the idea to make the embedding function conditionally dependent on the support set (Vinyals et al. [2016]) is used in the form of conditional batch normalization by Oreshkin et al. [2018]. They show that by combining support-set conditioned batch normalization with temperature learning, impressive performance gains can be achieved. Concurrently, similar work by Simon et al. [2019] explores subspace representations for few-shot learning.",
                "Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps. Our subspace networks method can also be seen as a form of meta-learning, in the sense that it dynamically produces a simple classifier from incoming test episodes, yet the parametrized embedding function f\u03c6 remains fixed after training. Oreshkin et al. [2018] show that, following Hinton et al. [2015], by adding a learnable temperature \u03b1 in the softmax (p\u03c6,\u03b1(y = n|x) = softmax(\u2212\u03b1d(ei,Pnei))), they enable the model to learn the best regime for each similarity metric. By using such a learnable temperature, the performance difference between matching networks and prototypical networks vanishes. However, the performance of prototypical networks improves only slightly. Also, the idea to make the embedding function conditionally dependent on the support set (Vinyals et al. [2016]) is used in the form of conditional batch normalization by Oreshkin et al.",
                "Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps.",
                "Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters.",
                "Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps. Our subspace networks method can also be seen as a form of meta-learning, in the sense that it dynamically produces a simple classifier from incoming test episodes, yet the parametrized embedding function f\u03c6 remains fixed after training. Oreshkin et al. [2018] show that, following Hinton et al. [2015], by adding a learnable temperature \u03b1 in the softmax (p\u03c6,\u03b1(y = n|x) = softmax(\u2212\u03b1d(ei,Pnei))), they enable the model to learn the best regime for each similarity metric.",
                "Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function. Doing so, they directly approach a classification problem with a regression method, but they show competitive results. To achieve this, they introduce learnable scalars that scale and shift the regression outputs for them to be used in the cross-entropy loss. Subspace networks rely on the same closed-form solver for linear regression to compute the projection matrices, but are inherently designed for classification problems because of their similarity to the LRC method (Naseem et al. [2010]). Meta-learning is another popular approach for few-shot learning and generalizes naturally to few-shot regression and reinforcement learning problems. Ravi and Larochelle [2017] use an external LSTM to learn to optimize parameters of a model, given the gradients of those parameters. Model-agnostic meta-learning (MAML) by Finn et al. [2017] outperforms the LSTM-based method by using a meta-gradient over multiple individual episode gradient update steps. Our subspace networks method can also be seen as a form of meta-learning, in the sense that it dynamically produces a simple classifier from incoming test episodes, yet the parametrized embedding function f\u03c6 remains fixed after training. Oreshkin et al. [2018] show that, following Hinton et al. [2015], by adding a learnable temperature \u03b1 in the softmax (p\u03c6,\u03b1(y = n|x) = softmax(\u2212\u03b1d(ei,Pnei))), they enable the model to learn the best regime for each similarity metric. By using such a learnable temperature, the performance difference between matching networks and prototypical networks vanishes. However, the performance of prototypical networks improves only slightly. Also, the idea to make the embedding function conditionally dependent on the support set (Vinyals et al. [2016]) is used in the form of conditional batch normalization by Oreshkin et al. [2018]. They show that by combining support-set conditioned batch normalization with temperature learning, impressive performance gains can be achieved.",
                "Bertinetto et al. [2018] propose to use regularized linear regression as a classifier on top of the embedding function."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "7d3b38568d045257b05f3c73ec18c26fd5ef5953",
                "externalIds": {
                    "MAG": "2947279351",
                    "DBLP": "journals/corr/abs-1905-13613",
                    "ArXiv": "1905.13613",
                    "CorpusId": 173188648
                },
                "corpusId": 173188648,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7d3b38568d045257b05f3c73ec18c26fd5ef5953",
                "title": "Subspace Networks for Few-shot Classification",
                "abstract": "We propose subspace networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each class. Subspace networks learn an embedding space in which classification can be performed by computing distances of embedded points to subspace representations of each class. The class subspaces are spanned by examples belonging to the same class, transformed by a learnable embedding function. Similarly to recent approaches for few-shot learning, subspace networks reflect a simple inductive bias that is beneficial in this limited-data regime and they achieve excellent results. In particular, our proposed method shows consistently better performance than other state-of-the-art few-shot distance-metric learning methods when the embedding function is deep or when training and testing domains are shifted.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "1664923028",
                        "name": "A. Devos"
                    },
                    {
                        "authorId": "2052174",
                        "name": "M. Grossglauser"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In addition to the reproduced metric (meta-)learning based few-shot methods (Snell et al., 2017; Vinyals et al., 2016; Sung et al., 2018; Bertinetto et al., 2019), there is a large body of work on few-shot learning and metric (meta-)learning.",
                "Compared to our direct approach, R2D2 is a meta-learning technique which leverages the closed-form solution of multinomial regression indirectly for classification (See Section 4).",
                "Bertinetto et al. (2019) propose to use regularized linear regression as a classifier on top of the embedding function.",
                ", 2019) of MatchingNet, ProtoNet, RelationNet, MAML and extend it with R2D2 (Bertinetto et al., 2019).",
                "Secondly, as the backbone gets deeper, regression networks and prototypical networks begin to perform significantly better than matching networks and relation networks with R2D2 following close.",
                "To ensure a fair comparison with other methods, we perform experiments under the same conditions using the verified re-implementation (Chen et al., 2019) of MatchingNet, ProtoNet, RelationNet, MAML and extend it with R2D2 (Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "637a0f52e253fed694cbae2f35607d787c99d9d6",
                "externalIds": {
                    "MAG": "3036014842",
                    "CorpusId": 219956084
                },
                "corpusId": 219956084,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/637a0f52e253fed694cbae2f35607d787c99d9d6",
                "title": "Regression Networks for Meta-Learning Few-Shot Classification",
                "abstract": "We propose regression networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each class. In high dimensional embedding spaces the direction of data generally contains richer information than magnitude. Next to this, state-of-the-art few-shot metric methods that compare distances with aggregated class representations, have shown superior performance. Combining these two insights, we propose to meta-learn classification of embedded points by regressing the closest approximation in every class subspace while using the regression error as a distance metric. Similarly to recent approaches for few-shot learning, regression networks reflect a simple inductive bias that is beneficial in this limited-data regime and they achieve excellent results, especially when more aggregate class representations can be formed with multiple shots.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "1664923028",
                        "name": "A. Devos"
                    },
                    {
                        "authorId": "2052174",
                        "name": "M. Grossglauser"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS: This dataset (Bertinetto et al., 2019) is a variant of CIFAR-100 dataset that consists of 100 general object categories."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "96f8e5820c5b59e65c2331d577aa738676e8c605",
                "externalIds": {
                    "ArXiv": "1905.12917",
                    "DBLP": "conf/iclr/LeeLNKPYH20",
                    "MAG": "2947247301",
                    "CorpusId": 170078603
                },
                "corpusId": 170078603,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/96f8e5820c5b59e65c2331d577aa738676e8c605",
                "title": "Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks",
                "abstract": "While tasks could come with varying the number of instances and classes in realistic settings, the existing meta-learning approaches for few-shot classification assume that the number of instances per task and class is fixed. Due to such restriction, they learn to equally utilize the meta-knowledge across all the tasks, even when the number of instances per task and class largely varies. Moreover, they do not consider distributional difference in unseen tasks, on which the meta-knowledge may have less usefulness depending on the task relatedness. To overcome these limitations, we propose a novel meta-learning model that adaptively balances the effect of the meta-learning and task-specific learning within each task. Through the learning of the balancing variables, we can decide whether to obtain a solution by relying on the meta-knowledge or task-specific learning. We formulate this objective into a Bayesian inference framework and tackle it using variational inference. We validate our Bayesian Task-Adaptive Meta-Learning (Bayesian TAML) on multiple realistic task- and class-imbalanced datasets, on which it significantly outperforms existing meta-learning approaches. Further ablation study confirms the effectiveness of each balancing component and the Bayesian learning framework.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2110308284",
                        "name": "Haebeom Lee"
                    },
                    {
                        "authorId": "2110616001",
                        "name": "Hayeon Lee"
                    },
                    {
                        "authorId": "2059662558",
                        "name": "Donghyun Na"
                    },
                    {
                        "authorId": "1898376",
                        "name": "Saehoon Kim"
                    },
                    {
                        "authorId": "144568677",
                        "name": "Minseop Park"
                    },
                    {
                        "authorId": "1720494",
                        "name": "Eunho Yang"
                    },
                    {
                        "authorId": "2110796623",
                        "name": "S. Hwang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0e177f69f49fbd8dd0c09efdc79ce8a76636e540",
                "externalIds": {
                    "DBLP": "journals/entropy/LeeKPC22",
                    "PubMedCentral": "9030705",
                    "ArXiv": "1905.11656",
                    "MAG": "3014037202",
                    "DOI": "10.3390/e24040501",
                    "CorpusId": 211259529,
                    "PubMed": "35455164"
                },
                "corpusId": 211259529,
                "publicationVenue": {
                    "id": "8270cfe1-3713-4325-a7bd-c6a87eed889e",
                    "name": "Entropy",
                    "type": "journal",
                    "issn": "1099-4300",
                    "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-155606",
                    "alternate_urls": [
                        "http://www.mdpi.com/journal/entropy/",
                        "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-155606",
                        "https://www.mdpi.com/journal/entropy"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/0e177f69f49fbd8dd0c09efdc79ce8a76636e540",
                "title": "Discrete Infomax Codes for Supervised Representation Learning",
                "abstract": "For high-dimensional data such as images, learning an encoder that can output a compact yet informative representation is a key task on its own, in addition to facilitating subsequent processing of data. We present a model that produces discrete infomax codes (DIMCO); we train a probabilistic encoder that yields k-way d-dimensional codes associated with input data. Our model maximizes the mutual information between codes and ground-truth class labels, with a regularization which encourages entries of a codeword to be statistically independent. In this context, we show that the infomax principle also justifies existing loss functions, such as cross-entropy as its special cases. Our analysis also shows that using shorter codes reduces overfitting in the context of few-shot classification, and our various experiments show this implicit task-level regularization effect of DIMCO. Furthermore, we show that the codes learned by DIMCO are efficient in terms of both memory and retrieval time compared to prior methods.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2110392124",
                        "name": "Yoonho Lee"
                    },
                    {
                        "authorId": "2382193",
                        "name": "Wonjae Kim"
                    },
                    {
                        "authorId": "107950764",
                        "name": "Wonpyo Park"
                    },
                    {
                        "authorId": "3960497",
                        "name": "Seungjin Choi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In general, we observe that the real-world datasets are challenging for all methods but ADKL methods consistently outperform R2-D2 and CNP.",
                "Once again, the difference in performance between ADKL-KRR and R2-D2 can be attributed to the kernel adaptation at test-time as it is the only difference between both methods.",
                "The gap between ADKL-KRR and R2-D2 shows the importance of adapting the kernel to each task rather than sharing a single kernel.",
                "[12] have also tackled this lack of adaptation for new tasks by using KRR and Logistic Regression to find the appropriate weighting of the training samples.",
                "2 Benchmarking analysis We evaluate model performance against R2-D2 [12], CNP[31], and MAML[14].",
                "It is worth mentioning that using the linear kernel and the KRR algorithm, we recover the few-shot classification algorithm R2-D2 proposed by Bertinetto et al. [12].",
                "We evaluate model performance against R2-D2 [12], CNP[31], and MAML[14].",
                "R2-D2 is a natural comparison to ADKL-KRR (when the latter uses the linear kernel) to show whether the adapted deep kernel provides more test-time adaptation.",
                "Moreover, for small support sets, ADKL-KRR shows better within-task generalization than ADKL-GP and R2-D2.",
                "Hence, few of the currently-used base learners have enough capacity to truly adapt [12, 13]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "7aa2c397dd55065af4f604104f29147f8d8d133f",
                "externalIds": {
                    "ArXiv": "1905.12131",
                    "DBLP": "journals/corr/abs-1905-12131",
                    "MAG": "2947341830",
                    "CorpusId": 168170032
                },
                "corpusId": 168170032,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/7aa2c397dd55065af4f604104f29147f8d8d133f",
                "title": "Adaptive Deep Kernel Learning",
                "abstract": "Deep kernel learning provides an elegant and principled framework for combining the structural properties of deep learning algorithms with the flexibility of kernel methods. By means of a deep neural network, it consists of learning a kernel operator which is combined with a differentiable kernel algorithm for inference. While previous work within this framework has mostly explored learning a single kernel for large datasets, we focus herein on learning a kernel family for a variety of tasks in few-shot regression settings. Compared to single deep kernel learning, our novel algorithm permits finding the appropriate kernel for each task during inference, rather than using the same for all tasks. As such, our algorithm performs more effectively with complex task distributions in few-shot learning, which we demonstrate by benchmarking against existing state-of-the-art algorithms using real-world, few-shot regression tasks related to drug discovery.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "12611623",
                        "name": "Prudencio Tossou"
                    },
                    {
                        "authorId": "123483982",
                        "name": "Basile Dura"
                    },
                    {
                        "authorId": "2482151",
                        "name": "Fran\u00e7ois Laviolette"
                    },
                    {
                        "authorId": "143858557",
                        "name": "M. Marchand"
                    },
                    {
                        "authorId": "8651990",
                        "name": "Alexandre Lacoste"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We test our algorithm on three datasets: miniImagenet [21], tieredImagenet [12] and CIFAR Few-Shot [1].",
                "Finally, [1] incorporates ridge regression in an endto-end manner into a deep-learning network.",
                "We test our algorithm on three datasets: miniImagenet [20], tieredImagenet [12] and CIFAR Few-Shot [1].",
                "The class identities are then either obtained through a function defined a-priori such as the sample mean in [16], an attention kernel [21], or ridge regression [1].",
                "Also shown in Table 4 is the perfor-\nmance of our method on the CIFAR Few-Shot dataset.",
                "The performance numbers for CIFAR Few-Shot are from [1].",
                "Finally, we use CIFAR Few-Shot, (CIFAR-FS) [1] containing images of size 32\u00d7 32, a reorganized version of the CIFAR-100 [8] dataset.",
                "We use the same data split as in [1], dividing the 100 classes into 64 for training, 16 for validation, and 20 for testing.",
                "From this table we see that our method performs the best for CIFAR Few-Shot."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "51ac59fa39e934347216b35da5e6aa292b4b5d59",
                "externalIds": {
                    "MAG": "2982049331",
                    "ArXiv": "1905.04398",
                    "DBLP": "conf/iccv/RavichandranBS19",
                    "DOI": "10.1109/ICCV.2019.00042",
                    "CorpusId": 152282585
                },
                "corpusId": 152282585,
                "publicationVenue": {
                    "id": "7654260e-79f9-45c5-9663-d72027cf88f3",
                    "name": "IEEE International Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ICCV",
                        "IEEE Int Conf Comput Vis",
                        "ICCV Workshops",
                        "ICCV Work"
                    ],
                    "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
                },
                "url": "https://www.semanticscholar.org/paper/51ac59fa39e934347216b35da5e6aa292b4b5d59",
                "title": "Few-Shot Learning With Embedded Class Models and Shot-Free Meta Training",
                "abstract": "We propose a method for learning embeddings for few-shot learning that is suitable for use with any number of shots (shot-free). Rather than fixing the class prototypes to be the Euclidean average of sample embeddings, we allow them to live in a higher-dimensional space (embedded class models) and learn the prototypes along with the model parameters. The class representation function is defined implicitly, which allows us to deal with a variable number of shots per class with a simple constant-size architecture. The class embedding encompasses metric learning, that facilitates adding new classes without crowding the class representation space. Despite being general and not tuned to the benchmark, our approach achieves state-of-the-art performance on the standard few-shot benchmark datasets.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2529423",
                        "name": "Avinash Ravichandran"
                    },
                    {
                        "authorId": "3243878",
                        "name": "Rahul Bhotika"
                    },
                    {
                        "authorId": "1715959",
                        "name": "Stefano Soatto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "R2-D2 [3] Conv-4-64 48."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4732ef442a5d0f2ec77600ddd44aaa288a043ace",
                "externalIds": {
                    "ArXiv": "1905.01102",
                    "MAG": "2962895018",
                    "DBLP": "conf/cvpr/GidarisK19",
                    "DOI": "10.1109/CVPR.2019.00011",
                    "CorpusId": 145053868
                },
                "corpusId": 145053868,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/4732ef442a5d0f2ec77600ddd44aaa288a043ace",
                "title": "Generating Classification Weights With GNN Denoising Autoencoders for Few-Shot Learning",
                "abstract": "Given an initial recognition model already trained on a set of base classes, the goal of this work is to develop a meta-model for few-shot learning. The meta-model, given as input some novel classes with few training examples per class, must properly adapt the existing recognition model into a new model that can correctly classify in a unified way both the novel and the base classes. To accomplish this goal it must learn to output the appropriate classification weight vectors for those two types of classes. To build our meta-model we make use of two main innovations: we propose the use of a Denoising Autoencoder network (DAE) that (during training) takes as input a set of classification weights corrupted with Gaussian noise and learns to reconstruct the target-discriminative classification weights. In this case, the injected noise on the classification weights serves the role of regularizing the weight generating meta-model. Furthermore, in order to capture the co-dependencies between different classes in a given task instance of our meta-model, we propose to implement the DAE model as a Graph Neural Network (GNN). In order to verify the efficacy of our approach, we extensively evaluate it on ImageNet based few-shot benchmarks and we report state-of-the-art results.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2475428",
                        "name": "Spyros Gidaris"
                    },
                    {
                        "authorId": "2505902",
                        "name": "N. Komodakis"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Improved upon Learnet, the classification layer of the learner is replaced by ridge regression in Reference [13], such that parameters can be efficiently obtained in closed-form.",
                "hybrid Learnet [14] adaptive CNN CNN weighted 1 distance DCCN [162] adaptive CNN CNN R2-D2 [13] adaptive CNN CNN TADAM [100] adaptive CNN the same as f squared 2 distance"
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c8e4d8ded0624f13cd7763b8e7a62fe7e36da6d3",
                "externalIds": {
                    "MAG": "2944378183",
                    "ArXiv": "1904.05046",
                    "CorpusId": 226931458
                },
                "corpusId": 226931458,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/c8e4d8ded0624f13cd7763b8e7a62fe7e36da6d3",
                "title": "Generalizing from a Few Examples: A Survey on Few-Shot Learning",
                "abstract": "Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-Shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this paper, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimized is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications and theories, are also proposed to provide insights for future research.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2115793087",
                        "name": "Yaqing Wang"
                    },
                    {
                        "authorId": "3259992",
                        "name": "Quanming Yao"
                    },
                    {
                        "authorId": "145193332",
                        "name": "J. Kwok"
                    },
                    {
                        "authorId": "1726587",
                        "name": "L. Ni"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods. Our results show that a simple baseline method with a distancebased classifier (without training over a collection of tasks/episodes as in meta-learning) achieves competitive performance with respect to other sophisticated algorithms. Besides meta-learning methods, both Gidaris & Komodakis (2018) and Qi et al. (2018) develop a similar method to our Baseline++ (described later in Section 3.",
                "(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods. Our results show that a simple baseline method with a distancebased classifier (without training over a collection of tasks/episodes as in meta-learning) achieves competitive performance with respect to other sophisticated algorithms. Besides meta-learning methods, both Gidaris & Komodakis (2018) and Qi et al. (2018) develop a similar method to our Baseline++ (described later in Section 3.2). The method in Gidaris & Komodakis (2018) learns a weight generator to predict the novel class classifier using an attentionbased mechanism (cosine similarity), and the Qi et al. (2018) directly use novel class features as their weights.",
                "(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods. Our results show that a simple baseline method with a distancebased classifier (without training over a collection of tasks/episodes as in meta-learning) achieves competitive performance with respect to other sophisticated algorithms. Besides meta-learning methods, both Gidaris & Komodakis (2018) and Qi et al.",
                "(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods.",
                "(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018).",
                "(2018), ridge regression Bertinetto et al. (2019), and graph neural network Garcia & Bruna (2018). In this paper, we compare the performance of three distance metric learning methods. Our results show that a simple baseline method with a distancebased classifier (without training over a collection of tasks/episodes as in meta-learning) achieves competitive performance with respect to other sophisticated algorithms. Besides meta-learning methods, both Gidaris & Komodakis (2018) and Qi et al. (2018) develop a similar method to our Baseline++ (described later in Section 3.2). The method in Gidaris & Komodakis (2018) learns a weight generator to predict the novel class classifier using an attentionbased mechanism (cosine similarity), and the Qi et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "9d5ec23154fb278a765f47ba5ee5150bd441d0de",
                "externalIds": {
                    "MAG": "2911906319",
                    "DBLP": "conf/iclr/ChenLKWH19",
                    "ArXiv": "1904.04232",
                    "CorpusId": 102351185
                },
                "corpusId": 102351185,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/9d5ec23154fb278a765f47ba5ee5150bd441d0de",
                "title": "A Closer Look at Few-shot Classification",
                "abstract": "Few-shot classification aims to learn a classifier to recognize unseen classes during training with limited labeled examples. While significant progress has been made, the growing complexity of network designs, meta-learning algorithms, and differences in implementation details make a fair comparison difficult. In this paper, we present 1) a consistent comparative analysis of several representative few-shot classification algorithms, with results showing that deeper backbones significantly reduce the performance differences among methods on datasets with limited domain differences, 2) a modified baseline method that surprisingly achieves competitive performance when compared with the state-of-the-art on both the \\miniI and the CUB datasets, and 3) a new experimental setting for evaluating the cross-domain generalization ability for few-shot classification algorithms. Our results reveal that reducing intra-class variation is an important factor when the feature backbone is shallow, but not as critical when using deeper backbones. In a realistic cross-domain evaluation setting, we show that a baseline method with a standard fine-tuning practice compares favorably against other state-of-the-art few-shot learning algorithms.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2109964068",
                        "name": "Wei-Yu Chen"
                    },
                    {
                        "authorId": "2108334170",
                        "name": "Yen-Cheng Liu"
                    },
                    {
                        "authorId": "145276578",
                        "name": "Z. Kira"
                    },
                    {
                        "authorId": "2108898473",
                        "name": "Y. Wang"
                    },
                    {
                        "authorId": "3068086",
                        "name": "Jia-Bin Huang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fc437af6204008647ea49f81058d5fdaddf75ead",
                "externalIds": {
                    "MAG": "2963070905",
                    "DBLP": "journals/corr/abs-1904-03758",
                    "ArXiv": "1904.03758",
                    "DOI": "10.1109/CVPR.2019.01091",
                    "CorpusId": 102351194
                },
                "corpusId": 102351194,
                "publicationVenue": {
                    "id": "768b87bb-8a18-4d9c-a161-4d483c776bcf",
                    "name": "Computer Vision and Pattern Recognition",
                    "type": "conference",
                    "alternate_names": [
                        "CVPR",
                        "Comput Vis Pattern Recognit"
                    ],
                    "issn": "1063-6919",
                    "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147",
                    "alternate_urls": [
                        "https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/fc437af6204008647ea49f81058d5fdaddf75ead",
                "title": "Meta-Learning With Differentiable Convex Optimization",
                "abstract": "Many meta-learning approaches for few-shot learning rely on simple base learners such as nearest-neighbor classifiers. However, even in the few-shot regime, discriminatively trained linear predictors can offer better generalization. We propose to use these predictors as base learners to learn representations for few-shot learning and show they offer better tradeoffs between feature size and performance across a range of few-shot recognition benchmarks. Our objective is to learn feature embeddings that generalize well under a linear classification rule for novel categories. To efficiently solve the objective, we exploit two properties of linear classifiers: implicit differentiation of the optimality conditions of the convex problem and the dual formulation of the optimization problem. This allows us to use high-dimensional embeddings with improved generalization at a modest increase in computational overhead. Our approach, named MetaOptNet, achieves state-of-the-art performance on miniImageNet, tieredImageNet, CIFAR-FS, and FC100 few-shot learning benchmarks.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2668978",
                        "name": "Kwonjoon Lee"
                    },
                    {
                        "authorId": "35208858",
                        "name": "Subhransu Maji"
                    },
                    {
                        "authorId": "2529423",
                        "name": "Avinash Ravichandran"
                    },
                    {
                        "authorId": "1715959",
                        "name": "Stefano Soatto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently, the approaches of predicting class centers or weights [22], [23] have attracted much interest."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "36067002f2c75cd96373c925503262048fe4d80e",
                "externalIds": {
                    "MAG": "2923054183",
                    "DBLP": "journals/access/HaoCWC19",
                    "DOI": "10.1109/ACCESS.2019.2906665",
                    "CorpusId": 108325688
                },
                "corpusId": 108325688,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/36067002f2c75cd96373c925503262048fe4d80e",
                "title": "Instance-Level Embedding Adaptation for Few-Shot Learning",
                "abstract": "Few-shot learning aims to recognize novel categories from just a few labeled instances. Existing metric learning-based approaches perform classifications by nearest neighbor search in the embedding space. The embedding function is a deep neural network and usually shared by all novel categories. However, these brute approaches lack a fast adaptation mechanism like meta-learning when dealing with novel categories. To tackle this, we present a novel instance-level embedding adaptation mechanism, aiming at rapidly adapting embedding deep features to improve their generalization ability in recognizing novel categories. To this end, we design an Attention Adaptation Module to pull a query instance and its corresponding class center as close as possible. Note that, each query instance is pulled closer to its corresponding class center before performing nearest neighbor classifications. This instance-level reduction of intra-class distance increases the probability of correct classifications, and thus improves the generalization ability to embed deep features and promoting the performance. The extensive experiments are conducted on two benchmark datasets: miniImageNet and CUB. Our approach yields very promising results on both datasets. In addition, in a realistic cross-domain evaluation setting, our method also achieves the-state-of-the-art performance.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "41022398",
                        "name": "Fusheng Hao"
                    },
                    {
                        "authorId": "2048628992",
                        "name": "Jun Cheng"
                    },
                    {
                        "authorId": "36547165",
                        "name": "Lei Wang"
                    },
                    {
                        "authorId": "47470213",
                        "name": "Jianzhong Cao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Others relate to Prototypical Networks by learning a data representation as well as a compact representation for a classifier of data under that representation (Bertinetto et al., 2019; Gidaris & Komodakis, 2018; Oreshkin et al.,\n2018; Gidaris & Komodakis, 2018).",
                "Others relate to Prototypical Networks by learning a data representation as well as a compact representation for a classifier of data under that representation (Bertinetto et al., 2019; Gidaris & Komodakis, 2018; Oreshkin et al., 2018; Gidaris & Komodakis, 2018)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "712f4f21b9d3e6a7f110a2ecd9b3a2f900397b9f",
                "externalIds": {
                    "MAG": "2995253937",
                    "ArXiv": "1903.03096",
                    "DBLP": "conf/iclr/TriantafillouZD20",
                    "CorpusId": 71145737
                },
                "corpusId": 71145737,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/712f4f21b9d3e6a7f110a2ecd9b3a2f900397b9f",
                "title": "Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples",
                "abstract": "Few-shot classification refers to learning a classifier for new classes given only a few examples. While a plethora of models have emerged to tackle it, we find the procedure and datasets that are used to assess their progress lacking. To address this limitation, we propose Meta-Dataset: a new benchmark for training and evaluating models that is large-scale, consists of diverse datasets, and presents more realistic tasks. We experiment with popular baselines and meta-learners on Meta-Dataset, along with a competitive method that we propose. We analyze performance as a function of various characteristics of test tasks and examine the models' ability to leverage diverse training sources for improving their generalization. We also propose a new set of baselines for quantifying the benefit of meta-learning in Meta-Dataset. Our extensive experimentation has uncovered important research challenges and we hope to inspire work in these directions.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2064782825",
                        "name": "Eleni Triantafillou"
                    },
                    {
                        "authorId": "8791781",
                        "name": "Tyler Lixuan Zhu"
                    },
                    {
                        "authorId": "3074927",
                        "name": "Vincent Dumoulin"
                    },
                    {
                        "authorId": "3087941",
                        "name": "Pascal Lamblin"
                    },
                    {
                        "authorId": "36303818",
                        "name": "Kelvin Xu"
                    },
                    {
                        "authorId": "2558463",
                        "name": "Ross Goroshin"
                    },
                    {
                        "authorId": "52382152",
                        "name": "Carles Gelada"
                    },
                    {
                        "authorId": "1754860",
                        "name": "Kevin Swersky"
                    },
                    {
                        "authorId": "1798462",
                        "name": "Pierre-Antoine Manzagol"
                    },
                    {
                        "authorId": "1777528",
                        "name": "H. Larochelle"
                    }
                ]
            }
        },
        {
            "contexts": [
                "More specifically, the embedding modules [1, 2, 3, 4] have [3, 4, 6, 3] SENet blocks respectively, as per [18].",
                "Recent extensions include also learning perparameter learning rates [26], and accelerating fine-tuning through solving some layers in closed form [1]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8d0051d1d6f531eef455da7234e81e0edda0eee5",
                "externalIds": {
                    "MAG": "2901329470",
                    "DBLP": "journals/corr/abs-1811-07100",
                    "CorpusId": 53716898
                },
                "corpusId": 53716898,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8d0051d1d6f531eef455da7234e81e0edda0eee5",
                "title": "Deep Comparison: Relation Columns for Few-Shot Learning",
                "abstract": "Few-shot deep learning is a topical challenge area for scaling visual recognition to open-ended growth in the space of categories to recognise. A promising line work towards realising this vision is deep networks that learn to match queries with stored training images. However, methods in this paradigm usually train a deep embedding followed by a single linear classifier. Our insight is that effective general-purpose matching requires discrimination with regards to features at multiple abstraction levels. We therefore propose a new framework termed Deep Comparison Network(DCN) that decomposes embedding learning into a sequence of modules, and pairs each with a relation module. The relation modules compute a non-linear metric to score the match using the corresponding embedding module's representation. To ensure that all embedding module's features are used, the relation modules are deeply supervised. Finally generalisation is further improved by a learned noise regulariser. The resulting network achieves state of the art performance on both miniImageNet and tieredImageNet, while retaining the appealing simplicity and efficiency of deep metric learning approaches.",
                "year": 2018,
                "authors": [
                    {
                        "authorId": "2108058854",
                        "name": "Xueting Zhang"
                    },
                    {
                        "authorId": "40497013",
                        "name": "Flood Sung"
                    },
                    {
                        "authorId": "3387134",
                        "name": "Yuting Qiang"
                    },
                    {
                        "authorId": "2653152",
                        "name": "Yongxin Yang"
                    },
                    {
                        "authorId": "1697755",
                        "name": "Timothy M. Hospedales"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recent extensions also include learning perparameter learning rates [25], and accelerating fine-tuning through solving some layers in closed form [26]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2f5b15f6c5a1a75a8808688f7708888d526f8bb5",
                "externalIds": {
                    "ArXiv": "1811.07100",
                    "MAG": "3021864183",
                    "CorpusId": 216562296
                },
                "corpusId": 216562296,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2f5b15f6c5a1a75a8808688f7708888d526f8bb5",
                "title": "RelationNet2: Deep Comparison Columns for Few-Shot Learning.",
                "abstract": "Few-shot deep learning is a topical challenge area for scaling visual recognition to open ended growth of unseen new classes with limited labeled examples. A promising approach is based on metric learning, which trains a deep embedding to support image similarity matching. Our insight is that effective general purpose matching requires non-linear comparison of features at multiple abstraction levels. We thus propose a new deep comparison network comprised of embedding and relation modules that learn multiple non-linear distance metrics based on different levels of features simultaneously. Furthermore, to reduce over-fitting and enable the use of deeper embeddings, we represent images as distributions rather than vectors via learning parameterized Gaussian noise regularization. The resulting network achieves excellent performance on both miniImageNet and tieredImageNet.",
                "year": 2018,
                "authors": [
                    {
                        "authorId": "2108058854",
                        "name": "Xueting Zhang"
                    },
                    {
                        "authorId": "3387134",
                        "name": "Yuting Qiang"
                    },
                    {
                        "authorId": "40497013",
                        "name": "Flood Sung"
                    },
                    {
                        "authorId": "2653152",
                        "name": "Yongxin Yang"
                    },
                    {
                        "authorId": "1697755",
                        "name": "Timothy M. Hospedales"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Compared to [4], our proposed method using recurrent back-propagation [18, 1, 25] is more general as it does not require a closed-form update, and the inner loop solver can employ any existing continuous optimizers.",
                "To address this problem, [4] proposes to use fast convergent models like logistic regression (LR), which can be back-propagated via a closed form update rule.",
                "Unlike [4], we do not rely on an analytic form of the gradients of the optimization process."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "cf17734c10177f6a6aca0cf83af854a8108454c8",
                "externalIds": {
                    "DBLP": "conf/nips/RenLFZ19",
                    "MAG": "2897029699",
                    "ArXiv": "1810.07218",
                    "CorpusId": 52986657
                },
                "corpusId": 52986657,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/cf17734c10177f6a6aca0cf83af854a8108454c8",
                "title": "Incremental Few-Shot Learning with Attention Attractor Networks",
                "abstract": "Machine learning classifiers are often trained to recognize a set of pre-defined classes. However, in many applications, it is often desirable to have the flexibility of learning additional concepts, with limited data and without re-training on the full training set. This paper addresses this problem, incremental few-shot learning, where a regular classification network has already been trained to recognize a set of base classes, and several extra novel classes are being considered, each with only a few labeled examples. After learning the novel classes, the model is then evaluated on the overall classification performance on both base and novel classes. To this end, we propose a meta-learning model, the Attention Attractor Network, which regularizes the learning of novel classes. In each episode, we train a set of new weights to recognize novel classes until they converge, and we show that the technique of recurrent back-propagation can back-propagate through the optimization process and facilitate the learning of these parameters. We demonstrate that the learned attractor network can help recognize novel classes while remembering old classes without the need to review the original training set, outperforming various baselines.",
                "year": 2018,
                "authors": [
                    {
                        "authorId": "2540599",
                        "name": "Mengye Ren"
                    },
                    {
                        "authorId": "2246396",
                        "name": "Renjie Liao"
                    },
                    {
                        "authorId": "2645055",
                        "name": "Ethan Fetaya"
                    },
                    {
                        "authorId": "1804104",
                        "name": "R. Zemel"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Most of the Methods use different techniques of metric learning [11, 12], attention mechanism [13], data augmentation [14], or meta learning [12, 15]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "384888d83e72700b0104dc45cb2cce88478609cd",
                "externalIds": {
                    "ArXiv": "1808.09001",
                    "DBLP": "journals/corr/abs-1808-09001",
                    "MAG": "2888850511",
                    "CorpusId": 52115773
                },
                "corpusId": 52115773,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/384888d83e72700b0104dc45cb2cce88478609cd",
                "title": "COFGA: Classification Of Fine-Grained Features In Aerial Images",
                "abstract": "Classification between thousands of classes in high-resolution images is one of the heavily studied problems in deep learning over the last decade. However, the challenge of fine-grained multi-class classification of objects in aerial images, especially in low resource cases, is still challenging and an active area of research in the literature. Solving this problem can give rise to various applications in the field of scene understanding and classification and re-identification of specific objects from aerial images. In this paper, we provide a description of our dataset - COFGA of multi-class annotated objects in aerial images. We examine the results of existing state-of-the-art models and modified deep neural networks. Finally, we explain in detail the first published competition for solving this task.",
                "year": 2018,
                "authors": [
                    {
                        "authorId": "32450996",
                        "name": "Eran Dahan"
                    },
                    {
                        "authorId": "9951258",
                        "name": "Tzvi Diskin"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "55967c3c80dfcad095446b819940d8a1b217c4e7",
                "externalIds": {
                    "MAG": "2883670420",
                    "DBLP": "journals/corr/abs-1807-08912",
                    "ArXiv": "1807.08912",
                    "DOI": "10.1007/978-3-030-44051-0_19",
                    "CorpusId": 50777536
                },
                "corpusId": 50777536,
                "publicationVenue": {
                    "id": "bff7eed1-d24f-440c-a9fe-c7b93f066cff",
                    "name": "Workshop on the Algorithmic Foundations of Robotics",
                    "type": "conference",
                    "alternate_names": [
                        "WAFR",
                        "International Workshop Algorithmic Foundations Robotics",
                        "Int Workshop Algorithmic Found Robot",
                        "Workshop Algorithmic Found Robot"
                    ],
                    "url": "http://www.wafr.org/"
                },
                "url": "https://www.semanticscholar.org/paper/55967c3c80dfcad095446b819940d8a1b217c4e7",
                "title": "Meta-Learning Priors for Efficient Online Bayesian Regression",
                "abstract": null,
                "year": 2018,
                "authors": [
                    {
                        "authorId": "2106702981",
                        "name": "James Harrison"
                    },
                    {
                        "authorId": "2109540240",
                        "name": "Apoorva Sharma"
                    },
                    {
                        "authorId": "1696085",
                        "name": "M. Pavone"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Generally, these approaches can be roughly categorized as either meta-learning algorithms (including MAML [38], Meta-SGD [39], DEML+Meta-SGD [40], META-LEARN LSTM [41], Meta-Net [42], R2-D2[43], Reptile[44], WRN [45]) and metric-learning algorithms (including Matching Nets [36], PROTO-NET [37], RELATION NET [46], MACO [47], and Cos & Att.",
                "(including MAML [38], Meta-SGD [39], DEML+Meta-SGD [40], META-LEARN LSTM [41], Meta-Net [42], R2-D2[43], Reptile[44], WRN [45]) and metric-learning algorithms (including Matching Nets [36], PROTO-NET [37], RELATION NET [46], MACO [47], and Cos & Att.",
                "[48], Delta-encoder [57] and R2-D2[43].",
                "CUB-200(%)1-shot 5-shot 1-shot 5-shot META-LEARN LSTM [41] 43.44\u00b10.77 60.60\u00b10.71 40.43 49.65\nMAML [38] 48.70\u00b11.84 63.11\u00b10.92 38.43 59.15 Meta-Net [42] 49.21\u00b10.96 - - -\nReptile[44] 49.97 65.99 - - MAML* [38] 52.23\u00b11.24 61.24\u00b10.77 - - Meta-SGD* [39] 52.31\u00b11.14 64.66\u00b10.89 - - DEML+Meta-SGD [40] 58.49\u00b10.91 71.28\u00b10.69 - -\nMACO [47] 41.09\u00b10.32 58.32\u00b10.21 60.76 74.96 Matching Nets* [36] 47.89\u00b10.86 60.12\u00b10.68 - -\nPROTO-NET [37] 49.42\u00b10.78 68.20\u00b10.66 45.27 56.35 GNN [52] 50.33\u00b10.36 66.41\u00b10.63 - -\nR2-D2 [43] 51.5\u00b10.2 68.8\u00b10.1 - - MM-Net [50] 53.37\u00b10.48 66.97\u00b10.35 - - Cos & Att."
            ],
            "intents": [],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "b41b23ef5a34c83f2bf9d4a9e98f8ed065f61918",
                "externalIds": {
                    "ArXiv": "1804.05298",
                    "DBLP": "journals/tip/ChenFZJXS19",
                    "MAG": "3099486271",
                    "DOI": "10.1109/TIP.2019.2910052",
                    "CorpusId": 52908669,
                    "PubMed": "30969924"
                },
                "corpusId": 52908669,
                "publicationVenue": {
                    "id": "e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                    "name": "IEEE Transactions on Image Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Image Process"
                    ],
                    "issn": "1057-7149",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b41b23ef5a34c83f2bf9d4a9e98f8ed065f61918",
                "title": "Multi-Level Semantic Feature Augmentation for One-Shot Learning",
                "abstract": "The ability to quickly recognize and learn new visual concepts from limited samples enable humans to quickly adapt to new tasks and environments. This ability is enabled by the semantic association of novel concepts with those that have already been learned and stored in memory. Computers can start to ascertain similar abilities by utilizing a semantic concept space. A concept space is a high-dimensional semantic space in which similar abstract concepts appear close and dissimilar ones far apart. In this paper, we propose a novel approach to one-shot learning that builds on this core idea. Our approach learns to map a novel sample instance to a concept, relates that concept to the existing ones in the concept space and, using these relationships, generates new instances, by interpolating among the concepts, to help learning. Instead of synthesizing new image instance, we propose to directly synthesize instance features by leveraging semantics using a novel auto-encoder network called dual TriNet. The encoder part of the TriNet learns to map multi-layer visual features from CNN to a semantic vector. In semantic space, we search for related concepts, which are then projected back into the image feature spaces by the decoder portion of the TriNet. Two strategies in the semantic space are explored. Notably, this seemingly simple strategy results in complex augmented feature distributions in the image feature space, leading to substantially better performance.",
                "year": 2018,
                "authors": [
                    {
                        "authorId": "13556061",
                        "name": "Z. Chen"
                    },
                    {
                        "authorId": "35782003",
                        "name": "Yanwei Fu"
                    },
                    {
                        "authorId": "1591143181",
                        "name": "Yinda Zhang"
                    },
                    {
                        "authorId": "1717861",
                        "name": "Yu-Gang Jiang"
                    },
                    {
                        "authorId": "145905953",
                        "name": "X. Xue"
                    },
                    {
                        "authorId": "144398147",
                        "name": "L. Sigal"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS is a standard benchmark for few-shot learning tasks, containing 100 classes from CIFAR-100 [68].",
                "As shown in Table II, in 1- and 5-shot test, our method attains 10.04% and 4.67% improvement over Fine-tuning [45] on CIFAR-FS dataset.",
                "FC100 is another dataset stemmed from CIFAR-100, which is similar to CIFAR-FS dataset with 100 classes grouped into 20\nadvanced classes differently.",
                "The extensive experiments on three few-shot learning datasets, CIFAR-FS [32], FC100 [33], and miniImageNet [23], [34] demonstrate that the proposed GCLR achieves remarkable performance in image classification tasks.",
                "Compared to the conference version, GCLR with GNN achieves further improvement in classification accuracy for 5-, 10-, 15-, and 20-shot tasks on CIFAR-FS, FC100, and miniImageNet.",
                "\u03c6 is a proportional optimizable parameter which has shown good performance in few-shot learning [32], [33] with SVM and RR as base-learners."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "6fb68e05c95539db69d8bce3fd88609f3bbde943",
                "externalIds": {
                    "DBLP": "journals/tmm/ZhongGYHL23",
                    "DOI": "10.1109/TMM.2022.3141886",
                    "CorpusId": 245885320
                },
                "corpusId": 245885320,
                "publicationVenue": {
                    "id": "10e76a35-58d6-443c-9683-fc16f2dd0a92",
                    "name": "IEEE transactions on multimedia",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Transactions on Multimedia",
                        "IEEE Trans Multimedia",
                        "IEEE trans multimedia"
                    ],
                    "issn": "1520-9210",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6046"
                },
                "url": "https://www.semanticscholar.org/paper/6fb68e05c95539db69d8bce3fd88609f3bbde943",
                "title": "Graph Complemented Latent Representation for Few-Shot Image Classification",
                "abstract": "Few-shot learning is a tough topic to solve since obtaining a large number of training samples in real applications is challenging. It has attracted increasing attention recently. Meta-learning is a prominent way to address this issue, intending to adapt predictors as base-learners to new tasks swiftly. However, a key challenge of meta-learning is its lack of expressive capacity, which stems from the difficulty of extracting general information from a small number of training samples. As a result, the generalizability of meta-learners trained from high-dimensional parameter spaces is frequently limited. To learn a better representation, we propose a graph complemented latent representation (GCLR) network for few-shot image classification. In particular, we embed the representation into a latent space, in which the latent codes are reconstructed using variational information to enrich the representation. In this way, the latent representation can achieve better generalizability. Another benefit is that, because the latent space is formed using variational inference, it cooperates well with various base-learners, boosting robustness. To make full use of the relation between samples in each category, a graph neural network (GNN) is also incorporated to improve relation mining. Consequently, our end-to-end framework delivers competitive performance on three few-shot learning benchmarks for image classification.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "46812609",
                        "name": "X. Zhong"
                    },
                    {
                        "authorId": "2053399518",
                        "name": "Cheng Gu"
                    },
                    {
                        "authorId": "2676247",
                        "name": "Mang Ye"
                    },
                    {
                        "authorId": "1500393994",
                        "name": "Wenxin Huang"
                    },
                    {
                        "authorId": "1685088",
                        "name": "Chia-Wen Lin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We evaluate our approach on the miniImageNet, CIFAR-FS and FC100 datasets, and present results demonstrating its advantages over previous work.",
                "For the fully connected layer in the auxiliary task the weight decay is 0.00001 on miniImageNet, and 0.0005 on FC100 and CIFAR-FS.",
                "Experiments on few-shot image classification using the miniImageNet, CIFAR-FS and FC100 datasets confirm these findings, and we observe improved accuracy using the variational approach to train the VERSA model (Gordon et al., 2019).",
                "We integrate SAMOVAR with the deterministic TADAM architecture (Oreshkin et al., 2018), and find that our stochastic formulation leads to significantly improved performance, competitive with the state of the art on the miniImageNet, CIFAR-FS and FC100 datasets.",
                "In Table 3.5, we compare our model to the state of the art on CIFAR-FS.",
                "In the 5-shot setup, the weight decay parameter in the inference networks is 0.00001 on miniImageNet, and 0.00005 on FC100 and CIFAR-FS.",
                "Our stochastic formulation significantly improves performance over the\n3.2 Related work 40\nbase architecture, and yields results competitive with the state of the art on the miniImageNet, CIFAR-FS and FC100 datasets.",
                "We consider three main benchmarks for few-shot learning: MiniIamgeNet, FC100 and CIFAR-FS.",
                "On FC100 and CIFAR-FS, we use 30k SGD updates with the same momentum and initial learning rate, and the latter is decreased after 15k, 20k and 25k updates.",
                "56\n3.4 Accuracy and 95% confidence intervals of the state-of-the-art models on the\n5-way task on FC100. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n3.5 Accuracy and 95% confidence intervals of the state-of-the-art models on the\n5-way task on CIFAR-FS. . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n4.1 Ablation experiments with different continuous adapters. . . . . . . . . . .",
                "CIFAR-FS (Bertinetto et al., 2019) is another meta-learning dataset derived from CIFAR100.",
                "In R2-D2, Bertinetto et al. (2019) propose to replace the gradient descent or LSTM updates in the inner loop of meta-optimisation models, referred to as the base learners, with standard machine learning algorithms that involve closed-form solutions, such as ridge regression.",
                "To adapt to the regime of (very) small training datasets, optimisationbased meta-learning techniques replace the vanilla SGD approach with a trainable update mechanism (Bertinetto et al., 2019; Finn et al., 2017; Ravi & Larochelle, 2017)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "21e2c9ef968f58d2e1b9c81655af4da1166f8019",
                "externalIds": {
                    "CorpusId": 259257452
                },
                "corpusId": 259257452,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/21e2c9ef968f58d2e1b9c81655af4da1166f8019",
                "title": "Transfert de repr\u00e9sentations de caract\u00e9ristiques entre les t\u00e2ches et les domaines Transferring feature representations across tasks and domains",
                "abstract": "Year after year advances in deep learning allow to solve a rapidly increasing range of challenging tasks, as well as to set new, even more ambitious goals. Such a success, however, comes at a price of increasing requirements for all aspects of learning: large-scale models, which tend to perform best, require large quantities of data, memory, computational resources and time to be properly trained. This cannot always be achieved in practice, especially on smaller datasets, which promotes exploration of the ways to transfer knowledge, i.e. re-purposing existing state-of-the-art models to solving new tasks. This problem of transferring knowledge between tasks comes with its own challenges caused by different factors, such as the type of knowledge which needs to be transferred, or availability of data. In this thesis we focus on two setups from this category: few-shot learning and multi-domain learning. Both problems share the motivation to learn a model that would be able to generalise to solving the same type of task, e.g. image classification, on a number of different domains. Our first contribution explores probabilistic modeling for few-shot classification, where the model aims to solve a wide range of classification tasks, each accompanied with a handful of labeled examples. Limited supervision leads to high uncertainty about the predictions, which can be naturally tackled by probabilistic framework. We treat the task-specific classifier as a latent variable, and propose a novel amortised variational inference scheme which uses a single network to predict parameters of the distribution both for the prior and for the approximated posterior of the latent variable in the considered graphical model. The prior is conditioned on the support set of the task, while the approximated posterior is conditioned on the union of the support and query sets. Minimisation of the distance between these two distributions provides additional guidance from the support set during training, allowing us to exploit the disparity between the two sets of data. We evaluate our model on several few-shot classification benchmarks, and show that it can achieve competitive results on all of them. We also demonstrate the benefits of modeling uncertainty by showing that a sampled ensemble of classifiers slightly improves the performance compared to the inferred classifier mean. This result that cannot be achieved by models relying on Monte Carlo approximations, which, according to our experiments, tend to underestimate the true variance.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "145806677",
                        "name": "J. Kuntzmann"
                    },
                    {
                        "authorId": "2082891951",
                        "name": "Ekaterina Iakovleva"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS: CIFAR-FS(Bertinetto et al., 2018) dataset used in our experiment is adapted from the CIFAR-100 dataset (Krizhevsky et al.",
                ", 2021), we conduct the experiments on four datasets: VGGFlowers(Nilsback & Zisserman, 2008), miniImagenet(Ravi & Larochelle, 2017), CIFAR-FS(Bertinetto et al., 2018), and Omniglot(Lake et al.",
                "Following exiting works (Yap et al., 2021; Zhang et al., 2021), we conduct the experiments on four datasets: VGGFlowers(Nilsback & Zisserman, 2008), miniImagenet(Ravi & Larochelle, 2017), CIFAR-FS(Bertinetto et al., 2018), and Omniglot(Lake et al., 2011).",
                "CIFAR-FS: CIFAR-FS(Bertinetto et al., 2018) dataset used in our experiment is adapted from the CIFAR-100 dataset (Krizhevsky et al., 2009) for few-shot learning, which consists of 100 classes."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2eab1668afb83d24712a2bf83efeab8f85557c63",
                "externalIds": {
                    "DBLP": "conf/icml/WuFZL023",
                    "CorpusId": 260817040
                },
                "corpusId": 260817040,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2eab1668afb83d24712a2bf83efeab8f85557c63",
                "title": "Adaptive Compositional Continual Meta-Learning",
                "abstract": "This paper focuses on continual meta-learning, where few-shot tasks are heterogeneous and sequentially available. Recent works use a mixture model for meta-knowledge to deal with the heterogeneity. However, these methods suffer from parameter inefficiency caused by two reasons: (1) the underlying assumption of mutual exclusiveness among mixture components hinders sharing meta-knowledge across heterogeneous tasks. (2) they only allow increasing mixture components and cannot adaptively filter out redundant components. In this paper, we pro-pose an A daptive C ompositional Continual M eta-L earning (ACML) algorithm, which employs a compositional premise to associate a task with a subset of mixture components, allowing meta-knowledge sharing among heterogeneous tasks. Moreover, to adaptively adjust the number of mixture components, we propose a component spar-sification method based on evidential theory to filter out redundant components. Experimental results show ACML outperforms strong baselines, showing the effectiveness of our compositional meta-knowledge, and confirming that ACML can adaptively learn meta-knowledge.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2187129580",
                        "name": "Bin Wu"
                    },
                    {
                        "authorId": "1384241384",
                        "name": "Jinyuan Fang"
                    },
                    {
                        "authorId": "2111550171",
                        "name": "Xiangxiang Zeng"
                    },
                    {
                        "authorId": "3279808",
                        "name": "Shangsong Liang"
                    },
                    {
                        "authorId": "150271064",
                        "name": "Qiang Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Unless otherwise specified, the ablations are performed on CIFAR-FS with the ResNet12, in the 5-way zero-shot setting.",
                "2 and 3 presents the experimental results on CIFAR-FS [4] and miniImageNet [47] respectively.",
                "Due to the lack of reliable and scalable baselines of adversarially robust methods in ZSL setting, we first applied LAAT to two popular few-shot benchmark datasets CIFAR-FS [4] and miniImageNet [47] and compared our method with several adversarially robust few-shot methods [14, 42, 50] directly.",
                "In most cases (except ResNet12 on CIFAR-FS), 1-shot performance of LAAT can further surpass the zero-shot performance.",
                "CIFAR-FS [4], a variant of CIFAR100 [24], is a classification dataset containing 64 categories of training data, 16 categories of validation data, and 20 categories of test data for evaluation."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "40af315cac824895a672da83afbc23f029136b38",
                "externalIds": {
                    "CorpusId": 256389508
                },
                "corpusId": 256389508,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/40af315cac824895a672da83afbc23f029136b38",
                "title": "Anchor-Based Adversarially Robust Zero-Shot Learning Driven by Language",
                "abstract": "Deep neural networks are vulnerable to adversarial attacks. We consider adversarial defense in the case of zero-shot image classi\ufb01cation setting, which has rarely been explored because both adversarial defense and zero-shot learning are challenging. We propose LAAT, a novel Language-driven, Anchor-based Adversarial Training strategy, to improve the adversarial robustness in a zero-shot setting. LAAT uses a text encoder to obtain \ufb01xed anchors (normalized feature embeddings) of each category, then uses these anchors to perform adversarial training. The text encoder has the property that semantically similar categories can be mapped to neighboring anchors in the feature space. By leveraging this property, LAAT can make the image model adversarially robust on novel categories without any extra examples. Experimental results show that our method achieves impressive zero-shot adversarial performance, even surpassing the previous state-of-the-art adversarially robust one-shot methods in most attacking settings. When models are trained with LAAT on large datasets like ImageNet-1K, they can have substantial zero-shot adversarial robustness across several downstream datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2108790183",
                        "name": "Xiao Li"
                    },
                    {
                        "authorId": "47528139",
                        "name": "Wei Zhang"
                    },
                    {
                        "authorId": "2108140808",
                        "name": "Yining Liu"
                    },
                    {
                        "authorId": "2110918716",
                        "name": "Zhan Hu"
                    },
                    {
                        "authorId": "2208118592",
                        "name": "Bo Zhang"
                    },
                    {
                        "authorId": "2148967005",
                        "name": "Xiaolin Hu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Several studies have shown the adaptation of only the last layer performs quite well (Bertinetto et al., 2018; Lee et al., 2019b; Kumagai et al., 2021).",
                "\u2026this assumption is not unique to the proposed method but is common to almost all metalearning methods (for anomaly detection) (Snell et al., 2017; Finn et al., 2017; Bertinetto et al., 2018; Rajeswaran et al.,\n2019; Kumagai et al., 2021; Frikha et al., 2021; Kruspe, 2019; Kumagai et al., 2019).",
                "However, many iterations can be problematic in the meta-learning since they significantly increase the computation cost (Rajeswaran et al., 2019; Bertinetto et al., 2018).",
                "Since they require the secondorder derivative of the whole parameters for training, they have considerable computation and memory burdens (Rajeswaran et al., 2019; Bertinetto et al., 2018)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "5e888048df7bc5a26712903e1772f63d9d695741",
                "externalIds": {
                    "DBLP": "conf/aistats/KumagaiITF23",
                    "CorpusId": 259107074
                },
                "corpusId": 259107074,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/5e888048df7bc5a26712903e1772f63d9d695741",
                "title": "Meta-learning for Robust Anomaly Detection",
                "abstract": "We propose a meta-learning method to improve the anomaly detection performance on unseen target tasks that have only unlabeled data. Existing meta-learning methods for anomaly detection have shown remarkable performance but require labeled data in target tasks. Although they can treat unlabeled data as normal assuming anomalies in the unlabeled data are negligible, this assumption is often violated in practice. As a result, the methods have low performance. Our method meta-learns with related tasks that have labeled and unlabeled data such that the expected test anomaly detection performance is directly improved when the anomaly detector is adapted to given unlabeled data. Our method is based on autoencoders (AEs), which are widely used neural network-based anomaly detectors. We model anomalous attributes for each unlabeled instance in the reconstruction loss of the AE, which are used to prevent the anomalies from being reconstructed; they can remove the effect of the anomalies. We formulate adaptation to the unlabeled data as a learning problem of the last layer of the AE and the anomalous attributes. This formulation enables the optimum solution to be obtained with a closed-form alternate update formula, which is preferable to ef\ufb01ciently maximize the expected test anomaly detection performance. The effectiveness of our method is experimentally shown with four real-world datasets.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "3370561",
                        "name": "Atsutoshi Kumagai"
                    },
                    {
                        "authorId": "2664600",
                        "name": "Tomoharu Iwata"
                    },
                    {
                        "authorId": "145979683",
                        "name": "Hiroshi Takahashi"
                    },
                    {
                        "authorId": "2112645215",
                        "name": "Yasuhiro Fujiwara"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Recently, \u201cshallow\u201d machine learning methods have been successfully integrated into CNNs for few-shot learning [29], [35], [36]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "aec864aa0c640a8c1641fef146ae58931fb2ed37",
                "externalIds": {
                    "DBLP": "journals/tmm/ChengHHLZ23",
                    "DOI": "10.1109/TMM.2021.3123813",
                    "CorpusId": 240269302
                },
                "corpusId": 240269302,
                "publicationVenue": {
                    "id": "10e76a35-58d6-443c-9683-fc16f2dd0a92",
                    "name": "IEEE transactions on multimedia",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Transactions on Multimedia",
                        "IEEE Trans Multimedia",
                        "IEEE trans multimedia"
                    ],
                    "issn": "1520-9210",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6046"
                },
                "url": "https://www.semanticscholar.org/paper/aec864aa0c640a8c1641fef146ae58931fb2ed37",
                "title": "Mixer-Based Semantic Spread for Few-Shot Learning",
                "abstract": "Key semantics can come from everywhere on an image. Semantic alignment is a key part of few-shot learning but still remains challenging. In this paper, we design a Mixer-Based Semantic Spread (MBSS) algorithm that employs a mixer module to spread the key semantic on the whole image, so that one can directly compare the processed image pairs. We first adopt a convolutional neural network to extract features from both support and query images and separate each of them into multiple Local Descriptor-based Representations (LDRs). The LDRs are then fed into the mixer for semantic spread, where every LDR attracts complementary information from its peers. In this way, the objective semantic is made spread on the whole image in a data-driven manner. The overall pipeline is supervised by a voting-based loss, guaranteeing a good mixer. Visualization results validate the feasibility of our mixer. Comprehensive experiments on three benchmark datasets, miniImageNet, tieredImageNet, and CUB, show that our algorithm achieves the state-of-the-art performance in both 5-way 1-shot and 5-way 5-shot settings.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2157745206",
                        "name": "Jun Cheng"
                    },
                    {
                        "authorId": "41022398",
                        "name": "Fusheng Hao"
                    },
                    {
                        "authorId": "51209425",
                        "name": "Fengxiang He"
                    },
                    {
                        "authorId": "2109528221",
                        "name": "Liu Liu"
                    },
                    {
                        "authorId": "1783427",
                        "name": "Qieshi Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d2a114339d095b497c0109d8f220287faa096c99",
                "externalIds": {
                    "DBLP": "journals/tim/TianMYLY23",
                    "DOI": "10.1109/TIM.2023.3268455",
                    "CorpusId": 258245656
                },
                "corpusId": 258245656,
                "publicationVenue": {
                    "id": "3edbd5e0-8799-420a-9ca8-b35c646c354f",
                    "name": "IEEE Transactions on Instrumentation and Measurement",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Instrum Meas"
                    ],
                    "issn": "0018-9456",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=19",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/d2a114339d095b497c0109d8f220287faa096c99",
                "title": "Vision Transformer With Enhanced Self-Attention for Few-Shot Ship Target Recognition in Complex Environments",
                "abstract": "Ship target recognition is essential for maritime transportation, commercial trade, maritime security, and monitoring illegal activity. The majority of previous ship target recognition models are based on fully supervised learning, which necessitates vast amounts of labeled training data. However, optical lenses capturing ship images in natural scenarios have numerous complex environments, making feature extraction difficult due to hardware, weather, light, waves, and other factors. Moreover, image annotation is also both expensive and time-consuming. How to effectively learn from unbalanced, limited, and sparsely annotated sample data is a significant challenge. In this article, we propose a new vision transformer with enhanced self-attention (SAVT) that can locate ship targets in complex environments with just a few shots. SAVT consists of a novel enhanced self-attention (ESA) module and a novel measurement self-adjusting computation (MAC) module to differentiate unique ship classes in complex environments with few labeled samples. The ESA module focuses on the features of the target region at each layer of the backbone network to ensure that the contour detailed features are extracted effectively from ship images with complex environments. The model is then enhanced in terms of speed and stability using the MAC module. The CIB-ships and public MAR-ships datasets are used to evaluate the proposed method. In this article, the results demonstrate that SAVT achieves good performance on few-shot labeled data under both one-shot and five-shot settings, while also providing valuable guidance for maritime ship target recognition with limited labeled samples.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2153663841",
                        "name": "Yang Tian"
                    },
                    {
                        "authorId": "2057833497",
                        "name": "Hao Meng"
                    },
                    {
                        "authorId": "2056632265",
                        "name": "Fei Yuan"
                    },
                    {
                        "authorId": "2162897483",
                        "name": "Yue Ling"
                    },
                    {
                        "authorId": "2214900507",
                        "name": "Ningze Yuan"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[6] proposed a differentiable ridge regression classifier to quickly adapt to novel classes."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f5de3fd6d72ab4502c6024319a81023ab8834caa",
                "externalIds": {
                    "DBLP": "journals/lgrs/YuanLL23",
                    "DOI": "10.1109/LGRS.2023.3282310",
                    "CorpusId": 259053966
                },
                "corpusId": 259053966,
                "publicationVenue": {
                    "id": "290335d6-cddc-465d-87f1-807e86d8efee",
                    "name": "IEEE Geoscience and Remote Sensing Letters",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Geosci Remote Sens Lett"
                    ],
                    "issn": "1545-598X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=8859",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8859"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f5de3fd6d72ab4502c6024319a81023ab8834caa",
                "title": "Double Discriminative Constraint-Based Affine Nonnegative Representation for Few-Shot Remote Sensing Scene Classification",
                "abstract": "Remote sensing scene classification (RSSC) has recently attracted more attention. However, due to restrictions in the imaging environment and equipment, it is difficult to get a large number of labeled images in remote sensing. This has led to the emergence of few-shot learning for RSSC, which aims to achieve better performance with few labeled samples. Remote sensing images\u2019 large interclass similarity may cause classification confusion. To overcome this issue, this study proposes a double discriminative constraint-based affine nonnegative representation for few-shot RSSC. To be specific, we devise a novel representation-based classifier with two discriminative constraint terms in the objective function and utilize affine nonnegative constraints to restrict the learned parameters. These constraints reduce the correlation between classes and strengthen the class specificity of the learned parameters. Experiments on benchmark datasets demonstrate the effectiveness of our method.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2218255198",
                        "name": "Tianhao Yuan"
                    },
                    {
                        "authorId": "2109174226",
                        "name": "Weifeng Liu"
                    },
                    {
                        "authorId": "2155992419",
                        "name": "Baodi Liu"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2019) and \u201cR2-D2\u201d (Bertinetto et al., 2018) for more details.",
                "You can check the paper \u201cANIL\u201d (Raghu et al., 2019) and \u201cR2-D2\u201d (Bertinetto et al., 2018) for more details."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dae0781c9077ced0e51cec1fdcc0367e5f171362",
                "externalIds": {
                    "CorpusId": 259841804
                },
                "corpusId": 259841804,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/dae0781c9077ced0e51cec1fdcc0367e5f171362",
                "title": "Model Agnostic Meta-Learning 1 . 1 Recap : Multitask Learning Problem",
                "abstract": "1. Rather than starting the training process from scratch each time a new task is encountered, we aim to develop a more effective approach. 2. Specifically, we seek to construct a potentially larger model that can be fine-tuned for the task at hand. 3. This aligns with the principles of Model Agnostic Meta-Learning (MAML), which aims to enable effective fine-tuning using only a small amount of task-specific data.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1724120",
                        "name": "A. Sahai"
                    },
                    {
                        "authorId": "2223570552",
                        "name": "Zixun Huang"
                    },
                    {
                        "authorId": "2223096171",
                        "name": "Tianyue Cheng"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e4f0ab1408504c3873a849d341ec63fbca899534",
                "externalIds": {
                    "DBLP": "conf/iclr/ChiangNMBGGG23",
                    "CorpusId": 259298444
                },
                "corpusId": 259298444,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/e4f0ab1408504c3873a849d341ec63fbca899534",
                "title": "Loss Landscapes are All You Need: Neural Network Generalization Can Be Explained Without the Implicit Bias of Gradient Descent",
                "abstract": "It is commonly believed that the implicit regularization of optimizers is needed for neural networks to generalize in the overparameterized regime. In this paper, we observe experimentally that this implicit regularization behavior is generic, i.e. it does not depend strongly on the choice of optimizer. We demonstrate this by training neural networks using several gradient-free optimizers, which do not benefit from properties that are often attributed to gradient-based optimizers. This includes a guess-and-check optimizer that generates uniformly random parameter vectors until finding one that happens to achieve perfect train accuracy, and a zeroth-order Pattern Search optimizer that uses no gradient computations. In the low sample and few-shot regimes, where zeroth order optimizers are most computationally tractable, we find that these non-gradient optimizers achieve test accuracy comparable to SGD. The code to reproduce results can be found at https://github.com/Ping-C/optimizer.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "143923090",
                        "name": "Ping-yeh Chiang"
                    },
                    {
                        "authorId": "3434279",
                        "name": "Renkun Ni"
                    },
                    {
                        "authorId": "2220922864",
                        "name": "David Yu Miller"
                    },
                    {
                        "authorId": "7364835",
                        "name": "Arpit Bansal"
                    },
                    {
                        "authorId": "8284185",
                        "name": "Jonas Geiping"
                    },
                    {
                        "authorId": "121592562",
                        "name": "Micah Goldblum"
                    },
                    {
                        "authorId": "1962083",
                        "name": "T. Goldstein"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Geometric ideas such as cosine similarity and Euclidean distance are utilized in [1] and [17], respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b7363e057436f9ec0b9f21c5c00e32a27603ba77",
                "externalIds": {
                    "DBLP": "journals/access/ZhengZK23",
                    "DOI": "10.1109/ACCESS.2023.3294984",
                    "CorpusId": 259886285
                },
                "corpusId": 259886285,
                "publicationVenue": {
                    "id": "2633f5b2-c15c-49fe-80f5-07523e770c26",
                    "name": "IEEE Access",
                    "type": "journal",
                    "issn": "2169-3536",
                    "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html",
                    "alternate_urls": [
                        "http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/b7363e057436f9ec0b9f21c5c00e32a27603ba77",
                "title": "DAC: Disentanglement-and-Calibration Module for Cross-Domain Few-Shot Classification",
                "abstract": "Cross-domain few-shot classification (CD-FSC) aims to develop few-shot classification models trained on seen domains but tested on unseen domains. However, the cross-domain setup poses a challenge in the form of domain shift between the training and testing domains. Previous research has demonstrated that the encoder can disentangle features into domain-shared and domain-specific features. However, poorly estimated domain-specific features can lead to inadequate generalization on the unseen domain. This paper proposes a disentanglement-and-calibration module (DAC) to address this issue. The disentanglement component separates the features into domain-shared and domain-specific features, while the calibration component corrects the domain-specific features. We demonstrate that the DAC module can significantly enhance the generalization capability of several baseline methods. Furthermore, we show that MatchingNet with the DAC module outperforms existing state-of-the-art methods by 10%-11% when trained on mini-ImageNet, CUB-200, Cars196, Places365 and tested on Plantae dataset.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "2115239329",
                        "name": "Hao Zheng"
                    },
                    {
                        "authorId": "19219781",
                        "name": "Q. Zhang"
                    },
                    {
                        "authorId": "2554424",
                        "name": "Asako Kanezaki"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "49e4009368d920dd5f7b81faa0a8a20b47fc41ff",
                "externalIds": {
                    "DBLP": "journals/tmm/GuoSHHK23",
                    "DOI": "10.1109/TMM.2022.3168146",
                    "CorpusId": 248287490
                },
                "corpusId": 248287490,
                "publicationVenue": {
                    "id": "10e76a35-58d6-443c-9683-fc16f2dd0a92",
                    "name": "IEEE transactions on multimedia",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Transactions on Multimedia",
                        "IEEE Trans Multimedia",
                        "IEEE trans multimedia"
                    ],
                    "issn": "1520-9210",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6046"
                },
                "url": "https://www.semanticscholar.org/paper/49e4009368d920dd5f7b81faa0a8a20b47fc41ff",
                "title": "RSNet: Relation Separation Network for Few-Shot Similar Class Recognition",
                "abstract": "Although deep learning methods have drastically improved the performance on visual recognition tasks in which large inter-class variances exist, similar-class recognition continues to pose significant challenges, mainly due to the close resemblance between similar classes. The challenge is further compounded in the case of few-shot learning because only a very small amount of training data is available; accordingly, a certain performance degradation has been observed when some few-shot methods are applied for classification tasks. To address the aforementioned issue, we propose a novel Relation Separation Network (RSNet) in this paper, aiming to boost few-shot learning by improving similar-class recognition performance. We assume that image features consist of common and private features, where the common features capture the basic attributes shared among similar classes and their private counterparts capture the unique attributes of each class. Our RSNet learns to decouple the common and private features of an image. As a result, the feature representation of an image is composed of two weakly associated but easily aligned components, and better classification performance is achieved by giving more attention to subtle features. Experimental results on the publicly available datasets miniImageNet, CUB, and CIFAR-FS show that the proposed model outperforms existing state-of-the-art methods. Specifically, compared to PT+MAP, RSNet improves the accuracy of classification on the CUB dataset by approximately 5% and that of similar-class classification by more than 10%.",
                "year": 2023,
                "authors": [
                    {
                        "authorId": "1808299",
                        "name": "Kehua Guo"
                    },
                    {
                        "authorId": "2113394530",
                        "name": "Changchun Shen"
                    },
                    {
                        "authorId": "1852333699",
                        "name": "Bin Hu"
                    },
                    {
                        "authorId": "2093566373",
                        "name": "Min Hu"
                    },
                    {
                        "authorId": "2157632957",
                        "name": "Xiaoyan Kui"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Meanwhile, R2-D2 (Bertinetto et al., 2019) and MetaOptNet (Lee et al., 2019) reduce the dimensionality of trainable model parameters by freezing feature extraction layers during inner loop optimization.",
                "\u2026few gradient steps away from \u03b8 (Finn et al., 2017, 2018, Grant et al., 2018, Yoon et al., 2018), while other meta-learning approaches assume that \u03c6\u03c4 and \u03b8 share the parameters in the feature extractor and only differ in the top layer (Bertinetto et al., 2019, Lee et al., 2019, Snell et al., 2017).",
                "CIFAR-FS (Bertinetto et al., 2019) is a derivative of the original CIFAR-100 dataset by randomly splitting 100 classes into 64, 16, and 20 classes for training, validation, and testing, respectively (Bertinetto et al., 2019).",
                ", 2019) is a derivative of the original CIFAR-100 dataset by randomly splitting 100 classes into 64, 16, and 20 classes for training, validation, and testing, respectively (Bertinetto et al., 2019).",
                "CIFAR-FS (Bertinetto et al., 2019) is a derivative of the original CIFAR-100 dataset by randomly splitting 100 classes into 64, 16, and 20 classes for training, validation, and testing, respectively (Bertinetto et al.",
                "Therefore, the temperature scaling factor can be applied to a\n0 100 200 300 400 500 600 Singular value index i\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nNo rm\nal ize\nd sin\ngu la\nr v al\nue\ni/ m\nax miniImageNet\nw.o. SWA: ilog i = 68.49 SWA: ilog i = 58.49\n0 100 200 300 400 500 600 Singular value index i\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nNo rm\nal ize\nd sin\ngu la\nr v al\nue\ni/ m\nax\ntieredImageNet w.o. SWA: ilog i = 83.98 SWA: ilog i = 80.01\n0 100 200 300 400 500 600 Singular value index i\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nNo rm\nal ize\nd sin\ngu la\nr v al\nue\ni/ m\nax\nCIFAR-FS\nw.o. SWA: ilog i = 40.94 SWA: ilog i = 33.63\n0 100 200 300 400 500 600 Singular value index i\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nNo rm\nal ize\nd sin\ngu la\nr v al\nue\ni/ m\nax\nFC100\nw.o. SWA: ilog i = 40.22 SWA: ilog i = 34.34\nFigure 2: Normalized singular values for representation with and without SWA.",
                "Meanwhile, R2-D2 (Bertinetto et al., 2019) and MetaOptNet (Lee et al.",
                "Note that the proposed method is fundamentally different from R2-D2 and MetaOptNet because our method requires neither episodic meta-learning nor bi-level optimization."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "992f0ba2c6082f85cfd3cec61b003372c2d94b04",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-12466",
                    "DOI": "10.48550/arXiv.2204.12466",
                    "CorpusId": 248391885
                },
                "corpusId": 248391885,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/992f0ba2c6082f85cfd3cec61b003372c2d94b04",
                "title": "Meta-free representation learning for few-shot learning via stochastic weight averaging",
                "abstract": "Recent studies on few-shot classi\ufb01cation using transfer learning pose challenges to the effectiveness and ef\ufb01ciency of episodic meta-learning algorithms. Transfer learning approaches are a natural alternative, but they are restricted to few-shot classi\ufb01cation. Moreover, little attention has been on the development of probabilistic models with well-calibrated uncertainty from few-shot samples, except for some Bayesian episodic learning algorithms. To tackle the aforementioned issues, we propose a new transfer learning method to obtain accurate and reliable models for few-shot regression and classi\ufb01cation. The resulting method does not require episodic meta-learning and is called meta-free representation learning (MFRL). MFRL \ufb01rst \ufb01nds low-rank representation generalizing well on meta-test tasks. Given the learned representation, probabilistic linear models are \ufb01ne-tuned with few-shot samples to obtain models with well-calibrated uncertainty. The proposed method not only achieves the highest accuracy on a wide range of few-shot learning benchmark datasets but also correctly quanti\ufb01es the prediction uncertainty. In addition, weight averaging and temperature scaling are effective in improving the accuracy and reliability of few-shot learning in existing meta-learning algorithms with a wide range of learning paradigms and model architectures.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3289893",
                        "name": "Kuilin Chen"
                    },
                    {
                        "authorId": "2143724945",
                        "name": "Chi-Guhn Lee"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We speculate that this property is connected to R2-D2\u2019s few-shot learning driven design and simulation of adapting to new tasks during its inner loop.",
                "As we see from Table 3, with the same fine-tune setting (See Appendix A.2), models pretrained by R2-D2 can achieve \u223c 5% higher top-1 accuracy than those pre-trained by SimCLR after fine-tuning on labeled data.",
                "From the results in Table 4, we find that R2-D2 initialized model consistently outperforms its contrastive counterpart on all 8 datasets.",
                "Now that we have established a framework for sampling tasks, we can directly apply various metalearning algorithms, such as R2-D2 and ProtoNet described in Section 2.1, in order to learn the parameters \u03b8 of the base model F .",
                "These results suggest that for the same number of epochs, a model trained with R2-D2 works better as an initialization for downstream tasks than one trained with SimCLR.",
                "We observe that representations learned via meta-learning (R2-D2 and ProtoNet) can achieve performance on par with SimCLR on CIFAR-10 but worse on ImageNet.",
                "We will see in the following experiments that although R2-D2 achieves worse linear evaluation on ImageNet with this hyperparameter setting, it actually performs better than SimCLR on downstream tasks, such as semi-supervised learning and transfer learning, other popular (and plausibly more realistic) evaluation scenarios for SSL methods.",
                "For the rotation angle predictor loss, we weight the additional loss term with coefficient \u03bb = 1 for all experiments except for pre-training with R2-D2, where we set \u03bb = 0.01.",
                "Meanwhile, meta-learning is an established popular framework for learning models that quickly adapt to on-the-fly tasks given a small number of examples (Hochreiter et al., 2001; Finn et al., 2017; Nichol et al., 2018; Bertinetto et al., 2018; Lee et al., 2019).",
                "Other algorithms, such as MetaOptNet and R2-D2 (Lee et al., 2019; Bertinetto et al., 2018), keep the feature extractor frozen during fine-tuning; MetaOptNet uses SVM, and R2D2 uses ridge regression on top of the feature extractor."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "5942115e923dcd5b3eae63865a59c05160ad1ad7",
                "externalIds": {
                    "DBLP": "conf/iclr/NiSSGG22",
                    "CorpusId": 251647290
                },
                "corpusId": 251647290,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/5942115e923dcd5b3eae63865a59c05160ad1ad7",
                "title": "The Close Relationship Between Contrastive Learning and Meta-Learning",
                "abstract": "Contrastive learning has recently taken off as a paradigm for learning from unlabeled data. In this paper, we discuss the close relationship between contrastive learning and meta-learning under a certain task distribution. We complement this observation by showing that established meta-learning methods, such as Prototypical Networks, achieve comparable performance to SimCLR when paired with this task distribution. This relationship can be leveraged by taking established techniques from meta-learning, such as task-based data augmentation, and showing that they benefit contrastive learning as well. These tricks also benefit state-of-the-art self-supervised learners without using negative pairs such as BYOL, which achieves 94.6% accuracy on CIFAR-10 using a self-supervised ResNet-18 feature extractor trained with our meta-learning tricks. We conclude that existing advances designed for contrastive learning or metalearning can be exploited to benefit the other, and it is better for contrastive learning researchers to take lessons from the meta-learning literature (and viceversa) than to reinvent the wheel. Our Pytorch implementation can be found on: https://github.com/RenkunNi/MetaContrastive",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3434279",
                        "name": "Renkun Ni"
                    },
                    {
                        "authorId": "1643697854",
                        "name": "Manli Shu"
                    },
                    {
                        "authorId": "78859465",
                        "name": "Hossein Souri"
                    },
                    {
                        "authorId": "121592562",
                        "name": "Micah Goldblum"
                    },
                    {
                        "authorId": "1962083",
                        "name": "T. Goldstein"
                    }
                ]
            }
        },
        {
            "contexts": [
                "For CIFAR-FS, our method outperforms best baselines by 4.8% and 5.7% for 10-shot and 20-shot learning, respectively.",
                "For CIFAR-FS, our method outperforms best baselines by 1.5% and 2.3% for 10-shot and 20-shot learning, respectively.",
                "For CIFAR-FS, our method outperforms best baselines by 2.3% and 3.2% for 10-shot and 20-shot learning, respectively.",
                "Table 2 shows the evaluation results for 5-way classification on CIFAR-FS and Mini-Imagenet respectively.",
                "To evaluate the effectiveness of the proposed method on more challenging real image datasets, we perform experiments on CIFAR-FS [Bertinetto et al., 2019] and MiniImagenet [Vinyals et al.",
                "Results Table 3 shows the evaluation results for 5-way classification on CIFAR-FS and Mini-Imagenet respectively.",
                "In addition, Table 3 shows the evaluation results for 10-way classification on CIFAR-FS and Mini-Imagenet re-\nspectively.",
                "For our proposed benchmarks with CIFAR-FS and Mini-ImageNet pre-trained models, our method improves over baselines in the range of 2% to 7%, demonstrating the effectiveness of the proposed approach.",
                "For CIFAR-FS, our method outperforms best baselines by 2.3% and 3.7% for 10-shot and 20-shot learning, respectively.",
                "To evaluate the effectiveness of the proposed method on more challenging real image datasets, we perform experiments on CIFAR-FS [Bertinetto et al., 2019] and MiniImagenet [Vinyals et al., 2016]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "dfcbc59870f77d2b3fff328c1ab09a655d714a01",
                "externalIds": {
                    "DBLP": "conf/uai/WangWSSS0SG22",
                    "CorpusId": 252898974
                },
                "corpusId": 252898974,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/dfcbc59870f77d2b3fff328c1ab09a655d714a01",
                "title": "Meta-learning without data via Wasserstein distributionally-robust model fusion",
                "abstract": "Existing meta-learning works assume that each task has available training and testing data. How-ever, we can only use many available pre-trained models without accessing their training data in practice. We often need a single model to solve different tasks simultaneously as this is much more convenient to deploy the models. Our work aims to meta-learn a model initialization from these pre-trained models without using corresponding training data. We name this challenging problem setting Data-Free Learning To Learn (DFL2L). We propose a distributionally robust optimization (DRO) framework to learn a black-box model to fuse and compress all the pre-trained models into a single network to address this problem. The proposed DRO framework diversi\ufb01es the learned task embedding associated with each pre-trained model to cover the diversity in the underlying training task distributions, encouraging good generalization to unseen new tasks. We sample a meta-initialization from the black-box network during meta-testing for fast adaptation to unseen new tasks. Extensive experiments on of\ufb02ine and online DFL2L settings and several real image datasets demonstrate the effectiveness of the proposed methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2920297",
                        "name": "Zhenyi Wang"
                    },
                    {
                        "authorId": "48631781",
                        "name": "Xiaoyang Wang"
                    },
                    {
                        "authorId": "2172820082",
                        "name": "Li Shen"
                    },
                    {
                        "authorId": "7623895",
                        "name": "Qiuling Suo"
                    },
                    {
                        "authorId": "50982080",
                        "name": "Kaiqiang Song"
                    },
                    {
                        "authorId": "144580027",
                        "name": "Dong Yu"
                    },
                    {
                        "authorId": "2115436349",
                        "name": "Yan Shen"
                    },
                    {
                        "authorId": "50987693",
                        "name": "Mingchen Gao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "While the authors used meta-batch size of 2 for 5-shot and 4 for 2-shot experiment to reduce training memory consumption, we stick to 4 as it leads to slightly better performance on CIFAR-FS [8] dataset during our experiments.",
                "For the experiments we have used the novel CIFARFS [8] dataset.",
                "In [8] it has been suggested to split 100 classes into train, validation and test sets.",
                "The testing results will be shown on a publicly-available few-shot learning dataset CIFAR-FS [8].",
                "The exact classes that go into each split are important for testing the resulting accuracy and are defined in [8]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "ae0e94e780e9e7116cbc0e8f626d6a2b46e4195a",
                "externalIds": {
                    "CorpusId": 248490910
                },
                "corpusId": 248490910,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ae0e94e780e9e7116cbc0e8f626d6a2b46e4195a",
                "title": "FASTER OPTIMIZATION-BASED META-LEARNING ADAPTATION PHASE",
                "abstract": "Context. Neural networks require a large amount of annotated data to learn. Meta-learning algorithms propose a way to decrease number of training samples to only a few. One of the most prominent optimization-based meta-learning algorithms is MAML. How-ever, its adaptation to new tasks is quite slow. The object of study is the process of meta-learning and adaptation phase as defined by the MAML algorithm. Objective. The goal of this work is creation of an approach, which should make it possible to: 1) increase the execution speed of MAML adaptation phase; 2) improve MAML accuracy in certain cases. The testing results will be shown on a publicly available few-shot learning dataset CIFAR-FS. Method. In this work an improvement to MAML meta-learning algorithm is proposed. Meta-learning procedure is defined in terms of tasks. In case of image classification problem, each task is to try to learn to classify images of new classes given only a few training examples. MAML defines 2 stages for the learning procedure: 1) adaptation to the new task; 2) meta-weights update. The whole training procedure requires Hessian computation, which makes the method computationally expensive. After being trained, the network will typically be used for adaptation to new tasks and the subsequent prediction on them. Thus, improving adaptation time is an important problem, which we focus on in this work. We introduce \u039b (lambda) pattern by which we restrict which weight we update in the network during the adaptation phase. This approach allows us to skip certain gradient computations. The pattern is selected given an allowed quality degradation threshold parameter. Among the pattern that fit the criteria, the fastest pattern is then selected. However, as it is discussed later, quality improvement is also possible is certain cases by a careful pattern selection. Results. The MAML algorithm with \u039b pattern adaptation has been implemented, trained and tested on the open CIFAR-FS dataset. This makes our results easily reproducible. Conclusions. The experiments conducted have shown that via \u039b adaptation pattern selection, it is possible to significantly improve the MAML method in the following areas: adaptation time has been decreased by a factor of 3 with minimal accuracy loss. Interestingly, accuracy for one-step adaptation has been substantially improved by using \u039b patterns as well. Prospects for further research are to investigate a way of a more robust automatic pattern selection scheme.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "52352630",
                        "name": "Udc"
                    },
                    {
                        "authorId": "2163978625",
                        "name": "Faster OPTIMIZATION-BASED"
                    }
                ]
            }
        },
        {
            "contexts": [
                "R2D2 [Bertinetto et al., 2018] parameterize a feature map \u03c6\u03b8 : X \u2192 R which give rise to a kernel M\u03b8(x, x\u2032) = \u27e8\u03c6\u03b8(x), \u03c6\u03b8(x)\u27e9.",
                "For example, in regression settings, a common choice of inner algorithm is ridge regression and the meta-parameter is a representation or embedding shared across the tasks that we wish to meta-learn [Bertinetto et al., 2018].",
                "For example, [Bertinetto et al., 2018] considered the case that A performs ridge regression (see Sec.",
                "Additionally we experiment with using a neural network random feature kernel, an extension of R2D2 [Bertinetto et al., 2018], and show competitive performance.",
                "R2D2 [Bertinetto et al., 2018].",
                "While most previous work focused on learning a shared data representation or feature map [Bertinetto et al., 2018, Finn et al., 2017, Franceschi et al., 2018] across tasks, here we propose the dual approach of learning a shared kernel function.",
                "Table 1: Validation results for meta-hyperparameter configurations for IKML, R2D2 [Bertinetto et al., 2018] and ANP [Kim et al."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "63bba0d754b947649953ba523d7fe38fb70f2a99",
                "externalIds": {
                    "DBLP": "conf/uai/FalkCP22",
                    "CorpusId": 252898954
                },
                "corpusId": 252898954,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/63bba0d754b947649953ba523d7fe38fb70f2a99",
                "title": "Implicit kernel meta-learning using kernel integral forms",
                "abstract": "Meta-learning algorithms have made signi\ufb01cant progress in the context of meta-learning for image classi\ufb01cation but less attention has been given to the regression setting. In this paper we propose to learn the probability distribution representing a random feature kernel that we wish to use within kernel ridge regression (KRR). We introduce two instances of this meta-learning framework, learning a neural network pushforward for a translation-invariant kernel and an af\ufb01ne pushforward for a neural network random feature kernel, both mapping from a Gaussian latent distribution. We learn the parameters of the pushforward by minimizing a meta-loss associated to the KRR objective. Since the resulting kernel does not admit an ana-lytical form, we adopt a random feature sampling approach to approximate it. We call the resulting method Implicit Kernel Meta-Learning (IKML). We derive a meta-learning bound for IKML, which shows the role played by the number of tasks T , the task sample size n , and the number of random features M . In particular the bound implies that M can be the chosen independently of T and only mildly dependent on n . We introduce one synthetic and two real-world meta-learning regression benchmark datasets. Experiments on these datasets show that IKML performs best or close to best when compared against competitive meta-learning methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2155835758",
                        "name": "Johannes Falk"
                    },
                    {
                        "authorId": "7666146",
                        "name": "C. Ciliberto"
                    },
                    {
                        "authorId": "1704699",
                        "name": "M. Pontil"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We evaluate our approach using four datasets: (i) Mini-ImageNet (Vinyals et al., 2016), (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al., 2018), (iv) and EMNIST (balanced) (Cohen et al., 2017).",
                "This occurred around iteration 16,000 for CIFAR-FS and around iteration 20,000 for Mini-ImageNet,\nGalanti, Gyo\u0308rgy and Hutter\nslightly after the first learning rate decay (at 15,000 and 18,000 steps, respectively).",
                "CIFAR-FS and FC-100 are both derived from the CIFAR-100 dataset (Krizhevsky, 2012).",
                "To demonstrate this, we compared the 1- and 5-shot performance of our approach to several other few-shot learning algorithms on the Mini-ImageNet, CIFAR-FS, and FC-100 datasets, as summarized in Table 1.",
                ", 2016), (ii) CIFAR-FS (Bertinetto et al., 2019), (iii) FC-100 (Oreshkin et al.",
                "CIFAR-FS consists of a random split of the CIFAR-100 classes into 64 meta-train classes, 14 metavalidation classes, and 20 meta-test classes.",
                "Therefore, we empirically investigated the dynamics of mini 6=j\u2208[l] \u2016\u00b5f (S\u0303i)\u2212\u00b5f (S\u0303j)\u2016 during training in our standard setting (WRN-28-4 with the default hyperparameters, see Section 2) on CIFAR-FS, considering a varying number source classes (l \u2208 {5, 10, 20, 30, 40, 50, 60}) and learning rates (\u03b7 \u2208 {2\u22122i\u22122}4i=1)."
            ],
            "intents": [],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "87db9f89804861b7b897456654e41ad2b1d6d9ab",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2212-12532",
                    "DOI": "10.48550/arXiv.2212.12532",
                    "CorpusId": 255096688
                },
                "corpusId": 255096688,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/87db9f89804861b7b897456654e41ad2b1d6d9ab",
                "title": "Generalization Bounds for Transfer Learning with Pretrained Classifiers",
                "abstract": "We study the ability of foundation models to learn representations for classi\ufb01cation that are transferable to new, unseen classes. Recent results in the literature show that representations learned by a single classi\ufb01er over many classes are competitive on few-shot learning problems with representations learned by special-purpose algorithms designed for such problems. We o\ufb00er an explanation for this phenomenon based on the concept of class-features variability collapse, which refers to the training dynamics of deep classi\ufb01cation networks where the feature embeddings of samples belonging to the same class tend to concentrate around their class means. More speci\ufb01cally, we examine the few-shot error of the learned feature map, which is the classi\ufb01cation error of the nearest class-center classi\ufb01er using centers learned from a small number of random samples from each class. Assuming that the classes appearing in the data are selected independently from a distribution, we show that the few-shot error generalizes from the training data to unseen test data, and we provide an upper bound on the expected few-shot error for new classes (selected from the same distribution) using the average few-shot error for the source classes. Additionally, we show that the few-shot error on the training data can be upper bounded using the degree of class-features variability collapse. This suggests that foundation models can provide feature maps that are transferable to new downstream tasks even with limited data available.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "9923405",
                        "name": "Tomer Galanti"
                    },
                    {
                        "authorId": "2090601385",
                        "name": "Andr'as Gyorgy"
                    },
                    {
                        "authorId": "144154444",
                        "name": "Marcus Hutter"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We consider WideResNet (WRN) [46], ResNet-12 [11] and a shallow network of 4 convolutional blocks (CONV) [2].",
                "We use three benchmarks for performance evaluation: miniImageNet [39], CUB [40] and CIFARFS [2].",
                "We meta-train the WRN, ResNet, CONV following [22], [19] and [2], respectively.",
                "For example, the overall performance of WRN outperforms CONV, and the performance boost of ADV-CE over CE with WRN in 1-shot tasks is 10.5%, which is larger than the boost with CONV (4.8%)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2569cb3562a864638d71da5da0ae3008d48f893f",
                "externalIds": {
                    "DBLP": "conf/nips/Huang022",
                    "CorpusId": 258509455
                },
                "corpusId": 258509455,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2569cb3562a864638d71da5da0ae3008d48f893f",
                "title": "Improving Task-Specific Generalization in Few-Shot Learning via Adaptive Vicinal Risk Minimization",
                "abstract": "Recent years have witnessed the rapid development of meta-learning in improving the meta generalization over tasks in few-shot learning. However, the task-specific level generalization is overlooked in most algorithms. For a novel few-shot learning task where the empirical distribution likely deviates from the true distribution, the model obtained via minimizing the empirical loss can hardly generalize to unseen data. A viable solution to improving the generalization comes as a more accurate approximation of the true distribution; that is, admitting a Gaussian-like vicinal distribution for each of the limited training samples. Thereupon we derive the resulting vicinal loss function over vicinities of all training samples and minimize it instead of the conventional empirical loss over training samples only, favorably free from the exhaustive sampling of all vicinal samples. It remains challenging to obtain the statistical parameters of the vicinal distribution for each sample. To tackle this challenge, we further propose to estimate the statistical parameters as the weighted mean and variance of a set of unlabeled data it passed by a random walk starting from training samples. To verify the performance of the proposed method, we conduct experiments on three standard few-shot learning benchmarks and consolidate the superiority of the proposed method over state-of-the-art few-shot learning baselines.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2957079",
                        "name": "Long-Kai Huang"
                    },
                    {
                        "authorId": "2112556840",
                        "name": "Ying Wei"
                    }
                ]
            }
        },
        {
            "contexts": [
                "[5], the Woodbury formulation, W \u2217 = Z (ZZ + \u03bbI)\u22121Y is used to alleviate the problem, leading to an O(d(3)) complexity, where d is the hidden size hyperparameter, fixed to some value (see Appendix D).",
                "We achieve this by leveraging a ridge regression closed-form solver [5], on top an INR, illustrated in Figure 2b.",
                "We search through the values \u03bc = [1, 3, 5, 7, 9], and select the best value based on the validation loss.",
                "We further leverage Implicit Neural Representations [24, 36] as our choice of deep time-index models, a random Fourier features layer [38] to ensure that we are able to learn high frequency information present in time-series data, and a closed-form ridge regressor [5] to efficiently tackle the meta-learning formulation."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "72cf171c0360687a9b5108d9d57f2ccb0ca2cd16",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2207-06046",
                    "DOI": "10.48550/arXiv.2207.06046",
                    "CorpusId": 250492841
                },
                "corpusId": 250492841,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/72cf171c0360687a9b5108d9d57f2ccb0ca2cd16",
                "title": "DeepTIMe: Deep Time-Index Meta-Learning for Non-Stationary Time-Series Forecasting",
                "abstract": "Deep learning has been actively applied to time-series forecasting, leading to a deluge of new autoregressive model architectures. Yet, despite the attractive prop-erties of time-index based models, such as being a continuous signal function over time leading to smooth representations, little attention has been given to them. Indeed, while naive deep time-index based models are far more expressive than the manually prede\ufb01ned function representations of classical time-index based models, they are inadequate for forecasting due to the lack of inductive biases, and the non-stationarity of time-series. In this paper, we propose DeepTIMe, a deep time-index based model trained via a meta-learning formulation which overcomes these limitations, yielding an ef\ufb01cient and accurate forecasting model. Extensive experiments on real world datasets demonstrate that our approach achieves competitive results with state-of-the-art methods, and is highly ef\ufb01cient. Code is available at https://github.com/salesforce/DeepTIMe . We perform substantial studies to identify also show",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "151488390",
                        "name": "Gerald Woo"
                    },
                    {
                        "authorId": "2039481",
                        "name": "Chenghao Liu"
                    },
                    {
                        "authorId": "36187119",
                        "name": "Doyen Sahoo"
                    },
                    {
                        "authorId": "40305195",
                        "name": "Akshat Kumar"
                    },
                    {
                        "authorId": "1741126",
                        "name": "S. Hoi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "As exhibited in Table 4, regardless of whether RRML or PN is used as the classifier, SaAML obtains some performance progress across different datasets in contrast to the published original model and MLADA.",
                "Therefore, this meta-learning framework achieves outstanding performance when combined with distribution signatures, where DS+RRML is the best method.",
                "Ridge Regression Meta-Learner (RRML) (Bertinetto et al., 2018) exploits the ridge regression to obtain the class vector and develops proper regularization to reduce model overfitting and speed up model convergence.",
                "We adopt RRML (Bertinetto et al., 2018) and PN (Snell\net al., 2017) as the classifier to build the model, respectively."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "527939c00773b976a94a6e184ca8e51cad5bc599",
                "externalIds": {
                    "DBLP": "conf/coling/WangLLD22",
                    "ACL": "2022.coling-1.428",
                    "CorpusId": 252819380
                },
                "corpusId": 252819380,
                "publicationVenue": {
                    "id": "f51ff783-cdff-4e22-94fb-28e6336d17b3",
                    "name": "International Conference on Computational Linguistics",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Comput Linguistics",
                        "COLING"
                    ],
                    "url": "https://www.aclweb.org/anthology/venues/coling/"
                },
                "url": "https://www.semanticscholar.org/paper/527939c00773b976a94a6e184ca8e51cad5bc599",
                "title": "Sentence-aware Adversarial Meta-Learning for Few-Shot Text Classification",
                "abstract": "Meta-learning has emerged as an effective approach for few-shot text classification. However, current studies fail to realize the importance of the semantic interaction between sentence features and neglect to enhance the generalization ability of the model to new tasks. In this paper, we integrate an adversarial network architecture into the meta-learning system and leverage cost-effective modules to build a novel few-shot classification framework named SaAML. Significantly, our approach can exploit the temporal convolutional network to encourage more discriminative representation learning and explore the attention mechanism to promote more comprehensive feature expression, thus resulting in better adaptation for new classes. Through a series of experiments on four benchmark datasets, we demonstrate that our new framework acquires considerable superiority over state-of-the-art methods in all datasets, increasing the performance of 1-shot classification and 5-shot classification by 7.15% and 2.89%, respectively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2038466068",
                        "name": "Suhe Wang"
                    },
                    {
                        "authorId": null,
                        "name": "Xiaoyuan Liu"
                    },
                    {
                        "authorId": "2156643091",
                        "name": "Bo Liu"
                    },
                    {
                        "authorId": "2137132800",
                        "name": "DiWen Dong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Results on CIFARFS The CIFARFS [3] dataset consists of 100 classes sampled from CIFAR100 [23].",
                "Table 4 shows the few-shot accuracies on CIFARFS.",
                "Following [3], we divide all classes into 64, 16, and 20 classes for training, validation, and testing, respectively.",
                "Based on the Conv-4 [46] and ResNet-12 backbones, we conduct experiments on the Omniglot [24], miniImageNet [46], tieredImageNet [41], and CIFARFS [3] datasets."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "364d41c20c40943baf97e7760449de5bda933fdd",
                "externalIds": {
                    "DBLP": "conf/eccv/LiLHZJ22",
                    "DOI": "10.1007/978-3-031-19821-2_24",
                    "CorpusId": 253120472
                },
                "corpusId": 253120472,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/364d41c20c40943baf97e7760449de5bda933fdd",
                "title": "Unsupervised Few-Shot Image Classification by Learning Features into Clustering Space",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "40804183",
                        "name": "S. Li"
                    },
                    {
                        "authorId": "47185625",
                        "name": "Fang Liu"
                    },
                    {
                        "authorId": "2028922504",
                        "name": "Zehua Hao"
                    },
                    {
                        "authorId": "2185369574",
                        "name": "Kaibo Zhao"
                    },
                    {
                        "authorId": "2143819911",
                        "name": "Licheng Jiao"
                    }
                ]
            }
        },
        {
            "contexts": [
                "During the evaluation, we compared our methods on five standard datasets for few-shot classification, miniImageNet [48], tieredImageNet [40], CIFAR-FS [5], FC100 [37], and CUB [49].\nminiImageNet and tieredImageNet are subsets of ImageNet [41].miniImageNet consists of 100 classes with 600 samples per class and is randomly divided into three disjoint sets of the training set (64 classes), validation set (16 classes), and testing set (20 classes). tieredImageNet, a bigger version of miniImageNet, contains 608 classes with 1200 samples per class and is randomly split into 351/97/160 for train/val/test.",
                "CIFAR-FS is randomly split into 64/16/20 classes for train/val/test, while FC100 is divided into 60/20/20 classes according to 20 superclasses.",
                "During the evaluation, we compared our methods on five standard datasets for few-shot classification, miniImageNet [48], tieredImageNet [40], CIFAR-FS [5], FC100 [37], and CUB [49].",
                "From table 3, We can see that the transferring effect of miniImageNet on CUB is better than the previous method, and the mutual evaluation effect of miniImageNet and CIFAR-FS is close to the result of the intra-domain training, partly because they both are randomly divided.",
                "CIFAR-FS and FC100 both are variants of CIFAR100."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2b3fa12b0eebe7daf82c4a06d71a3370428e6226",
                "externalIds": {
                    "DBLP": "conf/eccv/LiZZFYZ22",
                    "DOI": "10.1007/978-3-031-20044-1_30",
                    "CorpusId": 253099838
                },
                "corpusId": 253099838,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/2b3fa12b0eebe7daf82c4a06d71a3370428e6226",
                "title": "TransVLAD: Focusing on Locally Aggregated Descriptors for Few-Shot Learning",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2188740062",
                        "name": "Haoquan Li"
                    },
                    {
                        "authorId": "2188826904",
                        "name": "Laoming Zhang"
                    },
                    {
                        "authorId": "2188765758",
                        "name": "Daoan Zhang"
                    },
                    {
                        "authorId": "2088894449",
                        "name": "Lan Fu"
                    },
                    {
                        "authorId": "2119186034",
                        "name": "Peng Yang"
                    },
                    {
                        "authorId": "2141732326",
                        "name": "Jianguo Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Popular meta-learning algorithms can be roughly divided into three categories: metric-based (Vinyals et al., 2016; Snell et al., 2017; Bertinetto et al., 2018; Oreshkin et al., 2018; Lee et al., 2019), memory-based (Santoro et al.",
                "(iii) Meta-Dataset-CIO, which consists of three widely-used few-shot datasets: CIFAR-FS (Bertinetto et al., 2018), mini-ImageNet (Vinyals et al., 2016), and Omniglot (Lake et al., 2015).",
                "Popular meta-learning algorithms can be roughly divided into three categories: metric-based (Vinyals et al., 2016; Snell et al., 2017; Bertinetto et al., 2018; Oreshkin et al., 2018; Lee et al., 2019), memory-based (Santoro et al., 2016; Munkhdalai & Yu, 2017), and optimizationbased.",
                "(iii) Meta-Dataset-CIO, which consists of three widely-used few-shot datasets: CIFAR-FS (Bertinetto et al., 2018), mini-ImageNet (Vinyals et al."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "74632d15fc15096c42f3727df4d720f6c2bf521f",
                "externalIds": {
                    "DBLP": "conf/icml/JiangK022",
                    "CorpusId": 250340778
                },
                "corpusId": 250340778,
                "publicationVenue": {
                    "id": "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                    "name": "International Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "ICML",
                        "Int Conf Mach Learn"
                    ],
                    "url": "https://icml.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/74632d15fc15096c42f3727df4d720f6c2bf521f",
                "title": "Subspace Learning for Effective Meta-Learning",
                "abstract": "Meta-learning aims to extract meta-knowledge from historical tasks to accelerate learning on new tasks. Typical meta-learning algorithms like MAML learn a globally-shared meta-model for all tasks. However, when the task environments are complex, task model parameters are diverse and a common meta-model is insuf\ufb01cient to capture all the meta-knowledge. To address this challenge, in this paper, task model parameters are structured into multiple subspaces, and each subspace represents one type of meta-knowledge. We propose an algorithm to learn the meta-parameters (i.e., subspace bases). We theoretically study the generalization properties of the learned subspaces. Experiments on regression and classi\ufb01cation meta-learning datasets verify the effectiveness of the proposed algorithm.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2152123946",
                        "name": "Weisen Jiang"
                    },
                    {
                        "authorId": "2062528230",
                        "name": "J. Kwok"
                    },
                    {
                        "authorId": "2153638098",
                        "name": "Yu Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Besides, we also used the cifar-fs (Bertinetto et al., 2019) sampled from cifar-100 dataset (Krizhevsky et al., 2009), which consists of size 32x32 colored images.",
                "We follow the splits for this dataset according to (Bertinetto et al., 2019).",
                "Besides, we also used the cifar-fs (Bertinetto et al., 2019) sampled from cifar-100 dataset (Krizhevsky et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2b7d14e541bc7882cf2f206069ac8de0936fd1c1",
                "externalIds": {
                    "DBLP": "conf/acml/BaiH022",
                    "CorpusId": 259092991
                },
                "corpusId": 259092991,
                "publicationVenue": {
                    "id": "2486528b-036c-4f3c-953f-c574eb381d12",
                    "name": "Asian Conference on Machine Learning",
                    "type": "conference",
                    "alternate_names": [
                        "Asian Conf Mach Learn",
                        "ACML"
                    ],
                    "url": "http://www.wikicfp.com/cfp/program?id=40"
                },
                "url": "https://www.semanticscholar.org/paper/2b7d14e541bc7882cf2f206069ac8de0936fd1c1",
                "title": "On the Episodic Difficulty of Few-shot Learning",
                "abstract": "Dog vs. hot dog and dog vs. wolf , which one tends to be a harder comparison task? While simple, this question can be meaningful for few-shot classification. Few-shot learning en-ables trained models to recognize unseen classes through just a few labelled samples. As such, trained few-shot models usually have to possess the ability to assess the similarity degree between the unlabelled and labelled samples. In each few-shot learning episode, a combination of the labelled support set and unlabelled query set are sampled from the training dataset for model-training. In the episodic settings of few-shot learning, most algorithms draw the data samples uniformly at random for training. However, this approach disregards concepts of difficulty of each training episode, which may make a difference. After all, it is usually easier to differentiate between a dog and a hot dog, versus the dog and a wolf. Therefore, in this paper, we delve into the concept of episodic difficulty, or difficulty of each training episode, discovering several insights and proposing strategies to utilize the difficulty. Firstly, defining episodic difficulty as a training loss, we find and study the correlation between episodic difficulty and visual similarity among data samples in each episode. Secondly, we assess the respective usefulness of easy and difficult episodes for the training process. Lastly, based on the assessment, we design a curriculum for few-shot learning to support training with incremental difficulty. We observe that such an approach can achieve faster convergence for few-shot algorithms, reducing the average training time by around 50%. It can also make meta-learning algorithms achieve an increase in final testing accuracy scores. Our major implementation is available at: https://github.com/WendyBaiYunwei/EpisodicDifficulty.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "153802726",
                        "name": "Yunwei Bai"
                    },
                    {
                        "authorId": "1707812",
                        "name": "Zhenfeng He"
                    },
                    {
                        "authorId": "2218809131",
                        "name": "Junfeng Hu"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2019) and R2D2 (Bertinetto et al., 2018) consider semiamortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model.",
                "MetaOptNet (Lee et al., 2019) and R2D2 (Bertinetto et al., 2018) consider semiamortized models based on differentiable optimization and propose to use differentiable SVMs and ridge regression as part of the amortization model."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8198ec90c9e97f583f921451e7112d943da75cb4",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2202-00665",
                    "CorpusId": 246442376
                },
                "corpusId": 246442376,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/8198ec90c9e97f583f921451e7112d943da75cb4",
                "title": "Tutorial on amortized optimization for learning to optimize over continuous domains",
                "abstract": "Optimization is a ubiquitous modeling tool that is often deployed in settings that repeatedly solve similar instances of the same problem. Amortized optimization methods use learning to predict the solutions to problems in these settings. This leverages the shared structure between similar problem instances. In this tutorial, we will discuss the key design choices behind amortized optimization, roughly categorizing 1) models into fully-amortized and semi-amortized approaches, and 2) learning methods into regression-based and objectivebased. We then view existing applications through these foundations to draw connections between them, including for manifold optimization, variational inference, sparse coding, meta-learning, control, reinforcement learning, convex optimization, and deep equilibrium networks. This framing enables us easily see, for example, that the amortized inference in variational autoencoders is conceptually identical to value gradients in control and reinforcement learning as they both use fully-amortized models with a objective-based loss. The source code for this tutorial is available at: https://github.com/facebookresearch/amortized-optimization-tutorial ar X iv :2 20 2. 00 66 5v 1 [ cs .L G ] 1 F eb 2 02 2",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1773498",
                        "name": "Brandon Amos"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a; Liu et al., 2021a), hyperparamater optimization (Franceschi et al.,\u2026",
                "Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a; Liu et al., 2021a), hyperparamater optimization (Franceschi et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "77d675604266180d8b54a613448bf859449cf11d",
                "externalIds": {
                    "CorpusId": 246473219
                },
                "corpusId": 246473219,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/77d675604266180d8b54a613448bf859449cf11d",
                "title": "A Novel Hessian-Free Bilevel Optimizer via Evolution Strategies",
                "abstract": "Bilevel optimization has arisen as a powerful tool for solving many modern machine learning problems. However, due to the nested structure of bilevel optimization, even gradient-based methods require secondorder derivative approximations via Jacobianor/and Hessian-vector computations, which can be very costly in practice. In this work, we propose a novel Hessian-free bilevel algorithm, which adopts the Evolution Strategies (ES) method to approximate the response Jacobian matrix in the hypergradient of the bilevel problem, and hence fully eliminates all second-order computations. We call our algorithm as ESJ (which stands for the ES-based Jacobian method) and further extend it to the stochastic setting as ESJ-S. Theoretically, we show that both ESJ and ESJ-S are guaranteed to converge. Experimentally, we demonstrate that the proposed algorithms outperform baseline bilevel optimizers on various bilevel problems. Particularly, in our experiment on few-shot meta-learning of ResNet-12 network over the miniImageNet dataset, we show that our algorithm outperforms baseline meta-learning algorithms, while other baseline bilevel optimizers do not solve such meta-learning problems within a comparable time frame.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "143827145",
                        "name": "Daouda Sow"
                    },
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Instead, many machine learning tasks \u2013 such as adversarial learning, meta learning (Franceschi et al., 2018; Bertinetto et al., 2018), hyperparameter optimization (Franceschi et al., 2018; Feurer & Hutter, 2019), reinforcement/imitation learning (Arora et al., 2020; Hong et al., 2020), and neural\u2026",
                "Instead, many machine learning tasks \u2013 such as adversarial learning, meta learning (Franceschi et al., 2018; Bertinetto et al., 2018), hyperparameter optimization (Franceschi et al."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "eaf99bdfa9fb65b1e2e4ac5e49e348c7b82a4a39",
                "externalIds": {
                    "CorpusId": 247028626
                },
                "corpusId": 247028626,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/eaf99bdfa9fb65b1e2e4ac5e49e348c7b82a4a39",
                "title": "FEDNEST: Federated Bilevel Optimization",
                "abstract": "Standard federated optimization methods are being successfully applied to solve stochastic problems with a single-level structure. However, many contemporary ML problems \u2013 including adversarial robustness, hyperparameter tuning, actor-critic \u2013 fall under nested bilevel programming that subsumes compositional and min-max optimization. In this work, we propose FEDNEST: A federated alternating stochastic gradient method to address general nested problems. We establish provable convergence rates for FEDNEST in the presence of heterogeneous data and introduce variations for specific instances. FEDNEST introduces multiple innovations including federated hypergradient computation and variance reduction to address inner-level heterogeneity. We complement our theory with experiments on hyperparameter & hyper-representation learning that demonstrate the benefits of our method in practice.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "3281605",
                        "name": "Davoud Ataee Tarzanagh"
                    },
                    {
                        "authorId": "47629178",
                        "name": "Mingchen Li"
                    },
                    {
                        "authorId": "2751682",
                        "name": "Christos Thrampoulidis"
                    },
                    {
                        "authorId": "3103394",
                        "name": "Samet Oymak"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning (Bertinetto et al., 2018; Rajeswaran et al., 2019), hyperparameters and model parameters training in automated hyperparameter tuning (Franceschi et al.",
                "Typically, parameters handled by bilevel optimization are divided into two different types such as meta and base learners in few-shot meta-learning (Bertinetto et al., 2018; Rajeswaran et al., 2019), hyperparameters and model parameters training in automated hyperparameter tuning (Franceschi et\u2026"
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c6488c42e3d47f76366f74dee58b7f50d672ae8f",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2203-01123",
                    "DOI": "10.48550/arXiv.2203.01123",
                    "CorpusId": 247218354
                },
                "corpusId": 247218354,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c6488c42e3d47f76366f74dee58b7f50d672ae8f",
                "title": "A Constrained Optimization Approach to Bilevel Optimization with Multiple Inner Minima",
                "abstract": ",",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "143827145",
                        "name": "Daouda Sow"
                    },
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "11701175",
                        "name": "Ziwei Guan"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Results on miniImageNet and tieredImageNet: As contending metalearning algorithms, we choose the vanilla MAML along with notable metalearners such as Meta-SGD [12], Reptile [16], LLAMA [7], R2-D2 [3], and BOIL [17]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c157289355772c4e0db42a9dc3120d71c5ebd85c",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-03511",
                    "DOI": "10.48550/arXiv.2204.03511",
                    "CorpusId": 248006009
                },
                "corpusId": 248006009,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c157289355772c4e0db42a9dc3120d71c5ebd85c",
                "title": "Interval Bound Propagation-aided Few-shot Learning",
                "abstract": ". Few-shot learning aims to transfer the knowledge acquired from training on a diverse set of tasks, from a given task distribution, to generalize to unseen tasks, from the same distribution, with a limited amount of labeled data. The underlying requirement for effective few-shot generalization is to learn a good representation of the task manifold. One way to encourage this is to preserve local neighborhoods in the feature space learned by the few-shot learner. To this end, we introduce the notion of interval bounds from the provably robust training literature to few-shot learning. The interval bounds are used to char-acterize neighborhoods around the training tasks. These neighborhoods can then be preserved by minimizing the distance between a task and its respective bounds. We further introduce a novel strategy to artificially form new tasks for training by interpolating between the available tasks and their respective interval bounds, to aid in cases with a scarcity of tasks. We apply our framework to both model-agnostic meta-learning as well as prototype-based metric-learning paradigms. The efficacy of our proposed approach is evident from the improved performance on sev-eral datasets from diverse domains in comparison to a sizable number of recent competitors.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2165464",
                        "name": "Shounak Datta"
                    },
                    {
                        "authorId": "70040213",
                        "name": "S. S. Mullick"
                    },
                    {
                        "authorId": "71658519",
                        "name": "Swagatam Das"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Here, for example, we examined the 5-way (5 classes) 1-shot task of CIFAR-FS, which is a kind of standard task in one-shot classification.",
                "Also, for demonstrating evaluation of DNNs in DONE, we used CIFAR-FS [26] by Torchmeta [30]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5c47e98fe0a79ce376f72c7fa7d5696b959b984b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2204-13361",
                    "DOI": "10.48550/arXiv.2204.13361",
                    "CorpusId": 248427025
                },
                "corpusId": 248427025,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5c47e98fe0a79ce376f72c7fa7d5696b959b984b",
                "title": "It's DONE: Direct ONE-shot learning without training optimization",
                "abstract": "Learning a new concept from one example is a superior function of human brain and it is drawing attention in the \ufb01eld of machine learning as one-shot learning task. In this paper, we propose the simplest method for this task, named Direct ONE-shot learning (DONE). DONE adds a new class to a pretrained deep neural network (DNN) classi\ufb01er with neither training optimization nor other-classes modi\ufb01cation. DONE is inspired by Hebbian theory and directly uses the neural activity input of the \ufb01nal dense layer obtained from a data that belongs to the new additional class as the connectivity weight (synaptic strength) with a newly-provided-output neuron for the new class. DONE requires just one inference for obtaining the output of the \ufb01nal dense layer and its procedure is simple, deterministic, not requiring parameter tuning and hyperparameters. The performance of DONE depends entirely on the pretrained DNN model used as a backbone model, and we con\ufb01rmed that DONE with a well-trained backbone model performs a practical-level accuracy. DONE has some advantages including a DNN\u2019s practical use that is dif\ufb01cult to spend high cost for a training, an evaluation of existing DNN models, and the understanding of the brain. DONE might be telling us one-shot learning is an easy task that can be achieved by a simple principle not only for humans but also for current well-trained DNN models.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2811391",
                        "name": "Kazufumi Hosoda"
                    },
                    {
                        "authorId": "2163741763",
                        "name": "Keigo Nishida"
                    },
                    {
                        "authorId": "35532030",
                        "name": "S. Seno"
                    },
                    {
                        "authorId": "1828039",
                        "name": "T. Mashita"
                    },
                    {
                        "authorId": "1799065",
                        "name": "H. Kashioka"
                    },
                    {
                        "authorId": "2821490",
                        "name": "I. Ohzawa"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026the task-shared outerparameters can be the weights of a neural network that acts as a feature extractor that will help a task-specific classifier or regressor parameterized by the inner-parameters to solve the task at hand (Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019).",
                "The previous formulation can be extended to meta-learning (Schmidhuber, 1987; Finn et al., 2017; Bertinetto et al., 2019) by considering several tasks."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "43e668618191c8cdcc1d56df76fbc3bd04b3c28d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2205-03076",
                    "DOI": "10.48550/arXiv.2205.03076",
                    "CorpusId": 248562945
                },
                "corpusId": 248562945,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/43e668618191c8cdcc1d56df76fbc3bd04b3c28d",
                "title": "Beyond backpropagation: implicit gradients for bilevel optimization",
                "abstract": "This paper reviews gradient-based techniques to solve bilevel optimization problems. Bilevel optimization is a general way to frame the learning of systems that are implicitly de\ufb01ned through a quantity that they minimize. This characterization can be applied to neural networks, optimizers, algorithmic solvers and even physical systems, and allows for greater modeling \ufb02exibility compared to an explicit de\ufb01nition of such systems. Here we focus on gradient-based approaches that solve such problems. We distinguish them in two categories: those rooted in implicit di\ufb00erentiation, and those that leverage the equilibrium propagation theorem. We present the mathematical foundations that are behind such methods, introduce the gradient-estimation algorithms in detail and compare the competitive advantages of the di\ufb00erent approaches.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "1729494470",
                        "name": "Nicolas Zucchet"
                    },
                    {
                        "authorId": "3105061",
                        "name": "J. Sacramento"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Bertinetto et al. (2019) utilizes ridge-regression based task-specific few-shot learners within a discriminative meta-learning framework."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "df6eb1a964633dd8d6fa7bd55053187a6bc1f90f",
                "externalIds": {
                    "CorpusId": 248964178
                },
                "corpusId": 248964178,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/df6eb1a964633dd8d6fa7bd55053187a6bc1f90f",
                "title": "C LOSED - FORM S AMPLE P ROBING FOR L EARNING G ENERATIVE M ODELS IN Z ERO - SHOT L EARNING",
                "abstract": "Generative model based approaches have led to signi\ufb01cant advances in zero-shot learning (ZSL) over the past few years. These approaches typically aim to learn a conditional generator that synthesizes training samples of classes conditioned on class de\ufb01nitions. The \ufb01nal zero-shot learning model is then obtained by training a supervised classi\ufb01cation model over the real and/or synthesized training samples of seen and unseen classes, combined. Therefore, naturally, the generative model needs to produce not only relevant samples, but also those that are suf\ufb01ciently rich for classi\ufb01er training purposes, which is handled by various heuristics in existing works. In this paper, we introduce a principled approach for training generative models directly for training data generation purposes. Our main observation is that the use of closed-form models opens doors to end-to-end training thanks to the differentiability of the solvers. In our approach, at each generative model update step, we \ufb01t a task-speci\ufb01c closed-form ZSL model from generated samples, and measure its loss on novel samples all within the compute graph, a procedure that we refer to as sample probing . In this manner, the generator receives feedback directly based on the value of its samples for model training purposes. Our experimental results show that the proposed sample probing approach improves the ZSL results even when integrated into state-of-the-art generative models.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2165964300",
                        "name": "Samet \u00c7etin"
                    },
                    {
                        "authorId": "1505785792",
                        "name": "Orhun Bugra Baran"
                    },
                    {
                        "authorId": "1939006",
                        "name": "R. G. Cinbis"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The other two are linear classifiers, namely SVM (MetaSVM, Lee et al., 2019) and ridge regression (R2D2, Bertinetto et al., 2019).",
                "CIFAR-FS: The CIFAR-FS dataset (Bertinetto et al., 2019) contains all the 100 classes form CIFAR100.",
                "(15)\nAnother choice of base learner is a discriminatively trained linear classifier, e.g., SVM (Lee et al., 2019) or ridge regression (Bertinetto et al., 2019)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1317008502804e67efb468d2ac22854d6a13290e",
                "externalIds": {
                    "DBLP": "conf/aistats/MaZ22",
                    "CorpusId": 248923308
                },
                "corpusId": 248923308,
                "publicationVenue": {
                    "id": "2d136b11-c2b5-484b-b008-7f4a852fd61e",
                    "name": "International Conference on Artificial Intelligence and Statistics",
                    "type": "conference",
                    "alternate_names": [
                        "AISTATS",
                        "Int Conf Artif Intell Stat"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/1317008502804e67efb468d2ac22854d6a13290e",
                "title": "Warping Layer: Representation Learning for Label Structures in Weakly Supervised Learning",
                "abstract": "Many learning tasks only receive weak su-pervision, such as semi-supervised learning and few-shot learning. With limited labeled data, prior structures become especially important, and prominent examples include hi-erarchies and mutual exclusions in the class space. However, most existing approaches only learn the representations separately in the feature space and the label space, and do not explicitly enforce the logical relationships. In this paper, we propose a novel warping layer that jointly learns representations in both spaces, and thanks to the mod-ularity and di\ufb00erentiability, it can be directly embedded into generative models to leverage the prior hierarchical structure and unlabeled data. The e\ufb00ectiveness of the warping layer is demonstrated on both few-shot and semi-supervised learning, outperforming the state of the art in practice.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "121720851",
                        "name": "Yingyi Ma"
                    },
                    {
                        "authorId": "2108029096",
                        "name": "Xinhua Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We examined the 5-way (5 classes) 1-shot task of CIFAR-FS, which is a kind of standard task in one-shot classification.",
                "Also, for transfer learning, we used CIFAR-FS [28] by Torchmeta [31]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6c3ec8e33f8278d80917c4bc5b23a796d399481e",
                "externalIds": {
                    "CorpusId": 249375271
                },
                "corpusId": 249375271,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/6c3ec8e33f8278d80917c4bc5b23a796d399481e",
                "title": "It\u2019s DONE: Direct ONE-shot learning with Hebbian weight imprinting",
                "abstract": "Learning a new concept from one example is a superior function of human brain and it is drawing attention in the field of machine learning as one-shot learning task. In this paper, we propose the simplest method for this task with a nonparametric weight imprinting, named Direct ONE-shot learning (DONE). DONE adds new classes to a pretrained deep neural network (DNN) classifier with neither training optimization nor pretrained-DNN modification. DONE is inspired by Hebbian theory and directly uses the neural activity input of the final dense layer obtained from a data that belongs to the new additional class as the connectivity weight (synaptic strength) with a newly-provided-output neuron for the new class, by transforming all statistical properties of the neural activity into those of synaptic strength. DONE requires just one inference for learning a new concept and its procedure is simple, deterministic, not requiring parameter tuning and hyperparameters. The performance of DONE depends entirely on the pretrained DNN model used as a backbone model, and we confirmed that DONE with a well-trained backbone model performs a practical-level accuracy. DONE has some advantages including a DNN\u2019s practical use that is difficult to spend high cost for a training, an evaluation of existing DNN models, and the understanding of the brain. DONE might be telling us one-shot learning is an easy task that can be achieved by a simple principle not only for humans but also for current well-trained DNN models.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2811391",
                        "name": "Kazufumi Hosoda"
                    },
                    {
                        "authorId": "2163741763",
                        "name": "Keigo Nishida"
                    },
                    {
                        "authorId": "35532030",
                        "name": "S. Seno"
                    },
                    {
                        "authorId": "1828039",
                        "name": "T. Mashita"
                    },
                    {
                        "authorId": "1799065",
                        "name": "H. Kashioka"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "ea95451fe662d19fbde990aaad3acdf211a14383",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2206-08868",
                    "DOI": "10.48550/arXiv.2206.08868",
                    "CorpusId": 249848265
                },
                "corpusId": 249848265,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/ea95451fe662d19fbde990aaad3acdf211a14383",
                "title": "Generalized Frank-Wolfe Algorithm for Bilevel Optimization",
                "abstract": "In this paper, we study a class of bilevel optimization problems, also known as simple bilevel optimization, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are not satisfactory as they are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue, in this paper, we introduce a generalization of the Frank-Wolfe (FW) method to solve the considered problem. The main idea of our method is to locally approximate the solution set of the lower-level problem via a cutting plane, and then run a FW-type update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires O (max { 1 /(cid:15) f , 1 /(cid:15) g } ) iterations to \ufb01nd a solution that is (cid:15) f optimal for the upper-level objective and (cid:15) g -optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires O (max { 1 /(cid:15) 2 f , 1 / ( (cid:15) f (cid:15) g ) } ) iterations to \ufb01nd an ( (cid:15) f , (cid:15) g )-optimal solution. We further prove stronger convergence guarantees under the H\u00a8olderian error bound assumption on the lower-level problem. To the best of our knowledge, our method achieves the best-known iteration complexity for the considered bilevel problem. We also present numerical experiments to showcase the superior performance of our method compared with state-of-the-art methods.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2051263313",
                        "name": "Ruichen Jiang"
                    },
                    {
                        "authorId": "2171107359",
                        "name": "Nazanin Abolfazli"
                    },
                    {
                        "authorId": "2706423",
                        "name": "Aryan Mokhtari"
                    },
                    {
                        "authorId": "7783772",
                        "name": "E. Y. Hamedani"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1f8cb5df220f448b64438ef6cd203f2bdeae079c",
                "externalIds": {
                    "CorpusId": 249917355
                },
                "corpusId": 249917355,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1f8cb5df220f448b64438ef6cd203f2bdeae079c",
                "title": "Appendix for Mutual Centralized Learning in Few-shot Classifications",
                "abstract": "where e|\u00b7| is a vector of ones with different length indicated by its subscript. Nr and r are the cardinalities of S and q, respectively. We know (by the definition of stochastic matrix) that \u03bb = 1 is the largest eigenvalue of PSqPqS, and its uniqueness is guaranteed since there is no zero entry in both PSq and PqS. According to Eqn.(A.1), we get another eigenvalue \u03bb = \u22121 for stochastic matrix P. From the Perron\u2013Frobenius theorem that the period of P equals to the number of eigenvalue whose absolute value is equal to the spectral radius of P, we prove its stationary distribution is of period 2.",
                "year": 2022,
                "authors": []
            }
        },
        {
            "contexts": [
                "Furthermore, the EFIL assumption is empirically reasonable, since previous works (Raghu et al., 2020; Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020) yield comparable performance while leaving the encoder untouched during the inner loop.",
                "Similar ideas of freezing feature extractors during the inner loop have also been explored (Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020), and have been held as an assumption in theoretical works (Du et al., 2021; Tripuraneni et al., 2020; Chua et al., 2021).",
                "Similar ideas of freezing feature extractors during the inner loop have also been explored (Lee et al., 2019; Bertinetto et al., 2019; Liu et al., 2020), and have been held as an assumption in theoretical works (Du et al."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "75ff11dbd08df8180d30f8fd3d3ca8696cfe6929",
                "externalIds": {
                    "CorpusId": 251415840
                },
                "corpusId": 251415840,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/75ff11dbd08df8180d30f8fd3d3ca8696cfe6929",
                "title": "MAML IS A N OISY C ONTRASTIVE L EARNER IN C LASSIFICATION",
                "abstract": "Model-agnostic meta-learning (MAML) is one of the most popular and widely adopted meta-learning algorithms, achieving remarkable success in various learning problems. Yet, with the unique design of nested inner-loop and outer-loop updates, which govern the task-specific and meta-model-centric learning, respectively, the underlying learning objective of MAML remains implicit, impeding a more straightforward understanding of it. In this paper, we provide a new perspective of the working mechanism of MAML. We discover that MAML is analogous to a meta-learner using a supervised contrastive objective in classification. The query features are pulled towards the support features of the same class and against those of different classes. Such contrastiveness is experimentally verified via an analysis based on the cosine similarity. Moreover, we reveal that vanilla MAML has an undesirable interference term originating from the random initialization and the cross-task interaction. We thus propose a simple but effective technique, the zeroing trick, to alleviate the interference. Extensive experiments are conducted on both mini-ImageNet and Omniglot datasets to validate the consistent improvement brought by our proposed method. 1 we adopt two experimental settings: 5-way 1-shot and 5-way 5-shot where the batch size N batch is 32 and N query is 15 for both cases (Finn et al., 2017). The inner loop learning rate \u03b7 is 0.4. The models are trained for 3000 iterations using FOMAML or SOMAML. The few-shot classification accuracy is calculated by averaging the results over 1000 tasks in the test stage. The model architecture follows the architecture used to train on mini-ImageNet, but we substitute the convolution with max-pooling with strided convolution operation as in Finn et al. (2017). The loss function, optimizer, and outer loop learning rate are the same as those used in the experiments on mini-ImageNet. Each experiment is run on either a single NVIDIA 1080-Ti. The results are over four random and the deviation is with otherwise.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2115997017",
                        "name": "Chia-Hsiang Kao"
                    },
                    {
                        "authorId": "37811787",
                        "name": "Wei-Chen Chiu"
                    },
                    {
                        "authorId": "2158177948",
                        "name": "Pin-Yu Chen"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3e5b71df458556da8356bfe8ad245e19145aef55",
                "externalIds": {
                    "CorpusId": 252332284
                },
                "corpusId": 252332284,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3e5b71df458556da8356bfe8ad245e19145aef55",
                "title": "Vanilla Base Embedding c ) Incremental Prototype Init . Base Support of Different Classes Base Query Incremental Support Incremental Embedding Boundary Base Embedding Boundary Joint Embedding Distribution b ) Local-reprojection Meta-Learning d ) Incremental Prototype Generalization Incremental Clust",
                "abstract": "Few-shot learning is a booming research area in computer vision that aims to recognize and grasp novel concepts by learning from a limited number of known samples. Existing literature in few-shot learning only focuses to recognize novel categories while neglecting the understanding of base knowledge. This paper introduces the concept of local relationship learning and proposes a generalized representation method for local relationships to address the two major research problems of the few-shot incremental learning tasks, i.e., inferior inter-class distinguishability and difficult generalization of incremental categories. To enhance the distinguishability in the incremental process, this paper first adopts the local spatial relationship to regularize the incremental representation ability. To alleviate the inductive biases caused by the lack of data in the incremental process, this paper proposes a spatial generalization prototype generation algorithm, which uses the distribution characteristics to quickly generate virtual prototypes and promote the effective representation of samples. Benefiting from the meta-learning training mechanism, this paper proposes a joint locality and generalization awareness incremental learning framework, which effectively alleviates catastrophic forgetting and difficulties in distinguishability by combining the local representation of the base category and the fast generalization constraint of the incremental category. Experimental results have demonstrated that the proposed method achieves state-of-the-art results on few-shot incremental learning tasks.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Yifan ZHAO"
                    },
                    {
                        "authorId": "2185270261",
                        "name": "LI Jia"
                    },
                    {
                        "authorId": "40161651",
                        "name": "Yonghong Tian"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8704b1b7e76019b7955c5af62e25266861a5b894",
                "externalIds": {
                    "DBLP": "journals/tgrs/ChenWYCZ22",
                    "DOI": "10.1109/TGRS.2022.3168054",
                    "CorpusId": 248249939
                },
                "corpusId": 248249939,
                "publicationVenue": {
                    "id": "70628d6a-97aa-4571-9701-bc0eb3989c32",
                    "name": "IEEE Transactions on Geoscience and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Geosci Remote Sens"
                    ],
                    "issn": "0196-2892",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/8704b1b7e76019b7955c5af62e25266861a5b894",
                "title": "Data augmentation in prototypical networks for forest tree species classification using airborne hyperspectral images",
                "abstract": "Accurate and fine multiple tree species supervised classification based on few-shot learning has attracted close attention from researchers since the sample collection is often hindered in forests. Prototypical networks (P-Net), as a simple but efficient few-shot learning method, has significant advantages in forest tree species classification. Nevertheless, the overfitting phenomenon caused by the lack of training samples is still prevalent in few-shot classifiers, which brings challenges to training accurate classification models. In this study, we proposed a novel Proto-MaxUp framework to minimize the issue of overfitting from the perspective of data augmentation and a feature extraction backbone for tree species classification. Taking Gaofeng Forest Farm in Nanning City, Guangxi Province as the study area, 9 tree species, cutting-site and road were classified. First, by analyzing the effects of a series of popular data augmentation methods and their combinations in different parts of the P-Net, several effective data augmentation pools were established. Then, the pools aforementioned were combined with Proto-MaxUp to obtain the best classification performance. In order to verify the robustness and validity of the proposed strategy, we applied Proto-MaxUp to the other four popular public hyperspectral datasets, and achieved excellent results. Finally, this efficient data augmentation method was used in different feature extraction backbones. The results show that the classification accuracy was greatly improved with the optimal backbone (OA and Kappa are 98.08%, 0.9789, respectively), and the difference between training accuracy and test accuracy is less than 2%. It is concluded that the accurate and fine classification for multiple tree species can be realized by the Proto-MaxUp data augmentation strategy and backbone proposed in this paper.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2048307639",
                        "name": "Long Chen"
                    },
                    {
                        "authorId": "2162916225",
                        "name": "Yuxin Wei"
                    },
                    {
                        "authorId": "2162878350",
                        "name": "Zongqi Yao"
                    },
                    {
                        "authorId": "3270319",
                        "name": "E. Chen"
                    },
                    {
                        "authorId": "2118045466",
                        "name": "Xiaoling Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Existing meta-learning benchmarks such as MiniImagenet (Ravi & Larochelle, 2016) or CIFAR-FS (Bertinetto et al., 2018) are unsuitable, as they are built for the traditional few-shot learning setting, in which the task Ti is not associated with task descriptors but is meant to be inferred through\u2026",
                "Existing meta-learning benchmarks such as MiniImagenet (Ravi & Larochelle, 2016) or CIFAR-FS (Bertinetto et al., 2018) are unsuitable, as they are built for the traditional few-shot learning setting, in which the task Ti is not associated with task descriptors but is meant to be inferred through exposure to the support set Dsi.",
                "Existing meta-learning benchmarks such as MiniImagenet (Ravi & Larochelle, 2016) or CIFAR-FS (Bertinetto et al., 2018) are unsuitable, as they are built for the traditional few-shot learning setting, in which the task Ti is not associated with task descriptors but is meant to be inferred through exposure to the support set Ds i."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b285df3cdae1eee198a86fe3b02b1e10c78df59e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2210-08942",
                    "DOI": "10.48550/arXiv.2210.08942",
                    "CorpusId": 252917912
                },
                "corpusId": 252917912,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/b285df3cdae1eee198a86fe3b02b1e10c78df59e",
                "title": "Meta-Learning via Classifier(-free) Guidance",
                "abstract": "State-of-the-art meta-learning techniques do not optimize for zero-shot adaptation to unseen tasks, a setting in which humans excel. On the contrary, meta-learning algorithms learn hyperparameters and weight initializations that explicitly optimize for few-shot learning performance. In this work, we take inspiration from recent advances in generative modeling and language-conditioned image synthesis to propose meta-learning techniques that use natural language guidance to achieve higher zero-shot performance compared to the state-of-the-art. We do so by recasting the meta-learning problem as a multi-modal generative modeling problem: given a task, we consider its adapted neural network weights and its natural language description as equivalent multi-modal task representations. We \ufb01rst train an unconditional generative hypernetwork model to produce neural network weights; then we train a second \u201cguidance\u201d model that, given a natural language task description, traverses the hypernetwork latent space to \ufb01nd high-performance task-adapted weights in a zero-shot manner. We explore two alternative approaches for latent space guidance: \u201cHyperCLIP\u201d-based classi\ufb01er guidance and a conditional Hypernetwork Latent Diffusion Model (\u201cHyperLDM\u201d), which we show to bene\ufb01t",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2129786387",
                        "name": "Elvis Nava"
                    },
                    {
                        "authorId": "51194506",
                        "name": "Seijin Kobayashi"
                    },
                    {
                        "authorId": "2023392128",
                        "name": "Yifei Yin"
                    },
                    {
                        "authorId": "50191333",
                        "name": "Robert K. Katzschmann"
                    },
                    {
                        "authorId": "48117063",
                        "name": "B. Grewe"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The optimizedbased approaches [24,4,49,27,48,2,28,79] meta-learn the learning procedures to rapidly update models online with few examples."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "58cef5edb36ecf2b1dfe9193641da04c4ad1a64f",
                "externalIds": {
                    "DBLP": "conf/eccv/FanTT22a",
                    "DOI": "10.1007/978-3-031-19800-7_42",
                    "CorpusId": 253518571
                },
                "corpusId": 253518571,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/58cef5edb36ecf2b1dfe9193641da04c4ad1a64f",
                "title": "Few-Shot Object Detection with Model Calibration",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2105557652",
                        "name": "Qi Fan"
                    },
                    {
                        "authorId": "2088295",
                        "name": "Chi-Keung Tang"
                    },
                    {
                        "authorId": "5068280",
                        "name": "Yu-Wing Tai"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", CIFAR-FS [3], miniImageNet [31] and tieredImageNet [26] datasets.",
                "CIFAR-FS [3] is built upon CIFAR-100 dataset [13], which is divided into 64, 16 and 20 categories for training, validation and testing, respectively.",
                ", miniImageNet [31], tieredImageNet [26] and CIFAR-FS [3]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "65dc4a0deb1d644744b14a06e15cc05088348f51",
                "externalIds": {
                    "CorpusId": 253549636
                },
                "corpusId": 253549636,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/65dc4a0deb1d644744b14a06e15cc05088348f51",
                "title": "A Why Using ViT for Few-Shot Learning",
                "abstract": "The content of Appendix is summarized as follows: 0) in Sec. A, we discuss the justification of using ViT in few-shot learning scenarios; 1) in Sec. B, we list the network architectures we used in the experiment; 2) in Sec. C, we state implementation and training details to ensure that our SUN can be reproduced; 3) in Sec. D and Sec. E, we introduce the detail of SUN with FEAT (SUN-F) and DeepEMD (SUN-D), then demonstrating its performance; 4) in Sec. F, we conduct more ablation study to analyze other components of SUN; 5) and in Sec. G, we conduct t-SNE visualization to qualitatively evaluate ViT with SUN, thus demonstrating the effectiveness of SUN.",
                "year": 2022,
                "authors": []
            }
        },
        {
            "contexts": [
                "Considering that using the prototype-based nearest-neighbor classifier seems unfair for the comparison between the prototypical loss and contrastive losses, we provide the results with ridge regression classifier [6] in Fig."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "911df0be6c299452c4cf8f871849e6d1501b9422",
                "externalIds": {
                    "DBLP": "conf/eccv/WangD22",
                    "DOI": "10.1007/978-3-031-19800-7_39",
                    "CorpusId": 253523842
                },
                "corpusId": 253523842,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/911df0be6c299452c4cf8f871849e6d1501b9422",
                "title": "Contrastive Prototypical Network with Wasserstein Confidence Penalty",
                "abstract": null,
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2109293550",
                        "name": "Haoqing Wang"
                    },
                    {
                        "authorId": "49152600",
                        "name": "Zhiwei Deng"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The bi-level formulation Problem (4) is closely related to metric-based meta-learning (Snell et al., 2017; Bertinetto et al., 2019), where a shared representation f\u03b8\u0302 is learned across all tasks."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "69d76d8a89ab1ad8a988f320dc424ee6f9e67288",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2211-14666",
                    "DOI": "10.48550/arXiv.2211.14666",
                    "CorpusId": 254044391
                },
                "corpusId": 254044391,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/69d76d8a89ab1ad8a988f320dc424ee6f9e67288",
                "title": "Synergies Between Disentanglement and Sparsity: a Multi-Task Learning Perspective",
                "abstract": "Although disentangled representations are often said to be beneficial for downstream tasks, current empirical and theoretical understanding is limited. In this work, we provide evidence that disentangled representations coupled with sparse base-predictors improve generalization. In the context of multi-task learning, we prove a new identifiability result that provides conditions under which maximally sparse base-predictors yield disentangled representations. Motivated by this theoretical result, we propose a practical approach to learn disentangled representations based on a sparsity-promoting bi-level optimization problem. Finally, we explore a meta-learning version of this algorithm based on group Lasso multiclass SVM base-predictors, for which we derive a tractable dual formulation. It obtains competitive results on standard few-shot classification benchmarks, while each task is using only a fraction of the learned representations.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "134730235",
                        "name": "S\u00e9bastien Lachapelle"
                    },
                    {
                        "authorId": "7636193",
                        "name": "T. Deleu"
                    },
                    {
                        "authorId": "133841722",
                        "name": "Divyat Mahajan"
                    },
                    {
                        "authorId": "2065139188",
                        "name": "Ioannis Mitliagkas"
                    },
                    {
                        "authorId": "1865800402",
                        "name": "Y. Bengio"
                    },
                    {
                        "authorId": "1388317459",
                        "name": "S. Lacoste-Julien"
                    },
                    {
                        "authorId": "14205549",
                        "name": "Quentin Bertrand"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To accelerate the meta-training, literature [29] and [30] propose two approaches to accelerate meta-training via closed-form solvers in the inner step progress."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "f507218ddc13e03d549c50bd50c026066505f80f",
                "externalIds": {
                    "DBLP": "journals/tsp/ZhangHHH22",
                    "DOI": "10.1109/TSP.2022.3222734",
                    "CorpusId": 253621838
                },
                "corpusId": 253621838,
                "publicationVenue": {
                    "id": "1f6f3f05-6a23-42f0-8d31-98ab8089c1f2",
                    "name": "IEEE Transactions on Signal Processing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Trans Signal Process"
                    ],
                    "issn": "1053-587X",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=78",
                    "alternate_urls": [
                        "http://www.signalprocessingsociety.org/publications/periodicals/tsp/",
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=78"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/f507218ddc13e03d549c50bd50c026066505f80f",
                "title": "Distributed Reptile Algorithm for Meta-Learning Over Multi-Agent Systems",
                "abstract": "Learning a good initialization model from distributed data sources over multi-agent systems is highly promising, in which the tasks or data are distributed stored and not accessible to all agents. This paper focuses on the distributed meta-learning problem and proposes a distributed Reptile meta-learning algorithm. In the proposed algorithm, each agent approximates the global model through a bi-level optimization scheme, where the inner step employs a stochastic gradient descent on a specific task, and the outer step utilizes information from neighbors and a gradient-like updating. The suggested algorithm avoids calculating the Hessian-vector products during training, reducing the computational complexity and affording memory miniaturization. We further analyze the convergence properties of the proposed algorithm under the convexity assumption. Finally, we demonstrate the effectiveness of the proposed algorithm on regression and classification tasks. The results show that our algorithm approximates a centralized solution and outperforms the non-cooperative algorithm.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2108292298",
                        "name": "Xianyang Zhang"
                    },
                    {
                        "authorId": "2118956508",
                        "name": "Chen Hu"
                    },
                    {
                        "authorId": "2082463508",
                        "name": "Bing He"
                    },
                    {
                        "authorId": "2113961824",
                        "name": "Z. Han"
                    }
                ]
            }
        },
        {
            "contexts": [
                "This class of problems has attracted great attention due to their applications in hyper-parameter optimization [15, 46], meta-learning [4, 42], and reinforcement learning [23, 28], to name a few."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1695282ff3fa425d3ec7d48c8737ecd0694bd23e",
                "externalIds": {
                    "CorpusId": 259504344
                },
                "corpusId": 259504344,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1695282ff3fa425d3ec7d48c8737ecd0694bd23e",
                "title": "Conditional gradient-based method for bilevel optimization with convex lower-level problem",
                "abstract": "In this paper, we study simple bilevel optimization problems, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are not satisfactory as they are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue, in this paper, we introduce a conditional gradient-based (CG-based) method to solve the considered problem. The main idea is to locally approximate the solution set of the lower-level problem via a cutting plane, and then run a CG-type update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires O (max { 1 /\u03f5 f , 1 /\u03f5 g } ) iterations to find a solution that is \u03f5 f -optimal for the upper-level objective and \u03f5 g -optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires O (max { 1 /\u03f5 2 f , 1 / ( \u03f5 f \u03f5 g ) } ) iterations to find an ( \u03f5 f , \u03f5 g ) -stationary solution. To the best of our knowledge, our method achieves the best-known iteration complexity for the considered bilevel problem.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2051263313",
                        "name": "Ruichen Jiang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5975efa7ebd7aacc502a4b38d79e030ff6305b5d",
                "externalIds": {
                    "DBLP": "phd/hal/Iakovleva22",
                    "CorpusId": 259855901
                },
                "corpusId": 259855901,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/5975efa7ebd7aacc502a4b38d79e030ff6305b5d",
                "title": "Transferring feature representations across tasks and domains. (Transfert de repr\u00e9sentations de caract\u00e9ristiques entre les t\u00e2ches et les domaines)",
                "abstract": "Year after year advances in deep learning allow to solve a rapidly increasing range of challenging tasks, as well as to set new, even more ambitious goals. Such a success, however, comes at a price of increasing requirements for all aspects of learning: large-scale models, which tend to perform best, require large quantities of data, memory, computational resources and time to be properly trained. This cannot always be achieved in practice, especially on smaller datasets, which promotes exploration of the ways to transfer knowledge, i.e. re-purposing existing state-of-the-art models to solving new tasks. This problem of transferring knowledge between tasks comes with its own challenges caused by different factors, such as the type of knowledge which needs to be transferred, or availability of data. In this thesis we focus on two setups from this category: few-shot learning and multi-domain learning. Both problems share the motivation to learn a model that would be able to generalise to solving the same type of task, e.g. image classification, on a number of different domains. Our first contribution explores probabilistic modeling for few-shot classification, where the model aims to solve a wide range of classification tasks, each accompanied with a handful of labeled examples. Limited supervision leads to high uncertainty about the predictions, which can be naturally tackled by probabilistic framework. We treat the task-specific classifier as a latent variable, and propose a novel amortised variational inference scheme which uses a single network to predict parameters of the distribution both for the prior and for the approximated posterior of the latent variable in the considered graphical model. The prior is conditioned on the support set of the task, while the approximated posterior is conditioned on the union of the support and query sets. Minimisation of the distance between these two distributions provides additional guidance from the support set during training, allowing us to exploit the disparity between the two sets of data. We evaluate our model on several few-shot classification benchmarks, and show that it can achieve competitive results on all of them. We also demonstrate the benefits of modeling uncertainty by showing that a sampled ensemble of classifiers slightly improves the performance compared to the inferred classifier mean. This result that cannot be achieved by models relying on Monte Carlo approximations, which, according to our experiments, tend to underestimate the true variance.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "2082891969",
                        "name": "E. Iakovleva"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "fd29800aea5666fdd275f8838f8c3baec7a4f6f3",
                "externalIds": {
                    "CorpusId": 259934436
                },
                "corpusId": 259934436,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/fd29800aea5666fdd275f8838f8c3baec7a4f6f3",
                "title": "HyperShot: Few-Shot Learning by Kernel HyperNetworks \u2013 supplementary material",
                "abstract": "This section provides additional results in the 5-way (1shot and 5-shot) classification tasks for models using larger backbones, namely ResNet-10 and ResNet-12 [11], as well as and expanded version of Table 1 from the main text, containing more baselines . We provide the results for ResNet10 on the CUB and mini-ImageNet datasets in Table 1, for ResNet-12 on mini-ImageNet dataset in Table 2 and for Conv4 on the CUB and mini-ImageNet datasets in Table 3. It should be noted that the results for ResNet-10 on miniImageNet for all methods were obtained by us using a unified codebase [3, 27]. On the other hand, for benchmarks of ResNet-10 on CUB and ResNet-12 on mini-ImageNet we report the accuracies of methods other than HyperShot as reported in [27] and [45], respectively.",
                "year": 2022,
                "authors": [
                    {
                        "authorId": "46220915",
                        "name": "Marcin Sendera"
                    },
                    {
                        "authorId": "2220053601",
                        "name": "Marcin Przewiezlikowski"
                    },
                    {
                        "authorId": "2223581690",
                        "name": "Konrad Karanowski"
                    },
                    {
                        "authorId": "3027512",
                        "name": "Maciej Zi\u0229ba"
                    },
                    {
                        "authorId": "145541197",
                        "name": "J. Tabor"
                    },
                    {
                        "authorId": "1790922",
                        "name": "P. Spurek"
                    },
                    {
                        "authorId": "2223582230",
                        "name": "Tooploox"
                    },
                    {
                        "authorId": "2223579610",
                        "name": "T\u0119czowa"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In practice, 1) we never specify exactly what and how big the underlying set of classes that we care about is, and 2) many of the recent meta-learning methods (svm vs pn on CIFAR-FS Table 2 in Lee et al. [18], gnn vs r2-d2 on miniImageNet Table 1 in Bertinetto et al. [3], and ironically fix-ml) sometimes only improve over the prior works by < 1%.",
                "(ii) CIFAR-FS-Mod (cifar-M) and FC-100-Mod (FC-M): As we don\u2019t have additional samples for the base classes, we randomly partition each base class\u2019s 600 examples into a 500, 100 split where the meta-training tasks are constructed only from the 500 examples and the remaining 100 examples are reserved to generate fresh tasks from \u03c4(CB).",
                "2) Datasets: We consider three of the most widely-used few-shot learning benchmarks: (i) miniImageNet (mini) [31], which consists of 100 ImageNet [25] classes of 84 \u00d7 84 images, randomly split into 64 base, 16 validation, and 20 novel classes; (ii) CIFAR-FS (cifar) [3] with an identically sized random base-val-novel split of the CIFAR-100 [17] dataset of 32\u00d7 32 images; (iii) FC-100 (FC) [20], another split of the CIFAR-100 dataset, where the split is according to 20 super classes (each having 5 classes).",
                "[3] correctly claimed that methods like rr and svm outperform pn on \u03c4(CN ) for these benchmarks, but if we consider the BaseGen performance, pn consistently performs the best.",
                ", miniImageNet [31] and CIFAR-FS [3]) are particularly popular for evaluating meta-learning methods on this objective.",
                "Always using fix-ml could potentially cause meta-test performance loss if the meta-test task distribution is not that different from \u03c4(CB), e.g., the continual learning task distribution in CIFAR-FS-Mod when \u03bb = 20/(64 + 20) \u2248 0.238 in Figure 1.",
                "However, for many widely used FSL benchmarks (miniImageNet, CIFAR-FS, FC-100), only 20 novel classes are used for meta-test evaluation.",
                "To fully evaluate the performance differences, we compare fix-ml and ml along two major axes: 1) Metalearning methods: We explore using fix-ml\u2019s modified objective with three state-of-the-art meta-learning methods: protoypical-networks (pn) [28], MetaOptNet-SVM (svm) [18], and MetaOptNet-Ridge Regression (rr) [3, 18].",
                "Moreover, many works [3, 18, 22, 28] that propose new meta-learning methods do not explicitly state whether their method is intended to perform well in-distribution or out-of-distribution, yet only evaluate empirically on the out-of-distribution FSL benchmarks, leading to ambiguous and possibly incorrect claims that their methods generally work well in both settings.",
                "[3], and ironically fix-ml) sometimes only improve over the prior works by < 1%.",
                "Few-shot classification benchmarks (e.g., miniImageNet [31] and CIFAR-FS [3]) are particularly popular for evaluating meta-learning methods on this objective."
            ],
            "intents": [],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "6ddfbaa44ee6cc14a60114ea5ee2d50a9167989d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2102-11503",
                    "CorpusId": 232013408
                },
                "corpusId": 232013408,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/6ddfbaa44ee6cc14a60114ea5ee2d50a9167989d",
                "title": "Lessons from Chasing Few-Shot Learning Benchmarks: Rethinking the Evaluation of Meta-Learning Methods",
                "abstract": "In this work we introduce a simple baseline for meta-learning. Our unconventional method, fix-ml, reduces task diversity by keeping support sets fixed across tasks, and consistently improves the performance of meta-learning methods on popular few-shot learning benchmarks. However, in exploring the reason for this counter-intuitive phenomenon, we unearth a series of questions and concerns about meta-learning evaluation practices. We explore two possible goals of meta-learning: to develop methods that generalize (i) to the same task distribution that generates the training set (in-distribution), or (ii) to new, unseen task distributions (out-of-distribution). Through careful analyses, we show that for each of these two goals, current few-shot learning benchmarks have potential pitfalls in 1) performing model selection and hyperparameter tuning for a given meta-learning method and 2) comparing the performance of different meta-learning methods. Our results highlight that in order to reason about progress in this space, it is necessary to provide a clearer description of the goals of meta-learning, and to develop more appropriate corresponding evaluation strategies.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "80366270",
                        "name": "Amrith Rajagopal Setlur"
                    },
                    {
                        "authorId": "33282601",
                        "name": "Oscar Li"
                    },
                    {
                        "authorId": "145260024",
                        "name": "Virginia Smith"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Table 1 and 2 summarize the results of the few-shot classification tasks on CIFAR-FS, FC100, and mini-ImageNet, respectively.",
                "The CIFAR-FS dataset (Bertinetto et al., 2018) is a few-shot classification benchmark containing 100 classes from CIFAR-100 (Krizhevsky et al., 2009).",
                "We broadly divide the existing few-shot learning approaches into three categories: (1) Gradient-based methods optimize feature embedding with gradient descent during meta-test stage (Finn et al., 2017; Bertinetto et al., 2018; Lee et al., 2019).",
                "Our ResNet-12 model beats (Lee et al., 2019) 1-shot result by 2.7% on FC100, 3.4% on CIFAR-FS, and 1.72% on mini-ImageNet.",
                "1 DATASETS We adopt three standard benchmark datasets that are widely used in few-shot learning, CIFAR-FS dataset (Bertinetto et al., 2018), FC100 dataset (Oreshkin et al.",
                "We demonstrate the effectiveness of our approach on standard few-shot benchmarks, including FC100 (Oreshkin et al., 2018), CIFAR-FS (Bertinetto et al., 2018) and mini-ImageNet (Vinyals et al., 2016) by showing a significant improvement over the existing methods.",
                ", 2018), CIFAR-FS (Bertinetto et al., 2018) and mini-ImageNet (Vinyals et al.",
                "We adopt three standard benchmark datasets that are widely used in few-shot learning, CIFAR-FS dataset (Bertinetto et al., 2018), FC100 dataset (Oreshkin et al., 2018), and mini-ImageNet dataset (Vinyals et al., 2016)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "ab6413f67becd89dd7676c5cf5e260e13b42ddfd",
                "externalIds": {
                    "DBLP": "conf/iclr/XuXWT21",
                    "CorpusId": 232361248
                },
                "corpusId": 232361248,
                "publicationVenue": {
                    "id": "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                    "name": "International Conference on Learning Representations",
                    "type": "conference",
                    "alternate_names": [
                        "Int Conf Learn Represent",
                        "ICLR"
                    ],
                    "url": "https://iclr.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/ab6413f67becd89dd7676c5cf5e260e13b42ddfd",
                "title": "Attentional Constellation Nets for Few-Shot Learning",
                "abstract": "The success of deep convolutional neural networks builds on top of the learning of effective convolution operations, capturing a hierarchy of structured features via filtering, activation, and pooling. However, the explicit structured features, e.g. object parts, are not expressive in the existing CNN frameworks. In this paper, we tackle the few-shot learning problem and make an effort to enhance structured features by expanding CNNs with a constellation model, which performs cell feature clustering and encoding with a dense part representation; the relationships among the cell features are further modeled by an attention mechanism. With the additional constellation branch to increase the awareness of object parts, our method is able to attain the advantages of the CNNs while making the overall internal representations more robust in the few-shot learning setting. Our approach attains a significant improvement over the existing methods in few-shot learning on the CIFAR-FS, FC100, and mini-ImageNet benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2110546250",
                        "name": "Weijian Xu"
                    },
                    {
                        "authorId": "2125063007",
                        "name": "Yifan Xu"
                    },
                    {
                        "authorId": "2109629683",
                        "name": "Huaijin Wang"
                    },
                    {
                        "authorId": "144035504",
                        "name": "Z. Tu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFARFS is a recently proposed few-shot classification benchmark.",
                "In Table 5 of Appendix A, we also test MAML-L and TSA-MAML on CIFARFS [Bertinetto et al., 2019] and observe that TSA-MAML makes about at least 1.",
                "1 3 5 7 9 11 13 15 Number m of Initializations\n36\n38\n40\n42\n44\n46\nCl as\nsi fic\nat io\nn Ac\ncu ra\ncy (\n% )\n38.48\n40.52 39.77 40.44 40.55 40.19 39.75 39.12\n39.97\n42.91 42.18 42.59 42.67 42.57 41.91\n41.29\n1-shot 10-way on CIFARFS Non-transduction Transduction\nFigure 4: Effects of m to TSA-MAML.",
                "Specifically, on CIFARFS, TSAMAML respectively brings about 1.09%, 2.46%, 1.29% and 2.81% improvements on the four test cases (from left to right) under non-transduction setting, and under transduction setting it also makes about 0.75%, 0.77%, 2.21% and 2.48% improvements for the four cases.",
                "In TSA-MAML, the training iteration number S is 40, 000 for CIFARFS and 80, 000 for tieredImageNet and miniImageNet, and the cluster number m is five for all datasets.",
                "We evaluate TSA-MAML on three benchmarks, CIFARFS [Bertinetto et al., 2019], tieredImageNet [Ren et al., 2018] and miniImageNet [Ravi and Larochelle, 2017] .",
                "%) of the compared approaches on the CIFARFS dataset.",
                "Besides, compared with MAML, TSA-MAML respectively makes about 1.73% and 1.44% average improvements on CIFARFS and tieredImageNet.",
                "In Table 5 of Appendix A, we also test MAML-L and TSA-MAML on CIFARFS [Bertinetto et al., 2019] and observe that TSA-MAML makes about at least 1.5% average improvement on the four test settings (n-way k-shot, n = 5 or 10 and k = 1 or 5) over both MAML and MAML-L.",
                "We evaluate TSA-MAML on three benchmarks, CIFARFS [Bertinetto et al., 2019], tieredImageNet [Ren et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "79dfbde81b4c4622ad44c4223f5e27af99847fab",
                "externalIds": {
                    "DBLP": "conf/uai/ZhouZYFXH21",
                    "CorpusId": 235432562
                },
                "corpusId": 235432562,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/79dfbde81b4c4622ad44c4223f5e27af99847fab",
                "title": "Task similarity aware meta learning: theory-inspired improvement on MAML",
                "abstract": "Few-shot learning ability is heavily desired for machine intelligence. By meta-learning a model initialization from training tasks with fast adaptation ability to new tasks, model-agnostic meta-learning (MAML) has achieved remarkable success in a number of few-shot learning applications. However, theoretical understandings on the learning ability of MAML remain absent yet, hindering developing new and more advanced meta learning methods in a principle way. In this work, we solve this problem by theoretically justifying the fast adaptation capability of MAML when applied to new tasks. Speci\ufb01cally, we prove that the learnt meta-initialization can quickly adapt to new tasks with only a few steps of gradient descent. This result, for the \ufb01rst time, explicitly reveals the bene\ufb01ts of the unique designs in MAML. Then we propose a theory-inspired task similarity aware MAML which clusters tasks into multiple groups according to the estimated optimal model parameters and learns group-speci\ufb01c initializations. The proposed method improves upon MAML by speeding up the adaptation and giving stronger few-shot learning ability. Experimental results on the few-shot classi\ufb01cation tasks testify its advantages.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109890021",
                        "name": "Pan Zhou"
                    },
                    {
                        "authorId": "50817744",
                        "name": "Yingtian Zou"
                    },
                    {
                        "authorId": "8515907",
                        "name": "Xiaotong Yuan"
                    },
                    {
                        "authorId": "1698982",
                        "name": "Jiashi Feng"
                    },
                    {
                        "authorId": "2228109",
                        "name": "Caiming Xiong"
                    },
                    {
                        "authorId": "1741126",
                        "name": "S. Hoi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Specifically, we sequentially meta-train VC-BML and baselines on: VGG-Flowers, miniImagenet, CIFAR-FS and Omniglot, and show the experimental results in Figure 1.",
                "In the setting of non-stationary task distribution, we sequentially meta-train VC-BML on four datasets: Omniglot, CIFAR-FS, miniImagenet and VGG-Flowers.",
                "We use the same split as [12]: 64 classes for meta-training, 16 classes for validation and 20 classes for meta-test.",
                "In the settings of nonstationary task distribution, we use an inner learning rate of 0.1, an outer learning rate of 0.001 on Omniglot and CIFAR-FS, and use an inner learning rate of 0.01, an outer learning rate of 0.0001 on miniImagenet and VGG-Flowers.",
                "For example, on CIFAR-FS, the accuracies of parametric methods (FTML, OSML, DPMM and OSAKA) decrease from 69.79%-71.41% to 52.29%-59.74% at the end of training, while the accuracies of Bayesian methods (BOMVI, VC-BML) barely change (from 69.12%-75.61% to 70.16%-75.20%).",
                "Note that on CIFAR-FS, miniImagenet and VGG-Flowers datasets, we follow the same preprocessing steps as Omniglot to generate a sequence of tasks.",
                "Similar results can also be found on CIFAR-FS and miniImagenet datasets.",
                "From Figure 3, we can observe that similar results can also be found on CIFAR-FS and miniImagenet datasets.",
                "In the settings of non-stationary task distribution, we use 5 inner gradient descent steps with an inner learning rate of 0.01, and use an outer learning rate of 0.001 on Omniglot, 0.0001 on CIFAR-FS, miniImagenet and VGG-Flowers.",
                "To learn OSAKA, we use 3 inner gradient descent steps with an inner learning rate of 0.1, and use an outer learning rate of 0.001 on Omniglot, CIFAR-FS, 0.0001 on miniImagenet, VGG-Flowers.",
                "CIFAR-FS [12]: CIFAR-FS is adapted from the CIFAR-100 dataset [13] for few-shot learning.",
                "It can be observed from Figure 3 that Bayesian methods, i.e., VC-BML and BOMVI, always obtain the best and the second best performance on unseen tasks, i.e., miniImagenet and VGG-Flowers at CIFAR-FS meta-training stage and VGG-Flowers at miniImagenet meta-training stage."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "730c210dadd27fd83c7b4e886efc842f09fcc627",
                "externalIds": {
                    "CorpusId": 245615949
                },
                "corpusId": 245615949,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/730c210dadd27fd83c7b4e886efc842f09fcc627",
                "title": "Appendix: Variational Continual Bayesian Meta-Learning",
                "abstract": "Qiang Zhang1,2,3\u2217\u2020, Jinyuan Fang4\u2020, Zaiqiao Meng, Shangsong Liang4,6\u2021 , Emine Yilmaz7\u2021 1 Hangzhou Innovation Center, Zhejiang University, China 2 College of Computer Science and Technology, Zhejiang University, China 3 AZFT Knowledge Engine Lab, China; 4 Sun Yat-sen University, China 5 University of Glasgow, United Kingdom 6 Mohamed bin Zayed University of Artificial Intelligence, United Arab Emirates 7 University College London, United Kingdom {qiang.zhang.cs@zju.edu.cn; fangjy6@gmail.com; zaiqiao.meng@gmail.com} {liangshangsong@gmail.com; emine.yilmaz@ucl.ac.uk}",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "150271064",
                        "name": "Qiang Zhang"
                    },
                    {
                        "authorId": "1384241384",
                        "name": "Jinyuan Fang"
                    },
                    {
                        "authorId": "3451645",
                        "name": "Zaiqiao Meng"
                    },
                    {
                        "authorId": "3279808",
                        "name": "Shangsong Liang"
                    },
                    {
                        "authorId": "2149472702",
                        "name": "Emine Yilmaz"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [1] is an anagolous version of miniImagenet, but for CIFAR-100.",
                "For tieredImageNet only we increased the batch size to 1024, and train on 64 classes (like miniImageNet and CIFAR-FS) and 16 images per class within a batch, as we found it being beneficial.",
                "For miniImageNet and CIFAR-FS we decrease the learning rate by a factor of 10 after 70% of epochs have been trained, and train for a total of 120 epochs.",
                "All our miniImageNet and CIFAR-FS experiments took about 2 hours to finish training, and the tieredImageNet experiments took 8 hours per model.",
                "Results on miniImageNet and CIFAR-FS are shown in Table 4.",
                "For CIFAR-FS and tieredImageNet, we found this did not help performance.",
                "On CIFAR-FS, we increase the number of training epochs from 120 to 240, which improved accuracy by about 0.5%."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "0b83679692c76cf41be2f908e0151125c65e3c62",
                "externalIds": {
                    "CorpusId": 247432602
                },
                "corpusId": 247432602,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/0b83679692c76cf41be2f908e0151125c65e3c62",
                "title": "SUPPLEMENTARY MATERIAL Episodic Learning in Nonparametric Few-shot Classification: A Case Study",
                "abstract": "In this section we demonstrate that the total number of training pairs that the NCA loss can exploit within a batch is always strictly superior or equal to the one exploited by the episodic batch strategy used by Prototypical Networks (PNs) and Matching Networks (MNs). To ensure we have a \u201cvalid\u201d episodic batch with a nonzero number of both positive and negative distance pairs, we assume that n,m \u2265 1, and w \u2265 2. Below, we show that the number of positives for the NCA, i.e. ( m+n 2 ) w, is always greater or equal than the one for PNs and MNs, which is mnw: ( m+ n 2 ) w = (m+ n)! 2!(m+ n\u2212 2)! w",
                "year": 2021,
                "authors": []
            }
        },
        {
            "contexts": [
                "The model is trained for 100 epochs, with each epoch consisting of 600 randomly sampled episodes for both 1-shot and 5-shot cases on MiniImageNet, CUB-200-2011, CIFAR-FS and FC100 datasets, and is evaluated by averaging metrics over 600 randomly generated episodes from Dn, with each episode having 15 randomly sampled query samples.",
                "Table 1 and Table 2 summarize the results of the few-shot classification tasks on MiniImageNet, CIFAR-FS, FC100, and CUB-200-2011, respectively.",
                ", 2011), CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al.",
                "We conduct a comparison of our method to state-of-the-art methods in terms of few-shot classification accuracy on four benchmarks, including MiniImageNet (Vinyals et al., 2016), CUB-200-2011 (Wah et al., 2011), CIFAR-FS (Bertinetto et al., 2018) and FC100 (Oreshkin et al., 2018).",
                "To further validate the effectiveness of our method, we conduct a series of ablation studies on miniImageNet and CIFAR-FS datasets.",
                "As shown in Figure 3(b), we can observe that, the optimal \u03bb for MiniImageNet in 1- shot and 5-shot cases are 0.2 and 0.3, respectively, while for the CIFAR-FS dataset, the optimal \u03bb reaches at 0.1 for both 1-shot and 5-shot cases.",
                "We sample one episode in the test split of miniImageNet and CIFAR-FS datasets under the 5-way 1-shot and 5-way 5-shot settings."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "70535e6e6814d091689ee6fc17faaf004e35a73e",
                "externalIds": {
                    "CorpusId": 248491651
                },
                "corpusId": 248491651,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/70535e6e6814d091689ee6fc17faaf004e35a73e",
                "title": "-S C LASSIFICATION WITH T ASK -A DAPTIVE",
                "abstract": "stage, we freeze the parameters of the feature extractor in the meta-training and meta-testing stages. Therefore, only the semantic feature learner and the visual feature learner should be optimized, which is less time consuming. Our model trains the global classi\ufb01cation loss and the task-adaptive semantic feature dissimilarity loss separately, which can avoid collapsing different modalities into a common feature space, so as to preserve the structural heterogeneity of different modalities. Then, we propose two features combination approaches: feature concatenation and feature fusion, to further improve the performance. Experiments show that our method outperforms the state-of-the-arts on four benchmarks. In the future work, we expect to explore semantic-guided attention mechanism to pay more attention to the targets in the images, so as to better capture class-speci\ufb01c information from the images, which can further alleviate the in\ufb02uence of noise and irrelevant information.",
                "year": 2021,
                "authors": []
            }
        },
        {
            "contexts": [
                "CUB-2002011 is initially designed for fine-grained classification and CIFAR-FS is a subset of CIFAR-100 for few-shot classification.",
                "Meanwhile, partial experimental results on the CIFAR-FS dataset dropped slightly, the reason of which might lie in the categories in the CIFAR-FS dataset are highly distinguishable.",
                "Experimen-\ntal results demonstrate that it improves the performance of recently proposed GNN-based methods on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB-200-2011, and CIFAR-FS.",
                "To evaluate our module, we select two GNN-based few-shot models: EGNN and DPGN, and four standard few-shot learning benchmarks: mini-ImageNet [20], tiered-ImageNet [28], CUB-200-2011 [29] and CIFAR-FS [30].",
                "\u2022 The comprehensive experimental results on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB200-2011, and CIFAR-FS show that our proposed module is effective for GNN-based few-shot model."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "43b17c4b4fbc258c17d2f154f2122a90a0a01797",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-09840",
                    "CorpusId": 231698895
                },
                "corpusId": 231698895,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/43b17c4b4fbc258c17d2f154f2122a90a0a01797",
                "title": "ATRM: Attention-based Task-level Relation Module for GNN-based Few-shot Learning",
                "abstract": "Recently, graph neural networks (GNNs) have shown powerful ability to handle few-shot classi\ufb01cation problem, which aims at classifying unseen samples when trained with limited labeled samples per class. GNN-based few-shot learning ar-chitectures mostly replace traditional metric with a learnable GNN. In the GNN, the nodes are set as the samples\u2019 embedding, and the relationship between two connected nodes can be obtained by a network, the input of which is the difference of their embedding features. We consider this method of measuring relation of samples only models the sample-to-sample relation, while neglects the speci\ufb01city of different tasks. That is, this method of measuring relation does not take the task-level information into account. To this end, we propose a new relation measure method, namely the attention-based task-level relation module (ATRM) , to explicitly model the task-level relation of one sample to all the others. The proposed module captures the relation representations between nodes by considering the sample-to-task instead of sample-to-sample embedding features. We conducted extensive experiments on four benchmark datasets: mini-ImageNet, tiered-ImageNet, CUB- 200 - 2011 , and CIFAR-FS. Experimental results demonstrate that the proposed module is effective for GNN-based few-shot learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2124916479",
                        "name": "Yurong Guo"
                    },
                    {
                        "authorId": "1755773",
                        "name": "Zhanyu Ma"
                    },
                    {
                        "authorId": "145074587",
                        "name": "Xiaoxu Li"
                    },
                    {
                        "authorId": "2115460273",
                        "name": "Yuan Dong"
                    }
                ]
            }
        },
        {
            "contexts": [
                "5% improvement for miniImageNet [5], CIFAR-FS [1], and FC100 [3] datasets respectively (section 4.",
                "To further investigate the effect of knowledge distillation we perform multiple stages of self knowledge distillation on CIFAR-FS [1] dataset.",
                "13% for miniImageNet [5], CIFAR-FS [1], and FC100 [3] datasets respectively (section 4.",
                "We conduct an ablation study to measure the effect of different values of the coefficient of inductive loss (without multi-head distillation) on the CIFAR-FS [1] validation set; the results of 5-way 1-shot FSL tasks are presented in fig.",
                "To analyse the effect of knowledge distillation temperature (for Kullback Leibler (KL) divergence losses) we conduct an ablation study on the validation set of CIFAR-FS [1] dataset."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "95b1b56c9a3fe68f8c6ea5374fbcca6569b7482c",
                "externalIds": {
                    "CorpusId": 233227875
                },
                "corpusId": 233227875,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/95b1b56c9a3fe68f8c6ea5374fbcca6569b7482c",
                "title": "Supplementary Materials: Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning",
                "abstract": "001 002 003 004 005 006 007 008 009 010 011 012 013 014 015 016 017 018 019 020 021 022 023 024 025 026 027 028 029 030 031 032 033 034 035 036 037 038 039 040 041 042 043 044 045 046 047 048 049 050 051 052 053 054 055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071 072 073 074 075 076 077 078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 CVPR #10643 CVPR #10643 CVPR 2021 Submission #10643. CONFIDENTIAL REVIEW COPY. DO NOT DISTRIBUTE.",
                "year": 2021,
                "authors": []
            }
        },
        {
            "contexts": [
                "The CIFAR-FS dataset consists of 100 classes from CIFAR-100 randomly divided into groups of 64, 16 and 20 for training, validation, and testing datasets respectively.",
                "CIFAR-FS.",
                "The CIFAR-FS and FC100 datasets have a structure of coarse classes where distinct classes are\ngrouped together based on semantic similarities e.g., insects is a coarse class that might contain finer classes such as bee, butterfly.",
                "We conducted experiments on four datasets \u2013 CIFAR-FS [16], FC100 [25], miniImageNet [9] and tieredImageNet [21] (Tables 1, 2, 3, 4).",
                "R2D2 [16] and MetaOptNet [2] improved accuracy by using Ridge Regression and SVM as classifier correspondingly.",
                "We designed several experiments settings, according to the Section 3.3, to research the relative advantage of using the multi-task loss function (3) and SPSA-based optimization against original methods: MTM Backprop, where multi-task weights in the loss function are optimized jointly with the network parameters \u03b8; MTM Inner First-Order, where a separate gradient-based multi-task weights optimizer is used; MTM SPSA and MTM SPSA-Track where zero-order methods (5) and (6) are used as a multi-task weights optimizer respectively; MTM SPSA-Coarse (on CIFAR-FS and FC100) which used SPSA-based approach (5) but had a separate weight per coarse class as in (7).",
                "On CIFAR-FS we improve against original method up to 2.0%, with the largest improvement in 1-shot 2-way MAML MTM SPSA-Track."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "f6087842a018755181faf253c1a908186cccdc3b",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-13188",
                    "CorpusId": 239885901
                },
                "corpusId": 239885901,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/f6087842a018755181faf253c1a908186cccdc3b",
                "title": "Multi-Task Meta-Learning Modification with Stochastic Approximation",
                "abstract": "Meta-learning methods aim to build learning algorithms capable of quickly adapting to new tasks in low-data regime. One of the main benchmarks of such an algorithms is a few-shot learning problem. In this paper we investigate the modification of standard meta-learning pipeline that takes a multi-task approach during training. The proposed method simultaneously utilizes information from several meta-training tasks in a common loss function. The impact of each of these tasks in the loss function is controlled by the corresponding weight. Proper optimization of these weights can have a big influence on training of the entire model and might improve the quality on test time tasks. In this work we propose and investigate the use of methods from the family of simultaneous perturbation stochastic approximation (SPSA) approaches for meta-train tasks weights optimization. We have also compared the proposed algorithms with gradient-based methods and found that stochastic approximation demonstrates the largest quality boost in test time. Proposed multi-task modification can be applied to almost all methods that use meta-learning pipeline. In this paper we study applications of this modification on Prototypical Networks and Model-Agnostic Meta-Learning algorithms on CIFAR-FS, FC100, tieredImageNet and miniImageNet few-shot learning benchmarks. During these experiments, multi-task modification has demonstrated improvement over original methods. The proposed SPSATracking algorithm shows the largest accuracy boost that is competitive against the state-of-the-art meta-learning methods. Our code is available online1.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "27003403",
                        "name": "A. Boiarov"
                    },
                    {
                        "authorId": "2135103713",
                        "name": "Konstantin Khabarlak"
                    },
                    {
                        "authorId": "2135091095",
                        "name": "Igor Yastrebov"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Note that unlike other algorithms in the literature, we evaluate our frame-\n1https://github.com/eriklindernoren/PyTorch-GAN\nDataset CIFAR100 miniImagenet CUB200 TieredImagenet\n5way-5shot 2way-5shot 5way-5shot 2way-5shot 5way-5shot 2way-5shot 5way-5shot 2way-5shot\nPretrain 74.93% 95.61% 69.00% 95.54% 90.00% 89.27% 46.00% 66.70% Incremental 88.57% 96.77% 83.57% 95.56% 87.00% 86.98% 69.58% 78.68%\nTable 2: 5 shot Results for SemGIF using Resnet-50 backbone encoder\nDataset CIFAR100 miniImagenet CUB200 TieredImagenet\npretrain Accb Inc AccH Inc Accb Inc Accn pretrain Accb Inc AccH Inc Accb Inc Accn pretrain Accb Inc AccH Inc Accb Inc Accn pretrain Accb Inc AccH Inc Accb Inc Accn\n5-way 5-shot 66.52 79.95 87.27 73.76 63.63 75.49 86.09 67.22 84.41 86.56 91.09 82.46 47.23 69.89 83.16 60.27 2-way 5-shot 93.40 91.23 84.82 98.68 95.41 95.21 92.44 98.15 88.12 83.56 88.22 79.37 69.44 79.71 94.39 68.98 5-way 1-shot 44.22 57.21 75.50 46.06 40.22 56.75 71.89 46.87 43.01 57.35 67.31 49.96 33.04 55.63 67.25 47.43 2-way 1-shot 69.08 75.74 74.46 77.06 65.21 75.16 71.32 79.44 64.13 58.44 70.30 50.00 60.03 62.23 71.19 55.28 5-way 10-shot 72.65 87.61 94.64 81.54 69.82 83.39 92.09 76.20 91.56 87.45 85.00 90.03 51.85 68.47 94.20 53.78 2-way 10-shot 96.24 97.74 96.67 98.84 96.27 96.59 94.52 98.75 90.00 89.24 88.22 79.37 71.55 81.95 95.64 71.68\nTable 3: IFSL Results on multiple combinations of N-way K-shot across the four datasets\nwork across a wider variety of datasets.",
                "We consider a total of four standard datasets to evaluate the proposed SemGIF framework: CIFAR100 [3], miniImagenet [39], CUB200-2011 [40] and TieredImagenet [28].",
                "We also have employed batch-norm between the layers in the image branch, text branch, and the Visual-to-semantic mapping networks, while the embedding function also utilizes a dropout with p= 0.5 between its layers. fastText word\nDataset CIFAR100 miniImagenet CUB200 TieredImagenet*\nMethod 5way-1shot 5way-5shot 5way-1shot 5way-5shot 5way-1shot 5way-5shot 5way-1shot 5way-5shot\nProtoNet [34] B1 40.96% 62.50% 41.07% 55.15% 29.45% 46.00% 30.04% 41.38% CADA-VAE [32] B2 - - - - 54.15% 62.05% - - aCASTLE [44] B2 - - 43.63 % 56.33% - - 22.23% 33.54% LwoF [9] - - 52.37% 59.89% - - 52.40% 62.63% Imprint [25] - - 41.25% 43.92% 47.62% 61.59% 39.13% 53.60% Attractor [27] - - 53.62% 62.83% - - 56.11% 65.52% XtarNet [45] - - 55.28% 66.86% - - 61.37% 69.58%\nOurs without semantic 42.86% 55.17% 38.98% 49.89% 39.74% 63.29% 49.65% 62.83% Ours (full) 57.21% 79.95% 56.75% 75.49% 57.35% 86.56% 55.63% 69.89%\nTable 1: A comparative study with existing algorithms in the literature.",
                "Base Dataset CIFAR100 miniImagenet CUB200 TieredImagenet\nNovel Dataset 5way-1shot 5way-5shot 5way-1shot 5way-5shot 5way-1shot 5way-5shot 5way-1shot 5way-5shot\nCIFAR100 - - 60.73% 81.00% 57.91% 78.63% 54.87% 78.45% miniImagenet 55.89% 75.95% - - 51.41% 75.68% 50.69% 74.86% CUB200 56.32% 84.61% 57.19% 83.03% - - 50.38% 82.19% TieredImagenet 55.19% 69.07% 55.88% 67.75% 51.42% 69.49% - -\nTable 4: Heterogeneous evaluation by choosing Dbase and Dnovel from different domains\nHeterogeneous evaluation study: We perform a heterogeneous evaluation study using the standard datasets considered."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "f4283bf938aef0bf221d4c7e4bd6a66860c25b76",
                "externalIds": {
                    "DBLP": "conf/bmvc/BhatBC21",
                    "CorpusId": 249893036
                },
                "corpusId": 249893036,
                "publicationVenue": {
                    "id": "78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                    "name": "British Machine Vision Conference",
                    "type": "conference",
                    "alternate_names": [
                        "Br Mach Vis Conf",
                        "BMVC"
                    ],
                    "url": "http://www.bmva.org/bmvc/"
                },
                "url": "https://www.semanticscholar.org/paper/f4283bf938aef0bf221d4c7e4bd6a66860c25b76",
                "title": "SemGIF: A Semantics Guided Incremental Few-shot Learning Framework with Generative Replay",
                "abstract": "We address the problem of incremental few-shot learning (IFSL) by leveraging the notion of generative feature replay. Learning novel concepts while preserving old knowledge is a long-lasting challenge in machine learning. The main concern in IFSL is to combat the catastrophic forgetting of the base classes whose training data are not available during the incremental stage while ensuring good generalization for the few-shot classes. Existing techniques prefer to preserve some base class samples to tackle forgetting, which does not comply with the intention of incremental learning. To this end, we propose a novel framework called Semantics Guided IFSL (SemGIF), which trains a generative model to synthesize base class samples on demand during the incremental step. Considering the importance of modeling a discriminative feature space in IFSL for separating the base and the novel classes, we propose a feature augmentation strategy where the visual embeddings are supplemented with the semantic features obtained from a word-embedding space. Such a feature space is found to produce enriched class prototypes to be utilized during classi\ufb01cation. Experimental results on CIFAR-100, CUB, mini-ImageNet, and tiered-ImageNet in the homogeneous (within-dataset) and a novel heterogeneous (cross-dataset) setup showcase sharp improvements than the literature.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "122730967",
                        "name": "S. Bhat"
                    },
                    {
                        "authorId": "49124777",
                        "name": "Biplab Banerjee"
                    },
                    {
                        "authorId": "144527832",
                        "name": "S. Chaudhuri"
                    }
                ]
            }
        },
        {
            "contexts": [
                "On 5-way-1-shot, it slightly underperforms compared to a few methods ([27], [49]) on Mini-ImageNet and CIFAR-FS.",
                "We use 4 datasets to evaluate few-shot learning algorithms - MiniImageNet [51], Tiered-ImageNet [39], CIFAR-FS [1] & FC100 [35]:",
                "\u2022 CIFAR-FS : CIFAR-FS contains all 100 classes from CIFAR-100 [25] and the classes are randomly split into 64, 16 and 20 for training, validation and testing with each class contains 600 images.",
                "On the other hand, optimization based methods use a bi-level optimization to facilitate learning-to-learn and differ in the choice of inner/base learner - MAML [12] uses a linear predictor, MetaOptNet [27] uses SVM [8] & R2D2 [1] uses ridge regression.",
                "We use 4 datasets to evaluate few-shot learning algorithms - MiniImageNet [51], Tiered-ImageNet [39], CIFAR-FS [1] & FC100 [35]:\n\u2022 Mini-ImageNet : Mini-ImageNet contains 100 randomly chosen classes from ILSVRC-2012 [41] and these classes are randomly split into 64, 16 and 20 classes for train, validation and test with each class containing 600 images."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "49a654a9284c4f30092fdde13847cb6727faa80e",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-11058",
                    "CorpusId": 231719070
                },
                "corpusId": 231719070,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/49a654a9284c4f30092fdde13847cb6727faa80e",
                "title": "Revisiting Contrastive Learning for Few-Shot Classification",
                "abstract": "Instance discrimination based contrastive learning has emerged as a leading approach for self-supervised learning of visual representations. Yet, its generalization to novel tasks remains elusive when compared to representations learned with supervision, especially in the few-shot setting. We demonstrate how one can incorporate supervision in the instance discrimination based contrastive self-supervised learning framework to learn representations that generalize better to novel tasks. We call our approach CIDS ( C ontrastive I nstance D iscrimination with S upervision). CIDS performs favorably compared to existing algorithms on popular few-shot benchmarks like Mini-ImageNet or Tiered-ImageNet. We also propose a novel model selection algorithm that can be used in conjunction with a universal embedding trained using CIDS to outperform state-of-the-art algorithms on the challenging Meta-Dataset benchmark.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "134549850",
                        "name": "Orchid Majumder"
                    },
                    {
                        "authorId": "2529423",
                        "name": "Avinash Ravichandran"
                    },
                    {
                        "authorId": "35208858",
                        "name": "Subhransu Maji"
                    },
                    {
                        "authorId": "32235780",
                        "name": "M. Polito"
                    },
                    {
                        "authorId": "3243878",
                        "name": "Rahul Bhotika"
                    },
                    {
                        "authorId": "1715959",
                        "name": "Stefano Soatto"
                    }
                ]
            }
        },
        {
            "contexts": [
                ", 2017), ridge regression classifier (Bertinetto et al., 2019) and SVM classifier (Lee et al.",
                "The compared methods include ProtoNet, MetaOptNet-RR and MetaOptNet-SVM, whose task-specific learners are nearest-neighbor classifier (Snell et al., 2017), ridge regression classifier (Bertinetto et al., 2019) and SVM classifier (Lee et al., 2019), respectively.",
                "The CIFAR-FS dataset (Bertinetto et al., 2019) is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100.",
                "2 Experiments on CIFAR derivatives The CIFAR-FS dataset (Bertinetto et al., 2019) is a recently proposed few-shot image classification benchmark, consisting of all 100 classes from CIFAR-100."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "aea11444f97d618d895f0ca8a938528149efd7bd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2107-02378",
                    "CorpusId": 235743165
                },
                "corpusId": 235743165,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/aea11444f97d618d895f0ca8a938528149efd7bd",
                "title": "Learning an Explicit Hyperparameter Prediction Policy Conditioned on Tasks",
                "abstract": "Meta learning has attracted much attention recently in machine learning community. Contrary to conventional machine learning aiming to learn inherent prediction rules to predict labels for new query data, meta learning aims to learn the learning methodology for machine learning from observed tasks, so as to generalize to new query tasks by leveraging the meta-learned learning methodology. In this study, we interpret such learning methodology as learning an explicit hyperparameter prediction policy shared by all training tasks. Specifically, this policy is represented as a parameterized function called meta-learner, mapping from a training/test task to its suitable hyperparameter setting, extracted from a pre-specified function set called meta learning machine. Such setting guarantees that the meta-learned learning methodology is able to flexibly fit diverse query tasks, instead of only obtaining fixed hyperparameters by many current meta learning methods, with less adaptability to query task\u2019s variations. Such understanding of meta learning also makes it easily succeed from traditional learning theory for analyzing its generalization bounds with general losses/tasks/models. The theory naturally leads to some feasible controlling strategies for ameliorating the quality of the extracted meta-learner, verified to be able to finely ameliorate its generalization capability in some typical meta learning applications, including few-shot regression, few-shot classification and domain generalization.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "143653076",
                        "name": "Jun Shu"
                    },
                    {
                        "authorId": "1803714",
                        "name": "Deyu Meng"
                    },
                    {
                        "authorId": "98220533",
                        "name": "Zongben Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "To understand and explain the success of popular meta-representation learning approaches such as ANIL [43], MetaOptNet [36], R2D2 [9], and OML [33], we study a alternating gradient-descent minimization (AltMinGD) method (and its variant alternating minimization (AltMin) in the Appendix) which underlies the aforementioned methods.",
                "This is becoming increasingly popular with empirical successes in the few-shot learning scenarios [33, 36, 9, 42, 43, 27, 47, 14].",
                "This approach is becoming increasingly popular with a growing list of recent applications [33, 36, 9, 42, 43, 27, 47, 14, 13, 18] and has been empirically shown to achieve the state-of-the-art performances on benchmark few-shot learning datasets [47, 14, 43].",
                "Several closely related algorithms have been proposed, including separating training-set used for the inner loop and the validation-set used for the outer-loop [43, 36, 9, 5], early stopping the inner-loop [33], applying to datasets with imbalanced data sizes [42, 14], and proposing new architectures and regularizers [27].",
                "Several variations of this algorithm are widely used, for example [43, 36, 9]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "f3c73d44ab3fca0c593c6e28ef7c7bb5c8a0e436",
                "externalIds": {
                    "DBLP": "conf/nips/ThekumparampilJ21",
                    "CorpusId": 245122642
                },
                "corpusId": 245122642,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/f3c73d44ab3fca0c593c6e28ef7c7bb5c8a0e436",
                "title": "Statistically and Computationally Efficient Linear Meta-representation Learning",
                "abstract": "In typical few-shot learning, each task is not equipped with enough data to be learned in isolation. To cope with such data scarcity, meta-representation learning methods train across many related tasks to find a shared (lower-dimensional) representation of the data where all tasks can be solved accurately. It is hypothesized that any new arriving tasks can be rapidly trained on this low-dimensional representation using only a few samples. Despite the practical successes of this approach, its statistical and computational properties are less understood. Recent theoretical studies either provide a highly suboptimal statistical error, or require many samples for every task, which is infeasible in the few-shot learning setting. Moreover, the prescribed algorithms in these studies have little resemblance to those used in practice or they are computationally intractable. To understand and explain the success of popular meta-representation learning approaches such as ANIL [43], MetaOptNet [36], R2D2 [9], and OML [33], we study a alternating gradient-descent minimization (AltMinGD) method (and its variant alternating minimization (AltMin) in the Appendix) which underlies the aforementioned methods. For a simple but canonical setting of shared linear representations, we show that AltMinGD achieves nearly-optimal estimation error, requiring only \u03a9(polylog d) samples per task. This agrees with the observed efficacy of this algorithm in the practical few-shot learning scenarios.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "1690006",
                        "name": "K. K. Thekumparampil"
                    },
                    {
                        "authorId": "48964143",
                        "name": "Prateek Jain"
                    },
                    {
                        "authorId": "1751626",
                        "name": "Praneeth Netrapalli"
                    },
                    {
                        "authorId": "34184418",
                        "name": "Sewoong Oh"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Based on deep kernels [42], recent state-of-the-arts (R2D2 [4], MetaOptNet [22], and DKT [26]) propose to use a base kernel in the base learner and update the deep network in the meta-learner.",
                "Typical models include non-parametric prototype classifier (ProtoNet [35]), linear models like ridge regression (R2D2 [4]), SVM classifier (MetaOptNet-SVM [22]), and softmax classifier (ANIL [27]).",
                "We compare MetaProx with the state-of-the-arts: (i) meta-initialization: MAML [12] and its variants FOMAML [12], and REPTILE [25]; (ii) meta-regularization: iMAML [28] and Meta-MinibatchProx [43]; and (iii) metric learning: ANIL [27], R2D2 [4], ProtoNet [35], and MetaOptNet [22] with SVM using the linear kernel and cosine kernel.",
                "Popular meta-learning algorithms usually construct the task-specific model by: (i) metainitialization [12, 25, 11, 38], (ii) meta-regularization [7, 8, 9, 28, 43], or (iii) metric learning [35, 4, 22, 27].",
                "In particular, the base learners in R2D2 [4], MetaOptNet [22] and DKT [26] seek solutions in the dual space, which achieve state-ofthe-art performance.",
                "By setting f\u03b8 = 0, this recovers the state-of-the-arts of MetaOptNet [22], R2D2 [4], and DKT [26].",
                "For example, R2D2 [4] and MetaOptNet [22] use deep kernels [42] in meta-learning for few-shot",
                "With the dual formulation, \u03b8 in (2) allows extra flexibility over [22, 4, 7].",
                "Metric learning methods have been widely studied in few-shot learning [39, 35, 4, 22, 27]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "48027fb2bc13d3b1b71b9fe3e57feff1cb193350",
                "externalIds": {
                    "DBLP": "conf/nips/JiangKZ21",
                    "CorpusId": 248497864
                },
                "corpusId": 248497864,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/48027fb2bc13d3b1b71b9fe3e57feff1cb193350",
                "title": "Effective Meta-Regularization by Kernelized Proximal Regularization",
                "abstract": "We study the problem of meta-learning, which has proved to be advantageous to accelerate learning new tasks with a few samples. The recent approaches based on deep kernels achieve the state-of-the-art performance. However, the regularizers in their base learners are not learnable. In this paper, we propose an algorithm called MetaProx to learn a proximal regularizer for the base learner. We theoretically establish the convergence of MetaProx. Experimental results confirm the advantage of the proposed algorithm.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2152123946",
                        "name": "Weisen Jiang"
                    },
                    {
                        "authorId": "145193332",
                        "name": "J. Kwok"
                    },
                    {
                        "authorId": "2153638098",
                        "name": "Yu Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We perform our experiments on four benchmark datasets: MiniImageNet [10], CUB [11], CIFAR-FS [12] and TieredImageNet [13]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4de4b539968901a3c44adc4e2d464c27e8fd638d",
                "externalIds": {
                    "CorpusId": 231592540
                },
                "corpusId": 231592540,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/4de4b539968901a3c44adc4e2d464c27e8fd638d",
                "title": "2 Ja n 20 21 GRAPH FILTERING FOR IMPROVING THE ACCURACY OF CLASSIFICATION PROBLEMS",
                "abstract": "In machine learning, classifiers are typically susceptible to noise in the training data. In this work, we aim at reducing intra-class noise with the help of graph filtering to improve the classification performance. Considered graphs are obtained by connecting samples of the training set that belong to a same class depending on the similarity of their representation in a latent space. As a matter of fact, by looking at the features in latent representations of samples as graph signals, it is possible to filter them in order to remove high frequencies, thus improving the signal-to-noise ratio. A consequence is that intra-class variance gets smaller, while mean remains the same, as shown theoretically in this article. We support this analysis through experimental evaluation of the graph filtering impact on the accuracy of multiple standard benchmarks of the field. While our approach applies to all classification problems in general, it is particularly useful in few-shot settings, where intra-class noise has a huge impact due to initial sample selection.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "35477938",
                        "name": "Mounia Hamidouche"
                    },
                    {
                        "authorId": "3373720",
                        "name": "C. Lassance"
                    },
                    {
                        "authorId": "2143462361",
                        "name": "Yuqing Hu"
                    },
                    {
                        "authorId": "3407508",
                        "name": "Lucas Drumetz"
                    },
                    {
                        "authorId": "3334569",
                        "name": "Bastien Pasdeloup"
                    },
                    {
                        "authorId": "144916029",
                        "name": "Vincent Gripon"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3ad1caf62e0f4353ac3a7bb563392f7683999d23",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2101-11878",
                    "CorpusId": 231719786
                },
                "corpusId": 231719786,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/3ad1caf62e0f4353ac3a7bb563392f7683999d23",
                "title": "COMPAS: Representation Learning with Compositional Part Sharing for Few-Shot Classification",
                "abstract": "Few-shot image classification consists of two consecutive learning processes: 1) In the meta-learning stage, the model acquires a knowledge base from a set of training classes. 2) During meta-testing, the acquired knowledge is used to recognize unseen classes from very few examples. Inspired by the compositional representation of objects in humans, we train a neural network architecture that explicitly represents objects as a set of parts and their spatial composition. In particular, during meta-learning, we train a knowledge base that consists of a dictionary of part representations and a dictionary of part activation maps that encode frequent spatial activation patterns of parts. The elements of both dictionaries are shared among the training classes. During meta-testing, the representation of unseen classes is learned using the part representations and the part activation maps from the knowledge base. Finally, an attention mechanism is used to strengthen those parts that are most important for each category. We demonstrate the value of our compositional learning framework for a few-shot classification using miniImageNet, tieredImageNet, CIFAR-FS, and FC100, where we achieve state-ofthe-art performance.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "153146760",
                        "name": "Ju He"
                    },
                    {
                        "authorId": "2780587",
                        "name": "Adam Kortylewski"
                    },
                    {
                        "authorId": "145081362",
                        "name": "A. Yuille"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Existing few-shot learning methods based on data augmentation [16], [17], [18], metric learning [19], [20], [21], and initialization [22], [23], [24] ameliorate the models in terms of supervised empirical growth, hypothesis space reduction, and initial parameter setting, respectively, so as to enhance the generalization ability of the models under",
                "Metric learning-based approaches [19], [20], [21] imar X iv :2 10 3."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "c4c87768ce02b4ef3faf755f245dd98aebf78223",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2103-13733",
                    "CorpusId": 232352762
                },
                "corpusId": 232352762,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/c4c87768ce02b4ef3faf755f245dd98aebf78223",
                "title": "Spirit Distillation: Precise Real-time Prediction with Insufficient Data",
                "abstract": "Recent trend demonstrates the effectiveness of deep neural networks (DNNs) apply on the task of environment perception in autonomous driving system. While large-scale and complete data can train out fine DNNs, collecting it is always difficult, expensive, and time-consuming. Also, the significance of both accuracy and efficiency cannot be over-emphasized due to the requirement of real-time recognition. To alleviate the conflicts between weak data and high computational consumption of DNNs, we propose a new training framework named Spirit Distillation(SD). It extends the ideas of fine-tuning-based transfer learning(FTT) and feature-based knowledge distillation. By allowing the student to mimic its teacher in feature extraction, the gap of general features between the teacher-student networks is bridged. The Image Party distillation enhancement method(IP) is also proposed, which shuffling images from various domains, and randomly selecting a few as mini-batch. With this approach, the overfitting that the student network to the general features of the teacher network can be easily avoided. Persuasive experiments and discussions are conducted on CityScapes with the prompt of COCO2017 and KITTI. Results demonstrate the boosting performance in segmentation(mIOU and high-precision accuracy boost by 1.4% and 8.2% respectively, with 78.2% output variance), and can gain a precise compact network with only 41.8% FLOPs(see Fig. 1). This paper is a pioneering work on knowledge distillation applied to few-shot learning. The proposed methods significantly reduce the dependence on data of DNNs training, and improves the robustness of DNNs when facing rare situations, with real-time requirement satisfied. We provide important technical support for the advancement of scene perception technology for autonomous driving.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2146254894",
                        "name": "Zhiyuan Wu"
                    },
                    {
                        "authorId": "2072590105",
                        "name": "Hong Qi"
                    },
                    {
                        "authorId": "2118492219",
                        "name": "Yu Jiang"
                    },
                    {
                        "authorId": "2003576699",
                        "name": "Chupeng Cui"
                    },
                    {
                        "authorId": "2109479351",
                        "name": "Zongmin Yang"
                    },
                    {
                        "authorId": "2003577494",
                        "name": "Xinhui Xue"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "328f8e648cb7d6cb94cbf83d0e39af51d2b5e914",
                "externalIds": {
                    "DBLP": "journals/spl/XiongLLW21",
                    "DOI": "10.1109/LSP.2021.3061978",
                    "CorpusId": 233136277
                },
                "corpusId": 233136277,
                "publicationVenue": {
                    "id": "d5da7004-7b61-450a-9c7d-a39500de7acf",
                    "name": "IEEE Signal Processing Letters",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE Signal Process Lett"
                    ],
                    "issn": "1070-9908",
                    "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=97"
                },
                "url": "https://www.semanticscholar.org/paper/328f8e648cb7d6cb94cbf83d0e39af51d2b5e914",
                "title": "Multi-Dimensional Edge Features Graph Neural Network on Few-Shot Image Classification",
                "abstract": "Few-shot image classification with graph neural network (GNN) is a hot topic in recent years. Most GNN-based approaches have achieved promising performance. These methods utilize node features or one-dimensional edge feature for classification ignoring rich edge featues between nodes. In this letter, we propose a novel graph neural network exploiting multi-dimensional edge features (MDE-GNN) based on edge-labeling graph neural network (EGNN) and transductive neural network for few-shot learning. Unlike previous GNN-based approaches, we utilize multi-dimensional edge features information to construct edge matrices in graph. After layers of node and edge feautres updating, we generate a similarity score matrix by the mulit-dimensional edge features through a well-designed edge aggregation module. The parameters in our network are iteratively learnt by episode training with an edge similarity loss. We apply our model to supervised few-shot image classification tasks. Compared with previous GNNs and other few-shot learning approaches, we achieve state-of-the-art performance with two benchmark datasets.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2054594441",
                        "name": "Chao Xiong"
                    },
                    {
                        "authorId": "47112939",
                        "name": "Wenqi Li"
                    },
                    {
                        "authorId": "2119293955",
                        "name": "Yun Liu"
                    },
                    {
                        "authorId": "2108668601",
                        "name": "Minghui Wang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7d739b025c9666d45084672cfa72a62e329efbd3",
                "externalIds": {
                    "DBLP": "journals/staeors/ShiJZ21",
                    "DOI": "10.1109/JSTARS.2021.3066539",
                    "CorpusId": 233196335
                },
                "corpusId": 233196335,
                "publicationVenue": {
                    "id": "849b6687-df71-4d12-9c46-59f45d5ce951",
                    "name": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE J Sel Top Appl Earth Obs Remote Sens"
                    ],
                    "issn": "1939-1404",
                    "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=4609443",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4609443"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/7d739b025c9666d45084672cfa72a62e329efbd3",
                "title": "Few-Shot Ship Classification in Optical Remote Sensing Images Using Nearest Neighbor Prototype Representation",
                "abstract": "With the development of ship detection in optical remote sensing images, it is convenient to obtain accurate detection results and ship images. Owing to the superior performance of convolutional neural networks (CNNs), one way to acquire the category of ship is to train a classifier using numerous ship images. However, the classification performance of CNN may degrade in the case of a small number of training samples. To solve this problem, we propose a metric-based few-shot method to generate novel concept (class) representation using nearest neighbor prototype. Different from image-to-image measure in common few-shot methods, we use an image-to-feature measure. We map small number of samples to the feature space through CNN, and generate prototypes by computing nearest neighbor value on each dimension of the feature separately. Our method is validated on patch-level ship image dataset, a reproduced ship classification dataset based on HRSC2016. The experimental results demonstrate the accuracy and robustness of our method for ship classification with a small amount of labeled data.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2117868552",
                        "name": "Jiawei Shi"
                    },
                    {
                        "authorId": "144704199",
                        "name": "Zhi-guo Jiang"
                    },
                    {
                        "authorId": "2000351915",
                        "name": "Haopeng Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Numbers of metric learning algorithms have been explored including centroids based method, dimensionality reduction based method and so on[13], Euclidean distance to class-mean representations [14], CNN relation modules [15], ridge regression [16], and graph neural networks [17]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "02feed51980d5631ae18ab4cf595a2be77b81974",
                "externalIds": {
                    "DOI": "10.1088/1742-6596/1884/1/012024",
                    "CorpusId": 235281016
                },
                "corpusId": 235281016,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/02feed51980d5631ae18ab4cf595a2be77b81974",
                "title": "Few-shot learning approach for 3D defect detection in lithium battery",
                "abstract": "Detecting the surface defects in a lithium battery with an aluminium/steel shell is a difficult task. The effect of reflectivity, the limitation of acquiring the 3D information, and the shortage of massive amounts of labelled training data make the 2D detection method hard to classify surface defects. In this work, a few-shot learning approach for 3D defect detection in lithium batteries is proposed. The multi-exposure-based structured light method is introduced to reconstruct the 3D shape of the lithium battery. Then, the anomaly part of the 3D point cloud is transferred into 2D images by the height-gray transformation. The MiniImageNet datasets are used as the source domain to pretrain the Cross-Domain Few-Shot Learning (CD-FSL) model. The accuracy in our experiment result is 97.17%, which means that our method can be used to classify the surface defects of the lithium battery.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2109009345",
                        "name": "Ke Wu"
                    },
                    {
                        "authorId": "72437459",
                        "name": "JieFu Tan"
                    },
                    {
                        "authorId": "2109598359",
                        "name": "Jingwei Li"
                    },
                    {
                        "authorId": "49046697",
                        "name": "Chengbao Liu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "64f5a1100c065ec57be72f1d6f997f1593806bc0",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-02566",
                    "CorpusId": 235353032
                },
                "corpusId": 235353032,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/64f5a1100c065ec57be72f1d6f997f1593806bc0",
                "title": "Improve the Interpretability of Attention: A Fast, Accurate, and Interpretable High-Resolution Attention Model",
                "abstract": "The prevalence of employing attention mechanisms has brought along concerns on the interpretability of attention distributions. Although it provides insights about how a model is operating, utilizing attention as the explanation of model predictions is still highly dubious. The community is still seeking more interpretable strategies for better identifying local active regions that contribute the most to the final decision. To improve the interpretability of existing attention models, we propose a novel Bilinear Representative Non-Parametric Attention (BR-NPA) strategy that captures the task-relevant human-interpretable information. The target model is first distilled to have higher-resolution intermediate feature maps. From which, representative features are then grouped based on local pairwise feature similarity, to produce finer-grained, more precise attention maps highlighting task-relevant parts of the input. The obtained attention maps are ranked according to the \u2018active level\u2019 of the compound feature, which provides information regarding the important level of the highlighted regions. The proposed model can be easily adapted in a wide variety of modern deep models, where classification is involved. It is also more accurate, faster, and with a smaller memory footprint than usual neural attention modules. Extensive experiments showcase more comprehensive visual explanations compared to the state-of-the-art visualization model across multiple tasks including few-shot classification, person re-identification, fine-grained image classification. The proposed visualization model sheds imperative light on how neural networks \u2018pay their attention\u2019 differently in different tasks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2070904522",
                        "name": "T. Gomez"
                    },
                    {
                        "authorId": "23993939",
                        "name": "Suiyi Ling"
                    },
                    {
                        "authorId": "2107033619",
                        "name": "Thomas Fr'eour"
                    },
                    {
                        "authorId": "1790706",
                        "name": "H. Mouch\u00e8re"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "4866639645b5c5ee7f0b28a3d37d18ac74228be6",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2106-15367",
                    "CorpusId": 235670146
                },
                "corpusId": 235670146,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/4866639645b5c5ee7f0b28a3d37d18ac74228be6",
                "title": "MAML is a Noisy Contrastive Learner",
                "abstract": "Model-agnostic meta-learning (MAML) is one of the most popular and widelyadopted meta-learning algorithms nowadays, which achieves remarkable success in various learning problems. Yet, with the unique design of nested inner-loop and outer-loop updates which respectively govern the task-specific and meta-modelcentric learning, the underlying learning objective of MAML still remains implicit and thus impedes a more straightforward understanding of it. In this paper, we provide a new perspective to the working mechanism of MAML and discover that: MAML is analogous to a meta-learner using a supervised contrastive objective function, where the query features are pulled towards the support features of the same class and against those of different classes, in which such contrastiveness is experimentally verified via an analysis based on the cosine similarity. Moreover, our analysis reveals that the vanilla MAML algorithm has an undesirable interference term originating from the random initialization and the cross-task interaction. We therefore propose a simple but effective technique, zeroing trick, to alleviate such interference, where the extensive experiments are then conducted on both miniImagenet and Omniglot datasets to demonstrate the consistent improvement brought by our proposed technique thus validating its effectiveness.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2115997017",
                        "name": "Chia-Hsiang Kao"
                    },
                    {
                        "authorId": "37811787",
                        "name": "Wei-Chen Chiu"
                    },
                    {
                        "authorId": "153191489",
                        "name": "Pin-Yu Chen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Ridge Regression Meta-Learner (Bertinetto et al., 2019) (RRML) calculates the class vector by solving a Ridge regression problem on the support set.",
                "LaSAML with other meta-learning framework To further explore the potential of LaSAML, we incorporate it into the Ridge Regression Meta-learner (RRML) (Bertinetto et al., 2019), which is achieved by simply replacing the feature extractor f and g with the feature extractors used in LaSAML-PN."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5be31bd3a8c4905b7ee2ffc7c8f477ba6365b5de",
                "externalIds": {
                    "DBLP": "conf/acl/LuoLLZ21",
                    "ACL": "2021.findings-acl.245",
                    "DOI": "10.18653/v1/2021.findings-acl.245",
                    "CorpusId": 236477592
                },
                "corpusId": 236477592,
                "publicationVenue": {
                    "id": "479d5605-51be-4346-b1d6-4334084504df",
                    "name": "Findings",
                    "type": "journal",
                    "issn": "2652-8800",
                    "url": "https://findingspress.org/"
                },
                "url": "https://www.semanticscholar.org/paper/5be31bd3a8c4905b7ee2ffc7c8f477ba6365b5de",
                "title": "Don\u2019t Miss the Labels: Label-semantic Augmented Meta-Learner for Few-Shot Text Classification",
                "abstract": "Increasing studies leverage pre-trained language models and meta-learning frameworks to solve few-shot text classi\ufb01cation problems. Most of the current studies focus on building a meta-learner from the information of input texts but ignore abundant semantic information beneath class labels. In this work, we show that class-label information can be utilized for extracting more discriminative feature representation of the input text from a pre-trained language model like BERT, and can achieve a performance boost when the samples are scarce. Building on top of this discovery, we propose a framework called Label-semantic augmented meta-learner (LaSAML) to make full use of label semantics. We systematically investigate various factors in this framework and show that it can be plugged into the existing few-shot text classi\ufb01cation system. Through extensive experiments, we demonstrate that the few-shot text classi\ufb01cation system upgraded by LaSAML can lead to signi\ufb01cant performance improvement over its original counterparts.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2125648143",
                        "name": "Qiaoyang Luo"
                    },
                    {
                        "authorId": "120095791",
                        "name": "Ling-ling Liu"
                    },
                    {
                        "authorId": "2166060948",
                        "name": "Yuhao Lin"
                    },
                    {
                        "authorId": "31765881",
                        "name": "Wei Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "6f875033b836352b04190e23599b834461ec2413",
                "externalIds": {
                    "DBLP": "conf/ijcai/LiFG21",
                    "DOI": "10.24963/ijcai.2021/370",
                    "CorpusId": 237100966
                },
                "corpusId": 237100966,
                "publicationVenue": {
                    "id": "67f7f831-711a-43c8-8785-1e09005359b5",
                    "name": "International Joint Conference on Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Int Jt Conf Artif Intell",
                        "IJCAI"
                    ],
                    "url": "http://www.ijcai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/6f875033b836352b04190e23599b834461ec2413",
                "title": "Regularising Knowledge Transfer by Meta Functional Learning",
                "abstract": "Machine learning classifiers\u2019 capability is largely dependent on the scale of available training data and limited by the model overfitting in data-scarce learning tasks. To address this problem, this work proposes a novel Meta Functional Learning (MFL) by meta-learning a generalisable functional model from data-rich tasks whilst simultaneously regularising knowledge transfer to data-scarce tasks. The MFL computes meta-knowledge on functional regularisation generalisable to different learning tasks by which functional training on limited labelled data promotes more discriminative functions to be learned. Moreover, we adopt an Iterative Update strategy on MFL (MFL-IU). This improves knowledge transfer regularisation from MFL by progressively learning the functional regularisation in knowledge transfer. Experiments on three FewShot Learning (FSL) benchmarks (miniImageNet, CIFAR-FS and CUB) show that meta functional learning for regularisation knowledge transfer can benefit improving FSL classifiers.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2125435016",
                        "name": "Pan Li"
                    },
                    {
                        "authorId": "35782003",
                        "name": "Yanwei Fu"
                    },
                    {
                        "authorId": "144784813",
                        "name": "S. Gong"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "69bebcbea934c255ebe83b7817987dcf22e3392a",
                "externalIds": {
                    "DBLP": "conf/nips/DumoulinHEZGGLL21",
                    "CorpusId": 237396832
                },
                "corpusId": 237396832,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/69bebcbea934c255ebe83b7817987dcf22e3392a",
                "title": "A Unified Few-Shot Classification Benchmark to Compare Transfer and Meta Learning Approaches",
                "abstract": "Meta and transfer learning are two successful families of approaches to few-shot learning. Despite highly related goals, state-of-the-art advances in each family are measured largely in isolation of each other. As a result of diverging evaluation norms, a direct or thorough comparison of different approaches is challenging. To bridge this gap, we introduce a few-shot classification evaluation protocol named VTAB+MD with the explicit goal of facilitating sharing of insights from each community. We demonstrate its accessibility in practice by performing a cross-family study of the best transfer and meta learners which report on both a large-scale meta-learning benchmark (Meta-Dataset, MD), and a transfer learning benchmark (Visual Task Adaptation Benchmark, VTAB). We find that, on average, large-scale transfer methods (Big Transfer, BiT) outperform competing approaches on MD, even when trained only on ImageNet. In contrast, meta-learning approaches struggle to compete on VTAB when trained and validated on MD. However, BiT is not without limitations, and pushing for scale does not improve performance on highly out-of-distribution MD tasks. We hope that this work contributes to accelerating progress on few-shot learning research.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "3074927",
                        "name": "Vincent Dumoulin"
                    },
                    {
                        "authorId": "2815290",
                        "name": "N. Houlsby"
                    },
                    {
                        "authorId": "3399348",
                        "name": "Utku Evci"
                    },
                    {
                        "authorId": "2743563",
                        "name": "Xiaohua Zhai"
                    },
                    {
                        "authorId": "2558463",
                        "name": "Ross Goroshin"
                    },
                    {
                        "authorId": "1802148",
                        "name": "S. Gelly"
                    },
                    {
                        "authorId": "1777528",
                        "name": "H. Larochelle"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026this setting as \u201cfew-shot learning\u201d and it is considered as the primary setting to evaluate meta-learning algorithms [San-\ntoro et al., 2016, Finn et al., 2017, 2018, Ren et al., 2018a], even if meta-models can be defined over a broader variety of learning problems [e.g., Bertinetto et al., 2019]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e04dc30b977c003c33bd1f94b2f6dbb6aa837507",
                "externalIds": {
                    "DBLP": "conf/uai/ErmisZA21",
                    "CorpusId": 237511998
                },
                "corpusId": 237511998,
                "publicationVenue": {
                    "id": "f9af8000-42f8-410d-a622-e8811e41660a",
                    "name": "Conference on Uncertainty in Artificial Intelligence",
                    "type": "conference",
                    "alternate_names": [
                        "Uncertainty in Artificial Intelligence",
                        "UAI",
                        "Conf Uncertain Artif Intell",
                        "Uncertain Artif Intell"
                    ],
                    "url": "http://www.auai.org/"
                },
                "url": "https://www.semanticscholar.org/paper/e04dc30b977c003c33bd1f94b2f6dbb6aa837507",
                "title": "Towards robust episodic meta-learning",
                "abstract": "Meta-learning learns across historical tasks with the goal to discover a representation from which it is easy to adapt to unseen tasks. Episodic meta-learning attempts to simulate a realistic setting by generating a set of small arti\ufb01cial tasks from a larger set of training tasks for meta-training and proceeds in a similar fashion for meta-testing. However, this (meta-)learning paradigm has recently been shown to be brittle, suggesting that the inductive bias encoded in the learned representations is inadequate. In this work we propose to compose episodes to robustify meta-learning in the few-shot setting in order to learn more ef\ufb01ciently and to generalize better to new tasks. We make use of active learning scoring rules to select the data to be included in the episodes. We assume that the meta-learner is given new tasks at random, but the data associated to the tasks can be selected from a larger pool of unlabeled data, and investigate where active learning can boost the performance of episodic meta-learning. We show that instead of selecting samples at random, it is better to select samples in an active manner especially in settings with out-of-distribution and class-imbalanced tasks. We evaluate our method with Prototypical Networks, foMAML and protoMAML, reporting signi\ufb01cant improvements on public benchmarks.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2445273",
                        "name": "Beyza Ermis"
                    },
                    {
                        "authorId": "3024156",
                        "name": "Giovanni Zappella"
                    },
                    {
                        "authorId": "2824663",
                        "name": "C. Archambeau"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a; Liu et al., 2021a), hyperparamater optimization (Franceschi et al.,\u2026",
                "Bilevel optimization has recently arisen as a powerful tool to capture various modern machine learning problems, including meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020a; Liu et al., 2021a), hyperparamater optimization (Franceschi et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "161afd2bb86eda1888fb609dcc26b46d4e5189fd",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-07004",
                    "CorpusId": 238856839
                },
                "corpusId": 238856839,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/161afd2bb86eda1888fb609dcc26b46d4e5189fd",
                "title": "ES-Based Jacobian Enables Faster Bilevel Optimization",
                "abstract": "Bilevel optimization (BO) has arisen as a powerful tool for solving many modern machine learning problems. However, due to the nested structure of BO, existing gradient-based methods require secondorder derivative approximations via Jacobianor/and Hessian-vector computations, which can be very costly in practice, especially with large neural network models. In this work, we propose a novel BO algorithm, which adopts Evolution Strategies (ES) based method to approximate the response Jacobian matrix in the hypergradient of BO, and hence fully eliminates all second-order computations. We call our algorithm as ESJ (which stands for the ES-based Jacobian method) and further extend it to the stochastic setting as ESJ-S. Theoretically, we characterize the convergence guarantee and computational complexity for our algorithms. Experimentally, we demonstrate the superiority of our proposed algorithms compared to the state of the art methods on various bilevel problems. Particularly, in our experiment in the few-shot meta-learning problem, we meta-learn the twelve millions parameters of a ResNet-12 network over the miniImageNet dataset, which evidently demonstrates the scalability of our ES-based bilevel approach and its feasibility in the large-scale setting.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "143827145",
                        "name": "Daouda Sow"
                    },
                    {
                        "authorId": "24006255",
                        "name": "Kaiyi Ji"
                    },
                    {
                        "authorId": "50014661",
                        "name": "Yingbin Liang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "They can also be extended to other applications such as regression and image classification by changing the architecture and training objective [22, 62, 6, 41]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2c14871d2e51dc0ffb5c04bfa40401fd5d0c69ea",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2110-07510",
                    "CorpusId": 238856753
                },
                "corpusId": 238856753,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/2c14871d2e51dc0ffb5c04bfa40401fd5d0c69ea",
                "title": "Omni-Training for Data-Efficient Deep Learning",
                "abstract": "\ud835\udc53 meta , followed by activation functions \ud835\udc4e joint , \ud835\udc4e pre , \ud835\udc4e meta . The Omni-Loss consists of three losses respectively for joint-training \ue238 joint , pre-training \ue236 pre , and meta-training \ue236 meta , which are computed on the corresponding head. We also propose a self-distillation regularization for training pre-\ufb02ow and meta-\ufb02ow, which transfers knowledge across the training process and further boosts the transferability Study of Losses. We conduct an ablation study by using di\ufb00erent combinations of losses in the Omni-Training framework. For the losses of \ue238 pre , \ue238 meta and \ue238 joint , if we do not use any of the three losses, we will not use the corresponding branch for inference. We report results on mini-ImageNet, CUB and mini-ImageNet \u2192 CUB datasets with \ud835\udc3e = 5 in Table 6. We observe that all of the loss functions in the tri-\ufb02ow design including the self-distillation regularization contribute to the improvement of",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2066476988",
                        "name": "Yang Shu"
                    },
                    {
                        "authorId": "3451430",
                        "name": "Zhangjie Cao"
                    },
                    {
                        "authorId": "2118390591",
                        "name": "Jing Gao"
                    },
                    {
                        "authorId": "2144499343",
                        "name": "Jianmin Wang"
                    },
                    {
                        "authorId": "2054275000",
                        "name": "Mingsheng Long"
                    }
                ]
            }
        },
        {
            "contexts": [
                "They can also be extended to other applications such as regression and image classification by changing the architecture and training objective (Finn et al., 2017a; Rusu et al., 2019; Bertinetto et al., 2019; Lee et al., 2019)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1c2fd28c0cb4ea4e8bb7bd4a7cb0d8d7f1acdc0c",
                "externalIds": {
                    "CorpusId": 243831139
                },
                "corpusId": 243831139,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1c2fd28c0cb4ea4e8bb7bd4a7cb0d8d7f1acdc0c",
                "title": "Omni-Training for Data-Efficient Deep Learning Omni-Training for Data-Efficient Deep Learning",
                "abstract": "Learning a generalizable deep model from a few examples in a short time remains a major challenge of machine learning, which has impeded its wide deployment to many scenarios. While the unprecedented performance of deep learning models highly relies on large-scale labeled data, recent advances reveal that a properly pre-trained model endows an important property: transferability. A higher transferability of the learned representations indicates a better generalizability across domains of different distributions (domain transferability), or across tasks of different semantics (task transferability). Transferability has become the key to enable data-efficient deep learning, however, existing pre-training methods focus only on the domain transferability while meta-training methods only on the task transferability. This restricts their data-efficiency in downstream scenarios of diverging domains and tasks. A finding of this paper is that even a tight combination of pre-training and meta-training through a joint representation flow cannot achieve both kinds of transferability. This finding motivates the proposed Omni-Training framework towards data-efficient deep learning. Our first contribution is Omni-Net, a tri-flow architecture. Besides the joint representation flow, Omni-Net introduces two new parallel flows for pre-training and meta-training, respectively responsible for learning representations of domain transferability and task transferability. Omni-Net coordinates the parallel flows by routing their representations via the joint-flow, making each gain the other kind of transferability. Our second contribution is Omni-Loss, in which a mean-teacher regularization is imposed to both the pre-training and meta-training objectives, enabling the parallel flows to learn generalizable and stabilized representations. Omni-Training is a general framework that accommodates many existing pre-training and meta-training algorithms. A thorough evaluation on cross-task and cross-domain datasets in classification, regression and reinforcement learning problems shows that Omni-Training consistently and clearly outperforms the state-of-the-art deep learning methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2066476988",
                        "name": "Yang Shu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "These models learn by conditioning predictions on distance metrics such as cosine similarity [39], Euclidean distances [33], network based [36], ridge regression [3], convex optimization based [25], or graph neural networks [32]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2df0a776339b3337d3558eddc0afbeab49868cff",
                "externalIds": {
                    "DBLP": "conf/cvip/BhartiBJ21",
                    "DOI": "10.1007/978-3-031-11346-8_23",
                    "CorpusId": 244839189
                },
                "corpusId": 244839189,
                "publicationVenue": {
                    "id": "73dc1b2c-812e-4118-be6b-501cf924387d",
                    "name": "International Conference on Computer Vision and Image Processing",
                    "type": "conference",
                    "alternate_names": [
                        "CVIP",
                        "Int Conf Comput Vis Image Process"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/2df0a776339b3337d3558eddc0afbeab49868cff",
                "title": "Towards Label-Free Few-Shot Learning: How Far Can We Go?",
                "abstract": null,
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2064645504",
                        "name": "Aditya Bharti"
                    },
                    {
                        "authorId": "1380374163",
                        "name": "C.V. Jawahar"
                    }
                ]
            }
        },
        {
            "contexts": [
                "A common framework for such settings is few-shot learning [10, 18, 41, 53, 58, 64]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e394670b17005558cf59da476078fd29344acaa4",
                "externalIds": {
                    "DBLP": "conf/nips/StanleyBMMLSSB21",
                    "CorpusId": 244906257
                },
                "corpusId": 244906257,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e394670b17005558cf59da476078fd29344acaa4",
                "title": "FS-Mol: A Few-Shot Learning Dataset of Molecules",
                "abstract": "Small datasets are ubiquitous in drug discovery as data generation is expensive and can be restricted for ethical reasons (e.g. in vivo experiments). A widely applied technique in early drug discovery to identify novel active molecules against a protein target is modeling quantitative structure-activity relationships (QSAR). It is known to be extremely challenging, as available measurements of compound activities range in the low dozens or hundreds. However, many such related datasets exist, each with a small number of datapoints, opening up the opportunity for few-shot learning after pretraining on a substantially larger corpus of data. At the same time, many few-shot learning methods are currently evaluated in the computer-vision domain. We propose that expansion into a new application, as well as the possibility to use explicitly graph-structured data, will drive exciting progress in few-shot learning. Here, we provide a few-shot learning dataset (FS-Mol) and complementary benchmarking procedure. We de\ufb01ne a set of tasks on which few-shot learning methods can be evaluated, with a separate set of tasks for use in pretraining. In addition, we implement and evaluate a number of existing single-task, multi-task, and meta-learning approaches as baselines for the community. We hope that our dataset, support code release, and baselines will encourage future work on this extremely challenging new domain for few-shot learning.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2059909117",
                        "name": "Megan Stanley"
                    },
                    {
                        "authorId": "46242344",
                        "name": "J. Bronskill"
                    },
                    {
                        "authorId": "50351613",
                        "name": "Krzysztof Maziarz"
                    },
                    {
                        "authorId": "2785544",
                        "name": "Hubert Misztela"
                    },
                    {
                        "authorId": "47224196",
                        "name": "J. Lanini"
                    },
                    {
                        "authorId": "3451383",
                        "name": "Marwin H. S. Segler"
                    },
                    {
                        "authorId": "2164196529",
                        "name": "Nadine Schneider"
                    },
                    {
                        "authorId": "2107692",
                        "name": "Marc Brockschmidt"
                    }
                ]
            }
        },
        {
            "contexts": [
                "The adaptation of the entire network makes it hard to be scaled to large networks, and many recent efforts focus on adapting the last classification layer only [14, 5], while assuming a universal feature extractor that is shared across all tasks.",
                "Note the trainable temperature \u2327 here allows automatic scaling to the unnormalized multi-class posterior predictive, and a similar implementation can also be found in [5]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "a4de6509a26d4f31deea44194581c46b4ebab04c",
                "externalIds": {
                    "DBLP": "conf/nips/WangMZQ21",
                    "CorpusId": 245003918
                },
                "corpusId": 245003918,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/a4de6509a26d4f31deea44194581c46b4ebab04c",
                "title": "Learning to Learn Dense Gaussian Processes for Few-Shot Learning",
                "abstract": "Gaussian processes with deep neural networks demonstrate to be a strong learner for few-shot learning since they combine the strength of deep learning and kernels while being able to well capture uncertainty. However, it remains an open problem to leverage the shared knowledge provided by related tasks. In this paper, we propose to learn Gaussian processes with dense inducing variables by meta-learning for few-shot learning. In contrast to sparse Gaussian processes, we define a set of dense inducing variables to be of a much larger size than the support set in each task, which collects prior knowledge from experienced tasks. The dense inducing variables specify a shared Gaussian process prior over prediction functions of all tasks, which are learned in a variational inference framework and offer a strong inductive bias for learning new tasks. To achieve task-specific prediction functions, we propose to adapt the inducing variables to each task by efficient gradient descent. We conduct extensive experiments on common benchmark datasets for a variety of few-shot learning tasks. Our dense Gaussian processes present significant improvements over vanilla Gaussian processes and comparable or even better performance with state-of-the-art methods.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2128188053",
                        "name": "Ze Wang"
                    },
                    {
                        "authorId": "9140351",
                        "name": "Zichen Miao"
                    },
                    {
                        "authorId": "34798935",
                        "name": "Xiantong Zhen"
                    },
                    {
                        "authorId": "2077648",
                        "name": "Qiang Qiu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Similar to previous works [4, 25], we conduct experiments on four datasets: Omniglot [35], CIFARFS [36], miniImagenet [37] and VGG-Flowers [38]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "deb70115db215f68d518ab22fb4c82a57ca4d1fb",
                "externalIds": {
                    "DBLP": "conf/nips/ZhangFMLY21",
                    "CorpusId": 245011098
                },
                "corpusId": 245011098,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/deb70115db215f68d518ab22fb4c82a57ca4d1fb",
                "title": "Variational Continual Bayesian Meta-Learning",
                "abstract": "Conventional meta-learning considers a set of tasks from a stationary distribution. In contrast, this paper focuses on a more complex online setting, where tasks arrive sequentially and follow a non-stationary distribution. Accordingly, we propose a Variational Continual Bayesian Meta-Learning (VC-BML) algorithm. VC-BML maintains a Dynamic Gaussian Mixture Model for meta-parameters, with the number of component distributions determined by a Chinese Restaurant Process. Dynamic mixtures at the meta-parameter level increase the capability to adapt to diverse and dissimilar tasks due to a larger parameter space, alleviating the negative knowledge transfer problem. To infer the posteriors of model parameters, compared to the previously used point estimation method, we develop a more robust posterior approximation method \u2013 structured variational inference for the sake of avoiding forgetting knowledge. Experiments on tasks from non-stationary distributions show that VC-BML is superior in transferring knowledge among diverse tasks and alleviating catastrophic forgetting in an online setting.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "150271064",
                        "name": "Qiang Zhang"
                    },
                    {
                        "authorId": "1384241384",
                        "name": "Jinyuan Fang"
                    },
                    {
                        "authorId": "3451645",
                        "name": "Zaiqiao Meng"
                    },
                    {
                        "authorId": "3279808",
                        "name": "Shangsong Liang"
                    },
                    {
                        "authorId": "49724730",
                        "name": "Emine Yilmaz"
                    }
                ]
            }
        },
        {
            "contexts": [
                "2 [6] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi.",
                "However, the typical meta-testing stage just adapts the last classification head with the frozen backbone, which is commonly a fully connected (FC) layer [6]."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "bcb4d2773df30248954ffa2f4bd536d0977d354a",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2112-06320",
                    "CorpusId": 245124267
                },
                "corpusId": 245124267,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/bcb4d2773df30248954ffa2f4bd536d0977d354a",
                "title": "Anomaly Crossing: A New Method for Video Anomaly Detection as Cross-domain Few-shot Learning",
                "abstract": "Video anomaly detection aims to identify abnormal events that occurred in videos. Since anomalous events are relatively rare, it is not feasible to collect a balanced dataset and train a binary classi\ufb01er to solve the task. Thus, most previous approaches learn only from normal videos using unsupervised or semi-supervised methods. Obviously, they are limited in capturing and utilizing discriminative abnormal characteristics, which leads to compromised anomaly detection performance. In this paper, to address this issue, we propose a new learning paradigm by making full use of both normal and abnormal videos for video anomaly detection. In particular, we formulate a new learning task: cross-domain few-shot anomaly detection, which can transfer knowledge learned from numerous videos in the source domain to help solve few-shot abnormality detection in the target domain. Concretely, we leverage self-supervised training on the target normal videos to reduce the domain gap and devise a meta context perception module to explore the video context of the event in the few-shot setting. Our experiments show that our method signi\ufb01cantly outperforms baseline methods on DoTA and UCF-Crime datasets, and the new task contributes to a more practical training paradigm for anomaly detection.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2113639896",
                        "name": "Guangyu Sun"
                    },
                    {
                        "authorId": "1508234044",
                        "name": "Zhangpu Liu"
                    },
                    {
                        "authorId": "2152129821",
                        "name": "Lianggong Wen"
                    },
                    {
                        "authorId": "2112852471",
                        "name": "Jing Shi"
                    },
                    {
                        "authorId": "2026123",
                        "name": "Chenliang Xu"
                    }
                ]
            }
        },
        {
            "contexts": [
                "5-way few-shot classification accuracies (%) on mini-ImageNet [66], tiered-ImageNet [51], and CIFAR-FS [4].",
                "We evaluate our approach on three standard few-shot classification datasets: miniImageNet [66], tiered-ImageNet [51], and CIFAR-FS [4]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "388508a89ca6bfa6797a7e2ca959a4866d3b39de",
                "externalIds": {
                    "DBLP": "conf/nips/ShenXHSA21",
                    "CorpusId": 246527212
                },
                "corpusId": 246527212,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/388508a89ca6bfa6797a7e2ca959a4866d3b39de",
                "title": "Re-ranking for image retrieval and transductive few-shot classification",
                "abstract": "Hard training data sampling The main difficulty is that there is no standard clean training set. One choice is SFM120k used in [14], which is built with structure-from-motion pipeline, and clusters for the same 3D scene are cast as categories. We take features in [7], which already leads to good performance on the training set. For most training samples, the mAPs on the training set are already quite high and training SSR using the raw nearest neighbors makes it perform well only for high mAP queries. To address this problem, we sample only difficult examples: for each query, we sample 1K database images, the query and its nearest neighbors will be training samples only if the mAP is not saturated (\u22640.8) and there are sufficient true positive samples present in the nearest neighbors (\u22655).",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2067219928",
                        "name": "XI Shen"
                    },
                    {
                        "authorId": "2116642640",
                        "name": "Yanghua Xiao"
                    },
                    {
                        "authorId": "145498976",
                        "name": "S. Hu"
                    },
                    {
                        "authorId": "41015936",
                        "name": "Othman Sbai"
                    },
                    {
                        "authorId": "48582897",
                        "name": "Mathieu Aubry"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Much progress has been made in these settings with some state-of-the-art methods, such as MAML [6], Reptile [24], MetaOptNet [12], and R2-D2 [4].",
                "More precisely, the value of t0 is drawn from the set: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512], while the time budget T is set to 512."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "2cce96e189fb82cc4ed42fd7bbe92431e2dc9a60",
                "externalIds": {
                    "DBLP": "conf/pkdd/NguyenGSG21",
                    "CorpusId": 247434879
                },
                "corpusId": 247434879,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/2cce96e189fb82cc4ed42fd7bbe92431e2dc9a60",
                "title": "MetaREVEAL: RL-based Meta-learning from Learning Curves",
                "abstract": ". This paper addresses a cornerstone of Automated Machine Learning: the problem of rapidly uncovering which machine learning algorithm performs best on a new dataset. Our approach leverages performances of such algorithms on datasets to which they have been previously exposed, i.e., implementing a form of meta-learning . More speci\ufb01cally, the problem is cast as a REVEAL Reinforcement Learning (RL) game: the meta-learning problem is wrapped into a RL environment in which an agent can start, pause, or resume training various machine learning algorithms to progressively \u201creveal\u201d their learning curves. The learned policy is then applied to quickly uncover the best algorithm on a new dataset. While other similar approaches, such as Freeze-Thaw, were proposed in the past, using Bayesian optimization, our methodology is, to the best of our knowledge, the \ufb01rst that trains a RL agent to do this task on previous datasets. Using real and arti\ufb01cial data, we show that our new RL-based meta-learning paradigm outperforms Free-Thaw and other baseline methods, with respect to the Area under the Learning curve metric, a form of evaluation of Any-time learning (i.e., the capability of interrupting the algorithm at any time while obtaining good performance).",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2158776277",
                        "name": "Manh Hung Nguyen"
                    },
                    {
                        "authorId": "1743797",
                        "name": "Isabelle M Guyon"
                    },
                    {
                        "authorId": "1414759964",
                        "name": "Lisheng Sun-Hosoya"
                    },
                    {
                        "authorId": "2007774239",
                        "name": "Nathan Grinsztajn"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS & FC100 Proposed by Bertinetto et al. (2019) and Oreshkin et al. (2018), both are splits between the original classes of CIFAR100 (Krizhevsky et al.)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e20e45d98f2861168c640709bf46feb32dc663b0",
                "externalIds": {
                    "CorpusId": 248961817
                },
                "corpusId": 248961817,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e20e45d98f2861168c640709bf46feb32dc663b0",
                "title": "On the Role of Pre-training for Meta Few-Shot Learning",
                "abstract": "Few-shot learning aims to classify unknown classes of examples with a few new examples per class. There are two key routes for few-shot learning. One is to (pre-)train a classi\ufb01er with examples from known classes, and then transfer the pre-trained classi\ufb01er to unknown classes using the new examples. The other, called meta few-shot learning, is to couple pre-training with episodic training, which contains episodes of few-shot learning tasks simulated from the known classes. Pre-training is known to play a crucial role for the transfer route, but the role of pre-training for the episodic route is less clear. In this work, we study the role of pre-training for the episodic route. We \ufb01nd that pre-training serves as major role of disentangling representations of known classes, which makes the resulting learning tasks easier for episodic training. The \ufb01nding allows us to shift the some simulation burden of episodic training to a simpler pre-training stage. We justify such a bene\ufb01t of shift by designing a new disentanglement-based pre-training model, which helps episodic training achieve competitive performance more ef\ufb01ciently.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2165980664",
                        "name": "Chia-You Chen"
                    },
                    {
                        "authorId": "1798966",
                        "name": "Hsuan-Tien Lin"
                    }
                ]
            }
        },
        {
            "contexts": [
                "In order to predict weights, MetaOpt Net [28] advocates SVM, R2-D2 adopts ridge regression layer [29], while Dynamic Net [30] uses a memory module."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "27aacc5635c3c9df7e8d125023251a413f062dd0",
                "externalIds": {
                    "MAG": "3154527330",
                    "DOI": "10.32604/CMC.2021.016851",
                    "CorpusId": 234896914
                },
                "corpusId": 234896914,
                "publicationVenue": {
                    "id": "4a707e29-5a29-4222-b3da-e51b9a3ac36e",
                    "name": "Computers Materials & Continua",
                    "alternate_names": [
                        "Comput Mater  Contin"
                    ],
                    "issn": "1546-2218",
                    "url": "http://www.techscience.com/cmc/"
                },
                "url": "https://www.semanticscholar.org/paper/27aacc5635c3c9df7e8d125023251a413f062dd0",
                "title": "Multi-Head Attention Graph Network for Few Shot Learning",
                "abstract": ": The majority of existing graph-network-based few-shot models focus on a node-similarity update mode. The lack of adequate information intensifies the risk of overtraining. In this paper, we propose a novel Multi-head Attention Graph Network to excavate discriminative relation and fulfill effective information propagation. For edge update, the node-level attention is used to evaluate the similarities between the two nodes and the distribution-level attention extracts more in-deep global relation. The cooperation between those two parts provides a discriminative and comprehensive expression for edge feature. For node update, we embrace the label-level attention to soften the noise of irrelevant nodes and optimize the update direction. Our proposed model is verified through extensive experiments on two few-shot benchmark MiniImageNet and CIFAR-FS dataset. The results suggest that our method has a strong capability of noise immunity and quick convergence. The classification accuracy outperforms most state-of-the-art approaches.",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2118874391",
                        "name": "Baiyan Zhang"
                    },
                    {
                        "authorId": "144125487",
                        "name": "H. Ling"
                    },
                    {
                        "authorId": "2420746",
                        "name": "P. Li"
                    },
                    {
                        "authorId": null,
                        "name": "Qian Wang"
                    },
                    {
                        "authorId": "1753219181",
                        "name": "Yuxuan Shi"
                    },
                    {
                        "authorId": "50789878",
                        "name": "L. Wu"
                    },
                    {
                        "authorId": "2117975769",
                        "name": "Runsheng Wang"
                    },
                    {
                        "authorId": "38203359",
                        "name": "Jialie Shen"
                    }
                ]
            }
        },
        {
            "contexts": [
                "One prominent line of research is to increase the interdependence between the base learner and the metalearner by adjusting the optimization process to ensure feedback is sent in both directions [29, 18, 19, 9].",
                "This can be visualized as a double-loop architecture [45, 9], where the base learner iterates over a training set to learn model parameters under a fixed hypothesis space, in what is described as the inner loop, while concurrently, the metalearner iterates over different tasks to learn metaparameters under a family of hypothesis spaces, in what is described as the outer loop (see Figure 3)."
            ],
            "intents": [
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3db845837825fe27517b82475a094b553b2325e6",
                "externalIds": {
                    "CorpusId": 254136288
                },
                "corpusId": 254136288,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3db845837825fe27517b82475a094b553b2325e6",
                "title": "Transfer of Knowledge Across Tasks",
                "abstract": "Learning should not be viewed as an isolated task that starts from scratch with every new problem. Instead, a learning algorithm should exhibit the ability to adapt through a mechanism dedicated to the transfer of knowledge gathered from previous experience [41, 40]. The problem of how to transfer knowledge across tasks is central to the field of metalearning, and is also referred to as learning to learn or transfer learning. Here, knowledge can be understood as a collection of patterns observed across tasks. As an example, one view of the nature of patterns across tasks is that of invariant transformations. For example, image recognition of a target object is simplified if the object is invariant under rotation, translation, scaling, etc. A learning system should be able to recognize a target object in an image even if previous images show the object at different sizes or from different angles. We view transfer learning as the study of how to improve learning by detecting, extracting, and exploiting knowledge across tasks. In this chapter, we take a look at various approaches to implement learning systems armed with the ability to transfer knowledge across tasks. We focus our description by responding to two questions: What can be transferred across tasks? and what learning architectures have been commonly used for transfer learning? We also present developments in the theoretical aspects of learning to learn. Our focus is on supervised learning; other work can be found in fields such as unsupervised learning [8] and reinforcement learning [39].",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "34706692",
                        "name": "R. Vilalta"
                    },
                    {
                        "authorId": "52385586",
                        "name": "Mikhail M. Meskhi"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "efb2f84d43abe7dd8272fb70c9bc943aac45a2b8",
                "externalIds": {
                    "CorpusId": 260422530
                },
                "corpusId": 260422530,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/efb2f84d43abe7dd8272fb70c9bc943aac45a2b8",
                "title": "Variational Feature Disentangling for Fine-Grained Few-Shot Classification Supplementary Material",
                "abstract": "Our method works particularly well on fine-grained datasets including the CUB[18], NAB[16], and Stanford Dogs[4] datasets where the intra-class variations are similar across classes. Here we provide additional results on the non-fine-grained few-shot datasets such as CIFAR-FS [6], and mini-Imagenet[17], summarized in Tables 1 and 2 respectively. On both datasets, our method outperforms other methods in 5-shot setting by a small margin and achieves competitive performance in 1-shot setting. For the aforementioned datasets, intra-class variations between classes are very different in nature, for e.g., the variation of the \u201cwok\u201d class would bear no resemblance to variations in the \u201cjellyfish\u201d class or the unicycle \u201cunicycle\u201d class of the mini-Imagenet dataset as they are very different objects. Therefore, constructing a common embedding space to model the intra-class variability, which is crucial to our method, is challenging. However, our method still gets competitive results. This implies that our method can be used even when we cannot be sure about the type of variability in the dataset, without a performance penalty",
                "year": 2021,
                "authors": [
                    {
                        "authorId": "2155955514",
                        "name": "Jingyi Xu"
                    },
                    {
                        "authorId": "143631873",
                        "name": "Hieu M. Le"
                    },
                    {
                        "authorId": "1931660936",
                        "name": "Mingzhen Huang"
                    },
                    {
                        "authorId": "50989827",
                        "name": "ShahRukh Athar"
                    },
                    {
                        "authorId": "145654220",
                        "name": "D. Samaras"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Table 1 and 2 summarize the results of the few-shot classification tasks on CIFAR-FS, FC100, and mini-ImageNet, respectively.",
                "We broadly divide the existing few-shot learning approaches into three categories: (1) Gradient-based methods optimize feature embedding with gradient descent during meta-test stage (Finn et al., 2017; Bertinetto et al., 2018; Lee et al., 2019).",
                "Our ResNet-12 model beats (Lee et al., 2019) 1-shot result by 2.7% on FC100, 3.4% on CIFAR-FS, and 1.72% on mini-ImageNet.",
                "We demonstrate the effectiveness of our approach on standard fewshot benchmarks, including FC100 (Oreshkin et al., 2018), CIFAR-FS (Bertinetto et al., 2018) and mini-ImageNet (Vinyals et al., 2016) by showing a significant improvement over the existing methods.",
                "A.1 DATASETS The CIFAR-FS dataset (Bertinetto et al., 2018) is a few-shot classification benchmark containing 100 classes from CIFAR-100 (Krizhevsky et al., 2009).",
                ", 2018), CIFAR-FS (Bertinetto et al., 2018) and mini-ImageNet (Vinyals et al.",
                "We adopt three standard benchmark datasets that are widely used in few-shot learning, CIFAR-FS dataset (Bertinetto et al., 2018), FC100 dataset (Oreshkin et al., 2018), and mini-ImageNet dataset (Vinyals et al., 2016).",
                "We adopt three standard benchmark datasets that are widely used in few-shot learning, CIFAR-FS dataset (Bertinetto et al., 2018), FC100 dataset (Oreshkin et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "a757555fe2a573849378deffae2de173de41a1ee",
                "externalIds": {
                    "CorpusId": 223650452
                },
                "corpusId": 223650452,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/a757555fe2a573849378deffae2de173de41a1ee",
                "title": "ICLR 2021 C oncatenation C onv 1 x 1 BatchN orm R eLU Avg Pool Embeddings Support Query",
                "abstract": "The success of deep convolutional neural networks builds on top of the learning of effective convolution operations, capturing a hierarchy of structured features via filtering, activation, and pooling. However, the explicit structured features, e.g. object parts, are not expressive in the existing CNN frameworks. In this paper, we tackle the few-shot learning problem and make an effort to enhance structured features by expanding CNNs with a constellation model, which performs cell feature clustering and encoding with a dense part representation; the relationships among the cell features are further modeled by an attention mechanism. With the additional constellation branch to increase the awareness of object parts, our method is able to attain the advantages of the CNNs while making the overall internal representations more robust in the few-shot learning setting. Our approach attains a significant improvement over the existing methods in few-shot learning on the CIFAR-FS, FC100, and mini-ImageNet benchmarks.",
                "year": 2020,
                "authors": []
            }
        },
        {
            "contexts": [
                "CIFAR-FS, on the other hand, is similar to miniImageNet, where the dataset is randomly split.",
                "In particular, miniImagenet meta-train set is used for meta-training, while corresponding meta-test splits of Omniglot [7], FC100 [12], and CIFAR-FS [3] are used for evaluation.",
                "B Additional Experiments on Few-Shot Classification We further validate the effectiveness of our proposed dynamic inner-loop update rule ALFA, through evaluating the performance on the relatively new CIFAR100-based [6] few-shot classification datasets: FC100 (Fewshot-CIFAR100) [12] and CIFAR-FS (CIFAR100 few-shots) [3].",
                "Table B: Test accuracy on 5-way classification for FC100 and CIFAR-FS.",
                "All models are only trained with miniImageNet meta-train set and tested on various datasets (domains) without any fine-tuning.\nminiImageNet\n\u2192 Omniglot \u2192 FC100 \u2192 CIFAR-FS ALFA + Random Init 91.02\u00b1 0.29% 62.49\u00b1 0.48% 63.49\u00b1 0.45% MAML [4] 85.68\u00b1 0.35% 55.52\u00b1 0.50% 55.82\u00b1 0.50% ALFA + MAML 93.11\u00b1 0.23% 60.12\u00b1 0.49% 59.76\u00b1 0.49% MAML + L2F [2] 94.96\u00b1 0.22% 61.99\u00b1 0.49% 63.73\u00b1 0.48% ALFA + MAML + L2F 94.10\u00b1 0.24% 63.33\u00b1 0.45% 63.87\u00b1 0.48%",
                "We further validate the effectiveness of our proposed dynamic inner-loop update rule ALFA, through evaluating the performance on the relatively new CIFAR100-based [6] few-shot classification datasets: FC100 (Fewshot-CIFAR100) [12] and CIFAR-FS (CIFAR100 few-shots) [3].",
                "Backbone FC100 CIFAR-FS\n1-shot 5-shot 1-shot 5-shot\nRandom Init 4-CONV 27.50\u00b1 0.45% 35.37\u00b1 0.48% 29.74\u00b1 0.46% 39.87\u00b1 0.49% ALFA + Random Init 4-CONV 38.20\u00b1 0.49% 52.98\u00b1 0.50% 60.56\u00b1 0.49% 75.43\u00b1 0.43% MAML \u2020 [4] 4-CONV 36.67\u00b1 0.48% 49.38\u00b1 0.49% 56.80\u00b1 0.49% 74.97\u00b1 0.43% ALFA + MAML 4-CONV 37.99\u00b1 0.48% 53.01\u00b1 0.49% 59.96\u00b1 0.49% 76.79\u00b1 0.42% MAML + L2F \u2020 [2] 4-CONV 38.96\u00b1 0.49% 53.23\u00b1 0.48% 60.35\u00b1 0.48% 76.76\u00b1 0.42% ALFA + MAML + L2F 4-CONV 38.50\u00b1 0.47% 53.20\u00b1 0.50% 60.36\u00b1 0.50% 76.60\u00b1 0.42% Random Init ResNet12 32.26\u00b1 0.47% 42.00\u00b1 0.49% 36.86\u00b1 0.48% 49.46\u00b1 0.50% ALFA + Random Init ResNet12 40.57\u00b1 0.49% 53.19\u00b1 0.50% 64.14\u00b1 0.48% 78.11\u00b1 0.41% MAML \u2020 ResNet12 37.92\u00b1 0.48% 52.63\u00b1 0.50% 64.33\u00b1 0.48% 76.38\u00b1 0.42% ALFA + MAML ResNet12 41.46\u00b1 0.49% 55.82\u00b1 0.50% 66.79\u00b1 0.47% 83.62\u00b1 0.37% MAML + L2F \u2020 ResNet12 41.89\u00b1 0.47% 54.68\u00b1 0.50% 67.48\u00b1 0.46% 82.79\u00b1 0.38% ALFA + MAML + L2F ResNet12 42.37\u00b1 0.50% 55.23\u00b1 0.50% 68.25\u00b1 0.47% 82.98\u00b1 0.38% Prototypical Networks\u2217 [17] 4-CONV 35.3\u00b1 0.6% 48.6\u00b1 0.6% 55.5\u00b1 0.7% 72.0\u00b1 0.6% Relation Networks [18] 4-CONV+ - - 55.0\u00b1 1.0 69.3\u00b1 0.8 TADAM [12] ResNet12 40.1\u00b1 0.4% 56.1\u00b1 0.4% - - MetaOpt \u2021 [8] ResNet12 41.1\u00b1 0.6% 55.5\u00b1 0.6% 72.0\u00b1 0.7% 84.2\u00b1 0.5%\n* Meta-network is trained using the union of meta-training set and meta-validation set."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "f88a9a4e8b2db1ec2c4e6b85a6d3ba4c62f92a7f",
                "externalIds": {
                    "CorpusId": 227237606
                },
                "corpusId": 227237606,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/f88a9a4e8b2db1ec2c4e6b85a6d3ba4c62f92a7f",
                "title": "Meta-Learning with Adaptive Hyperparameters \u2013 Supplementary Document \u2013",
                "abstract": "We found a bug that is related to batch normalization in multi-GPU training/inference in the original MAML++ code [1], which our code is based on. The bug results in different performance depending on whether training/inference is performed with a single GPU or with multiple GPUs. We believe this is due to how (asynchronous) batch normalization behaves differently in a multi-GPU setting and MAML++ code does not shuffle the order of examples in a minibatch. This setting results in uneven class distribution across GPUs. While MAML performs worse in this setting, adaptive variants of MAML (L2F [2] or ALFA) perform substantially better, compared with a single-GPU setting (see Table A). This result suggests more investigation can be done on normalization in few-shot learning setting for possible performance improvement. While we report single-GPU ResNet12 results, we share our results and finding in hope of facilitating further research and study on the issue.",
                "year": 2020,
                "authors": []
            }
        },
        {
            "contexts": [
                "3We exactly reproduced MetaOptNet on CIFAR-FS, but were unable to close the gap on miniImageNet.",
                "Lastly, alternative optimization-based methods train a meta feature extractor followed by different base learners such as ridge or logistic regression in [6, 49], and support vector machine (SVM) in [21].",
                "CIFAR-FS [6] is a popular few-shot classification benchmark, designed to be more complicated than the previous Omniglot [20] yet more compact than miniImageNet [53].",
                "In addition to comparing with ProtoNets [44] and R2D2 [6] on their original small backbones, we also compare with these two methods with larger convolutional backbones.",
                "We follow this practice to use 15-shot episodes for miniImageNet and 5-shot for CIFAR-FS.",
                "We compare against a few competitive methods, including MAML [10], ProtoNets [44], Relation Networks [45], R2D2 [6], MetaOptNet [21] and RFS [48].",
                "However, the optimization for correction terms require a set of models, while most recent meta-learning frameworks assume to learn a single model [6, 10, 21, 27, 40, 49], limiting the general applicability of [1].",
                "On a separate note, although many meta-learning frameworks [21, 40] have achieved impressive results on few-shot learning benchmarks such as CIFAR-FS and miniImageNet [53], task representation remains to be rarely exploited.",
                "2 Experiments on CIFAR-FS CIFAR-FS [6] is a popular few-shot classification benchmark, designed to be more complicated than the previous Omniglot [20] yet more compact than miniImageNet [53].",
                "Each class in CIFAR-FS contains 600 images of size 32\u00d732.",
                "Interestingly, We find that once we try replace the backbone feature extractor with the same ResNet-12 used in MetaOptNet, ProtoNets and R2D2 both show competitive results, and especially R2D2 already performs better than MetaOptNet just by ensuring a fair backbone.",
                "In this section, we first describe the implementation details (Section 4.1), and then benchmark MATE on two few-shot classification datasets, CIFAR-FS [6] and miniImageNet [53] (Sections 4.2 and 4.3).",
                "The results of 5-way classification on CIFAR-FS are shown in Table 1.",
                "Model Backbone CIFAR-FS [6] 5-way 1-shot 5-way 5-shot MAML [10] 32-32-32-32 58.",
                "Then, MATE can still consistently provide improvements to both (enhanced) baselines: 1) applying MATE to ProtoNets+ResNet12 yields +0.64% 5-shot accuracy and slightly better 1-shot accuracy (+0.14%); 2) applying MATE to R2D2+ResNet12 yields +0.44% 5-shot accuracy improvement and similar 1-shot accuracy (+0.08%).",
                "1), and then benchmark MATE on two few-shot classification datasets, CIFAR-FS [6] and miniImageNet [53] (Sections 4."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "71bb9c90fb356609042171f1a42b0b73051307e9",
                "externalIds": {
                    "MAG": "3104169401",
                    "DBLP": "conf/nips/ChenWTM20",
                    "DOI": "10.3929/ETHZ-B-000466892",
                    "CorpusId": 227223790
                },
                "corpusId": 227223790,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/71bb9c90fb356609042171f1a42b0b73051307e9",
                "title": "MATE: Plugging in Model Awareness to Task Embedding for Meta Learning",
                "abstract": "Meta-learning improves generalization of machine learning models when faced with previously unseen tasks by leveraging experiences from different, yet related prior tasks. To allow for better generalization, we propose a novel task representation called model-aware task embedding (MATE) that incorporates not only the data distributions of different tasks, but also the complexity of the tasks through the models used. The task complexity is taken into account by a novel variant of kernel mean embedding, combined with an instance-adaptive attention mechanism inspired by an SVM-based feature selection algorithm. Together with conditioning layers in deep neural networks, MATE can be easily incorporated into existing meta learners as a plug-and-play module. While MATE is widely applicable to general tasks where the concept of task/environment is involved, we demonstrate its effectiveness in few-shot learning by improving a state-of-the-art model consistently on two benchmarks. Source codes for this paper are available at https://github.com/VITA-Group/MATE.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "66273769",
                        "name": "Xiaohan Chen"
                    },
                    {
                        "authorId": "2969311",
                        "name": "Zhangyang Wang"
                    },
                    {
                        "authorId": "1831081930",
                        "name": "Siyu Tang"
                    },
                    {
                        "authorId": "2276351",
                        "name": "Krikamol Muandet"
                    }
                ]
            }
        },
        {
            "contexts": [
                "\u2026methods Ravi & Larochelle (2016), metric learning based methods Vinyals et al. (2016); Snell et al. (2017); Ren et al. (2018); Sung et al. (2018); Guo & Cheung (2020); Li et al. (2020) and methods which use ridge regression and support vector machine Bertinetto et al. (2018); Lee et al.\n(2019).",
                "(2019); Chen et al. (2020), model optimization based methods Ravi & Larochelle (2016), metric learning based methods Vinyals et al. (2016); Snell et al. (2017); Ren et al. (2018); Sung et al. (2018); Guo & Cheung (2020); Li et al.",
                "(2019); Chen et al. (2020), model optimization based methods Ravi & Larochelle (2016), metric learning based methods Vinyals et al.",
                "(2020) and methods which use ridge regression and support vector machine Bertinetto et al. (2018); Lee et al.",
                "(2019); Chen et al. (2020), model optimization based methods Ravi & Larochelle (2016), metric learning based methods Vinyals et al. (2016); Snell et al. (2017); Ren et al. (2018); Sung et al. (2018); Guo & Cheung (2020); Li et al. (2020) and methods which use ridge regression and support vector machine Bertinetto et al."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "96be96cbdd3e2ac4a2ff64e865c8b111e582b1f9",
                "externalIds": {
                    "CorpusId": 236921317
                },
                "corpusId": 236921317,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/96be96cbdd3e2ac4a2ff64e865c8b111e582b1f9",
                "title": "IMPROVE NOVEL CLASS GENERALIZATION BY ADAP-",
                "abstract": "In this work, we focus on improving the novel class generalization of few-shot learning. By addressing the difference between feature distributions of base and novel classes, we propose the adaptive feature distribution method which is to finetune one scale vector using the support set of novel classes. The scale vector is applied on the normalized feature distribution and by using one scale vector to reshape the feature space manifold, we obtain consistent performance improvement for both in-domain and cross-domain evaluations. By simply finetuning one scale vector using 5 images, we observe a 2.23% performance boost on 5-way 1-shot cross-domain evaluation with CUB over statistics results of 2000 episodes. This approach is simple yet effective. By just finetuning a single scale vector we provide a solution of reducing number of parameters while still obtain generalization ability for few-shot learning. We achieve the state-of-the-art performance on mini-Imagenet, tiered-Imagenet as well as cross-domain evaluation on CUB.",
                "year": 2020,
                "authors": []
            }
        },
        {
            "contexts": [
                "CIFAR-FS, on the other hand, is similar to miniImageNet, where the dataset is randomly split.",
                "In particular, miniImagenet meta-train set is used for meta-training, while corresponding meta-test splits of Omniglot [7], FC100 [12], and CIFAR-FS [3] are used for evaluation.",
                "B Additional Experiments on Few-Shot Classification We further validate the effectiveness of our proposed dynamic inner-loop update rule ALFA, through evaluating the performance on the relatively new CIFAR100-based [6] few-shot classification datasets: FC100 (Fewshot-CIFAR100) [12] and CIFAR-FS (CIFAR100 few-shots) [3].",
                "Table B: Test accuracy on 5-way classification for FC100 and CIFAR-FS.",
                "All models are only trained with miniImageNet meta-train set and tested on various datasets (domains) without any fine-tuning.\nminiImageNet\n\u2192 Omniglot \u2192 FC100 \u2192 CIFAR-FS ALFA + Random Init 91.02\u00b1 0.29% 62.49\u00b1 0.48% 63.49\u00b1 0.45% MAML [4] 85.68\u00b1 0.35% 55.52\u00b1 0.50% 55.82\u00b1 0.50% ALFA + MAML 93.11\u00b1 0.23% 60.12\u00b1 0.49% 59.76\u00b1 0.49% MAML + L2F [2] 94.96\u00b1 0.22% 61.99\u00b1 0.49% 63.73\u00b1 0.48% ALFA + MAML + L2F 94.10\u00b1 0.24% 63.33\u00b1 0.45% 63.87\u00b1 0.48%",
                "We further validate the effectiveness of our proposed dynamic inner-loop update rule ALFA, through evaluating the performance on the relatively new CIFAR100-based [6] few-shot classification datasets: FC100 (Fewshot-CIFAR100) [12] and CIFAR-FS (CIFAR100 few-shots) [3].",
                "Backbone FC100 CIFAR-FS\n1-shot 5-shot 1-shot 5-shot\nRandom Init 4-CONV 27.50\u00b1 0.45% 35.37\u00b1 0.48% 29.74\u00b1 0.46% 39.87\u00b1 0.49% ALFA + Random Init 4-CONV 38.20\u00b1 0.49% 52.98\u00b1 0.50% 60.56\u00b1 0.49% 75.43\u00b1 0.43% MAML \u2020 [4] 4-CONV 36.67\u00b1 0.48% 49.38\u00b1 0.49% 56.80\u00b1 0.49% 74.97\u00b1 0.43% ALFA + MAML 4-CONV 37.99\u00b1 0.48% 53.01\u00b1 0.49% 59.96\u00b1 0.49% 76.79\u00b1 0.42% MAML + L2F \u2020 [2] 4-CONV 38.96\u00b1 0.49% 53.23\u00b1 0.48% 60.35\u00b1 0.48% 76.76\u00b1 0.42% ALFA + MAML + L2F 4-CONV 38.50\u00b1 0.47% 53.20\u00b1 0.50% 60.36\u00b1 0.50% 76.60\u00b1 0.42% Random Init ResNet12 32.26\u00b1 0.47% 42.00\u00b1 0.49% 36.86\u00b1 0.48% 49.46\u00b1 0.50% ALFA + Random Init ResNet12 40.57\u00b1 0.49% 53.19\u00b1 0.50% 64.14\u00b1 0.48% 78.11\u00b1 0.41% MAML \u2020 ResNet12 37.92\u00b1 0.48% 52.63\u00b1 0.50% 64.33\u00b1 0.48% 76.38\u00b1 0.42% ALFA + MAML ResNet12 41.46\u00b1 0.49% 55.82\u00b1 0.50% 66.79\u00b1 0.47% 83.62\u00b1 0.37% MAML + L2F \u2020 ResNet12 41.89\u00b1 0.47% 54.68\u00b1 0.50% 67.48\u00b1 0.46% 82.79\u00b1 0.38% ALFA + MAML + L2F ResNet12 42.37\u00b1 0.50% 55.23\u00b1 0.50% 68.25\u00b1 0.47% 82.98\u00b1 0.38% Prototypical Networks\u2217 [17] 4-CONV 35.3\u00b1 0.6% 48.6\u00b1 0.6% 55.5\u00b1 0.7% 72.0\u00b1 0.6% Relation Networks [18] 4-CONV+ - - 55.0\u00b1 1.0 69.3\u00b1 0.8 TADAM [12] ResNet12 40.1\u00b1 0.4% 56.1\u00b1 0.4% - - MetaOpt \u2021 [8] ResNet12 41.1\u00b1 0.6% 55.5\u00b1 0.6% 72.0\u00b1 0.7% 84.2\u00b1 0.5%\n* Meta-network is trained using the union of meta-training set and meta-validation set."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "6c91669ce358ff78cdc1e648d4ca9a2c0381319e",
                "externalIds": null,
                "corpusId": "260440206",
                "publicationVenue": null,
                "url": "http://www.semanticscholar.org/paper/6c91669ce358ff78cdc1e648d4ca9a2c0381319e",
                "title": "Meta-Learning with Adaptive Hyperparameters \u2013 Supplementary Document \u2013",
                "abstract": null,
                "year": 2020,
                "authors": []
            }
        },
        {
            "contexts": [
                "Our results on three few-shot benchmark datasets \u2013 miniImageNet, CIFAR-FS, and FC100 \u2013 showed that MABAS significantly enhanced the performance of the base methods with various characteristics, and consequently achieved the state-of-the-art performance in several tasks.",
                "This class split is designed to minimize the overlap of information between all three subsets, to be more challenging than CIFAR-FS for few-shot learning.",
                "Our experiments demonstrate that MABAS provides all of the three few-shot learners with significant performance gains and achieves the state-of-the-art\nperformance in a number of tasks on three benchmarks: miniImageNet [45], CIFAR-FS [3] and FC100 [34].",
                "performance in a number of tasks on three benchmarks: miniImageNet [45], CIFAR-FS [3] and FC100 [34].",
                "Our method achieves the new state-of-the-art performance on four of the six tasks (miniImageNet 5-shot, CIFAR-FS 1-shot and 5-shot, and FC100 5-shot settings) if we exclude the methods with WRN-28-10 [50], which consumes about three times more parameters than ResNet-12 [22].",
                "(2) CIFAR-FS [3] splits all of the classes in CIFAR100 [20] into 64 training, 16 validation and 20 test sets, respectively."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "c3868028316e6d5d3650103e0c74e4088e1ce260",
                "externalIds": {
                    "DBLP": "conf/eccv/KimKK20a",
                    "MAG": "3095388829",
                    "DOI": "10.1007/978-3-030-58452-8_35",
                    "CorpusId": 226239557
                },
                "corpusId": 226239557,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/c3868028316e6d5d3650103e0c74e4088e1ce260",
                "title": "Model-Agnostic Boundary-Adversarial Sampling for Test-Time Generalization in Few-Shot Learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "65924935",
                        "name": "Jaekyeom Kim"
                    },
                    {
                        "authorId": "2141827144",
                        "name": "Hyoungseok Kim"
                    },
                    {
                        "authorId": "1743920",
                        "name": "Gunhee Kim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We ran experiments on Omniglot [14], CIFAR-FS [2], and miniImageNet [24], which are popular benchmark datasets used for few-shot learning.",
                "The dimension of the final\nCNN layer is 256, 256, and 288 for Omniglot, CIFAR-FS, and miniImageNet, respectively.",
                "After the meta-training of OOD-MAML with benchmark dataset (CIFAR-FS), we compared the extracted features of in-distribution samples, OOD samples, \u03b8fake, and \u03b8ifake on both \u03b8fake-classifier and (\u03b8fake + \u03b8ifake)-classifier.",
                "Each module consists of 3\u00d7 3 convolutions and 64 filters for Omniglot and CIFAR-FS, and 32 filters for miniImageNet, which are followed by batch normalization [12], the exponential linear units (ELU) activation function [6], and max-pooling with 2\u00d7 2 stride and padding.",
                "Our base model in both OOD-MAML and MAML has a convolution neural network (CNN) architecture, which has four modules for Omniglot and CIFAR-FS and five modules for miniImageNet."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "2b088b9b1abc84bb207396b440527219277e2718",
                "externalIds": {
                    "MAG": "3102719996",
                    "DBLP": "conf/nips/JeongK20",
                    "CorpusId": 227275366
                },
                "corpusId": 227275366,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/2b088b9b1abc84bb207396b440527219277e2718",
                "title": "OOD-MAML: Meta-Learning for Few-Shot Out-of-Distribution Detection and Classification",
                "abstract": "We propose a few-shot learning method for detecting out-of-distribution (OOD) samples from classes that are unseen during training while classifying samples from seen classes using only a few labeled examples. For detecting unseen classes while generalizing to new samples of known classes, we synthesize fake samples, i.e., OOD samples, but that resemble in-distribution samples, and use them along with real samples. Our approach is based on an extension of model-agnostic meta learning (MAML) and is denoted as OOD-MAML, which not only learns a model initialization but also the initial fake samples across tasks. The learned initial fake samples can be used to quickly adapt to new tasks to form task-speci\ufb01c fake samples with only one or a few gradient update steps using MAML. For testing, OOD-MAML converts a K -shot N -way classi\ufb01cation task into N sub-tasks of K -shot OOD detection with respect to each class. The joint analysis of N sub-tasks facilitates simultaneous classi\ufb01cation and OOD detection and, furthermore, offers an advantage, in that it does not require re-training when the number of classes for a test task differs from that for training tasks; it is suf\ufb01cient to simply assume as many sub-tasks as the number of classes for the test task. We also demonstrate the effective performance of OOD-MAML over benchmark datasets.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2066605641",
                        "name": "Taewon Jeong"
                    },
                    {
                        "authorId": "2108873782",
                        "name": "Heeyoung Kim"
                    }
                ]
            }
        },
        {
            "contexts": [
                "On Omniglot and CIFAR-FS, we only report ours (Reptile) due to its low computation cost.",
                "\u2026Prototypical Networks (Snell et al., 2017), which uses the Euclidean distance to compute the similarity, Relation Network (Sung et al., 2017), which uses a relation module as the similarity function, ridge regression (Bertinetto et al., 2018), and graph neural networks (Satorras & Estrach, 2018).",
                ", 2017), which uses a relation module as the similarity function, ridge regression (Bertinetto et al., 2018), and graph neural networks (Satorras & Estrach, 2018).",
                "CIFAR-FS re-purposes CIFAR-100 (Krizhevsky & Hinton, 2009), splitting its 100 classes into 64, 16, and 20 classes for meta-training, meta-validation, and meta-test, respectively.",
                "We experiment with four datasets for few-shot learning: Omniglot (Lake et al., 2011), MiniImageNet (Vinyals et al., 2016b), TieredImageNet (Ren et al., 2018a), and CIFAR-FS (Bertinetto et al., 2018)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "ac8fca7c3b9c5a5f88f75e1fff75d8bb78de8261",
                "externalIds": {
                    "CorpusId": 231816492
                },
                "corpusId": 231816492,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/ac8fca7c3b9c5a5f88f75e1fff75d8bb78de8261",
                "title": "\u2205 2 \u2205 3 ! MAML 1 \u2205 \u2205 2 \u2205 3 ! Implicit MAML ComputationTask-specific parameter 1 \u2205 \u2205 2 \u2205 3 ! \u201c Lazy \u201d MAML",
                "abstract": "Gradient-based meta-learning relates task-specific models to a meta-model by gradients. By this design, an algorithm first optimizes the task-specific models by an inner loop and then backpropagates meta-gradients through the loop to update the meta-model. The number of inner-loop optimization steps has to be small (e.g., one step) to avoid high-order derivatives, big memory footprints, and the risk of vanishing or exploding meta-gradients. We propose an intuitive teacherstudent scheme to enable the gradient-based meta-learning algorithms to explore long horizons by the inner loop. The key idea is to employ a student network to adequately explore the search space of task-specific models (e.g., by more than ten steps), and a teacher then takes a \u201cleap\u201d toward the regions probed by the student. The teacher not only arrives at a high-quality model but also defines a lightweight computation graph for meta-gradients. Our approach is generic; it performs well when applied to four meta-learning algorithms over three tasks: few-shot learning, long-tailed classification, and meta-attack.",
                "year": 2020,
                "authors": []
            }
        },
        {
            "contexts": [
                "Extended Experiments on Classification To further validate that our method consistently provides benefits regardless of scenarios, we compare our method against the baseline on additional datasets that have been recently introduced: FC100 (Fewshot-CIFAR100) [7] and CIFAR-FS (CIFAR100 few-shots) [1]."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1ace59babbd6de407e35e3411f0d1dcf09bed87c",
                "externalIds": {
                    "CorpusId": 219630976
                },
                "corpusId": 219630976,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1ace59babbd6de407e35e3411f0d1dcf09bed87c",
                "title": "Learning to Forget for Meta-Learning Supplementary Materials",
                "abstract": "In [11], they analyze the stability and smoothness of the optimization landscape by measuring Lipschitzness and the \u201ceffective\u201d \u03b2-smoothness of loss. We use these measurements to analyze learning dynamics for both MAML and our proposed method during training on 5-way 5-shot miniImageNet classification tasks. In Figure A, we start with investigating fast-adaptation (or inner-loop) optimization. At each inner-loop update step, we measure variations in loss (Figure A(a)), the l2 difference in gradients (Figure A(b)), and the maximum difference in gradient over the distance (Figure A(c)), as we move to different points along the computed gradient for that gradient descent. We take an average of these values over the number of inner-loop updates and plot them against training iterations. With a similar approach, we also analyze the optimization stability of fast adaptation to validation tasks at every epoch (Figure B). The measurements were averaged over (the number of validation tasks \u00d7 the number of inner-loop update steps). At the initial stages of training, L2F appears to struggle more, while optimization of MAML seems more stable. This may seem contradictory at first but this actually validates our argument about conflicts between tasks even further. At the beginning, the MAML initialization is not trained enough and thus does not have sufficient prior knowledge of task distribution yet. As training proceeds, the initialization encodes more information about task distribution and encounters conflicts between tasks more frequently. As for L2F, the attenuator network g\u03c6 initially does not have enough knowledge about the task distribution and thus generates meaningless attenuation \u03b3, deteriorating the initialization. But, the attenuator network increasingly encodes more information about the task distribution, generating more appropriate attenuation \u03b3 that corresponds to tasks well. The generated \u03b3 accordingly allows for a learner to forget the irrelevant part of prior knowledge to help fast adaptation, as illustrated by increasing stability and smoothness of landscape in Figure A. The similar observation can be made from B, illustrating the generalizability and the robustness of the proposed method to unseen tasks. We also investigate the optimization landscape of learning the initialization \u03b8 itself for both MAML and L2F in Figure C. The figure demonstrates that the more stable and smoother landscape is realized by L2F. Because the taskdependent layer-wise attenuation allows for forgetting the irrelevant or conflicting part of prior knowledge present in the initialization \u03b8, it lifts a burden of trying to resolve conflicts between tasks from \u03b8, allowing for more stable training of the initialization itself.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "148009160",
                        "name": "Sungyong Baik"
                    },
                    {
                        "authorId": "150297656",
                        "name": "Seokil Hong"
                    },
                    {
                        "authorId": "2135837",
                        "name": "Kyoung Mu Lee"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dbcbdada13c7d643e240b6da8faf980b260b0780",
                "externalIds": {
                    "DBLP": "journals/staeors/GaoGYLYW20",
                    "MAG": "3036632808",
                    "DOI": "10.1109/JSTARS.2020.3002787",
                    "CorpusId": 220366810
                },
                "corpusId": 220366810,
                "publicationVenue": {
                    "id": "849b6687-df71-4d12-9c46-59f45d5ce951",
                    "name": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
                    "type": "journal",
                    "alternate_names": [
                        "IEEE J Sel Top Appl Earth Obs Remote Sens"
                    ],
                    "issn": "1939-1404",
                    "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=4609443",
                    "alternate_urls": [
                        "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4609443"
                    ]
                },
                "url": "https://www.semanticscholar.org/paper/dbcbdada13c7d643e240b6da8faf980b260b0780",
                "title": "Deep Induction Network for Small Samples Classification of Hyperspectral Images",
                "abstract": "Recently, the deep learning models have achieved great success in hyperspectral images (HSI) classification. However, most of the deep learning models fail to obtain satisfactory results under the condition of small samples due to the contradiction between the large parameter space of the deep learning models and the insufficient labeled samples in HSI. To address the problem, a deep model based on the induction network is designed in this article to improve the classification performance of HSI under the condition of small samples. Specifically, the typical meta-training strategy is adopted, enabling the model to acquire stronger generalization ability, so as to accurately distinguish the new classes with only a few labeled samples (e.g., five samples per class). Moreover, in order to deal with the disturbance caused by the various characteristics of the samples in the same class in HSI, the class-wise induction module is introduced utilizing the dynamic routing algorithm, which can induce the sample-wise representations to the class-wise level representations. The obtained class-wise level representations possess better separability, allowing the designed model to generate more accurate and robust classification results. Extensive experiments are carried out on three public HSI to verify the effectiveness of the proposed method. The results demonstrate that our method outperforms existing deep learning methods under the condition of small samples.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "121145046",
                        "name": "Kuiliang Gao"
                    },
                    {
                        "authorId": "1780948108",
                        "name": "Wenyue Guo"
                    },
                    {
                        "authorId": "1829252",
                        "name": "Xuchu Yu"
                    },
                    {
                        "authorId": "2149123909",
                        "name": "Bing Liu"
                    },
                    {
                        "authorId": "9759716",
                        "name": "Anzhu Yu"
                    },
                    {
                        "authorId": "40808536",
                        "name": "Xiangpo Wei"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "1fd96af3a684b04b257e0063d15667cb1e8acb03",
                "externalIds": {
                    "MAG": "3095891659",
                    "DBLP": "conf/eccv/SimonKNH20",
                    "DOI": "10.1007/978-3-030-58598-3_33",
                    "CorpusId": 221669134
                },
                "corpusId": 221669134,
                "publicationVenue": {
                    "id": "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                    "name": "European Conference on Computer Vision",
                    "type": "conference",
                    "alternate_names": [
                        "ECCV",
                        "Eur Conf Comput Vis"
                    ],
                    "url": "https://link.springer.com/conference/eccv"
                },
                "url": "https://www.semanticscholar.org/paper/1fd96af3a684b04b257e0063d15667cb1e8acb03",
                "title": "On Modulating the Gradient for Meta-learning",
                "abstract": null,
                "year": 2020,
                "authors": [
                    {
                        "authorId": "144616396",
                        "name": "Christian Simon"
                    },
                    {
                        "authorId": "2155775",
                        "name": "Piotr Koniusz"
                    },
                    {
                        "authorId": "1718786",
                        "name": "R. Nock"
                    },
                    {
                        "authorId": "1686714",
                        "name": "M. Harandi"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Standard meta learning models utilizes gradient ascent/descent techniques to compute the updated parameters on new tasks [23, 3, 42, 56].",
                "Meta learning techniques aim to train a general model with general parameters that can quickly adapt to a variety of new learning tasks with refined parameters [23, 3, 42, 56]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "8779238f73d401d24f00858db6360799aa70ae7f",
                "externalIds": {
                    "CorpusId": 228216692
                },
                "corpusId": 228216692,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/8779238f73d401d24f00858db6360799aa70ae7f",
                "title": "To appear in Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 (NeurIPS\u201920). Adversarial Attacks on Deep Graph Matching",
                "abstract": "Despite achieving remarkable performance, deep graph learning models, such as node classification and network embedding, suffer from harassment caused by small adversarial perturbations. However, the vulnerability analysis of graph matching under adversarial attacks has not been fully investigated yet. This paper proposes an adversarial attack model with two novel attack techniques to perturb the graph structure and degrade the quality of deep graph matching: (1) a kernel density estimation approach is utilized to estimate and maximize node densities to derive imperceptible perturbations, by pushing attacked nodes to dense regions in two graphs, such that they are indistinguishable from many neighbors; and (2) a meta learning-based projected gradient descent method is developed to well choose attack starting points and to improve the search performance for producing effective perturbations. We evaluate the effectiveness of the attack model on real datasets and validate that the attacks can be transferable to other graph learning models.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1942180",
                        "name": "Zijie Zhang"
                    },
                    {
                        "authorId": "122542578",
                        "name": "Zeru Zhang"
                    },
                    {
                        "authorId": "2145499198",
                        "name": "Yang Zhou"
                    },
                    {
                        "authorId": "1752875",
                        "name": "Yelong Shen"
                    },
                    {
                        "authorId": "1740308",
                        "name": "R. Jin"
                    },
                    {
                        "authorId": "1721158",
                        "name": "D. Dou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "CIFAR-FS [2] contains 100 classes with the class split for (64,16,20).",
                "We further conduct FSOR experiments on two fewshot benchmark datasets: CIFAR-FS [2], FC100 [29]."
            ],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5f2cd3f4d504c27dd8609baedb82968cca4d1c8d",
                "externalIds": {
                    "DBLP": "journals/corr/abs-2012-13073",
                    "CorpusId": 229371268
                },
                "corpusId": 229371268,
                "publicationVenue": {
                    "id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
                    "name": "arXiv.org",
                    "alternate_names": [
                        "ArXiv"
                    ],
                    "issn": "2331-8422",
                    "url": "https://arxiv.org"
                },
                "url": "https://www.semanticscholar.org/paper/5f2cd3f4d504c27dd8609baedb82968cca4d1c8d",
                "title": "Task-Adaptive Negative Class Envision for Few-Shot Open-Set Recognition",
                "abstract": "We study the problem of few-shot open-set recognition (FSOR), which learns a recognition system capable of both fast adaptation to new classes with limited labeled examples and rejection of unknown negative samples. Tradi-tional large-scale open-set methods have been shown in-effective for FSOR problem due to data limitation. Current FSOR methods typically calibrate few-shot closed-set classi\ufb01ers to be sensitive to negative samples so that they can be rejected via thresholding. However, threshold tuning is a challenging process as different FSOR tasks may require different rejection powers. In this paper, we instead propose task-adaptive negative class envision for FSOR to integrate threshold tuning into the learning process. Speci\ufb01cally, we augment the few-shot closed-set classi\ufb01er with additional negative prototypes generated from few-shot examples. By incorporating few-shot class correlations in the negative generation process, we are able to learn dynamic rejection boundaries for FSOR tasks. Besides, we extend our method to generalized few-shot open-set recognition (GF-SOR), which requires classi\ufb01cation on both many-shot and few-shot classes as well as rejection of negative samples. Extensive experiments on public benchmarks validate our methods on both problems. 1",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2110443113",
                        "name": "Shiyuan Huang"
                    },
                    {
                        "authorId": "152320135",
                        "name": "Jiawei Ma"
                    },
                    {
                        "authorId": "2067641876",
                        "name": "G. Han"
                    },
                    {
                        "authorId": "9546964",
                        "name": "Shih-Fu Chang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "One is gradient-based method that empower the model with ability to rapidly fine-tune to novel classes with limited labeled images (Finn et al., 2017; Ravi & Larochelle, 2017; Rusu et al., 2019; Bertinetto et al., 2019; Lee et al., 2019)."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "e8fcf8f5c47bfbcffcb19bc67ffa6870d7a56b82",
                "externalIds": {
                    "CorpusId": 231401334
                },
                "corpusId": 231401334,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/e8fcf8f5c47bfbcffcb19bc67ffa6870d7a56b82",
                "title": "A UTO-VIEW CONTRASTIVE LEARNING FOR FEW-SHOT IMAGE RECOGNITION",
                "abstract": "Few-shot learning aims to recognize new classes with few annotated instances within each category. Recently, metric-based meta-learning approaches have shown the superior performance in tackling few-shot learning problems. Despite their success, existing metric-based few-shot approaches often fail to push the fine-grained sub-categories apart in the embedding space given no fine-grained labels. This may result in poor generalization to fine-grained sub-categories, and thus affects model interpretation. To alleviate this problem, we introduce contrastive loss into few-shot classification for learning latent fine-grained structure in the embedding space. Furthermore, to overcome the drawbacks of random image transformation used in current contrastive learning in producing noisy and inaccurate image pairs (i.e., views), we develop a learning-to-learn algorithm to automatically generate different views of the same image. Extensive experiments on standard few-shot learning benchmarks and few-shot fine-grained image classification demonstrate the superiority of our method.",
                "year": 2020,
                "authors": []
            }
        },
        {
            "contexts": [
                "Standard meta learning models utilizes gradient ascent/descent techniques to compute the updated parameters on new tasks [23, 3, 42, 56].",
                "Meta learning techniques aim to train a general model with general parameters that can quickly adapt to a variety of new learning tasks with refined parameters [23, 3, 42, 56]."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "0684ac9c25354d2360bae182f3dc266eb748639c",
                "externalIds": {
                    "DBLP": "conf/nips/ZhangZ0SJD20",
                    "MAG": "3104173740",
                    "CorpusId": 227276294
                },
                "corpusId": 227276294,
                "publicationVenue": {
                    "id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                    "name": "Neural Information Processing Systems",
                    "type": "conference",
                    "alternate_names": [
                        "Neural Inf Process Syst",
                        "NeurIPS",
                        "NIPS"
                    ],
                    "url": "http://neurips.cc/"
                },
                "url": "https://www.semanticscholar.org/paper/0684ac9c25354d2360bae182f3dc266eb748639c",
                "title": "Adversarial Attacks on Deep Graph Matching",
                "abstract": "Despite achieving remarkable performance, deep graph learning models, such as node classi\ufb01cation and network embedding, suffer from harassment caused by small adversarial perturbations. However, the vulnerability analysis of graph matching under adversarial attacks has not been fully investigated yet. This paper proposes an adversarial attack model with two novel attack techniques to perturb the graph structure and degrade the quality of deep graph matching: (1) a kernel density estimation approach is utilized to estimate and maximize node densities to derive imperceptible perturbations, by pushing attacked nodes to dense regions in two graphs, such that they are indistinguishable from many neighbors; and (2) a meta learning-based projected gradient descent method is developed to well choose attack starting points and to improve the search performance for producing effective perturbations. We evaluate the effectiveness of the attack model on real datasets and validate that the attacks can be transferable to other graph learning models.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1942180",
                        "name": "Zijie Zhang"
                    },
                    {
                        "authorId": "122542578",
                        "name": "Zeru Zhang"
                    },
                    {
                        "authorId": "2145499198",
                        "name": "Yang Zhou"
                    },
                    {
                        "authorId": "1752875",
                        "name": "Yelong Shen"
                    },
                    {
                        "authorId": "1740308",
                        "name": "R. Jin"
                    },
                    {
                        "authorId": "1721158",
                        "name": "D. Dou"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Bertinetto et al. (2018) resized all the images to 32\u00d7 32 and divided this dataset into 64 classes for meta-training, 16 classes for meta-validation, and 20 classes for meta-testing."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "5f0c6b858396524ee5096d47f627d8abeeef349f",
                "externalIds": {
                    "CorpusId": 234100056
                },
                "corpusId": 234100056,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/5f0c6b858396524ee5096d47f627d8abeeef349f",
                "title": "A Pseudo-code of OOD-MAML",
                "abstract": "Algorithm 1 OOD-MAML with K-shot training samples Require: p(T ): distribution over tasks of OOD detection Require: \u03b1,\u03b3 > 0: hyper-parameter 1: randomly initialize \u03b8, \u03b8fake and \u03b2fake 2: while not done do 3: Sample batch of Ti \u223c p(T ) 4: for all Ti do 5: Sample K data points D train = {x1,x2, . . . ,xK} 6: First update \u03b8 with Eq.(1): \u03b8 = \u03b8 \u2212 \u03b1\u2207\u03b8L\u03b8;Ti(D train, \u03b8fake) 7: Update \u03b8fake with Eq.(2): \u03b8 fake = \u03b8fake \u2212 \u03b2fake sign(\u2212\u2207\u03b8fakeL\u03b8i;Ti(D train, \u03b8fake)) 8: Compute the final adapted base parameter \u03b8 adapt, with Eq.(3): \u03b8 adapt = \u03b8 \u2212 \u03b1\u2207\u03b8L\u03b8i;Ti(D train, (\u03b8fake, \u03b8 fake)) 9: Sample data points D test = {(x1, y 1), (x2, y 2), . . . , (xQ, y Q)} from Ti for meta-update 10: end for 11: update \u03b8 \u2190 \u03b8 \u2212 \u03b3\u2207\u03b8 \u2211 Ti\u223cP (T ) L(D i test) where \u03b8 = (\u03b8b, \u03b8fake, \u03b2fake) 12: end while",
                "year": 2020,
                "authors": []
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "dc0137dae1b0bc0eed6805a1b7b691775d960e5d",
                "externalIds": {
                    "CorpusId": 244951499
                },
                "corpusId": 244951499,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/dc0137dae1b0bc0eed6805a1b7b691775d960e5d",
                "title": "Fit The Right NP-Hard Problem: End-to-end Learning of Integer Programming Constraints",
                "abstract": "Bridging logical and algorithmic reasoning with modern machine learning techniques is a fundamental challenge with potentially transformative impact. On the algorithmic side, many NP-Hard problems can be expressed as integer programs, in which the constraints play the role of their \u201ccombinatorial specification\u201d. In this work, we aim to integrate integer programming solvers into neural network architectures by providing loss functions for both the objective and the constraints. The resulting end-to-end trainable architectures have the power of jointly extracting features from raw data and of solving a suitable (learned) combinatorial problem with state-of-the-art integer programming solvers. We experimentally validate our approach on artificial datasets created from random constraints, and on solving KNAPSACK instances from their description in natural language.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "1443432623",
                        "name": "Anselm Paulus"
                    },
                    {
                        "authorId": "2753055",
                        "name": "Michal Rolinek"
                    },
                    {
                        "authorId": "153431278",
                        "name": "V\u00edt Musil"
                    },
                    {
                        "authorId": "1773498",
                        "name": "Brandon Amos"
                    },
                    {
                        "authorId": "144247521",
                        "name": "G. Martius"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We perform extensive experiments on two popular few-shot learning benchmarks, MiniImagenet (Snell et al., 2017), and CIFAR-FS (Bertinetto et al., 2018).",
                "And CIFAR-FS benchmark is much more chanllenging than Mini-Imagenet due to its more constrained splits between training set and test set and lower image resolution."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "78256739af4f39aa8eaed9c370033aa38130c296",
                "externalIds": {
                    "CorpusId": 248384530
                },
                "corpusId": 248384530,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/78256739af4f39aa8eaed9c370033aa38130c296",
                "title": "Boosting Transferable Meta-learning via Unsupervised Visual Representation",
                "abstract": "Deep neural network have been widely used in image classi\ufb01cation, but it requires a lot of labeled data to train to obtain a higher accuracy rate. However, extensive data acquisition and manual label annotation are expensive. Therefore, few-shot classi\ufb01cation is of crucial signi\ufb01cance which aims to recognize novel categories with only few labeled data. Many existing few-shot classi\ufb01cation algorithms predict categories by comparing the feature embeddings of query images which are not good enough with those from a few labeled images (support examples) or using full connected layer to classify. In this paper, we propose a learning method to obtain better features by \ufb01ne-tuning Deep neural network using transferable meta-learning. In addition, we exploit the complementarity of few-shot learning and self-supervision learning and use self-supervision as an auxiliary task in a few-shot learning pipeline, enabling feature extractors to learn richer and more transferable visual representations while still using few annotated samples. We conduct extensive experiments using two challenging few-shot learning bench-marks: Mini-Imagenet and Fewshot-CIFAR100. Experimental results have proved the effectiveness of our method and perfect performance on benchmarks.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2152943153",
                        "name": "Fengqi Liu"
                    },
                    {
                        "authorId": "2112119393",
                        "name": "Mingjie Li"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Others relate to Prototypical Networks by learning a representation on which differentiable training can be performed on some form of classifier (Bertinetto et al., 2019; Gidaris & Komodakis, 2018; Oreshkin et al., 2018).",
                "Larger-scale few-shot classification benchmarks were also proposed using CIFAR-100 (Krizhevsky et al., 2009; Bertinetto et al., 2019; Oreshkin et al., 2018), tiered-ImageNet (Ren et al.",
                "Larger-scale few-shot classification benchmarks were also proposed using CIFAR-100 (Krizhevsky et al., 2009; Bertinetto et al., 2019; Oreshkin et al., 2018), tiered-ImageNet (Ren et al., 2018), and ImageNet-21k (Dhillon et al., 2019)."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "d2b8a907fe4b9e1178110a2cf1aeb3cb762487bc",
                "externalIds": {
                    "CorpusId": 251925527
                },
                "corpusId": 251925527,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d2b8a907fe4b9e1178110a2cf1aeb3cb762487bc",
                "title": "M ETA -D ATASET : A D ATASET OF D ATASETS FOR L EARNING TO L EARN FROM F EW E XAMPLES",
                "abstract": "Few-shot classification refers to learning a classifier for new classes given only a few examples. While a plethora of models have emerged to tackle it, we find the procedure and datasets that are used to assess their progress lacking. To address this limitation, we propose META-DATASET: a new benchmark for training and evaluating models that is large-scale, consists of diverse datasets, and presents more realistic tasks. We experiment with popular baselines and meta-learners on META-DATASET, along with a competitive method that we propose. We analyze performance as a function of various characteristics of test tasks and examine the models\u2019 ability to leverage diverse training sources for improving their generalization. We also propose a new set of baselines for quantifying the benefit of meta-learning in META-DATASET. Our extensive experimentation has uncovered important research challenges and we hope to inspire work in these directions.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "8791781",
                        "name": "Tyler Lixuan Zhu"
                    },
                    {
                        "authorId": "3074927",
                        "name": "Vincent Dumoulin"
                    },
                    {
                        "authorId": "3087941",
                        "name": "Pascal Lamblin"
                    },
                    {
                        "authorId": "3399348",
                        "name": "Utku Evci"
                    },
                    {
                        "authorId": "36303818",
                        "name": "Kelvin Xu"
                    },
                    {
                        "authorId": "2558463",
                        "name": "Ross Goroshin"
                    },
                    {
                        "authorId": "1754860",
                        "name": "Kevin Swersky"
                    },
                    {
                        "authorId": "1798462",
                        "name": "Pierre-Antoine Manzagol"
                    },
                    {
                        "authorId": "1777528",
                        "name": "H. Larochelle"
                    }
                ]
            }
        },
        {
            "contexts": [
                "It can be seen that our AdarGCN FSL method yields 2\u20135% improvements over the latest GCN-based FSL methods [9, 6, 5] and 2\u20137% improvements over the state-of-theart FSL baselines [8, 2, 1, 3, 7], validating the effectiveness of our AdarGCN module under one-shot setting."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "b946d948e6d9862ed9f7d64aff21204299d47270",
                "externalIds": {
                    "CorpusId": 260531890
                },
                "corpusId": 260531890,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/b946d948e6d9862ed9f7d64aff21204299d47270",
                "title": "AdarGCN: Adaptive Aggregation GCN for Few-Shot Learning \u2013 Supplementary Material \u2013",
                "abstract": "In this document, we provide more supporting results to show the effectiveness of our AdarGCN under both the new SSFSL and conventional FSL settings. Firstly, we illustrate the cleaned examples and the removed examples (i.e. noise) obtained by our AdarGCN-based label denoising (LDN) method under the new SSFSL setting. Secondly, we present the weight distributions of outlying examples obtained by our AdarGCN-based FSL method under the conventional FSL setting. These qualitative results (shown in Sections 1 and 2) suggest that our AdarGCN can effectively deal with both noisy and outlying images, explaining its superior performance under both FSL settings. Thirdly, we report some quantitative 5-way 1-shot results under the conventional FSL setting, together with the 5-way 5-shot results in the main paper,to validate the effectiveness of our AdarGCN with different 5-way settings.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "2108239433",
                        "name": "Jianhong Zhang"
                    },
                    {
                        "authorId": "151483168",
                        "name": "Manli Zhang"
                    },
                    {
                        "authorId": "1776220",
                        "name": "Zhiwu Lu"
                    },
                    {
                        "authorId": "2167762316",
                        "name": "Tao Xiang"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "7440027dd478779de66f676e49b12a0936e01936",
                "externalIds": {
                    "CorpusId": 261053409
                },
                "corpusId": 261053409,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/7440027dd478779de66f676e49b12a0936e01936",
                "title": "Open-Set Incremental Learning via Bayesian Prototypical Embeddings",
                "abstract": "As autonomous decision-making agents move from narrow operating environments to unstructured worlds, learning systems must move from a closed-world formulation to an open-world, lifelong, few-shot setting in which agents continuously learn new classes from small amounts of information. This stands in stark contrast to modern machine learning systems that are typically designed with a known set of classes and a large number of examples for each class. In this work we extend embedding-based few-shot learning algorithms toward open-world problems. We combine Bayesian non-parametric class priors with an embedding-based pre-training scheme to yield a highly \ufb02exible framework for use in both the lifelong and the incremental settings. We benchmark our framework on miniImageNet and TieredImageNet in the lifelong setting. Our results show, compared to prior methods, up to a 14% classi\ufb01cation accuracy improvement from our novel pretraining scheme and up to a 22% improvement in AUROC (a measure of novel class detection) from our non-parametric few-shot learning scheme.",
                "year": 2020,
                "authors": [
                    {
                        "authorId": "114401442",
                        "name": "John Willes"
                    },
                    {
                        "authorId": "2106702981",
                        "name": "James Harrison"
                    },
                    {
                        "authorId": "2006610",
                        "name": "Ali Harakeh"
                    },
                    {
                        "authorId": "46881670",
                        "name": "Chelsea Finn"
                    },
                    {
                        "authorId": "1696085",
                        "name": "M. Pavone"
                    },
                    {
                        "authorId": "145292735",
                        "name": "Steven L. Waslander"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Then, we amend this MAML implementation to reproduce the results on the new CIFAR-FS dataset proposed by their paper (Bertinetto et al. [2019]). When reproducing the R2D2 algorithm, our first consideration is that the feature extractors in MAML and R2D2 are very different. MAML uses four convolutional blocks with an organization of [32, 32, 32, 32] filters. Whereas, R2D2\u2019s four blocks employ a [96, 192, 384, 512] scheme, as shown in Figure 3. In other words, the feature extractor in R2D2 is more complex hence is expected to yield better results (Mhaskar et al. [2016]).",
                "In this work we reproduce the paper of Bertinetto et al. [2019] (referenced as \"their paper\"); it falls into the class of gradient-based meta-learning algorithms that learn a model parameter intialization for rapid fine-tuning with a few shots (Finn et al.",
                "com/ArnoutDevos/maml-CIFAR-FS (4)Bertinetto et al. [2019] code: https://github.",
                "In this work we reproduce the paper of Bertinetto et al. [2019] (referenced as \"their paper\"); it falls into the class of gradient-based meta-learning algorithms that learn a model parameter intialization for rapid fine-tuning with a few shots (Finn et al. [2017], Nichol and Schulman [2018]).",
                "Then, we amend this MAML implementation to reproduce the results on the new CIFAR-FS dataset proposed by their paper (Bertinetto et al. [2019]).",
                "3 Analysis of the R2D2 Classifier In their paper, Bertinetto et al. [2019] present a new approach that relies on using fast and simple base learners such as ridge regression differentiable discriminator (R2D2) or (regularized) logistic regression differentiable discriminator (LRD2).",
                "Then, we amend this MAML implementation to reproduce the results on the new CIFAR-FS dataset proposed by their paper (Bertinetto et al. [2019]). When reproducing the R2D2 algorithm, our first consideration is that the feature extractors in MAML and R2D2 are very different. MAML uses four convolutional blocks with an organization of [32, 32, 32, 32] filters. Whereas, R2D2\u2019s four blocks employ a [96, 192, 384, 512] scheme, as shown in Figure 3. In other words, the feature extractor in R2D2 is more complex hence is expected to yield better results (Mhaskar et al. [2016]). In order to provide a meaningful comparison, we implement and evaluate both the simple and more complex feature extractors for the R2D2 algorithm, denoted by R2D2* and R2D2 respectively. In order to make a working reproduction of their paper we had to make the following assumptions. We first considered the aforementioned complex architecture and feature extractor. In particular, for the feature extractor, we made assumptions on the convolutional block options. We considered a 3x3 convolution block with a \u2019same\u2019 padding and a stride of 1. For the 2x2 maximum pooling, we use a stride of 2 and no padding. Second, concerning the ridge regression base-learner, we opted for a multinomial regression that returns the class with the maximum value through one-hot encoding. Following the guidelines for the feature extractor presented in Section 4.2 of their paper, we were not successful in reproducing the exact number of features at the output of the feature extractor. In their paper, the overall numbers of features at the output of the extractor are 3584, 72576 and 8064 for Omniglot, miniImageNet and CIFAR-FS, respectively. However, by implementing the feature extractor described in their paper, we obtain 3988, 51200 and 8192 respectively. For comparison purposes, we use the same number of classes (e.g. 5) and shots during (e.g. 1) training and testing, despite their paper using a higher number of classes during training (16 for miniImageNet, 20 for CIFAR-FS) than during testing (5 for miniImageNet and CIFAR-FS). Regarding the amount of shots, their paper uses a random number of shots during training. This is different from the way most baselines are trained using the same number of shots per class during training and testing (Finn [2018], Nichol and Schulman [2018], Vinyals et al.",
                "In this paper, we present a reproduction of the paper of Bertinetto et al. [2019] \"Meta-learning with differentiable closed-form solvers\" as part of the ICLR 2019 Reproducibility Challenge."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "8eda53960a582ad2072d90a03f1323c19c83148a",
                "externalIds": {
                    "MAG": "2965122203",
                    "DBLP": "conf/iclr/DevosCG19",
                    "CorpusId": 198488680
                },
                "corpusId": 198488680,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/8eda53960a582ad2072d90a03f1323c19c83148a",
                "title": "Reproducing Meta-learning with differentiable closed-form solvers",
                "abstract": "In this paper, we present a reproduction of the paper of Bertinetto et al. [2019] \"Meta-learning with differentiable closed-form solvers\" as part of the ICLR 2019 Reproducibility Challenge. In successfully reproducing the most crucial part of the paper, we reach a performance that is comparable with or superior to the original paper on two benchmarks for several settings. We evaluate new baseline results, using a new dataset presented in the paper. Yet, we also provide multiple remarks and recommendations about reproducibility and comparability. After we brought our reproducibility work to the authors\u2019 attention, they have updated the original paper on which this work is based and released code as well. Our contributions mainly consist in reproducing the most important results of their original paper, in giving insight in the reproducibility and in providing a first open-source implementation.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "1664923028",
                        "name": "A. Devos"
                    },
                    {
                        "authorId": "3080772",
                        "name": "S. Chatel"
                    },
                    {
                        "authorId": "2052174",
                        "name": "M. Grossglauser"
                    }
                ]
            }
        },
        {
            "contexts": [
                "(2019); Bertinetto et al. (2018) on CIFAR-FS, FC100, miniImageNet few-shot learning tasks with the standard training protocol, and the training protocol with ensemble method Huang et al.",
                "\u2217CIFAR-FS results from Bertinetto et al. (2018). \u2020Result from Lee et al. (2019). The best results are highlighted.",
                "To identify whether the rotation multi 90 degrees for Task Aug is better than that for Data Aug, we analyzed the experiment on CIFAR-FS and miniImageNet.",
                "Besides, Table 2 and Table 3 summarize the results on the CIFAR-FS and FC100 5-way tasks, and in most cases our method rises accuracy by 0.5%-3%.",
                "We used ProtoNets Snell et al. (2017), MetaOptNet-SVM Lee et al. (2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug.",
                "The proposed method is evaluated by experiments with the state of art meta-learning Methods Snell et al. (2017); Lee\net al. (2019); Bertinetto et al. (2018) on CIFAR-FS, FC100, miniImageNet few-shot learning tasks with the standard training protocol, and the training protocol with ensemble method Huang et al. (2017).",
                "We proved that Task Aug was valid for CIFAR-FS, FC100, and miniImageNet, and exceeded the result of the previous works.",
                "(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al.",
                "(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al. (2019), For M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.1; and a learnable scale was used following Lee et al. (2019). We did not use label smoothing like Lee et al. (2019), because we did not find that label smoothing can improve the performance in our environment.",
                "Therefore, in the experiment, the methods applied in the \u201cinner loop\u201d are able to classify data, and they are K-nearest neighbor (KNN), Support Vector Machine (SVM) and ridge regression, respectively Snell et al. (2017); Lee et al. (2019); Bertinetto et al. (2018).",
                "For R2-D2, we set the same training shot as for M-SVM, and used a learnable scale and bias following Bertinetto et al. (2018).",
                "(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al. (2019), For M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.",
                "(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al. (2019), For M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.1; and a learnable scale was used following Lee et al. (2019). We did not use label smoothing like Lee et al.",
                "The CIFAR-FS Bertinetto et al. (2018) containing all 100 classes from CIFAR-100 Krizhevsky et al. (2010) is proposed as few-shot classification benchmark recently.",
                "(2019); Bertinetto et al. (2018) on CIFAR-FS, FC100, miniImageNet few-shot learning tasks with the standard training protocol, and the training protocol with ensemble method Huang et al. (2017). The experimental result analysis shows that Task Aug can reduce over-fitting and improve the performance, while the conventional data augmentation (referred to Data Aug) of rotation, which converts the novel data into the classes of original data, does not improve the performance and even causes the worse result.",
                "Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al. (2018); Lee et al. (2019),\nFor M-SVM, we set training shot to 5 for CIFAR-FS; 15 for FC100; and 15 for miniImageNet; regularization parameter of SVM was set to 0.1; and a learnable scale was used following Lee et al. (2019).",
                "(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug. For ProtoNets, we did not use a higher way for training than testing like Snell et al. (2017). Instead, the equal number of shot and way were used in both training and evaluation, and its output multiplied by a learnable scale before the softmax following Oreshkin et al.",
                "We set pmax to 0.5 for CIFAR-FS and FC100; 0.25 for miniImageNet; and T was set to 80000 for all experiments.",
                "It was different from Bertinetto et al. (2018) we used a fixed regularization parameter of ridge regression which was set to 50 because Bertinetto et al. (2018) has confirmed that making it learnable might not be helpful.",
                "Same as CIFAR-FS, there are 600 nature color images of size 32\u00d7 32 in each class.",
                "The proposed method is evaluated by experiments with the state of art meta-learning Methods Snell et al. (2017); Lee\net al. (2019); Bertinetto et al. (2018) on CIFAR-FS, FC100, miniImageNet few-shot learning tasks with the standard training protocol, and the training protocol with ensemble method\u2026",
                "Previous studies have introduced many popular regularization techniques to few-shot learning from deep learning, such as weight decay, dropout, label smooth Bertinetto et al. (2018), and data augmentation.",
                "\u2217CIFAR-FS results from Bertinetto et al. (2018). \u2020Result from Lee et al.",
                "(2019) (we write it as M-SVM) and Ridge Regression Differentiable Discriminator (R2-D2) Bertinetto et al. (2018) as basic methods to verify the effective of Task Aug."
            ],
            "intents": [
                "methodology",
                "background",
                "result"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "d4c28361c7e77b94ec8df786ce85f37b1d2e8ec1",
                "externalIds": {
                    "CorpusId": 209175257
                },
                "corpusId": 209175257,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/d4c28361c7e77b94ec8df786ce85f37b1d2e8ec1",
                "title": "Novel classes 2 Original classesNovel classes 1 Novel classes 3 Novel classes 2 Novel classes 1 Novel classes",
                "abstract": "Data augmentation is one of the most effective approaches for improving the accuracy of modern machine learning models, and it is also indispensable to train a deep model for meta-learning. However, most current data augmentation implementations applied in meta-learning are the same as those used in the conventional image classification. In this paper, we introduce a new data augmentation method for meta-learning, which is named as \u201cTask Level Data Augmentation\u201d (referred to Task Aug). The basic idea of Task Aug is to increase the number of image classes rather than the number of images in each class. In contrast, with a larger amount of classes, we can sample more diverse task instances during training. This allows us to train a deep network by meta-learning methods with little over-fitting. Experimental results show that our approach achieves state-of-the-art performance on miniImageNet, CIFAR-FS, and FC100 few-shot learning benchmarks. Once paper is accepted, we will provide the link to code.",
                "year": 2019,
                "authors": []
            }
        },
        {
            "contexts": [
                "[1], R2D2 (with its more complex network architecture) performs better than the MAML method for most simulations.",
                "[1] present a new approach that relies on using fast and simple base learners such as ridge regression differentiable discriminator (R2D2) or (regularized) logistic regression differentiable discriminator (LRD2).",
                "[1] MAML ours R2D2* ours R2D2 ours R2D2 paper Bertinetto et al.",
                "[1] \u201dMetalearning with differentiable closed-form solvers\u201d as part of the ICLR 2019 Reproducibility Challenge.",
                "[1] (referenced as \u201dtheir paper\u201d); it falls into the class of gradient-based meta-learning algorithms that learn a model parameter initialization for rapidfine-tuningwith a few shots (Finn, Abbeel, andLevine [5], Nichol and Schulman [6])."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": true,
            "citingPaper": {
                "paperId": "1cf8c580eb936a3bd9ca32d8d347d479334f4e0b",
                "externalIds": {
                    "MAG": "2947021994",
                    "CorpusId": 191537503
                },
                "corpusId": 191537503,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/1cf8c580eb936a3bd9ca32d8d347d479334f4e0b",
                "title": "[Re] Meta learning with differentiable closed-form solvers",
                "abstract": "The ability to adapt to new situations and learn quickly is a cornerstone of human intelligence. When given a previously unseen task, humans can use their previous experience and learning abilities to perform well on this new task in a matter of seconds and with a relatively small amount of new data. Artificial learning methods have been shown to be very effective for specific tasks, often times surpassing human performance1,2). However, by relying on standard supervised-learning or reinforcement learning training paradigms, these artificial methods still require much training data and training time to adapt to a new task. An area of machine learning that learns and adapts from a small amount of data is called few-shot learning3. A shot corresponds to a single example, e.g. an image and its label. In few-shot learning the learning scope is expanded from the classic setting of a single task withmany shots to a variety of tasks with a few shots each. A promising approach for few-shot learning is the field of meta-learning. Meta-learning, also known as learning-to-learn, is a paradigm that exploits cross-task information and training experience to perform well on a new unseen task.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "1664923028",
                        "name": "A. Devos"
                    },
                    {
                        "authorId": "3080772",
                        "name": "S. Chatel"
                    },
                    {
                        "authorId": "2052174",
                        "name": "M. Grossglauser"
                    }
                ]
            }
        },
        {
            "contexts": [
                "A recent line of work learns the base-level in closed-form using simpler models such as SVMs [10, 11] which restricts the capacity of the base-level although it alleviates the optimization problem.",
                "The first is the CIFAR-FS dataset [10] which splits classes randomly into 64 training, 16 validation and 20 test with 600 images in each."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "845018bac3a681678399cb0fa1e1d96f55278180",
                "externalIds": {
                    "CorpusId": 215821486
                },
                "corpusId": 215821486,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/845018bac3a681678399cb0fa1e1d96f55278180",
                "title": "Appendix: A Baseline for Few-Shot Image Classification",
                "abstract": "We first introduce some notation and formalize the few-shot image classification problem. Let (x, y) denote an image and its ground-truth label respectively. The training and test datasets are Ds = {(xi, yi)} i=1 and Dq = {(xi, yi)} Nq i=1 respectively, where yi \u2208 Ct for some set of classes Ct. The training and test datasets are disjoint. In the few-shot learning literature, training and test datasets are commonly referred to as support and query datasets respectively, and are collectively called a few-shot episode. The number of ways, or classes, is |Ct|. The set {xi | yi = k, (xi, yi) \u2208 Ds} of samples is the support of class k and its cardinality is (non-zero) s support shots (more generally referred to as shots). The set {xi | yi = k, (xi, yi) \u2208 Dq} of samples is the query of class k and its cardinality is q query shots. The goal is to learn a function F to exploit the training set Ds to predict the label of a test datum x, where (x, y) \u2208 Dq, by",
                "year": 2019,
                "authors": [
                    {
                        "authorId": null,
                        "name": "Guneet S. Dhillon"
                    },
                    {
                        "authorId": "143976382",
                        "name": "P. Chaudhari"
                    },
                    {
                        "authorId": "2529423",
                        "name": "Avinash Ravichandran"
                    },
                    {
                        "authorId": "1715959",
                        "name": "Stefano Soatto"
                    }
                ]
            }
        },
        {
            "contexts": [
                "Other uses of such differentiable optimization have been found in meta-learning to differentiate through the learning algorithm in the middle [32, 33], or to train the generator in a generative adversarial model by optimizing out the discriminator [43], or for end-to-end planning and control [45].",
                "For example, [27\u201329] used simple metric-based nearest neighbor, [30, 31] optimized standard learning algorithms iteratively, and [32, 33] leveraged closed-form solutions for base learners."
            ],
            "intents": [
                "methodology",
                "background"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "3b6ccd6203219915b8eee88596ea8f5526ebf772",
                "externalIds": {
                    "CorpusId": 220825135
                },
                "corpusId": 220825135,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/3b6ccd6203219915b8eee88596ea8f5526ebf772",
                "title": "Meta-Learning of Structured Representation by Proximal Mapping",
                "abstract": "Underpinning the success of deep learning are the effective regularization techniques that allow a broad range of structures in data to be compactly modeled in a deep architecture. Examples include transformation invariances and correlations between multiple modalities. However, most existing methods incorporate such priors either by auto-encoders, whose result is used to initialize supervised learning, or by augmenting the data with exemplifications of the transformations which, despite the improved performance of supervised learning, leaves it unclear whether the learned latent representation does encode the desired regularities. To address these issues, this work proposes an end-to-end representation learning framework based on meta-learning, which allows prior structures to be encoded explicitly in the hidden layers, and to be trained efficiently in conjunction with the supervised learning task. It extends meta-learning to unsupervised base learners. The resulting technique is applied to generalize dropout and invariant kernel warping, and to develop novel algorithms for multiview modeling and robust temporal learning.",
                "year": 2019,
                "authors": [
                    {
                        "authorId": "2118481327",
                        "name": "Mao Li"
                    },
                    {
                        "authorId": "121720851",
                        "name": "Yingyi Ma"
                    },
                    {
                        "authorId": "2108029096",
                        "name": "Xinhua Zhang"
                    }
                ]
            }
        },
        {
            "contexts": [
                "We use CIFAR-FS [46] and Omniglot [47] datasets for our few-shot learning tasks; see Appendix A for details.",
                "In the CIFAR-FS experiments, the prototypical methods outperform our method only in the 1-shot scenario."
            ],
            "intents": [
                "methodology"
            ],
            "isInfluential": false,
            "citingPaper": {
                "paperId": "eeefbd8c0bbe47b38d7ef794f1d993eddfc488fb",
                "externalIds": {
                    "CorpusId": 245011320
                },
                "corpusId": 245011320,
                "publicationVenue": null,
                "url": "https://www.semanticscholar.org/paper/eeefbd8c0bbe47b38d7ef794f1d993eddfc488fb",
                "title": "Online Meta-Learning via Learning with Layer-Distributed Memory",
                "abstract": "We demonstrate that efficient meta-learning can be achieved via end-to-end training of deep neural networks with memory distributed across layers. The persistent state of this memory assumes the entire burden of guiding task adaptation. Moreover, its distributed nature is instrumental in orchestrating adaptation. Ablation experiments demonstrate that providing relevant feedback to memory units distributed across the depth of the network enables them to guide adaptation throughout the entire network. Our results show that this is a successful strategy for simplifying metalearning \u2013 often cast as a bi-level optimization problem \u2013 to standard end-to-end training, while outperforming gradient-based, prototype-based, and other memorybased meta-learning strategies. Additionally, our adaptation strategy naturally handles online learning scenarios with a significant delay between observing a sample and its corresponding label \u2013 a setting in which other approaches struggle. Adaptation via distributed memory is effective across a wide range of learning tasks, ranging from classification to online few-shot semantic segmentation.",
                "year": null,
                "authors": [
                    {
                        "authorId": "36366640",
                        "name": "Sudarshan Babu"
                    }
                ]
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": null,
                "externalIds": null,
                "corpusId": "250640321",
                "publicationVenue": null,
                "url": null,
                "title": "! \" \" ! \" ! ! \" # ! ! \" ! ! ! !",
                "abstract": null,
                "year": null,
                "authors": []
            }
        },
        {
            "contexts": [],
            "intents": [],
            "isInfluential": false,
            "citingPaper": {
                "paperId": null,
                "externalIds": null,
                "corpusId": "259841390",
                "publicationVenue": null,
                "url": null,
                "title": "Lecture 22: MAML & Generative Models",
                "abstract": null,
                "year": null,
                "authors": []
            }
        }
    ]
}