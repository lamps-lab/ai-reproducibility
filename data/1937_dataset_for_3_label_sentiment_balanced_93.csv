context,label_score,label,3_label,target
"Table 2 Comparison of detection accuracy (%) among CluSTi, DeepDeSRT [34], and TableNet [23] on ICDAR 2013 dataset",0.0,Neutral,neutral,1
"Due to the absence of released annotations for the test set, we follow previous approaches [20, 35, 46, 47] and evaluate our model on the validation set using TEDS and TEDS-Struct [48] metrics.",0.5,Weak,positive,2
"Existing Theory of Contrastive Learning Besides the empirical success, theoretical foundations, which explain the efficiency of the methods in contrastive learning, are gradually gathering attention [23, 56, 65, 61, 59].",0.0,Neutral,neutral,1
"However, we were unable to obtain reasonable performance, even after exploring a variety of values for post processing thresholds and training hyperparameters (values not specified in [6]).",-2.0,O-NR,negative,0
"On the PubTabNet dataset, our model achieved TEDS-struc. of 97.88% which again improves TableFormer and LGPMA (Qiao et al., 2021) by about 1.1% and other methods by more than 4.87%.",0.5,Weak,positive,2
"We selected the Local and Global Pyramid Mask Alignment (LGPMA) method [37] and the VCGroup method [55],
which came in first and second place respectively in the ICDAR 2021 Competition on Scientific Literature Parsing - Task B Table Recognition [15].",0.5,Weak,positive,2
"Under the new evaluation setting, the result of SPLERGE significantly drops by 10.2% absolutely in F1-score.",-2.0,O-NR,negative,0
"Hsieh et al. (2019) even have convergence guarantees for their method, something rare in deep learning.",0.0,Neutral,neutral,1
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR,negative,0
"We use four existing recognizers —ocr [26], equation descriptor [19], table recognizer [23], and figure classifier [12] to recognize content from the segmented regions.",0.5,Weak,positive,2
This is consistent with ICDAR-13 image-based table structure recognition dataset generated by Schreiber et al. (2017) [2] where row/column span (hierarchical labels) were also discarded.,0.0,Neutral,neutral,1
"Since LGMPA [13] and CycleCenterNet [11] recover table structure based on heuristic rules after detecting cells, which is infeasible to perform the comparison between them and our method, we do not report them in Tab.",-1.0,P-NR,negative,0
"A combination of heuristics and deep learning methods was also proposed [30] based on splitting the table into sub-cells, and then merging semantically connected",0.0,Neutral,neutral,1
"Category Method F-measure Recall Precision PDF Input Image Input
Proposed Models
Split 86.79 86.64 86.93 Split-PDF 91.63 91.26 92.00 SPLERGE-PDF 90.89 90.44 91.36 SPLERGE-PDF + Heuristics 91.95 91.46 92.45
Split + Heuristics 93.00 92.24 93.78 Split-PDF + Heuristics 95.26 94.64 95.89
Previously Reported Results
Nurminen [3] 94.60 94.09 95.12 TEXUS [4] 82.59 84.23 81.02 Shigarov [5] C1 91.50 91.21 91.80 Shigarov [5] C2 93.64 92.33 94.99 DeepDeSRT [6] 91.44† 87.36† 95.93†
† result not directly comparable due to evaluation on a random subset of 34 tables.",-1.0,P-NR,negative,0
"2) Baselines: We compare our framework with five categories of baselines: feature-based models (SVM), neural text classification models (LSTM+ATT, CNN+GRU, BiGRU+Capsule, Transformer), pre-trained language model (Bert, HurtBert), Graph Neural Network (DepGCN), and multi-task model (SKS) for abusive language detection.",0.5,Weak,positive,2
"Recent years have witnessed great successes in self-supervised learning (SSL) for floating point (FP) networks (Goyal et al., 2021; Tian et al., 2021a; Zbontar et al., 2021; Li et al., 2021a; Cai et al., 2021; Ericsson et al., 2021; Tian et al., 2021b; Ermolov et al., 2021; Tian et al., 2020b; Chen…",0.0,Neutral,neutral,1
"The proposed framework can address also TSR, but implementation details are still under investigation.",-1.0,P-NR,negative,0
"Dynamics for λB: We can write down the dynamics for λB as follows:
λ̇B = λB [ −(1 + σ2) |λB |4α + |λB |2α − η ] Similar as the analysis in (Tian et al., 2021), when η > 14(1+σ2) , we know λ̇B < 0 for any λB > 0 and λB = 0 is a critical point.",0.5,Weak,positive,2
Following ideas presented in Section II-C that have been proven successful for TD [35] and TSR [36] we enrich our graph nodes with positional and textual features.,0.0,Neutral,neutral,1
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR,negative,0
"This interpretation echos well with the finding that the eigenspace of hweight aligns well with that of correlation matrix (Tian et al., 2021).",0.0,Neutral,neutral,1
"Recent works investigating bias in language models have found issues with inconsistencies between seed words (Antoniak and Mimno, 2021),",0.0,Neutral,neutral,1
"Although we tried to train split network with the same training data we used, we failed to reproduce their results and used the model trained by the authors [32].",-2.0,O-NR,negative,0
"We also compared the performance of CluSTi to DeepDeSRT [34], which is known as the best",0.5,Weak,positive,2
"We seek to replicate the Antoniak and Mimno [1] paper, hereafter referred to as ”the original paper/work”.",1.0,Strong,positive,2
"Notably, the experimental results of Tabby, GraphTSR, DeepDeSRT on the ICDAR2013, SciTSR and SciTSR-COMP dataset come from the study [3], and the results of TableStrucNet and Split+Heur are from study [22].",0.0,Neutral,neutral,1
"Our code is adapted from (Tian et al., 2021) 5, and we follow the same data augmentation process.",1.0,Strong,positive,2
"The predictor acts as a whitening operator preventing collapse [Tian et al., 2021], and momentum network can be applied only to the projector [Pham et al.",0.0,Neutral,neutral,1
"In this scenario, TSR usually deals with tables which are subareas of document images (Zuyev, 1997; Schreiber et al., 2017; Siddiqui et al., 2019a, 2019b; Zheng et al., 2021; Hashmi et al., 2021c), lines of plain-text (Kieninger, 1998; Ng et al., 1999; Hu et al., 2000), or text chunks and rulings…",0.0,Neutral,neutral,1
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR,negative,0
"(Raja et al., 2020) presented a table structure recognizer named TabStruct-Net that combines cell detection and interaction modules to localize the cells and predicts their row and column associations with other detected cells.",0.0,Neutral,neutral,1
"Therefore, we
6
also use SynthTable proposed in TIES [4].",0.0,Neutral,neutral,1
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR,negative,0
"In experiment 2a, we replace the self-attention encoder with a graph-attention encoder similar to graph-based TSR models (Qasim, Mahmood, and Shafait 2019; Xue et al. 2021) with an equal amount of parameters with LORE.",0.5,Weak,positive,2
[8] recently reported an F-score of 0.,-2.0,O-NR,negative,0
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR,negative,0
"As we pointed in Section VI, we cannot be sure that we reproduce results from [17] because the paper contains omissions.",-1.0,P-NR,negative,0
"In order to verify the effectiveness of TSRFormer for more challenging borderless tables, we re-implement another split-and-merge based method SPLERGE [45] and compare our approach with it on serveral datasets.",1.0,Strong,positive,2
[41] used the CNNmodel introduced by Gilani et al.,0.0,Neutral,neutral,1
"Note that LGPMA requires additional
annotation information for training.",-1.0,P-NR,negative,0
"To bypass this problem, the second group of methods [19, 23, 33, 35, 36, 54] detects the bounding boxes of table cells or cell contents directly and uses different methods to group them into rows and columns.",0.0,Neutral,neutral,1
"We unfortunately could not directly evaluate the approaches presented in References [5, 25, 30, 41, 47, 89] using our cybersecurity corpus documents, because their respective implementations were not available online.",-1.0,P-NR,negative,0
"For this, we reproduced an experiment by Antoniak and Mimno [1] ranking the cosine similarity between 155",1.0,Strong,positive,2
"The source codes of 6 papers were not executable [30, 33, 34, 36, 38, 39].",-2.0,O-NR,negative,0
"However, only a few studies [19] investigate the unfairness caused by the graph structure without knowing a sensitive feature.",0.0,Neutral,neutral,1
"(ii) LSTM [42], Bi-LSTM [43], GRU [44], and Bi-GRU [45] are investigated as classifiers (with one-dimensional convolution layer).",0.5,Weak,positive,2
"The DialSummEval (Gao and Wan, 2022) benchmark is a summarization evaluation benchmark created following the format of SummEval (Fabbri et al., 2021) for the domain of dialogue summarization.",0.0,Neutral,neutral,1
"To evaluate the efficacy of our proposed augmentation methodology, we train the Split model proposed by [23] on ICDAR 2013 dataset.",0.5,Weak,positive,2
"We develop on the insights of Antoniak and Mimno (2021) by facilitating access to these technologies to domain experts with no technical expertise, so that they can provide well-founded word lists, by pouring their knowledge into those lists.",0.5,Weak,positive,2
"This result also outperformed DeepDeSRT, which is known as the best recent method applied on document images.",0.5,Weak,positive,2
"Recently, FinTabNet [23] and SciTSR [2] datasets add the cell coordinates and row-column information to become the most complete and large-scale dataset for table structure parsing task.",0.0,Neutral,neutral,1
"Recent contrastive self-supervised learning methods (Grill et al., 2020; Chen & He, 2021; Tian et al., 2021; He et al., 2020; Chen et al., 2021) alleviate the huge batch challenge at the cost of deploying an momentum copy of the target model to facilitate the training and prevent trivial solutions.",0.0,Neutral,neutral,1
"We picked the model parameter configuration that produced the best prediction quality (enc=6, dec=6, heads=8) with PubTabNet alone, then independently trained and evaluated it on three publicly available data sets: PubTabNet (395k samples), FinTabNet (113k samples) and PubTables-1M (about 1M samples).",0.5,Weak,positive,2
"Similar as the analysis in Tian et al. (2021), when η > 1 4(1+σ2) , we know λ̇B < 0 for any λB > 0 and λB = 0 is a stable stationary point, as illustrated in Figure 4 (Left).",0.5,Weak,positive,2
"of parameters CascadeTabNet [23] 82,852,033 TabStructNet [25] 68,636,098 SPLERGE [32] 255,862 Ours 1,120,692",0.0,Neutral,neutral,1
"We unfortunately could not directly evaluate the approaches presented in [5, 25, 30, 41, 47, 89] using our cybersecurity corpus documents because their respective implementations were not available online.",-1.0,P-NR,negative,0
"Moreover, Wen and Li (2021) considered the representation learning under the sparse coding model and studied the optimization properties on shallow ReLU neural networks, (Tian et al., 2021; Wang et al., 2021) investigated why self-supervised learning can learn features without contrastive pairs in a linear representation setting, and (Jing et al.",0.0,Neutral,neutral,1
"This module is present in a number of contrastive self-supervised learning methods (Chen et al., 2020a; Grill et al., 2020; Zbontar et al., 2021; Tian et al., 2021).",0.5,Weak,positive,2
1) Faster Recurrent Conventional Neural Network (FRCNN) [2] [3] algorithm to detect the table.,0.0,Neutral,neutral,1
"Since FinTabNet has bounding boxes wrapped around the cell’s content, we pre-process the ground truth to obtain cell level coordinates (refer supplementary paper)2.",0.5,Weak,positive,2
"Paper metadata from these sources are harmonized, PDFs are converted into machinereadable JSON using the S2ORC pipeline described in [54] and HTML representations of tables in papers are added using IBM Watson Discovery’s Global Table Extractor [115].",0.5,Weak,positive,2
"More recent works [4], [32], [33] have shown that we can learn high-quality representations without negative samples.",0.0,Neutral,neutral,1
"In S-A, we observe that our model outperforms deepdesrt [7] method by a 27.",0.5,Weak,positive,2
"In addition, our model is only trained on the training set of SciTSR for a fair comparison with TabStruct-Net [31].",0.5,Weak,positive,2
"Method Reference Code Pre-processing In training Post-processing Keywords FairOT [41] Github ✓ Optimal Transport, Laplacian regularization FairDrop [65] Github ✓ Edge Drop, Homophily UGE [70] NA ✓ Structural generative graph model FairWalk [60] Github∗ ✓ Random walk CrossWalk [34] Github ✓ Random walk DeBayes [11] Github ✓ Conditional Network Embeddings, Bayeisan prior FIPR [12] Github ✓ I-Projection regularizer CFC [10] Github ✓ Adversarial Learning, Compositional filtering FLIP [50] Github ✓ Adversarial Learning, Modularity DKGE [21] NA ✓ Adversarial, Knowledge graphs FairGNN [17] Github ✓ GNNs, Adversarial Learning FairAdj [45] Github ✓ Graph Neural Networks MONET [58] Github ✓ GNNs, metadata NIFTY [3] Github ✓ GNNs, augmented views, stability InFoRM [31] Github ✓ ✓ ✓",0.5,Weak,positive,2
"The comparison of performance between open source F. Shafait et al.5 technique (Tesseract),Schreiber et al. Hao et al.10 , Gilani et al.12 and our method is shown in Table 2.",0.5,Weak,positive,2
"Quite a number of table recognition techniques have been reported in recent years [14]–[16], and most of them can be broadly classified into three categories.",0.0,Neutral,neutral,1
"Furthermore, to assess the effectiveness of our method in oriented and distorted scenarios, we compare it with two mainstream open-source methods, SPLERGE [39] and Table-Master [44], on the TAL, TAL_rotated, and TAL_curved datasets.",0.5,Weak,positive,2
"Additionally, it is benchmarked with a number of state-of-the-art techniques such as SPLERGE [10], TabStruct-Net [18], EDD [3], GTE [28], LGPMA [9], FLAG-Net [29], etc. Unlike many state-of-the-art methods that perform evaluations only at TEDs, our method also test the Structure TEDs on PubTabNet.",0.5,Weak,positive,2
Method #Param FLOPs GPU CPU SPLERGE [35] 0.,0.0,Neutral,neutral,1
"[17] uses a deep learning-based method to detect tables and identify table structure by detecting rows, columns, and table cells.",0.0,Neutral,neutral,1
Table structure recognizer is our own implementation of the model proposed in [13].,0.5,Weak,positive,2
"The results shown in Figure 3 and Figure 4 indicate that none of the 4 methods that allow inference on custom data [13, 17, 16, 31] was replicable with respect to the GenTSR dataset, under a threshold of 10% absolute F1-score.",-2.0,O-NR,negative,0
"We compare the performance of our tabstruct-net against seven benchmark methods — deepdesrt [7], tablenet [12], graphtsr [14], splerge [10], dgcnn [9], Bi-directional gru [15] and Image-to-Text [11].",0.5,Weak,positive,2
"For table extraction, we use our Global Table Extractor (GTE) (Zheng et al. 2020), which leverages specialized object detection models and clustering techniques to extract, for each table, both its bounding box and cell structure.",0.5,Weak,positive,2
"• An augmented dataset based on PubTabNet [37], FinTabNet [36], and TableBank [17] with generated ground-truth for reproducibility.",0.5,Weak,positive,2
"4) On the DV dataset, DCL achieved the best performance by accuracy, and better performance by weighted-F1 than all the baseline models except SKS.",0.0,Neutral,neutral,1
"All other methods except EDD (Zhong et al., 2020) are non-end-to-end
approach and the methods in (Qiao et al., 2021; Ye et al., 2021; Zhang et al., 2022) requires additional annotation information for training.",-1.0,P-NR,negative,0
"[33] Jun-Ting Hsieh, Shengjia Zhao, Stephan Eismann, Lucia Mirabella, and Stefano Ermon.",0.0,Neutral,neutral,1
"(Schreiber et al., 2018) uses a different, non-public 50 % random subset.",-1.0,P-NR,negative,0
"Compared with the strong baseline TabStruct-Net [31] greedily exploiting large numbers of proposals (round 2,000), our proposed FLAG-Net can achieve marginally better performance with less parameters and computational consumption, which thanks to the proposal filtering mechanism in our method.",0.5,Weak,positive,2
to boost downstream performance on image [165] and video tasks [161].,0.0,Neutral,neutral,1
works (trained on ImageNet [20] or COCO [43]) on the problem of table detection and table structure recognition in document images [44]–[53].,0.0,Neutral,neutral,1
"The ICDAR labels now serve as the target dataset, while we continue to use arXivdocs-weak for weak supervision.7 Following (Schreiber et al., 2018), we use a random subset of 50 % of the ICDAR 2013 competition dataset for testing.",0.0,Neutral,neutral,1
"To further validate the robustness of our approach to distorted or even curved table images, we conducted
experiments on the in-house dataset and compared our table structure recognizer with SPLERGE.",0.5,Weak,positive,2
"The first group are the single component-based methods, which rely on either boundary extraction [15, 25, 31, 38, 41] or element relationship [4, 23, 34, 36].",0.0,Neutral,neutral,1
[24] trained a convolutional network to improve a GMG algorithm for the structured Poisson problem.,0.0,Neutral,neutral,1
"In this work, we consider the linear network setting used previously for studying non-contrastive SSL in [1, 8], and provide a straightforward analysis of how the learning dynamics in DirectPred and DirectCopy prevent representational collapse.",0.0,Neutral,neutral,1
"As shown in Table 4, the re-implemented SPLERGE can achieve competitve results on SciTSR and PubTabNet datasets while it is still 11.4% worse than TSRFormer in F1-score on our challenging in-house dataset.",-2.0,O-NR,negative,0
"Following [44], we assume that ∂qMi ∂z is positive definite.",0.5,Weak,positive,2
"Average time taken for our system for each document image is 0.3765 seconds, however this could not be compared with DeepDSert as their model was not publicly available.",-1.0,P-NR,negative,0
"We also compared the performance of CluSTi to DeepDeSRT [34], which is known as the best
recent method for table structure recognition on the ICDAR 2013 and ICDAR 2019 competition’s datasets.",0.5,Weak,positive,2
"Also, [23, 26] used different train/test split from the original competition without publishing their split and so cannot be compared directly.",-1.0,P-NR,negative,0
