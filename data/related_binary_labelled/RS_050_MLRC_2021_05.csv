text,label_score,label,target_predict,target_predict_label
"Similar to the interpretation of image generation process [10], we consider the",,,1,related
"effective way to remove spurious correlations and help learn causal representations, and has attracted considerable attention in visual and language learning [10].",,,0,not_related
Image generation process is decomposed into independent causal mechanisms in [10].,,,0,not_related
"Even state-ofthe-art deep learning models, with their high computational cost and carbon footprint [3], tend to learn simple correlations instead of capturing the underlying causal dynamics of the data [4], [5].",,,0,not_related
"Even state-of-the-art deep learning models, with their high computational cost and carbon footprint [13], tend to learn simple correlations instead of capturing the underlying causal dynamics of the data [14, 4].",,,0,not_related
"The inputs can be images (Sauer and Geiger 2021), tabular vectors (Wachter, Mittelstadt, and Russell 2017), sequential actions (Tsirtsis, De, and",,,0,not_related
"We adopt this hypothesis from Schölkopf et al. [2021], positing that distribution changes typically affect only a sparse or local subset of factors, rather than all factors simultaneously.",,,1,related
"If one has access to or can recover this causal structure, it can be used to generate samples from interventional and counterfactual queries [Kocaoglu et al., 2018, Sauer and Geiger, 2021, Nemirovsky et al., 2022].",,,0,not_related
"(1) Point counterfactual identification has been recently addressed through neural methods [16, 24, 26, 60, 73, 85, 97, 98, 101, 102, 118, 119, 124] but without identifiability results.",,,0,not_related
"Examples are normalizing flows [85]; diffusion models [16, 97]; variational inference [60, 85, 98, 118, 119]; adversarial learning [24, 73, 85, 101, 102, 124], and neural expectation-maximization [26].",,,0,not_related
"(1) The first stream [16, 24, 26, 60, 73, 85, 97, 98, 101, 102, 118, 119, 124] makes no explicit assumptions besides assuming a structural causal model (SCM) with",,,0,not_related
"L 3 C ou nt er fa ct ua l M Deep generative models [16, 24, 60, 85, 97, 98, 101, 102] ; Markovian BGMs [50, 56, 79, 80, 107, 132] ; transport-based counterfactuals [27] CSM (this paper)",,,0,not_related
"When confounders are present, disentanglement of features exhibiting spurious correlations through generative modeling becomes an arduous task [43, 40, 11].",,,0,not_related
"The application of empirical risk minimization (ERM) [49] to augmented data has proven to be effective in alleviating confounding bias and learning informative features for image data [19, 52, 13, 43].",,,0,not_related
"While previous studies [52, 13, 43] have demonstrated the efficacy of this approach in enhancing downstream task performance, they have predominantly focused on its practical benefits without conducting a comprehensive analysis of data augmentation.",,,0,not_related
"Recent endeavors have made significant strides in addressing spurious correlations stemming from confounding effects in observational data [48, 43, 13, 19, 52, 50, 2].",,,0,not_related
"Image data augmentations encompass a wide range of approaches, ranging from traditional image manipulation techniques such as rotation, flipping, cropping, among others [25, 46, 36, 16, 10, 58, 57, 19], to more recent generative-based augmentations [1, 43, 52, 13] that manipulate higher-level semantic aspects of an image, such as smiling or hair color.",,,0,not_related
", n}, X := g(Z) (5) U ∼ pU, Zi ∼ pZi ; ∀Zi ∈ Zcnf , Zj := fj(pa(Zj)); ∀Zj ̸∈ Zcnf , X := g(Z) (6) U ∼ pU, Zi ∼ pZi ; ∀Zi ∈ Zcnf ∪ {Z0}, Zj := fj(pa(Zj)); ∀Zj ̸∈ Zcnf ∪ {Z0}, X := g(Z) (7) As explained in § 2, counterfactual generative networks (CGN) [43] generates counterfactual images by simulating causal model in Eqn 7 above, performing interventions on all of {Z0} ∪ Zcnf .",,,1,related
"Addressing confounding biases in trained machine learning models has demonstrated its usefulness in various applications such as zero or few-shot learning [3, 56], disentanglement [47, 40], domain generalization [43, 8, 19], algorithmic fairness [22, 23], healthcare [13, 59].",,,0,not_related
"To overcome this limitation, counterfactual data augmentation has emerged as a promising approach [43, 52, 13, 26, 38, 9].",,,0,not_related
"X Y Gdo({Z0}∪Zcnf ) [43, 15] Gdo(X) [16, 57, 10, 58] Gdo(Zcnf ) [52, 13] Gdo(Z0)",,,1,related
"A recent method known as Counterfactual Generative Networks (CGN)[43] assumes that each image is a result of a composition of three fixed generative factors: shape, texture, and background.",,,0,not_related
"For instance, in computer vision applications, the image generation process can often be modelled based on a fixed graph (Sauer and Geiger, 2021; Tangemann et al., 2021).",,,0,not_related
"Some of these approaches focus on generating a realistic counterfactual sample (such as a “what-if” image) instead of quantifying the counterfactual distributions [42, 53, 61].",,,0,not_related
"Counterfactual generative model Generative models, including a variety of deep network architectures such as generative adversarial networks (GAN) and autoencoders, have been recently developed to estimate counterfactual outcomes [3, 12, 14, 19, 28, 31, 32, 42, 52, 53, 61, 65, 67].",,,0,not_related
"This is a fairly new area, and relevant to this line of work may be semantic adversarial approaches [8, 12, 17] which rely on generative models in order to generate adversarial examples, and [6] where interpretable controls are discovered for generative models.",,,0,not_related
…(2009); Peters et al. (2017); Chalupka et al. (2014); Zhang et al. (2022b); Mitrovic et al. (2021); Bühlmann (2020); Zhang et al. (2020); Tang et al. (2020); Sauer and Geiger (2021) has been widely applied to machine learning to identify causal relations and ignore nuisance factors by intervention.,,,0,not_related
", counterfactuals) by making small changes to the original samples, which can be divided into hand-crafted [5], [6] and using causal generative models [19], [20], demonstrating competitive performance.",,,0,not_related
"Generative networks have become an emerging technique to model the inference of counterfactual features [3], [10], [19].",,,0,not_related
CGN [19] disentangles the components of an image into three independent mechanisms that are decided by the class label.,,,0,not_related
"Recall that we use CGN [19] to generate counterfactual samples for each training and testing samples (cf. Section II-B) by intervening the texture of the object (i.e., T represents texture).",,,1,related
"For both Animal and Vehicle datasets, we use two widely used data augmentation strategies: 1) randomly cropping
2We adopt this initialization for fair comparison since the CGN used in L2D is trained on ImageNet [22].
the images with random retain ratio in [0.8, 1.0]; and 2) randomly applied horizontal flipping with 50% probability.",,,1,related
"Unlike our work which calculates the consensus for every class and utilizes the result for correction, CGN [19] simply adds these samples to the training set and GCM-CF [10] provides binary information about seen/unseen of an image, but do not interfere the inference.",,,1,related
Recall that we use CGN [19] to generate counterfactual samples for each training and testing samples (cf.,,,1,related
"(4); 5: Return θ̂, CGN, η̂, and ω̂.",,,1,related
"Among the existing models, we find that Counterfactual Generative Network (CGN) [19] can well support our requirement, which accounts for the mediator between X and Y and consists of components to model TY=y and TX=x.",,,1,related
"Considering that CGN is not a perfect generative network, which shows high cognitive uncertainty, we run four repeats for each x∗y′ .",,,1,related
"We thus directly use CGN as the CI module in the L2D framework to generate the counterfactual samples for all candidate classes: {x∗y′ |y′ ∈ [1, C]}.",,,1,related
"/* Testing */ 6: Infer y = f(x|θ̂); 7: for y′ = 1 → C do 8: Infer x∗y′ = CGN(x, y
′); 9: end for
10: Calculate zy (Eq.",,,1,related
"In particular, given a sample x, we generate a counterfactual image x∗y′ by feeding CGN with the common textual of class y′ where we enumerate all possible classes y′.",,,1,related
This pattern occurs mostly in images where the shape is not correctly given by CGN.,,,0,not_related
(1)); 2: Train CGN; 3: Train CM module (optimize Eq.,,,0,not_related
"• CGN [19]: CGN is a data augmentation method, which generates various counterfactual samples with the imagined texture and background.",,,0,not_related
"Following the rules [19], we generate the same amount of counterfactual samples as the training set to train models.",,,1,related
"Apparently, this counterfactual is identifiable as long as TY=y and TX=x are identifiable, which can be easily inferred through texture extraction tools [19].",,,0,not_related
"More recently, [9, 23, 26] propose generative methods to synthesize semantically perturbed images to visualize where the target model fails.",,,0,not_related
"Sauer & Geiger (2021) use a deep network to disentangle object shape, object texture and background in natural images.",,,0,not_related
"CGN, unlike CausalGAN, aims for robust, interpretable classifiers and mitigates shortcut learning [148].",,,0,not_related
"For specific implementations and results in this property, readers can refer to [64, 74, 150, 72, 101, 90].",,,1,related
"Empirical evaluations have validated the effectiveness of this approach on the MNIST dataset [65], although achieving complete invariance remains elusive on more complex datasets like ImageNet-9 [67].",,,0,not_related
"In a vein similar to CausalGAN, the Counterfactual Generative Network (CGN) [64] incorporates SCMs into the generator’s architecture to control specific factors of variation, such as shape, texture, and background.",,,0,not_related
"Various benchmark datasets, including MNIST, its derivatives like ColoredMNIST, Wildlife MNIST [64], and Morpho-MNIST [83], have been instrumental in assessing this integration’s effectiveness.",,,0,not_related
"Integrating Causal Principles in DGMs CausalGAN [62] GANs image generation generalization CelebA [63] CGN [64] GANs multi-task (image generation, classification) generalization MNISTs [65, 66], ImageNet [67]",,,0,not_related
"For instance, some studies leverage counterfactuals to train invariant classifiers, bolster out-of-distribution robustness [64], eliminate undesired spurious features, and enhance model resilience [74, 150].",,,0,not_related
"The generator function in CGN is formally described as:
xgen = C(m,f , b) = m⊙ f + (1−m)⊙ b (5)
where m represents the mask, f is the foreground, and b stands for the background.",,,1,related
"Still, as the difficulty of the integration with otherwise prominent success stories of deep learning such as computer vision, with publications at CVPR and such (including (Sauer and Geiger, 2021; Lv et al., 2022; Liu et al., 2022) to mention a select few), becomes apparent, countering opinions start speaking out against causal AI/ML (Bishop, 2021).",,,0,not_related
"…of the integration with otherwise prominent success stories of deep learning such as computer vision, with publications at CVPR and such (including (Sauer and Geiger, 2021; Lv et al., 2022; Liu et al., 2022) to mention a select few), becomes apparent, countering opinions start speaking out against…",,,0,not_related
"Also, there are known short-cut learning problems with regard to training on RGB images Geirhos et al. (2019; 2020); Sauer & Geiger (2021) – there is no constraint for overfitting the textures or the discriminative parts of the known classes during training.",,,0,not_related
[39] utilizes independent mechanisms to generate images to improve image classification.,,,0,not_related
"[5], Sauer and Geiger [41] aim to explain a deep classifier using the counterfactual approach.",,,0,not_related
"Recently, Chang et al. [4], Cohen et al. [5], Sauer and Geiger [41] aim to explain a deep classifier using the counterfactual approach.",,,0,not_related
"Generating Counterfactuals by Learning ICMs: In a more recent effort, assuming any real-world image is generated with three independent causal mechanisms for shape, texture, background, and a composition mechanism of the first three, (Sauer & Geiger, 2021) developed Counterfactual Generative Networks (CGN) that generate counterfactual images of a given image.",,,0,not_related
"3) variants (Arjovsky et al., 2019; Castro et al., 2019; Sauer & Geiger, 2021): (i) colored morpho MNIST (CM-MNIST), (ii) double colored morpho MNIST (DCM-MNIST), and (iii) wildlife morpho MNIST (WLMMNIST).",,,0,not_related
Figure 1: (a) causal data generating process considered in this paper (CONIC = Ours); (b) causal data generating process considered in CGN [34].,,,1,related
"3) variants [1, 4, 34]: (i) colored morpho MNIST (CM-MNIST), (ii) double colored morpho MNIST (DCMMNIST), and (iii) wildlife morpho MNIST (WLM-MNIST).",,,0,not_related
"Recent years have seen a few efforts to handle the spurious correlations caused by confounding effects in observational data (Träuble et al., 2021; Sauer & Geiger, 2021; Goel et al., 2021; Reddy et al., 2022).",,,0,not_related
"We compare CONIC with various baselines including traditional Empirical Risk Minimizer (ERM), Conditional GAN (CGAN) (Goodfellow et al., 2014a), Conditional VAE (CVAE) (Kingma & Welling, 2013), Conditional-β-VAE (C-βVAE) (Higgins et al., 2017), AugMix (Hendrycks et al., 2020), CutMix (Yun et al., 2019), Invariant Risk Minimization (IRM) (Arjovsky et al., 2019), and Counterfactual Generative Networks (CGN) (Sauer & Geiger, 2021).",,,1,related
"In this work, we begin with quantifying confounding in observational data that is generated by an underlying causal graph (more general than considered by CGN) of the form shown in Figure 1(a).",,,1,related
"We compare CONIC with various baselines including Empirical Risk Minimizer (ERM), Conditional GAN (CGAN) [12], Conditional VAE (CVAE) [20], Conditional-β-VAE (C-βVAE) [16], AugMix [15], CutMix [43], Invariant Risk Minimization (IRM) [1], and Counterfactual Generative Networks (CGN) [34].",,,1,related
"A related recent effort by (Sauer & Geiger, 2021) proposes Counterfactual Generative Networks (CGN) to address this problem using a data augmentation approach.",,,0,not_related
"We also note that the deterministic models such as CGN fail when they are applied to a different task where the number and type of generative factors are not fixed and are difficult to separate (e.g., CelebA).",,,1,related
"CGN trains three Generative Adversarial Networks (GANs) (Goodfellow et al., 2014b) to learn shape, texture, background mechanisms and combine these three mechanisms using a composition mechanism g as g(shape, texture, background) = shape texture+(1− shape) background where is the Hadamard product.",,,0,not_related
"Recent years have seen a few efforts to handle the spurious correlations caused by confounding effects in observational data [36, 34, 11, 32].",,,0,not_related
"…domain generalization, counterfactual generation, algorithmic fairness, healthcare, etc. (Suter et al., 2019; Kilbertus et al., 2020; Atzmon et al., 2020; Zhao et al., 2020; Yue et al., 2021; Sauer & Geiger, 2021; Goel et al., 2021; Dash et al., 2022; Reddy et al., 2022; Dinga et al., 2020).",,,0,not_related
CGN results in table 1 are obtained with only 1000 counterfactual images as augmented data points.,,,0,not_related
"When we increase the number of counterfactual instances, performance of CGN reduces further.",,,1,related
"Time Complexity Analysis: Apart from its simple methodology, CONIC brings
Dataset CONIC CGN
CM-MNIST 2.76 ± 0.19 103 ± 1.50 DCM-MNIST 2.22 ± 0.01 103 ± 2.04 WLM-MNIST 1.22 ± 0.01 111 ± 2.50
Table 2: Run time (in minutes) of CONIC compared to CGN on MNIST variants
additional advantages in terms of computing time required to train the model that generates counterfactual images.",,,0,not_related
"…2014a), Conditional VAE (CVAE) (Kingma & Welling, 2013), Conditional-β-VAE (C-βVAE) (Higgins et al., 2017), AugMix (Hendrycks et al., 2020), CutMix (Yun et al., 2019), Invariant Risk Minimization (IRM) (Arjovsky et al., 2019), and Counterfactual Generative Networks (CGN) (Sauer & Geiger, 2021).",,,0,not_related
"Once the independent mechanisms are trained, counterfactual images are generated by sampling a label and a noise vector corresponding to each mechanism and then feeding the input to CGN. Finally, a classifier is trained with both original and counterfactual images to achieve better test time accuracy, showing the usefulness of CGN.",,,0,not_related
"…effort, assuming any real-world image is generated with three independent causal mechanisms for shape, texture, background, and a composition mechanism of the first three, (Sauer & Geiger, 2021) developed Counterfactual Generative Networks (CGN) that generate counterfactual images of a given image.",,,0,not_related
"Generating Counterfactuals by Learning ICMs: In a more recent effort, assuming any real-world image is generated with three independent causal mechanisms for shape, texture, background, and a composition mechanism of the first three, [34] developed Counterfactual Generative Networks (CGN) that generate counterfactual images of a given image.",,,0,not_related
A related recent effort by [34] proposes Counterfactual Generative Networks (CGN) to address this problem using a data augmentation approach.,,,0,not_related
"As shown in Table 2, the time required to run our method to generate counterfactual images w.r.t. a generative factor Zj is significantly less than CGN that learns deterministic causal mechanisms as discussed in Section 2.",,,1,related
"L G
] 1
0 D
ec 2
using generative modeling when there are confounders is challenging (Sauer & Geiger, 2021; Reddy et al., 2022; Funke et al., 2022).",,,1,related
"Additionally, one could use counterfactual generation methods (Karras et al., 2019; Sauer & Geiger, 2021; Pawelczyk et al., 2020) and apply them for “distributional counterfactuals” which would show what a sample from Ptgt would have looked like if it instead came from Psrc (e.g., Pawelczyk et al.…",,,0,not_related
"Using Grad-CAM (Selvaraju et al., 2016) to explain a ResNet-50 (He et al., 2016) domain classifier (bottom-left) does not lead to actionable insights.",,,1,related
The baseline method of unpaired samples (top-left) requires many more samples to begin to understand the differences across the hospitals domains and using Grad-CAM Selvaraju et al. [2016] to explain a ResNet-50 He et al.,,,0,not_related
"[Goudet et al., 2017, Yoon et al., 2018, Kocaoglu et al., 2018, Sauer and Geiger, 2021] use generative models to capture a causal perspective on evaluating the effect of interventions on high-dimensional data such as images.",,,0,not_related
", the methods considering representations of distribution balance[40, 42, 43], exploiting the effects of covariates confounding learning[52, 65, 66, 67], the methods based on generative adversarial networks[44, 68, 69, 70] , and so forth[56, 33, 71].",,,0,not_related
"com/usaito/counterfactual-cv CGN[70] MNIST,ImageNet Pytorch https://github.",,,1,related
"Moreover, CGN[70] proposed more robust and interpretable classifiers that explicitly expose the causal structure of tasks.",,,0,not_related
"A simple way of (approximately) achieving counterfactualinvariant predictors is via counterfactual data augmentations (CDA) [Lu et al., 2020, Kaushik et al., 2019, Sauer and Geiger, 2021], where one augments the training data with inputs generated from different spurious features.",,,1,related
"For example, do(ai+A′) where A′ ∈ {15, 20} and a ∈ [60, 70] results in xcf with the highest median VED, since ai+A′ ∈ [65, 90] is generally outside the learned range of ages.",,,1,related
"Thus far, state-of-the-art causal structure learning frameworks, utilising deep learning components, have been employed to model the data generation process of 2D images [54,41,65,76].",,,0,not_related
"1) can also be built using neural networks to enable this functionality [76,41,65].",,,0,not_related
"Although some work has been done in this field [41,65], Pawlowski et al.",,,0,not_related
Sauer and Geiger [65] improved upon this by jointly optimising the losses of all high-dimensional mechanisms.,,,0,not_related
"The goal of disentangled representation learning is to construct a compact and interpretable latent representation, by discovering independent factors of variation (FoVs) in the data [4,11,24].",,,0,not_related
"The CRM has been wildly adopted in computer vision community for unbiased learning [1,33,38], which is however not been well studied in 3D pose estimation tasks.",,,0,not_related
"For robust out-of-domain classification, Sauer and Geiger [28] enables counterfactual generation by disentangling object shape, texture, and background without direct supervision.",,,0,not_related
"Counterfactual explanation methods [18, 19, 20, 21] help in analysing a classifier by creating several carefully constructed what-if scenarios by perturbing specific features, but are also example-based.",,,0,not_related
"Among the different forms of explanations, counterfactual explanations are recently gaining attention [9, 10, 16, 17].",,,0,not_related
"There are many different forms of explainability techniques, including feature attribution methods [5], network dissection-based interpretability [6], mechanistic approaches for understanding neural networks [7, 8], and causal/counterfactual explanations [9, 10, 11].",,,0,not_related
"[25,15] introduce causality in their generation process, to produce images from classes.",,,0,not_related
", replacing with another image’s texture as done in prior works [7, 17] hinders the model from learning semantically meaningful representations of images in the original dataset and thus negatively affects the model’s accuracy on the in-domain samples.",,,0,not_related
"Motivated by the findings from the prior works [9, 17], we designed the shape-focused augmentation introduced in Sec.",,,1,related
"To reduce the model’s heavy reliance on the image’s texture information in classifying images, numerous works [7, 17] proposed to generate images whose texture is modified and to train the model on the generated images along (b) Shape-focused augmentation (a) Original Image",,,0,not_related
"Regarding the superior performance of the model trained with shape-focused augmentation over the model trained on counterfactual images across all OOD datasets, we supposed that it results from the inherent limitations that the model architecture in CGN [17] has.",,,1,related
Sauer-Geiger [17] proposed the generative model to create counterfactual images where the texture in the foreground and background of an object are independently altered to that of other classes in ImageNet.,,,0,not_related
"By utilizing CGN [17]’s method, we generate a set of the counterfactual images where the alteration of texture makes them semantically not resembled with the images of the identical label from the original dataset as shown in Fig.",,,1,related
"Additionally, Sauer-Geiger [17] proposed the method differentiating an image into two parts by the shape silhouette of the object and independently altering texture in each divided part to the texture of other classes.",,,0,not_related
Sauer-Geiger [17] proposed counterfactual generative network (CGN) changing the texture of the foreground and background of an object in the image from ImageNet separately to the texture of other classes.,,,0,not_related
We implemented the experiment to validate the effectiveness of shape-focused augmentation by comparing it with the prior method [17] in terms of the accuracy on both the original dataset (ImageNet-100) and out-of-distribution samples (OOD dataset [6]).,,,1,related
"However, our work also partly shares the same intuition with CGN [17] in that defining visual features in an image more structurally as the foreground and background of the object and giving different variations to each part.",,,0,not_related
"…In recent years, it has drawn increasing attention
from the machine learning community (Schölkopf, 2019; Schölkopf et al., 2021), e.g., in few-shot learning (Teshima et al., 2020)(Yue et al., 2020), long-tail classification (Tang et al., 2020), and generative modeling (Sauer & Geiger, 2021).",,,0,not_related
"Counterfactual Generative Network (CGN) (Sauer & Geiger, 2020) suggests to decouple the ImageNet generation into four aspects of the shape, texture, background, and composer.",,,0,not_related
"Counterfactual synthesis (Kocaoglu et al., 2018; Sauer & Geiger, 2020; Nemirovsky et al., 2020; Yang et al., 2021; Averitt et al., 2020; Thiagarajan et al., 2021) is one of the most promising tasks to achieve the general goal of knowledge extrapolation in GANs.",,,0,not_related
"CGN explicitly models the causality in the four aspects to yield counterfactual combinations of them, like triumphal arch with the elephant texture.",,,0,not_related
"Previous works have also used GANs and VAEs for counterfactual generation (Goyal et al., 2019; Mertes et al., 2020; Sauer & Geiger, 2021; Singla et al., 2020; Liu et al., 2019; Baumgartner et al., 2018; Chang et al., 2019).",,,0,not_related
"The learning of directed acyclic graphs (DAGs) is an important problem for probabilistic and causal inference [15,17] with important applications in social sciences [11], genome research [21] and machine learning itself [16,2,18].",,,0,not_related
"Multiple works on CE use generative models to create tangible changes in the image [28, 48, 51].",,,0,not_related
"More recently, [40] decomposes image generation into parallel mechanisms (shape, texture, and background) and the distributions over the individual mechanisms are learned.",,,0,not_related
"While scaling datasets and model architectures has worked well, more structured approaches could lead to more data-efficient generalization: for instance, generative models with explicit machinery for counterfactual reasoning (Sauer & Geiger, 2021).",,,0,not_related
", 2020); (vi) increasing robustness against spurious correlations (Sauer and Geiger, 2021).",,,0,not_related
"…al., 2021); (ii) defining fairness (Kusner et al., 2017); (iii) mitigating data biases (Denton et al., 2019); (iv) improving reinforcement learning (Lu et al., 2020); (v) predicting accuracy (Kaushik et al., 2020); (vi) increasing robustness against spurious correlations (Sauer and Geiger, 2021).",,,0,not_related
"StyleGAN-XL inherits this ability and, to a certain extent, even generates out-of-domain combinations between different classes, akin to counterfactual images presented in [53].",,,0,not_related
"Other constructive works aimed to reduce the reliance of deep models on spurious features appeal to counterfactual data generation [1, 6, 17], often appealing to disentangled representations or explicit annotations to break correlations of texture, shapes, colors, and backgrounds.",,,0,not_related
"Sauer and Geiger [26] propose to disentangle object shape, object texture and background in the image generation process and generate structured conterfacturals which help improve the robustness and interpretability of classifiers.",,,0,not_related
", the work [61] specified independent modules for image background and texture.",,,0,not_related
"A growing number of recent work has used causality with machine learning [62] for disentangled representation [54, 78], model explanation [6, 13], and robust prediction [61, 24, 83].",,,0,not_related
"We use two datasets where the target attribute has a correlation strength of over 90% with the confounding factor, following the challenging settings of the latest work on visual bias [73, 17, 61, 65].",,,1,related
"Several latest works have studied causal inference combined with deep generative models for images, to learn causal structures between attributes [78, 65, 51], synthesize novel images [32, 3], and augment unbiased classifier training [61].",,,0,not_related
"The causal lens and generative counterfactual data augmentation have also shown recent, positive results in the computer vision domain [27].",,,0,not_related
"Varying Textures, Backgrounds and More As shown in [14, 29], it is hard to control texture and background in standard GANs.",,,0,not_related
"Pretrained models can be used as a guiding mechanism to disentangle causal generative factors [54], for text-driven image manipulation [44], matching the generator activations to inverted classifiers [19, 56], or to generate images via gradient ascent in the latent space of a generator [41].",,,0,not_related
"Sauer & Geiger (2021) propose a generative framework which allows choosing the color, texture and background of a generated image independently.",,,0,not_related
"Sauer and Geiger [51] proposed to decompose the image generation process into independent causal mechanisms, which disentangle object shape, object texture and background, for generating counterfactual images that improve out-of-distribution robustness.",,,0,not_related
"In previous work, [39, 51] proposed to utilize generative models to produce counterfactual images.",,,0,not_related
"Secondly, unlike [39, 51], our method proposes to generate counterfactual features rather than counterfactual images.",,,0,not_related
"ducing a counterfactual explanation exploit generative models with generative adversarial network (GAN) and its variants [33], [34], [35].",,,0,not_related
"Despite their state-of-the-art performance on object classification tasks, deep neural networks (DNN) are highly prone to shortcut learning [8, 33, 11].",,,0,not_related
"This approach has further been extended to generative model-based augmentations [31, 34, 33].",,,0,not_related
"Recent work shows the benefits of introducing causality into machine learning from various aspects (Zhang et al., 2020a; Mitrovic et al., 2020; Teshima et al., 2020; Tang et al., 2020; Sauer & Geiger, 2020; Tang et al., 2021).",,,0,not_related
"In addition, we will investigate generation module for language understanding with unsupervised generative techniques (Sauer and Geiger, 2021).",,,1,related
"Subsequent works (Wang et al., 2019; Bahng et al., 2020; Shi et al., 2020; Nam et al., 2020; Li et al., 2021; Sauer & Geiger, 2021) focus on addressing the bias problem with explicit debiasing procedure.",,,0,not_related
"Augmentation using GANs can be applied at training time for robustness or test-time for ensembling; while we primarily focus on the latter, concurrent works [35, 50] investigate the benefits of the former approach while [56] investigates intermediate GAN representations for few-shot segmentation.",,,0,not_related
"Along
this direction, for example, Sauer and Geiger (2021) recently combined disentangled generative models and out-of-distribution classification, but adopted a different disentanglement framework.",,,0,not_related
", 2020) is effective for enhancing OOD generalization, which leverages factual and counterfactual samples to push the learning of decision boundary to focus on features causally affect the label (Sauer and Geiger, 2021; Teney et al., 2020).",,,0,not_related
"A set of methods condition the generative model on attributes annotated in the dataset by using a conditional Generative Adversarial
Network (GAN) (Joshi et al., 2018; Liu et al., 2019; Sauer & Geiger, 2021; Van Looveren et al., 2021; Yang et al., 2021).",,,1,related
Our experimental setup is largely based on the description provided by Sauer and Geiger [22].,,,1,related
69 Section 5 concludes this work by discussing our experience with reproducing the research by Sauer and Geiger [22].,,,1,related
"One central 53 principle in causal inference is the assumption of independent mechanisms (IMs), which states that a causal generative 54 process is composed of autonomous modules that do not influence each other [19, 22, 24].",,,0,not_related
The counterfactual generative network is a manifestation of a structural causal model (SCM) for the task of image 72 classification [22].,,,0,not_related
"Throughout this work, we have conducted several experiments to reproduce the main results from the research by 221 Sauer and Geiger [22].",,,0,not_related
"In summary, this work makes the following contributions: 44 • We reproduce the main experiments conducted by Sauer and Geiger [22] to identify which parts of the 45 experimental results supporting their claims can be reproduced, and at what cost in terms of resources (e.",,,1,related
"37 In order to enhance the robustness and interpretability of classifiers, Sauer and Geiger [22] introduce the idea of a 38 Counterfactual Generative Network (CGN).",,,0,not_related
"(2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al.",,,0,not_related
"…inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of…",,,0,not_related
"(2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of Adversarially Learned Inference for generating counterfactual images. Normalizing flow-based methods for answering counterfactual queries has received a lot of attention in no time. For example, Pawlowski et al. (2020)’s work on healthy magnetic resonance images of the brain has been extended to account for the clinical and radiological phenotype of multiple sclerosis (MS) by Reinhold et al. (2021). Wang et al. (2021) perform counterfactual inference to achieve harmonization of brain imaging data with different protocols and from different sites in a clinical study. From a deep learning perspective, an exogenous variable might be considered as an inferred latent variable. To infer the state of the latent noise attached to an endogenous variable, we typically model a normalizing flow, perform amortized variational inference (in the case of very high dimensional variables) (Pawlowski et al., 2020) or use deterministic forward diffusion(Sanchez & Tsaftaris, 2022). Our ability to infer a latent variable comes at a computational cost as well as a statistical cost. To illustrate, the framework for counterfactual estimation by inferring exogenous noises via normalising flows parameterizes each structural assignment of an SCM as an invertible mechanism. Each mechanism explicitly calculates its inverse to enable efficient abduction of exogenous noises. These invertible architectures are typically computationally heavy. For a description of normalizing flows, see Appendix A and Papamakarios et al. (2019). However, given an SCM, in practice, we are interested in counterfactual queries involving a few variables (not all)! For example, Reinhold et al. (2021) studied what the brain image of the subject would look like if the subject did not have lesions, given the observation that they have a 60 mL lesion load. While the proposed SCM consists of age, lesion volume of the subject, duration of MS symptoms, slice number, brain volume, biological sex, image, ventricle volume, and the expanded disability severity score. Hence, it is quite natural to ask for noise variables that we can get rid of from abducting. While Pawlowski et al. (2020) have mentioned (on a footnote) in the case of brain imaging example that abduction of the noise attached to ‘sex’ is not necessary as ‘sex’ has no causal parents in the SCM1 (Figure 5, Pawlowski et al. (2020)), we are unaware of any dedicated effort to identify the noises that must be abducted to answer a counterfactual query.",,,0,not_related
"(2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of Adversarially Learned Inference for generating counterfactual images. Normalizing flow-based methods for answering counterfactual queries has received a lot of attention in no time. For example, Pawlowski et al. (2020)’s work on healthy magnetic resonance images of the brain has been extended to account for the clinical and radiological phenotype of multiple sclerosis (MS) by Reinhold et al. (2021). Wang et al. (2021) perform counterfactual inference to achieve harmonization of brain imaging data with different protocols and from different sites in a clinical study.",,,0,not_related
"For instance, Pawlowski et al. (2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of Adversarially Learned Inference for generating counterfactual images.",,,0,not_related
"(2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of Adversarially Learned Inference for generating counterfactual images. Normalizing flow-based methods for answering counterfactual queries has received a lot of attention in no time. For example, Pawlowski et al. (2020)’s work on healthy magnetic resonance images of the brain has been extended to account for the clinical and radiological phenotype of multiple sclerosis (MS) by Reinhold et al. (2021). Wang et al. (2021) perform counterfactual inference to achieve harmonization of brain imaging data with different protocols and from different sites in a clinical study. From a deep learning perspective, an exogenous variable might be considered as an inferred latent variable. To infer the state of the latent noise attached to an endogenous variable, we typically model a normalizing flow, perform amortized variational inference (in the case of very high dimensional variables) (Pawlowski et al., 2020) or use deterministic forward diffusion(Sanchez & Tsaftaris, 2022). Our ability to infer a latent variable comes at a computational cost as well as a statistical cost. To illustrate, the framework for counterfactual estimation by inferring exogenous noises via normalising flows parameterizes each structural assignment of an SCM as an invertible mechanism. Each mechanism explicitly calculates its inverse to enable efficient abduction of exogenous noises. These invertible architectures are typically computationally heavy. For a description of normalizing flows, see Appendix A and Papamakarios et al. (2019). However, given an SCM, in practice, we are interested in counterfactual queries involving a few variables (not all)! For example, Reinhold et al. (2021) studied what the brain image of the subject would look like if the subject did not have lesions, given the observation that they have a 60 mL lesion load. While the proposed SCM consists of age, lesion volume of the subject, duration of MS symptoms, slice number, brain volume, biological sex, image, ventricle volume, and the expanded disability severity score. Hence, it is quite natural to ask for noise variables that we can get rid of from abducting. While Pawlowski et al. (2020) have mentioned (on a footnote) in the case of brain imaging example that abduction of the noise attached to ‘sex’ is not necessary as ‘sex’ has no causal parents in the SCM1 (Figure 5, Pawlowski et al.",,,0,not_related
"(2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of Adversarially Learned Inference for generating counterfactual images. Normalizing flow-based methods for answering counterfactual queries has received a lot of attention in no time. For example, Pawlowski et al. (2020)’s work on healthy magnetic resonance images of the brain has been extended to account for the clinical and radiological phenotype of multiple sclerosis (MS) by Reinhold et al. (2021). Wang et al.",,,0,not_related
"(2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of Adversarially Learned Inference for generating counterfactual images.",,,0,not_related
"(2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of Adversarially Learned Inference for generating counterfactual images. Normalizing flow-based methods for answering counterfactual queries has received a lot of attention in no time. For example, Pawlowski et al. (2020)’s work on healthy magnetic resonance images of the brain has been extended to account for the clinical and radiological phenotype of multiple sclerosis (MS) by Reinhold et al.",,,0,not_related
"(2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of Adversarially Learned Inference for generating counterfactual images. Normalizing flow-based methods for answering counterfactual queries has received a lot of attention in no time. For example, Pawlowski et al. (2020)’s work on healthy magnetic resonance images of the brain has been extended to account for the clinical and radiological phenotype of multiple sclerosis (MS) by Reinhold et al. (2021). Wang et al. (2021) perform counterfactual inference to achieve harmonization of brain imaging data with different protocols and from different sites in a clinical study. From a deep learning perspective, an exogenous variable might be considered as an inferred latent variable. To infer the state of the latent noise attached to an endogenous variable, we typically model a normalizing flow, perform amortized variational inference (in the case of very high dimensional variables) (Pawlowski et al., 2020) or use deterministic forward diffusion(Sanchez & Tsaftaris, 2022). Our ability to infer a latent variable comes at a computational cost as well as a statistical cost. To illustrate, the framework for counterfactual estimation by inferring exogenous noises via normalising flows parameterizes each structural assignment of an SCM as an invertible mechanism. Each mechanism explicitly calculates its inverse to enable efficient abduction of exogenous noises. These invertible architectures are typically computationally heavy. For a description of normalizing flows, see Appendix A and Papamakarios et al. (2019). However, given an SCM, in practice, we are interested in counterfactual queries involving a few variables (not all)! For example, Reinhold et al.",,,0,not_related
"(2020) employ normalizing flows and variational inference for enabling tractable counterfactual inference, Sanchez & Tsaftaris (2022) use diffusion models for counterfactual estimation, Axel Sauer (2021) proposes counterfactual generative networks, Dash et al. (2022) incorporates a structural causal model (SCM) in a variant of Adversarially Learned Inference for generating counterfactual images. Normalizing flow-based methods for answering counterfactual queries has received a lot of attention in no time. For example, Pawlowski et al. (2020)’s work on healthy magnetic resonance images of the brain has been extended to account for the clinical and radiological phenotype of multiple sclerosis (MS) by Reinhold et al. (2021). Wang et al. (2021) perform counterfactual inference to achieve harmonization of brain imaging data with different protocols and from different sites in a clinical study. From a deep learning perspective, an exogenous variable might be considered as an inferred latent variable. To infer the state of the latent noise attached to an endogenous variable, we typically model a normalizing flow, perform amortized variational inference (in the case of very high dimensional variables) (Pawlowski et al., 2020) or use deterministic forward diffusion(Sanchez & Tsaftaris, 2022). Our ability to infer a latent variable comes at a computational cost as well as a statistical cost. To illustrate, the framework for counterfactual estimation by inferring exogenous noises via normalising flows parameterizes each structural assignment of an SCM as an invertible mechanism. Each mechanism explicitly calculates its inverse to enable efficient abduction of exogenous noises. These invertible architectures are typically computationally heavy. For a description of normalizing flows, see Appendix A and Papamakarios et al. (2019). However, given an SCM, in practice, we are interested in counterfactual queries involving a few variables (not all)! For example, Reinhold et al. (2021) studied what the brain image of the subject would look like if the subject did not have lesions, given the observation that they have a 60 mL lesion load.",,,0,not_related
FlexTENet[131] # ! # # SCP[132] # ! # # CGN[74] ! ! # # SyncTwin[101] # # ! #,,,1,related
"com/trends/explore?date=all&q=mnist [125, 198, 74, 199, 200, 201, 202, 203, 204] ADNI www.",,,1,related
", the methods considering representations of distribution balance[40, 42, 43], exploiting the effects of covariates confounding learning[53, 69, 70, 71], the methods based on generative adversarial networks[44, 72, 73, 74] , and so forth[57, 33, 75].",,,0,not_related
"com/usaito/counterfactual-cv CGN[74] MNIST,ImageNet Pytorch https://github.",,,1,related
"few studies along this line also generate counterfactual samples with neural networks (Sauer and Geiger, 2021; Yue et al., 2021).",,,0,not_related
"Thus far, state-of-the-art deep causal structure learning frameworks have been employed to model the data generation process of 2D images (Pawlowski et al., 2020; Vlontzos et al., 2022; Sauer and Geiger, 2021).",,,0,not_related
"…we also find that our approach offers the ability to effectively interpolate between OOD face images and more importantly, manipulate specific attributes of interest (e.g., non-smiling → smiling), thus validating its utility in semantic editing and counterfactual reasoning (Axel Sauer, 2021).",,,1,related
"Such data can be manipulated, interpolated or composed [12, 13, 28, 43, 44] with dedicated operators in their latent space, and further used for counterfactual reasoning [56, 65, 72, 92].",,,1,related
"Some works investigate intermediate GAN representations to construct part segmentation datasets [74, 75], while some treat pretrained GANs as black-box models and use them to augment data for robustness [76, 35] or ensembling [77].",,,0,not_related
"Examples include CausalGAN, CausalVAE, and counterfactual generative networks (Kocaoglu et al., 2017; Yang et al., 2021; Sauer & Geiger, 2021).",,,0,not_related
