text,label_score,label,target_predict,target_predict_label
"A number of authors have reported pitfalls with the use of SHAP and Shapley values as a measure of feature importance [73, 42, 66, 52, 27, 72, 55, 2, 70, 41, 14].",,,0,not_related
It is also worth noting that [2] extends the previous results to the least core with the same complexity guarantees.,,,0,not_related
It has been observed [2] that allocations that cannot be clearly communicated to participants are less likely to be perceived as fair and are thus less likely to incentivize participation.,,,0,not_related
"To do this, we leverage resuls from [2], [3], where the authors show that cost sharing mechanisms can be efficiently learned for large-scale instances.",,,1,related
"For instance, relaxing the efficiency axiom gives rise to semi-values (Kwon & Zou, 2022; Wang & Jia, 2023); relaxing the linearity axiom gives rise to least cores (Yan & Procaccia, 2021).",,,0,not_related
"…new data value notions obtained by relaxing some of the aforementioned axioms and enabled improvements in terms of accuracy of bad data identification (Kwon & Zou, 2022), robustness to learning stochasticity (Wang & Jia, 2023; Wu et al., 2022a), and computational efficiency (Yan & Procaccia, 2021).",,,0,not_related
"…LOO and influence function (Koh & Liang, 2017), the Shapley value (Jia et al., 2019b; Ghorbani & Zou, 2019; Wang & Jia, 2023), the Banzhaf value (Wang & Jia, 2022), Least Cores (Yan & Procaccia, 2021), Beta Shapley (Kwon & Zou, 2021), and reinforcement learning-based method (Yoon et al., 2020).",,,0,not_related
"L G
] 2
8 A
pr 2
02 3
& Jia, 2022), general semivalues (Kwon & Zou, 2021), and Least cores (Yan & Procaccia, 2021) to value data.",,,0,not_related
"We also consider the popular data valuation approaches: (6) Permutation Sampling-based Shapely value (Perm-SV) (Jia et al., 2019b), (7) Least Cores (LC) (Yan & Procaccia, 2021), (8) TMC-Shapley (TMC-SV) and (9) G-Shapley (G-SV) (Ghorbani & Zou, 2019).",,,1,related
"5 RELATED WORK
Existing data valuation methods include LOO and influence function (Koh & Liang, 2017), the Shapley value (Jia et al., 2019b; Ghorbani & Zou, 2019; Wang & Jia, 2023), the Banzhaf value (Wang & Jia, 2022), Least Cores (Yan & Procaccia, 2021), Beta Shapley (Kwon & Zou, 2021), and reinforcement learning-based method (Yoon et al., 2020).",,,0,not_related
"approaches have been studied by relaxing some of the underlying fair division axioms (Yan and Procaccia, 2021; Kwon and Zou, 2022a; Wang and Jia, 2022; Rozemberczki et al., 2022).",,,0,not_related
"The Shapley value is one of the most widely used marginal contributionbased methods, and many alternative approaches have been studied by relaxing some of the underlying fair division axioms (Yan & Procaccia, 2021; Kwon & Zou, 2022a; Wang & Jia, 2022; Rozemberczki et al., 2022).",,,0,not_related
"Local explanations like this have been extensively studied in recent years [8, 7, 6, 10].",,,0,not_related
Zou and Hastie (2005). Table 7 contains an example of a scoring system learnt from tabular data using SLIM for predicting the risk of pediatric appendicitis in children.,,,0,not_related
"…sampling estimator, it has been reported in several subsequent data valuation studies that the actual performance of the Group Testing-based estimator does not observably outperform permutation sampling technique [Wang et al., 2020, Yan and Procaccia, 2020, Wang et al., 2021, Wang and Jia, 2023].",,,0,not_related
"In contrast, a number of authors have reported pitfalls with the use of SHAP and Shapley values as a measure of feature importance [105, 60, 95, 74, 37, 104, 78, 2, 101, 59, 20].",,,0,not_related
"Additivity is not a requirement of influence analysis, and there are provably non-additive influence estimators [YP21].",,,0,not_related
"We provide a brief overview of cooperative game theory (examined in details in various books [45, 12]) and discuss how solution concepts in cooperative game theory have been applied in Explainable AI [15, 35, 36, 14, 56].",,,0,not_related
"Least core • δ-probable least core and (δ, ε)-probably approximate least core [Yan and Procaccia, 2021]",,,0,not_related
"It is a group notion of fairness and ensures that each C gets its dues and hence would not deviate from the grand coalition [Yan and Procaccia, 2021].",,,0,not_related
"Least core relaxations can be computed with (sub)linear time in n [Yan and Procaccia, 2021].",,,0,not_related
", 2018), which are parts of an instance that are sufficient to explain its classification, as well as scores that intend to quantify the impact of a single feature in the output of such a classification (Lundberg and Lee, 2017; Yan and Procaccia, 2021).",,,0,not_related
"In addition, by relaxing the linearity axiom of the Shapley value, Yan and Procaccia (2020) propose to use the Least core (Deng and Papadimitriou, 1994), another classic concept in cooperative game theory, as an alternative to the Shapley value for data valuation.",,,0,not_related
"Due to the great potential in real applications, there has been a surge of research efforts on developing data value notions for supervised ML (Jia et al., 2019b; Ghorbani and Zou, 2019; Yan and Procaccia, 2020; Ghorbani et al., 2021; Kwon and Zou, 2021; Yoon et al., 2020).",,,0,not_related
The estimation algorithm for the least core is the Monte Carlo algorithm from Yan and Procaccia (2020).,,,0,not_related
"Some alternative methods [106, 104] enjoy better efficiency or coalition stability, but lose fairness guarantee.",,,0,not_related
Yan and Procaccia [104] tackle the efficiency issue by proposing a Monte Carlo approximation algorithm with guaranteed approximation errors.,,,0,not_related
"Yan and Procaccia [104] design a data pricing model based on core [35], which is a celebrated revenue allocation solution in cooperative game theory.",,,0,not_related
"However, Yan and Procaccia [104] argue that the necessity of additivity for data valuation is debatable.",,,0,not_related
"Yan T, Procaccia AD (2021) If you like shapley then you’ll love the core.",,,0,not_related
"Sampling-based heuristics comprise of all the existing unbiased heuristics (Castro et al., 2009; Jia et al., 2019b; Yan & Procaccia, 2020) as well as some of the biased heuristics (e.g., TMC Shapley (Ghorbani & Zou, 2019)).",,,0,not_related
"For larger datasets, since it is impractical to compute the exact data value, we compare the performance of data value estimates on data removal task, following existing data valuation literature (Ghorbani & Zou, 2019; Jia et al., 2019a;c; Wang et al., 2020; Yan & Procaccia, 2020).",,,1,related
"For LC estimation, we use Monte Carlo (MC) approach (Yan & Procaccia, 2020) as the baseline.",,,1,related
"In the experiment, when we talk about the LC, we always refer to the vector ψ that has the smallest `2 norm, following the tie-breaking rule in Yan & Procaccia (2020).",,,1,related
"As a side note, the Shapley value estimated by Permutation sampling is superior to the Least core estimated by Monte-Carlo algorithm, which does not agree with the experiment results in Yan & Procaccia (2020).",,,1,related
"We follow Yan & Procaccia (2020) and define the (ε, δ)-probably approximate least core to be the vector ψ ∈ Rn s.t. PrS∼D [∑ i∈S ψi + e ?",,,1,related
"Recently, Yan & Procaccia (2020) propose to use the Least core, another classic solution concept in cooperative game theory, as an alternative to Shapley value for data valuation.",,,0,not_related
"This proof directly extends the proof of Theorem 2 of Yan & Procaccia (2020), which is based on the observation in Balcan et al. (2015) and Balkanski et al. (2017) that estimating least core from finite samples is equivalent to the problem of learning an unknown linear function (x, e) s.t.∑ i∈S xi…",,,0,not_related
"When σ = 0, Theorem 2 recovers Theorem 2 in Yan & Procaccia (2020) for the case of v̂ = v.",,,1,related
"In this paper, when we talk about the least core, we always refer to the least core vector that has the smallest `2 norm, following the tie-breaking rule in the original literature [18].",,,1,related
"More recently, [18] suggests that the Least core is also a viable alternative to Shapley value for measuring data importance.",,,0,not_related
"(5) Least Core (LC) [18], another data value notion in cooperative game theory.",,,0,not_related
", influence functions [10], Shapley values [16, 17] and least cores [18], to quantify each training point according to the contributions toward the training processes, then decide which data to retain or remove based on the valuation rankings.",,,0,not_related
purpose Driven Agnostic Utility Traditional × × × × Data Cleaning × ◦ ◦ × Perm-Shapley [19] X X X × TMC-Shapley [16] X X X × G-Shapley [16] X X × × KNN-Shapley [20] × × X × Least Core [18] X X X × Leave-one-out [10] X X X × Infl.,,,0,not_related
"variants of the Banzhaf index as seen in this work and others [10, 35]) and even the core [41].",,,0,not_related
"Other work suggests using a different metric, the core [102] which is also apt for coalitional games.",,,0,not_related
"Examples of global explanations include using a second interpretable model to approximate the black-box model, often termed “model distillation” [9, 19, 25, 26, 32, 40, 55], analyzing intermediate representations [10, 47] or concepts [37] encoded by the black-box model, prototype selection [12, 36, 65], counterfactual explanations [52] that summarize actions that can be taken to change the black-box model’s predictions for an entire population, and feature importance measures [13, 18, 22, 45, 68, 71].",,,0,not_related
"…two works from the broader ML community have mentioned these other values, and neither are directly comparable to our case of explaining graph data: Yan & Procaccia (2021) studies the core value for data valuation, while Chen et al. (2019) mentions the Myerson value (Myerson, 1977) in the context…",,,0,not_related
"Recently, there has been a surge of research efforts on formalizing the notion of data value for supervised ML [Jia et al., 2019b,a, Ghorbani and Zou, 2019, Yan and Procaccia, 2020, Ghorbani et al., 2021, Kwon and Zou, 2021, Yoon et al., 2020].",,,0,not_related
"The estimation algorithms for the least core is the Monte Carlo algorithm from [Yan and Procaccia, 2020].",,,0,not_related
"Yan and Procaccia [Yan and Procaccia, 2020] propose to use the Least core [Deng and Papadimitriou, 1994], another classic concept in cooperative game theory, as an alternative to the Shapley value for data valuation.",,,0,not_related
"• Following the game-theoretic approaches to capture the degree of influence on inconsistency [12] or of inputs on outputs in decision making systems [13, 14, 15, 16, 17], we can for instance use Shapley(-like) values:",,,0,not_related
