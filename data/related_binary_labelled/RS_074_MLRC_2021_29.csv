text,label_score,label,target_predict,target_predict_label
"Starting with explicit intermediate shape representations, such as voxels [38, 19] and meshes [42], which lack photorealism and are memory-inefficient, researchers have recently shifted towards using implicit functions [44, 36, 9] along with physical rendering processes [60, 37] as intrinsic 3D inductive biases.",,,0,not_related
"Inspired by the success of Generative Adversarial Networks (GAN)[16] in generating photorealistic images[24, 5, 26], researchers have been making efforts towards 3D-aware generation [38, 19, 42].",,,0,not_related
"Later approaches [10, 36, 58, 48, 68, 37, 9] successfully extract the 3D representations by the 3D generator and refine the output using image-based CNN networks.",,,0,not_related
"Prior approaches utilize GANs [19, 33, 55] to synthesize data for tasks including classification [2, 8, 43, 72, 75], 3D vision [21, 52, 64, 86], 2D segmentation [44, 74, 87], dense visual alignment [54]; or diffusion models [27, 59] for data augmentation [73] or as synthetic data for few-shot learning [25].",,,0,not_related
"Some works go further [10, 17] and reconstruct some simple 3D models from a single image.",,,0,not_related
"Conversely, other approaches [36, 58] use a single channel for illumination, which only enforces white illumination.",,,0,not_related
The recovered 3D shapes allow high-quality image editing such as relighting and object rotation [148].,,,0,not_related
"However, one common property among Unsup3d-based frameworks [5]–[8] is the absence of skip connections [9] giving networks the advantage of picking up useful details for tasks.",,,0,not_related
GAN2Shape [8] trained reconstruction networks with the help of 3D geometry clues mined from the pre-trained GAN.,,,0,not_related
"What is known about what StyleGAN knows: Various papers have investigated what StyleGAN knows, starting with good evidence that StyleGAN “knows” 3D information about faces [38, 65], enough to support editing [40, 39, 52].",,,0,not_related
Our experimental results show comparable performances to GAN2Shape [12] in terms of 2D level.,,,1,related
"Method 3DMMCNN [5]
3DMM GCN [18] Nonlinear 3DMM [7]
Unsup3D [8] GAN2Shape [12]
Ours 3DMM+CNN [5]
3DMM+GCN [18] Nonlinear 3DMM [7]
Unsup3D [8] GAN2Shape [12]
Ours
Dataset Ce1ebA Ce1ebA CelebA Ce1ebA Ce1ebA Ce1ebA
Bosphorus Bosphorus Bosphorus Bosphorus Bosphorus Bosphorus PSNR(dB)t 26.58 29.69 27.36 29.51 29.92 29.87 26.37 29.24 26.91 29.06 29.58 29.54 SSIMt 0.826 0.894 0.857 0.883 0.898 0.903 0.778 0.861 0.813 0.876 0.867 0.872 N-CD+ 0.0260 0.0145 0.0203 0.0194 0.0139 0.0136",,,1,related
"Unsup3d [8], GAN2Shape [12]) on datasets(CelebA, Bosphorus) in Table I.",,,0,not_related
"We compare our method with five state-of-the-art methods (3DMM CNN [5], 3DMM GCN [18], Nonlinear 3DMM [7], Unsup3d [8], GAN2Shape [12]) on datasets(CelebA, Bosphorus) in Table I.",,,1,related
Method 3DMMCNN [5] 3DMM GCN [18] Nonlinear 3DMM [7] Unsup3D [8] GAN2Shape [12] Ours 3DMM+CNN [5] 3DMM+GCN [18] Nonlinear 3DMM [7] Unsup3D [8] GAN2Shape [12] Ours Dataset Ce1ebA Ce1ebA CelebA Ce1ebA Ce1ebA Ce1ebA Bosphorus Bosphorus Bosphorus Bosphorus Bosphorus Bosphorus PSNR(dB)t 26.,,,0,not_related
"[12] proposed a multi-stage 3D face reconstruction framework, which utilized GAN in the second stage of training to infer the viewpoint and illumination changes of images to obtain accurate 3D face shapes.",,,0,not_related
"[2] was adopted in the experiment, which may be summed up as follows: 1.",,,0,not_related
"In [105], the authors answer the question, ”Is it possible to reconstruct the 3D shape of a single 2D image by exploiting the 3D-alike image manipulation effects produced by GANs?” with a yes using their unsupervised approach, GAN2Shape, by showing that when existing 2D GANs are trained only on images, they could accurately reconstruct its 3D shape for objects belonging to several categories including human faces, cars, buildings among others without the need for a 2D keypoint or 3D annotations.",,,0,not_related
[30] attempts to reconstruct the 3D shape using pretrained 2D GANs.,,,0,not_related
"Iterative methods [50, 30, 7] based on StyleGAN optimization can produce the most realistic face UV images.",,,0,not_related
"To this end, we use the pre-trained model of Unsup3D [45] since it has been widely applied in unsupervised face reconstruction [50, 30, 35, 49] in recent years.",,,1,related
"Previously, some approaches attempt to extract 3D structure from pretrained 2D-GANs [44, 54].",,,0,not_related
", voxels [15,31] and meshes [34] as the intermediate shape models, which lacks photorealism and is memory-inefficient.",,,0,not_related
"Generative Adversarial Network [13] has shown promising results in generating photorealistic images [5, 21, 22] and inspired researchers to put efforts on 3D aware generation [15, 31, 34].",,,0,not_related
"2021] and physics-based decomposition methods [Pan et al. 2021; Wu et al. 2020], refer to the Supplemental Document.",,,0,not_related
"Another research direction is to reconstruct the 3D geometry of an input image based on the physics-based priors of light transport, where Unsup3d [Wu et al. 2020], GAN2Shape [Pan et al. 2021], and StyleGANRender [Zhang et al. 2021] show promising results.",,,0,not_related
"2020], GAN2Shape [Pan et al. 2021], and StyleGANRender [Zhang et al.",,,0,not_related
"For the results of parametric fitting [Feng et al. 2021] and physics-based decomposition methods [Pan et al. 2021; Wu et al. 2020], refer to the Supplemental Document.",,,0,not_related
"Generative Adversarial Networks (GANs) [10] have shown promise in learning unsupervised representations of 2D data, even learning information about the underlying 3D geometry [28].",,,0,not_related
"Using the knowledge that 2D GANs can learn 3D geometrical information [28], we train a StyleGAN2 [17] network to generate rendered feet from StyleGAN2 latent codes.",,,1,related
"Recent work of [38, 57] leverage photo-geometric autoencoding and neural rendering [49] to reconstruct depth map, while estimating albedo map, viewpoint and lighting condition from a single image.",,,0,not_related
"Compared to the SFS-based approaches [27, 38, 57], ours",,,0,not_related
"Other methods focus on wild images and reconstruct 3D faces in supervised [15, 66] or unsupervised ways [33, 49].",,,0,not_related
"While aforementioned 2D GANs [15], [17], [22], [23] allow explicit head pose control to some extent, they fail to guarantee appearance consistency, leading to inconsistent identity or facial attributes when viewed from vastly different angles.",,,0,not_related
"Training one cycle of the above three steps is not enough to reconstruct the 3D shape with fine details, hence we repeat these three steps four times to refine the 3D reconstructed results [20].",,,0,not_related
"[20] adopts an ellipsoid shape as the shape prior, giving better estimations on the face depth.",,,0,not_related
"However, the discovered semantic directions by these methods are still coupled [20] with other semantic concepts.",,,0,not_related
"Since the 3D shape reconstruction requires images of consistent multiple views and lighting, recent works [6], [7], [20], [33], [34] attempt to uncover extra cues to guide the learning process.",,,0,not_related
"Note that here we have the latent codes w for the original input images as discussed in Section III-C, hence we predict the offset ∆w with an encoder E(·) to ease the training difficulty [20], whose optimization process can be denoted as",,,1,related
"[20], [33], [35] aim to manipulate the latent codes of StyleGAN [8], [9] to generate synthetic data for 3D shape learning.",,,0,not_related
"We take the iterative learning scheme of [20], and initialize the shape prior with an ellipsoid shape.",,,1,related
"However, the rendered images have unnatural distortions, we follow [20] to project the rendered images back to the latent space W of StyleGAN, which gives strong regularization on the projected images, such that they can have better quality.",,,0,not_related
"To reconstruct the 3D avatar shape from a single image, we follow the method proposed by [20], [34], where we use the manipulated images through StyleGAN to give the various viewpoint and lighting information.",,,1,related
Hence we follow [20] to reconstruct the 3D cartoon shapes.,,,1,related
"Recently, a few methods [57,47] have incorporated a pre-trained StyleGAN with a differentiable renderer, but they struggle with photorealism, high-resolution [47] and real image editing [57].",,,0,not_related
"In addition, a few unsupervised approaches have been proposed by adopting implicit 3D feature [42,43] or differentiable renderer [57,47] in generation.",,,0,not_related
"[38] recover the geometric cues from pre-trained 2D GANs and achieve exceptional reconstruction results, but the reconstructed shapes are limited to 2.",,,0,not_related
"5D, depth ✗ ✗ GAN models, pre-trained ✓ GAN2Shape [44] 2.",,,0,not_related
"Similarly, GAN2Shape [44] produces an unsupervised decomposition by using a GAN model as supervision.",,,0,not_related
"Early attempts [44,52,63] are made to mine 3D geometric cues from the pretrained 2D GAN models in an unsupervised manner.",,,0,not_related
"Additionally, we add a depth smoothness loss Lds used in [3, 27] to reduce inference error of surface normals.",,,1,related
"Differently, the semantics-embedding networks of GAN2Shape use the rendered images as a intermediary, while LiftedGAN does not and achieves high-fidelity rotation results in a large angle range.",,,0,not_related
"As GAN2Shape has to do GAN inversion to produce multi-view images, it will have more model parameters and cost much more time to retrain its networks for each input image.",,,0,not_related
"Besides, GAN2Shape, while produces realistic qualitative results, is a resource-consuming method that should additionally
re-train StyleGAN2.",,,0,not_related
"GAN2Shape [3] and [16] uses randomly sampled view to render more versions of input for learning, while SMR uses interpolated attributes to avoid unreasonable sampling values.",,,0,not_related
"7, are not vivid enough comparing to GAN2shape [3].",,,0,not_related
GAN2Shape [3] and LiftedGAN [24] use neural networks and a differentiable renderer [25] for reasoning the mapping process by semantics-embedding-semantics selfmapping.,,,0,not_related
Experiments show that ASRMM outperforms the stateof-the-art unsupervised shape learning methods [3] on BFM [8] dataset in some reconstruction metric.,,,0,not_related
"To further improve the reconstruction quality, some methods consider to sample and generate novel-view images to enrich the diversity of the training data, while this idea may require silhouette annotations [1, 2] or models of inferring novel-view images [3].",,,0,not_related
"In contrast, our ASRMM focuses on a light way to improve the reconstruction accuracy, without relying on heavy prior models for view changing or relighting, but our ASRMM is also inspired by [3, 22, 24] that style-transferred images can improve the diversity of the input, and we transfer image style by making the material monotonous.",,,0,not_related
7 Limitations of our proposed model comparing to GAN2Shape [3].,,,1,related
"Although GAN2Shape [3] introduces a strong image generator StyleGAN2 [20] to produce vivid novel-view images, ASRMM still outperforms it in SIDE and reach close performance in MAD.",,,0,not_related
"In Table 4, we also compare ASRMM with Unsup3d and GAN2Shape in terms of model complexity and time consuming.",,,1,related
"Unsupervised Shape Reconstruction We quantitatively compare our ASRMM with a fully-supervised baseline and two unsupervised methods [3, 8] in Table 4.",,,1,related
An efficient unsupervised approach for reconstructing 3D shapes has been discussed in paper [2].,,,0,not_related
Modern GANs are a lot of engineering and it often takes a lot of futile experiments to get to a point where the obtained performance is acceptable.,,,0,not_related
"We believe that the future of 3D GANs is a combination of efficient volumetric representations, regularized 2D upsamplers, and patch-wise training.",,,0,not_related
"In contrast to classical NeRF [38], we do not utilize view direction conditioning since it worsens multi-view consistency [7] in GANs which are trained on RGB datasets with a single view per instance.",,,1,related
"Note that this high training efficiency is achieved without the use of an upsampler, which initially enabled high-resolution synthesis of 3D-aware GANs.",,,0,not_related
"Also, in contrast to upsampler-based 3D GANs, our generator can naturally incorporate the techniques from the traditional NeRF literature.",,,0,not_related
NeRF-based GANs.,,,0,not_related
"Compared to upsampler-based 3D GANs [15, 43, 72, 79, 6, 78], we use a pure NeRF [38] as our generator G and utilize the tri-plane representation [6, 8] as the backbone.",,,1,related
"Recently, there appeared works which train from single-view RGB only, including mesh-generation methods [19, 73, 53] and methods that extract 3D structure from pretrained 2D GANs [58, 48].",,,0,not_related
"Apart from that, we also compare to pi-GAN [7] and GRAM [12], which are non-upsampler-based GANs.",,,1,related
"Finally, 3D GANs generating faces and humans may have negative societal impact as discussed in Appx G.",,,0,not_related
Patch-wise training of NeRF-based GANs was originally proposed by GRAF [56] and got largely neglected by the community since then.,,,0,not_related
"But for NeRF-based GANs, it becomes prohibitively expensive for high resolutions since convolutional discriminators operate on dense full-size images.",,,0,not_related
"Training NeRF-based GANs is computationally expensive, because rendering each pixel via volumetric rendering requires many evaluations (e.g., in our case, 96) of the underlying MLP.",,,0,not_related
"People address these scaling issues of NeRF-based GANs in different ways, but the dominating approach is to train a separate 2D decoder to produce a high-resolution image from a low-resolution image or feature grid rendered from a NeRF backbone [43].",,,0,not_related
"Our method partially uses [32] as a tool, but we go beyond it to further explore if GANs can also be used to disentangle material properties.",,,1,related
We first initialize Fs to produce an ellipsoid as a convex shape prior following [32].,,,1,related
"Different from [32], in this work the inverse rendering is based on the new non-Lambertian neural representation and rendering equation introduced before.",,,0,not_related
4 shows the qualitative comparison between our approach and two unsupervised inverse rendering baselines Unsup3d [52] and GAN2Shape [32] on the CelebA dataset.,,,1,related
"GAN2Shape [32] assumes Lambertian reflectance and does not recover high-quality albedo, while [62] does
not disentangle albedo and illumination.",,,0,not_related
"GAN2Shape [32] assumes Lambertian reflectance and does not recover high-quality albedo, while [62] does not disentangle albedo and illumination.",,,0,not_related
"Similar to us, [32] and [62] also exploit GANs to reconstruct 3D shapes.",,,0,not_related
"Apart from Unsup3d and GAN2Shape, we also compare with pi-GAN [9] and ShadeGAN [33] that can perform unsupervised 3D reconstruction via GAN inversion.",,,1,related
"Inspired by [32], we adopt an exploration-and-exploitation algorithm to generate pseudo multi-view and multi-lighting images from a pretrained GAN.",,,1,related
"Having this dependence allows us to further extend our method for joint training on multiple instances as done in [32], which improves generalization.",,,1,related
"It is shown in the recent Shape-from-GAN works [32, 62] that the pseudo paired data generated by GAN can be used to reconstruct 3D shapes.",,,0,not_related
"In order to generate a number of approximated paired images of various viewpoint and lighting conditions using the GAN, we adopt an exploration and exploitation algorithm following [32].",,,1,related
GAN2Shape [42] avoids such symmetric constraint but brings heavy per-image optimization.,,,0,not_related
"More recent works [42, 58] disentangle a face into intrinsic factors and accomplishes canonical reconstruction in an unsupervised manner via render-",,,0,not_related
Gan2Shape [40] and LiftedGAN [51] try to distill knowledge from 2D GANs for 3D reconstruction.,,,0,not_related
"ized by certain latent space in unsupervised GANs, contains rich 3D geometric clues [11], such that walking along certain paths on the manifold could lead to meaningful geometric transformation of an underlying object (e.",,,0,not_related
"Template-based methods assume that all target shapes can be represented by deforming a template mesh, usually a sphere [5, 10, 22, 27, 35, 43] or a plane [33, 46].",,,0,not_related
"More relevant topics to 3D-aware deformation would be (1) human pose transfer [6, 29, 33], which works only for human bodies, (2) novel view synthesis [13, 37, 51], which is limited to altering a viewpoint of an image, and (3) 3D modelbased manipulation [26], which requires the exact 3D model of the object in an image.",,,0,not_related
", not deviate too far from mean face [58,26,27,4,44]).",,,0,not_related
"…Steenkiste, Locatello, Schmidhuber, and Bachem], [Yue et al.(2021)Yue, Wang, Sun, Hua, and Zhang], discovery of physical concepts [Iten et al.(2020)Iten, Metger, Wilming, Del Rio, and Renner] and enabling 3D shape reconstruction from 2D images [Pan et al.(2020)Pan, Dai, Liu, Loy, and Luo].",,,0,not_related
"(2020)Iten, Metger, Wilming, Del Rio, and Renner] and enabling 3D shape reconstruction from 2D images [Pan et al.(2020)Pan, Dai, Liu, Loy, and Luo].",,,0,not_related
"[Pan et al.(2020)Pan, Dai, Liu, Loy, and Luo] Xingang Pan, Bo Dai, Ziwei Liu, Chen Change Loy, and Ping Luo.",,,0,not_related
"[65] Xingang Pan, Bo Dai, Ziwei Liu, Chen Change Loy, and Ping Luo.",,,0,not_related
"Prior work has explored the use of GANs [27, 68] in vision tasks such as classification [10, 12, 55, 75, 85], segmentation [57, 80, 83, 91] and representation learning [7, 20, 21, 23, 36], as well as 3D vision and graphics tasks [28, 65, 73, 90].",,,0,not_related
2020) and recover explicit 3D shapes from images (Pan et al. 2020; Zhang et al. 2020).,,,0,not_related
"In another line of work, the 3D scene information is extracted from 2D GANs such as StyleGAN2 to manipulate 2D images in 3D (Shen and Zhou 2020; Härkönen et al. 2020) and recover explicit 3D shapes from images (Pan et al. 2020; Zhang et al. 2020).",,,0,not_related
"Recently, GAN2Shape [41] shows that it is possible to recover 3D shapes for images generated by 2D GANs.",,,0,not_related
"Besides, ShadeGAN also outperforms other advanced unsupervised 3D shape learning approaches including Unsup3d [39] and GAN2Shape [41], demonstrating its large potential in unsupervised 3D shapes learning.",,,0,not_related
"In experiments, we demonstrate superior performance over recent state-of-the-art approaches Unsup3d [39] and GAN2Shape [41].",,,1,related
"Note that the symmetry is a double-edged sword, and it facilitates the fitting of symmetrical objects [44,58] such as human faces, cat faces, cars, etc.",,,0,not_related
"scratch [11], [12], [13], [14], [15], [16], [17].",,,0,not_related
"Semantic Field for Facial Editing Given an input image I ∈ R3×H×W and a pretrained GAN generator G, similar to previous latent space based manipulation methods [40, 41, 59, 35], we need to firstly inverse the corresponding latent code z ∈ R such that I = G(z), and then find the certain vector fz ∈ R which can change the attribute degree.",,,1,related
"GAN-based approaches [18, 7] for 3D reconstruction demonstrate high quality outputs and have recently been extended to allow control over the output.",,,0,not_related
"Adversarial learning has also been explored to replace the need of multi-views for training (Kudo et al., 2018; Chen et al., 2019; Henzler et al., 2019; Nguyen-Phuoc et al., 2019, 2020; Ye et al., 2021; Schwarz et al., 2020; Niemeyer & Geiger, 2021; Zhang et al., 2021; Chan et al., 2021; Pan et al., 2021).",,,0,not_related
"To alleviate the problem, random augmentation strategies were used to generate novel attributes in [27, 19, 30].",,,0,not_related
"Reconstruction on BFM: In this experiment, we combine our proposed IC and LC with the unsupervised reconstruction methods [41, 30] on the BFM Face reconstruction dataset.",,,1,related
"Compared with the original [10, 18] or randomly augmented attribute in [30], our interpolated attributes can render images with more viewpoints, geometrical structures, and appearances, thus is more efficient to promote the learning process of the target attribute encoder.",,,0,not_related
The main difference between [30] and our IC is that the former randomly augments attributes.,,,1,related
"Other works have taken this approach in the context of extracting 3D structure from 2D images [33]; Inverse Graphics GAN [29] uses a neural renderer to recover 3D (voxelbased) representations of scenes, and GAN2Shape [38] ex-",,,0,not_related
"Other works have taken this approach in the context of extracting 3D structure from 2D images [33]; Inverse Graphics GAN [29] uses a neural renderer to recover 3D (voxelbased) representations of scenes, and GAN2Shape [38] ex-
ploits viewpoint and lighting variations in generated images to recover 3D shapes.",,,0,not_related
"Apart from linear edit directions, recent works [67, 36] learn latent editing operations that control the 3D appearance of generated images.",,,0,not_related
"To generate 3D shapes directly from text or sound, we can easily integrate our method with a concurrent shape reconstruction method [74] for the reason that we share the same latent space of a pretrained GAN model.",,,1,related
"[48] Xingang Pan, Bo Dai, Ziwei Liu, Chen Change Loy, and Ping Luo.",,,0,not_related
"Examples include various image and video editing tasks, image inpainting [13, 47, 46, 41], local image editing [42, 2], low bit-rate video conferencing [40], image super resolution [28, 12], image colorization [4, 27], and extracting 3D models [30].",,,0,not_related
"common image editing applications, in the last few months, GAN inversion techniques have been widely introduced to many other tasks, such as 3D reconstruction [132], [133],",,,0,not_related
[132] first render a number of unnatural images with various randomly sampled viewpoints and,,,0,not_related
[18] propose to iteratively synthesize data and train the reconstruction network.,,,0,not_related
"[18], which use StyleGAN2 to create synthetic training data.",,,0,not_related
"[18], we implement Equation (3) as two parts.",,,1,related
[18] have utilized StyleGAN to generate multiview synthetic data for 3D reconstruction tasks.,,,0,not_related
"However, different from them, we do not need any manual annotation [31] nor iterative training [18].",,,1,related
"manipulation [15], [39], [40], [41], [42], [43], but is restricted to synthetic images of the GAN itself or real images of limited complexity, e.",,,0,not_related
", and can be applied to face rendering [18], [19], [20].",,,0,not_related
"We recompose the photo-geometric autoencoding model in [20] by combining GANs and renderer, and adjust the output of the GANs to view, light, albedo, and normal (as shown in Fig.",,,1,related
"As a result, later methods moved away from fully convolutional GANs by incorporating 3D inductive biases in the architecture and training pipeline, such as 3D neural representations and differentiable rendering methods [34, 35, 47, 38].",,,0,not_related
"As a result, later works aimed at unsupervised methods by introducing 3D inductive biases in GANs, including 3D neural representations and differentiable rendering [34, 38, 47, 35] These methods, although promising, lag far behind 2D GANs in terms of image quality or struggle with high-resolution generation due to the additional computational complexity compared to the convolutional generators.",,,0,not_related
"[14] proposed a GAN2Shape model to recover 3-D shapes from a single RGB image in an unsupervised manner which mines only some 3-D geometric cues from 2-D images generated by generative adversarial network (GAN), and depth information of the RGB image cannot be provided.",,,0,not_related
"While aforementioned 2D GANs [15], [17], [22], [23] allow explicit head pose control to some extent, they fail to guarantee appearance consistency, leading to inconsistent identity or facial attributes when viewed from vastly different angles.",,,0,not_related
"[18] first used a neural renderer to generate pseudo samples with various poses and lightings, then used these samples to guide the images generated by GANs toward the corresponding sampled poses and lighting conditions.",,,0,not_related
"3 Transcoder It has been observed in prior works that altering viewpoint by directly manipulating the style code is possible [28, 33].",,,0,not_related
"For instance, StyleGAN [13] representations have been shown to disentangle pose, shape and fine detail naturally, a property which has been used to help lift objects to 3D [12, 17, 28, 33, 39], these methods are 3D aware, but lack multi-view consistency.",,,0,not_related
